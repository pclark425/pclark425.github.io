<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5162 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5162</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5162</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-109.html">extraction-schema-109</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <p><strong>Paper ID:</strong> paper-250975117</p>
                <p><strong>Paper Title:</strong> A Hybrid Account of Concepts Within the Predictive Processing Paradigm</p>
                <p><strong>Paper Abstract:</strong> We seem to learn and use concepts in a variety of heterogenous “formats”, including exemplars, prototypes, and theories. Different strategies have been proposed to account for this diversity. Hybridists consider instances in different formats to be instances of a single concept. Pluralists think that each instance in a different format is a different concept. Eliminativists deny that the different instances in different formats pertain to a scientifically fruitful kind and recommend eliminating the notion of a “concept” entirely. In recent years, hybridism has received the most attention and support. However, we are still lacking a cognitive-computational model for concept representation and processing that would underpin hybridism. The aim of this paper is to advance the understanding of concepts by grounding hybridism in a neuroscientific model within the Predictive Processing framework. In the suggested view, the different formats are not distinct parts of a concept but arise from different ways of processing a functionally unified representational structure.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5162.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5162.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar theory of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional-level account that represents category concepts as collections of stored individual instances (exemplars) and performs classification by matching/selection among those stored instances.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is functionally represented as a set of remembered particular instances; categorization and related tasks are performed by retrieving/matching those stored exemplars and choosing the hypothesis that best predicts current input.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>exemplar / instance-based, distributed memory of instances</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>instance-level storage; variable specificity (can be vague or highly detailed); relies on similarity between stored exemplars and target; flexible and context-sensitive via retrieval processes.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Explains item-specific advantages in categorization (old-item advantage), many behavioral exemplar effects in category learning literature (cited classic works such as Medin & Schaffer 1978; Nosofsky 1986; Smith & Minda 1998/2000 referenced in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Fails alone to account for broad range of data (format heterogeneity); cannot by itself explain prototype-like typicality effects or theory/causal knowledge effects without additional structure (paper cites general critiques that no single-format account covers all empirical phenomena).</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization, similarity judgments, memory-for-instances effects, item recognition in concept tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasted with prototype theory (instance vs. abstract summary) and theory-theory (instance vs. causal/theoretical structure); in this paper exemplar-mode is recast as deeper, downward processing of a unified hierarchical representation rather than a separate stored module.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>In the paper's PP reformulation, exemplar processing corresponds to relatively deep downward activation of lower-level nodes in a hierarchical generative model so that stored specific-instance hypotheses minimize prediction error for detailed inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Cannot explain why exemplar vs. prototype use is selected in context without an explicit mechanism; classical exemplar accounts lack the precision-weighting/selection mechanism PP supplies; interaction with theory-like knowledge remains under-specified in pure exemplar accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Hybrid Account of Concepts Within the Predictive Processing Paradigm', 'publication_date_yy_mm': '2022-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5162.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5162.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype theory of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional account that represents categories by one or more abstracted summary representations (prototypes) encoding typical features and typicality gradients, used for classification by matching target stimuli to these summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is functionally represented as compressed, abstracted summaries (prototypes) that encode typical feature values and typicality relations; categorization uses these coarse-grained expectations rather than stored particulars.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>prototype / summary-statistic, feature-based compressed representation</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>abstracted over instances, graded typicality, computationally efficient, captures typicality effects, context-sensitive in use though more schematic than exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Accounts for typicality effects (e.g., sparrow judged a more typical bird than ostrich) and many categorization phenomena cited in prototype literature (Rosch 1978; Posner & Keele 1968 referenced in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Fails to account for exemplar-specific advantages and for many cases where causal/theoretical knowledge determines classification; alone cannot capture full heterogeneity of conceptual behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Typicality judgments, basic-level categorization, rapid coarse-grained predictions in perception and action.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Set against exemplar models (concrete instances) and theory-theory (causal/structural knowledge); in this paper prototype-mode is reinterpreted as shallower activation of higher-level nodes in a hierarchical predictive model rather than a distinct stored format.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Within the paper's PP account, prototype processing corresponds to activation limited to higher, more compressed nodes of the concept's subnetwork so that coarse-grained priors minimize prediction error with minimal lower-level detail.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Does not by itself explain how abstraction is computed or selected in context; needs mechanisms for selecting abstraction level (provided by PP precision-weighting in the paper) and for integrating with causal/theoretical knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Hybrid Account of Concepts Within the Predictive Processing Paradigm', 'publication_date_yy_mm': '2022-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5162.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5162.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Theory-theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Theory-theory (theory-like representations in concepts)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A family of accounts positing that conceptual knowledge includes or is structured by theory-like (causal, explanatory, taxonomic) information; concepts either constitute parts of broader folk-theories or are themselves small, partial theories.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Theory-theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are functionally embedded in or constituted by structured bodies of causal/explanatory knowledge (folk theories); classification and inference rely on invoking these theory-like networks rather than mere similarity to instances.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>theory-based / causal-network or schema-like representations (could be sub-symbolic or propositional depending on version)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>captures causal, taxonomic, mereological relations; can be liberal (loose, folk-theory style) or literal (coherent, scientific-theory analogue); supports inferential reasoning beyond surface similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Explains knowledge effects like Rips' pizza experiment where causal/production knowledge shifts categorization independent of surface similarity; supports explanations for essentialist reasoning and other folk-theory phenomena (cited studies such as Rips 1989, Gelman).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Ambiguity about representational format (mini-theory vs. concept-as-constituent); strict literal versions are psychologically implausible; classical theory-theory does not specify mechanistic/representational implementation for how theories are stored and used in real-time tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Causal reasoning, inductive inference, taxonomic classification, judgments where background knowledge overrides similarity (e.g., Rips' tasks), folk biology/psychology domains.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasted with prototype/exemplar accounts which emphasize similarity-based processing; the paper argues theory-mode is realized by upward and lateral processing in a hierarchical predictive model rather than separate propositional belief modules.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>In the paper's PP account, theory processing corresponds to exploiting connectivity of a concept node to higher-level and lateral nodes (schemas, causal frames) to perform generative/inferential predictions and to explain lower-level features.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to represent coherence and explanatory structure mechanistically remains underspecified in classical theory-theory; distinguishing literal vs. liberal readings leaves questions about necessary structure and granularity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Hybrid Account of Concepts Within the Predictive Processing Paradigm', 'publication_date_yy_mm': '2022-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5162.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5162.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mereological hybridism</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mereological hybrid accounts of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Hybrid models that treat different format-instances (exemplar, prototype, theory) as distinct components or parts combined into a composite concept, typically without detailed integration mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Mereological hybrid accounts</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are wholes composed of distinct format-specific parts (e.g., a prototype part, an exemplar part, a theory part) that are aggregated but often lack principled mechanisms for functional integration or selection.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>multi-part composition of format-specific sub-representations (modular parts)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>plural-format storage; compositional clustering of separate representations; often minimal specification of integration/selection rules.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Addresses the empirical heterogeneity of format-specific effects by positing coexisting parts for different tasks; some hybrid proposals historically cited (e.g., Margolis & Laurence, Rice) motivate the move.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Criticized for explanatorily thin integration—difficulty explaining what binds components, how formats are selected in context, and lacking constraints on admissible formats (arguments raised by pluralists and eliminativists and discussed in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Used to account for diverse empirical findings across categorization, reasoning, and development by positing coexisting representational parts.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Compared unfavorably in the paper to functional hybrids (coactivation packages) and to the PP account which supplies mechanisms for integration and selection; mereological hybrids lack mechanistic specificity.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Typically invoke retrieval of format-specific components and post-hoc combination, but lack a detailed functional-level mechanism for context-sensitive selection—this is a core criticism in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>No principled constraints on what counts as a format/component; under-specified selection and integration processes; vulnerable to eliminativist critiques that components are arbitrary.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Hybrid Account of Concepts Within the Predictive Processing Paradigm', 'publication_date_yy_mm': '2022-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5162.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5162.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Coactivation package (V&MM)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Coactivation package account (Vicente & Martínez Manrique, 'The Big Concepts Paper')</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional hybrid proposal that unifies different concept formats by claiming the formats are concurrently coactivated in a stable, functionally significant way to form a single concept 'package' whose parts are selected based on task/context.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The Big Concepts Paper: A Defence of Hybridism</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Coactivation package (functional hybrid)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are functionally unified units constituted by the stable, functional coactivation of multiple format-specific structures (prototypes, exemplars, theories), where context-sensitive activation weights determine which parts dominate on a use occasion.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>coactivated multi-format package (hybrid of exemplar/prototype/theory components)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>functional integration via concurrent activation; context-sensitive selection of components; stability across related tasks; components remain identifiable but interdependent.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Motivated by empirical heterogeneity of format effects and by the need to explain why multiple formats seemingly contribute to categorization and reasoning; cited by the paper as a modern hybrid position.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Original formulation under-specified operationalization of 'functional significance' and lacked mechanistic account of how selection and integration happen; offered little constraint on admissible formats—criticisms that Michel addresses by embedding in PP.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>General conceptual tasks (categorization, induction, reasoning) where different formats appear to be mobilized depending on context and task demands.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Presented as an improvement over mereological hybrids by emphasizing functional integration; the paper refines it by providing a PP-based mechanism for coactivation, thereby addressing V&MM's underspecification.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Originally appealed to concurrent activation and positive contribution to selecting appropriate tokening; in Michel's extension, coactivation is implemented as activation of a concept root-node and its subnetwork with precision-weighted selection of subnodes.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Requires a lower-level mechanistic account to specify what counts as functional contribution and to constrain admissible formats—gap the paper aims to fill by using PP.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Hybrid Account of Concepts Within the Predictive Processing Paradigm', 'publication_date_yy_mm': '2022-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5162.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5162.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Predictive Processing (PP)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Predictive Processing / Predictive Coding framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hierarchical, probabilistic, generative-causal computational paradigm in which the brain minimizes prediction error by continuously generating top-down predictions and updating them via weighted bottom-up error signals; used here to model functional concept representation and processing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Predictive Processing (PP)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is embedded in a hierarchical generative probabilistic model realized by prediction units; concepts function as prediction units/root nodes whose activation generates priors that constrain lower-level representations and whose connectivity supports inference, abstraction, and context-sensitive selection.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>hierarchical probabilistic generative representation (prediction units/nodes, distributed and graded)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>hierarchical abstraction gradient; probabilistic priors and conditional distributions; precision-weighting mechanism for context-sensitive selection; distributed node networks; generative/inferential dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>PP has been applied to perception, action, and cognition; empirical neuroscientific work supports hierarchical organization and task-dependent connectivity (cited sources in paper such as Kanai et al., Kuhnke et al., Kiefer & Pulvermüller, Raut et al.). The paper leverages published behavioral and neural findings (typicality, exemplar effects, knowledge effects) to argue PP can model them functionally.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>PP is still a developing paradigm with debates about specific claims and neural evidence; paper acknowledges PP is not fully mature and that mapping detailed neural dynamics of concept activation remains incompletely empirically specified.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Perception, categorization, conceptual processing, reasoning, action selection; used in the paper to account for exemplar/prototype/theory manifestations and selection across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Offers a unifying computational-level mechanism that subsumes exemplar, prototype, and theory effects as different modes of processing a single hierarchical representation, addressing integration and selection problems that hybrid and mereological accounts leave open.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Prediction error minimization as core drive; hierarchical generative priors; precision-weighting to control influence of error signals (contextual selection of nodes); root-node activation selects a subnetwork; horizontal/upward processing enables theory-mode inferences.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Specific implementational/neural dynamics of context-sensitive node selection for concepts need more empirical mapping; whether all concept types (esp. abstract concepts) consistently recruit sensorimotor lower levels remains contested.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Hybrid Account of Concepts Within the Predictive Processing Paradigm', 'publication_date_yy_mm': '2022-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5162.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5162.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Michel PP hybrid account</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Michel's Predictive Processing hybrid account of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper's central model: concepts are single, unified hierarchical subnetworks of prediction units (root node + dependent nodes) and different concept 'formats' (exemplar, prototype, theory) are modes of processing that selectively activate parts of this unified structure via precision-weighted prediction error dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>PP-based hybrid account (Michel)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functionally, a concept is instantiated by a root prediction unit that makes available a hierarchical probabilistic subnetwork; exemplar/prototype/theory effects arise from context-controlled depth (downwards), breadth (lateral), and level (upwards) of processing of that single structure, governed by precision-weighting and prediction-error minimization.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>single distributed hierarchical generative structure (prediction-unit rooted subnetwork); formats are processing modes rather than distinct stored formats</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>unified representational structure; hierarchical abstraction/compression gradient; context-sensitive depth/width of processing; probabilistic distributions over child nodes; precision-weighted selection of subparts; integrates exemplar/prototype/theory within one architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Grounded in empirical facts the paper cites: hierarchical brain organization, modality-specific and multimodal activation patterns (Kiefer & Pulvermüller 2012; Kuhnke et al. 2021), typicality and exemplar item advantages in behavioral studies (Smith & Minda; Medin & Schaffer), and knowledge effects (Rips' pizza experiment) reinterpreted as use-cases of different processing directions.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Empirical mapping of the precise dynamics (which nodes are active in which tasks, temporal unfolding, and neural substrates) is incomplete; current imaging lacks full spatiotemporal resolution to fully test the node-level predictions; PP framework debates remain active.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization (prototype/exemplar effects), similarity judgments, knowledge-based classification/inference (theory effects), concept tokening across perception/action/reasoning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Offers a mechanistic refinement of Vicente & Martínez Manrique's coactivation package by specifying how functional integration and selection occur via PP mechanisms; contrasts with mereological hybrids by denying format parts are separate representational entities and instead deriving formats from processing operations.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Concept activation = root-node activation → makes available hierarchical subnetwork; precision-weighting tunes error sensitivity at different levels determining shallow (prototype) vs. deep (exemplar) activation; upward/lateral propagation enables theory-mode inferences; similarity emerges from prediction-error minimization rather than explicit similarity computations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Requires empirical validation of predicted node-level dynamics (depth/width selection) and mapping to neural circuits; open question whether other proposed formats (definitions, scripts, ideals) can be derived within the same PP architecture; relies on contested aspects of PP (e.g., implementation details, universality).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Hybrid Account of Concepts Within the Predictive Processing Paradigm', 'publication_date_yy_mm': '2022-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The Big Concepts Paper: A Defence of Hybridism <em>(Rating: 2)</em></li>
                <li>Whatever next? Predictive brains, situated agents, and the future of cognitive science <em>(Rating: 2)</em></li>
                <li>Conceptual representations in mind and brain: Theoretical developments, current evidence and future directions <em>(Rating: 2)</em></li>
                <li>Task-Dependent Functional and Effective Connectivity during Conceptual Processing <em>(Rating: 2)</em></li>
                <li>Bridging the Gap between Similarity and Causality: An Integrated Approach to Concepts <em>(Rating: 2)</em></li>
                <li>On Staying Grounded and Avoiding Quixotic Dead Ends <em>(Rating: 1)</em></li>
                <li>Context theory of classification learning <em>(Rating: 1)</em></li>
                <li>The free-energy principle: A unified brain theory? <em>(Rating: 1)</em></li>
                <li>Similarity, typicality, and categorization <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5162",
    "paper_id": "paper-250975117",
    "extraction_schema_id": "extraction-schema-109",
    "extracted_data": [
        {
            "name_short": "Exemplar theory",
            "name_full": "Exemplar theory of concepts",
            "brief_description": "A functional-level account that represents category concepts as collections of stored individual instances (exemplars) and performs classification by matching/selection among those stored instances.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_or_model_name": "Exemplar theory",
            "theory_or_model_description": "Conceptual knowledge is functionally represented as a set of remembered particular instances; categorization and related tasks are performed by retrieving/matching those stored exemplars and choosing the hypothesis that best predicts current input.",
            "representation_format_type": "exemplar / instance-based, distributed memory of instances",
            "key_properties": "instance-level storage; variable specificity (can be vague or highly detailed); relies on similarity between stored exemplars and target; flexible and context-sensitive via retrieval processes.",
            "empirical_support": "Explains item-specific advantages in categorization (old-item advantage), many behavioral exemplar effects in category learning literature (cited classic works such as Medin & Schaffer 1978; Nosofsky 1986; Smith & Minda 1998/2000 referenced in the paper).",
            "empirical_challenges": "Fails alone to account for broad range of data (format heterogeneity); cannot by itself explain prototype-like typicality effects or theory/causal knowledge effects without additional structure (paper cites general critiques that no single-format account covers all empirical phenomena).",
            "applied_domains_or_tasks": "Categorization, similarity judgments, memory-for-instances effects, item recognition in concept tasks.",
            "comparison_to_other_models": "Contrasted with prototype theory (instance vs. abstract summary) and theory-theory (instance vs. causal/theoretical structure); in this paper exemplar-mode is recast as deeper, downward processing of a unified hierarchical representation rather than a separate stored module.",
            "functional_mechanisms": "In the paper's PP reformulation, exemplar processing corresponds to relatively deep downward activation of lower-level nodes in a hierarchical generative model so that stored specific-instance hypotheses minimize prediction error for detailed inputs.",
            "limitations_or_open_questions": "Cannot explain why exemplar vs. prototype use is selected in context without an explicit mechanism; classical exemplar accounts lack the precision-weighting/selection mechanism PP supplies; interaction with theory-like knowledge remains under-specified in pure exemplar accounts.",
            "uuid": "e5162.0",
            "source_info": {
                "paper_title": "A Hybrid Account of Concepts Within the Predictive Processing Paradigm",
                "publication_date_yy_mm": "2022-07"
            }
        },
        {
            "name_short": "Prototype theory",
            "name_full": "Prototype theory of concepts",
            "brief_description": "A functional account that represents categories by one or more abstracted summary representations (prototypes) encoding typical features and typicality gradients, used for classification by matching target stimuli to these summaries.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_or_model_name": "Prototype theory",
            "theory_or_model_description": "Conceptual knowledge is functionally represented as compressed, abstracted summaries (prototypes) that encode typical feature values and typicality relations; categorization uses these coarse-grained expectations rather than stored particulars.",
            "representation_format_type": "prototype / summary-statistic, feature-based compressed representation",
            "key_properties": "abstracted over instances, graded typicality, computationally efficient, captures typicality effects, context-sensitive in use though more schematic than exemplars.",
            "empirical_support": "Accounts for typicality effects (e.g., sparrow judged a more typical bird than ostrich) and many categorization phenomena cited in prototype literature (Rosch 1978; Posner & Keele 1968 referenced in the paper).",
            "empirical_challenges": "Fails to account for exemplar-specific advantages and for many cases where causal/theoretical knowledge determines classification; alone cannot capture full heterogeneity of conceptual behavior.",
            "applied_domains_or_tasks": "Typicality judgments, basic-level categorization, rapid coarse-grained predictions in perception and action.",
            "comparison_to_other_models": "Set against exemplar models (concrete instances) and theory-theory (causal/structural knowledge); in this paper prototype-mode is reinterpreted as shallower activation of higher-level nodes in a hierarchical predictive model rather than a distinct stored format.",
            "functional_mechanisms": "Within the paper's PP account, prototype processing corresponds to activation limited to higher, more compressed nodes of the concept's subnetwork so that coarse-grained priors minimize prediction error with minimal lower-level detail.",
            "limitations_or_open_questions": "Does not by itself explain how abstraction is computed or selected in context; needs mechanisms for selecting abstraction level (provided by PP precision-weighting in the paper) and for integrating with causal/theoretical knowledge.",
            "uuid": "e5162.1",
            "source_info": {
                "paper_title": "A Hybrid Account of Concepts Within the Predictive Processing Paradigm",
                "publication_date_yy_mm": "2022-07"
            }
        },
        {
            "name_short": "Theory-theory",
            "name_full": "Theory-theory (theory-like representations in concepts)",
            "brief_description": "A family of accounts positing that conceptual knowledge includes or is structured by theory-like (causal, explanatory, taxonomic) information; concepts either constitute parts of broader folk-theories or are themselves small, partial theories.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_or_model_name": "Theory-theory",
            "theory_or_model_description": "Concepts are functionally embedded in or constituted by structured bodies of causal/explanatory knowledge (folk theories); classification and inference rely on invoking these theory-like networks rather than mere similarity to instances.",
            "representation_format_type": "theory-based / causal-network or schema-like representations (could be sub-symbolic or propositional depending on version)",
            "key_properties": "captures causal, taxonomic, mereological relations; can be liberal (loose, folk-theory style) or literal (coherent, scientific-theory analogue); supports inferential reasoning beyond surface similarity.",
            "empirical_support": "Explains knowledge effects like Rips' pizza experiment where causal/production knowledge shifts categorization independent of surface similarity; supports explanations for essentialist reasoning and other folk-theory phenomena (cited studies such as Rips 1989, Gelman).",
            "empirical_challenges": "Ambiguity about representational format (mini-theory vs. concept-as-constituent); strict literal versions are psychologically implausible; classical theory-theory does not specify mechanistic/representational implementation for how theories are stored and used in real-time tasks.",
            "applied_domains_or_tasks": "Causal reasoning, inductive inference, taxonomic classification, judgments where background knowledge overrides similarity (e.g., Rips' tasks), folk biology/psychology domains.",
            "comparison_to_other_models": "Contrasted with prototype/exemplar accounts which emphasize similarity-based processing; the paper argues theory-mode is realized by upward and lateral processing in a hierarchical predictive model rather than separate propositional belief modules.",
            "functional_mechanisms": "In the paper's PP account, theory processing corresponds to exploiting connectivity of a concept node to higher-level and lateral nodes (schemas, causal frames) to perform generative/inferential predictions and to explain lower-level features.",
            "limitations_or_open_questions": "How to represent coherence and explanatory structure mechanistically remains underspecified in classical theory-theory; distinguishing literal vs. liberal readings leaves questions about necessary structure and granularity.",
            "uuid": "e5162.2",
            "source_info": {
                "paper_title": "A Hybrid Account of Concepts Within the Predictive Processing Paradigm",
                "publication_date_yy_mm": "2022-07"
            }
        },
        {
            "name_short": "Mereological hybridism",
            "name_full": "Mereological hybrid accounts of concepts",
            "brief_description": "Hybrid models that treat different format-instances (exemplar, prototype, theory) as distinct components or parts combined into a composite concept, typically without detailed integration mechanisms.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_or_model_name": "Mereological hybrid accounts",
            "theory_or_model_description": "Concepts are wholes composed of distinct format-specific parts (e.g., a prototype part, an exemplar part, a theory part) that are aggregated but often lack principled mechanisms for functional integration or selection.",
            "representation_format_type": "multi-part composition of format-specific sub-representations (modular parts)",
            "key_properties": "plural-format storage; compositional clustering of separate representations; often minimal specification of integration/selection rules.",
            "empirical_support": "Addresses the empirical heterogeneity of format-specific effects by positing coexisting parts for different tasks; some hybrid proposals historically cited (e.g., Margolis & Laurence, Rice) motivate the move.",
            "empirical_challenges": "Criticized for explanatorily thin integration—difficulty explaining what binds components, how formats are selected in context, and lacking constraints on admissible formats (arguments raised by pluralists and eliminativists and discussed in the paper).",
            "applied_domains_or_tasks": "Used to account for diverse empirical findings across categorization, reasoning, and development by positing coexisting representational parts.",
            "comparison_to_other_models": "Compared unfavorably in the paper to functional hybrids (coactivation packages) and to the PP account which supplies mechanisms for integration and selection; mereological hybrids lack mechanistic specificity.",
            "functional_mechanisms": "Typically invoke retrieval of format-specific components and post-hoc combination, but lack a detailed functional-level mechanism for context-sensitive selection—this is a core criticism in the paper.",
            "limitations_or_open_questions": "No principled constraints on what counts as a format/component; under-specified selection and integration processes; vulnerable to eliminativist critiques that components are arbitrary.",
            "uuid": "e5162.3",
            "source_info": {
                "paper_title": "A Hybrid Account of Concepts Within the Predictive Processing Paradigm",
                "publication_date_yy_mm": "2022-07"
            }
        },
        {
            "name_short": "Coactivation package (V&MM)",
            "name_full": "Coactivation package account (Vicente & Martínez Manrique, 'The Big Concepts Paper')",
            "brief_description": "A functional hybrid proposal that unifies different concept formats by claiming the formats are concurrently coactivated in a stable, functionally significant way to form a single concept 'package' whose parts are selected based on task/context.",
            "citation_title": "The Big Concepts Paper: A Defence of Hybridism",
            "mention_or_use": "use",
            "theory_or_model_name": "Coactivation package (functional hybrid)",
            "theory_or_model_description": "Concepts are functionally unified units constituted by the stable, functional coactivation of multiple format-specific structures (prototypes, exemplars, theories), where context-sensitive activation weights determine which parts dominate on a use occasion.",
            "representation_format_type": "coactivated multi-format package (hybrid of exemplar/prototype/theory components)",
            "key_properties": "functional integration via concurrent activation; context-sensitive selection of components; stability across related tasks; components remain identifiable but interdependent.",
            "empirical_support": "Motivated by empirical heterogeneity of format effects and by the need to explain why multiple formats seemingly contribute to categorization and reasoning; cited by the paper as a modern hybrid position.",
            "empirical_challenges": "Original formulation under-specified operationalization of 'functional significance' and lacked mechanistic account of how selection and integration happen; offered little constraint on admissible formats—criticisms that Michel addresses by embedding in PP.",
            "applied_domains_or_tasks": "General conceptual tasks (categorization, induction, reasoning) where different formats appear to be mobilized depending on context and task demands.",
            "comparison_to_other_models": "Presented as an improvement over mereological hybrids by emphasizing functional integration; the paper refines it by providing a PP-based mechanism for coactivation, thereby addressing V&MM's underspecification.",
            "functional_mechanisms": "Originally appealed to concurrent activation and positive contribution to selecting appropriate tokening; in Michel's extension, coactivation is implemented as activation of a concept root-node and its subnetwork with precision-weighted selection of subnodes.",
            "limitations_or_open_questions": "Requires a lower-level mechanistic account to specify what counts as functional contribution and to constrain admissible formats—gap the paper aims to fill by using PP.",
            "uuid": "e5162.4",
            "source_info": {
                "paper_title": "A Hybrid Account of Concepts Within the Predictive Processing Paradigm",
                "publication_date_yy_mm": "2022-07"
            }
        },
        {
            "name_short": "Predictive Processing (PP)",
            "name_full": "Predictive Processing / Predictive Coding framework",
            "brief_description": "A hierarchical, probabilistic, generative-causal computational paradigm in which the brain minimizes prediction error by continuously generating top-down predictions and updating them via weighted bottom-up error signals; used here to model functional concept representation and processing.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_or_model_name": "Predictive Processing (PP)",
            "theory_or_model_description": "Conceptual knowledge is embedded in a hierarchical generative probabilistic model realized by prediction units; concepts function as prediction units/root nodes whose activation generates priors that constrain lower-level representations and whose connectivity supports inference, abstraction, and context-sensitive selection.",
            "representation_format_type": "hierarchical probabilistic generative representation (prediction units/nodes, distributed and graded)",
            "key_properties": "hierarchical abstraction gradient; probabilistic priors and conditional distributions; precision-weighting mechanism for context-sensitive selection; distributed node networks; generative/inferential dynamics.",
            "empirical_support": "PP has been applied to perception, action, and cognition; empirical neuroscientific work supports hierarchical organization and task-dependent connectivity (cited sources in paper such as Kanai et al., Kuhnke et al., Kiefer & Pulvermüller, Raut et al.). The paper leverages published behavioral and neural findings (typicality, exemplar effects, knowledge effects) to argue PP can model them functionally.",
            "empirical_challenges": "PP is still a developing paradigm with debates about specific claims and neural evidence; paper acknowledges PP is not fully mature and that mapping detailed neural dynamics of concept activation remains incompletely empirically specified.",
            "applied_domains_or_tasks": "Perception, categorization, conceptual processing, reasoning, action selection; used in the paper to account for exemplar/prototype/theory manifestations and selection across tasks.",
            "comparison_to_other_models": "Offers a unifying computational-level mechanism that subsumes exemplar, prototype, and theory effects as different modes of processing a single hierarchical representation, addressing integration and selection problems that hybrid and mereological accounts leave open.",
            "functional_mechanisms": "Prediction error minimization as core drive; hierarchical generative priors; precision-weighting to control influence of error signals (contextual selection of nodes); root-node activation selects a subnetwork; horizontal/upward processing enables theory-mode inferences.",
            "limitations_or_open_questions": "Specific implementational/neural dynamics of context-sensitive node selection for concepts need more empirical mapping; whether all concept types (esp. abstract concepts) consistently recruit sensorimotor lower levels remains contested.",
            "uuid": "e5162.5",
            "source_info": {
                "paper_title": "A Hybrid Account of Concepts Within the Predictive Processing Paradigm",
                "publication_date_yy_mm": "2022-07"
            }
        },
        {
            "name_short": "Michel PP hybrid account",
            "name_full": "Michel's Predictive Processing hybrid account of concepts",
            "brief_description": "The paper's central model: concepts are single, unified hierarchical subnetworks of prediction units (root node + dependent nodes) and different concept 'formats' (exemplar, prototype, theory) are modes of processing that selectively activate parts of this unified structure via precision-weighted prediction error dynamics.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_or_model_name": "PP-based hybrid account (Michel)",
            "theory_or_model_description": "Functionally, a concept is instantiated by a root prediction unit that makes available a hierarchical probabilistic subnetwork; exemplar/prototype/theory effects arise from context-controlled depth (downwards), breadth (lateral), and level (upwards) of processing of that single structure, governed by precision-weighting and prediction-error minimization.",
            "representation_format_type": "single distributed hierarchical generative structure (prediction-unit rooted subnetwork); formats are processing modes rather than distinct stored formats",
            "key_properties": "unified representational structure; hierarchical abstraction/compression gradient; context-sensitive depth/width of processing; probabilistic distributions over child nodes; precision-weighted selection of subparts; integrates exemplar/prototype/theory within one architecture.",
            "empirical_support": "Grounded in empirical facts the paper cites: hierarchical brain organization, modality-specific and multimodal activation patterns (Kiefer & Pulvermüller 2012; Kuhnke et al. 2021), typicality and exemplar item advantages in behavioral studies (Smith & Minda; Medin & Schaffer), and knowledge effects (Rips' pizza experiment) reinterpreted as use-cases of different processing directions.",
            "empirical_challenges": "Empirical mapping of the precise dynamics (which nodes are active in which tasks, temporal unfolding, and neural substrates) is incomplete; current imaging lacks full spatiotemporal resolution to fully test the node-level predictions; PP framework debates remain active.",
            "applied_domains_or_tasks": "Categorization (prototype/exemplar effects), similarity judgments, knowledge-based classification/inference (theory effects), concept tokening across perception/action/reasoning tasks.",
            "comparison_to_other_models": "Offers a mechanistic refinement of Vicente & Martínez Manrique's coactivation package by specifying how functional integration and selection occur via PP mechanisms; contrasts with mereological hybrids by denying format parts are separate representational entities and instead deriving formats from processing operations.",
            "functional_mechanisms": "Concept activation = root-node activation → makes available hierarchical subnetwork; precision-weighting tunes error sensitivity at different levels determining shallow (prototype) vs. deep (exemplar) activation; upward/lateral propagation enables theory-mode inferences; similarity emerges from prediction-error minimization rather than explicit similarity computations.",
            "limitations_or_open_questions": "Requires empirical validation of predicted node-level dynamics (depth/width selection) and mapping to neural circuits; open question whether other proposed formats (definitions, scripts, ideals) can be derived within the same PP architecture; relies on contested aspects of PP (e.g., implementation details, universality).",
            "uuid": "e5162.6",
            "source_info": {
                "paper_title": "A Hybrid Account of Concepts Within the Predictive Processing Paradigm",
                "publication_date_yy_mm": "2022-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The Big Concepts Paper: A Defence of Hybridism",
            "rating": 2,
            "sanitized_title": "the_big_concepts_paper_a_defence_of_hybridism"
        },
        {
            "paper_title": "Whatever next? Predictive brains, situated agents, and the future of cognitive science",
            "rating": 2,
            "sanitized_title": "whatever_next_predictive_brains_situated_agents_and_the_future_of_cognitive_science"
        },
        {
            "paper_title": "Conceptual representations in mind and brain: Theoretical developments, current evidence and future directions",
            "rating": 2,
            "sanitized_title": "conceptual_representations_in_mind_and_brain_theoretical_developments_current_evidence_and_future_directions"
        },
        {
            "paper_title": "Task-Dependent Functional and Effective Connectivity during Conceptual Processing",
            "rating": 2,
            "sanitized_title": "taskdependent_functional_and_effective_connectivity_during_conceptual_processing"
        },
        {
            "paper_title": "Bridging the Gap between Similarity and Causality: An Integrated Approach to Concepts",
            "rating": 2,
            "sanitized_title": "bridging_the_gap_between_similarity_and_causality_an_integrated_approach_to_concepts"
        },
        {
            "paper_title": "On Staying Grounded and Avoiding Quixotic Dead Ends",
            "rating": 1,
            "sanitized_title": "on_staying_grounded_and_avoiding_quixotic_dead_ends"
        },
        {
            "paper_title": "Context theory of classification learning",
            "rating": 1,
            "sanitized_title": "context_theory_of_classification_learning"
        },
        {
            "paper_title": "The free-energy principle: A unified brain theory?",
            "rating": 1,
            "sanitized_title": "the_freeenergy_principle_a_unified_brain_theory"
        },
        {
            "paper_title": "Similarity, typicality, and categorization",
            "rating": 1,
            "sanitized_title": "similarity_typicality_and_categorization"
        }
    ],
    "cost": 0.01539375,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>A Hybrid Account of Concepts Within the Predictive Processing Paradigm
21 July 2022</p>
<p>Christian Michel 0000-0001-9962-5403
of Philosophy
University
1 3</p>
<p>of Philosophy
University
1 3</p>
<p>A Hybrid Account of Concepts Within the Predictive Processing Paradigm
21 July 2022632BC4E44FB72C654FAA9865B666B4E710.1007/s13164-022-00648-8Accepted: 17 June 2022
We seem to learn and use concepts in a variety of heterogenous "formats", including exemplars, prototypes, and theories.Different strategies have been proposed to account for this diversity.Hybridists consider instances in different formats to be instances of a single concept.Pluralists think that each instance in a different format is a different concept.Eliminativists deny that the different instances in different formats pertain to a scientifically fruitful kind and recommend eliminating the notion of a "concept" entirely.In recent years, hybridism has received the most attention and support.However, we are still lacking a cognitive-computational model for concept representation and processing that would underpin hybridism.The aim of this paper is to advance the understanding of concepts by grounding hybridism in a neuroscientific model within the Predictive Processing framework.In the suggested view, the different formats are not distinct parts of a concept but arise from different ways of processing a functionally unified representational structure.KeywordsConcept • Concept eliminativism • Concept pluralism • Concept hybridism • Predictive Processing • Coactivation package account of concepts</p>
<p>Introduction</p>
<p>We seem to learn and process concepts 1 in different and heterogenous "formats" 2 , like exemplars (e.g., Medin and Schaffer 1978;Nosofsky 1986), prototypes (e.g., Posner and Keele 1968;Rosch 1978;Hampton 2006) and theories (e.g., Keil 1989;Murphy and Medin 1985;Gopnik and Wellman 2012).Exemplar theory holds that concepts are represented as a set of exemplars stored under a category label.Prototypes are abstracted summary representations, for instance, in the form of a list of features with typicality ratings.And theory-theory describes concepts as embedded in theory-like structures or as little theories themselves.Other formats are sometimes hypothesized: for instance, definitions (a set of necessary and sufficient characteristics), scripts (procedural knowledge) or ideals (a description of an ideal member of a category).However, exemplars, prototypes and theories are the formats that are generally accepted; for this reason, here I will focus on those three.</p>
<p>Those formats were posited to account for a large range of empirical, mostly behavioral, data related to conceptual development and conceptual tasks (some of which I will discuss later).But none of the aforementioned accounts turns out to be able to accommodate the wealth of empirical data (e.g., Kruschke 2005:188, 190;Machery 2009).Therefore, format variety is now generally recognized as an unavoidable conclusion (e.g., Bloch-Mullins 2018;Hampton 2015;Voorspoels et al. 2011) and has been discussed in depth by Machery (2009).</p>
<p>This heterogeneity of formats sparked many early hybrid proposals, most of them combining two formats (e.g., Osherson and Smith 1981;Nosofsky et al. 1994;Erickson and Kruschke 1998;Anderson and Betz 2001).Given the limited scope and other defects of those initial hybrids, Machery (2009) concluded that each format corresponds to a different fundamental type, and we should dispose of the notion of a concept because the formats have nothing scientifically interesting in common.</p>
<p>Notwithstanding this, many researchers find eliminativism implausible and have continued to propose hybrid solutions in defence of the notion of a concept (e.g., Bloch-Mullins 2018;Keil 2010;Margolis andLaurence 1999, 2010;Rice 2016;Vicente and Martínez Manrique 2016), searched for unity behind the diversity of concept formats (e.g., Danks 2014) or endorsed conceptual pluralism (e.g., Piccinini and Scott 2006;Weiskopf 2009).</p>
<p>Arguably, hybridism is the approach that has received most attention and support in recent years.Therefore, here I will leave pluralism and eliminativism aside and focus only on hybrid accounts.My overall goal is not to defend hybrid approaches.Rather I want to provide a novel way to spell out a hybrid account in the spirit of Vicente 1 I take concepts to be certain bodies of information (see Machery 2009) that are used in many higher cognitive tasks, i.e., abilities like categorization, inductive and deductive reasoning, planning or analogy making.The focus here is on the psychological notion of concepts (see Machery 2009Machery , 2020)), which is concerned with their cognitive-computational significance. 2I use the term "format" as a placeholder for whatever protypes, exemplars and theories turn out to be (representational structures, types of knowledge, ways of processing, etc.).Thanks to an anonymous reviewer for suggesting this way of using the term.Also note that "format" is sometimes used in connection with concepts to distinguish amodal and modality-specific representations.This is not the way I use the term here.</p>
<p>&amp; Martínez Manrique's "coactivation package" account (2016). Vicente &amp; Martínez</p>
<p>Manrique have forcefully argued that hybrids that do not consider "functional integration" of the formats are hopelessly flawed.While I endorse this view, I nevertheless argue that their approach deserves further development and improvements.</p>
<p>I do not develop a full theory of concepts here.Rather, I focus on the aspect of how a concept needs to be structured as a representational device so that it can serve the roles that the different formats (exemplars, prototypes, and theories) are supposed to play in conceptual cognition.A full theory of concepts would need to address a host of additional desiderata, for instance, how concepts compose to more complex concepts, how they can be shared among members of a language community, etc. (see, e.g., Prinz 2002).</p>
<p>The rest of the paper is structured as follows.In Sect.2, I discuss hybrid accounts and examine in some more detail Vicente &amp; Martínez Manrique's coactivation package hybrid proposal.I identify two aspects that need further development.In Sect.3, I introduce a model of concepts that is emerging from neuroscience.In Sect.4, I introduce Predictive Processing (PP), a cognitive computational framework, and show how the concept model from Sect. 3 can be embedded in it.In Sect.5, I suggest how the different formats of concepts might arise and how this approach improves the coactivation package account.</p>
<p>2 Hybrid accounts of concepts I focus on Vicente and Martínez Manrique (2016) (V&amp;MM) which is one of the most recent hybrids 3 .Their account, which I call a "functional hybrid", is a reaction to previously dominating "mereological hybrids".To better appreciate the strengths and weaknesses of V&amp;MM's account, and motivate needed improvements, let me set the stage by briefly discussing mereological hybrids.</p>
<p>Mereological hybrids</p>
<p>Mereological hybrids treat instances of concepts in different formats as numerically distinct entities that are combined to create a hybrid entity.For most such hybrids, their proponents do not emphasize and provide principles for a deeper functional integration of the parts.This is not to say that mereological hybrids do not provide some integrating principle, of course, but the characterization of how and why the components are integrated is rather minimal and "thin."That, however, makes them vulnerable to various anti-hybrid arguments put forward by eliminativists and pluralists (see, e.g., Vicente and Martínez Manrique 2016, for a discussion).In a nutshell, mereological hybrids have difficulty explaining what keeps the components together, beyond some minimal description, and hence what justifies calling the cluster of formats a concept.Furthermore, it is unclear what explanatory advantage hybridism would have over pluralism and eliminativism.Secondly, mereological hybrids can-not say much about what formats are possible, how they hang together and interact, and how they are acquired.They do not seek to reveal an underlying principle from which different formats might naturally arise.Hence, they have an ad-hoc air and lack deeper unity.</p>
<p>As an example, in Margolis &amp; Laurence's (2010) account the different formats are "bound to the same mental symbol".However, no constraints are provided for what formats can be bound to a symbol.Also, nothing is said about how exactly the formats are represented and processed, in particular how different formats are selected on some use occasion.Rice's "pluralist hybrid" ( 2016) is a further instance of a mereological hybrid.In his proposal, we store information in different formats in long term memory.Information chunks in different formats are retrieved and combined dynamically to create a concept, which is then processed, depending on the task, context, and category.Each combination of different formats corresponds to a different concept.This proposal has the advantage that it does justice to the highly dynamic and flexible processes in concept retrieval.But Rice does not provide constraints for what kind of formats are possible.He also does not explain how those formats are represented and how the selection and assembly mechanisms work.</p>
<p>A functional hybrid account</p>
<p>I now discuss how V&amp;MM respond to the problems that afflict the mereological hybrid accounts.I argue that while their response focuses on, and advances in terms of a solution to the first problem, they still face issues, including the second problem of mereological hybrids just discussed.</p>
<p>V&amp;MM suggest that functional integration is what holds the different formats of a concept together.Contrary to the above-mentioned mereological hybrids, V&amp;MM put the issue of the functional integration into the spotlight.For this reason, I suggest calling their approach a "functional hybrid."Their proposal is then that the unity of a hybrid rests on the "functional stable coactivation" of the formats:</p>
<p>In a nutshell, the idea is that different structures can be regarded as constituting a common representation when they are activated concurrently, in a way that is functionally significant for the task at hand, and in patterns that remain substantially stable along different tasks related to the same category.(Vicente &amp; Martínez Manrique, 2016:61) A concept is, roughly, a "coactivation package" that makes information of different formats available.Different formats are different parts of the concept that are contextsensitively selected:</p>
<p>Depending on the task at hand, and on background factors, one part or another of this complex structure receives more activation and plays the leading functional role.Taken separately, prototypes, theories, and so on may be not concepts, but they are components of concepts.(Vicente &amp; Martínez Manrique, 2016:72, emphasis added) Note that the authors still speak of formats as "components of concepts".But they use "component" in a rather loose sense, not necessarily implying that formats are strictly "separate modules" (p.73).</p>
<p>I agree with the idea that formats should be integrated in such a way that for a given use of a concept the different formats should simultaneously play some functional role.Only some form of functional interdependence guarantees integration.And without integration it is difficult to see why we need hybrids rather than formats as standalone entities, as pluralists and eliminativists claim.Functional integration makes the hybrid resistant to the above-mentioned anti-hybrid arguments, moreover, it undermines eliminativism, because a functionally integrated unit certainly is a scientifically interesting kind that gives rise to generalizations.</p>
<p>However, I see two issues with V&amp;MM's account.</p>
<p>First, what exactly is "functional significance"?V&amp;MM have not spelled out in detail what this notion amounts to.They only provide a minimal characterization:</p>
<p>The idea behind the functionality condition is that only representational components that make a positive contribution to select the appropriate tokening of the concept count as part of such a concept.(p.69, emphasis added) According to V&amp;MM, the concept components are "functional" in so far as they make a "positive contribution" to the selection of the "appropriate tokening of the concept".I assume here that V&amp;MM mean that "appropriate tokening" involves two elements.Firstly, the "correct" concept should be selected (e.g., DOG instead of HORSE) and, secondly, it should be tokened in an appropriate format (each concept can be tokened in different ways by selecting different "representational components", which I understand correspond to different formats).The interesting question then is: what does this contribution consist of exactly?An answer to this question crucially requires an account of how the context-sensitive selection of formats works, which is not provided by V&amp;MM.</p>
<p>A second issue with the coactivation package account is that it provides no constraints for possible formats.Should we include, for instance, ideals, scripts, and definitions in the coactivation package?The account is simply silent on this question.Formats are given and then merely added to the coactivation package as a range of possible formats.While V&amp;MM strongly emphasize functional integration, without further details about what exactly this consists in and without further constraints on admissible formats, their account risks remaining a programmatic desideratum about functional integration.</p>
<p>I suggest that we can further develop and improve V&amp;MM´s account by adding a level of description from below, i.e., by being more specific about aspects of neurallevel implementation.Rather than starting with a set of independently given formats, we should start from a general neurocognitive architecture that is motivated independently of the question of format variety.From this we can then derive the formats.</p>
<p>As such a general neurocognitive framework, I will use Predictive Processing (PP).But before describing it in Sect.4, I will first provide a sketch of a current neuroscientific picture of how concepts might be represented in the brain.</p>
<p>A neuroscientific model of concepts</p>
<p>The hybrid account I propose builds on a model of the neural realization of conceptual representations that, so I suggest, crystalizes out of an increasing body of current empirical and theoretical neuroscience.This model can be articulated in the form of three core claims.</p>
<p>C1. Conceptual representations are realized as extended networks of nodes: A conceptual representation is neurally realized as the activation of a set of neuron assemblies (nodes) in the form of a distributed network that can cover different brain areas, from higher cortical areas down to lower-level sensorimotor ones.</p>
<p>C2. Concepts are hierarchically organized networks: Different subassemblies (nodes) of the network structure of a concept represent information with different degrees of abstraction/schematicity.The network forms a hierarchy of nodes with an abstraction gradient.Very roughly, higher layers of nodes are sensitive to lowerlevel node patterns, or in other words, they compress lower-level information.The lowest level in the hierarchy corresponds to the sensory periphery, where representations are maximally modality specific.As we go higher in the hierarchy, information represented by the nodes gets not only increasingly abstracted/compressed, but also convolved, i.e., different modalities (visual, acoustic, proprioceptive, affective, etc.) get mixed (see also Eliasmith 2013).</p>
<p>C3. Context-sensitive and flexible conceptual processing: On different occasions different parts of the network of a concept are activated in a task-and context-sensitive manner.The tokening of the same concept on different occasions can reach into lower levels of the hierarchy to different degrees.</p>
<p>C1 and C3 closely follow the view of the neural realization of concepts suggested by Kiefer and Pulvermüller (2012).They characterize concepts as "flexible, distributed representations comprised of modality-specific conceptual features".Furthermore, with regard to C2, it is well established that the brain is hierarchically organized; neural layers and areas correspond to different levels of abstraction/compression (e.g., Raut et al. 2020, Hilgetag andGoulas 2020).This suggests that the extended network structure reaching from higher cortical levels down to sensorimotor areas plausibly has an abstraction/compression gradient.Kuhnke et al. (2021) have put forward a model and empirical evidence that characterizes the hierarchical structure in more detail by mapping the different hierarchy levels on specific brain regions.Lower-level monomodal representations are compressed in layers in so-called unimodal convergence zones.Those feed into layers in multimodal convergence zones.The highest level is an amodal 4 layer that compresses multimodal input.We have here a double gradient in the hierarchy.On the one hand, the higher the level, the more abstract and compressed the information is.Secondly, in multimodal convergence zones we have a mixing (or convolution) of different modalities.That is, neuron assemblies are sensitive to patterns that involve various modalities.The different layers can be identified with different brain areas (e.g., being the "amodal" layer the ATL).Kuhnke et al. (2021) also show that the connectivity between the layers is strongly task-dependent (claim C3).</p>
<p>C1, C2 and C3 are closely interrelated and empirical evidence for them is increasing.Modality-specific (action, visual, gustatory, olfactory, sound, but also interoceptive) representations often activate complex extended neural networks including modality-specific lower-level brain areas (e.g., Hoenig et al. 2008; see also the overview by Harpaintner et al. 2018).What is debated however, is whether a concept includes sensorimotor areas each time it is tokened, and whether abstract concepts like democracy or freedom also include sensorimotor information.</p>
<p>It is safe to say that lower-level sensorimotor areas are not necessarily activated on each occasion even for concrete concepts (Barsalou 2016;Kemmerer 2015;Pecher 2018).Van Dam, van Dijk, Bekkering and Rueschemeyer (2012) argue for the flexibility and context-dependency of the activation of lower-level modality-specific areas in the case of lexical concepts.Yee and Thompson-Schill (2016) conclude that concepts are highly fluid and their activations depend on the context, including the individual short and long-term experience.</p>
<p>With regard to abstract concepts, studies show that their activation can also include lower-level sensorimotor areas (e.g., Harpaintner et al. 2020), including interoceptive and areas processing emotions.Harpaintner et al. (2018) highlight the "importance of linguistic, social, introspective and affective experiential information for the representation of abstract concepts."Such modality specific features can be context and task-dependently activated (e.g., Harpaintner 2020).Furthermore, various researchers suggest that abstract concepts are grounded in emotions (e.g., Vigliocco et al. 2014, Lenci et al. 2018), supporting the idea that their neural realizations also potentially extend into sensorimotor and affective 5 areas.All of this is evidence that all concepts might have the same fundamental structure.Also, it is evidence for the claim that concepts are sensorimotor grounded in the sense that they are hierarchical networks of nodes that bottom out at the sensorimotor periphery.</p>
<p>It is important to stress that the neuroscientific model of concepts I have articulated here mainly covers the structure of the realization of concepts (C1 and C2), but little research is available about the specific dynamics of the context sensitive activation patterns postulated by C3.Specifically, an account of how the different formats of concepts arise is lacking.In other words, from the available neuroscientific work we cannot yet derive a full neuro-mechanistic account of dynamic concept processing and the format heterogeneity.This is where the Predictive Processing framework comes in.</p>
<p>My strategy going forward is to embed the flexible, layered network model of concepts in the Predictive Processing (PP) framework which I will introduce in the next section.I argue that PP can take on board the three core principles of the model and, more importantly, it can bring the wealth of individual findings under a single comprehensive neuro-mechanistic framework.What PP can then bring uniquely to the table is a model of how concepts are processed.This will be central for my proposal 5 Sensory areas are meant to include both exteroceptive and interoceptive modalities.</p>
<p>1 3 that different formats arise from different ways of processing the network structure that realizes a concept.</p>
<p>Concepts within the Predictive Processing framework</p>
<p>In this section I briefly introduce the Predictive Processing (PP) framework and suggest how the model of the neural realization of concepts just described could be embedded in it.6</p>
<p>The Predictive Processing paradigm</p>
<p>Predictive Processing (or coding) (see Clark 2013Clark , 2016;;Hohwy 2013;Friston, 2010;Sprevak, 2021) provides a neuroscientific framework or paradigm for how the brain works from a cognitive-computational perspective.PP is an ambitious framework as it aims at providing a general and unified view on cognitive agency, i.e., an account of perception, action and cognition.It should be stressed that PP is far from being a mature and worked out theory (Sprevak 2021a;Walsh et al. 2020).However, it is a very popular framework in cognitive science.In recent years, its scope of applications has been extended and is now ranging from low-level sensorimotor phenomena to several psychological phenomena and even consciousness (Hohwy 2020).</p>
<p>As a paradigm, PP provides guidance and constrains for the development of more specific theories of cognitive phenomena; PP can be seen as a research program based on some programmatic commitments that are generally but not unanimously accepted by the PP community.In the following part I try to synthesize what I consider to be the core commitments that are most relevant for the purpose of this paper.Most if not all commitments taken in isolation are neither original nor unique to PP (see Sprevak 2021a) and it is rather the combination and integration of the commitments that characterizes PP.</p>
<p>Prediction error minimization of sensory input</p>
<p>In very general terms, PP pictures the brain as an anticipation and expectation organ that constantly fine-tunes a mental model to continually predict its sensory input.</p>
<p>For instance, perception is not passive bottom-up feature aggregation and pattern recognition, as traditionally conceived (e.g., Marr 1982, Hubel andWiesel 1959).Rather, the brain constantly generates hypotheses of its sensorimotor states (including all extero-and interoceptive modalities) and corrects the model in the case of errors, so next time it does a better prediction job.In a way, the brain constantly hallucinates in a manner that happens (normally) to match reality.</p>
<p>The mental model: generative, hierarchical, and probabilistic</p>
<p>Predictions are being generated by a mental model that is generative, hierarchical, and probabilistic.The attribute generative captures the already mentioned idea that the model serves to generate hypotheses constantly and proactively about sensorimotor states.</p>
<p>The model is hierarchical because the predictions are being done through representations on many different levels of abstraction/compression (e.g., Clark 2013).In other words, representations, and hence knowledge, are structured in a hierarchy with an abstraction gradient.Higher levels contain representations that are responsive to larger "receptive fields", i.e., they capture more abstract and coarse-grained patterns represented on lower levels.For instance, while on a very low-level pixels in the retina are represented (which change heavily), higher levels contain representations7 corresponding to concepts like apple, which abstract over many instances of specific apples (and hence are more stable).In the downward flow of information, the predictions of higher-level layers play the role of priors for the lower-level predictions and, in this way, constrain the predictions on lower levels.Predictions are being carried out all the time and on all levels of the model at the same time.</p>
<p>The model is probabilistic because it represents probability distributions over (sub-personal) "hypotheses" about the causes of sensory input.Furthermore, prediction error minimization approximates Bayesian inference as its primary computational mechanism (e.g., Clark 2013:188-189;Hohwy 2013:15-39).</p>
<p>Precision weighting mechanism</p>
<p>The PP system contains a so-called "precision-weighting mechanism" of prediction errors (Clark 2016:53-83).Such a mechanism is necessary as the brain must predict the reliability of its sensory input (or more generally the inputs from lower levels in the hierarchy) to distinguish noise and useful signals.In this way, useless modifications of the model due to noisy signals can be avoided.Weights are assigned to the error signals, which allows the system to control the influence of top-down predictions versus bottom-up driven updates of the model.This modulatory mechanism is implemented as part of the overall PP prediction model as (second order) "knowledge" about the reliability and relevance of features in each context (see Michel 2020a).</p>
<p>Neural architecture</p>
<p>PP also makes some general claims about neural implementation.The smallest unit in the model is a combination of an "error unit" and a "representation unit" which I will call a "prediction unit" or simply a "node".Prediction units or nodes are realized as small neural assemblies or "canonical circuits" (see Kanai et al. 2015, also Bastos et al. 2012, Keller and Mrsic-Flogel 2018, Weilnhammer et al. 2018).The error unit is connected to prediction units on higher levels and the representation unit is connected downwards.Furthermore, there are modulatory inputs into the error units that allow the above-mentioned precision weighting mechanism to tune the error signal.</p>
<p>This brief sketch of the PP paradigm which emphasizes the elements that will play a role in the rest of the paper, should suffice.8In the next section I show how the neural model of concepts from Sect. 3 can be embedded in the PP framework.</p>
<p>PP and concepts</p>
<p>My proposal for how concepts manifest themselves in different formats relies on Michel (2020a, b) who suggests that concepts are implemented in PP by the prediction units just described.Specifically, a given concept is instantiated by a prediction unit, taken as the root node of an extended tree of other prediction units.</p>
<p>The idea then is that the activation of a concept's root node makes available a body of information, namely the subnetwork depending on that root-node.This subnetwork can be seen to correspond to Vicente &amp; Martínez Manrique's "coactivation package".When a concept unit is activated, it makes available a subnetwork that can cover various brain regions, potentially including higher cortical down to primary sensory or motor areas.Critically, which other sub-nodes apart from the root-node itself, are selected is regulated by a context-sensitive modulation mechanism (see Michel 2020a).The basic idea is that higher order knowledge about the reliability and relevance of the different nodes is also encoded in the world model.This higher order knowledge then regulates how the prediction error signals are modulated (i.e., more or less suppressed).Such a mechanism is equivalent to a mechanism that can switch on and off certain parts or nodes of the network depending on the context.</p>
<p>There are concept root-nodes that correspond to patterns on all levels of complexity and spatial and temporal scales.There are, hence, concept root-nodes that range from simple sensory-based expectations, like RED, passing through intermediate-level ones like FACE, to abstract concepts like DEMOCRACY, up to complex situation representations that we grasp in some gestalt-fashion.Such concept rootnodes do not necessarily correspond to lexicalized concepts but also include a host of sub-conscious ineffable ("sub-symbolic") representations that are used as prediction vehicles.</p>
<p>This view of concepts within the PP framework can be put in correspondence with the neural account of concepts as dynamic networks from Sect. 3 in the following way:</p>
<p>C1: The extended network of a given concept corresponds to the sub-network in the PP model that consists of the concept root node and all of its child nodes.(Note that each child node is itself a concept root node).</p>
<p>C2: The sub-network corresponding to a concept is organized hierarchically and has an abstraction gradient in the PP model, exactly like in the neuroscientific model.</p>
<p>Regarding C3, we said that neuroscientific evidence suggests that the concept networks are flexibly and context-dependently activated.According to the PP model the depth with which a concept's tree is activated is flexible, namely task and context-sensitive, driven by the error signal weighting mechanism.Lower-level features can be suppressed by the error weighting mechanism when they are estimated to be unreliable or irrelevant.Activation of a concept can be "shallow" (e.g., a "schematic apple" in which no specific colour is co-activated), in which case only higher-level nodes are activated.Or activations can be "deep", which involves, e.g., a more vivid (modality-specific) mental representation due to the co-activation of nodes that are located lower in the hierarchy (a mental picture of an apple, with a specific colour, form, size, etc.).</p>
<p>The existence and flexibility of concepts can be motivated within the PP framework in a principled way (see Michel 2020a).Concepts are necessary vehicles for prediction making; it is in virtue of prediction units that predictions are made.An efficient prediction economy requires making predictions with an adequate level of detail.When you want to cross a street successfully, your brain's predictions cannot and need not happen on the situation's pixel-level of precision.Rather the predictions need to be more schematic and have a coarser grain.There are two ways to regulate prediction detail.The first is by using prediction units at higher levels in the hierarchy.The higher the nodes, the more schematic and compressed (hence less detailed) their content.The second is by co-activating a varying number of other nodes; those represent more detailed and concrete features of that conceptual representation.</p>
<p>In conclusion, by embedding the neuroscientific model of concepts from Sect. 3 in the PP framework, we get a more comprehensive model of concept representation and processing.As we have seen, PP can provide an implementational-level proposal for the network structure (a network of PP prediction units with an abstraction gradient).But what PP can crucially contribute is the processing aspect, which is still underdeveloped in the literature.For instance, PP supplies a self-organizing driving force operative in the node network (prediction error minimization), as well as a mechanism for feature selection (based on the precision weighting mechanism).Furthermore, PP motivates the existence of concepts as prediction vehicles, and the need for the right level of granularity, which in turn motivates the existence of the feature selection mechanism.</p>
<p>The manifestation of different concept formats</p>
<p>With a cognitive-computational account of the structure of conceptual representations in place, I will now show that the different formats correspond to how the network of a concept is being context-sensitively processed.The different formats mirror not numerically distinct representational entities, but the processing depth and width of the concept's (and surrounding) network structure.More precisely, exemplar effects correspond to relatively deep vertical downward processing (i.e., towards less abstract nodes), prototype effects to relatively shallower vertical downward processing, and theory effects to additional vertical upwards and horizontal processing (i.e., towards parent and neighbor nodes).</p>
<p>Exemplars and prototypes</p>
<p>In this subsection I argue that a concept can manifest itself in "exemplar mode" and "prototype mode" when the node tree associated with the concept is processed from more to less abstract nodes (vertically downwards processing).Processing only higher-level nodes corresponds to prototypes.Processing in addition lower-level nodes corresponds to exemplars.I will first unpack this proposal by explaining how exactly to understand exemplars and prototypes and how they are realized in the PP model.Then I will provide some examples of how we can account for the exemplar and prototype effects that motivated those formats in the first place.</p>
<p>What exactly are exemplars and prototypes?</p>
<p>In the standard story of exemplar theory, which aims to address exemplar effects, my concept DOG consists of the memorized collection of representations of specific dogs.They are modality-wise specific as they correspond to instances of dogs.Categorizing some animal as a dog implies using dog exemplar(s) and calculating similarities.Note that the exemplars might have very different levels of specificity, i.e., levels of modality-specific detail or vividity.Sometimes we remember objectexemplars only vaguely with little detail, and sometimes very concretely with a lot of detail.</p>
<p>In the standard story of prototype theory, which aims to address prototype effects, my concept DOG consists of some representation of a typical dog.The representation is more abstract compared to an exemplar.Categorizing some animal as a dog under prototype theory, implies using the dog prototype and calculating the similarity.</p>
<p>Note that the processing, for instance in categorization tasks, of both exemplars and prototypes rely essentially on similarity calculations, primarily over relatively superficial features.</p>
<p>Some researchers think that exemplars and prototypes are the ends of a continuum rather than two distinct kinds (e.g., Vanpaemel et al. 2005, or Verbeemen et al. 2007).Authors like Barsalou (1990) and Hampton (2003) think that prototypes and exemplars differ only to the extent to which exemplar information is retained or abstracted away.Smith and Medin (1999:209) characterize exemplars in terms of a relative lack of abstraction.Exemplars can be maximally specific object-particulars but are not necessarily; they can also be subsets.For instance, PLANET is a subset of HEAV-ENLY BODY, and hence an exemplar for it.</p>
<p>Following those authors, I assume that there is no fundamental difference between exemplars and prototypes in terms of the deeper, underlying representational structure in the first place.In both cases, the general structure consists of a set of pairs of features and values.Those features might have different degrees of specificity/ schematicity.</p>
<p>Prototypes and exemplars in the PP model</p>
<p>The posited structure of a concept as a hierarchical node tree allows us to account for the exemplar and prototype formats.Concept processing in exemplar mode can be cashed out as the processing of the concept's node tree with attention towards relatively more specific information (without necessarily being maximally modally specific), while processing in prototype mode can be cashed out as more shallow processing, i.e., involving nodes with relatively less specific information.In both cases we have more or less deep "vertical downwards" processing of more superficial features.Those features are included in the node tree that origins in the concept's root node.</p>
<p>In PP terms, processing a concept in exemplar mode is processing towards lowerlevel (i.e., modally more specific) nodes.The tokening of the concept DOG in exemplar mode reaches from the conceptual root node [DOG] down to at least a subordinate node and potentially (but not necessarily) further to lower-level nodes down to the sensorimotor periphery.To conceive of a specific dog, e.g., Hasso, as a dog, implies the activation of the abstract [DOG] node and the subordinated [HASSO] node and other subordinate nodes, potentially down to specific shapes, colours, odours, etc.So, a whole node sub-tree from [DOG] might be activated.</p>
<p>To categorize a specific dog exemplar, say Hasso, a hypothesis needs to be generated that matches as well as possible whatever sensory input I receive.If my dog Fido is very similar to Hasso, a salient hypothesis is of course that Fido actually is Hasso.So, the hypothesis that reproduces a memory of Hasso fits well with the bottom-up Fido input, i.e., it produces a small prediction error in relation to other hypotheses.</p>
<p>Categorization might also happen via a prototype of DOG.If you cannot see Fido well (because he moves quickly and is far away and could be a cat as well) but hear loud barks, given that the feature of barking is strongly cue valid (i.e., the probability that something that barks is a dog is high), there is no need (and it would not be very economic) to recur to more specific exemplar information.The barking can be immediately explained by the hypothesis DOG and Fido categorized as a dog.</p>
<p>It is important to stress that, in the proposed view, what is an exemplar and what is a prototype is task-dependent.It might happen that in a task a prototype of some concept is represented with more detail than an exemplar of that concept in another task.Consider the following example:9 1) Suppose that a Bach scholar is played a piece of music and asked whether it is typical of Bach.To answer this question, the scholar may draw upon a very rich mental representation of the typical features of Bach pieces, which encodes very specific information about sensorimotor details such as certain kinds of instrumentation, cadences, melodies, harmonies, ornaments, rhythms and so on.</p>
<p>2) Now suppose that the scholar is asked whether the Brandenburg Concertos are a work by Bach.Plausibly, the scholar could answer this question without drawing on deep, specific, information, close to the sensory periphery.</p>
<p>In task 1), the prototypical representation, say BACH prototype , used by the scholar to decide whether the piece he is listening to is typical of Bach might perfectly contain very specific features.The important point is that BACH prototype is relatively more abstract than the exemplar representation in this task, which is the piece of music, say BACH exemplar , that she has to classify.In task 2) we deal with a completely different process, again with two representations, say, BACH-WORKS and BANDENBURG-CONCERTO.The question is whether the latter is an exemplar of the former.Indeed, to answer this, one only needs to know that the Brandenburg Concertos are works by Bach (the former is an instance of the latter category).What is needed is that BACH-WORKS is a relatively more abstract representation than BANDENBURG-CON-CERTO, and that is sufficient for the latter to be an exemplar of the former.According to the PP model, this is the case if, for instance, BANDENBURG-CONCERTO is represented as a child node of BACH-CONCERTOS.Here the exemplar BANDEN-BURG-CONCERTO from task 2) is much less concrete than BACH prototype from task 1); but that does not undermine the proposed account.What matters is the relative abstractness of the relevant representations within each task.</p>
<p>Let us turn to the probabilistic element of PP: the nodes making up the PP model represent whatever they represent in terms of probability distributions.Specifically, a node represents a probability distribution over nodes in the next lower level.For instance,10 Richard II might be represented as an exemplar of MONARCHS-OF-ENGLAND because the probability distribution over monarchs encoded in MON-ARCHS-OF-ENGLAND has at a given moment a sharp spike at the child node RICHARD II.Being an exemplar does not imply, however, that all lower-level nodes have sharp distributions.For instance, my probability distribution over the hair color feature of Richard II must be very spread-out indeed.As already mentioned, often exemplars are quite schematic (as in the Bach example 2).In the case of a prototype representation, the probability distribution is more broadly spread.A typical feature or exemplar is then one with the largest likelihood.For instance, MONARCHS-OF-ENGLAND might encode a probability distribution over features such that a typical monarch is one who has the most likely features, i.e., those features with the highest probabilities.</p>
<p>Note that in the PP view, there is no explicit "calculation" of similarity formulas, which is central to categorization in exemplar and prototype theories (see, e.g., Machery 2009 for examples of formulas).Rather, similarity is implicit in the fundamental mechanism of the PP model, namely, weighted prediction error minimization.In weighted prediction error minimization, the top-down prediction and the bottomup input at each level are compared, i.e., their "similarity" is determined.This mechanism can model both the more abstract prototype level (by focusing attention on higher level nodes, i.e., dampening lower-level nodes that represent more details) and the exemplar level (i.e., lower-level nodes are more error sensitive).</p>
<p>Prototype and exemplar effects</p>
<p>As emphasized already, a theory of concepts aims at accounting for a large body of behavioral effects observed during conceptual tasks.</p>
<p>Prototypes have been motivated by "typicality effects" that could not be explained by the previously prevailing definitional theory of concepts, according to which concepts are definitions or necessary and sufficient properties.A typicality effect arises when we judge certain objects to be more typical members of a category than others.For instance, a sparrow -in normal contexts -is judged to be a more typical bird than an ostrich.In the standard story of prototypes theory, the concept BIRD consists of a set of properties and a typicality rating for each property.A sparrow would in normal circumstances be a more typical bird than an ostrich.</p>
<p>Typicality can be accounted for in terms of representations based on probability distributions through conditional probabilities as they are posited by PP.For instance, if we know that something is a bird, we expect to a higher degree (in a neutral context) that some instantiation is a sparrow rather than an ostrich.So, a sparrow is a more typical bird that an ostrich.In PP jargon: when you are asked to mention a typical bird, your generative model is more likely to "sample" [SPARROW] in the next lower level in the node tree below [BIRD] than [OSTRICH].This is expressed as the following relation between two conditional probabilities p(OSTRICH | BIRD) &lt; p(SPARROW | BIRD) which are encoded in the PP world model.</p>
<p>The PP model can also provide an account of how exemplar effects work.Take, for instance, the old item advantage effect: memorized exemplars are more easily categorized than new ones that are equally typical (e.g., Smith andMinda 1998, 2000).Those effects could be modelled within the PP framework as follows.For sensory input like previously encountered and memorized exemplars, the prediction error is better minimized by using the exemplar rather than a prototype.In the case of "deep processing" which is characteristic for exemplar processing and where details matter, the most similar memorized bird exemplar just best "predicts" the target bird you see in front of you because it causes the least prediction error.The fact that details matter is cashed out in terms of the higher error sensitivity of lower-level nodes that represent more specific features.The more specific features, however, are only considered in the prediction if the brain assigns a high precision estimate to the prediction errors on the level of those features, i.e., when it considers details to be relevant and reliable.In the above example, where a person hears a dog barking in a foggy environment, details will be suppressed due to the lack of reliability of the sensory input.Therefore, more abstract prototype representations are used.Barking is a property with high cue validity.</p>
<p>So, according to the PP model, depending on the relevance and reliability of the details, exemplar or prototype modes of processing arise.Note that those are not two strictly dichotomic modes, but a gradation along the abstraction gradient exists.As mentioned, concepts within the PP model serve to modulate the granularity of predictions.Taking up again the example from Sect.4.2., it is not efficient when a street is crossed to predict the exact, maybe pixel-level, details of the event.Rather the event should be processed on a more aggregated level.For instance, we do not need to predict the exact shape and colour of the car approaching when we try to cross the street.It is sufficient to conceptualize the scene in larger grain, e.g., that some fastmoving car is approaching.Exemplar and prototype formats are manifestation of this context dependent granularity modulation (or choice of abstraction level).Also note that what format, or more precisely, what level of abstraction is used in each 1 3 task might vary across individuals.For instance, someone who is especially afraid of sports cars when crossing a street might pay more attention to more detailed features.Maybe someone is especially afraid of a specific car (because in the past Uncle Tim's car has almost hit her, for instance) and, therefore, she mobilizes even more detailed exemplar information for prediction making.</p>
<p>Theories</p>
<p>Now I argue that a concept can manifest itself in "theory mode" when the surrounding node structure in which the concept is embedded is processed (i.e., processing in a vertically upwards and horizontal direction from the concept's root node).I will first unpack this proposal by explaining how exactly to understand the notion of "theory" and how a theory is realized in the PP model.Then I will walk through an example of how we can account for a classical knowledge effect that motivated the theory format in the first place.</p>
<p>What is a "theory" in the theory-theory of concepts?</p>
<p>It is important to point out that theory-theory is far from being a monolithic position.Discrepancies (or indeterminacies) exist along various dimensions; let me mention two and make explicit what notion of theory I will assume.</p>
<p>Firstly, there are two ways in which the relation between concepts and theories has been spelled out (see, e.g., Weiskopf 2011): concepts are constituents of theories or concepts are miniature theories that store relevant theoretical (i.e., causal, functional, taxonomic, etc.) knowledge.In the first case, theories are bodies of beliefs or propositional structures with concepts as constituents.In a strong version of this view (e.g., Carey 1985) concepts are individuated as the roles they play in those theories.In the second case, concepts are structures that are themselves little theories (e.g., Keil 1989).However, it is not spelled out in detail what this position exactly amount to in terms of its representational structure.For instance, when Keil says most concepts are partial theories themselves in that they embody explanations of the relations between their constituents, of their origins, and of their relations to other clusters of features.(1989:281) the question arises as to what exactly the embodiment of those items looks like.If those items are articulated as beliefs or propositional structures, how is this then different from the concepts-as-constituents view?Even worse, the view seems then to have the incoherent implication that a concept is both a constituent and a theory of which it is a constituent.So, it is crucial to spell out how the knowledge items are represented.The concept-as-constituents view seems not to have this specific problem because there are two things: some theory and a concept that is a constituent of that theory.In turn, this view does not capture the intuition that a concept indeed seems to be some sort of "information package" including a host of theoretical information.In any case, we have here an unresolved problematic aspect of theory-theory in general because, as Weiskopf points out (2011), "the empirical evidence taken to support the Theory-Theory does not generally discriminate between them, nor have psychologists always been careful to mark these distinctions."</p>
<p>The advantage of the proposed PP account of concepts is, as I will argue later on, that it spells out a specific representational structure that allows to perfectly make sense of the idea that a concept can be seen to be both, a miniature theory and a constituent of a theory.</p>
<p>A second aspect where theory-theories vary is the demand regarding the coherence of the encoded knowledge.Kwong (2006) usefully distinguishes two different notions of theory, a literal and a liberal one.A literal theory is analogous to a scientific theory, and cognitive and conceptual development is equivalent to scientific theory formation and change.Here aspects of causal relationships, coherence, and systematic structure are stressed.An example of a literal understanding of a theory notion is Gopnik &amp; Wellman's (2012) account.According to the authors, a theory is a coherent structure of abstract representations, analogous to scientific theories (2012:1086).</p>
<p>On the other hand, in the liberal understanding of theory, as endorsed, for instance, by Murphy and Medin (1985), the knowledge structure is more flexible.When they say that "…we use theory to mean any of a host of mental 'explanations,' rather than a complete, organized, scientific account" (1985:426), they allow other, informal types of knowledge structures, i.e., formats, in a theory.Such formats are, for example, empirical generalizations (mere correlations of phenomena) or scripts (procedural knowledge, or a chain of events or acts).Liberal theory theorists put less demand on the coherence of a body of knowledge.A representational knowledge system does not need to exhibit formal consistency and rigor, deductive closure, etc., to count as a theory.Such features might be desirable and are most probably normative; however, they are not plausible as a description of how we cognitive-psychologically store knowledge.</p>
<p>I will endorse the liberal view of theories relevant for concepts because the strict view seems psychologically implausible (see also Machery 2009:102).The liberal notion of theory is closely related to the notion of "folk theories."A folk theory, or "intuitive theory" is common sense knowledge about a specific domain, for instance folk biology or folk psychology (e.g., Gerstenberg and Tenenbaum 2017).The building of such folk theories is less systematic and conscious than scientific theory building.</p>
<p>Theories in the PP model</p>
<p>As we have said before, in the proposed PP model, world knowledge is encoded as a huge network of interconnected prediction units (nodes) on many levels of abstraction/complexity.In the upper levels we have prediction units that represent complex situations, contexts, scenes, relations, patterns, patterns of patterns, etc.The lower levels represent for instance concepts of concrete objects or simple features like colour, etc.</p>
<p>The PP framework quite naturally accommodates theory-like structures, as the generative PP model is standardly interpreted as a multilevel causal model (e.g., Friston 2010, van Pelt et al. 2016).Nodes that correspond to variables form a proba-bilistic network.The model is hierarchical, i.e., the nodes at one level, roughly, correspond to latent variables that are the causes from which the variable in the next lower level can be derived.However, limiting the relations between the variables to causal relations makes the model too narrow (see also Sprevak 2021b).A prediction unit can be more generally interpreted as a prior that constrains the values on lower levels, i.e., nodes and sub-nodes have a more general form of "predictive relation", which can also include part-whole relations or taxonomic relations or object-property relations.The reason is that all of those are "predictive" in the sense that in the same way as causes constrain possible effects, genera constrain possible species, and wholes constrain possible parts.</p>
<p>In theory mode, so I suggest, it is the connectivity of a concept root node with higher-level nodes and nodes on similar levels in the total model hierarchy that is being exploited.In other words, the theory mode of concept processing arises from horizontal and vertical upwards processing outside the concept node tree, in addition to vertical downwards processing within the concept node tree below the concept's root node.While exemplar and protype processing remain within the structure of the subordinate nodes of a concept root node, in theory mode, processing expands upwards to more abstract and laterally into neighbouring concepts units.</p>
<p>One might think that theories are represented in terms of high-level, relatively abstract, human-interpretable, lexicalized concepts.For instance, a certain edge form representation in the brain´s visual processing stream is not a concept in the more traditional and common-sense understanding.Perceptual and conceptual representations are normally seen as qualitatively distinct.</p>
<p>However, authors proposing the existence of "folk theories" (e.g., Gerstenberg and Tenenbaum 2017) do not assume representations in symbolic and lexicalized form.A folk theory of physics, which allows for guessing whether certain tower constructions are stable, requires complex "sub-symbolic" sensorimotor representations.Similarly, I have emphasized within the proposed PP view the existence of many ineffable, consciously not accessible, and non-lexicalized nodes on many levels of abstraction (see also Lake et al. 2017 for a discussion of sub-personal "theories" that are not lexicalized).Those sub-symbolic nodes are continuous with the symbolic nodes that correspond to more narrowly understood concepts (e.g., only lexicalized or lexicalizable11 concepts).All the nodes are "concepts" in virtue of them playing the role of prediction units.They just differ in the degree of abstraction.We could stipulate that only narrowly conceived concepts form theories.But nothing hangs on this rather terminological decision.We can consider theories based on narrow concepts to be "embedded" in the total PP model, which consists of both narrow and inclusively conceived concepts.</p>
<p>Accounting for knowledge effects</p>
<p>The classical knowledge effect I want to focus on here as an example is reported by Rips (1989) in his famous pizza experiment.It provides evidence that sometimes we classify some A to be a B, rather than a C, even if A is more similar to C. Rips asked participants to imagine a circular object of three inches and asked whether it was more similar to a quarter or a pizza.The dominant answer was that it was more similar to a coin (because of its small size).Then the participants were asked whether it is more likely a pizza or a quarter.The dominant answer was that it was more likely a pizza (because quarters have uniform sizes, while pizza sizes might vary).Here we do not categorize in terms of similarity but rather based on more extended knowledge, e.g., of the manufacturing process of pizzas and quarters from which we can infer their possible variability in size.</p>
<p>Let us now account for the pizza experiment by the PP model.The concept formats involved -prototypes/ exemplars versus theory-like common-sense knowledge -seem to be primed by the task.In the first task, the subjects are explicitly being asked to make a similarity judgement while the second task evokes a judgement about the causal chain that brought about each object (pizza versus quarter).</p>
<p>Such causal knowledge is encoded in the PP model as specific experiences but also more abstract generalizations that one might have, which also involve other concepts like PIZZA BAKER, PIZZA OVEN, DOUGH, etc. from experiences with how pizzas are made (see Fig. 1).Hence the concept PIZZA is being processed by carrying out inferences with concept units outside the information package PIZZA itself.A more abstract node in the PP model might be a concept unit representing a complex schema PIZZA-BAKING_SCHEMA which is a sub-domain of commonsense knowledge about baking represented by BAKING-SCHEMA.PIZZA-BAK-ING_SCHEMA might have sub-nodes that are part of the knowledge about pizza baking, let us say AGENT-FORMS-DOUGH_SCHEMA and HEAT-DOUGH-TO-END-PRODUCT_SCHEMA.12 AGENT-FORMS-DOUGH_SCHEMA again contains sub-nodes that contain information about how an agent forms the dough, etc. From that knowledge one can infer that it is easy to make, for instance, a pizza that is smaller than usual, simply by applying the same pizza forming process to a reduced quantity of dough.This reduced quantity is possible as the pizza baker is free to choose the quantity she wishes.</p>
<p>Similarly, quarter, might be a node subordinate to a more abstract node corresponding to some frame concept unit, which links quarter in such a way as to encode common-sense knowledge about the role and production of coins.From that knowledge one can infer that it is very unlikely that a coin has the size of the target object.The agents intervening in the coin producing process do not normally have the "freedom" to alter the size of a coin ad hoc.</p>
<p>Taking this way of processing the concept structure, the inference is being made that a pizza can easily have different sizes, while coins do not.Therefore, the target object is more likely to be a pizza 13 .</p>
<p>Are concepts then theories or constituents of theories?</p>
<p>With this approach of the theory format in hand, we can now briefly revisit the question discussed in Sect.5.2.1.,namely whether a concept (in its theory format) is a theory or a constituent of a theory.It is easy to see that the dispute now looks merely verbal.A concept can be both.A concept, say APPLE, can appear to be a theory when connected nodes are processed that represent theoretically relevant information (i.e., when it is processed in theory mode).But APPLE can also appear to be a "constituent" of some (other) theory, namely when at least the root-node of APPLE is processed as part of the processing in theory mode of some (other) concept, for instance, FRUIT or NUTRITION.</p>
<p>The functional integration of exemplars/prototypes and theories</p>
<p>One might object that exemplars/prototypes and theories do not seem to have the same status in the concept's information package.There are three properties that prototype and exemplar processing share but that are absent from theory processing.Firstly, prototype and exemplar processing involve nodes of the sub-network of the 13 Given that the PP approach has commitments on the level of neural implementation, at least in principle, there is an avenue for empirical verification/falsification of the model.Admittedly, the current state of the art in brain imaging techniques does not yet provide a sufficient level of temporal and spatial resolution to map out concepts and neural structures in the required way.concept's root node, while at least some nodes corresponding to theory processing lie outside this sub-network.Secondly, we have also seen that the distinction between exemplars and prototypes is a relative affair, but nothing similar has been said for the theory format.Finally, exemplars and prototypes are closely associated with the notion of similarity, which is not (at least not obviously) the case for theoretical knowledge.</p>
<p>Despite those differences, all three formats should be seen as deeply functionally integrated in the form of a prediction device.To better understand why theoretical information is also integrated with exemplar and prototype information of a given concept, note that -from a neuro-anatomical point of view -the main difference is that processing theoretical information involves nodes on a level higher than (or the same level as) the concept's root-node, while prototype/exemplar information involves nodes at a relatively lower-level.In both cases, however, the concept's root node is involved and connected to those nodes, and the general structure and processing principles are the same in the whole hierarchy.The specific connectivity implements a layered structure of conditional probabilistic dependencies among the nodes on different levels.It is this informational dependency dynamics which then integrates the higher and lower-level nodes connected to a given root-node into a functional whole.Let me work this out in further detail.</p>
<p>Remember that a PP model is a generative model with latent variables represented as nodes that "explain" (or "generate", or "sample") features represented by lowerlevel nodes.While lower-level nodes correspond to concepts that are "explained" by some concept in question, higher-level nodes correspond to concepts that "explain" that lower-level concept.For instance, while APPLE "explains" RED, FRUIT "explains" APPLE in the sense relevant here.In other words, using the terminology of generative models, RED is a sampled (a "generated") feature from the probability distribution over features represented by APPLE.APPLE, in turn, is sampled with a relatively high probability from FRUIT, which is a probability distribution over fruit types.</p>
<p>Plausibly, the body of knowledge associated with some concept includes both information about what it is caused/explained by and what it is a cause/explanation for.In this sense, exemplars/prototypes (with more superficial features) and theoretical features (representing more abstract causal, taxonomic, mereological, etc. relations) form a functionally integrated information package.The difference is only one of explanatory (or "generative") direction.</p>
<p>To bring home my point about the tight functional integration of exemplars/prototypes and theoretical information, it might be useful to refer briefly to Bloch-Mullins' recent work on concepts (e.g., 2018, 2021).There is no space here for a careful discussion of her account and a detailed comparison, but it is worthwhile pointing to some deeper commonalities, which suggest some substantial common ground.</p>
<p>Bloch-Mullins (e.g., 2018: 607) observes, quite correctly in my view, that the problem with the different single-format accounts of concepts is not that they are each on their own unable to cover all of the empirical data from concept research.The problem is that they do not even have sufficient explanatory depth with regards to the restricted scope of the phenomena they were designed to cover.For instance, she argues that the similarity judgements involved in exemplar and prototype applica-1 3 tions cannot be calculated without theoretical (specifically causal) knowledge about how to pick out the relevant dimensions for comparison (pp.609-614).Theoretical knowledge, in turn, can't be applied in categorization without using similarity judgements to determine the relevant range of values that determine the category of a variable figuring in a causal relation (pp. 615-621).Normally, the values of the variables by which those causal relations (used for categorization) are described are not identical, but only sufficiently similar to underwrite classification.A second way in which causal knowledge is relevant in categorization is that the dimensions selected for similarity judgements might also include causal relations (Bloch-Mullins 2018, pp.622 and 624; see also Bloch-Mullins 2021:61-62;Hampton 2006:85-86).I suggest a third way in which similarity intrudes categorization based on causal knowledge: grasping and applying theoretical knowledge is itself recognizing analogies/similarities to abstract (e.g., causal) patterns, i.e., causal knowledge is stored as patterns that demand similarity matching.</p>
<p>I am very sympathetic with Bloch-Mullins' view.In the PP model, the similarity of A and B can be fleshed out as A and B being an instance of (being "sampled from") some concept node.If there is some C that "generates" A and B, then A and B are similar with respect to the features that C encodes.But this idea is transferable to theoretical (i.e., causal, taxonomic, mereological, etc.) features.To see this, let us take one of the examples that motivated the theory format of concepts, namely deep "essences" of living creatures (e.g., Medin &amp; Ortony, 1989;Gelman, 2004).For example, assume that HORSE-A and HORSE-B are representations of horse exemplars in virtue of being sampled by some HORSE-ESSENCE which represents the horse essence that "generates" horses.Our folk-biology might be represented minimally as the knowledge that animals have hidden essences that are responsible for (i.e., cause) the existence of certain animal types.In the PP model, this knowledge is captured by some abstract high-level prediction unit that encodes the very general concept of ANIMAL-ESSENCE as part of some animal folk-theory.There are lowerlevel child nodes of [ANIMAL-ESSENCE] that correspond to more specific essences like HORSE-ESSENCE, DOG-ESSENCE, etc.Those in turn sample (or "generate") concrete exemplars of the corresponding species, e.g., FIDO (the dog).</p>
<p>The advantage of the PP approach is, as previously pointed out, that similarity calculations are not based on algorithms over an explicit list of features but are the implicit result of holistic prediction error minimization.What is then instantiated as being similar to what depends heavily on the "context" which includes background knowledge, goals, foils under consideration, etc., all of which are represented by other prediction units in the network.PP captures well this highly context dependent dynamics of similarity calculations.Similarity judgements emerge holistically from all of the relevant available information in the PP model.</p>
<p>In which sense does the PP model refine the coactivation hybrid account?</p>
<p>Let us get back to the end of Sect. 2 where I pointed out two possible improvements to the coactivation account: spelling out more concretely what functional integration amounts to and providing constraints for "admissible" formats.Let us revisit each of them in the light of the proposal just developed.</p>
<p>First, there is a more specific notion of functional integration that emerges from the PP model.The whole coactivation package of a concept serves as a contextsensitive prediction device for the category represented by the concept.A coactivation package, we have seen, consists of a root-node and the depending sub-network of lower-level nodes.The root-node is the result of abstraction and convolution of lower-level nodes, therefore in a sense it is closely connected to (i.e., it "contains" information of) all sub-nodes.Those subordinate nodes correspond to exemplar and prototypical information.Furthermore, as this package is integrated into the whole overall model, it has external connections to other lateral and higher-level nodes.Those nodes correspond to more theoretical and abstract knowledge associated with the concept, namely causal, taxonomic, mereological, etc., information that "explains" the concept.</p>
<p>Processing in the PP model is holistic, so all of the nodes are interlocked and have an influence on the overall state of the information package associated with the concept, i.e., on which other nodes are selected, and which are not.</p>
<p>With the PP model, an account of the context sensitive modulation of the subparts of a coactivation package comes for free because it is a core feature of the general PP framework.It can be put to work to select the processing depth and direction that determine the appearance of the concept formats.</p>
<p>Secondly, the PP model provides constraints for possible formats, namely those imposed by the PP architecture.One needs to be able to derive the format from the representational resources provided by PP.We have seen that we can derive the three generally accepted, classical formats: exemplars, prototypes, and theories.An interesting next step -that needs to be carried out elsewhere, however -would be to explore whether other candidate formats like definitions, scripts or ideals could be derived from, or are consistent with, the proposed PP model.</p>
<p>Conclusions</p>
<p>This paper has attempted to put forward a cognitive-computational model of hybrid concepts within the Predictive Processing framework.In the view proposed here, formats are -contrary to most other hybrid accounts -not to be understood as components of a concept.Rather, formats correspond to different directions and depths of processing of the same concept structure.</p>
<p>The model aims to further develop and improve Vicente &amp; Martínez Manrique's hybrid account with regard to two aspects.Firstly, it spells out what "functional integration" of the formats more specifically amounts to.Functional integration is necessary for a genuine hybrid account.Formats are functionally integrated in the PP model because they arise as optimal (i.e., prediction error minimizing) ways of processing a unified representational structure.Critical for the functional integration is the context-sensitive selection of subparts of the structure (which then appear as different formats).Such a format selection mechanism comes for free in the PP model.Secondly, the proposed model provides constraints for possible formats because it supplies more detail about how concepts are represented and processed in the mind, 1 3 providing more specific computational, algorithmic and implementational level commitments.</p>
<p>Fig. 1
1
Fig. 1 A schematic toy example of a concept unit network for the concept PIZZA and modes of processing</p>
<p>The authors call the highest level in the hierarchy "amodal". However, it seems also appropriate to call it "multimodal", given that in that layer we abstract across a maximally broad range of modalities, so it is just one more step in the abstraction/convolution hierarchy, not a qualitatively different step (see also Michel 2020b).
Let me stress that I don't aim here at defending the PP framework, therefore I will not put forward arguments or evidence for it. For that I refer to the mentioned literature.1 3
We will later see that it would be more accurate to say here that higher levels contain the root nodes of the representational structure corresponding to concepts.1 3
My brief exposition of PP is far from complete, and I have omitted many features, e.g., active inference, efficient coding, etc. Virtually every paper related to Predictive Processing contains introductions to the framework. I can recommend, e.g.,Wiese (2017);Williams (2018);Sprevak (2021a,b), for a more detailed overview.
I am grateful to an anonymous reviewer for providing various potential counterexamples, including this one.1 3
Thanks to an anonymous reviewer for the example, which helped me to make the point clearer.
A feral child might have the lexicalizable concept WOLF, though it is not lexicalized. In contrast, all sorts of ineffable edge-patterns and shapes are used, e.g., in lower levels of the visual pathway there are prediction nodes that are not consciously accessible and lexicalizable in any meaningful way.
Here PIZZA-BAKING_SCHEMA could be a concept that encodes a script, i.e., a sequence of actions.1 3
Acknowledgements I would like to thank Mark Sprevak and three anonymous reviewers for their veryPublisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
A Hybrid Model of Categorization. J R Anderson, J Betz, Psychonomic Bulletin and Review. 82001</p>
<p>On the indistinguishability of exemplar memory and abstraction in category representation. L W Barsalou, Advances in social cognition. 31990</p>
<p>On Staying Grounded and Avoiding Quixotic Dead Ends. L W Barsalou, Psychonomic Bulletin &amp; Review. 2342016</p>
<p>Canonical Microcircuits for Predictive Coding. A M Bastos, W M Usrey, R A Adams, G R Mangun, P Fries, K J Friston, Neuron. 7642012</p>
<p>Bridging the Gap between Similarity and Causality: An Integrated Approach to Concepts. C L Bloch-Mullins, The British Journal for the Philosophy of Science. 6932018</p>
<p>Similarity Reimagined (with Implications for a Theory of Concepts). C L Bloch-Mullins, Theoria. 8712021</p>
<p>Conceptual change in childhood. S Carey, 1985MIT press</p>
<p>Whatever next? Predictive brains, situated agents, and the future of cognitive science. A Clark, Behavioral and Brain Sciences. 3632013</p>
<p>Unifying the mind: Cognitive representations as graphical models. A Clark, 2016. 2014MIT PressDanks, DSurfing uncertainty: Prediction, action, and the embodied mind</p>
<p>How to build a brain: A neural architecture for biological cognition. C Eliasmith, 2013Oxford University Press</p>
<p>Rules and Exemplars in Category Learning. M A Erickson, J K Kruschke, Journal of Experimental Psychology: General. 1271998</p>
<p>The free-energy principle: A unified brain theory?. K Friston, Nature Reviews Neuroscience. 1122010</p>
<p>Psychological essentialism in children. S A Gelman, Trends in cognitive sciences. 82004</p>
<p>Intuitive theories. Oxford Handbook of Causal Reasoning. T Gerstenberg, J B Tenenbaum, 2017</p>
<p>Reconstructing constructivism: Causal models, Bayesian learning mechanisms, and the theory theory. A Gopnik, H M Wellman, Psychological bulletin. 138610852012</p>
<p>Abstraction and context in concept representation. J A Hampton, Philosophical Transactions of the Royal Society of London Series B: Biological Sciences. 3582003. 1435</p>
<p>Concepts as prototypes. J A Hampton, The Psychology of Learning and Motivation: Advances in Research and Theory. B H Ross, AmsterdamElsevier200646</p>
<p>Categories, prototypes and exemplars. J A Hampton, The Routledge Handbook of Semantics. Routledge2015</p>
<p>The Semantic Content of Abstract Concepts: A Property Listing Study of 296 Abstract Words. M Harpaintner, N M Trumpp, M Kiefer, Frontiers in Psychology. 917482018</p>
<p>Neurocognitive architecture of the semantics of abstract concepts. M Harpaintner, 2020Dissertation University of Ulm</p>
<p>The grounding of abstract concepts in the motor and visual system: An fMRI study. M Harpaintner, E.-J Sim, N M Trumpp, M Ulrich, M Kiefer, Cortex; A Journal Devoted To The Study Of The Nervous System And Behavior. 1242020</p>
<p>Hierarchy' in the organization of brain networks. C C Hilgetag, A Goulas, Philosophical Transactions of the Royal Society B: Biological Sciences. 375201903192020. 1796</p>
<p>Conceptual flexibility in the human brain: Dynamic recruitment of semantic maps from visual, motor, and motion-related areas. K Hoenig, E.-J Sim, V Bochev, B Herrnberger, M Kiefer, Journal of Cognitive Neuroscience. 20102008</p>
<p>The predictive mind. J Hohwy, 2013Oxford University Press</p>
<p>New directions in predictive processing. J Hohwy, Mind &amp; Language. 3522020</p>
<p>Receptive fields of single neurones in the cat's striate cortex. D H Hubel, T N Wiesel, The Journal of physiology. 14831959</p>
<p>Cerebral hierarchies: Predictive processing, precision and the pulvinar. R Kanai, Y Komura, S Shipp, K Friston, Philosophical Transactions of the Royal Society B: Biological Sciences. 3702015. 1668</p>
<p>Concepts and conceptual development: Ecological and intellectual factors in categorization (1). F C Keil, Neisser, U.1989CUP Archive</p>
<p>Hybrid vigor and conceptual structure. F Keil, Concepts, Kinds, and Cognitive Development. Cambridge, MAMIT Press201033</p>
<p>Predictive Processing: A Canonical Cortical Computation. G B Keller, T D Mrsic-Flogel, Neuron. 10022018</p>
<p>Are the motor features of verb meanings represented in the precentral motor cortices? Yes, but within the context of a flexible, multilevel architecture for conceptual knowledge. D Kemmerer, Psychonomic Bulletin &amp; Review. 2242015</p>
<p>Conceptual representations in mind and brain: Theoretical developments, current evidence and future directions. M Kiefer, F Pulvermüller, Cortex; A Journal Devoted To The Study Of The Nervous System And Behavior. 4872012</p>
<p>Category learning. J K Kruschke, R L Lamberts, Goldstone, The handbook of cognition. Sage2005</p>
<p>Task-Dependent Functional and Effective Connectivity during Conceptual Processing. P Kuhnke, M Kiefer, G Hartwigsen, Cerebral Cortex. 3172021</p>
<p>Why concepts can't be theories. J M Kwong, Philosophical Explorations. 932006</p>
<p>Building machines that learn and think like people. B M Lake, T D Ullman, J B Tenenbaum, S J Gershman, Behavioral and Brain Sciences. 402017</p>
<p>The Emotions of Abstract Words: A Distributional Semantic Analysis. A Lenci, G E Lebani, L C Passaro, Topics in Cognitive Science. 1032018</p>
<p>Concepts and categorization: Do philosophers and psychologists theorize about different things?. G Löhr, Synthese. 19752020</p>
<p>E Machery, E Margolis, S Laurence, Concepts: Core Readings. Mit Press2009. 1999Doing Without Concepts</p>
<p>Concepts and Theoretical Unification. E Margolis, S Laurence, Behavioral and Brain Sciences. 332010</p>
<p>. D Marr, 1982MIT PressCambridge, MA</p>
<p>Context theory of classification learning. D L Medin, M M Schaffer, Psychological Review. 851978</p>
<p>Psychological essentialism. D L Medin, A Ortony, Similarity and analogical reasoning. S Vosniadou, A Ortony, Cambridge University Press1989</p>
<p>Concept contextualism through the lens of Predictive Processing. C Michel, Philosophical Psychology. 3342020a</p>
<p>Overcoming the modal/amodal dichotomy of concepts. C Michel, 10.1007/s11097-020-09678-yPhenomenology and the Cognitive Sciences. 2020b</p>
<p>The role of theories in conceptual coherence. C Michel Murphy, G L , D L Medin, Psychological Review. 9232891985</p>
<p>Attention, similarity, and the identification categorization relationship. R M Nosofsky, Journal of Experimental Psychology: General. 1151986</p>
<p>Rule-plus-exception model of classification learning. R M Nosofsky, T J Palmeri, S Mckinley, Psychological Review. 1011994</p>
<p>On the adequacy of prototype theory as a theory of concepts. D N Osherson, E E Smith, Cognition. 911981</p>
<p>Curb Your Embodiment. D Pecher, Topics in Cognitive Science. 1032018</p>
<p>Splitting concepts. G Piccinini, S Scott, Philosophy of Science. 7342006</p>
<p>On the genesis of abstract ideas. M I Posner, S W Keele, Journal of Experimental Psychology. 773p11968</p>
<p>Hierarchical dynamics as a macroscopic organizing principle of the human brain. J J Prinz, R V Raut, A Z Snyder, M E Raichle, Proceedings of the National Academy of Sciences. 117342002. 2020MIT PressFurnishing the mind: Concepts and their perceptual basis</p>
<p>Concepts as Pluralistic Hybrids. C Rice, Philosophy and Phenomenological Research. 9232016</p>
<p>Similarity, typicality, and categorization. L J Rips, Similarity and analogical reasoning, eds. S. Vosniadou, and A. Ortony1989Cambridge University Press</p>
<p>Principles of categorization. E Rosch, Cognition and categorization. E Rosch, B B Lloyd, Hillsdale, NJLawrence Erlbaum1978</p>
<p>The exemplar view. E Smith, D Medin, Concepts: Core Readings. E Margolis, S Laurence, MIT Press1999</p>
<p>Prototypes in the mist: The early epochs of category learning. J D Smith, J P Minda, Journal of Experimental Psychology: Learning Memory and Cognition. 241998</p>
<p>Thirty categorization results in search of a model. J D Smith, J P Minda, J Exp Psyc : Learning Memory and Cognition. 262000</p>
<p>M Sprevak, Predictive coding I: Introduction. PhilSci-Archive URL. 2021a</p>
<p>M Sprevak, Predictive coding III: Algorithm. PhilSci-Archive URL. 2021b</p>
<p>Flexibility in embodied lexical-semantic representations. W O Van Dam, M Van Dijk, H Bekkering, S.-A Rueschemeyer, Human Brain Mapping. 33102012</p>
<p>Beta-and gammaband activity reflect predictive coding in the processing of causal events. S Van Pelt, L Heil, J Kwisthout, S Ondobaka, I Van Rooij, H Bekkering, Social cognitive and affective neuroscience. 1162016</p>
<p>A varying abstraction model for categorization. W Vanpaemel, G Storms, B Ons, Proceedings of the Annual Conference of the Cognitive Science Society. the Annual Conference of the Cognitive Science SocietyMahwah, NJLawrence Erlbaum Associates200527</p>
<p>Beyond exemplars and prototypes as memory representations of natural concepts: A clustering approach. T Verbeemen, W Vanpaemel, S Pattyn, G Storms, T Verguts, Journal of Memory and Language. 5642007</p>
<p>The Big Concepts Paper: A Defence of Hybridism. A Vicente, F Martínez Manrique, British Journal for the Philosophy of Science. 6712016</p>
<p>The Neural Representation of Abstract Words: The Role of Emotion. G Vigliocco, P A S.-T. Kousta, D P Della Rosa, M Vinson, J T Tettamanti, S F Devlin, Cappa, Cerebral Cortex. 2472014</p>
<p>Representation at different levels in a conceptual hierarchy. W Voorspoels, G Storms, W Vanpaemel, Acta psychologica. 13812011</p>
<p>Evaluating the neurophysiological evidence for predictive processing as a model of perception. K S Walsh, D P Mcgovern, A Clark, R G O'connell, Annals of the New York Academy of Sciences. 146412020</p>
<p>The Neural Correlates of Hierarchical Predictions for Perceptual Decisions. V A Weilnhammer, H Stuke, P Sterzer, K Schmack, The Journal of Neuroscience. 38212018</p>
<p>The plurality of concepts. D A Weiskopf, Synthese. 16912009</p>
<p>The theory-theory of concepts. D A Weiskopf, Internet Encyclopedia of Philosophy. James Fieser, &amp; Bradley Dowden, 2011. April 202216Last access</p>
<p>What are the contents of representations in predictive processing?. W Wiese, Phenomenology and the Cognitive Sciences. 1642017</p>
<p>Predictive Processing and the Representation Wars. D Williams, Minds and Machines. 201828</p>
<p>Putting concepts into context. E Yee, S L Thompson-Schill, Psychonomic Bulletin &amp; Review. 2342016</p>            </div>
        </div>

    </div>
</body>
</html>