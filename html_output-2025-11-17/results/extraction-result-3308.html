<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3308 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3308</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3308</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-76.html">extraction-schema-76</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <p><strong>Paper ID:</strong> paper-8db1dcae055842f43ccac04182957b20d15bbe6b</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/8db1dcae055842f43ccac04182957b20d15bbe6b" target="_blank">Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> A novel Bayesian formulation for creating an ensemble over the base methods to further boost the accuracy of LLMs on the backward reasoning task, with the ensemble-based method resulting in significant performance gains compared to the SOTA forward reasoning strategies the authors adapt.</p>
                <p><strong>Paper Abstract:</strong> While forward reasoning (i.e., find the answer given the question) has been explored extensively in recent literature, backward reasoning is relatively unexplored. We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information? On modifying three benchmark datasets for this task, to evaluate this task: GSM8k, SVAMP, and MultiArith, we find a significant drop in the accuracy of models on this task compared to forward reasoning across SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa). Motivated by the fact backward reasoning can be seen as the ''inverse'' of forward reasoning, we propose variations of three different forward reasoning strategies to improve performance. Rephrase reformulates the given problem into a forward reasoning problem, PAL-Tools combines the idea of Program-Aided LLMs to produce a set of equations that can be solved by an external solver, and Check your Work exploits the availability of natural verifier of high accuracy in the forward direction, interleaving solving and verification steps. Finally, realizing that each of our base methods correctly solves a different set of problems, we propose a novel Bayesian formulation for creating an ensemble over the base methods to further boost the accuracy. Extensive experimentation demonstrates successive improvement in the performance of LLMs on the backward reasoning task, using our strategies, with our ensemble-based method resulting in significant performance gains compared to the SOTA forward reasoning strategies we adapt.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3308.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3308.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A state-of-the-art closed-source large conversational transformer model from OpenAI, evaluated in the paper for math word problems using few-shot Chain-of-Thought (CoT) prompts and compared on forward vs. backward reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>GPT-4 technical report</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source large pretrained transformer (chat-capable) from OpenAI, used via API with few-shot prompting (Chain-of-Thought). The paper uses GPT-4 as a representative SOTA forward reasoner baseline and measures its drop on backward tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Chain-of-Thought (CoT, few-shot)', 'Rephrase (algebraic rephrasing for backward -> forward)', 'Verification (forward verifier via LLM)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>CoT: 8-shot chain-of-thought prompts as in Wei et al. 2022. Rephrase: convert backward masked question into an explicit forward problem by injecting the final answer and introducing an 'x' variable and ask model to solve for x. Verification: substituting candidate blank into question and solving forward to check match with given final answer.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>Paper evaluates GPT-4 primarily with CoT in Table 1 (baseline) and applies rephrasing style in follow-up methods; diversity of methods in experiments is realized across models but GPT-4 itself is tested mostly with CoT prompting for the forward/backward comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Backward MWP variants (GSM8k_B, SVAMP_B, MultiArith_B); Forward MWP baselines (GSM8k, SVAMP, MultiArith)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Math Word Problems (grade-school arithmetic) transformed into 'backward' tasks by blanking a single numeric token and providing the original forward answer; objective is to infer the blanked numeric value.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td>Table 1 few-shot CoT baseline: GSM8k forward 92.8% -> backward 38.6%; SVAMP forward 90.5% -> backward 43.9%; MultiArith forward 97.8% -> backward 54.8%. (These values reflect a large drop when moving from forward to backward reasoning using CoT prompting.)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td>The paper shows GPT-4 using standard CoT suffers a substantial accuracy drop on backward tasks compared to forward; rephrasing and other strategies (evaluated more extensively with GPT-3.5) improve backward performance, suggesting CoT alone (a similar style) is insufficient and diverse prompting/solver+verifier strategies help.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Even SOTA models such as GPT-4 show large accuracy degradation on backward MWPs when only using standard CoT prompting. Transforming backward tasks into explicit forward formulations (rephrase) and using verification/ensemble strategies provides pathways to recover performance (demonstrated more fully with GPT-3.5).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>No multi-method ablations were run extensively for GPT-4 in the paper; the baseline negative result is that standard CoT yields low backward accuracy (≈38.6% on GSM8k_B) compared to forward.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3308.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3308.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5-Turbo (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely-used chat-style large language model used extensively in the paper to evaluate multiple reasoning strategies for backward math word problems, including rephrasing, PAL, Tools, CYW, Self-Refine, PAL-Tools, and a Bayesian ensemble with a forward verifier.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source chat-capable LLM from OpenAI used via API. In experiments, used with various few-shot prompting strategies (different shot counts per method) and as the verifier model in the ensemble. Temperature set to 0.5 in many experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Chain-of-Thought (CoT, few-shot)', 'Rephrase (algebraic and linguistic)', 'PAL (Program-Aided Language Model)', 'Tools (frame equations, call SymPy solver)', 'PAL-Tools (PAL + Tools combination)', 'Check Your Work (CYW) / Self-verification (iterative)', 'Self-Refine (iterative refinement)', 'Bayesian Ensemble with LLM forward verifier', 'Majority voting baseline']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>CoT: standard 8-shot chain-of-thought prompting. Rephrase: transform backward Q/A pair into a forward problem by inserting the final answer and introducing x; two rephrase styles: algebraic (explicit x and equations) and linguistic. PAL: prompt to write Python/SymPy programs to solve for blank. Tools: ask model to frame equations in natural language and call external solver (SymPy). PAL-Tools: combine PAL program formulation with external solver calls. CYW: generate candidate blank, substitute into question, then verify by solving forward to match given final answer; loop until verified. Self-Refine: iterative self-feedback. Bayesian ensemble: sample answers from diverse models, use LLM verifier's forward-check output on holdout to estimate P(Z|correct) and P(Z|incorrect) and apply Bayes' rule to weight candidates; selects answer with highest posterior.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>Paper explicitly uses a diverse set of reasoning/prompting styles (symbolic/program-based (PAL), tool-assisted equation solving (Tools), natural-language rephrasing, iterative self-verification/refinement, and a Bayesian ensemble combining them). Diversity is introduced via different prompting paradigms and use of external solvers and a verifier.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>GSM8k_B, SVAMP_B, MultiArith_B (backward MWP variants); also phrase-masked backward reasoning (100-example subset).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Backward MWP: single numeric token blanked from the question; model is given original forward answer and must infer the blank. Phrase-mask extension blanks a phrase (may allow multiple acceptable answers) and requires manual verification.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td>Table 1 forward/backward baseline (CoT 8-shot): GSM8k forward 58.4% -> backward 10.8%; SVAMP 79.1% -> 20.4%; MultiArith 97.0% -> 14.5%. Detailed GPT-3.5 results (Table 2, per-method on backward datasets): CoT: GSM8k_B 10.77%, SVAMP_B 20.40%, MultiArith_B 14.50%. PAL: 9.27%, 20.90%, 18.17%. Tools: 31.45%, 43.50%, 71.83%. PAL-Tools: 37.11%, 42.70%, 80.50%. Rephrased variants improved performance (CoT(R): 36.12%, 37.80%, 71.67%; Tools(R): 41.43%, 48.5%, 73.00%; PAL-Tools(R): 48.74%, 51.10%, 84.50%). CYW(R): 41.82%, 47.40%, 84.83%. Self-Refine(R): 40.17%, 49.70%, 77.50%. Ensembling (Table 3): Majority voting: 58.28% (GSM8k_B), 59.07% (SVAMP_B), 92.00% (MultiArith_B); Bayesian Ensemble (with verifier): 65.33%, 66.67%, 92.60% (GSM8k_B, SVAMP_B, MultiArith_B respectively). Phrase-masked 100-example subset (Table 8): Ensembling achieved 61.16% accuracy; best single rephrased methods ~37-38%.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td>Explicit comparisons show (1) single-method CoT and PAL perform poorly on backward tasks; (2) Tools and PAL-Tools substantially outperform CoT and PAL; (3) Rephrasing (especially algebraic prompt using 'x') improves all methods, with larger gains for initially weaker methods; (4) CYW (verification-based iterative approach) outperforms Self-Refine on some datasets; (5) PAL-Tools (R) is the best single method in many cases; (6) combining diverse methods via Bayesian ensembling with a forward verifier outperforms majority voting and any single method (gains of ~7% over majority voting, and ~10-20% over best single-methods).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Diverse reasoning styles (programmatic PAL, external solver Tools, rephrasing, and verifier-guided iterative methods) solve different subsets of backward MWPs, so combining them yields large gains. Rephrasing the backward task into an explicit forward problem (algebraic prompt) is broadly helpful. Using a forward verifier (LLM solving the forward substituted problem) and Bayesian ensembling yields the best performance and outperforms naive majority voting.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>PAL by itself performs poorly (low program quality for backward tasks). Self-Refine is not always better than the CYW verifier approach. Some phrase-masked generations can trivially 'cheat' by guessing the final answer as x, leading to technically correct but non-general solutions; ensemble selection can treat multiple semantically equivalent phrase variants as distinct (exact matching issues). Overall, backward reasoning remains substantially harder than forward reasoning across models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3308.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3308.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PaLM-2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PaLM 2</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Google's PaLM-2 family of large language models, evaluated as a baseline in forward vs. backward MWP comparisons using few-shot prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Palm 2 technical report</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PaLM-2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large pretrained transformer family from Google (PaLM-2 technical report cited). In this paper, PaLM-2 is used as a baseline model with CoT few-shot prompts to measure forward vs. backward performance.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Chain-of-Thought (CoT, few-shot)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>8-shot chain-of-thought prompting used for forward/backward baseline comparisons (as with other SOTA models in Table 1). The paper does not extensively evaluate PaLM-2 across the other specialized backward strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>Limited for PaLM-2 within this paper — primarily evaluated with standard CoT prompting for baseline forward/backward comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>GSM8k_B, SVAMP_B, MultiArith_B (backward MWP variants) and forward counterparts</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Same backward MWP transformation as for other models.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td>Table 1 (CoT baseline): GSM8k forward 60.5% -> backward 15.2%; SVAMP forward 73.7% -> backward 11.2%; MultiArith forward 95.7% -> backward 6.3%.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td>PaLM-2's CoT baseline shows a very large drop on backward tasks, consistent with trends observed for other models; the paper uses this to motivate specialized strategies but does not run PaLM-2 on the full set of adapted methods.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>PaLM-2 exhibits substantial degradation from forward to backward reasoning under CoT prompting, reinforcing the paper's claim that backward reasoning is substantially harder for LLMs and that method adaptations are required.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>No further method-level ablations for PaLM-2 in this work; limited conclusions about how PaLM-2 responds to rephrasing, PAL, Tools, or ensembling from this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3308.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3308.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMa-2-70B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMa 2 (70B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-weight large language model (LLaMa-2 70B) evaluated with few-shot CoT prompts as a baseline for forward vs. backward MWP performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Llama 2: Open foundation and finetuned chat models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMa-2-70B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source foundation model (70B parameters) from Meta (referenced paper). The authors ran LLaMa-2-70B quantized with GPTQ for forward/backward CoT comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>70B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Chain-of-Thought (CoT, few-shot)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>8-shot CoT prompts used for baseline forward/backward evaluations; the LLaMa-2-70B model was quantized and run locally for inference.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>Within this study LLaMa-2-70B is evaluated primarily with the single CoT prompting style for baseline comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>GSM8k_B, SVAMP_B, MultiArith_B (backward MWP variants) and forward counterparts</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Backward MWP variants as defined in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td>Table 1 (CoT baseline): GSM8k forward 37.0% -> backward 6.8%; SVAMP forward 70.3% -> backward 20.3%; MultiArith forward 89.2% -> backward 11.0%.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td>LLaMa-2-70B displays the same qualitative pattern: strong drop from forward to backward when using a single prompting style (CoT), motivating diverse strategies and ensembling.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Even large open-weight models like LLaMa-2-70B drop sharply on backward MWP tasks with CoT prompting, implying the difficulty is not limited to closed models or a single architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>No additional adapted-method experiments for LLaMa-2-70B in this paper; thus no evidence that LLaMa-2-70B benefits as much from PAL/Tools/CYW variants in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain-of-thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>PAL: Program-aided language models <em>(Rating: 2)</em></li>
                <li>Solving math word problems by combining language models with symbolic solvers <em>(Rating: 2)</em></li>
                <li>Self-refine: Iterative refinement with self-feedback <em>(Rating: 2)</em></li>
                <li>Large language models are better reasoners with self-verification <em>(Rating: 2)</em></li>
                <li>Training verifiers to solve math word problems <em>(Rating: 2)</em></li>
                <li>Progressive-hint prompting improves reasoning in large language models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3308",
    "paper_id": "paper-8db1dcae055842f43ccac04182957b20d15bbe6b",
    "extraction_schema_id": "extraction-schema-76",
    "extracted_data": [
        {
            "name_short": "GPT-4",
            "name_full": "GPT-4 (OpenAI)",
            "brief_description": "A state-of-the-art closed-source large conversational transformer model from OpenAI, evaluated in the paper for math word problems using few-shot Chain-of-Thought (CoT) prompts and compared on forward vs. backward reasoning.",
            "citation_title": "GPT-4 technical report",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "Closed-source large pretrained transformer (chat-capable) from OpenAI, used via API with few-shot prompting (Chain-of-Thought). The paper uses GPT-4 as a representative SOTA forward reasoner baseline and measures its drop on backward tasks.",
            "model_size": null,
            "reasoning_methods": [
                "Chain-of-Thought (CoT, few-shot)",
                "Rephrase (algebraic rephrasing for backward -&gt; forward)",
                "Verification (forward verifier via LLM)"
            ],
            "reasoning_methods_description": "CoT: 8-shot chain-of-thought prompts as in Wei et al. 2022. Rephrase: convert backward masked question into an explicit forward problem by injecting the final answer and introducing an 'x' variable and ask model to solve for x. Verification: substituting candidate blank into question and solving forward to check match with given final answer.",
            "diversity_of_methods": "Paper evaluates GPT-4 primarily with CoT in Table 1 (baseline) and applies rephrasing style in follow-up methods; diversity of methods in experiments is realized across models but GPT-4 itself is tested mostly with CoT prompting for the forward/backward comparison.",
            "reasoning_task_name": "Backward MWP variants (GSM8k_B, SVAMP_B, MultiArith_B); Forward MWP baselines (GSM8k, SVAMP, MultiArith)",
            "reasoning_task_description": "Math Word Problems (grade-school arithmetic) transformed into 'backward' tasks by blanking a single numeric token and providing the original forward answer; objective is to infer the blanked numeric value.",
            "performance_by_method": "Table 1 few-shot CoT baseline: GSM8k forward 92.8% -&gt; backward 38.6%; SVAMP forward 90.5% -&gt; backward 43.9%; MultiArith forward 97.8% -&gt; backward 54.8%. (These values reflect a large drop when moving from forward to backward reasoning using CoT prompting.)",
            "comparison_of_methods": "The paper shows GPT-4 using standard CoT suffers a substantial accuracy drop on backward tasks compared to forward; rephrasing and other strategies (evaluated more extensively with GPT-3.5) improve backward performance, suggesting CoT alone (a similar style) is insufficient and diverse prompting/solver+verifier strategies help.",
            "key_findings": "Even SOTA models such as GPT-4 show large accuracy degradation on backward MWPs when only using standard CoT prompting. Transforming backward tasks into explicit forward formulations (rephrase) and using verification/ensemble strategies provides pathways to recover performance (demonstrated more fully with GPT-3.5).",
            "counter_examples_or_negative_results": "No multi-method ablations were run extensively for GPT-4 in the paper; the baseline negative result is that standard CoT yields low backward accuracy (≈38.6% on GSM8k_B) compared to forward.",
            "uuid": "e3308.0",
            "source_info": {
                "paper_title": "Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "GPT-3.5",
            "name_full": "GPT-3.5-Turbo (OpenAI)",
            "brief_description": "A widely-used chat-style large language model used extensively in the paper to evaluate multiple reasoning strategies for backward math word problems, including rephrasing, PAL, Tools, CYW, Self-Refine, PAL-Tools, and a Bayesian ensemble with a forward verifier.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo",
            "model_description": "Closed-source chat-capable LLM from OpenAI used via API. In experiments, used with various few-shot prompting strategies (different shot counts per method) and as the verifier model in the ensemble. Temperature set to 0.5 in many experiments.",
            "model_size": null,
            "reasoning_methods": [
                "Chain-of-Thought (CoT, few-shot)",
                "Rephrase (algebraic and linguistic)",
                "PAL (Program-Aided Language Model)",
                "Tools (frame equations, call SymPy solver)",
                "PAL-Tools (PAL + Tools combination)",
                "Check Your Work (CYW) / Self-verification (iterative)",
                "Self-Refine (iterative refinement)",
                "Bayesian Ensemble with LLM forward verifier",
                "Majority voting baseline"
            ],
            "reasoning_methods_description": "CoT: standard 8-shot chain-of-thought prompting. Rephrase: transform backward Q/A pair into a forward problem by inserting the final answer and introducing x; two rephrase styles: algebraic (explicit x and equations) and linguistic. PAL: prompt to write Python/SymPy programs to solve for blank. Tools: ask model to frame equations in natural language and call external solver (SymPy). PAL-Tools: combine PAL program formulation with external solver calls. CYW: generate candidate blank, substitute into question, then verify by solving forward to match given final answer; loop until verified. Self-Refine: iterative self-feedback. Bayesian ensemble: sample answers from diverse models, use LLM verifier's forward-check output on holdout to estimate P(Z|correct) and P(Z|incorrect) and apply Bayes' rule to weight candidates; selects answer with highest posterior.",
            "diversity_of_methods": "Paper explicitly uses a diverse set of reasoning/prompting styles (symbolic/program-based (PAL), tool-assisted equation solving (Tools), natural-language rephrasing, iterative self-verification/refinement, and a Bayesian ensemble combining them). Diversity is introduced via different prompting paradigms and use of external solvers and a verifier.",
            "reasoning_task_name": "GSM8k_B, SVAMP_B, MultiArith_B (backward MWP variants); also phrase-masked backward reasoning (100-example subset).",
            "reasoning_task_description": "Backward MWP: single numeric token blanked from the question; model is given original forward answer and must infer the blank. Phrase-mask extension blanks a phrase (may allow multiple acceptable answers) and requires manual verification.",
            "performance_by_method": "Table 1 forward/backward baseline (CoT 8-shot): GSM8k forward 58.4% -&gt; backward 10.8%; SVAMP 79.1% -&gt; 20.4%; MultiArith 97.0% -&gt; 14.5%. Detailed GPT-3.5 results (Table 2, per-method on backward datasets): CoT: GSM8k_B 10.77%, SVAMP_B 20.40%, MultiArith_B 14.50%. PAL: 9.27%, 20.90%, 18.17%. Tools: 31.45%, 43.50%, 71.83%. PAL-Tools: 37.11%, 42.70%, 80.50%. Rephrased variants improved performance (CoT(R): 36.12%, 37.80%, 71.67%; Tools(R): 41.43%, 48.5%, 73.00%; PAL-Tools(R): 48.74%, 51.10%, 84.50%). CYW(R): 41.82%, 47.40%, 84.83%. Self-Refine(R): 40.17%, 49.70%, 77.50%. Ensembling (Table 3): Majority voting: 58.28% (GSM8k_B), 59.07% (SVAMP_B), 92.00% (MultiArith_B); Bayesian Ensemble (with verifier): 65.33%, 66.67%, 92.60% (GSM8k_B, SVAMP_B, MultiArith_B respectively). Phrase-masked 100-example subset (Table 8): Ensembling achieved 61.16% accuracy; best single rephrased methods ~37-38%.",
            "comparison_of_methods": "Explicit comparisons show (1) single-method CoT and PAL perform poorly on backward tasks; (2) Tools and PAL-Tools substantially outperform CoT and PAL; (3) Rephrasing (especially algebraic prompt using 'x') improves all methods, with larger gains for initially weaker methods; (4) CYW (verification-based iterative approach) outperforms Self-Refine on some datasets; (5) PAL-Tools (R) is the best single method in many cases; (6) combining diverse methods via Bayesian ensembling with a forward verifier outperforms majority voting and any single method (gains of ~7% over majority voting, and ~10-20% over best single-methods).",
            "key_findings": "Diverse reasoning styles (programmatic PAL, external solver Tools, rephrasing, and verifier-guided iterative methods) solve different subsets of backward MWPs, so combining them yields large gains. Rephrasing the backward task into an explicit forward problem (algebraic prompt) is broadly helpful. Using a forward verifier (LLM solving the forward substituted problem) and Bayesian ensembling yields the best performance and outperforms naive majority voting.",
            "counter_examples_or_negative_results": "PAL by itself performs poorly (low program quality for backward tasks). Self-Refine is not always better than the CYW verifier approach. Some phrase-masked generations can trivially 'cheat' by guessing the final answer as x, leading to technically correct but non-general solutions; ensemble selection can treat multiple semantically equivalent phrase variants as distinct (exact matching issues). Overall, backward reasoning remains substantially harder than forward reasoning across models.",
            "uuid": "e3308.1",
            "source_info": {
                "paper_title": "Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "PaLM-2",
            "name_full": "PaLM 2",
            "brief_description": "Google's PaLM-2 family of large language models, evaluated as a baseline in forward vs. backward MWP comparisons using few-shot prompting.",
            "citation_title": "Palm 2 technical report",
            "mention_or_use": "use",
            "model_name": "PaLM-2",
            "model_description": "Large pretrained transformer family from Google (PaLM-2 technical report cited). In this paper, PaLM-2 is used as a baseline model with CoT few-shot prompts to measure forward vs. backward performance.",
            "model_size": null,
            "reasoning_methods": [
                "Chain-of-Thought (CoT, few-shot)"
            ],
            "reasoning_methods_description": "8-shot chain-of-thought prompting used for forward/backward baseline comparisons (as with other SOTA models in Table 1). The paper does not extensively evaluate PaLM-2 across the other specialized backward strategies.",
            "diversity_of_methods": "Limited for PaLM-2 within this paper — primarily evaluated with standard CoT prompting for baseline forward/backward comparison.",
            "reasoning_task_name": "GSM8k_B, SVAMP_B, MultiArith_B (backward MWP variants) and forward counterparts",
            "reasoning_task_description": "Same backward MWP transformation as for other models.",
            "performance_by_method": "Table 1 (CoT baseline): GSM8k forward 60.5% -&gt; backward 15.2%; SVAMP forward 73.7% -&gt; backward 11.2%; MultiArith forward 95.7% -&gt; backward 6.3%.",
            "comparison_of_methods": "PaLM-2's CoT baseline shows a very large drop on backward tasks, consistent with trends observed for other models; the paper uses this to motivate specialized strategies but does not run PaLM-2 on the full set of adapted methods.",
            "key_findings": "PaLM-2 exhibits substantial degradation from forward to backward reasoning under CoT prompting, reinforcing the paper's claim that backward reasoning is substantially harder for LLMs and that method adaptations are required.",
            "counter_examples_or_negative_results": "No further method-level ablations for PaLM-2 in this work; limited conclusions about how PaLM-2 responds to rephrasing, PAL, Tools, or ensembling from this paper.",
            "uuid": "e3308.2",
            "source_info": {
                "paper_title": "Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "LLaMa-2-70B",
            "name_full": "LLaMa 2 (70B)",
            "brief_description": "An open-weight large language model (LLaMa-2 70B) evaluated with few-shot CoT prompts as a baseline for forward vs. backward MWP performance.",
            "citation_title": "Llama 2: Open foundation and finetuned chat models",
            "mention_or_use": "use",
            "model_name": "LLaMa-2-70B",
            "model_description": "Open-source foundation model (70B parameters) from Meta (referenced paper). The authors ran LLaMa-2-70B quantized with GPTQ for forward/backward CoT comparisons.",
            "model_size": "70B",
            "reasoning_methods": [
                "Chain-of-Thought (CoT, few-shot)"
            ],
            "reasoning_methods_description": "8-shot CoT prompts used for baseline forward/backward evaluations; the LLaMa-2-70B model was quantized and run locally for inference.",
            "diversity_of_methods": "Within this study LLaMa-2-70B is evaluated primarily with the single CoT prompting style for baseline comparisons.",
            "reasoning_task_name": "GSM8k_B, SVAMP_B, MultiArith_B (backward MWP variants) and forward counterparts",
            "reasoning_task_description": "Backward MWP variants as defined in the paper.",
            "performance_by_method": "Table 1 (CoT baseline): GSM8k forward 37.0% -&gt; backward 6.8%; SVAMP forward 70.3% -&gt; backward 20.3%; MultiArith forward 89.2% -&gt; backward 11.0%.",
            "comparison_of_methods": "LLaMa-2-70B displays the same qualitative pattern: strong drop from forward to backward when using a single prompting style (CoT), motivating diverse strategies and ensembling.",
            "key_findings": "Even large open-weight models like LLaMa-2-70B drop sharply on backward MWP tasks with CoT prompting, implying the difficulty is not limited to closed models or a single architecture.",
            "counter_examples_or_negative_results": "No additional adapted-method experiments for LLaMa-2-70B in this paper; thus no evidence that LLaMa-2-70B benefits as much from PAL/Tools/CYW variants in this work.",
            "uuid": "e3308.3",
            "source_info": {
                "paper_title": "Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems",
                "publication_date_yy_mm": "2023-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain-of-thought prompting elicits reasoning in large language models",
            "rating": 2
        },
        {
            "paper_title": "PAL: Program-aided language models",
            "rating": 2
        },
        {
            "paper_title": "Solving math word problems by combining language models with symbolic solvers",
            "rating": 2
        },
        {
            "paper_title": "Self-refine: Iterative refinement with self-feedback",
            "rating": 2
        },
        {
            "paper_title": "Large language models are better reasoners with self-verification",
            "rating": 2
        },
        {
            "paper_title": "Training verifiers to solve math word problems",
            "rating": 2
        },
        {
            "paper_title": "Progressive-hint prompting improves reasoning in large language models",
            "rating": 1
        }
    ],
    "cost": 0.015849,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems</h1>
<p>Aniruddha Deb ${ }^{1 <em>}$ Neeva Oza ${ }^{1 </em>}$ Sarthak Singla ${ }^{11}$ Dinesh Khandelwal ${ }^{2}$ Dinesh Garg ${ }^{2}$ Parag Singla ${ }^{1}$<br>${ }^{1}$ Indian Institute of Technology Delhi ${ }^{2}$ IBM Research AI</p>
<h4>Abstract</h4>
<p>While forward reasoning (i.e., find the answer given the question) has been explored extensively in recent literature, backward reasoning is relatively unexplored. We examine the backward reasoning capabilities of LLMs on Math Word Problems (MWPs): given a mathematical question and its answer, with some details omitted from the question, can LLMs effectively retrieve the missing information? On modifying three benchmark datasets for this task, to evaluate this task: GSM8k, SVAMP, and MultiArith, we find a significant drop in the accuracy of models on this task compared to forward reasoning across SOTA LLMs (GPT4, GPT3.5, PaLM-2, and LLaMa). Motivated by the fact backward reasoning can be seen as the "inverse" of forward reasoning, we propose variations of three different forward reasoning strategies to improve performance. Rephrase reformulates the given problem into a forward reasoning problem, PAL-Tools combines the idea of Program-Aided LLMs to produce a set of equations that can be solved by an external solver, and Check your Work exploits the availability of natural verifier of high accuracy in the forward direction, interleaving solving and verification steps. Finally, realizing that each of our base methods correctly solves a different set of problems, we propose a novel Bayesian formulation for creating an ensemble over the base methods to further boost the accuracy. Extensive experimentation demonstrates successive improvement in the performance of LLMs on the backward reasoning task, using our strategies, with our ensemble-based method resulting in significant performance gains compared to the SOTA forward reasoning strategies we adapt.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>1 Introduction</h2>
<p>Large language models (LLMs) (Brown et al., 2020; OpenAI, 2023; Anil et al., 2023) have shown remarkable versatility, excelling in various tasks like sentence completion, question answering, and summarization. They have been successfully applied to mathematical reasoning, specifically in solving Math Word Problems (MWPs) (Kushman et al., 2014; Roy and Roth, 2018), where the goal is to produce the answer given an elementary school-level mathematics question. We refer to this task as Forward Reasoning. This problem has received significant attention in the recent literature (Lu et al., 2022), and specific datasets (Cobbe et al., 2021; Roy and Roth, 2015; Patel et al., 2021) have been proposed as a benchmark for this task. The performance of powerful LLMs such as GPT-4 (OpenAI, 2023) with techniques such as Chain-of-Thought (Wei et al., 2022) and SelfVerification (Zhou et al., 2023) on some of these datasets is more than $90 \%$ (Lu et al., 2022).</p>
<p>We would like to solve a slightly different problem: given an MWP, with one of the numerical quantities omitted from the question, and the answer to the original question, what is the value of the omitted numerical quantity? Yu et al. (2024) refer to this as the problem of Backward Reasoning Problem, and we would like to examine how effective are LLMs on this task. While this problem of backward reasoning has been studied in the literature in the context of improving the performance of forward reasoning (Weng et al., 2022), to the best of our knowledge, there is no existing work that explicitly aims to solve this problem analyzing its hardness and providing solutions thereof. We believe this is an interesting problem because (1) It is a matter of study that even for humans, whether forward reasoning and backward reasoning have different complexities (Ramful and Olive, 2008; Rivera, 2008), and we would like to ask the same</p>
<p>question in the context of LLMs (2) Assuming we establish that backward reasoning is a harder problem, how can we design techniques to improve performance on this task, that specifically exploit the problem structure of backward reasoning and the availability of the forward direction answer? (3) The backward reasoning problem can be seen as a special case of abduction, with a unique answer, and it is interesting to explore this connection since LLMs have not been explored as much for this important class of abductive reasoning problems (Bhagavatula et al., 2020; Qin et al., 2020, 2022). (4) Enhancing the backward reasoning capabilities of large language models (LLMs) can be highly beneficial in domains such as automated theorem proving (Bibel, 2013; Yang et al., 2024), where solutions are already known and where backward reasoning is essential for automatically generating mathematical proofs.</p>
<p>As an initial analysis, we modify existing benchmark MWP datasets for backward reasoning, and experiment with existing forward reasoning strategies. Interestingly, we observe a significant drop in the LLM accuracy across multiple datasets when working with backward reasoning (refer Table 1). We hypothesize this may be due to the specific nature of the task, which makes it harder to solve, or the lack of sufficient data that LLMs have seen during their training compared to forward reasoning.</p>
<p>We take three different existing forward reasoning strategies and modify them appropriately to make them work effectively for backward reasoning, resulting in (a) Rephrase, based on (Weng et al., 2022) (b) PAL-Tools, based on (Gao et al., 2023) and (He-Yueya et al., 2023), and (c) Check your work, based on (Madaan et al., 2023). As our final technique, we propose a novel ensemble-based approach combining these base strategies using a Bayesian framework and making use of a forward verifier whose accuracy is estimated using a holdout set. Experiments on several benchmark datasets show that we get successive performance improvement using our strategies, with the Bayesian ensemble based approach performing the best, providing 20-30\% points gains compared to SOTA techniques for forward reasoning. We perform additional analysis on the models to explain our results.</p>
<p>Our contributions can be summarized as: (1) we explicitly handle the problem of backward reasoning and identify the performance gap using existing LLM strategies for this task (2) we propose
variations of three different existing forward reasoning strategies and a Bayesian ensemble based approach (3) we perform extensive experimentation to demonstrate the efficacy of our models for backward reasoning via LLMs. (4) We perform additional analysis, giving further insights into the performance of the proposed models. We publicly release our code and data ${ }^{1}$.</p>
<h2>2 Related Work</h2>
<p>A mathematical word problem (MWP) (Lu et al., 2022) consists of a description in natural language that expresses the relation between various entities and quantities, followed by a query for an unknown quantity, as shown in Figure 1. One can answer the question by representing the relationship between the entities and quantities through a set of equations and then solving these equations. Solving MWPs necessitates a semantic understanding of the natural language description. Initial works (Kushman et al., 2014; Koncel-Kedziorski et al., 2015; Roy and Roth, 2018) to solve MWPs involve parsing the natural language description and utilizing statistical learning techniques to identify suitable templates for generating answers. Subsequently, following the triumph of sequence-to-sequence (Seq2Seq) neural models (Sutskever et al., 2014) in machine translation and other NLP tasks, the encoder-decoder framework (Wang et al., 2017; Ling et al., 2017; Li et al., 2020; Shen et al., 2021; Jie et al., 2022) is employed to directly translate the natural language description in MWPs into equations.</p>
<p>MWPs: Recently, the strongest performance on MWPs has been given by large pre-trained language models like GPT-4 (OpenAI, 2023) and PaLM (Anil et al., 2023). These models leverage the power of few-shot in-context examples and employ prompting methods like CoT (Wei et al., 2022), all without requiring any modifications to their parameters.
Answer Verification: One class of techniques (Madaan et al., 2023; Welleck et al., 2023) using LLMs involves verifying the answer provided by the Language Model, either using the model itself or external verifiers such as compilers or proof checkers. If the answer is incorrect, the model is reprompted, optionally with suggestions on improving its output. Other techniques, such as Progres-</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: A summary of the prompting techniques we adapt</p>
<p>sive Hint Prompting <em>Zheng et al. (2023)</em> iteratively pass the model's previous answers to itself as hints. Iterative prompting techniques like <em>Wang et al. (2023)</em> do not use a verifier; instead, they sample multiple hypotheses from the model and select the answer using majority voting.</p>
<p><strong>Backward Reasoning:</strong> Our work can be seen as a special case of abductive reasoning with a unique answer. Abductive reasoning <em>Bhagavatula et al. (2020); Qin et al. (2020, 2022)</em> involves inferring the most plausible out of the several explanations. Prior work on abductive reasoning has focused mostly on text-based reasoning under constraints. In the context of arithmetic reasoning tasks, <em>Weng et al. (2022)</em> has utilized backward reasoning to enhance forward reasoning accuracy. In contrast, our work addresses backward reasoning as an independent problem. Our primary interest lies in analyzing the inherent complexities of backward reasoning and devising more effective solutions to tackle it.</p>
<h2>3 Task Definition</h2>
<p>A forward or the typical Mathematical Word Problem (MWP) consists of a question text $Q_f$, which we call a forward question, and its corresponding answer $A_f$. The forward question is a textual representation of the MWP. It is typically composed of one or more sentences and encompasses various elements, including numbers, operations, and textual information, all represented by tokens within the question. A backward MWP is defined as a tuple $Q, A_f$, where $Q$ is obtained from the forward question $Q_f$ by replacing one numerical quantity such as 5, 3.7, or 'half' with a blank. The goal of solving the backward MWP is to find out the unique value of the numerical quantity that was blanked out using backward reasoning. By backward reasoning, we mean the process of using the provided answer $A_f$ and the context provided by the question $Q$ to deduce the missing numerical quantity to arrive at the given answer. Since there is a unique answer for every question, we measure accuracy on this task by the number of questions on which the model is able to provide the correct numeric value of the blank.</p>
<h2>4 Base Strategies</h2>
<p>Table 1 compares the performance of four state-of-the-art (SOTA) language models on forward and backward reasoning tasks by using the 8-shot chain of thought <em>Wei et al. (2022)</em> prompts. The experiments were conducted using the chain of thought prompts defined in <em>Wei et al. (2022)</em>. The few-shot examples used in the chain of thought prompts were modified for the backward reasoning task following the procedure described above. A significant drop in backward reasoning accuracy compared to forward reasoning accuracy across all models proves the difficulty of this task for LLMs. Next, we adopt three base approaches for the backward reasoning task, as described below:</p>
<p>Table 1: Performance of various models on the MWP backward reasoning task, compared to their accuracies on the forward reasoning task of solving the original problem. Numbers marked ${}^{\dagger}$ are taken from <em>Zheng et al. (2023)</em></p>
<p>|  | GSM8k |  | SVAMP |  | MultiArith |  |
| Model | forward | backward | forward | backward | forward | backward |
| --- | --- | --- | --- | --- | --- | --- |
| GPT-4 | 92.8 | 38.6 | $90.5^{\dagger}$ | 43.9 | $97.8^{\dagger}$ | 54.8 |
| GPT-3.5-turbo | 58.4 | 10.8 | 79.1 | 20.4 | 97.0 | 14.5 |
| PaLM-2 | 60.5 | 15.2 | 73.7 | 11.2 | 95.7 | 6.3 |
| LLaMa-2-70B | 37.0 | 6.8 | 70.3 | 20.3 | 89.2 | 11.0 |</p>
<p>Rephrase: Our first modified SOTA method to tackle the challenging backward reasoning problem involves a problem transformation through rephrasing. This transformation effectively converts the complex backward reasoning task into a more manageable forward reasoning problem. Consequently, we employ the LLM to solve this transformed forward reasoning problem instead of the original and inherently more difficult backward reasoning challenge. Given a backward MWP $\left(Q, A_{f}\right)$, we ask the language model to produce a rephrased question $R$, which incorporates the forward answer $A_{f}$ into the question $Q$ and changes the objective of the question from finding the answer $A_{f}$ to finding the value of the blank. We then ask the language model to solve the rephrased problem $R$ instead of the original backward problem. The verification method used by <em>Weng et al. (2022)</em> works similarly to this, and they use this task only to improve the accuracy of the forward reasoner. In this prompting strategy, to rephrase the question, the LLM is given in-context examples where the blank is replaced by ' $x$ ', $A_{f}$ is used to change the interrogative part of the question to assertive and the value of ' $x$ ' is asked to be found. We define it as algebraic prompt and have used this for all experiments that include rephrasing the question before solving it. (see the first part of Analysis 7 for more details).</p>
<p>PAL-Tools: We modify the Program-aided language model (PAL) <em>Gao et al. (2023)</em> which writes a Python program to solve the MWP and integrate it with Tools <em>He-Yueya et al. (2023)</em> which uses the techniques of framing equations in natural language and calls SymPy to solve them. Neither of the two techniques, i.e., PAL or Tools, does well independently, as shown by our experiments.</p>
<p>Check your Work (CYW): Inspired from the iterative prompting technique SelfRefine <em>Madaan et al. (2023)</em>, that cycles between refinement and feedback until a stopping criteria is met, our approach has the following steps: (1) Generate the answer of $Q$ say $a$. (2) Form a forward problem obtained by substituting the blank with the obtained answer $a$. (3) Check the correctness of $a$ by checking whether the answer to the forward problem matches with the gold answer $A_{f}$. We repeat this if $a$ is found to be incorrect. Comparing Self-Refine (that we modified to solve the backward task) with Check your Work, Self-Refine uses the LLM’s assessment on the backward task as a stopping criteria, whereas in Check your Work, we use the easier problem of forward verification, for deciding when to stop (ref. Appendix C for prompts).</p>
<p>Table 2: Performance of base strategies. LLM is GPT-3.5-Turbo. R: Rephrase. CYW: Check Your Work</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Strategy</th>
<th style="text-align: center;">Shots</th>
<th style="text-align: center;">GSM8k $_{B}$</th>
<th style="text-align: center;">SVAMP $_{B}$</th>
<th style="text-align: center;">MultiArith $_{B}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">CoT</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">10.77</td>
<td style="text-align: center;">20.40</td>
<td style="text-align: center;">14.50</td>
</tr>
<tr>
<td style="text-align: left;">PAL</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">9.27</td>
<td style="text-align: center;">20.90</td>
<td style="text-align: center;">18.17</td>
</tr>
<tr>
<td style="text-align: left;">Tools</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">31.45</td>
<td style="text-align: center;">43.50</td>
<td style="text-align: center;">71.83</td>
</tr>
<tr>
<td style="text-align: left;">PAL-Tools</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">37.11</td>
<td style="text-align: center;">42.70</td>
<td style="text-align: center;">80.50</td>
</tr>
<tr>
<td style="text-align: left;">CoT (R)</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">36.12</td>
<td style="text-align: center;">37.80</td>
<td style="text-align: center;">71.67</td>
</tr>
<tr>
<td style="text-align: left;">PAL (R)</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">21.38</td>
<td style="text-align: center;">37.0</td>
<td style="text-align: center;">55.50</td>
</tr>
<tr>
<td style="text-align: left;">Tools (R)</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">41.43</td>
<td style="text-align: center;">48.5</td>
<td style="text-align: center;">73.00</td>
</tr>
<tr>
<td style="text-align: left;">Self-Refine (R)</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">40.17</td>
<td style="text-align: center;">49.70</td>
<td style="text-align: center;">77.50</td>
</tr>
<tr>
<td style="text-align: left;">CYW (R)</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">41.82</td>
<td style="text-align: center;">47.40</td>
<td style="text-align: center;">$\mathbf{8 4 . 8 3}$</td>
</tr>
<tr>
<td style="text-align: left;">PAL-Tools (R)</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">$\mathbf{4 8 . 7 4}$</td>
<td style="text-align: center;">$\mathbf{5 1 . 1 0}$</td>
<td style="text-align: center;">84.50</td>
</tr>
</tbody>
</table>
<h2>5 A Novel Approach of Ensembling</h2>
<p>We propose a way of ensembling these methods as illustrated by an example in Figure 2. Assume that we are given a set of models $\left{M_{1}, M_{2}, \cdots, M_{k}\right}$. Given a model $M_{i}$, we run the model $M_{i}$ on the question $Q r$ times, to get a multi-set of answers $\left{A_{i j}\right}_{j=1}^{r}$. For each unique answer $A$ in this multiset, we want to estimate the probability of it being correct. We do so by using an LLM as a verifier $V$ in the forward direction, i.e., by substituting the answer in the original question in place of the miss-</p>
<p>ing numerical quantity; and solving the forward problem. Given a question $Q$ and an answer $A, V$ gives a Boolean output $Z$, which is equal to 1 if $A$ is the correct answer to the question according to the verifier, and 0 otherwise. If $A^{*}$ is the gold answer to $Q$, we want the probability of $A$ being correct conditioned on the output of the verifier. From Bayes' rule,</p>
<p>$$
P\left(A=A^{*} \mid Z, Q\right)=\frac{X}{X+Y}
$$</p>
<p>where $X$ and $Y$ are defined as follows:</p>
<p>$$
\begin{aligned}
&amp; X=P\left(Z \mid A=A^{<em>}, Q\right) P\left(A=A^{</em>} \mid Q\right) \
&amp; Y=P\left(Z \mid A \neq A^{<em>}, Q\right) P\left(A \neq A^{</em>} \mid Q\right)
\end{aligned}
$$</p>
<p>We compute the prior $P\left(A=A^{<em>} \mid Q\right)$ as the fraction of times $A$ appears as the answers in the union of the multiset of answers produced by each model for the question $Q: P\left(A=A^{</em>} \mid Q\right)=\sum_{i, j} \mathbb{1}\left[A_{i j}=a\right] / k r$.</p>
<p>Now, let $P\left(Z \mid A=A^{<em>}, Q\right)$ denote the distribution over $V$ 's outputs when $A=A^{</em>}$. Similarly, let $P\left(Z \mid A \neq A^{<em>}, Q\right)$ denote the distribution over $V$ 's outputs when $A \neq A^{</em>}$. We estimate these distributions by computing the accuracy of the verifier on the holdout set $S^{\prime}$, and supplying a set of answers produced by the $k$ models, each run $r$ times on each $Q \in S^{\prime}$, along with the gold answer. Thus, we obtain values for Equation (1) and select the answer having the highest probability.</p>
<p>Note that we could also use the verifier's internal model to estimate $P\left(Z \mid A=A^{*}, Q\right)$, but this may not be well calibrated (Jiang et al., 2021; Zhao et al., 2021), i.e., the model's probability estimates may not accurately reflect the true likelihood of the answer being correct. Therefore, we instead use a holdout set to estimate these probabilities.</p>
<h2>6 Experiments</h2>
<h3>6.1 Setup</h3>
<p>We start with three forward reasoning datasets: GSM8k (Cobbe et al., 2021), MultiArith (Roy and Roth, 2015), and SVAMP (Patel et al., 2021), and transform the examples in these datasets into backward tasks, resulting in the creation of three modified datasets: GSM8k ${ }<em _mathrm_B="\mathrm{B">{\mathrm{B}}, \mathrm{SVAMP}</em>$ (ref. Appendix A for modification details). We have experimented with four SOTA LLMs: GPT-4, GPT-3.5-Turbo (OpenAI, 2023), PaLM-2 (Anil}}$, and MultiArith ${ }_{\mathrm{B}</p>
<p>Table 3: Ensembling results. LLM: GPT-3.5-Turbo</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">GSM8k</th>
<th style="text-align: center;">SVAMP $_{\mathrm{B}}^{\mathrm{f}}$</th>
<th style="text-align: center;">MultiArith $_{\mathrm{B}}^{\mathrm{f}}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">CoT (R)</td>
<td style="text-align: center;">35.67</td>
<td style="text-align: center;">37.78</td>
<td style="text-align: center;">69.60</td>
</tr>
<tr>
<td style="text-align: left;">Tools (R)</td>
<td style="text-align: center;">41.81</td>
<td style="text-align: center;">48.11</td>
<td style="text-align: center;">72.00</td>
</tr>
<tr>
<td style="text-align: left;">PAL-Tools (R)</td>
<td style="text-align: center;">48.55</td>
<td style="text-align: center;">45.00</td>
<td style="text-align: center;">81.50</td>
</tr>
<tr>
<td style="text-align: left;">Majority Voting</td>
<td style="text-align: center;">58.28</td>
<td style="text-align: center;">59.07</td>
<td style="text-align: center;">92.00</td>
</tr>
<tr>
<td style="text-align: left;">Ensemble</td>
<td style="text-align: center;">$\mathbf{6 5 . 3 3}$</td>
<td style="text-align: center;">$\mathbf{6 6 . 6 7}$</td>
<td style="text-align: center;">$\mathbf{9 2 . 6 0}$</td>
</tr>
</tbody>
</table>
<p>et al., 2023) and LLaMa-2 (Touvron et al., 2023). Further details are in Appendix B. Prompts and in-context examples for the prompting techniques are taken from their original works. The in-context examples are modified for the backward setting as discussed in Section 4. Examples of the prompts used are given in Appendix C.</p>
<h3>6.2 Results of Base Strategies</h3>
<p>Table 2 presents the results comparing standard forward reasoning strategies, with their variants that we introduced for backward reasoning ${ }^{2}$. Surprisingly, PAL does quite badly on this task, likely because the LLM is not able to construct good programs for the backward reasoning task. For rephrasing, we find that models perform better when the rephrased problem has the blank replaced with $x$ compared to the baseline prompt. This is because the relationship between the missing value and the equations that models need to frame in order to solve the forward problem is explicit. Also, for the baseline prompt, the model requires inferring the relationship between the forward answer and the equations they need to frame to obtain it, which may introduce ambiguity and reduce accuracy. We see that Rephrase also helps the other standard techniques in all cases, and we use that along with our remaining models.</p>
<p>CYW does better than Self-Refine on two of the datasets, gaining significantly on MultiArith ${ }_{\mathrm{B}}$. This points to the efficacy of using LLM as a forward verifier. The best-performing model is PAL+Tools, significantly improving accuracy over both PAL and Tools when run independently. We hypothesize the combination allows the model to retain the advantages of the programmatic way of formulation, while the backward reasoning is handled effectively by calling the external solver as in Tools.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<ol>
<li>Obtain samples from models</li>
</ol>
<p>Figure 2: An illustrative example of how the ensembling of base models works together with a verifier.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Overlap between problems in GSM8k<sup>B</sup> that different base techniques can solve</p>
<h3>6.3 Ensembling</h3>
<p>The models we included in the ensemble are rephrased versions of three of our strongest single-prompt models: CoT, Tools, and PAL-Tools. We use a temperature of 0.5 for sampling to generate 3 answers per question with each model. With 3 different models, we generate a total of 9 answers per question. The verifier is the LLM used in each of these base strategies. We select 100 examples from the datasets as holdout sets to compute an estimate of the verifier accuracy. We evaluate all the models on the non-holdout set, which is denoted with a † symbol in Table 3 to show the results. Clearly, we see that our ensembling technique results in significant gains (10-20%) on all the datasets, compared to the best-performing PAL-Tools which is the best-performing base model (ref. Table 2). We also compare our ensemble-based method with plain majority voting. Our approach results in close to 7% gain compared to vanilla majority voting pointing on two of the datasets to the efficacy of our Bayesian ensembling via a forward verifier. We observe that the accuracy on backward MWP via ensembling surpasses the forward accuracy of CoT by up to 6%. We also show that ensembling improves performance compared to majority voting, it shows the significance of using a verifier for selecting the correct answer compared to generating multiple answers via LLM.</p>
<p>On analyzing the base methods, as shown in figure 3, we find that there are a significant number of problems that are solved correctly by one of the models but not by others. This shows how ensembling exploits the strengths of individual models to provide significant boost in overall performance. Ensembling exploits the fact that the task of verifying is easier for LLMs than solving the backward MWP.</p>
<h2>7 Analysis</h2>
<p>How much does rephrasing help? Since rephrasing is a strategy that can be applied across multiple techniques, we analyze the extent of accuracy gains obtained via rephrasing by applying it independently to the base techniques: CoT, PAL, and Tools. The results are shown in Table 2. Rephrasing improves the accuracy of every technique that it is applied to. We see larger gains with rephrasing in weaker methods, such as CoT. We also see that rephrasing has higher</p>
<p>Table 4: Improvements in accuracy with rephrasing strategies. LP: Linguistic prompt rephrase. AP: Algebraic prompt rephrase</p>
<table>
<thead>
<tr>
<th>Strategy</th>
<th>Shots</th>
<th>GSM8kB</th>
<th>SVAMP B</th>
<th>MultiArith B</th>
</tr>
</thead>
<tbody>
<tr>
<td>CoT</td>
<td>8</td>
<td>10.77</td>
<td>20.40</td>
<td>14.50</td>
</tr>
<tr>
<td>CoT (LR)</td>
<td>8</td>
<td>19.65</td>
<td>32.60</td>
<td>40.50</td>
</tr>
<tr>
<td>CoT (AR)</td>
<td>8</td>
<td>36.12</td>
<td>37.80</td>
<td>71.67</td>
</tr>
</tbody>
</table>
<p>gains in datasets where the problems are harder, such as in GSM8k compared to SVAMP. We also tried to check whether the nature of the prompt affected the performance of rephrasing. We tried using a prompt where unlike the algebraic prompt, instead of introducing an ' $x$ ' and asking to find its value, we gave in-context examples that convert the problem to be worded similar to a forward reasoning task MWP. We call this a linguistic prompt In the experiment of table 4, we show how our specific prompts improve the performance of CoT. And we demonstrate the advantage of explicitly naming the value to be found as ' $x$ '.</p>
<p>Is verifying easier than solving? In the third step of the ensembling method, we try to verify whether the blank provided is correct by solving the resulting forward problem after substituting the blank. There are two settings in which we can verify this: 1) We ask the model to solve this new question and compare whether the answer obtained is the same as the original answer $a$. 2) We give the original answer $a$ to the model and ask it to check whether it is the answer obtained for the new question.</p>
<p>To find which method is better at correctly verifying the blank, we check the accuracy of GPT-3.5turbo on GSM8k in setting 2. In the first pass, we provide the correct blank and in the second pass, we provide an incorrect blank formed by multiplying $z \in{2 \ldots 10}$ with the correct blank. The confusion matrix obtained is shown in Table 5. It is observed that the accuracy of setting 2 is higher than the forward reasoning accuracy of GPT-3.5-turbo. Hence, we use that as the verification method for ensembling.</p>
<p>Does the verifier assist in ensembling? We compare the accuracies obtained by using majority voting with and without the verifier. We find that using a verifier improves the accuracy on GSM8k ${ }<em _mathrm_B="\mathrm{B">{\mathrm{B}}^{\mathrm{I}}$ and SVAMP ${ }</em>$ by $0.6 \%$. Since the verifier has a higher accuracy than any}}^{\mathrm{I}}$ by $7 \%$ and on MultiArith ${ }_{\mathrm{B}}^{\mathrm{I}</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">model</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">actual</td>
<td style="text-align: left;">positive</td>
<td style="text-align: left;">negative</td>
</tr>
<tr>
<td style="text-align: left;">positive</td>
<td style="text-align: left;">75.94</td>
<td style="text-align: left;">24.05</td>
</tr>
<tr>
<td style="text-align: left;">negative</td>
<td style="text-align: left;">7.39</td>
<td style="text-align: left;">92.61</td>
</tr>
</tbody>
</table>
<p>Table 5: Confusion matrix for verifying problems and their solutions on GSM8k ${ }_{B}$, normalized across rows
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Table 6: Relative performance increase rephrasing brings to PAL-tools when 4 shots are used compared to 2 .
of the models we consider, its inclusion inevitably increases the accuracy of any set of methods we choose. Even if we use a noisy verifier, updating our priors based on its results using Bayes' rule ensures that the priors are not changed significantly.</p>
<p>Do some prompts subsume others? Let prompts $M_{1}, M_{2}, M_{3}$ be able to solve problems $\mathcal{D}<em 2="2">{1}, \mathcal{D}</em>}, \mathcal{D<em i="i">{3}$ respectively, where $\mathcal{D}</em>} \subseteq D$. If we choose to ensemble these prompts together, then $\left|\bigcup_{j} \mathcal{D<em i="i">{j}\right|&gt;\left|\mathcal{D}</em>\right|$ for the ensemble to do better. Figure 3 gives an overview of the subsets of GSM8k that the three prompts, namely Rephrased Chain of Thought, Rephrased PAL-Tools, and Rephrased Tools can solve in a single try. We see that even though there is significant overlap between the prompts, the probability of any one of them giving the right answer is $66.9 \%$, provided we sample from each prompt once. The Venn diagram also shows the subsets of problems different prompts cover are quite disjoint in nature. No prompt can solve all the problems that another prompt can solve.</p>
<h2>Can every blank's answer be determined?</h2>
<p>There may be cases where the blank does not directly contribute to the answer or is irrelevant. In such a case, inferring the value of the blank is not possible given the answer. Even though (Cobbe et al., 2021) claim that less than two percent of</p>
<p>Table 7: Examples of questions in GSM8k ${ }_{B}$ that don't require the answer to find the value of the blank</p>
<p>Carla just gave birth to identical octuplets. She dresses $3 / 4$ of them in purple and $\qquad$ in blue. If all the blue wearers and $1 / 3$ of the purple wearers also wear bows, what is the percentage chance a baby wearing a bow is wearing purple?
Ian has a board that is 40 feet long. He decides to make a cut so he can have $\qquad$ pieces. The longer piece is 4 times longer than the shorter piece. How long is the longer piece?
problems have breaking errors, We sample 50 random examples from GSM8k ${ }_{B}$ that our strongest model solves incorrectly and find that no such problems in the sample we analyse, leading us to believe that the probability of such problems existing in our dataset is little to none.</p>
<p>Do all blanks need answers to be solved? In the 50 examples we analyse above, there are 10 examples where the value of the blank can be obtained simply from reading the question, as the question makes implicit assumptions or provides further information that can be used to fill in the blank. Two examples are presented in table 7. It is surprising that even our strongest model is unable to find the answer to such questions, either as a consequence of its poor reasoning abilities or because we make the dependency between requiring the answer to fill in the blank explicit.</p>
<h2>8 Going beyond masking of a single numeric quantity</h2>
<p>As a preliminary study, we aim to extend the task by forming tuples $\left(Q, A_{f}\right)$ by masking a phrase instead of a numeric quantity. A phrase is defined as the contiguous set of words between two connectives such as ['and', ‘,’ , ‘.’], and from the forward question $Q_{f}$, we replace the phrase containing the second occurrence of any numeric quantity with a blank. This choice is made to make the task similar to abductive reasoning (Bhagavatula et al., 2020; Qin et al., 2020, 2022) for story completion. We define this as a phrase-masked backward reasoning task. Note that in this setting, there can be multiple correct answers, which may differ from the originally masked phrase. To verify the correctness of the generated phrases, the task requires hand-evaluation of the results produced by various techniques.</p>
<p>Table 8: Performance on 100 examples for phrasemasked backward reasoning task. Note: The accuracy of CoT on the forward task of these 100 examples is $80 \%$. Ensembling uses 3 rephrased methods: CoT, Tools, and PAL-Tools *The number of shots for each strategy used in ensembling matches the number used when the strategy is applied individually.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Strategy</th>
<th style="text-align: center;">Shots</th>
<th style="text-align: left;">Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">CoT</td>
<td style="text-align: center;">8</td>
<td style="text-align: left;">22</td>
</tr>
<tr>
<td style="text-align: left;">Check Your Work</td>
<td style="text-align: center;">8</td>
<td style="text-align: left;">27</td>
</tr>
<tr>
<td style="text-align: left;">CoT Rephrase</td>
<td style="text-align: center;">8</td>
<td style="text-align: left;">37</td>
</tr>
<tr>
<td style="text-align: left;">Rephrased Tools</td>
<td style="text-align: center;">3</td>
<td style="text-align: left;">34</td>
</tr>
<tr>
<td style="text-align: left;">Rephrased PAL-Tools</td>
<td style="text-align: center;">4</td>
<td style="text-align: left;">38</td>
</tr>
<tr>
<td style="text-align: left;">Ensembling</td>
<td style="text-align: center;">$*$</td>
<td style="text-align: left;">$\mathbf{6 1 . 1 6}$</td>
</tr>
</tbody>
</table>
<p>As a baseline, we prompt the LLM to fill in the masked phrase given the rest of the question and the final answer to the original question using CoT. We observed experimentally that asking LLM to divide the task to first guessing the missing phrase with an ' $x$ ' in it and then solving it similar to a single numeric quantity masked backward reasoning task, performed better than finding the entire phrase altogether. We modified our methods to include a prior step to guess in this manner. For the hand-evaluation of the method, we replace the blank phrase in $Q$ with the predicted phrase and replace the value of ' $x$ ' in it with the value generated by the respective method. We then manually solve the resulting question and if its answer is the same as $A_{f}$, we mark that generation as correct. We performed the experiments on a 100 -sized subset of the GSM8k dataset. We used GPT-3.5-Turbo with the same experimental setup as before. As it can be seen in table 8 , our methods improve performance for this extension of the task.</p>
<p>Esembling: As the multiset of answers for ensembling consists of phrases instead of numbers, almost all answers have minor differences in wording, capitalization, etc. Thus, as we use exact phrase matching to count the frequency of an answer, even semantically identical answers get counted as different. Additionally, the probability of the verifier giving output 1 for a correct answer is independent of the question and answer. When these factors are applied in Equation 1, they result in a set $S_{m}$ where each answer marked as correct by the verifier, has an equal probability of being correct. This differs from number masking, where typically only a single answer has the highest probability of being correct. Therefore, we hand-evaluate all the answers</p>
<p>Table 9: Example of an LLM generation that frames the phrase as a guess of $A_{f}$</p>
<p>Phrase-masked question:
$Q$ : A football team played 22 games. $\qquad$ How many did they win?
$A_{f}: 15$
The phrase that was masked:
They won 8 more than they lost
LLM generation (by CoT rephrase method):
Guess: They won x games
Rephrased: A football team played 22 games. They won x games. They won 15 games. Find the value of x. Answer: The football team played 22 games. If they won x games, then they won x out of 22 games. So the answer is $\mathrm{x}=15$.</p>
<p>Phrase that was finally extracted from LLM:
They won 15 games</p>
<p>Table 10: Number of questions in the 100-sized subset that are like the example in table 9.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Strategy</th>
<th style="text-align: center;">Number of questions</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">CoT</td>
<td style="text-align: center;">14.00</td>
</tr>
<tr>
<td style="text-align: left;">Check Your Work</td>
<td style="text-align: center;">9.00</td>
</tr>
<tr>
<td style="text-align: left;">CoT Rephrase</td>
<td style="text-align: center;">6.00</td>
</tr>
<tr>
<td style="text-align: left;">Rephrased Tools</td>
<td style="text-align: center;">2.00</td>
</tr>
<tr>
<td style="text-align: left;">Rephrased PAL-Tools</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: left;">Ensembling</td>
<td style="text-align: center;">5.28</td>
</tr>
</tbody>
</table>
<p>in $S_{m}$, and use the fraction of correct answers in $S_{m}$ as the probability that an answer sampled from $S_{m}$ is correct.</p>
<p>Caveat: On analyzing, we found that for a few generations, the predicted phrase trivially requires the LLM to directly guess the quantity $A_{f}$ as ' $x$ ' and then it solves for ' $x$ ' (for now, we have marked it correct in our evaluation); thus making it technically correct without actually solving the backward reasoning task. An example of such generation is depicted in table 9. Tricky MWPs include questions with extra information, which creates a spectrum depending on how many lines of questions are needed to find the answer. The phrases generated by the LLM achieve their goal but may simplify MWPs to be solved with just one line of information. Table 10 shows the counts of such correctly generated phrases. For Ensembling, in case of multiple correct answers, we report the fraction of answers that are trivially correct as described above. We will try other methods in the future to improve on this aspect.</p>
<h2>9 Conclusion and Future Work</h2>
<p>We consider the problem of backward reasoning in MWPs. We show that existing forward reasoning strategies do not work well off-the-shelf for the forward problem, and propose 3 different variations of existing techniques for the backward task. We also propose a novel Bayesian ensemble based approach to further improve the accuracy. Experiments demonstrate the efficacy of our approach compared to forward reasoning strategies. Finally, we analyze the fallacies and pitfalls of each of these techniques and show areas for future improvements. Our method of Bayesian ensembling can also be extended to other tasks of backward reasoning. If there is a setting where the verification or the forward reasoning task is easier compared to the backward, and there is an existing set of methods to solve the backward task in different ways; our method can potentially be used in such settings. Our future work includes extending our technique to other backward reasoning datasets, including those derived from explicit abductive reasoning tasks.</p>
<h2>10 Limitations</h2>
<p>Limitations of our approach include (a) It has only been tested on the MWPs. (b) It requires a (small) hold-out set to estimate the accuracy of the verifier in the ensemble.</p>
<h2>Acknowledgements</h2>
<p>This work was supported by an IBM AI Horizons Network (AIHN) grant and IBM SUR Awards. We thank IIT Delhi HPC facility ${ }^{3}$, IBM cloud facility, and IBM Cognitive Computing Cluster (CCC) for computational resources. We thank anonymous reviewers for their insightful comments that helped in further improving our paper. Any opinions, findings, conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views or official policies, either expressed or implied, of the funding agencies.</p>
<h2>References</h2>
<p>Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Shafey, Yanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan Botha, James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng, Colin Cherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, Clément Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark Díaz, Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, Guy GurAri, Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey Hui, Jeremy Hurwitz, Michael Isard, Abe Iltycheriah, Matthew Jagielski, Wenhao Jia, Kathleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric Ni, Andrew Nystrom, Alicia Parrish, Marie Pellat, Martin Polacek, Alex Polozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel, Renee Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng, Ce Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu. 2023. Palm 2 technical report. arXiv preprint arXiv:2305.10403.</p>
<p>Chandra Bhagavatula, Ronan Le Bras, Chaitanya Malaviya, Keisuke Sakaguchi, Ari Holtzman, Hannah Rashkin, Doug Downey, Wen tau Yih, and Yejin Choi. 2020. Abductive commonsense reasoning. In $I C L R$.</p>
<p>Wolfgang Bibel. 2013. Automated theorem proving. Springer Science \&amp; Business Media.</p>
<p>Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, T. J. Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. arXiv preprint arXiv:2005.14165.</p>
<p>Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168.</p>
<p>Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh. 2022. Optq: Accurate quantization for generative pre-trained transformers. In $I C L R$.</p>
<p>Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023. Pal: Program-aided language models. In ICML.</p>
<p>Joy He-Yueya, Gabriel Poesia, Rose E. Wang, and Noah D. Goodman. 2023. Solving math word problems by combining language models with symbolic solvers. arXiv preprint arXiv:2304.09102.</p>
<p>Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig. 2021. How can we know when language models know? on the calibration of language models for question answering. Transactions of the Association for Computational Linguistics, 9:962-977.</p>
<p>Zhanming Jie, Jierui Li, and Wei Lu. 2022. Learning to reason deductively: Math word problem solving as complex relation extraction. In $A C L$.</p>
<p>Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, and Siena Dumas Ang. 2015. Parsing algebraic word problems into equations. Transactions of the Association for Computational Linguistics, 3:585-597.</p>
<p>Nate Kushman, Yoav Artzi, Luke Zettlemoyer, and Regina Barzilay. 2014. Learning to automatically solve algebra word problems. In $A C L$, pages 271281 .</p>
<p>Shucheng Li, Lingfei Wu, Shiwei Feng, Fangli Xu, Fengyuan Xu, and Sheng Zhong. 2020. Graph-totree neural networks for learning structured inputoutput translation with applications to semantic parsing and math word problem. In Findings EMNLP, pages 2841-2852.</p>
<p>Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017. Program induction by rationale generation: Learning to solve and explain algebraic word problems. In $A C L$, pages 158-167.</p>
<p>Pan Lu, Liang Qiu, Wenhao Yu, Sean Welleck, and Kai-Wei Chang. 2022. A survey of deep learning for mathematical reasoning. arXiv preprint arXiv:2212.10535.</p>
<p>Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. 2023. Self-refine: Iterative refinement with self-feedback. arXiv preprint arXiv:2303.17651.</p>
<p>OpenAI. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774.</p>
<p>Arkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021. Are NLP models really able to solve simple math word problems? In NAACL.</p>
<p>Lianhui Qin, Vered Shwartz, Peter West, Chandra Bhagavatula, Jena D. Hwang, Ronan Le Bras, Antoine Bosselut, and Yejin Choi. 2020. Back to the future: Unsupervised backprop-based decoding for counterfactual and abductive commonsense reasoning. In EMNLP.</p>
<p>Lianhui Qin, Sean Welleck, Daniel Khashabi, and Yejin Choi. 2022. COLD decoding: Energy-based constrained text generation with langevin dynamics. In NeurIPS.</p>
<p>Ajay Ramful and John Olive. 2008. Reversibility of thought: An instance in multiplicative tasks. The Journal of Mathematical Behavior, 27(2):138-151.</p>
<p>FD Rivera. 2008. On the pitfalls of abduction: Compolicities and complexities in patterning activity. For the learning of mathematics, 28(1):17-25.</p>
<p>Subhro Roy and Dan Roth. 2015. Solving general arithmetic word problems. In EMNLP.</p>
<p>Subhro Roy and Dan Roth. 2018. Mapping to declarative knowledge for word problem solving. Transactions of the Association for Computational Linguistics, 6:159-172.</p>
<p>Jianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin Jiang, Ming Zhang, and Qun Liu. 2021. Generate \&amp; rank: A multi-task framework for math word problems. In Findings of EMNLP, pages 2269-2279.</p>
<p>Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural networks. In NeurIPS.</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. Llama 2: Open foundation and finetuned chat models. arXiv preprint arXiv:2307.09288.</p>
<p>Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2023. Self-consistency improves chain of thought reasoning in language models. In $I C L R$.</p>
<p>Yan Wang, Xiaojiang Liu, and Shuming Shi. 2017. Deep neural solver for math word problems. In EMNLP, pages 845-854.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le, and Denny Zhou. 2022. Chain-of-thought prompting elicits reasoning in large language models. In NeurIPS.</p>
<p>Sean Welleck, Ximing Lu, Peter West, Faeze Brahman, Tianxiao Shen, Daniel Khashabi, and Yejin Choi. 2023. Generating sequences by learning to self-correct. In $I C L R$.</p>
<p>Yixuan Weng, Minjun Zhu, Fei Xia, Bin Li, Shizhu He, Kang Liu, and Jun Zhao. 2022. Large language models are better reasoners with self-verification. arXiv preprint arXiv:2212.09561.</p>
<p>Kaiyu Yang, Aidan Swope, Alex Gu, Rahul Chalamala, Peiyang Song, Shixing Yu, Saad Godil, Ryan J Prenger, and Animashree Anandkumar. 2024. Leandojo: Theorem proving with retrieval-augmented language models. In NeurIPS.</p>
<p>Longhui Yu, Weisen Jiang, Han Shi, YU Jincheng, Zhengying Liu, Yu Zhang, James Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2024. Metamath: Bootstrap your own mathematical questions for large language models. In $I C L R$.</p>
<p>Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improving few-shot performance of language models. In ICML, pages 12697-12706.</p>
<p>Chuanyang Zheng, Zhengying Liu, Enze Xie, Zhenguo Li, and Yu Li. 2023. Progressive-hint prompting improves reasoning in large language models. arXiv preprint arXiv:2304.09797.</p>
<p>Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song, Mingjie Zhan, and Hongsheng Li. 2023. Solving challenging math word problems using gpt-4 code interpreter with code-based self-verification. arXiv preprint arXiv:2308.07921.</p>
<p>Appendix A: Dataset</p>
<p>We consider three datasets of interest: GSM8K (Cobbe et al., 2021), MultiArith (Roy and Roth, 2015), and SVAMP (Patel et al., 2021). All these datasets consist of grade-school arithmetic word problems along with their answers.</p>
<h1>A. 1 Generation Methodology</h1>
<p>Given a source forward dataset</p>
<p>$$
D=\left{\left(Q_{i}, A_{i}\right)<em i="i">{i=1}^{n} \mid Q</em>\right}
$$} \in \Sigma^{*}, A_{i} \in \mathbb{R</p>
<p>we present a method to create a backward dataset</p>
<p>$$
D_{k}^{\prime}=\left{\left(Q_{i}^{\prime}, A_{i},\left(B_{i}^{0}, \ldots, B_{i}^{k}\right)\right)<em i="i">{i=1}^{n} \mid Q</em>\right}
$$}^{\prime} \in \Sigma^{*}, A_{i}, B_{i}^{j} \in \mathbb{R</p>
<p>To convert $Q_{i}$ (Source question) to $Q_{i}^{\prime}$ (blanked out question) and extract blanks $B_{i}^{0} \ldots B_{i}^{k}$, we split $Q_{i}$ into its constituent tokens based on a delimiter, usually space. We then consider all numeric tokens, which are defined as tokens that encode a number. Numeric tokens may be alphanumeric, such as $\$ 42,80 \%$ or 3.14 , or they may be alphabetic, such as three, twice, or half. Using this heuristic for numeric tokens, we ignore the first numeric token and extract the next $k$ tokens sequentially. If we are unable to extract $k$ tokens, then we skip that question and answer pair. It is worth noting that for the datasets we use, $k=1$, that is we only consider the problem of backwardly inferring one missing number in the question, given the answer. Solving the $n&gt;1$ case would require first checking if a unique solution exists and is a topic for future work.</p>
<p>The reason we choose to blank out only numeric tokens rather than an entire phrase or sentence is to make the task of validation easier. An alternative that was explored was phrase masking. However, phrase masking would lead to generations that would not be verifiable with perfect accuracy, and multiple possible generations for each question. The benefit of number masking is that quantities can be compared to each other without loss of accuracy, and every question-answer pair has a unique blank.</p>
<h2>A. 2 Generation Results</h2>
<p>Using the above method, we were able to convert 1272 of the 1319 question and answer pairs in GSM8k to backward reasoning problems, and all 1000 and 600 pairs in SVAMP and MultiArith respectively. All of these are obtained from the respective test splits of the original datasets.</p>
<h2>A. 3 Dataset Examples</h2>
<p>Some examples of the datasets under consideration are shown in Table 11. Note that for GSM8k, the original dataset contains 1319 sample problems but our dataset generation method for the backward task filters out 47 of them. For comparability with the backward task, we have used the 1272 common examples of this dataset.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;">N</th>
<th style="text-align: center;">Example</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">GSM8k</td>
<td style="text-align: center;">$1272^{*}$</td>
<td style="text-align: center;">Kylar went to the store to buy glasses for his new apartment. One glass costs \$5, but every second glass costs only $60 \%$ of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them?</td>
</tr>
<tr>
<td style="text-align: center;">GSM8k $_{B}$</td>
<td style="text-align: center;">1272</td>
<td style="text-align: center;">Q : Kylar went to the store to buy glasses for his new apartment. One glass costs \$5, but every second glass costs only $\qquad$ $\%$ of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them? <br> A : 64</td>
</tr>
<tr>
<td style="text-align: center;">SVAMP</td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">28 children were riding on the bus. At the bus stop 82 children got on the bus while some got off the bus. Then there were 30 children altogether on the bus. How many more children got on the bus than those that got off?</td>
</tr>
<tr>
<td style="text-align: center;">SVAMP $_{B}$</td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">Q : 28 children were riding on the bus. At the bus stop, $\qquad$ children got on the bus while some got off the bus. Then there were 30 children altogether on the bus. How many more children got on the bus than those that got off?" <br> A : 2</td>
</tr>
<tr>
<td style="text-align: center;">MultiArith</td>
<td style="text-align: center;">600</td>
<td style="text-align: center;">Lana picked 36 tulips and 37 roses to make flower bouquets. If she only used 70 of the flowers though, how many extra flowers did Lana pick?</td>
</tr>
<tr>
<td style="text-align: center;">MultiArith $_{B}$</td>
<td style="text-align: center;">600</td>
<td style="text-align: center;">Q : Lana picked 36 tulips and $\qquad$ roses to make flower bouquets. If she only used 70 of the flowers though, how many extra flowers did Lana pick? <br> A : 3</td>
</tr>
</tbody>
</table>
<p>Table 11: Sample questions from the datasets we consider</p>
<h1>Appendix B: Experiment Reproducibility Details</h1>
<p>For all experiments involving closed-source LLMs, (i.e. GPT-4, GPT-3.5-turbo, and PaLM-2), we utilized the respective model APIs (OpenAI, Google Bard). For experiments using LLaMa-2, we use the 70-billion-parameter model quantized to 4-bit using GPTQ (Frantar et al., 2022). Inference was performed on two 40GB NVIDIA A100 GPUs, on a High Performance Computing cluster node with 8 cores and 16 GB of RAM allocated to the job. For all models, the temperature was set to 0.5 and the maximum number of tokens to generate was limited to 1024. In all the tables showing results, the accuracy values are obtained by taking the mean across all examples of the dataset, in a single run of the mentioned method.</p>
<h2>Appendix C: Prompts</h2>
<p>We construct prompts by changing the original examples of the papers we consider to solve the backward task. We show one to two in-context examples of each prompt. The remaining examples may be seen in our code.</p>
<div class="codehilite"><pre><span></span><code><span class="nv">Rephrase</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">given</span><span class="w"> </span><span class="nv">blanked</span><span class="w"> </span><span class="nv">question</span><span class="w"> </span><span class="nv">and</span><span class="w"> </span><span class="nv">answer</span><span class="w"> </span><span class="nv">pairs</span><span class="w"> </span><span class="nv">and</span><span class="w"> </span><span class="k">then</span><span class="w"> </span><span class="nv">find</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">solution</span><span class="w"> </span><span class="nv">to</span>
<span class="nv">the</span><span class="w"> </span><span class="nv">rephrased</span><span class="w"> </span><span class="nv">question</span>.<span class="w"> </span><span class="nv">Give</span><span class="w"> </span><span class="nv">your</span><span class="w"> </span><span class="nv">answer</span><span class="w"> </span><span class="nv">as</span><span class="w"> </span><span class="nv">either</span><span class="w"> </span><span class="nv">a</span><span class="w"> </span><span class="nv">number</span><span class="w"> </span><span class="nv">or</span><span class="w"> </span><span class="nv">a</span><span class="w"> </span><span class="nv">decimal</span><span class="w"> </span><span class="ss">(</span><span class="nv">no</span>
<span class="nv">fractions</span><span class="ss">)</span>.<span class="w"> </span><span class="nv">Follow</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">format</span><span class="w"> </span><span class="nv">specified</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">examples</span><span class="w"> </span><span class="nv">below</span>:
<span class="nv">Q</span>:<span class="w"> </span><span class="nv">There</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="mi">15</span><span class="w"> </span><span class="nv">trees</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">grove</span>.<span class="w"> </span><span class="nv">Grove</span><span class="w"> </span><span class="nv">workers</span><span class="w"> </span><span class="nv">will</span><span class="w"> </span><span class="nv">plant</span>
<span class="w">    </span><span class="nv">trees</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span>
<span class="nv">grove</span><span class="w"> </span><span class="nv">today</span>.<span class="w"> </span><span class="nv">After</span><span class="w"> </span><span class="nv">they</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="nv">done</span>,<span class="w"> </span><span class="nv">how</span><span class="w"> </span><span class="nv">many</span><span class="w"> </span><span class="nv">trees</span><span class="w"> </span><span class="nv">would</span><span class="w"> </span><span class="nv">be</span><span class="w"> </span><span class="nv">there</span>?
<span class="nv">A</span>:<span class="w"> </span><span class="mi">21</span>
<span class="nv">Rephrased</span>:<span class="w"> </span><span class="nv">There</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="mi">15</span><span class="w"> </span><span class="nv">trees</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">grove</span>.<span class="w"> </span><span class="nv">Grove</span><span class="w"> </span><span class="nv">workers</span><span class="w"> </span><span class="nv">will</span><span class="w"> </span><span class="nv">plant</span><span class="w"> </span><span class="nv">some</span><span class="w"> </span><span class="nv">trees</span><span class="w"> </span><span class="nv">in</span>
<span class="nv">the</span><span class="w"> </span><span class="nv">grove</span><span class="w"> </span><span class="nv">today</span>.<span class="w"> </span><span class="nv">After</span><span class="w"> </span><span class="nv">they</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="nv">done</span>,<span class="w"> </span><span class="nv">there</span><span class="w"> </span><span class="nv">would</span><span class="w"> </span><span class="nv">be</span><span class="w"> </span><span class="mi">21</span><span class="w"> </span><span class="nv">trees</span>.<span class="w"> </span><span class="nv">Find</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">number</span><span class="w"> </span><span class="nv">of</span>
<span class="nv">trees</span><span class="w"> </span><span class="nv">planted</span>.
<span class="nv">Answer</span>:<span class="w"> </span><span class="nv">There</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="mi">15</span><span class="w"> </span><span class="nv">trees</span><span class="w"> </span><span class="nv">originally</span>,<span class="w"> </span><span class="k">Then</span><span class="w"> </span><span class="nv">there</span><span class="w"> </span><span class="nv">were</span><span class="w"> </span><span class="mi">21</span><span class="w"> </span><span class="nv">trees</span><span class="w"> </span><span class="nv">after</span><span class="w"> </span><span class="nv">some</span><span class="w"> </span><span class="nv">more</span>
<span class="nv">were</span><span class="w"> </span><span class="nv">planted</span>.<span class="w"> </span><span class="nv">So</span><span class="w"> </span><span class="nv">there</span><span class="w"> </span><span class="nv">must</span><span class="w"> </span><span class="nv">have</span><span class="w"> </span><span class="nv">been</span><span class="w"> </span><span class="mi">21</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">15</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">6</span><span class="w"> </span><span class="nv">trees</span>.<span class="w"> </span><span class="nv">The</span><span class="w"> </span><span class="nv">answer</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="mi">6</span>.
<span class="nv">Q</span>:<span class="w"> </span><span class="k">If</span><span class="w"> </span><span class="nv">there</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">parking</span><span class="w"> </span><span class="nv">lot</span><span class="w"> </span><span class="nv">and</span>
<span class="w">    </span><span class="nv">more</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">arrive</span>,<span class="w"> </span><span class="nv">how</span><span class="w"> </span><span class="nv">many</span><span class="w"> </span><span class="nv">cars</span>
<span class="nv">are</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">parking</span><span class="w"> </span><span class="nv">lot</span>?
<span class="nv">A</span>:<span class="w"> </span><span class="mi">5</span>
<span class="nv">Rephrased</span>:<span class="w"> </span><span class="k">If</span><span class="w"> </span><span class="nv">there</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">parking</span><span class="w"> </span><span class="nv">lot</span><span class="w"> </span><span class="nv">and</span><span class="w"> </span><span class="nv">some</span><span class="w"> </span><span class="nv">more</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">arrive</span>,<span class="w"> </span><span class="nv">there</span>
<span class="nv">are</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">parking</span><span class="w"> </span><span class="nv">lot</span>.<span class="w"> </span><span class="nv">Find</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">number</span><span class="w"> </span><span class="nv">of</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">that</span><span class="w"> </span><span class="nv">arrived</span>.
<span class="nv">Answer</span>:<span class="w"> </span><span class="nv">There</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="nv">originally</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="nv">cars</span>.<span class="w"> </span><span class="nv">There</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">after</span><span class="w"> </span><span class="nv">some</span><span class="w"> </span><span class="nv">more</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">arrive</span>.
<span class="mi">5</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span>,<span class="w"> </span><span class="nv">so</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">arrived</span>.<span class="w"> </span><span class="nv">The</span><span class="w"> </span><span class="nv">answer</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="mi">2</span>.
</code></pre></div>

<p>Figure 4: Rephrasing with Linguistic prompt</p>
<div class="codehilite"><pre><span></span><code><span class="nv">Rephrase</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">given</span><span class="w"> </span><span class="nv">blanked</span><span class="w"> </span><span class="nv">question</span><span class="w"> </span><span class="nv">and</span><span class="w"> </span><span class="nv">answer</span><span class="w"> </span><span class="nv">pairs</span><span class="w"> </span><span class="nv">and</span><span class="w"> </span><span class="k">then</span><span class="w"> </span><span class="nv">find</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">solution</span><span class="w"> </span><span class="nv">to</span>
<span class="nv">the</span><span class="w"> </span><span class="nv">rephrased</span><span class="w"> </span><span class="nv">question</span>.<span class="w"> </span><span class="nv">Give</span><span class="w"> </span><span class="nv">your</span><span class="w"> </span><span class="nv">answer</span><span class="w"> </span><span class="nv">as</span><span class="w"> </span><span class="nv">either</span><span class="w"> </span><span class="nv">a</span><span class="w"> </span><span class="nv">number</span><span class="w"> </span><span class="nv">or</span><span class="w"> </span><span class="nv">a</span><span class="w"> </span><span class="nv">decimal</span><span class="w"> </span><span class="ss">(</span><span class="nv">no</span>
<span class="nv">fractions</span><span class="ss">)</span>.<span class="w"> </span><span class="nv">Follow</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">format</span><span class="w"> </span><span class="nv">specified</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">examples</span><span class="w"> </span><span class="nv">below</span>:
<span class="nv">Q</span>:<span class="w"> </span><span class="nv">There</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="mi">15</span><span class="w"> </span><span class="nv">trees</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">grove</span>.<span class="w"> </span><span class="nv">Grove</span><span class="w"> </span><span class="nv">workers</span><span class="w"> </span><span class="nv">will</span><span class="w"> </span><span class="nv">plant</span>
<span class="w">    </span><span class="nv">trees</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span>
<span class="nv">grove</span><span class="w"> </span><span class="nv">today</span>.<span class="w"> </span><span class="nv">After</span><span class="w"> </span><span class="nv">they</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="nv">done</span>,<span class="w"> </span><span class="nv">how</span><span class="w"> </span><span class="nv">many</span><span class="w"> </span><span class="nv">trees</span><span class="w"> </span><span class="nv">would</span><span class="w"> </span><span class="nv">be</span><span class="w"> </span><span class="nv">there</span>?
<span class="nv">A</span>:<span class="w"> </span><span class="mi">21</span>
<span class="nv">Rephrased</span>:<span class="w"> </span><span class="nv">There</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="mi">15</span><span class="w"> </span><span class="nv">trees</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">grove</span>.<span class="w"> </span><span class="nv">Grove</span><span class="w"> </span><span class="nv">workers</span><span class="w"> </span><span class="nv">will</span><span class="w"> </span><span class="nv">plant</span><span class="w"> </span><span class="nv">x</span><span class="w"> </span><span class="nv">trees</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span>
<span class="nv">grove</span><span class="w"> </span><span class="nv">today</span>.<span class="w"> </span><span class="nv">After</span><span class="w"> </span><span class="nv">they</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="nv">done</span>,<span class="w"> </span><span class="nv">there</span><span class="w"> </span><span class="nv">would</span><span class="w"> </span><span class="nv">be</span><span class="w"> </span><span class="mi">21</span><span class="w"> </span><span class="nv">trees</span>.<span class="w"> </span><span class="nv">Find</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">value</span><span class="w"> </span><span class="nv">of</span><span class="w"> </span><span class="nv">x</span>.
<span class="nv">Answer</span>:<span class="w"> </span><span class="nv">There</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="mi">15</span><span class="w"> </span><span class="nv">trees</span><span class="w"> </span><span class="nv">originally</span>,<span class="w"> </span><span class="k">Then</span><span class="w"> </span><span class="nv">there</span><span class="w"> </span><span class="nv">were</span><span class="w"> </span><span class="mi">21</span><span class="w"> </span><span class="nv">trees</span><span class="w"> </span><span class="nv">after</span><span class="w"> </span><span class="nv">some</span><span class="w"> </span><span class="nv">more</span>
<span class="nv">were</span><span class="w"> </span><span class="nv">planted</span>.<span class="w"> </span><span class="nv">So</span><span class="w"> </span><span class="nv">there</span><span class="w"> </span><span class="nv">must</span><span class="w"> </span><span class="nv">have</span><span class="w"> </span><span class="nv">been</span><span class="w"> </span><span class="nv">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">21</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">15</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">6</span><span class="w"> </span><span class="nv">trees</span>.<span class="w"> </span><span class="nv">The</span><span class="w"> </span><span class="nv">answer</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="mi">6</span>.
<span class="nv">Q</span>:<span class="w"> </span><span class="k">If</span><span class="w"> </span><span class="nv">there</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">parking</span><span class="w"> </span><span class="nv">lot</span><span class="w"> </span><span class="nv">and</span>
<span class="w">    </span><span class="nv">more</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">arrive</span>,<span class="w"> </span><span class="nv">how</span><span class="w"> </span><span class="nv">many</span><span class="w"> </span><span class="nv">cars</span>
<span class="nv">are</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">parking</span><span class="w"> </span><span class="nv">lot</span>?
<span class="nv">A</span>:<span class="w"> </span><span class="mi">5</span>
<span class="nv">Rephrased</span>:<span class="w"> </span><span class="k">If</span><span class="w"> </span><span class="nv">there</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">parking</span><span class="w"> </span><span class="nv">lot</span><span class="w"> </span><span class="nv">and</span><span class="w"> </span><span class="nv">x</span><span class="w"> </span><span class="nv">more</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">arrive</span>,<span class="w"> </span><span class="nv">there</span><span class="w"> </span><span class="nv">are</span>
<span class="mi">5</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">parking</span><span class="w"> </span><span class="nv">lot</span>.<span class="w"> </span><span class="nv">Find</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">value</span><span class="w"> </span><span class="nv">of</span><span class="w"> </span><span class="nv">x</span>.
<span class="nv">Answer</span>:<span class="w"> </span><span class="nv">There</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="nv">originally</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="nv">cars</span>.<span class="w"> </span><span class="nv">x</span><span class="w"> </span><span class="nv">more</span><span class="w"> </span><span class="nv">cars</span><span class="w"> </span><span class="nv">arrive</span>.<span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nv">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span>,<span class="w"> </span><span class="nv">so</span><span class="w"> </span><span class="nv">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="o">=</span>
<span class="mi">2</span>.<span class="w"> </span><span class="nv">The</span><span class="w"> </span><span class="nv">answer</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="mi">2</span>.
</code></pre></div>

<p>Figure 5: Rephrasing with Algebraic prompt</p>
<div class="codehilite"><pre><span></span><code><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">math</span><span class="w"> </span><span class="n">question</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">blank</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">answer</span><span class="p">.</span><span class="w"> </span><span class="n">Solve</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="n">b</span>
<span class="n">step</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">find</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">blank</span><span class="p">.</span><span class="w"> </span><span class="n">Strictly</span><span class="w"> </span><span class="n">follow</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">format</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">examples</span>
<span class="n">below</span><span class="p">.</span>
<span class="nl">Question</span><span class="p">:</span><span class="w"> </span><span class="n">Ben</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">four</span><span class="w"> </span><span class="n">boxes</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">ten</span><span class="w"> </span><span class="n">basketball</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">box</span><span class="p">.</span><span class="w"> </span><span class="n">Ben</span><span class="w"> </span><span class="n">received</span>
<span class="w">    </span><span class="n">cards</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">his</span><span class="w"> </span><span class="n">mother</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">he</span><span class="w"> </span><span class="n">gives</span><span class="w"> </span><span class="mi">58</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">his</span><span class="w"> </span><span class="n">classmates</span><span class="p">,</span><span class="w"> </span><span class="n">how</span><span class="w"> </span><span class="n">many</span>
<span class="n">cards</span><span class="w"> </span><span class="n">does</span><span class="w"> </span><span class="n">he</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">left</span><span class="o">?</span>
<span class="nl">Answer</span><span class="p">:</span><span class="w"> </span><span class="mi">22</span>
<span class="n">Peano</span><span class="w"> </span><span class="n">solution</span><span class="o">:</span>
<span class="w">    </span><span class="n">Let</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">boxes</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">a</span><span class="p">]].</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">]].</span>
<span class="w">    </span><span class="n">Let</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">box</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">b</span><span class="p">]].</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">]].</span>
<span class="w">    </span><span class="n">Let</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="n">Ben</span><span class="w"> </span><span class="n">initially</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">c</span><span class="p">]].</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">]].</span>
<span class="w">    </span><span class="n">Let</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="n">received</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">mother</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">d</span><span class="p">]].</span>
<span class="w">    </span><span class="n">Let</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">classmates</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">e</span><span class="p">]].</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">58</span><span class="p">]].</span>
<span class="w">    </span><span class="n">Let</span><span class="w"> </span><span class="n">f</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="n">left</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">f</span><span class="p">]].</span><span class="w"> </span><span class="n">From</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="n">Answer</span><span class="p">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">22</span><span class="p">]].</span>
<span class="w">    </span><span class="n">We</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">c</span><span class="p">]]</span>
<span class="w">    </span><span class="n">The</span><span class="w"> </span><span class="n">answer</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="p">[[</span><span class="n">answer</span><span class="w"> </span><span class="n">d</span><span class="p">]].</span>
</code></pre></div>

<p>Question: Natalia sold $\qquad$ clips to her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? Answer: 72
Peano solution:</p>
<p>Let a be number of clips Natalia sold in April [[var a]].
So number of clips Natalia sold in May are half of a.
Let b be number of clips sold altogether [[var b]]. From given Answer, we have [[eq $\mathrm{b}=72$ ]].
We have $[[e q a=b /(1+1 / 2)]]$
The answer is the value of a [[answer a]].</p>
<div class="codehilite"><pre><span></span><code><span class="x">Q: </span><span class="cp">{{</span><span class="nv">question</span><span class="cp">}}</span>
<span class="x">A: </span><span class="cp">{{</span><span class="nv">answer</span><span class="cp">}}</span>
<span class="x">Peano solution:</span>
</code></pre></div>

<p>Figure 6: Tools</p>
<div class="codehilite"><pre><span></span><code><span class="n">Rephrase</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="n">blanked</span><span class="w"> </span><span class="n">question</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">answer</span><span class="w"> </span><span class="n">pairs</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="n">solve</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="n">step</span>
<span class="n">to</span><span class="w"> </span><span class="n">find</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">blank</span><span class="p">.</span><span class="w"> </span><span class="n">Strictly</span><span class="w"> </span><span class="n">follow</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">format</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">examples</span><span class="w"> </span><span class="n">below</span><span class="p">.</span>
<span class="nl">Question</span><span class="p">:</span><span class="w"> </span><span class="n">Ben</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">four</span><span class="w"> </span><span class="n">boxes</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">ten</span><span class="w"> </span><span class="n">basketball</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">box</span><span class="p">.</span><span class="w"> </span><span class="n">Ben</span><span class="w"> </span><span class="n">received</span>
<span class="w">    </span><span class="n">cards</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">his</span><span class="w"> </span><span class="n">mother</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">he</span><span class="w"> </span><span class="n">gives</span><span class="w"> </span><span class="mi">58</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">his</span><span class="w"> </span><span class="n">classmates</span><span class="p">,</span><span class="w"> </span><span class="n">how</span><span class="w"> </span><span class="n">many</span>
<span class="n">cards</span><span class="w"> </span><span class="n">does</span><span class="w"> </span><span class="n">he</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">left</span><span class="o">?</span>
<span class="nl">Answer</span><span class="p">:</span><span class="w"> </span><span class="mi">22</span>
<span class="nl">Rephrased</span><span class="p">:</span><span class="w"> </span><span class="n">Ben</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">four</span><span class="w"> </span><span class="n">boxes</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">ten</span><span class="w"> </span><span class="n">basketball</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">box</span><span class="p">.</span><span class="w"> </span><span class="n">Ben</span><span class="w"> </span><span class="n">received</span><span class="w"> </span><span class="n">x</span>
<span class="n">cards</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">his</span><span class="w"> </span><span class="n">mother</span><span class="p">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">he</span><span class="w"> </span><span class="n">gives</span><span class="w"> </span><span class="mi">58</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">his</span><span class="w"> </span><span class="n">classmates</span><span class="p">,</span><span class="w"> </span><span class="n">he</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="mi">22</span><span class="w"> </span><span class="n">cards</span>
<span class="n">left</span><span class="p">.</span><span class="w"> </span><span class="n">Find</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">x</span><span class="p">.</span>
<span class="n">Peano</span><span class="w"> </span><span class="n">solution</span><span class="o">:</span>
<span class="mi">1</span>
<span class="mi">1</span><span class="p">}</span><span class="err">\</span><span class="n">mathrm</span><span class="p">{</span><span class="w"> </span><span class="n">Let</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">boxes</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">a</span><span class="p">]].</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">]].</span>
<span class="n">Let</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">box</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">b</span><span class="p">]].</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">]].</span>
<span class="n">Let</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="n">Ben</span><span class="w"> </span><span class="n">initially</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">c</span><span class="p">]].</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">]].</span>
<span class="n">Let</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="n">received</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">mother</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">x</span><span class="p">]].</span>
<span class="n">Let</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">total</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">Ben</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">d</span><span class="p">]].</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="p">]]</span>
<span class="n">Let</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">classmates</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">e</span><span class="p">]].</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">58</span><span class="p">]].</span>
<span class="n">Let</span><span class="w"> </span><span class="n">f</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="n">left</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">f</span><span class="p">]].</span><span class="w"> </span><span class="n">From</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="n">Answer</span><span class="p">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">22</span><span class="p">]].</span>
<span class="n">As</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="n">left</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">also</span><span class="w"> </span><span class="n">total</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">cards</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">classmates</span><span class="p">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">d</span>
<span class="o">-</span><span class="w"> </span><span class="n">e</span><span class="p">]]</span>
<span class="n">The</span><span class="w"> </span><span class="n">answer</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="p">[[</span><span class="n">answer</span><span class="w"> </span><span class="n">x</span><span class="p">]].</span>
<span class="mi">23</span>
<span class="mi">24</span>
<span class="mi">25</span>
<span class="mi">26</span><span class="n">Question</span><span class="o">:</span><span class="w"> </span><span class="n">Natalia</span><span class="w"> </span><span class="n">sold</span><span class="w"> </span><span class="n">clips</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">her</span><span class="w"> </span><span class="n">friends</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">April</span><span class="p">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="n">she</span><span class="w"> </span><span class="n">sold</span><span class="w"> </span><span class="n">half</span>
<span class="n">as</span><span class="w"> </span><span class="n">many</span><span class="w"> </span><span class="n">clips</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">May</span><span class="p">.</span><span class="w"> </span><span class="n">How</span><span class="w"> </span><span class="n">many</span><span class="w"> </span><span class="n">clips</span><span class="w"> </span><span class="n">did</span><span class="w"> </span><span class="n">Natalia</span><span class="w"> </span><span class="n">sell</span><span class="w"> </span><span class="n">altogether</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">April</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">May</span><span class="o">?</span>
<span class="nl">Answer</span><span class="p">:</span><span class="w"> </span><span class="mi">72</span>
<span class="mi">27</span>
<span class="mi">28</span><span class="n">Rephrased</span><span class="o">:</span><span class="w"> </span><span class="n">Natalia</span><span class="w"> </span><span class="n">sold</span><span class="w"> </span><span class="n">clips</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">her</span><span class="w"> </span><span class="n">friends</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">April</span><span class="p">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="n">she</span><span class="w"> </span><span class="n">sold</span><span class="w"> </span><span class="n">half</span>
<span class="n">as</span><span class="w"> </span><span class="n">many</span><span class="w"> </span><span class="n">clips</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">May</span><span class="p">.</span><span class="w"> </span><span class="n">Find</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="n">such</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">she</span><span class="w"> </span><span class="n">sold</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">total</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="mi">72</span><span class="w"> </span><span class="n">clips</span>
<span class="n">altogether</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">April</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">May</span><span class="p">.</span>
<span class="n">Peano</span><span class="w"> </span><span class="n">solution</span><span class="o">:</span>
<span class="mi">29</span>
<span class="mi">30</span>
<span class="mi">31</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">Let</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">clips</span><span class="w"> </span><span class="n">Natalia</span><span class="w"> </span><span class="n">sold</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">April</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">x</span><span class="p">]]</span>
<span class="n">Let</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">clips</span><span class="w"> </span><span class="n">Natalia</span><span class="w"> </span><span class="n">sold</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">May</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">a</span><span class="p">]].</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="p">]].</span>
<span class="n">Let</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">clips</span><span class="w"> </span><span class="n">sold</span><span class="w"> </span><span class="n">altogether</span><span class="w"> </span><span class="p">[[</span><span class="n">var</span><span class="w"> </span><span class="n">b</span><span class="p">]].</span><span class="w"> </span><span class="n">From</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="n">Answer</span><span class="p">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="p">[[</span><span class="n">eq</span>
<span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">72</span><span class="p">]].</span>
<span class="n">As</span><span class="w"> </span><span class="n">clips</span><span class="w"> </span><span class="n">sold</span><span class="w"> </span><span class="n">altogether</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">also</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">clips</span><span class="w"> </span><span class="n">sold</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">April</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">May</span><span class="p">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">have</span>
<span class="w">    </span><span class="p">[[</span><span class="n">eq</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="p">]]</span>
<span class="n">The</span><span class="w"> </span><span class="n">answer</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="p">[[</span><span class="n">answer</span><span class="w"> </span><span class="n">x</span><span class="p">]].</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>. . .
Q: \{\{question\}\}
A: \{\{answer\}\}
Rephrased:
</code></pre></div>

<p>Figure 7: Tools with Rephrasing</p>
<p>Rephrase the given blanked question and answer pairs and then find the solution to the rephrased question. Write a python function that finds the value of $x$ by solving step by step. Make sure you name your method finding_x. A few examples are given below.:
Question: Ben has four boxes with ten basketball cards in each box. Ben received $\qquad$ cards from his mother. If he gives 58 cards to his classmates, how many cards does he has left?
Answer: 22
Rephrased: Ben has four boxes with ten basketball cards in each box. Ben received x cards from his mother. He gives 58 cards to his classmates. He has 22 cards left. Program:
' ' 'python
def finding_x():
num_boxes $=4$
cards_per_box $=10$
# cards_received_from_mother $=x$ - This line is commented because $x$ is unknown # hence the variable cards_received_from_mother can't be used in R.H.S. of any calculation
cards_given_to_classmates $=58$
cards_left $=22$
cards_in_boxes = num_boxes * cards_per_box
total_cards_before_given_to_classmates = cards_given_to_classmates + cards_left
cards_received_from_mother = total_cards_before_given_to_classmates cards_in_boxes
return cards_received_from_mother
・・
Question: Olivia has $\$ 23$. She bought $\qquad$ bagels for $\$ 3$ each. How much money does she have left?
Answer: 8
Rephrased: Olivia has $\$ 23$. She bought x bagels for $\$ 3$ each. She has $\$ 8$ left. Find the value of $x$.
Program:
' ' 'python
def finding_x():
money_initial $=23$
# num_of_bagels $=\mathrm{x}$ - This line is commented because x is unknown
# hence the variable num_of_bagels can't be used in R.H.S. of any calculation bagel_cost $=3$
money_left $=8$
money_spent = money_initial - money_left
num_of_bagels = money_spent / bagel_cost
return num_of_bagels
・・
Question: {{question}}
Answer: {{answer}}
Rephrased:</p>
<p>Figure 8: PAL with Rephrasing</p>
<div class="codehilite"><pre><span></span><code><span class="x">Rephrase the given blanked question and answer pairs and then write a python</span>
<span class="x">function called solution() to find the value of x in the rephrased question. Return</span>
<span class="x">the value of x. You may assume the neccessary libraries are imported. Strictly</span>
<span class="x">follow the format given in the examples below, as the method will be executed with</span>
<span class="x">the same name.</span>
<span class="x">Q: Ben has four boxes with ten basketball cards in each box. Ben received</span>
<span class="x">cards from his mother. If he gives 58 cards to his classmates, how many cards does</span>
<span class="x">he has left?</span>
<span class="x">A: 22</span>
<span class="x">Rephrased: Ben has four boxes with ten basketball cards in each box. Ben received x</span>
<span class="x">cards from his mother. He gives 58 cards to his classmates. He has 22 cards left.</span>
<span class="x">Find the value of x.</span>
<span class="x">Program:</span>
<span class="x">&#39;&#39;&#39;python</span>
<span class="x">def solution():</span>
<span class="x">    num_boxes = 4</span>
<span class="x">    cards_per_box = 10</span>
<span class="x">    total_cards_in_boxes = num_boxes * cards_per_box</span>
<span class="x">    cards_from_mother = x</span>
<span class="x">    cards_given_to_classmates = 58</span>
<span class="x">    cards_left = 22</span>
<span class="x">    equation = Eq(cards_from_mother + total_cards_in_boxes,</span>
<span class="x">cards_given_to_classmates + cards_left)</span>
<span class="x">    blank = solve(equation)[0]</span>
<span class="x">    return blank</span>
<span class="x">&#39;&#39;&#39;</span>
<span class="x">Q: Natalia sold ____ clips to her friends in April, and then she sold half as</span>
<span class="x">many clips in May. How many clips did Natalia sell altogether in April and May?</span>
<span class="x">A: 72</span>
<span class="x">Rephrased: Natalia sold x clips to her friends in April, and then she sold half as</span>
<span class="x">many clips in May. Natalia sells 72 clips altogether in April and May. Find the</span>
<span class="x">value of x.</span>
<span class="x">Program:</span>
<span class="x">&#39;&#39;&#39;python</span>
<span class="x">def solution():</span>
<span class="x">    april_clips = x</span>
<span class="x">    may_clips = april_clips / 2</span>
<span class="x">    total_clips = 72</span>
<span class="x">    equation = Eq(april_clips + may_clips, total_clips)</span>
<span class="x">    blank = solve(equation)[0]</span>
<span class="x">    return blank</span>
<span class="x">&#39;&#39;&#39;</span>
<span class="x">・.</span>
<span class="x">Q: </span><span class="cp">{{</span><span class="nv">question</span><span class="cp">}}</span>
<span class="x">A: </span><span class="cp">{{</span><span class="nv">answer</span><span class="cp">}}</span>
<span class="x">Rephrased:</span>
</code></pre></div>

<p>Figure 9: PAL-Tools with Rephrasing</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 10: Check your work with Rephrasing</p>
<div class="codehilite"><pre><span></span><code><span class="x">You are given a math question with a blank value and an answer. Rephrase the given</span>
<span class="x">blanked question and answer pairs and then write a python function called</span>
<span class="x">solution() to find the value of x in the rephrased question. Return the value of x.</span>
<span class="x">You may assume the neccessary libraries are imported. Strictly follow the format</span>
<span class="x">given in the examples below, as the method will be executed with the same name.</span>
<span class="x">Q: Ben has four boxes with ten basketball cards in each box. Ben received</span>
<span class="x">cards from his mother. If he gives 58 cards to his classmates, how many cards does</span>
<span class="x">he has left?</span>
<span class="x">A: 22</span>
<span class="x">Rephrased: Ben has four boxes with ten basketball cards in each box. Ben received x</span>
<span class="x">cards from his mother. He gives 58 cards to his classmates. He has 22 cards left.</span>
<span class="x">Find the value of x.</span>
<span class="x">Program:</span>
<span class="x">&#39;&#39;&#39;python</span>
<span class="x">def solution():</span>
<span class="x">    num_boxes = 4</span>
<span class="x">    cards_per_box = 10</span>
<span class="x">    total_cards_in_boxes = num_boxes * cards_per_box</span>
<span class="x">    cards_from_mother = x</span>
<span class="x">    cards_given_to_classmates = 58</span>
<span class="x">    cards_left = 22</span>
<span class="x">    equation = Eq(cards_from_mother + total_cards_in_boxes,</span>
<span class="x">cards_given_to_classmates + cards_left)</span>
<span class="x">    blank = solve(equation)[0]</span>
<span class="x">    return blank</span>
<span class="x">&#39;&#39;&#39;</span>
<span class="x">Q: Natalia sold ____ clips to her friends in April, and then she sold half as</span>
<span class="x">many clips in May. How many clips did Natalia sell altogether in April and May?</span>
<span class="x">A: 72</span>
<span class="x">Rephrased: Natalia sold x clips to her friends in April, and then she sold half as</span>
<span class="x">many clips in May. Natalia sells 72 clips altogether in April and May. Find the</span>
<span class="x">value of x.</span>
<span class="x">Program:</span>
<span class="x">&#39;&#39;&#39;python</span>
<span class="x">def solution():</span>
<span class="x">    april_clips = x</span>
<span class="x">    may_clips = april_clips / 2</span>
<span class="x">    total_clips = 72</span>
<span class="x">    equation = Eq(april_clips + may_clips, total_clips)</span>
<span class="x">    blank = solve(equation)[0]</span>
<span class="x">    return blank</span>
<span class="x">&#39;&#39;&#39;</span>
<span class="x">Q: </span><span class="cp">{{</span><span class="nv">question</span><span class="cp">}}</span>
<span class="x">A: </span><span class="cp">{{</span><span class="nv">answer</span><span class="cp">}}</span>
<span class="x">Rephrased:</span>
</code></pre></div>

<p>Figure 11: PAL-Tools with Rephrasing and Self-Refine: init prompt</p>
<div class="codehilite"><pre><span></span><code><span class="n">You</span><span class="w"> </span><span class="k">are</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">question</span><span class="o">-</span><span class="n">answer</span><span class="w"> </span><span class="n">pair</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">blank</span><span class="p">,</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">chain</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">thought</span><span class="w"> </span><span class="p">(</span><span class="nf">CoT</span><span class="p">)</span><span class="w"> </span><span class="k">for</span>
<span class="n">filling</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blank</span><span class="p">.</span><span class="w"> </span><span class="k">Go</span><span class="w"> </span><span class="n">through</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">chain</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">thought</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="k">by</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">point</span><span class="w"> </span><span class="k">out</span>
<span class="n">mistakes</span><span class="p">,</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="ow">any</span><span class="p">.</span><span class="w"> </span><span class="n">Provide</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">final</span><span class="w"> </span><span class="n">corrected</span><span class="w"> </span><span class="n">answer</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">shown</span><span class="w"> </span><span class="n">below</span><span class="p">.</span>
<span class="nl">Q</span><span class="p">:</span><span class="w"> </span><span class="n">Kelly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">grocery</span><span class="w"> </span><span class="n">shopping</span><span class="w"> </span><span class="k">at</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">supermarket</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">making</span><span class="w"> </span><span class="n">sure</span><span class="w"> </span><span class="n">she</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">enough</span><span class="w"> </span><span class="ow">in</span>
<span class="n">her</span><span class="w"> </span><span class="n">budget</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">items</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">her</span><span class="w"> </span><span class="n">cart</span><span class="p">.</span><span class="w"> </span><span class="n">Her</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="n">packs</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">bacon</span><span class="w"> </span><span class="n">cost</span><span class="w"> </span><span class="err">$</span><span class="n">______</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">total</span><span class="w"> </span><span class="ow">and</span>
<span class="n">she</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="mi">6</span><span class="w"> </span><span class="n">packets</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">chicken</span><span class="w"> </span><span class="n">which</span><span class="w"> </span><span class="k">each</span><span class="w"> </span><span class="n">cost</span><span class="w"> </span><span class="n">twice</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">much</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">pack</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">bacon</span><span class="p">.</span><span class="w"> </span><span class="n">She</span>
<span class="n">also</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="n">packs</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">strawberries</span><span class="p">,</span><span class="w"> </span><span class="n">priced</span><span class="w"> </span><span class="k">at</span><span class="w"> </span><span class="err">$</span><span class="mi">4</span><span class="w"> </span><span class="k">each</span><span class="p">,</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="mi">7</span><span class="w"> </span><span class="n">packs</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">apples</span><span class="p">,</span><span class="w"> </span><span class="k">each</span>
<span class="n">priced</span><span class="w"> </span><span class="k">at</span><span class="w"> </span><span class="n">half</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">price</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">pack</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">strawberries</span><span class="p">.</span><span class="w"> </span><span class="k">If</span><span class="w"> </span><span class="n">Kelly</span><span class="s1">&#39;s budget is $65 then</span>
<span class="s1">how much money, in dollars, does she have left in her budget?</span>
<span class="s1">A: 5</span>
<span class="s1">Rephrased: Kelly is grocery shopping at a supermarket and is making sure she has</span>
<span class="s1">enough in her budget for the items in her cart. Her 5 packs of bacon cost a total</span>
<span class="s1">of x dollars, and she has 6 packets of chicken, each costing twice as much as a</span>
<span class="s1">pack of bacon. She also has 3 packs of strawberries priced at $4 each, and 7 packs</span>
<span class="s1">of apples, each priced at half the price of a pack of strawberries. If Kelly&#39;</span><span class="n">s</span>
<span class="n">budget</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="err">$</span><span class="mi">65</span><span class="p">,</span><span class="w"> </span><span class="k">then</span><span class="w"> </span><span class="n">how</span><span class="w"> </span><span class="n">much</span><span class="w"> </span><span class="nc">money</span><span class="p">,</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">dollars</span><span class="p">,</span><span class="w"> </span><span class="n">does</span><span class="w"> </span><span class="n">she</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="nf">left</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">her</span><span class="w"> </span><span class="n">budget</span><span class="vm">?</span>
<span class="nl">Program</span><span class="p">:</span>
<span class="s1">&#39;&#39;</span><span class="n">python</span>
<span class="n">def</span><span class="w"> </span><span class="n">solution</span><span class="p">()</span><span class="err">:</span>
<span class="w">    </span><span class="n">bacon_cost</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span>
<span class="w">    </span><span class="n">chicken_cost</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">bacon_cost</span>
<span class="w">    </span><span class="n">strawberry_cost</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span>
<span class="w">    </span><span class="n">apple_cost</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">strawberry_cost</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span>
<span class="w">    </span><span class="n">budget</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">65</span>
<span class="w">    </span><span class="n">remaining_budget</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">budget</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="p">(</span><span class="mi">5</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">bacon_cost</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">6</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">chicken_cost</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="o">*</span>
<span class="n">strawberry_cost</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">7</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">apple_cost</span><span class="p">)</span>
<span class="w">    </span><span class="n">equation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Eq</span><span class="p">(</span><span class="n">remaining_budget</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span>
<span class="w">    </span><span class="n">blank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">solve</span><span class="p">(</span><span class="n">equation</span><span class="p">)</span><span class="o">[</span><span class="n">0</span><span class="o">]</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">blank</span>
<span class="err">・・</span>
<span class="nl">Correction</span><span class="p">:</span>
<span class="n">The</span><span class="w"> </span><span class="n">rephrased</span><span class="w"> </span><span class="n">problem</span><span class="w"> </span><span class="n">does</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">end</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="s1">&#39;Find the value of x&#39;</span><span class="p">.</span><span class="w"> </span><span class="n">Instead</span><span class="p">,</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">asks</span><span class="w"> </span><span class="n">us</span>
<span class="k">to</span><span class="w"> </span><span class="n">find</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="nc">money</span><span class="w"> </span><span class="n">Kelly</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="nf">left</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">her</span><span class="w"> </span><span class="n">budget</span><span class="p">.</span><span class="w"> </span><span class="n">This</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">incorrect</span><span class="p">.</span>
<span class="n">Let</span><span class="err">&#39;</span><span class="n">s</span><span class="w"> </span><span class="k">check</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="nl">program</span><span class="p">:</span>
<span class="w">    </span><span class="n">bacon_cost</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span>
<span class="w">    </span><span class="n">chicken_cost</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">bacon_cost</span>
<span class="n">Looks</span><span class="w"> </span><span class="n">good</span>
<span class="w">    </span><span class="n">strawberry_cost</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span>
<span class="w">    </span><span class="n">apple_cost</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">strawberry_cost</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span>
<span class="n">Looks</span><span class="w"> </span><span class="n">good</span>
<span class="w">    </span><span class="n">budget</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">65</span>
<span class="w">    </span><span class="n">remaining_budget</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">budget</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="p">(</span><span class="mi">5</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">bacon_cost</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">6</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">chicken_cost</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="o">*</span>
<span class="n">strawberry_cost</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">7</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">apple_cost</span><span class="p">)</span>
<span class="n">The</span><span class="w"> </span><span class="n">equation</span><span class="w"> </span><span class="n">formed</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">correct</span><span class="p">,</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="k">are</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">packs</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">bacon</span><span class="p">,</span><span class="w"> </span><span class="n">chicken</span><span class="p">,</span>
<span class="n">strawberry</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">apples</span>
<span class="w">    </span><span class="n">equation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Eq</span><span class="p">(</span><span class="n">remaining_budget</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span>
<span class="w">    </span><span class="n">blank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">solve</span><span class="p">(</span><span class="n">equation</span><span class="p">)</span><span class="o">[</span><span class="n">0</span><span class="o">]</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">blank</span>
<span class="n">The</span><span class="w"> </span><span class="n">equation</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">equated</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">correct</span><span class="w"> </span><span class="n">answer</span><span class="p">,</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">program</span><span class="w"> </span><span class="k">returns</span><span class="w"> </span><span class="n">the</span>
<span class="n">blank</span><span class="p">.</span>
<span class="n">The</span><span class="w"> </span><span class="n">program</span><span class="w"> </span><span class="n">provided</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">completely</span><span class="w"> </span><span class="n">correct</span><span class="err">!</span>
</code></pre></div>

<p>Figure 12: PAL-Tools with Rephrasing and Self-Refine: feedback prompt</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ https://supercomputing.iitd.ac.in/&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>