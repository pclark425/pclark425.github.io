<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1741 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1741</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1741</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-31.html">extraction-schema-31</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <p><strong>Paper ID:</strong> paper-3841234dd49250c4fcbba79eed6593d3b57932c1</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/3841234dd49250c4fcbba79eed6593d3b57932c1" target="_blank">Language Model Crossover: Variation through Few-Shot Prompting</a></p>
                <p><strong>Paper Venue:</strong> ACM Transactions on Evolutionary Learning and Optimization</p>
                <p><strong>Paper TL;DR:</strong> The conclusion is that language model crossover is a flexible and effective method for evolving genomes representable as text, and naturally benefits from current progress in language models.</p>
                <p><strong>Paper Abstract:</strong> This article pursues the insight that language models naturally enable an intelligent variation operator similar in spirit to evolutionary crossover. In particular, language models of sufficient scale demonstrate in-context learning, i.e., they can learn from associations between a small number of input patterns to generate outputs incorporating such associations (also called few-shot prompting). This ability can be leveraged to form a simple but powerful variation operator, i.e., to prompt a language model with a few text-based genotypes (such as code, plain-text sentences, or equations), and to parse its corresponding output as those genotypesâ€™ offspring. The promise of such language model crossover (which is simple to implement and can leverage many different open source language models) is that it enables a simple mechanism to evolve semantically rich text representations (with few domain-specific tweaks), and naturally benefits from current progress in language models. Experiments in this article highlight the versatility of language-model crossover, through evolving binary bit-strings, sentences, equations, text-to-image prompts, and Python code. The conclusion is that language model crossover is a flexible and effective method for evolving genomes representable as text.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1741.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1741.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LMX</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Language Model Crossover</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-general genetic recombination operator that forms prompts by concatenating k parent text genotypes, feeds that prompt to an LLM, and interprets the LLM's continuation as offspring; used as crossover (k>1) or mutation (k=1) across multiple domains (binary strings, math expressions, sentences, image prompts, Python code).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Language Model Crossover (LMX)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>LMX is an evolutionary variation operator implemented by: selecting k parent genotypes (text), concatenating them into a prompt (optionally with a short header), performing a single forward pass through an autoregressive LLM, and parsing generated continuations into one or more offspring genotypes. It functions as a crossover operator when k>1 and as a mutation operator when k=1. LMX is framed as an implicit estimation-of-distribution operator (EDA-like): the LLM builds a probabilistic model of the parent set via in-context learning and samples offspring from that model. LMX is applied in a standard EA loop (generate children via LMX, combine with parents, select next population) and is flexible to different LLMs, prompt formats, and genotype text formats.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>text and code</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Concatenate k parent text genotypes (separated by newlines and optionally a header) into a prompt; feed the prompt to an autoregressive LLM; sample the model continuation (often truncated to a fixed number of lines or tokens); parse each generated line/block as a candidate child genotype; accept valid/parsible offspring. k is configurable (experiments used k from 1 to 7), and multiple children per forward pass (up to 3 in several experiments) can be accepted.</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>LMX with k=1 acts as prompt-based mutation: a single parent is placed in the prompt and the LLM is asked (implicitly, by continuation) to produce modifications. The paper also references explicit prompt-based mutation methods from prior work and uses single-parent LMX as a mutation ablation in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Domain-dependent metrics used as proxies for novelty: (1) count of novel genotypes (distinct from parents) produced per set of LMX runs (e.g., number of distinct offspring out of up to 60 in binary-string experiments); (2) Hamming/edit distance from reference strings to quantify heritable novelty; (3) MAP-Elites QD score (sum of fitness across niches) and number of niches filled for diversity/novelty in MAP-Elites runs; (4) Euclidean distance in sentence-embedding space (sentence-transformers) to measure distance/novelty from a seed sentence; (5) 'expression size' (parse-tree nodes) used for parsimony but not pure novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td>Key quantitative novelty/diversity findings reported: (a) Binary strings: percent valid offspring approaches ~100% as number of parents increases; number of novel genotypes generated per 20 applications peaks at four parents (max possible 60 offspring in that protocol). (b) Heritability: offspring generated from neighborhoods around different reference strings had significantly different Hamming-distance distributions (Mann-Whitney p<0.001), showing parent-dependent novelty. (c) OneMax GA: LMX drove evolution but converged to optimum in fewer runs (LMX 16/20 runs vs one-point crossover 20/20) while exhibiting higher mean fitness (Mann-Whitney p=0.002). (d) Sentence style transfer (MAP-Elites): LMX and LMX-Near achieved higher QD scores than a baseline control (Mann-Whitney p<1e-5); LMX-Near outperformed LMX on one quote (p<0.05). (e) Sodarace: diversity (niches filled and QD score) increased with number of parents in the prompt. Exact numeric QD or niche counts vary per experiment and are shown in the paper's figures but not always tabulated numerically in text.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Domain-specific executability/validity metrics: (1) Binary strings: syntactic validity (string composed only of '0'/'1' and correct length). (2) Symbolic regression: parseability to expression (using sympy) and numerical fitness R^2 on dataset; unparsable children discarded. (3) Sentence domain: coherence not directly scored; fitness used sentiment probability (cardiffnlp sentiment classifier) and embedding-distance for diversity. (4) Image prompts: deterministic Stable Diffusion outputs; image fitness measured by channel-based metrics (excess red/green/blue = R-0.5G-0.5B etc.). (5) Python Sodaracers: 'validation rate' = % of generated programs that are valid Sodaracer Python functions that instantiate and evaluate in the simulator; functionality measured by distance traveled in simulation as fitness.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Reported executability/validity observations: (a) Binary strings: syntactic validity rate approaches 100% with sufficient parents and larger LLMs (figures show monotonic improvement with number of parents and model size). (b) Symbolic regression: invalid/unparsable offspring were discarded; LMX produced parsable and high-R^2 expressions competitive with baselines. (c) Sodaracers: roughly ~30% of generated offspring were valid Sodaracer programs with the 6B CodeGen model; validation rate increased with model scale. (d) One-point comparisons: some domains (text-to-image) are robust to grammatical errors, so executability is less restrictive there. Exact numeric rates are provided in figures (e.g., ~30% valid programs for 6B model) and trends are emphasized over absolute numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td>Number of novel genotypes; Hamming/edit distance distributions; number of MAP-Elites niches filled; MAP-Elites QD score (sum of fitness across cells); embedding-distance for sentences; qualitative diversity of prompt text and generated images.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td>Trends: More parents typically increase diversity (greater novel-offspring counts, larger QD scores, more niches filled). Larger LLMs tend to produce both higher validity and more novel offspring (binary and sodarace experiments). In image-prompt evolution, LMX discovered diverse, non-obvious high-color prompts (e.g., including 'background' but differing in detail). Exact numerical diversity metrics are plotted in the paper figures; statistical tests reported for some comparisons (see novelty_results).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>The paper documents tradeoffs: increased novelty (e.g., moving far from a seed sentence) can produce high objective scores (sentiment) but also incoherent or ungrammatical text at large distances; larger prompts/parent sets increase novelty but may affect duplication rate (five parents more often produce offspring identical to a parent). In optimization (OneMax) LMX attained higher mean fitness but fewer full convergences than classical crossover, suggesting a tradeoff between exploratory novelty and guaranteed executability/convergence.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td>LMX was used in MAP-Elites to produce Pareto-like fronts (e.g., distance-from-seed vs positive-sentiment probability) and the paper visualizes non-dominated individuals, but does not provide a closed-form quantitative frontier equation; characterization is empirical (plots of elite maps and non-dominated sets) showing trade-offs between novelty and the target fitness.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Binary strings (OneMax), Symbolic regression (SRBench 'banana' black-box), Natural-language sentence style transfer (sentence sentiment via MAP-Elites), Text-to-image prompts for Stable Diffusion (color optimization), Python Sodaracers (robot morphology/function programs), and more generally any genotype representable as text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Classical one-point crossover (with mutation), zero-shot LLM prompt generation (no parents), random human-designed prompts baseline (for image prompts), gplearn (symbolic regression), LMX-NoHeader ablation, and LMX-Near variant (sampling nearby elites).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LMX is a simple, general variation operator that: (1) generates novel, valid offspring across many text-based genotype domains; (2) benefits from larger LLMs and from more parents in the prompt in terms of validity and novelty; (3) can drive evolutionary optimization in diverse domains (competitive symbolic regression results, effective style transfer, strong prompt evolution for images, ability to evolve Python programs with nontrivial validation rates); (4) exhibits heritable variation (offspring distributions depend on parent sets), and approximates EDA-like probabilistic modeling of parents via in-context learning; and (5) shows tradeoffs between novelty/diversity and executability/robust convergence, highlighting the need for selection regimes and prompt design to balance exploration and validity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Language Model Crossover: Variation through Few-Shot Prompting', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1741.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1741.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Evolution through Large Models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evolution through Large Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior work referenced in the paper that uses large pre-trained models to perform instructed mutation-style modifications to genotypes (LLM-guided mutation) and relates to LMX's use of LLMs for mutation/crossover.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evolution through Large Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM-based Instructed Mutation (as described in referenced work)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced as an example of using foundation LLMs to guide mutation (instructed mutation) by prompting the model with instructions to modify genotypes; contrasted with LMX which uses few-shot parent concatenation as a crossover operator. The referenced work is cited as part of the trend toward LLMs in evolutionary operators.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>text and code</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Instructed mutation guided by natural-language prompts to an LLM (as characterized in the table and referenced text); specifics are not provided in this paper beyond the high-level categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>General LLM mutation contexts (cited in Table 1 as foundation-model + past runs / instructed mutation); exact domains in that paper not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as prior art demonstrating LLMs used for mutation/instructed mutation; cited to situate LMX among methods that use LLMs to modify code/genotypes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Language Model Crossover: Variation through Few-Shot Prompting', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1741.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1741.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Promptbreeder</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 2023 work that evolves prompts (i.e., text genotypes) to improve LLM outputs by evolutionary methods; included in the paper's Table 1 as an example of LLMs used for solution generation and mutation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Prompt evolution via LLMs (Promptbreeder)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced as an approach that applies evolutionary operations to prompts themselves, evolving prompts to improve downstream LLM behavior; listed in Table 1 as combining LLMs with evolutionary operators for prompt generation and mutation.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>text (prompts)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Evolutionary mutation/recombination of prompts combined with LLM evaluation/feedback (exact mechanics are not detailed in this paper beyond the listing in Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Prompt engineering / prompt evolution</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as related work showing that evolving prompts is an active research direction compatible with LMX-style approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Language Model Crossover: Variation through Few-Shot Prompting', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1741.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1741.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FullyAutonomousProgramming</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fully Autonomous Programming with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 2023 work (in Table 1) listed as using LLMs for instructed mutation or program generation, relevant to evolving code with LLM-guided operations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fully Autonomous Programming with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM-driven program generation/mutation (referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced in the paper's survey of LLM+evolution approaches as an example of work that uses LLMs to autonomously generate or modify code; in the present paper such works motivate LMX's extension to evolving Python code (Sodaracers).</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>code</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>LLM-guided generation or repair of code via instruction-style prompts (specifics not described in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Program synthesis/automation</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Included in the Table 1 timeline of LLM+evolution research as an example of program-focused LLM mutation/generation approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Language Model Crossover: Variation through Few-Shot Prompting', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1741.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1741.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MathFromProgramSearch</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mathematical Discoveries From Program Search with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 2023 work listed in the paper's Table 1 that uses LLMs to search program/code space for mathematical discoveries, illustrating program-level search using language models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mathematical Discoveries From Program Search with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Program-search with LLMs for mathematical discovery (referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited as part of the recent surge in works combining LLMs and program search/evolution; represents application of LLM-based solution generation to discovery in mathematical/programmatic spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>code and symbolic expressions</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>LLM-based generation/search over program expressions; exact evolutionary operators are not described in this paper beyond the citation.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Mathematical/program search</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Listed to demonstrate existing uses of LLMs for program-level search and discovery that motivate LMX's applicability to code and symbolic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Language Model Crossover: Variation through Few-Shot Prompting', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1741.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1741.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlgorithmEvolution-LLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Algorithm Evolution using Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 2023 paper in Table 1 that explores using LLMs to evolve or generate algorithms; cited as related work in the LLM+evolution trend.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Algorithm Evolution using Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Algorithm evolution with LLMs (referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Mentioned in the paper's survey as an example of contemporary works that use LLMs for evolving algorithms or algorithmic descriptions; the present paper situates LMX alongside such efforts.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>text and algorithm descriptions/code</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>LLM-based mutation/generation of algorithm descriptions (details not provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Algorithm discovery/evolution</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Included in the chronological table of related LLM+evolution works to highlight growing interest in algorithm/program evolution using LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Language Model Crossover: Variation through Few-Shot Prompting', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Evolution through Large Models <em>(Rating: 2)</em></li>
                <li>Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution <em>(Rating: 2)</em></li>
                <li>Fully Autonomous Programming with Large Language Models <em>(Rating: 2)</em></li>
                <li>Mathematical Discoveries From Program Search with Large Language Models <em>(Rating: 2)</em></li>
                <li>Algorithm Evolution using Large Language Models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1741",
    "paper_id": "paper-3841234dd49250c4fcbba79eed6593d3b57932c1",
    "extraction_schema_id": "extraction-schema-31",
    "extracted_data": [
        {
            "name_short": "LMX",
            "name_full": "Language Model Crossover",
            "brief_description": "A domain-general genetic recombination operator that forms prompts by concatenating k parent text genotypes, feeds that prompt to an LLM, and interprets the LLM's continuation as offspring; used as crossover (k&gt;1) or mutation (k=1) across multiple domains (binary strings, math expressions, sentences, image prompts, Python code).",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Language Model Crossover (LMX)",
            "system_description": "LMX is an evolutionary variation operator implemented by: selecting k parent genotypes (text), concatenating them into a prompt (optionally with a short header), performing a single forward pass through an autoregressive LLM, and parsing generated continuations into one or more offspring genotypes. It functions as a crossover operator when k&gt;1 and as a mutation operator when k=1. LMX is framed as an implicit estimation-of-distribution operator (EDA-like): the LLM builds a probabilistic model of the parent set via in-context learning and samples offspring from that model. LMX is applied in a standard EA loop (generate children via LMX, combine with parents, select next population) and is flexible to different LLMs, prompt formats, and genotype text formats.",
            "input_type": "text and code",
            "crossover_operation": "Concatenate k parent text genotypes (separated by newlines and optionally a header) into a prompt; feed the prompt to an autoregressive LLM; sample the model continuation (often truncated to a fixed number of lines or tokens); parse each generated line/block as a candidate child genotype; accept valid/parsible offspring. k is configurable (experiments used k from 1 to 7), and multiple children per forward pass (up to 3 in several experiments) can be accepted.",
            "mutation_operation": "LMX with k=1 acts as prompt-based mutation: a single parent is placed in the prompt and the LLM is asked (implicitly, by continuation) to produce modifications. The paper also references explicit prompt-based mutation methods from prior work and uses single-parent LMX as a mutation ablation in experiments.",
            "uses_literature": true,
            "uses_code": true,
            "novelty_metric": "Domain-dependent metrics used as proxies for novelty: (1) count of novel genotypes (distinct from parents) produced per set of LMX runs (e.g., number of distinct offspring out of up to 60 in binary-string experiments); (2) Hamming/edit distance from reference strings to quantify heritable novelty; (3) MAP-Elites QD score (sum of fitness across niches) and number of niches filled for diversity/novelty in MAP-Elites runs; (4) Euclidean distance in sentence-embedding space (sentence-transformers) to measure distance/novelty from a seed sentence; (5) 'expression size' (parse-tree nodes) used for parsimony but not pure novelty.",
            "novelty_results": "Key quantitative novelty/diversity findings reported: (a) Binary strings: percent valid offspring approaches ~100% as number of parents increases; number of novel genotypes generated per 20 applications peaks at four parents (max possible 60 offspring in that protocol). (b) Heritability: offspring generated from neighborhoods around different reference strings had significantly different Hamming-distance distributions (Mann-Whitney p&lt;0.001), showing parent-dependent novelty. (c) OneMax GA: LMX drove evolution but converged to optimum in fewer runs (LMX 16/20 runs vs one-point crossover 20/20) while exhibiting higher mean fitness (Mann-Whitney p=0.002). (d) Sentence style transfer (MAP-Elites): LMX and LMX-Near achieved higher QD scores than a baseline control (Mann-Whitney p&lt;1e-5); LMX-Near outperformed LMX on one quote (p&lt;0.05). (e) Sodarace: diversity (niches filled and QD score) increased with number of parents in the prompt. Exact numeric QD or niche counts vary per experiment and are shown in the paper's figures but not always tabulated numerically in text.",
            "executability_metric": "Domain-specific executability/validity metrics: (1) Binary strings: syntactic validity (string composed only of '0'/'1' and correct length). (2) Symbolic regression: parseability to expression (using sympy) and numerical fitness R^2 on dataset; unparsable children discarded. (3) Sentence domain: coherence not directly scored; fitness used sentiment probability (cardiffnlp sentiment classifier) and embedding-distance for diversity. (4) Image prompts: deterministic Stable Diffusion outputs; image fitness measured by channel-based metrics (excess red/green/blue = R-0.5G-0.5B etc.). (5) Python Sodaracers: 'validation rate' = % of generated programs that are valid Sodaracer Python functions that instantiate and evaluate in the simulator; functionality measured by distance traveled in simulation as fitness.",
            "executability_results": "Reported executability/validity observations: (a) Binary strings: syntactic validity rate approaches 100% with sufficient parents and larger LLMs (figures show monotonic improvement with number of parents and model size). (b) Symbolic regression: invalid/unparsable offspring were discarded; LMX produced parsable and high-R^2 expressions competitive with baselines. (c) Sodaracers: roughly ~30% of generated offspring were valid Sodaracer programs with the 6B CodeGen model; validation rate increased with model scale. (d) One-point comparisons: some domains (text-to-image) are robust to grammatical errors, so executability is less restrictive there. Exact numeric rates are provided in figures (e.g., ~30% valid programs for 6B model) and trends are emphasized over absolute numbers.",
            "diversity_metric": "Number of novel genotypes; Hamming/edit distance distributions; number of MAP-Elites niches filled; MAP-Elites QD score (sum of fitness across cells); embedding-distance for sentences; qualitative diversity of prompt text and generated images.",
            "diversity_results": "Trends: More parents typically increase diversity (greater novel-offspring counts, larger QD scores, more niches filled). Larger LLMs tend to produce both higher validity and more novel offspring (binary and sodarace experiments). In image-prompt evolution, LMX discovered diverse, non-obvious high-color prompts (e.g., including 'background' but differing in detail). Exact numerical diversity metrics are plotted in the paper figures; statistical tests reported for some comparisons (see novelty_results).",
            "novelty_executability_tradeoff": "The paper documents tradeoffs: increased novelty (e.g., moving far from a seed sentence) can produce high objective scores (sentiment) but also incoherent or ungrammatical text at large distances; larger prompts/parent sets increase novelty but may affect duplication rate (five parents more often produce offspring identical to a parent). In optimization (OneMax) LMX attained higher mean fitness but fewer full convergences than classical crossover, suggesting a tradeoff between exploratory novelty and guaranteed executability/convergence.",
            "frontier_characterization": "LMX was used in MAP-Elites to produce Pareto-like fronts (e.g., distance-from-seed vs positive-sentiment probability) and the paper visualizes non-dominated individuals, but does not provide a closed-form quantitative frontier equation; characterization is empirical (plots of elite maps and non-dominated sets) showing trade-offs between novelty and the target fitness.",
            "benchmark_or_domain": "Binary strings (OneMax), Symbolic regression (SRBench 'banana' black-box), Natural-language sentence style transfer (sentence sentiment via MAP-Elites), Text-to-image prompts for Stable Diffusion (color optimization), Python Sodaracers (robot morphology/function programs), and more generally any genotype representable as text.",
            "comparison_baseline": "Classical one-point crossover (with mutation), zero-shot LLM prompt generation (no parents), random human-designed prompts baseline (for image prompts), gplearn (symbolic regression), LMX-NoHeader ablation, and LMX-Near variant (sampling nearby elites).",
            "key_findings": "LMX is a simple, general variation operator that: (1) generates novel, valid offspring across many text-based genotype domains; (2) benefits from larger LLMs and from more parents in the prompt in terms of validity and novelty; (3) can drive evolutionary optimization in diverse domains (competitive symbolic regression results, effective style transfer, strong prompt evolution for images, ability to evolve Python programs with nontrivial validation rates); (4) exhibits heritable variation (offspring distributions depend on parent sets), and approximates EDA-like probabilistic modeling of parents via in-context learning; and (5) shows tradeoffs between novelty/diversity and executability/robust convergence, highlighting the need for selection regimes and prompt design to balance exploration and validity.",
            "uuid": "e1741.0",
            "source_info": {
                "paper_title": "Language Model Crossover: Variation through Few-Shot Prompting",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "Evolution through Large Models",
            "name_full": "Evolution through Large Models",
            "brief_description": "Prior work referenced in the paper that uses large pre-trained models to perform instructed mutation-style modifications to genotypes (LLM-guided mutation) and relates to LMX's use of LLMs for mutation/crossover.",
            "citation_title": "Evolution through Large Models",
            "mention_or_use": "mention",
            "system_name": "LLM-based Instructed Mutation (as described in referenced work)",
            "system_description": "Referenced as an example of using foundation LLMs to guide mutation (instructed mutation) by prompting the model with instructions to modify genotypes; contrasted with LMX which uses few-shot parent concatenation as a crossover operator. The referenced work is cited as part of the trend toward LLMs in evolutionary operators.",
            "input_type": "text and code",
            "crossover_operation": null,
            "mutation_operation": "Instructed mutation guided by natural-language prompts to an LLM (as characterized in the table and referenced text); specifics are not provided in this paper beyond the high-level categorization.",
            "uses_literature": null,
            "uses_code": null,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "General LLM mutation contexts (cited in Table 1 as foundation-model + past runs / instructed mutation); exact domains in that paper not detailed here.",
            "comparison_baseline": null,
            "key_findings": "Mentioned as prior art demonstrating LLMs used for mutation/instructed mutation; cited to situate LMX among methods that use LLMs to modify code/genotypes.",
            "uuid": "e1741.1",
            "source_info": {
                "paper_title": "Language Model Crossover: Variation through Few-Shot Prompting",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "Promptbreeder",
            "name_full": "Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution",
            "brief_description": "A 2023 work that evolves prompts (i.e., text genotypes) to improve LLM outputs by evolutionary methods; included in the paper's Table 1 as an example of LLMs used for solution generation and mutation.",
            "citation_title": "Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution",
            "mention_or_use": "mention",
            "system_name": "Prompt evolution via LLMs (Promptbreeder)",
            "system_description": "Referenced as an approach that applies evolutionary operations to prompts themselves, evolving prompts to improve downstream LLM behavior; listed in Table 1 as combining LLMs with evolutionary operators for prompt generation and mutation.",
            "input_type": "text (prompts)",
            "crossover_operation": null,
            "mutation_operation": "Evolutionary mutation/recombination of prompts combined with LLM evaluation/feedback (exact mechanics are not detailed in this paper beyond the listing in Table 1).",
            "uses_literature": false,
            "uses_code": false,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Prompt engineering / prompt evolution",
            "comparison_baseline": null,
            "key_findings": "Cited as related work showing that evolving prompts is an active research direction compatible with LMX-style approaches.",
            "uuid": "e1741.2",
            "source_info": {
                "paper_title": "Language Model Crossover: Variation through Few-Shot Prompting",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "FullyAutonomousProgramming",
            "name_full": "Fully Autonomous Programming with Large Language Models",
            "brief_description": "A 2023 work (in Table 1) listed as using LLMs for instructed mutation or program generation, relevant to evolving code with LLM-guided operations.",
            "citation_title": "Fully Autonomous Programming with Large Language Models",
            "mention_or_use": "mention",
            "system_name": "LLM-driven program generation/mutation (referenced)",
            "system_description": "Referenced in the paper's survey of LLM+evolution approaches as an example of work that uses LLMs to autonomously generate or modify code; in the present paper such works motivate LMX's extension to evolving Python code (Sodaracers).",
            "input_type": "code",
            "crossover_operation": null,
            "mutation_operation": "LLM-guided generation or repair of code via instruction-style prompts (specifics not described in this paper).",
            "uses_literature": null,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Program synthesis/automation",
            "comparison_baseline": null,
            "key_findings": "Included in the Table 1 timeline of LLM+evolution research as an example of program-focused LLM mutation/generation approaches.",
            "uuid": "e1741.3",
            "source_info": {
                "paper_title": "Language Model Crossover: Variation through Few-Shot Prompting",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "MathFromProgramSearch",
            "name_full": "Mathematical Discoveries From Program Search with Large Language Models",
            "brief_description": "A 2023 work listed in the paper's Table 1 that uses LLMs to search program/code space for mathematical discoveries, illustrating program-level search using language models.",
            "citation_title": "Mathematical Discoveries From Program Search with Large Language Models",
            "mention_or_use": "mention",
            "system_name": "Program-search with LLMs for mathematical discovery (referenced)",
            "system_description": "Cited as part of the recent surge in works combining LLMs and program search/evolution; represents application of LLM-based solution generation to discovery in mathematical/programmatic spaces.",
            "input_type": "code and symbolic expressions",
            "crossover_operation": null,
            "mutation_operation": "LLM-based generation/search over program expressions; exact evolutionary operators are not described in this paper beyond the citation.",
            "uses_literature": null,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Mathematical/program search",
            "comparison_baseline": null,
            "key_findings": "Listed to demonstrate existing uses of LLMs for program-level search and discovery that motivate LMX's applicability to code and symbolic tasks.",
            "uuid": "e1741.4",
            "source_info": {
                "paper_title": "Language Model Crossover: Variation through Few-Shot Prompting",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "AlgorithmEvolution-LLM",
            "name_full": "Algorithm Evolution using Large Language Models",
            "brief_description": "A 2023 paper in Table 1 that explores using LLMs to evolve or generate algorithms; cited as related work in the LLM+evolution trend.",
            "citation_title": "Algorithm Evolution using Large Language Models",
            "mention_or_use": "mention",
            "system_name": "Algorithm evolution with LLMs (referenced)",
            "system_description": "Mentioned in the paper's survey as an example of contemporary works that use LLMs for evolving algorithms or algorithmic descriptions; the present paper situates LMX alongside such efforts.",
            "input_type": "text and algorithm descriptions/code",
            "crossover_operation": null,
            "mutation_operation": "LLM-based mutation/generation of algorithm descriptions (details not provided in this paper).",
            "uses_literature": null,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Algorithm discovery/evolution",
            "comparison_baseline": null,
            "key_findings": "Included in the chronological table of related LLM+evolution works to highlight growing interest in algorithm/program evolution using LLMs.",
            "uuid": "e1741.5",
            "source_info": {
                "paper_title": "Language Model Crossover: Variation through Few-Shot Prompting",
                "publication_date_yy_mm": "2023-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Evolution through Large Models",
            "rating": 2
        },
        {
            "paper_title": "Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution",
            "rating": 2
        },
        {
            "paper_title": "Fully Autonomous Programming with Large Language Models",
            "rating": 2
        },
        {
            "paper_title": "Mathematical Discoveries From Program Search with Large Language Models",
            "rating": 2
        },
        {
            "paper_title": "Algorithm Evolution using Large Language Models",
            "rating": 1
        }
    ],
    "cost": 0.02045325,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Language Model Crossover: Variation through Few-Shot Prompting</h1>
<p>ELLIOT MEYERSON, Cognizant AI Labs<br>MARK J. NELSON, American University<br>HERBIE BRADLEY, University of Cambridge \&amp; CarperAI<br>ADAM GAIER, Autodesk Research<br>ARASH MORADI, New Jersey Institute of Technology<br>AMY K. HOOVER, New Jersey Institute of Technology<br>JOEL LEHMAN, CarperAI</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. Language Model Crossover (LMX). New candidate solutions are generated by concatenating parents into a prompt, feeding the prompt through any large pre-trained large language model (LLM), and collecting offspring from the output. Such an operator can be created through very few lines of code. The enormity and breadth of the dataset on which the LLM was trained, along with its ability to perform in-context learning, enables LMX to generate high-quality offspring across a broad range of domains. Domains demonstrated in this paper include (a) binary strings, (b) mathematical expressions, (c) English sentences, (d) image generation prompts, and (e) Python code; many more are possible. When integrated into an optimization loop, LMX serves as a general and effective engine of text-representation evolution.</p>
<p>This paper pursues the insight that language models naturally enable an intelligent variation operator similar in spirit to evolutionary crossover. In particular, language models of sufficient scale demonstrate in-context learning, i.e. they can learn from associations between a small number of input patterns to generate outputs incorporating such associations (also called few-shot prompting). This ability can be leveraged to form a simple but powerful variation operator, i.e. to prompt a language model with a few text-based genotypes (such as code, plain-text sentences, or equations), and to parse its corresponding output as those genotypes' offspring. The promise of such language model crossover (which is simple to implement and can leverage many different open-source language models) is that it enables a simple mechanism to evolve semantically-rich text representations (with few domain-specific tweaks), and naturally benefits from current progress in language models. Experiments in this paper highlight the versatility of language-model</p>
<p>Authors' addresses: Elliot Meyerson, Cognizant AI Labs, elliot.meyerson@cognizant.com; Mark J. Nelson, American University, mnelson@american.edu; Herbie Bradley, University of Cambridge \&amp; CarperAI, hb574@cam.ac.uk; Adam Gaier, Autodesk Research, adam.gaier@autodesk.com; Arash Moradi, New Jersey Institute of Technology, am3493@njit.edu; Amy K. Hoover, New Jersey Institute of Technology, ahoover@njit.edu; Joel LehmanCarperAI, lehman.154@gmail.com.</p>
<p>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.
(c) 2024 Association for Computing Machinery.</p>
<p>Manuscript submitted to ACM</p>
<p>crossover, through evolving binary bit-strings, sentences, equations, text-to-image prompts, and Python code. The conclusion is that language model crossover is a flexible and effective method for evolving genomes representable as text.</p>
<p>CCS Concepts: $\cdot$ Computing methodologies $\rightarrow$ Neural networks; Genetic algorithms; Genetic programming.
Additional Key Words and Phrases: neuroevolution, recombination, language models</p>
<h1>ACM Reference Format:</h1>
<p>Elliot Meyerson, Mark J. Nelson, Herbie Bradley, Adam Gaier, Arash Moradi, Amy K. Hoover, and Joel Lehman. 2024. Language Model Crossover: Variation through Few-Shot Prompting. 1, 1 (May 2024), 38 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn</p>
<h2>1 INTRODUCTION</h2>
<p>Large language models (LLMs; [9, 13]) are behind many of the approaches achieving state-of-the-art results in natural language processing domains, such as question-answering [19, 33, 70], code-generation [17, 66], and few-shot classification [13, 99]. One popular type of LLM is trained on corpora of human-authored text to predict the next token from previous ones, i.e. autoregressive LLMs (e.g. GPT-3), which at their core model a distribution of likely output sequences given an input sequence or prompt. In zero-shot prompting, a LLM generates an output response from a single input query. However, another popular prompting paradigm is few-shot prompting [13], wherein the input to the LLM contains a few examples of desired input-output behavior (e.g. how to classify a sentence's sentiment) preceding a new target input that the model is to classify. In this way, to some extent such LLMs have meta-learned how to learn a desired task given only a few natural-language examples [15, 119].</p>
<p>One reason this ability is exciting is because it highlights how LLMs can in effect be seen as powerful patterncompletion engines. Few-shot prompting works because the LLM can "guess the pattern" behind a few input/output pairs and generalize its behavior to a new target input (provided at the end of the few-shot prompt). The central insight of this paper is is that the pattern-completion ability of few-shot prompting can be leveraged to create a form of intelligent evolutionary crossover.</p>
<p>For example, if three text-based genotypes are drawn from a population and concatenated into a prompt, an ideal pattern-completion engine would analyze their commonalities and generate a new (fourth) genotype that qualitatively follows from the same distribution. In effect such an operator would combine aspects of the input genotypes, and indeed, an experiment in Section 4.1 demonstrates empirically that LLMs enable this with binary strings. Theoretically we also connect this form of LLM crossover (LMX) to estimation of distribution algorithms (EDAs; [3, 60]), wherein LMX can be seen as building an implicit probabilistic model of the input parent genotypes from which to sample a new offspring, through a single forward pass of the LLM. From the perspective of intelligent pattern-completion, this operator should naturally improve as LLMs increase in capabilities (which experiments here validate); furthermore, to increase performance the method can easily leverage the rise of open-source domain-specific LLMs that match a target domain (e.g. LLMs that focus on code, when the target domain is to evolve code), often with changing only a single line of code to rely on a different hosted model (e.g. through the HuggingFace model repository [128]).</p>
<p>The benefit of LMX is that evolution can easily and effectively leverage the semantically-rich (and generic) representation of text, e.g. without having to design domain-specific variation operators. LMX's versatility is highlighted in experiments with binary strings, style transfer of plain-text sentences, symbolic regression of mathematical expressions, generating images through prompts for a text-to-image model, and generating Python code. The results highlight the potential of the method to produce quality results across domains, often by leveraging the broad ecosystem of pretrained models that can be easily combined in many ways to quantify fitness or diversity, or to cross modalities (i.e. Manuscript submitted to ACM</p>
<p>from text to image). LMX may also synergize with recent LLM-based mutation techniques [63], and is amenable to similar possibilities such as fine-tuning an LLM as a way of accelerating search, although we leave these possibilities for future work (See Section 7).</p>
<p>In short, the main contributions of this paper are to introduce LMX, explore its basic properties, and highlight its versatility through testing it in a variety of domains. We will release an implementation of LMX and code to recreate the main experiments of the paper.</p>
<h1>2 BACKGROUND</h1>
<p>This section reviews foundation models and intelligent variation in evolutionary computation.</p>
<h3>2.1 Foundation Models</h3>
<p>A recent paradigm in ML is to train increasingly large models on internet-scale data, e.g. BERT and GPT-3 on text [13, 32], or DALL-E and stable diffusion on captioned images [93, 95]. Such models are sometimes called foundation models [9], as they provide a broad foundation from which they can be specialized to many specific domains (e.g. with supervised fine-tuning (i.e., further training on a domain-specific dataset) or prompt-engineering). Foundation models have enabled a vibrant ecosystem of specialized models [120] that can be combined in a plug-and-play way (e.g. models that measure sentiment of text [14], summarize text [111], write code [83], rank the aesthetics of images [30, 56, 103], and create high-dimensional embeddings of text or images [94, 132]. One contribution of this paper is to demonstrate how evolutionary methods can easily leverage this growing ecosystem to evolve high-quality artifacts in diverse applications.</p>
<p>One particularly exciting class of foundation models are pre-trained language models (LMs) that model the distribution of text. While early LMs used markov chains [107] or recurrent neural networks [40], more recently the transformer architecture [118] has enabled significant progress in NLP. Let $V$ be a vocabulary of text tokens, e.g., words or other atomic pieces of text. Then, $V^{<em>}$ is the set of strings made up of tokens from $V$. Given an input string $a_{1} a_{2} \ldots a_{T_{\text {in }}} \in V^{</em>}$, a large autoregressive transformer-based LM (LLM) probabilistically generates an output string:</p>
<p>$$
a_{T_{\text {in }}+1} a_{T_{\text {in }}+2} \ldots a_{T_{\text {in }}+T_{\text {out }}} \sim \operatorname{LLM}\left(a_{1} a_{2} \ldots a_{T_{\text {in }}}\right)
$$</p>
<p>where $a_{T_{\text {in }}+i}$ are all sampled autoregressively:</p>
<p>$$
a_{T_{\text {in }}+i} \sim \operatorname{LLM}<em 1="1">{\sigma}\left(a</em>\right]
$$} a_{2} \ldots a_{T_{\text {in }}+i-1}\right) \forall i \in\left[1, T_{\text {out }</p>
<p>where $\mathrm{LLM}<em i="i">{\sigma}$ is the softmax distribution over $V$ induced by a single forward pass through the transformer model. The method in this paper focuses on one emergent capability of LLMs: the potential to learn from text examples provided as input to the model when generating an output, which is called in-context learning or few-shot prompting [13, 119]. For example, including input-output examples of a text classification task in a prompt will improve an LLM's performance at that task. Say, for some input space $\mathcal{X}$ and output space $\mathcal{Y}$, we have ground truth classification examples $\left(x</em>)$, an LLM, a function $\phi$ for formatting a list of examples as a prompt (e.g., by concatenating them with a delimiter), and $\psi$ for extracting a prediction from text output (e.g., by splitting on a delimiter). Then, in-context learning}, y_{i}\right) \sim(\mathcal{X}, \mathcal{Y</p>
<p>with $k$ examples ( $k$-shot prompting) is successful if</p>
<p>$$
\begin{aligned}
\operatorname{Pr}\left[\psi\left(\operatorname{LLM}\left(\phi\left(\left[x_{1}, y_{1}, \ldots, x_{k}, y_{k}, x_{k+1}\right]\right)\right)\right)=y_{k+1}\right] &amp; &gt;\operatorname{Pr}\left[\psi\left(\operatorname{LLM}\left(\phi\left(\left[x_{1}, y_{1}, x_{k+1}\right]\right)\right)\right)=y_{k+1} \mid\right. \
&amp; &gt;\operatorname{Pr}\left[\psi\left(\operatorname{LLM}\left(\phi\left(\left[x_{k+1}\right]\right)\right)\right)=y_{k+1}\right]
\end{aligned}
$$</p>
<p>i.e., the model is more likely to produce the true target $y_{k+1}$ for $x_{k+1}$ if multiple ground truth pairs are provided. It is called in-context learning because it fits the standard machine learning paradigm of using a set of training data $\left{\left(x_{i}, y_{i}\right)\right}<em k_1="k+1">{i=1}^{k}$ to make predictions on hold-out data $x</em>$. Importantly, performance at in-context learning improves with model scale [15, 124], implying that methods relying upon this capability will benefit from continuing progress in LLM training. This paper highlights how the in-context learning capabilities of autoregressive LLMs (such as the popular GPT architecture) naturally enable a recombination operator. The next section reviews existing methods for intelligent variation in evolutionary computation.</p>
<h1>2.2 Intelligent Variation Operators</h1>
<p>Populations in evolutionary algorithms (EAs) generally evolve through high-performing candidate solutions being mutated or recombined to form the next generation. Such variation is critical as a primary driver of both exploration and exploitation of the search space [27]. Given the space of all candidate solutions $\mathcal{X}$, a genetic variation operator $g$ is a (usually stochastic) function that generates a child solution $x \in \mathcal{X}$ given a set of parent solutions $X \subset \mathcal{X}$. Since $g(X)$ induces a distribution over candidates, we can write</p>
<p>$$
x \sim g(X)
$$</p>
<p>If $|X|=1$ we call $g$ a mutation operator; if $|X|&gt;1$ we call $g$ a recombination or crossover operator. A solution $x$ is called a genotype since it is in the space where genetic operators are applied. An encoding $E: \mathcal{X} \rightarrow \mathcal{Y}$ maps a genotype $x$ to a phenotype $y$, so that its fitness $f(y)=f(E(x))$ can be evaluated with a fitness function $f: \mathcal{Y} \rightarrow \mathbb{R}$. Traditional mutation and crossover operators (such as one-point crossover or bit-flip mutation) do not explicitly seek to model and exploit regularities among high-fitness individuals (or do so in an implicit way [47, 76]), which can cause EAs to be relatively sample-inefficient in some situations when compared to statistical methods [116].</p>
<p>To address this limitation, strategies for generating intelligent variation have been a focus of much EA research. For example, evolving within the latent space of an ML model [35, 36, 92, 102], through training models to mimic mutations [53, 63], or code repair operators that draw on knowledge about the program's existing correct behaviors and integrate fault localization techniques to guide operators toward promising regions of improvement [62]. Such methods are intelligent in the sense that they autonomously draw on prior knowledge outside of the scope of the parent genomes in order to better generate promising child solutions.</p>
<p>One particularly popular such strategy is to build probabilistic models of high-performing individuals or to model elements of the search path taken across recent generations. For example, estimation of distribution algorithms (EDA; [3, 60]), covariance matrix adaptation evolution strategy (CMA-ES; [43]), and natural evolution strategies (NES; [125]) build and sample candidate solutions from an explicit probability distribution. While EDAs estimate the distribution of the solutions that have been sampled, CMA-ES additionally estimates the steps of the search direction. The LMX operator in this paper can be seen similarly as building a probabilistic model of individuals (here of parents, rather than the whole population), and doing so implicitly in the forward-pass of the LLM (through in-context learning).</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th>Date</th>
<th>Title</th>
<th>Model</th>
<th>Model Usage</th>
<th>Training Data</th>
</tr>
</thead>
<tbody>
<tr>
<td>2014</td>
<td>A Denoising Autoencoder that Guides Stochastic Search [22]</td>
<td>DAE</td>
<td>Solution Encoding</td>
<td>Current Run</td>
</tr>
<tr>
<td>2015</td>
<td>Denoising Autoencoders for Fast Combinatorial Black Box Optimization [89]</td>
<td>DAE</td>
<td>Solution Generation</td>
<td>Current Run</td>
</tr>
<tr>
<td>2018</td>
<td>Learning an Evolvable Genotype-Phenotype Mapping [77]</td>
<td>AE, DAE</td>
<td>Solution Encoding</td>
<td>Previous Runs</td>
</tr>
<tr>
<td>2018</td>
<td>Expanding Variational Autoencoders for Learning and Exploiting Latent Representations in Search Distributions [37]</td>
<td>VAE</td>
<td>Solution Generation</td>
<td>Current Run</td>
</tr>
<tr>
<td>2019</td>
<td>Estimation of Distribution using Population Queue based Variational Autoencoders [6]</td>
<td>VAE</td>
<td>Solution Generation</td>
<td>Current Run</td>
</tr>
<tr>
<td>2020</td>
<td>Harmless Overfitting: Using Denoising Autoencoders in EDAs [90]</td>
<td>DAE</td>
<td>Solution Generation</td>
<td>Current Run</td>
</tr>
<tr>
<td>2020</td>
<td>DAE-GP: Denoising Autoencoder LSTM Networks as Probabilistic Models in Estimation of Distribution Genetic Programming [127]</td>
<td>DAE</td>
<td>Solution Generation</td>
<td>Current Run</td>
</tr>
<tr>
<td>2022</td>
<td>Using Denoising Autoencoder Genetic Programming to Control Exploration and Exploitation in Search [126]</td>
<td>DAE</td>
<td>Solution Generation</td>
<td>Current Run</td>
</tr>
<tr>
<td>2022</td>
<td>Evolving through the looking glass: Learning Improved Search Spaces with Variational Autoencoders [4]</td>
<td>VAE</td>
<td>Solution Encoding</td>
<td>Previous Runs</td>
</tr>
<tr>
<td>2022</td>
<td>Evolution through Large Models [63]</td>
<td>LLM</td>
<td>Instructed Mutation</td>
<td>Foundation Model + Past Runs</td>
</tr>
<tr>
<td>2023</td>
<td>Language Model Crossover: Variation through Few-Shot Prompting (arsis) [2]</td>
<td>LLM</td>
<td>Solution Generation</td>
<td>Foundation Model</td>
</tr>
<tr>
<td>2023</td>
<td>Evoprompting: Language Models for Code-Level Neural Architecture Search [16]</td>
<td>LLM</td>
<td>Solution Generation, Instructed Mutation</td>
<td>Foundation Model + Current Run</td>
</tr>
<tr>
<td>2023</td>
<td>MarioGPT: Open-Ended Text2Level Generation through Large Language Models [112]</td>
<td>LLM</td>
<td>Instructed Mutation</td>
<td>Foundation Model</td>
</tr>
<tr>
<td>2023</td>
<td>Wizardlm: Empowering Large Language Models to Follow Complex Instructions [130]</td>
<td>LLM</td>
<td>Instructed Mutation</td>
<td>Foundation Model</td>
</tr>
<tr>
<td>2023</td>
<td>Fully Autonomous Programming with Large Language Models [69]</td>
<td>LLM</td>
<td>Instructed Mutation</td>
<td>Foundation Model</td>
</tr>
<tr>
<td>2023</td>
<td>LLMatic: Neural Architecture Search via Large Language Models and Quality-Diversity Optimization [82]</td>
<td>LLM</td>
<td>Instructed Mutation</td>
<td>Foundation Model</td>
</tr>
<tr>
<td>2023</td>
<td>Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution [34]</td>
<td>LLM</td>
<td>Solution Generation, Instructed Mutation</td>
<td>Foundation Model</td>
</tr>
<tr>
<td>2023</td>
<td>Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers [41]</td>
<td>LLM</td>
<td>Instructed Mutation</td>
<td>Foundation Model</td>
</tr>
<tr>
<td>2023</td>
<td>Large Language Models as Optimizers [131]</td>
<td>LLM</td>
<td>Instructed Mutation</td>
<td>Foundation Model</td>
</tr>
<tr>
<td>2023</td>
<td>Eureka: Human-Level Reward Design via Coding Large Language Models [72]</td>
<td>LLM</td>
<td>Instructed Mutation</td>
<td>Foundation Model</td>
</tr>
<tr>
<td>2023</td>
<td>Large Language Model for Multi-Objective Evolutionary Optimization [67]</td>
<td>LLM</td>
<td>Instructed Mutation</td>
<td>Foundation Model</td>
</tr>
<tr>
<td>2023</td>
<td>Algorithm Evolution using Large Language Models [68]</td>
<td>LLM</td>
<td>Instructed Mutation</td>
<td>Foundation Model</td>
</tr>
<tr>
<td>2023</td>
<td>Mathematical Discoveries From Program Search with Large Language Models [96]</td>
<td>LLM</td>
<td>Solution Generation</td>
<td>Foundation Model</td>
</tr>
</tbody>
</table>
<p>Table 1. Evolutionary Recombination with Deep Generative Models. This table characterizes, in chronological order, the use of generative machine learning models in evolutionary recombination. Models include Autoencoders (Green), Denoising Autoencoders (Blue), Variational Autoencoders (Red), and Large Language Models (Orange). Model Usage encompasses Solution Encoding (Purple)â€”where models serve as a mapping from genotype to phenotype, Solution Generation (Brown)â€”where genotypes are directly sampled from the model, and Instructed Mutation (Yellow)â€”mutation guided by predefined prompts. Training Data details the data source for model training: Current Run (Darker Blue) indicates models trained on data from the current optimization run, Previous Runs (Light Blue) on data from past runs, Foundation Model (Dark Green) utilizes a large, general-purpose pre-trained model, and Foundation Model + Current Run (Gold) denotes a pre-trained model fine-tuned with current run (or past run) results. The burst of approaches using LLMs and evolution in 2023 highlights a shift towards pre-existing models and prompting, along with a surge of interest in both the machine learning and evolutionary algorithms communities.</p>
<h1>2.3 Evolution with Deep Generative Models</h1>
<p>Over the past decade, deep generative models have been explored as a method to aid evolutionary search (see Table 1). EDA approaches have leveraged autoencoders [46] to define distributions based on high-performing solutions identified during the search process. Autoencoders are used either as solution encodings which convert raw genotypes into phenotypes that align with the learned distribution; or as a mechanism for solution generation, with new solutions drawn directly from the established distribution.</p>
<p>The advent of large, pre-trained Foundation Models marks a significant step in this paradigm and has caused a flurry of exploration. Unlike traditional approaches that necessitate training models on solutions generated during the search, these advanced models can be directly leveraged, with distributions defined via strategic prompting. Foundation Models, particularly LLMs, bring a nuanced understanding of grammar and domain-specific patterns, enabling search across more abstract spaces, such as narratives [11] and high level programming languages [96]. This innovation introduces a novel dimension to search directionality through 'instructed mutation' - a method where instruction prompts guide the mutation process, offering an unprecedented level of natural-language-based control and specificity.</p>
<p>However, even without instructed mutation, Foundation Models contain an innate propensity to generate variation, due to their fundamental capacities as probabilistic pattern completion engines. The distribution from which new solutions are sampled can still be defined using top performing solutions from the population - but by providing multiple solutions directly to the model as a prompt, without explicit instruction that they be modified, and without retraining. The present work explores this fundamental approach.</p>
<h1>3 APPROACH: LANGUAGE MODEL CROSSOVER (LMX)</h1>
<p>The approach in this paper builds from the insight that the objective function used to train many self-supervised LLMs, i.e. next-token prediction [13], naturally lends itself to creating an evolutionary variation operator, from which evolutionary algorithms that represent genomes as text can be derived. The reason is that such an objective entails anticipating what comes next from some limited input context, and if that input consists of a few example genotypes, then the ideal anticipation is to continue that pattern, i.e. through suggesting a new genotype from the distribution implied by those examples. In other words, LLMs trained by next-token prediction can be seen as learning to become general pattern-completion engines. From this lens, as higher-performing LLMs (i.e. those with lower prediction loss on a held-out set) are continually developed, their performance as engines of evolutionary variation should continue to improve. Supporting this idea, when trained over a large amount of diverse examples, LLMs demonstrate an increasing capability for in-context learning (i.e. inferring novel associations within the input given at test-time when generating completions) [13, 15, 124].</p>
<p>What is intriguing about this insight is that the variation operator it suggests is (1) simple to implement (i.e. concatenate a few text-based genotypes into a prompt, run it through an LLM, and extract a new genotype from its output; we release code implementing it accompanying this paper), (2) relatively domain-independent (i.e. in theory it should be capable of generating meaningful variation for any text representation that has moderate support in the training set, which often encompasses an enormous crawl of the internet), and (3) should suggest increasingly semantically-sophisticated variation with more capable LLMs (i.e. an LLM that is generally better at predicting the next token in text will generate outputs in a manner that implies that it has a deeper semantic understanding of the input text). The experiments that follow add supporting evidence to these claims.</p>
<p>Figure 1 shows from a high level how LMX enables creating a domain-independent evolutionary algorithm for text representations. The basic idea is that given a set of a few text-based genotypes (or bootstrapping from a single genotype using prompt-based mutation [63]), an initial population can be generated through LMX. Then, a standard evolutionary loop can be instantiated by repeated selection and generation of new variation through LMX (See Algorithm 1).</p>
<p>Formally, the approach is grounded in a direct generalization of Eq. 3, namely, that providing a prompt of examples from a distribution can condition the LLM to generate further high-probability examples from that distribution. So, if we</p>
<div class="codehilite"><pre><span></span><code><span class="n">Algorithm</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">Evolutionary</span><span class="w"> </span><span class="n">Algorithm</span><span class="w"> </span><span class="n">using</span><span class="w"> </span><span class="n">LMX</span><span class="o">.</span><span class="w"> </span><span class="n">Lines</span><span class="w"> </span><span class="mi">7</span><span class="o">-</span><span class="mi">9</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">essense</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">LMX</span><span class="o">.</span>
<span class="w">    </span><span class="n">Given</span><span class="w"> </span><span class="n">LLM</span><span class="p">,</span><span class="w"> </span><span class="n">population</span><span class="w"> </span><span class="n">size</span><span class="w"> </span>\<span class="p">(</span><span class="n">n</span>\<span class="p">),</span><span class="w"> </span><span class="n">parents</span><span class="w"> </span><span class="n">per</span><span class="w"> </span><span class="n">crossover</span><span class="w"> </span>\<span class="p">(</span><span class="n">k</span>\<span class="p">),</span><span class="w"> </span><span class="n">fitness</span><span class="w"> </span><span class="n">function</span><span class="w"> </span>\<span class="p">(</span><span class="n">f</span>\<span class="p">)</span>
<span class="w">    </span><span class="n">Initialize</span><span class="w"> </span><span class="n">population</span><span class="w"> </span>\<span class="p">(</span><span class="n">P</span>\<span class="p">)</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">random</span><span class="w"> </span><span class="n">text</span><span class="o">-</span><span class="n">based</span><span class="w"> </span><span class="n">individuals</span>
<span class="w">    </span><span class="k">while</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">done</span><span class="w"> </span><span class="n">evolving</span><span class="w"> </span><span class="n">do</span>
<span class="w">        </span>\<span class="p">(</span><span class="n">P_</span><span class="p">{</span>\<span class="n">text</span><span class="w"> </span><span class="p">{</span><span class="n">new</span><span class="w"> </span><span class="p">}}</span><span class="o">=</span>\<span class="n">varnothing</span>\<span class="p">)</span>
<span class="w">        </span><span class="k">while</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">left</span><span class="o">|</span><span class="n">P_</span><span class="p">{</span>\<span class="n">text</span><span class="w"> </span><span class="p">{</span><span class="n">new</span><span class="w"> </span><span class="p">}}</span>\<span class="n">right</span><span class="o">|&lt;</span><span class="n">n</span>\<span class="p">)</span><span class="w"> </span><span class="n">do</span>
<span class="w">            </span>\<span class="p">(</span><span class="n">x_</span><span class="p">{</span><span class="mi">1</span><span class="p">},</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">,</span><span class="w"> </span><span class="n">x_</span><span class="p">{</span><span class="n">k</span><span class="p">}</span><span class="w"> </span>\<span class="n">leftarrow</span>\<span class="p">)</span><span class="w"> </span><span class="n">randomly</span><span class="w"> </span><span class="n">choose</span><span class="w"> </span>\<span class="p">(</span><span class="n">k</span>\<span class="p">)</span><span class="w"> </span><span class="n">individuals</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span>\<span class="p">(</span><span class="n">P</span>\<span class="p">)</span>
<span class="w">            </span>\<span class="p">(</span>\<span class="n">operatorname</span><span class="p">{</span><span class="n">prompt</span><span class="p">}</span><span class="w"> </span>\<span class="n">leftarrow</span><span class="w"> </span><span class="n">x_</span><span class="p">{</span><span class="mi">1</span><span class="p">}</span><span class="w"> </span>\<span class="n">backslash</span><span class="w"> </span>\<span class="n">mathrm</span><span class="p">{</span><span class="n">n</span><span class="p">}</span><span class="w"> </span><span class="n">x_</span><span class="p">{</span><span class="mi">2</span><span class="p">}</span><span class="w"> </span>\<span class="n">backslash</span><span class="w"> </span>\<span class="n">mathrm</span><span class="p">{</span><span class="n">n</span><span class="p">}</span><span class="w"> </span>\<span class="n">ldots</span><span class="w"> </span>\<span class="n">backslash</span><span class="w"> </span>\<span class="n">mathrm</span><span class="p">{</span><span class="n">n</span><span class="p">}</span><span class="w"> </span><span class="n">x_</span><span class="p">{</span><span class="n">k</span><span class="p">}</span>\<span class="p">)</span>
<span class="w">            </span><span class="n">output</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">leftarrow</span><span class="w"> </span>\<span class="n">mathrm</span><span class="p">{</span><span class="n">LLM</span><span class="p">}(</span>\<span class="p">)</span><span class="w"> </span><span class="n">prompt</span><span class="w"> </span>\<span class="p">()</span>\<span class="p">)</span>
<span class="w">            </span><span class="n">children</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">leftarrow</span>\<span class="p">)</span><span class="w"> </span><span class="n">extract</span><span class="w"> </span><span class="n">valid</span><span class="w"> </span><span class="n">candidates</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">output</span>
<span class="w">            </span>\<span class="p">(</span><span class="n">P_</span><span class="p">{</span>\<span class="n">text</span><span class="w"> </span><span class="p">{</span><span class="n">new</span><span class="w"> </span><span class="p">}}</span><span class="w"> </span>\<span class="n">leftarrow</span><span class="w"> </span><span class="n">P_</span><span class="p">{</span>\<span class="n">text</span><span class="w"> </span><span class="p">{</span><span class="n">new</span><span class="w"> </span><span class="p">}}</span><span class="w"> </span>\<span class="n">cup</span>\<span class="p">)</span><span class="w"> </span><span class="n">children</span>
<span class="w">        </span><span class="n">end</span><span class="w"> </span><span class="k">while</span>
<span class="w">        </span>\<span class="p">(</span><span class="n">P</span><span class="w"> </span>\<span class="n">leftarrow</span><span class="w"> </span><span class="n">P</span><span class="w"> </span>\<span class="n">cup</span><span class="w"> </span><span class="n">P_</span><span class="p">{</span>\<span class="n">text</span><span class="w"> </span><span class="p">{</span><span class="n">new</span><span class="w"> </span><span class="p">}}</span>\<span class="p">)</span>
<span class="w">        </span>\<span class="p">(</span><span class="n">P</span><span class="w"> </span>\<span class="n">leftarrow</span>\<span class="p">)</span><span class="w"> </span><span class="n">refine</span><span class="w"> </span>\<span class="p">(</span><span class="n">P</span>\<span class="p">)</span><span class="w"> </span><span class="n">down</span><span class="w"> </span><span class="n">to</span><span class="w"> </span>\<span class="p">(</span><span class="n">n</span>\<span class="p">)</span><span class="w"> </span><span class="n">individuals</span><span class="w"> </span><span class="n">using</span><span class="w"> </span>\<span class="p">(</span><span class="n">f</span>\<span class="p">)</span>
<span class="w">    </span><span class="n">end</span><span class="w"> </span><span class="k">while</span>
</code></pre></div>

<p>have examples $x_{i} \sim \mathcal{X}$, then</p>
<p>$$
\operatorname{Pr}\left[\psi\left(\operatorname{LLM}\left(\phi\left(\left[x_{1}, \ldots, x_{k}\right]\right)\right)\right) \mid \mathcal{X}\right]&gt;\operatorname{Pr}\left[\psi\left(\operatorname{LLM}\left(\phi\left(\left[x_{1}\right]\right)\right)\right) \mid \mathcal{X}\right]&gt;\operatorname{Pr}\left[\psi\left(\operatorname{LLM}(\phi(\mid}])\right) \mid \mathcal{X}\right]
$$</p>
<p>Eq. 5 is applied to the evolutionary context by letting $x_{1}, \ldots, x_{k}$ be a set of parent genotypes and $\mathcal{X}$ a distribution of (relatively) high-performing genotypes. So, Lines 7-9 of Algorithm 1 are an instance of the general formulation of LMX:</p>
<p>$$
\operatorname{LMX}\left(x_{1}, \ldots, x_{k}\right)=\psi\left(\operatorname{LLM}\left(\phi\left(\left[x_{1}, \ldots, x_{k}\right]\right)\right)\right)
$$</p>
<p>This connection to $k$-shot prompting suggests that, at least in the case of a pre-trained LLM, recombination or crossover (i.e., $k&gt;1$ ) will be more effective than mutation $(k=1)$ or random sampling $(k=0)$. The resulting genetic operator is intelligent in the sense that, given a set of parents, it uses in-context learning (powered by the knowledge encoded in the LLM) to build a model of high-quality solutions, instead of directly searching in low-level genotype space.</p>
<p>In the experiments that follow, we use simple genetic algorithms (GAs; although one experiment instantiates a simple quality diversity algorithm). In theory, however, LMX can be generically applied to most EAs, e.g. multi-objective EAs [23, 29], evolutionary strategies [1, 5], or in support of open-ended evolution [121], but simply swapping it in as the genetic variation operator. How or if LMX can be applied in EAs that explicitly leverage probabilistic models of genotypes (e.g. EDAs [3, 60], natural evolution strategies [125], or CMA-ES [42, 43]) is an interesting question for future research (Section 7), although LMX does bear a theoretical relationship to EDAs, as explored in Section 5.</p>
<h1>4 EXPERIMENTS</h1>
<p>This section demonstrates the application of LMX to five domains, to investigate the basic properties of the method and illustrate the breadth of its applicability. Table 2 gives an overview of the experiments. Section 4.1 applies LMX to a toy domain to confirm the basic properties of the method; Section 4.2 applies LMX to symbolic regression, to show how evolving text representations with LMX can be effective in domains not classically represented as text; Section 4.3 applies LMX in its most natural setting: evolving well-formed natural-language sentences, while also showing how the method can be naturally integrated with other NLP components and QD algorithms; Section 4.4 applies LMX to evolving text prompts for image generation, a domain that further highlights the plug-and-play capability of LMX with other deep generative models, while enabling a comparison to zero-shot generation and where naive evolution of</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Section</th>
<th style="text-align: left;">Domain</th>
<th style="text-align: left;">Genotype</th>
<th style="text-align: left;">Phenotype</th>
<th style="text-align: left;">LLM</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">4.1</td>
<td style="text-align: left;">Binary Strings</td>
<td style="text-align: left;">text</td>
<td style="text-align: left;">binary strings</td>
<td style="text-align: left;">Pythia-70M to 6.9B (eight models)</td>
</tr>
<tr>
<td style="text-align: left;">4.2</td>
<td style="text-align: left;">Symbolic Regression</td>
<td style="text-align: left;">text</td>
<td style="text-align: left;">math expressions</td>
<td style="text-align: left;">Pythia-1.4B, GALACTICA-1.3B</td>
</tr>
<tr>
<td style="text-align: left;">4.3</td>
<td style="text-align: left;">Modifying Sentiment</td>
<td style="text-align: left;">text</td>
<td style="text-align: left;">text</td>
<td style="text-align: left;">Pythia-1.4B</td>
</tr>
<tr>
<td style="text-align: left;">4.4</td>
<td style="text-align: left;">Image Generation</td>
<td style="text-align: left;">text</td>
<td style="text-align: left;">image</td>
<td style="text-align: left;">Pythia-2.8B</td>
</tr>
<tr>
<td style="text-align: left;">4.5</td>
<td style="text-align: left;">Sodaracers</td>
<td style="text-align: left;">text</td>
<td style="text-align: left;">Python functions</td>
<td style="text-align: left;">CodeGen-350M, 2B, 6B</td>
</tr>
</tbody>
</table>
<p>Table 2. Overview of experiments. In all domains, the genotype is text, since text is the substrate LMX evolves. In all domains except Modifying Sentiment, this text is converted to another form (phenotype) for evaluation. Section 4.1 evaluates the effect of LLM size within the Pythia family; Sections 4.3 and 4.4 use LLMs within that family; Sections 4.2 and 4.5 use LLMs that are more specialized to the domain. Taken together, the experiments demonstrate that LMX is a generic method of generating variation for evolution.
text is a strong baseline (due to the fact that text-to-image models are fairly agnostic to grammatical correctness); and, finally, Section 4.5 shows how LMX can be applied to generating Python code, clearly situating the method across this intersection of the genetic programming and LLM code-generation communities. Source code will be made publicly available for each domain.</p>
<h1>4.1 Illustrative Example: Binary Strings</h1>
<p>As an instructive example to explore the properties of LMX, in this section this operator is applied to generate variation in the space of binary strings (e.g. composed of text strings such as "011000"); first, to see whether LMX can generate meaningful and heritable variation (i.e. to create new valid binary strings from old ones, and that the new ones resemble the old ones); and then, to see whether LMX can successfully drive evolution of binary strings, in this case to maximize the number of 1 s (i.e. the OneMax problem, where the fitness function is the number of 1 s in a valid binary string).</p>
<p>A first question is whether a pretrained LLM (here an 800-million parameter Pythia model [7]), given only a few examples of such genomes, can generate meaningful variation (i.e. without any hard-coded knowledge about the representation). To explore this question, a prompt is generated by concatenating randomly chosen length-6 binary strings separated by newlines; the LLM's response (truncated after three new lines) is interpreted as three offspring individuals. Figure 2a shows how often such a prompt will generate valid individuals (i.e. strings of length six composed of 1 s and 0 s ) as a function of number of examples in the prompt, and how many novel offspring (i.e. the size of the set of individuals generated that are distinct from the parents) are generated on average from 20 trials of LMX crossover on the same set of parents (averaged across 20 randomly-sampled parent sets). A follow-up experiment, with length-9 binary strings, demonstrates how LMX in this domain improves with larger LLMs (details in appendix A.1; results shown in Figure 2b). The conclusion is that indeed, LMX can reliably generate novel, valid offspring (from as few as three examples).</p>
<p>A second question is whether LMX can create heritable variation. Evolution requires there to be meaningful information transmitted from parents to offspring. One way to explore this is to measure whether a prompt composed of highly-related binary strings produces novel but nearby offspring (e.g. as measured by edit distance). To test this, prompts were created by sampling the neighborhood around one of two reference strings (i.e. single-step mutations from either the all-ones or all-zeros string), and offspring were generated from the LLM. Indeed, offspring generated from the neighborhood of the all-ones string had significantly higher (Mann-Whitney U-test; $p&lt;0.001$ ) hamming distance from the all-zeros string than the all-ones string (and vice-versa; see Figure 3a).
Manuscript submitted to ACM</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2. The effect on LMX from varying the number of parents and LLM size. (a) As the number of parent genotypes input into the LLM is increased, the percent of valid offspring approaches $100 \%$. The number of novel genotypes generated on average from 20 applications of LMX (which at 3 offspring per application can result in at most 60 offspring) to a random set of parents reaches its maximum at four parents (while five parents tends to more often produce offspring that duplicate one of the parents exactly). The conclusion is that LMX effectively generates variation from as few as three input genotypes. (b) As the parameter count (i.e., number of weights trained with SGD) of the LLM is increased in the length-9 binary string domain, the percent of valid offspring and number of novel offspring (out of at most 60) also increase. The number of parents is fixed to 3 for this experiment. Note $m$ indicates millions of parameters, while $b$ indicates billions. The conclusion is that in this domain LMX becomes more effective with larger LLMs.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3. Heritability and convergence of LMX on binary strings. (a) The histogram shows the distribution of how far offspring are from the all 1 s string, depending on if parents are taken in the neighborhood of the all-1s or all-0s string. As expected these distributions are significantly different. The conclusion is that LMX indeed produces heritable variation. (b) Convergence results (median and IQR) for a simple genetic algorithm using either LMX or one-point crossover. Though fewer solutions converge on the optima using LMX the classical recombination (16/20 vs. 20/20), mean values are higher (Mann-Whitney $p=0.002$ ). Though not as efficient as a domain-specific operator, it is clear that LMX can indeed drive an evolutionary process.</p>
<p>A final instructive question is whether an evolutionary process can be successfully driven by LMX. To explore this, we test LMX in OneMax, i.e. evolving the all-1s string, in a simple genetic algorithm. A small population ( 10 individuals) of length 10 bit strings is initialized randomly. At each generation the top 5 solutions, plus the elite solution from any previous generations, are chosen as parents for recombination to form the next population. LMX recombination is compared to recombination via one point crossover with a $10 \%$ chance of a bit flip mutation. Figure 3b shows the median max/mean fitness values over 20 runs of each, clearly illustrating LMX's ability to drive an evolutionary process. Overall, these experiments highlight basic properties of LMX, showing how it can evolve string-based representations without domain-specific operators.</p>
<h1>4.2 Symbolic Regression</h1>
<p>To demonstrate LMX's potential in a more challenging task, this section applies the algorithm to symbolic regression, a key domain of interest for genetic programming [59, 74, 85, 100], and more recently for the larger machine learning community [8, 52, 58, 88]. The goal of symbolic regression is to discover a mathematical expression that models a data set accurately, while also being as compact as possible [58]. Beyond the usual benefits of regularization, compactness is desirable for interpretability of the expression, e.g., to enable scientific insights [51, 100, 117, 122].</p>
<p>Symbolic regression is challenging to tackle with hand-designed operators, due to non-locality and discontinuities in the space of expressions. Existing symbolic regression approaches use carefully-developed representations, genetic operators, and auxiliary methods like gradient-based/convex coefficient optimization [18, 55, 115] to construct the right kind of search process for reaching high-performing expressions that look like the kinds of expressions the experimenter is interested in. With LMX, these challenges can be avoided by simply feeding parent expressions into the language model. Note that this section does not aim to provide a comprehensive comparison against state-of-the-art-methods, but instead aims to show how LMX can be applied off-the-shelf to important domains with complex representations.
4.2.1 Experimental Setup. The LLM for this experiment was the 1.3B-parameter version of GALACTICA [114]. GALACTICA's training set was specifically designed to assist in scientific endeavors, and includes tens of millions of LaTeX papers, and thus many human-designed equations, making it an appropriate choice for symbolic regression. This choice also highlights how different off-the-shelf LLMs can be selected for LMX based on properties of the problem.</p>
<p>When the ground truth expression for symbolic regression is known, we run the risk that the expression is already in the dataset used to train the LLM. To avoid such test-set contamination, we consider a 'black-box' problem (which has no known ground-truth expression) from the established SRBench testbed [58]. The 'banana' problem was chosen because there is a clear Pareto front across existing methods, making it easy to see how LMX compares. This black-box problem was originally derived from a popular ML benchmark in the KEEL data set repository [31]; it has 5300 samples and two input features $x_{1}, x_{2}$.</p>
<p>In this experiment, crossover prompts began with the string "Below are 10 expressions that approximate the dataset: \n" followed by seven randomly selected parents from the population separated by newlines (see Figure 4 for examples). Each subsequent line generated by the model was interpreted as a possible offspring, interpreted as Python code, and simplified using sympy (as in the SRBench comparisons [58]). Up to three child expressions were accepted for each forward pass of the LLM. Each child was evaluated against the dataset, using $R^{2}$ for fitness; any child that could not be parsed or that raised an exception during evaluation was discarded. The same compactness/complexity measure was used as in SRBench, i.e., 'expression size': the number of nodes in the parse tree of the expression.</p>
<p>The initial population was constructed from 113 popular symbolic regression benchmarks ${ }^{1}$. The idea is that these benchmark expressions capture the distribution of the kinds of expressions humans want symbolic regression to discover, thereby avoiding the need to generate random expressions from scratch. To give each benchmark expression a greater chance of initial success, the initial population consisted of 1000 candidates, each generated by randomly selecting a benchmark expression and then randomly mapping its input variables $x_{1}^{\prime}, x_{2}^{\prime}, \ldots$ to the input variables $x_{1}, x_{2}$ in the test problem. Thereafter, the population size was set to 50 . Each generation the combined parent and child population was culled to 50 individuals via tournament selection and then 50 new children were generated. The algorithm was run for 5000 generations using a single GeForce RTX 2080 Ti GPU (which took roughly 100 hours).</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Below are 10 expressions that approximate the dataset:
sin(1.5<em>x1)</em>cos(0.5<em>x2)
$x 2 * * 2+x 2 * * 2+x 2+\operatorname{sin}(x 2)+\operatorname{sin}(x 2 * * 2)$
$1.5 * \exp (x 1)+5.0 * \cos (x 1)$
$x 1 * * 3 </em>(x 2-5) <em>(\operatorname{sin}(x 1) * * 2 * \cos (x 1)-1) * \exp (-x 1) * \sin (x 1) * \cos (x 1)$
$-2.1 * \sin (1.3 * x 2) * \cos (9.8 * x 1)+2$
$\sin (x 2 * * 2) * \cos (x 2)-5$
$\exp (-(x 1-1) * * 2) /(6.25 </em>(0.4 * x 1-1) * * 2+1.2)$
$\sin (2.1 * x 1) * \cos (0.9 * x 2)+6.5$
$1.5 * \sin (2.1 * x 1) * \cos (0.5 * x 2) * \exp (x 1)+5.5$
$\sin (0.5 * x 2) * \exp (x 2)-5$
$x 1 * * 2 <em>(x 2-5) </em>(2.1 * \sin (x 1) * * 2 * \cos (x 1)-1) * \exp (-x 1) * \sin (x 1) * \cos (x 1)$
$x 1 * * 2 <em>(x 2-5) * * 2 </em>(\sin (x 1) * * 2 * \cos (x 1)-1) * * 2 * \exp (-x 1) * * 2 * \sin (x 1) * * 2 * \cos (x 1) * * 2$</p>
<p>Answer:
Your code should be the same as your first line, but
$1.5 * \exp (x 1)+5.0 * \cos (x 1)$
should be
$1.5 * \exp (x 1) * \cos (x 1)+5.0$
as</p>
<p>Below are 10 expressions that approximate the dataset:
$x 1 * x 2 /((x 2-3) * * 2+1)$
$x 2 * * 2 /(10000 <em>((x 1-3) * * 2+(x 2-3) * * 2+4))$
$x 1 * * 2+x 2 * * 2$
$x 1 * x 2 /((x 1-3) * * 2+(x 2-3) * * 2+2)$
$(x 2-3) /((x 2-3) * * 2+1) * * 2$
$\exp (-x 1 * * 2)$
$x 1 * x 2 * * 2 /((x 1-3) * * 2+2)$
$(x 2-3) /((x 1-3) * * 2+1) * * 2$
$x 1 * x 2 * * 2 </em>((x 1-3) * * 2+(x 2-3) * * 2+2)$
$(x 2-3)+x 1+x 2 /((x 1-3) * * 2+(x 2-3) * * 2+1) * * 2$
$(x 2-3) * * 2+x 2 * 2 /(10000 *((x 1-3) * * 2+(x 2-3) * * 2+4))$
$(x 2-3) * * 2+x 1 * 2+x 1+x 2 /((x 1-3) * * 2+(x 2-3) * * 2+2)$
$x 2 /((x 1-3) * * 2+1) * * 2$
$x 1 * x 2 /((x 1-3) * * 2+(x 2-3) * * 2+2)$
$x 2 /(((x 1-3) * * 2+1) * * 2$</p>
<p>Below are 10 expressions that approximate the dataset:
sqrt $(x 1 * * 2+x 1+x 2+2 * * 2 * 2+1)+1)+1.5$
$x 1 * * 2+x 1 * x 2+2 * * 2 * * 2+1&lt;4000$
$x 1 * * 2+4 * * 2 * * 2+1&lt;400000000$
sqrt $(x 1 * * 2+x 1 * x 2+2 * * 2+1)+1) \leqslant 1.4740426350899773765$
$(x 1 * * 2+x 1 * x 2+1) * * 3 \leqslant 1.336395683282781841$
sqrt $(x 1 * * 2+x 1 * x 2+1200 * x 2 * * 2) \leqslant 1.1969521946187728419$
$\operatorname{sqrt}(x 1 * * 2+x 1 * x 2+3 * x 2 * * 2+1) \leqslant 2.068817213090777115$
$x 1 * * 2+x 1 * * 2+1&lt;2.407303205449004$
$(x 1 * * 2+x 1 * x 2+1) * * 2 \leqslant 1.529026864021614135$
$\operatorname{sqrt}(x 1 * * 2+x 1 * x 2+x 2+x 2+1)+1) \leqslant 3.425986639014800117$
$\operatorname{sqrt}(x 1 * * 2+x 1 * x 2+1) * * 4 \leqslant 7.639437278029600423$
$\operatorname{sqrt}(x 1 * * 2+x 1 * x 2+1200 * x 2 * *$</p>
<p>Below are 10 expressions that approximate the dataset:
-0.0005082377<em>cos $(x 2) * \cos (x 1-0.6) * \cos (x 2-0.6) * \cos (x 2-0.4)$
$2.6 * \cos (x 1+0.7) * \cos (x 2-0.7) * \cos (x 2+0.8)$
$2.4 * \cos (x 1+0.5) * \cos (x 2-0.6) * \cos (x 2+0.9)$
$-0.231 * \sin (x 1) * \cos (x 2+0.2) * \cos (x 2+0.5)$
$0.003898335144775358 * \sin (x 1+0.2) * \sin (x 2-0.5) * \cos (x 2+0.3)$
$2.2 * \cos (x 2) * * 2 * \cos (x 1+0.3) * \cos (x 2-0.8) * \cos (x 2-0.4)$
$2.4 * \cos (x 1+0.5) * \cos (x 2-0.3) * \cos (x 2+0.7)$
$2.6 * \cos (x 1+0.5) * \cos (x 2-0.4) * \cos (x 2+0.6)$
$-0.179 * \sin (x 1) * \cos (x 2+0.4) * \cos (x 2-0.8)$
$0.0014232921 * \sin (x 1+0.2) * \sin (x 2-0.6) * \cos (x 2+0.4)$
$2.4 * \cos (x 2) * * 2 * \cos (x 1+0.2) * \cos (x 2-0.8)$
-0.179</em>sin</p>
<p>Fig. 4. Four examples of LMX for symbolic regression. The prompt of seven parents is in blue; the LLM output parsed as (up to three) offspring is in violet; remaining discarded LLM output is in gray. In all cases, children exhibit meaningful variations of parents.</p>
<p>To contextualize the convergence behavior of LMX, gplearn (one of the most popular symbolic regression tools ${ }^{2}$ ) was run with hyperparameters previously used for SRBench [58]; as an ablation to evaluate the benefit of using an LLM specialized for scientific work, LMX was also run with a 1.4-billion parameter Pythia model ${ }^{3}$; as an ablation to assess</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 5. Example convergence trajectory. Fitness over time for a single run of LMX (Galactica) on the SRBench black-box 'banana' problem [58]. The expression with the highest fitness so far is plotted at several generations to illustrate the kinds of improvements evolution finds. Evolution settles on a core functional skeleton relatively quickly (i.e., $c_{1} e^{-c_{2} x_{1}^{c_{3}}-c_{6} x_{2}^{c_{3}}} \cos \left(x_{1}+c_{6} x_{2}+c_{7}\right)$, with $x_{1}, x_{2}$ input variables and $c_{1}$ constants), after which it tunes constants to a surprising specificity, while simultaneously tweaking and augmenting the skeleton. Even after the process appears to have converged, around generation 3000 it discovers innovations leading to further substantial improvements. This late boost highlights the ability of the LLM to be an engine of interesting and valuable hypotheses in mathematical/numerical spaces.
the impact of initialization vs. LMX itself, a version of gplearn was run with the same population initialization as LMX, by writing around 100 lines of complex custom code to translate the benchmark expressions to the format required by gplearn ${ }^{4}$. Ten independent runs were performed for each experimental setup.
4.2.2 Results. LMX produces competitive results, generating fit and parsimonous expressions. Figure 5 shows how fitness evolves over generations for one run of LMX, with the expression of highest fitness so far plotted at several generations to illustrate the kinds of improvements evolution finds. Interestingly, the method finds parsimonious expressions even though there is no explicit drive towards parsimony in the algorithm. An implicit drive towards parsimony is enforced by the maximum text size the model processes, which in this experiment was set to 500 tokens; prompts longer than this cannot produce offspring. Future work could investigate the effects of tuning this parameter or developing other methods for incorporating explicit drives towards parsimony (Section 7). Beyond discovering a useful algebraic scaffolding for the problem, LMX tunes constants to a surprising degree, indicating that the method is capable of continuous optimization, even though LLMs operate in a space of discrete tokens; this is an interesting ability that could also be further explored in future work (Section 7).</p>
<p>Figure 6 shows that LMX (using the GALACTICA LLM) achieves overall higher fitness and lower expression size than gplearn, and the choice of LLM appears to have a substantial impact, with the Pythia runs falling short of the others. This result highlights the value in being able to easily drop in a particular LLM that could be well-suited to a</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 6. Convergence comparison and LLM ablation. (a) In terms of number of fitness evaluations, LMX converges in a similar manner to gplearn, when Galactica is the underlying LLM. As an ablation, when Pythia is the LLM, performance is not as strong. This result highlights the value of being able to swap in different LLMs depending on the domain. (Line is median, shading is IQR) (b) LMX avoids model bloat as it incrementally improves fitness, thereby satisfying a key desirable property for SR. (c) Overall, the final expressions returned by LMX are of comparable quality to those of gplearn. The conclusion is that the general LMX approach can yield high-quality solutions even in highly specialized domains like SR.
given domain. Figure 6 also shows that the customized version of gplearn initialized in the same way as LMX does not improve over the standard gplearn. This result reinforces the idea that in classical GP methods the kinds of expressions that are easy to evolve may not be the kinds humans are most interested in, while LMX thrives in this space since the LLM is naturally familiar with human-designed expressions due to its training data. This bias towards human-designed expressions is also a natural bias against model bloat, since humans strive to design compact expressions.</p>
<p>Figure 7 shows that the performance of LMX on this problem is competitive with state-of-the-art methods [58], settling at an intermediate point along the Pareto front. However, unlike these other methods, which carefully consider model representations, genetic operators, distributions of synthetic functions, bloat, multiple objectives, etc., we simply ask an off-the-shelf language model to be the generator in a minimal evolutionary loop. Note that the claim here is not that LMX is better than these existing methods, but simply that it is able to evolve reasonable solutions. In particular, the comparison methods all used a fixed amount of CPU compute, while LMX uses GPU (See Section 6 for discussion of this distinction). That said, the results clearly show the ability of LMX, with little domain-specific tuning and an unsophisticated optimization loop, to nonetheless optimize symbolic expressions in an intuitive and desirable way.</p>
<h1>4.3 Modifying Sentence Sentiment</h1>
<p>LMX is next applied to evolve plain-text English sentences. While LMX could be applied in many ways to evolve sentences, the focus here is a form of natural language style transfer [50], i.e. to translate an input into a new style while maintaining as much as possible the spirit of the original. Such an application can be important in optimizing how ideas are communicated amongst humans, i.e. one may want to communicate specific content but in a style maximally amenable for a target recipient; this defines an optimization problem over text. In this proof-of-concept experiment, the task is to take a seed sentence, and maximally change its sentiment (i.e. how positive the sentence is) with minimal change to the sentence itself.</p>
<p>To do so, a simple quality-diversity evolutionary algorithm [65, 79] is applied that measures quality as maximizing the sentiment of a sentence and measures diversity as distance from the seed sentence. In particular, sentiment is measured through the "cardiffnlp/twitter-roberta-base-sentiment-latest" model hosted on HuggingFace, which is part of the TweetNLP project [14]; the network takes in a sentence, and outputs classification probabilities for whether the sentence is positive, negative, or neutral. The experiments focus on using the probability of a positive sentiment as</p>
<p>the fitness function (although see appendix C for results with negative sentiment as fitness). For measuring distance from the seed sentence, a separate neural network generates a 384-dimensional embedding of a sentence (in particular the "sentence-transformers/all-MiniLM-L6-v2" model, from the sentence transformer project [94]). Distance is then quantified as the Euclidean distance between the embeddings of a new individual and the seed sentence.</p>
<p>For the QD algorithm, we use MAP-Elites [79] with a 1D map (with 30 niches, spanning a distance of 0 to a distance of 1.5 from the seed sentence in the embedding space; at 0 distance the sentences are exactly the same, while at a distance of 1.5 no words may be shared). The algorithm is run independently on three pessimistic quotes: "Whenever a friend succeeds, a little something in me dies," from Gore Vidal, "Kids, you tried your best and you failed miserably. The lesson is, never try," from Homer Simpson, and Woody Allen's "Life is divided into the horrible and the miserable." Each run targets changing the sentiment of a single sentence (from negative to positive). To seed the initial MAP-Elites population for each run, we use LMX on the three initial quotes to generate 196 initial offspring. From there onwards, offspring for MAP-Elites are generated from LMX by one of two strategies for sampling individuals from the map: (1) randomly sampling three elites from the map (LMX), or (2) probabilistically selecting three elites from nearby cells (LMX-Near; the motivation is that nearby elites will generate more focused variation). MAP-Elites runs consist of 2500 evaluations each; to confirm that the evolutionary process generates quality solutions beyond the direct generative ability of the LLM, a baseline control is also tested that generates 2500 offspring only from the initial 3 seed sentences. Ten runs were conducted for each combination of sentence and method; each run took on the order of minutes on a Google Colab notebook.</p>
<p>Quantitatively, both LMX-Near and LMX achieved higher QD scores (sum of the fitnesses of all niches in the map) than the control for all three quotes (Mann-Whiteny U-test; $p&lt;1 e-5$ ), and were always able to discover high-sentiment sentences. Interestingly, LMX-Near and LMX performed significantly differently only for the Gore Vidal quote (LMXNear produced higher final QD-scores; Mann-Whitney U-test; $p&lt;0.05$ ). Future work is thus needed to determine whether there exist methods for robustly choosing parents for LMX more effectively (Section 7). QD score plots for the Homer Simpson quote is shown in Figure 8, and plots for the other quotes (and representative heatmaps of final MAP-Elites maps) are shown in Appendix C.</p>
<p>Qualitatively, evolution is generally able to find intuitive trade-offs between sentiment and distance from the original sentence. For example, Figure 9 shows the final map of elites from a representative run on the Homer Simpson quote (with LMX-Near), with some highlighted sentences. At sufficient distance from the original sentence, evolution often produces repetitive, unrelated text: e.g. "You are the best that ever happened to me! You are the best that ever happened Manuscript submitted to ACM</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 8. Modifying Simpsons Quote Sentiment. The plot compares LMX-Near, LMX, and the baseline control in increasing the positive sentiment of the quote: "Kids, you tried your best and you failed miserably. The lesson is, never try." LMX and LMX-Near do not perform significantly differently, but both significantly outperform the control. Example sentences of such runs are shown in appendix section C.1.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Fig. 9. Example pareto front from improving positivity of a negative quote. The plot shows non-dominated individuals from the final map of a representative run, across the tradeoff between distance from the seed sentence (as measured by an embedding model) and the probability of positive sentiment (as measured by a sentiment analysis model). The full table of final sentences is shown in appendix C.
to me! You are the best that ever happened to me!" Also, sometimes the method produces incoherent or grammaticallyflawed sentences, e.g. "you tried your best and you failed. The lesson is, you can never stop trying. Kids, you tried your best and you". Optimization pressure for coherence (i.e. to maintain high log-probability under a LLM), or better/larger sentiment models, might address these problems, as discussed in Section 7. The conclusion is that LMX can be used to discover solutions for natural language tasks like text style transfer; beyond sentiment other styles could be explored by using different NLP models as fitness functions, e.g. emotion-recognition NLP models [81].</p>
<h1>4.4 Evolving Stable Diffusion Images</h1>
<p>This section explores the application of LMX to another creative domain: evolving prompts for generative text-to-image models. Stable Diffusion ${ }^{5}$ is a publicly available latent diffusion model [95] that supports CLIP-guided [91] text-to-image</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>synthesis. Since Stable Diffusion's release, artists, researchers, and hobbyists have developed prompting practices, swapping tips for constructing text prompts to produce desired outputs [84]. For a human with a desired output, discovering an effective prompt defines an optimization problem over text. The research question here is whether LMX can effectively evolve Stable Diffusion prompts. The genotype for this experiment is a text string, the prompt fed into the Stable Diffusion model. Beyond allowing us to investigate how LMX interacts with other generative models, this domain enables comparison to two natural baselines (1) classical one-point crossover, and (2) zero-shot generation. (1) In contrast to other domains in this paper, even though the genotype is text, text-to-image models tend to be quite robust to grammatical errors and nonsense, so a one-point crossover that produces a mangled bag-of-words is a strong baseline. (2) If we have a particular criteria for an image in mind, we can simply prompt the LLM directly to produce a prompt for such an image, i.e., without providing any example (parent) prompts; since there are no examples, this is called zero-shot.</p>
<p>For all setups, the initial population is seeded by randomly choosing from a set of 80,000 human-designed Stable Diffusion prompts that were scraped from lexica.art. ${ }^{6}$ The phenotype is the image generated by feeding a given prompt to Stable Diffusion. We make Stable Diffusion deterministic by reseeding with a fixed PRNG seed before each image is generated, so a given prompt always produces the same image. The EA is the same as in Section 4.2; experimental details are in Appendix D. Three interpretable fitness functions are explored, maximizing respectively the "redness", "greenness" and "blueness" of an image. Redness is measured by excess red: the sum of the red channel of an RGB image, minus half the sum of the other two channels $(R-0.5 G-0.5 B)$. Excess green and excess blue are defined analogously. These functions are easy to calculate, correspond roughly to perceived image color (e.g., they are well studied in agricultural image processing [75]), and provide a proof-of-concept where performance can be visually verified at a glance. Three random seeds are selected to initialize the population for each color, giving a total of nine runs per method. Each run uses a population size of 50 for 100 generations, for a total of 5000 evaluations.</p>
<p>Given two parent prompts, the one-point crossover baseline splits the prompts on whitespace and chooses crossover points uniformly at random. LMX prompts consist of the header "List of text-to-image prompts for generating the most <color> image possible:" followed by lines "Prompt: <parent>" and finally an empty "Prompt:" for the LLM to fill in. The zero-shot baseline is the same, but with no parent prompts. Two additional comparisons were also run (1) LMX without the header, to ablate the impact of removing this basic knowledge about the problem, and (2) random human-designed prompts from the initial dataset, setting a baseline for the fitness we can expect without any generative or evolutionary process.</p>
<p>Figure 10a shows performance aggregated over nine runs (three seeds for each color for each method; normalized to $[0,1]$ based on the min and max fitness for each each seed; mean and std. err. shown) shows that LMX substantially outperforms the alternatives. One-point crossover is a strong baseline, with performance statistically similar to the 'no header' ablation, supporting the idea that the ability to naturally incorporate natural language problem specifications is a key advantage of LMX over classical EAs. The zero-shot baseline quickly stagnates, as it is unable to iteratively refine it's initial solutions; even randomly-selected human prompts eventually outperform it, as they have greater diversity; both these baselines far underperform the evolutionary methods. So, overall, it is the combination of evolution with the native linguistic capacity of LLMs that makes LMX excel. Figure 10b shows the highest-fitness prompts and corresponding images of LMX for each color. All three images have clearly optimized for the target color. All three</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Fig. 10. Image generation results. (a) Performance aggregated (mean and std. err.) over nine runs (three seeds for each color for each method; normalized to $[0,1]$ based on the min and max fitness for each each seed) shows that LMX substantially outperforms the alternatives. One-point crossover is a strong baseline, with performance statistically similar to the LMX - No Header ablation. The zero-shot baseline quickly stagnates, as it is unable to iteratively refine it's initial solutions; even Human Random solutions eventually outperform it, as they have greater diversity. (b) The highest-fitness prompts and corresponding images of LMX for each color all include the word "background", but vary in the length and detailed content, highlighting LMX's ability to discover diverse, non-obvious solutions.
prompts include the word "background", but vary in the length and kind of detailed content, highlighting LMX's ability to discover diverse, non-obvious solutions. The conclusion is that LMX can enable sensible evolution of images.</p>
<h1>4.5 LMX with Python Sodaracers</h1>
<p>Finally, to explore whether LMX can generate variation in code, we apply LMX to evolving Python programs in the Sodarace environment from Lehman et al. [63], which also explored evolving Python programs with LLMs (we leverage the OpenELM implementation of sodarace [12]). Sodarace is a 2D simulation of robots with arbitrary morphology constructed from Python functions (the genotype) which output a dictionary specifying joints and muscles, and how they are connected. A Sodaracer robot is instantiated from this dictionary and placed in the environment, and the distance travelled by the robot is used as our fitness function.</p>
<p>We evolve these programs with MAP-Elites [79], using the distance travelled by the generated Sodaracers in a simulation as the fitness and the morpology of the Sodaracer (height, width, and mass) as the dimensions of the behavior space (as in Lehman et al. [63]). We explore the effect on evolution from varying the number of parents that LMX uses to generate offspring (from one to three parents).</p>
<p>Seven pre-existing Sodarace programs were chosen as seeds (details in appendix E). To initialize the population for evolution, LMX was prompted across combinations of these seeds as parents. We randomize the order of seeds for each application of LMX, to control for variance in results from the order of programs in the prompt. The programs were all given the same Python function signature make_walker(): and then concatenated together in the prompt. Note that we begin each completion with this function signature to improve performance (experiments where the LLM prompt did not end with the function signature performed worse; see appendix E). The LLM output is then interpreted as a potential offspring Python program, to be evaluated in the Sodarace environment.</p>
<p>During evolution steps, we use the same procedure, but randomly select populated niches in the map to select from to build the prompt (as many niches are sampled as parents for each separate treatment), and choose the fittest individual in each niche. We experiment with three different-sized LLMs from the Salesforce CodeGen suite [83], a set of models trained on a large dataset of code in many languages, including Python.</p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Fig. 11. Sodaracer results. We show the results for varying numbers of parents in the LLM prompt and across LLM scale. (left) Number of niches filled in MAP-Elites. (center) Quality-Diversity scores (sum of the fitnesses of all niches in the map) (right) Validation rate (\%) for the generated Sodaracers. LMX generally benefits from more examples in its prompt, is able to produce reasonable variation, and often creates valid Sodarace mutations, highlighting its promise for evolving code.</p>
<p>We perform 10,000 evolutionary iterations (corresponding to 10,000 outputs from the language model, not all of which are valid programs) using 500 initialization iterations. We evaluate the performance of each experimental treatment by computing the percentage of valid programs, number of niches filled at the end of evolution, and the QD score at the end of evolution.</p>
<p>The results from these experiments are shown in Figure 11, showing that as the number of parents in the prompt increases, the diversity of offspring generally increases, as measured by the number of niches filled and the QD score (This effect is even more dramatic in the experiments where the LLM prompt did not end with the function signature-A single parent yields no valid offspring (see Appendix Figure 17)).</p>
<p>Furthermore, a significant proportion of generated offspring are valid Sodaracers (roughly $30 \%$ with the 6B model), highlighting the potential for evolution. Experiments with a single seed in the prompt can be viewed as a simple mutation operator (a different approach to the same end in Lehman et al. [63]). There is a clear trend in model size, showing that the 6B model can create higher fitness and more diverse Sodaracers, along with a slight trend towards an improved proportion of valid programs with model scale. These results therefore demonstrate the promise of LMX for evolving non-trivial Python code.</p>
<h1>5 WHAT MAKES LMX EFFECTIVE?</h1>
<p>The breadth of experiments in Section 4 show how LMX can serve as a simple and general method for evolution across a range of domains. This section presents some perspectives on where the effectiveness of LMX could come from, including its connection to EDAs and how it could serve as a starting point for more powerful future algorithms.</p>
<h3>5.1 Connection to EDAs</h3>
<p>An EDA constructs an explicit probabilistic distribution $D$ fit to the parent set $\left{x_{1}, \ldots, x_{M}\right}$, and samples child solutions $x$ from $D[45,61]$. In contrast, a standard GA generates children by sampling from an implicit conditional probability distribution $p_{g}\left(x \mid\left[x_{1}, \ldots, x_{M}\right]\right)$ induced by the process of randomly sampling parents and applying a stochastic reproduction operator $g$ (e.g., a crossover operator; Eq. 4). LMX occupies an intermediate level of explicitness: The conditional distribution induced by feeding the parent prompt into the LLM is explicit in that it yields a series of probability distributions over tokens, and the probability of any output sequence can be directly computed, but is Manuscript submitted to ACM</p>
<p>implicit in the sense that the internal workings of the distribution are encoded opaquely within the millions or billions of parameters and activations of the LLM for a given prompt.</p>
<p>Whatever the level of explicitness, LMX acts like an EDA in that it builds a probabilistic model of parents, from which children are then sampled. This connection is most clear when LMX takes as input the full population of $n$ potential parents. Let $S_{n}$ be a selection operator that refines a collection of $N&gt;n$ candidates down to $n$ (as in Line 13 of Alg. 1).</p>
<p>Theorem 5.1 (EDA Representation). LMX and $S_{n}$ are sufficient operators to define an EDA.
Proof. Let $P_{t}$ denote the current population at iteration $t$ (as when entering the loop at Line 5 in Alg. 1). Then,</p>
<p>$$
P_{t+1}=S_{n} \circ\left{x_{i} \sim \operatorname{LMX}\left(P_{t}\right)\right}_{i=1}^{N&gt;n}
$$</p>
<p>denotes an algorithm (akin to the loop in Alg. 1) in which at each iteration the next population is constructed by sampling $N$ candidates from LMX conditioned on all of $P_{t}$ and then refining down to $n$ candidates via $S_{n}$. Using Eq. 6,</p>
<p>$$
\begin{aligned}
P_{t+1} &amp; =S_{n} \circ\left{x_{i} \sim \psi\left(\operatorname{LLM}\left(\phi\left(P_{t}\right)\right)\right)\right}<em n="n">{i=1}^{N&gt;n} \
&amp; =S</em>} \circ \psi \circ \beta_{N} \circ \operatorname{LLM<em t="t">{o} \circ \phi\left(P</em>\right)
\end{aligned}
$$</p>
<p>where $\beta_{N}$ is the autoregressive sampling operation (Eq. 2) applied multiple times to generate $N$ candidates. Rotating the recursive composition to the left yields</p>
<p>$$
D_{t+1}=\operatorname{LLM}<em n="n">{o} \circ \phi \circ S</em>\right)
$$} \circ \psi \circ \beta_{N}\left(D_{t</p>
<p>where $D_{t}$ defines the distribution (i.e., model) that candidates are sampled from at iteration $t$. Then, $\alpha=\operatorname{LLM}<em N="N">{o} \circ \phi$ is a model-building operator called only once per iteration that constructs a probabilistic model from a set of solutions, and $\beta=\psi \circ \beta</em>$, we have}$ is a sampling operator that samples new solutions from a model. So, along with the selection operator $S=S_{n</p>
<p>$$
D_{t+1}=\alpha \circ S \circ \beta\left(D_{t}\right)
$$</p>
<p>which is the functional form of an EDA.</p>
<p>The key design feature of an EDA is the class of distributions $\mathcal{D}$ to which $D$ belongs. This class $\mathcal{D}$ can range from simple univariate distributions [3, 44] to more complex models like Bayesian networks [86, 87]. What is the class $\mathcal{D}<em _mathrm_LM="\mathrm{LM">{\mathrm{LM}}$ from which LMX constructs parent distributions? Due to its in-context learning capabilities [97, 129], the LLM can be seen as attempting to infer underlying distribution of parents in the prompt, and to generate continuations accordingly. By concatenating parents in a random order, the implicit signal to the LLM is that the list is unordered. The LLM may notice some accidental patterns in the order, but, as the number of parents increases, e.g., when LMX processes the full population as in the EDA above, the significance of such spurious patterns diminishes and a well-trained LLM is more likely to perceive the order as random. These parents are text-based objects that must have been sampled from some ground truth distribution $D^{<em>}$, and thus the LLM's highest-probability action is to keep sampling objects from $D^{</em>}$ as it generates output. In other words $\mathcal{D}</em>}}$ consists of distributions of objects that are found in sets that might appear in the universe of data from which the dataset used to train the LLM was drawn. An ideal EDA would select the most probable $D=D_{\mathrm{EDA}}^{*} \in \mathcal{D<em 1="1">{\mathrm{LM}}$ based on the parent set $\left{x</em>\right}$. E.g.,}, \ldots, x_{k</p>
<p>$$
D_{\mathrm{EDA}}^{*}=\underset{D \in \mathcal{D}<em i="1">{\mathrm{LM}}}{\operatorname{argmax}} p(D) \prod</em> \mid D\right)
$$}^{k} p\left(x_{i</p>
<p>where $p(D)$ is the prior probability of $D$ in $\mathcal{D}_{\mathrm{LM}}$. As the LLM becomes a better and better in-context learner, it becomes better able to detect subtler patterns within a prompt of randomly-ordered concatenated parents, and thus</p>
<p>$$
\operatorname{LMX}\left(x_{1}, \ldots, x_{k}\right) \approx D_{\mathrm{EDA}}^{*}
$$</p>
<p>Note that the left side depends on an ordered list of parents, while the right side has removed this dependency on order.
We investigate this relationship and the conditions under which the approximation tightens using a simple bitstring case. Optimizing pseudo-Boolean functions using EDAs involves establishing the probability distribution of each bit containing a ' 1 ' or ' 0 '. The Univariate Marginal Distribution Algorithm [80], the prototypical EDA, samples $\lambda$ individuals each iteration, choosing the best $\mu$. The probability of a ' 1 ' in each position is then determined by the relative frequency of ' 1 's at that location in the selected population. In LMX a similar selection process is followed and, by prompting the model with the selected parents, a probability distribution is defined.</p>
<p>Despite the implicit definition in LMX, the probability distributions produced by LMX and an EDA can be directly compared. After prompting the LLM with the parent population, we can extract the probability distribution of a ' 1 ' or ' 0 ' before each token is generated. This provides an explicit probability distribution analogous to that of the EDA. In this way we can test the hypothesis that LMX approximates an EDA more closely as the size of the parent population increases. We examine the similarity of distributions with increasing populations in a six-bit case with the following procedure:
(1) For each bit in the string, the probability of it being a 1 or 0 is drawn uniformly at random from $[0,1]$.
(2) A set of parents is generated according to the distribution established in the previous step.
(3) Given this set of parents the mean absolute difference in the probability of a 0 for each gene between the resulting EDA and LMX distributions is calculated.
(4) The entire experiment is repeated with a different initial probability distribution.</p>
<p>When we examine the difference between the EDA and LMX distributions with an increasing number of parents (Figure 12), we find that indeed the disparity between the two distributions diminishes as the number of parents increases, i.e., LMX becomes more similar to the EDA.</p>
<p>Though a faithful application of an EDA may include the full parent population in each parent prompt, the experiments in Section 4 save compute by sampling only a small number of parents. Nonetheless, by comparing LMX to EDAs it may be possible to analyze the optimization behavior of LMX [57] (e.g., global convergence analysis [134]), as discussed in Section 7. Note that, as we are using a causal LLM, probabilities of each bit are not technically independent, but rather conditional on the previously generated bits in the genome as well as on the order of the parents. This nuanced scenario is also characteristic of more sophisticated EDAs that incorporate conditional dependencies [106]. Despite this confounding factor, it is clear that with a larger number of parents both approaches converge toward the same distribution - and this connection to EDAs may help to explain why LMX is effective as an off-the-shelf genetic operator across a wide range of domains.</p>
<h1>5.2 Universality of LMX</h1>
<p>Section 5.1 highlighted the connection between LMX and EDAs. This section explores another property of LMX, its theoretical universality (i.e. its ability in theory to express any genetic operator). With a sufficiently expressive class of model, such as Bayesian networks [86, 87], EDAs can approximate any candidate distribution as the size of the parent set increases [134]. Not only can LMX sample from distributions represented by an EDA, but it can in principle sample from Manuscript submitted to ACM</p>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Fig. 12. LMX and EDA Probability Distributions Across Different Sized Parent Sets. The average difference in gene probabilities predicted by LMX and EDA approaches 0 across various parent set sizes in a population of bit strings. Each parent set is generated by randomly setting the probability for each gene bit. The EDA gene probabilities are derived from the frequency of the gene values of the parents while the LMX gene probabilities are obtained from the language model's output logits (softmax applied with temperature $=1.0$ ). The Y-axis represents the mean absolute difference across all genes between the two methods' probability distributions. Error bars indicate the standard deviation over 20 experiments. The discrepancy between LMX and EDA probability predictions decrease with the number of parents.
any conditional probability distribution, making it universal in the space of genetic operators, even with small parent sets. Recent theoretical work has shown how crossover of large neural networks can yield universal approximation of reproduction distributions [76]. LMX also achieves theoretical universal approximation via large neural networks, but by feeding parents directly into the LLM, instead of crossing-over weights. If modification (e.g., fine-tuning) of LLM weights is permitted, this result follows naturally from the universal approximation ability of NNs [26, 48, 54] (note that this property also applies in the single-parent case for mutation-based evolution through LLMs [63]):</p>
<p>Theorem 5.2 (weight-based universality). For any genetic operator g on candidate space $\mathcal{X}$ and $\epsilon&gt;0$, if $\phi: 2^{\mathcal{X}} \rightarrow$ $V^{<em>}$ is injective, and $\psi: V^{</em>} \rightarrow \mathcal{X}$ is surjective, then $\exists$ an LLM s.t. for all parent sets $X$ of $g$ and children $x$</p>
<p>$$
|\operatorname{Pr}[x \mid g(X)]-\operatorname{Pr}[x \mid L M X(X)]|&lt;\epsilon
$$</p>
<p>Proof. $\operatorname{LMX}(X)=\psi(\operatorname{LLM}(\phi(X)))$. Since $\phi$ is injective, for all parent sets $X, \phi(X)=s_{X}$ is unique. Since $\psi$ is surjective, $\forall x \in \mathcal{X}, \exists s_{x}$ s.t. $\psi\left(s_{x}\right)=x$. Let $S_{x}=\left{s_{x}: \psi\left(s_{x}\right)=x\right}$. It suffices to find an LLM with weights such that</p>
<p>$$
|\operatorname{Pr}[x \mid g(X)]-\operatorname{Pr}\left[s_{x} \in S_{x} \mid \operatorname{LLM}\left(s_{X}\right)\right]|&lt;\epsilon
$$</p>
<p>The existence of such an LLM exists follows from the universal approximation capability of transformers [133].
However, when coupled with external memory, existing fixed pre-trained LLMs today, e.g., Flan-U-PaLM 540B [21], have been shown to implement universal Turing machines (UTMs) [38, 104], implying that universality can be achieved through effective prompting schemes, without altering LLM weights:</p>
<p>Theorem 5.3 (prompt-based universality). For any genetic operator g on candidate space $\mathcal{X}$ and $\epsilon&gt;0$, if the LLM is a UTM and $\psi$ is surjective, then $\exists \phi$ s.t. for all parent sets $X$ of $g$ and children $x$</p>
<p>$$
|\operatorname{Pr}[x \mid g(X)]-\operatorname{Pr}[x \mid L M X(X)]|&lt;\epsilon
$$</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{6}$ https://huggingface.co/datasets/Gustavosta/Stable-Diffusion-Prompts
Manuscript submitted to ACM&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>