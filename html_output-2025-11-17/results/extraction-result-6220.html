<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6220 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6220</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6220</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-122.html">extraction-schema-122</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of comparisons between LLM-as-a-judge and human evaluations, including reported differences, limitations, failure cases, and mitigation strategies.</div>
                <p><strong>Paper ID:</strong> paper-e81466aab95dfba46b27f5d24dd3d2860cad45cd</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/e81466aab95dfba46b27f5d24dd3d2860cad45cd" target="_blank">Empowering LLM-based Machine Translation with Cultural Awareness</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> A new data curation pipeline is introduced to construct a culturally relevant parallel corpus, enriched with annotations of cultural-specific entities, outper-forming traditional NMT systems in translating cultural-specific sentences.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6220.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6220.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of comparisons between LLM-as-a-judge and human evaluations, including reported differences, limitations, failure cases, and mitigation strategies.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4o-as-judge</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4o used as an automatic evaluator (LLM-as-a-judge) for pragmatic translation assessment</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper uses GPT-4o as an automatic judge to perform Pragmatic Translation Assessment (PTA) of culture-specific item (CSI) translations, comparing its judgments to a native human annotator and to other automatic metrics via Pearson correlation on a human-evaluated subset.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Machine translation — pragmatic evaluation of culture-specific item (CSI) translations (PTA), primarily English↔Chinese</td>
                        </tr>
                        <tr>
                            <td><strong>llm_judge_model</strong></td>
                            <td>GPT-4o (gpt-4o-2024-05-13)</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_setup</strong></td>
                            <td>Native Chinese speaker(s) (paper reports a single native Chinese annotator for the 200-sample subset; annotators for other steps are authors who are native speakers). The annotator(s) compared machine outputs and references on accuracy and PTA for 200 En→Zh examples drawn from eight MT systems (NLLB, LLaMA2, Google Translate, GPT-3.5 across multiple prompting settings). The human annotator used the same structured prompt/instructions as GPT-4o (one-sentence comparison + discrete Preferred: A/B/C).</td>
                        </tr>
                        <tr>
                            <td><strong>metrics_compared</strong></td>
                            <td>Pragmatic Translation Assessment (PTA) evaluated by GPT-4o and by human annotator(s); CSI-Match; traditional automatic metrics (BLEU/spBLEU, BLEURT, COMET, Exact-Match). Comparison primarily via Pearson correlation coefficients between each automatic metric and human judgements (separately for human accuracy and human PTA).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_differences</strong></td>
                            <td>GPT-4o PTA correlates very highly with human PTA (Pearson 0.957) and strongly with human accuracy (Pearson 0.871). CSI-Match had the highest correlation with human accuracy (0.887). Traditional metrics (BLEU, BLEURT, COMET, Exact-Match) showed lower correlations with human assessments than GPT-4o PTA (particularly for PTA). The authors therefore report that GPT-4o can serve as a reliable proxy for human PTA in English–Chinese CSI pragmatic evaluations on their subset.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_specific_limitations</strong></td>
                            <td>The authors note potential fairness issues with using GPT-4 as an evaluator, including internal biases and unbalanced language capabilities across languages/regions; limited validation beyond English–Chinese; and potential instability or systematic differences when evaluating low-resource languages or culturally specific content outside the model's strengths. They also acknowledge broader concerns about LLM evaluators' internal biases referenced in prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_failure_cases</strong></td>
                            <td>The paper does not present detailed, quantified examples of systematic disagreements between GPT-4o and the human annotator, but flags conceptual failure modes: (1) GPT-4/GPT-4o may exhibit internal biases and uneven language competence that could produce unfair or inconsistent judgments across languages and cultures; (2) evaluation was validated only on a 200-sample English–Chinese subset, so unobserved divergences may exist for other language pairs or for more diverse annotator populations. Example-level outputs in the paper show agreement on illustrative cases, but no breakdown of specific disagreement instances is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_strategies</strong></td>
                            <td>To mitigate mismatch and improve reliability the authors (1) used the same evaluation prompt/instructions for GPT-4o and human annotators to align judging criteria; (2) validated GPT-4o by computing Pearson correlations with human judgments on a held-out 200-sample En→Zh subset before using GPT-4o at scale; (3) set GPT-4o temperature to 0 for stable evaluator outputs; (4) recommend further investigation and caution, explicitly advising human post-editing for downstream deployment and calling for more validation across languages and annotator pools to address fairness and capability gaps.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Direct preference optimization: Your language model is secretly a reward model. <em>(Rating: 2)</em></li>
                <li>Large language models are state-of-the-art evaluators of translation quality. <em>(Rating: 2)</em></li>
                <li>Translate meanings, not just words: Idiomkb's role in optimizing idiomatic translation with language models. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6220",
    "paper_id": "paper-e81466aab95dfba46b27f5d24dd3d2860cad45cd",
    "extraction_schema_id": "extraction-schema-122",
    "extracted_data": [
        {
            "name_short": "GPT-4o-as-judge",
            "name_full": "GPT-4o used as an automatic evaluator (LLM-as-a-judge) for pragmatic translation assessment",
            "brief_description": "The paper uses GPT-4o as an automatic judge to perform Pragmatic Translation Assessment (PTA) of culture-specific item (CSI) translations, comparing its judgments to a native human annotator and to other automatic metrics via Pearson correlation on a human-evaluated subset.",
            "citation_title": "here",
            "mention_or_use": "use",
            "task_domain": "Machine translation — pragmatic evaluation of culture-specific item (CSI) translations (PTA), primarily English↔Chinese",
            "llm_judge_model": "GPT-4o (gpt-4o-2024-05-13)",
            "human_evaluation_setup": "Native Chinese speaker(s) (paper reports a single native Chinese annotator for the 200-sample subset; annotators for other steps are authors who are native speakers). The annotator(s) compared machine outputs and references on accuracy and PTA for 200 En→Zh examples drawn from eight MT systems (NLLB, LLaMA2, Google Translate, GPT-3.5 across multiple prompting settings). The human annotator used the same structured prompt/instructions as GPT-4o (one-sentence comparison + discrete Preferred: A/B/C).",
            "metrics_compared": "Pragmatic Translation Assessment (PTA) evaluated by GPT-4o and by human annotator(s); CSI-Match; traditional automatic metrics (BLEU/spBLEU, BLEURT, COMET, Exact-Match). Comparison primarily via Pearson correlation coefficients between each automatic metric and human judgements (separately for human accuracy and human PTA).",
            "reported_differences": "GPT-4o PTA correlates very highly with human PTA (Pearson 0.957) and strongly with human accuracy (Pearson 0.871). CSI-Match had the highest correlation with human accuracy (0.887). Traditional metrics (BLEU, BLEURT, COMET, Exact-Match) showed lower correlations with human assessments than GPT-4o PTA (particularly for PTA). The authors therefore report that GPT-4o can serve as a reliable proxy for human PTA in English–Chinese CSI pragmatic evaluations on their subset.",
            "llm_specific_limitations": "The authors note potential fairness issues with using GPT-4 as an evaluator, including internal biases and unbalanced language capabilities across languages/regions; limited validation beyond English–Chinese; and potential instability or systematic differences when evaluating low-resource languages or culturally specific content outside the model's strengths. They also acknowledge broader concerns about LLM evaluators' internal biases referenced in prior work.",
            "notable_failure_cases": "The paper does not present detailed, quantified examples of systematic disagreements between GPT-4o and the human annotator, but flags conceptual failure modes: (1) GPT-4/GPT-4o may exhibit internal biases and uneven language competence that could produce unfair or inconsistent judgments across languages and cultures; (2) evaluation was validated only on a 200-sample English–Chinese subset, so unobserved divergences may exist for other language pairs or for more diverse annotator populations. Example-level outputs in the paper show agreement on illustrative cases, but no breakdown of specific disagreement instances is reported.",
            "mitigation_strategies": "To mitigate mismatch and improve reliability the authors (1) used the same evaluation prompt/instructions for GPT-4o and human annotators to align judging criteria; (2) validated GPT-4o by computing Pearson correlations with human judgments on a held-out 200-sample En→Zh subset before using GPT-4o at scale; (3) set GPT-4o temperature to 0 for stable evaluator outputs; (4) recommend further investigation and caution, explicitly advising human post-editing for downstream deployment and calling for more validation across languages and annotator pools to address fairness and capability gaps.",
            "uuid": "e6220.0"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Direct preference optimization: Your language model is secretly a reward model.",
            "rating": 2
        },
        {
            "paper_title": "Large language models are state-of-the-art evaluators of translation quality.",
            "rating": 2
        },
        {
            "paper_title": "Translate meanings, not just words: Idiomkb's role in optimizing idiomatic translation with language models.",
            "rating": 1
        }
    ],
    "cost": 0.01190925,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Benchmarking Machine Translation with Cultural Awareness</h1>
<p>Binwei Yao ${ }^{1}$, Ming Jiang ${ }^{2}$, Tara Bobinac ${ }^{1}$, Diyi Yang ${ }^{3}$, Junjie Hu ${ }^{1}$<br>${ }^{1}$ University of Wisconsin-Madison, ${ }^{2}$ Indiana University Indianapolis, ${ }^{3}$ Stanford University<br>binwei.yao@wisc.edu, mj200@iu.edu, bobinac@wisc.edu<br>diyiy@stanford.edu, junjie.hu@wisc.edu</p>
<h4>Abstract</h4>
<p>Translating culture-related content is vital for effective cross-cultural communication. However, many culture-specific items (CSIs) often lack viable translations across languages, making it challenging to collect high-quality, diverse parallel corpora with CSI annotations. This difficulty hinders the analysis of cultural awareness of machine translation (MT) systems, including traditional neural MT and the emerging MT paradigm using large language models (LLM). To address this gap, we introduce a novel parallel corpus, enriched with CSI annotations in 6 language pairs for investigating Culturally-Aware Machine TranslationCAMT. ${ }^{1}$ Furthermore, we design two evaluation metrics to assess CSI translations, focusing on their pragmatic translation quality. Our findings show the superior ability of LLMs over neural MTs in leveraging external cultural knowledge for translating CSIs, especially those lacking translations in the target culture.</p>
<h2>1 Introduction</h2>
<p>Machine translation (MT) systems have achieved remarkable success in recent years, thanks in part to the pre-trained backbones of multilingual language models (Aharoni et al., 2019) and the availability of multilingual corpora (NLLB Team et al., 2022). Despite these advances, terminology translation remains challenging in both general contexts (Dinu et al., 2019) and specific domains like medicine and law (Ghazvininejad et al., 2023). Many existing MT studies on terminology translation have focused on breaking language barriers rather than cultural barriers, often assuming that literal (i.e., word-for-word) translation pairs already exist for the common knowledge shared by speakers of both the source and target languages (Anastasopoulos</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Culture-specific item translation errors.
et al., 2021). However, culture is deeply intrinsic to language, and language translation entails cross-cultural communication (Newmark, 1988; Fernández Guerra, 2012). Due to the diverse nature of knowledge and norms across cultures, many cultural-specific items (CSIs) related to food, clothing, art, and religion are rarely used by speakers outside the items' associated cultural group, with some items even not existing in certain cultures (Woolford, 1983; Persson, 2015). As a result, cultural-specific items usually lack available literal translations across languages, leading most MT systems to perform poorly on cultural-centered translations in real-world deployment (Akinade et al., 2023; Liebling et al., 2022). As shown in Figure 1, common errors, including copy and factual errors, are still made by the state-of-the-art MT systems (e.g., Google Translate and ChatGPT). More importantly, the nature of CSIs leads to difficulty in collecting high-quality, yet diverse parallel corpora at scale, hindering a systematic evaluation of both the traditional neural MT systems and the emerging MT paradigm using large language models (LLM).</p>
<p>To address this challenge, a handful of recent studies have begun to curate culture-related corpora for analysis from two main perspectives. The first perspective emphasizes regional varieties, such</p>
<p>as the variety of Portuguese used in Brazil versus Portugal (Riley et al., 2023). The second perspective focuses on cultural content in translation, such as recipes (Cao et al., 2024) and idioms (Li et al., 2024). Given the difficulty of obtaining word-for-word translation pairs for CSIs, these studies are shifting from the traditional literal translation paradigm to free translation which aims to convey the meaning of source texts and prioritizes readability and cultural relevance over strict accuracy and structural fidelity. Despite the valuable contributions of these works, two major concerns may still hinder the analysis of MT systems in navigating cultural nuances. First, the demand for high-quality data requires costly human annotations, restricting these studies from scaling up their curated data resources in terms of size, language pair diversity, and cultural domain coverage (see Table 1). Second, common MT evaluation metrics designed for literal translation lead to a lack of reliable assessments of free translation quality.</p>
<p>In this study, we address the two aforementioned concerns with a particular focus on translating culture-specific items. Specifically, we introduce an annotation-efficient data curation pipeline that can freely gather a diverse, large-scale, culture-centered parallel corpus while ensuring data quality. The resulting corpus, called Culturally-Aware Machine Translation (CAMT), encompasses $\boldsymbol{6}$ language pairs, covering 6,983 CSIs across 18 concept categories from 235 countries and regions. To facilitate automatic assessment emphasizing CSIcentered free translation, we propose two evaluation metrics: CSI-Match and pragmatic translation assessment (PTA). The CSI-Match metric evaluates the translation accuracy of isolated CSIs, independent of their sentence context. In contrast, the PTA metric assesses the comprehensibility of CSI translations within sentence contexts, emphasizing their pragmatic effectiveness in communication with native speakers of the target language.</p>
<p>Leveraging our CAMT corpus and designed evaluation metrics, we conduct a systematic analysis to investigate the capability of state-of-the-art neural MT and LLM-based MT systems in translating cultural content. First, we examine their efficacy with two popular terminology translation strategies that utilize the CSI dictionary. Our findings indicate that the terminology translation strategies greatly enhance the CSI translation accuracy for both neural MT and LLM-based MT systems. However, LLMs exhibit superior capability in leveraging the external dictionary compared to NMTs, particularly for CSIs that lack well-known translations. Next, to further examine LLMs’ capability for integrating external knowledge into translations, we explore prompting strategies that incorporate the CSI explanations in the prompts. Our results show that incorporating CSI explanations in the prompts notably improves the pragmatic translation quality, especially for CSIs without direct translations. In summary, our contributions are as follows:</p>
<ul>
<li>We curate a diverse parallel corpus in six language pairs with rich cultural-specific item annotations using a highly automatic pipeline.</li>
<li>We introduce two new evaluation metrics (CSIMatch and PTA) to assess translation quality regarding cultural nuances, particularly for terms lacking established translations.</li>
<li>We examine both LLM-based MT and NMT systems using our dataset and metrics. Our results indicate that LLMs can effectively incorporate external cultural knowledge, thereby improving the pragmatic translation quality of CSIs.</li>
</ul>
<h2>2 Related Works</h2>
<p>Culturally-Aware Machine Translation: As languages and cultures are highly intertwined, there is a growing desire to empower cultural awareness of MT systems (Hershcovich et al., 2022; Riley et al., 2023). However, as cultural nuances are subtle, collecting culturally sensitive data (Akinade et al., 2023) remains costly and time-consuming. Therefore, current work on cultural-aware translations is limited to specific domains and language pairs (Cao et al., 2024; Li et al., 2024). It is also challenging to perform a human-centered evaluation of the cultural nuances (Liebling et al., 2022; Li et al., 2024). Existing studies have proposed strategies to evaluate cultural awareness of traditional MT systems by grounding images (Khani et al., 2021), adapting entities (Peskov et al., 2021) or targeting at dilates (Riley et al., 2022). Different from existing culturally relevant MTs, we focus on evaluating the cultural awareness of MT by translating culture-specific items, a relatively underexplored area.</p>
<p>MT with Terminology Previous studies on machine translation with terminology focused primarily on generic domains (Dinu et al., 2019), or popular ones (e.g., law, medicine) (Ghazvininejad et al.,</p>
<p>2023). However, translating culture-specific items carries its own set of unique challenges because literal translations of CSIs may not exist in the target culture, making translation adaption crucial for target language readers to understand these terms (Vinay and Darbelnet, 1995). The adaptation can create semantic asymmetry between the source words and their translations, which makes traditional translation evaluation metrics focused on semantic alignment insufficient for cross-cultural translation (Hershcovich et al., 2022).</p>
<p>External Knowledge for MT: There have been multiple threads of research efforts on integrating external knowledge such as bilingual translation lexicons for neural machine translation systems, including probability interpolation of lexicons (Arthur et al., 2016; Khandelwal et al., 2021), data augmentation by back-translations (Hu et al., 2019), decoding with a phrase memory (Wang et al., 2017), and pre-training with an entity-based denoising objective (Hu et al., 2022). Despite their effectiveness, these methods require further finetuning of the original MTs. As the parameters of LLMs (e.g., ChatGPT) may not be accessible, we focus on tuning-free methods for integrating external knowledge in this study (Dinu et al., 2019).</p>
<p>LLM-based MT: Large language models, such as GPT-3 (Brown et al., 2020), have proven effective in machine translation for various highresource languages (Hendy et al., 2023; Jiao et al., 2023). In particular, a few recent studies have investigated the performance of LLM-based MT, including formality control of translation outputs (Garcia and Firat, 2022), in-context translation ability during pre-training (Shin et al., 2022), and multilingual translation (Scao et al., 2022; Zhu et al., 2023). Moreover, previous work indicates that LLMs can integrate external knowledge in the context into translation (Ghazvininejad et al., 2023; Li et al., 2024). However, the exploration of LLM-based MT on leveraging cultural knowledge to translate culture-specific items is still lacking.</p>
<h2>3 CAMT Dataset</h2>
<p>To minimize the need for human efforts while still obtaining diverse, high-quality CSI-centered translation pairs across multiple languages and cultures, we rely on Wikipedia to collect the data. The overall workflow of our data collection includes (1) building a wiki-centered cultural tax-
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Overview of CAMT construction pipeline.
onomy (§3.1); (2) curating parallel sentences containing culturally-relevant entities (§3.2); and, (3) augmenting geo-metadata (§3.3). Figure 2 displays an overview of our data construction pipeline.</p>
<h3>3.1 Cultural Taxonomy Extraction</h3>
<p>Since culture is an abstract concept, it is difficult to capture fine-grained cultural characteristics from texts directly. With this consideration in mind, we referred to an existing CSI classification framework (Newmark, 1988), which has been popularly used in the study of human translations of cultural concepts, to identify culturally relevant texts from Wikipedia. Specifically, there are five CSI categories in this framework, including: 1) ecology; 2) material culture; 3) social culture; 4) organizations, customs, ideas; 5) gestures and habits. Each entity-centered Wikipedia page is labeled by a variety of Wikipedia categories (Asthana and Halfaker, 2018). To save the efforts of matching each entity on Wikipedia with each CSI category, we map CSI categories with Wikipedia categories by manually creating a mapping table (in Table 9) to establish connections between the two categories. Ultimately, 18 Wikipedia categories are identified as culturally related. An entity is classified as culturally related if the category of its Wikipedia page maps to one of the CSI categories.</p>
<h3>3.2 Culture Parallel Text Collection</h3>
<p>To construct a culture parallel text corpus (e.g., for English-Chinese), we collect public text articles from Wikipedia's translation tool that cover a wide range of cultural topics, and conduct sentence alignment to get parallel sentences (tools are detailed in Appendix §C). To expand the language coverage in our corpora, we also reuse open-source parallel corpora from OPUS (Tiedemann, 2016). These</p>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Language</th>
<th>Domains</th>
<th>Format</th>
</tr>
</thead>
<tbody>
<tr>
<td>ApposCorpus</td>
<td>en, es</td>
<td>Person</td>
<td>Sent.</td>
</tr>
<tr>
<td><em>Kementcheffbieva et al. (2020)</em></td>
<td>de, pl</td>
<td>Organization</td>
<td></td>
</tr>
<tr>
<td>Adaption</td>
<td>en, de</td>
<td>Celebrity</td>
<td>Ent.</td>
</tr>
<tr>
<td><em>Peskov and Hangya (2021)</em></td>
<td>en, zh</td>
<td>Idiom</td>
<td>Sent.</td>
</tr>
<tr>
<td>IdiomKB</td>
<td>ja</td>
<td>Recipes</td>
<td>Para.</td>
</tr>
<tr>
<td><em>Li et al. (2024)</em></td>
<td>en, zh</td>
<td>Recipes</td>
<td>Para.</td>
</tr>
<tr>
<td>CulturalRecipes</td>
<td>en, zh</td>
<td>Cultural</td>
<td></td>
</tr>
<tr>
<td><em>Cao et al. (2024)</em></td>
<td>fr, es</td>
<td>Categories</td>
<td>Sent.</td>
</tr>
<tr>
<td>CAMT (Ours)</td>
<td>hi, ta, te</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Table 1: Dataset comparison. Sent., Ent., and Para. are abbreviations of sentence, entity and paragraph.
include Wikipedia v1.0 for English to French and Spanish, as well as Samanantar v0.2 for English to Hindi, Tamil, and Telugu. To identify sentences that contain culture-related items (Step 1 in Figure 2), we first perform entity-linking <em>Ringgaard et al. (2017)</em> to identify Wikipedia entities on the source texts, then use classification tool <em>Asthana and Halfaker (2018)</em> to classify the Wikipedia categories of these entities. The categories are further mapped to our CSI categories using the cultural taxonomy (§3.1). The mapping table is shown in Appendix B. Finally, we only keep sentences that contain entities belonging to CSI categories.</p>
<h3>3.3 Cultural Knowledge Augmentation</h3>
<p>Existing MT studies <em>Arthur et al. (2016); Hu et al. (2022)</em> have used external knowledge sources (e.g., Wikidata) to improve named entity translations. To enable future adaptations of these studies on our dataset, we parse Wikidata to augment cultural knowledge of CSIs (Step 2 in Figure 2), which includes their translations, descriptions, and aliases in multiple languages. We also obtain the plain text of the first paragraph of the Wikipedia article as the CSI explanation. Moreover, to identify cultural items that are specific to a certain country, we collect information on country of origin from Wikidata for each item and remove sentences that contain only items without an associated country of origin. We refer to these groupings of data for each CSI as CSI dictionaries, an example of which is shown in the data example in Appendix §A. This meticulous approach enriches our dataset with supplementary cultural knowledge, enabling us to evaluate MTs’ performances in handling CSIs.</p>
<h3>3.4 Dataset Analysis</h3>
<p>We briefly compare CAMT with existing datasets that similarly focus on translating culture-specific content in Table 1. Similar to ApposCorpus and IdiomKB, translation pairs in CAMT are at the sentence level, aiming to provide fine-level textual context to explore the translation quality of CSIs from both semantic and pragmatic perspectives. Regarding data diversity, CAMT significantly expands the coverage to 18 cultural categories compared to prior work that focus on a specific domain. With respect to languages, CAMT includes 7 languages, which is more than in existing datasets ( $\leq 4$ ).</p>
<p>We further conduct detailed corpus statistics on CAMT. As shown in Table 2, our dataset contains 6,948 parallel sentences over 6 language pairs, of which 3,029 sentences have CSI translations and the rest are non-translation instances. The total number of unique CSIs (called CSIs Types) in CAMT is 6,983 . Among various cultural categories, we find that organizations, customs, ideas and material culture are the top 2 categories, and social culture and ecology are the bottom ones. A more detailed breakdown of statistics of CAMT can found in Appendix §D.</p>
<h2>4 Cultural Awareness Evaluation</h2>
<p>To better capture the cultural nuances in CSI translations, we devise two evaluation metrics: (1) CSIMatch, which evaluates the accuracy of CSIs with labels, and (2) PTA, which assesses the pragmatic translation quality of CSIs without labels.</p>
<p>CSI-Match: Existing evaluation metrics for terminology are efficient for evaluating the accuracy of translations and the fluency of outputs <em>Anastasopoulos et al. (2021)</em>. However, previous metrics such as Exact Match (EM) assume that terminology translations must be exact matches, while reasonable adaptations of CSIs are also acceptable <em>Vinay and Darbelnet (1995)</em>. To address this, we introduce the CSI-Match metric as a modification to the EM evaluation metric. CSI-Match measures the accuracy of term translation using a more nuanced, fuzzy matching approach. It calculates the maximal partial similarity ratio (PSR) between the reference CSI translations $t_{1}, t_{2}, \ldots, t_{n}$ and the system out-</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Pair</th>
<th style="text-align: center;">Sent.</th>
<th style="text-align: center;">CSIs Counts</th>
<th style="text-align: center;">CSIs Types</th>
<th style="text-align: center;">CSI Translations</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">En-Zh</td>
<td style="text-align: center;">778</td>
<td style="text-align: center;">794</td>
<td style="text-align: center;">601</td>
<td style="text-align: center;">730</td>
</tr>
<tr>
<td style="text-align: center;">En-Fr</td>
<td style="text-align: center;">2,073</td>
<td style="text-align: center;">2,213</td>
<td style="text-align: center;">2,213</td>
<td style="text-align: center;">1,130</td>
</tr>
<tr>
<td style="text-align: center;">En-Es</td>
<td style="text-align: center;">1,580</td>
<td style="text-align: center;">1,652</td>
<td style="text-align: center;">1,652</td>
<td style="text-align: center;">817</td>
</tr>
<tr>
<td style="text-align: center;">En-Hi</td>
<td style="text-align: center;">1,086</td>
<td style="text-align: center;">1,127</td>
<td style="text-align: center;">1,127</td>
<td style="text-align: center;">168</td>
</tr>
<tr>
<td style="text-align: center;">En-Ta</td>
<td style="text-align: center;">677</td>
<td style="text-align: center;">695</td>
<td style="text-align: center;">695</td>
<td style="text-align: center;">118</td>
</tr>
<tr>
<td style="text-align: center;">En-Te</td>
<td style="text-align: center;">754</td>
<td style="text-align: center;">695</td>
<td style="text-align: center;">695</td>
<td style="text-align: center;">66</td>
</tr>
<tr>
<td style="text-align: center;">Total</td>
<td style="text-align: center;">6,948</td>
<td style="text-align: center;">7,176</td>
<td style="text-align: center;">6,983</td>
<td style="text-align: center;">3,029</td>
</tr>
</tbody>
</table>
<p>Table 2: Dataset Statistics on Six Language Pairs.</p>
<p>put sentence $S$. CSI-Match is determined by Eq. (1), resulting in a value from 0 to 100. A higher value indicates a stronger similarity of the predicted CSIs to a set of CSI translation references.</p>
<p>$$
\text { CSI-Match }=\max <em 1="1">{t \in\left{t</em>(t, S)
$$}, t_{2}, \ldots, t_{n}\right}} \operatorname{PSR</p>
<p>PSR measures the maximum similarity between string $t$ and any substring in $S$.</p>
<p>$$
\begin{aligned}
&amp; \operatorname{PSR}(t, S)=\max <em i:="i:" j="j">{s \in P}(1-d(t, s)) \times 100 \
&amp; P=\left{S</em> \mid 0 \leq i \leq j&lt;|S|\right}
\end{aligned}
$$</p>
<p>where $S_{i: j}$ is a substring of $S$ from word index $i$ to $j$, and $d(,)$ is the normalized Levenshtein distance which measures the minimum number of insertions, deletions, and substitutions required to change one string into another (Levenshtein et al., 1966).</p>
<p>Pragmatic Translation Assessment (PTA): Existing evaluation metrics like BLEU (Papineni et al., 2002a) and COMET (Rei et al., 2020a) mainly focus on surface-level or semantic-level accuracy between the source and target texts. However, in the context of CSI translation where translation quality is tightly associated with target culture (Hershcovich et al., 2022), pragmatic translation quality becomes crucial. For example, a free translation based on the description of the CSI might have better pragmatic translation quality than a direct literal translation, as it would be easier for people from the target culture to understand. Therefore, we design a new assessment metric called PTA, measuring the win rate at which CSI translations by the MT system are judged to exhibit better pragmatic translation quality compared to human reference translations. Specifically, in the human evaluation, we specify what the CSIs are in the source language and ask native speakers of the target language to compare the CSI translations within the sentential context between an MT system and a reference, and then select the translation that is easier to understand. To improve the applicability of PTA when native speakers are not available, we use GPT-4o to replace human judgments for PTA, which has proven effective for the automatic evaluation of generative models in recent studies (Rafailov et al., 2023; Kocmi and Federmann, 2023). The evaluation prompt, shown in Appendix §E, is used for both human annotators and GPT-4. A higher PTA score means the system translates the CSI in a more comprehensive manner than the reference sentence does, which might use other accurate but less understandable translations of CSIs.</p>
<h2>5 Experimental Settings</h2>
<p>To fully evaluate the efficacy of MT system translating CSIs, we compare NMT systems with LLMbased MTs (§5.1). Secondly, to investigate the performances of traditional terminology translation methods on CSI translations, we evaluate two dictionary-based terminology methods on opensourced NMT and LLMs (§5.2). Moreover, to gauge the capacity of LLMs to leverage external knowledge, we evaluate 4 cultural knowledge prompting strategies on tuning-free LLMs (§5.3).</p>
<h3>5.1 MT systems in Comparison</h3>
<p>We evaluate the following MT systems:</p>
<ul>
<li>NMTs: We asses the NLLB 1.3B (NLLB Team et al., 2022) model, which is a state-of-the-art multilingual MT model. We also use the Google Translate engine in our comparison.</li>
<li>LLMs: We examine ChatGPT (GPT-3.5-turbo1106) and the open-source LLaMA2-7B for comparison, as both have been proven to be efficient multilingual MT tools (Zhu et al., 2023).</li>
</ul>
<h3>5.2 Dictionary-based Methods in Comparison</h3>
<p>For the open-sourced models (i.e., LLaMA and NLLB) we experiment with two additional methods proven to be highly effective in terminology MT during inference (Dinu et al., 2019). Specifically, we employ 1) the Append method: append the CSI dictionary before the input, whose format is "<CSI $>$&gt;<CSI $_{1}$ Translations>,...,<CSI $_{n}>&lt;$ CSI $_{n}$ Translations&gt;[Source language]"; and 2) the Replace method: replace the CSIs in the source sentence with their translation in target language. For LLaMA2, we use the following prompt in 8 shots: [Source language]:[Source sentence] = [Target language]:[Target sentence], which is efficient for machine translation (Zhu et al., 2023).</p>
<h3>5.3 Prompting Strategies in Comparison</h3>
<p>We explore various prompting strategies to introduce cultural knowledge into LLM-based MT. Our strategies generate in-context examples to integrate additional cultural knowledge, which involves employing CSI dictionaries and CSI explanations. Table 3 shows examples of four prompting strategies.</p>
<ul>
<li>Basic Instruction (BI) The basic machine translation prompt of LLMs (e.g. ChatGPT).</li>
<li>External CSI Translation (CT) To assess the impact of incorporating a CSI dictionary within</li>
</ul>
<table>
<thead>
<tr>
<th>Strategy</th>
<th>Prompt</th>
</tr>
</thead>
<tbody>
<tr>
<td>Basic Instruction (BI)</td>
<td>Translate the following English text to Chinese</td>
</tr>
<tr>
<td>CSI Translation (CT)</td>
<td>The Chinese translation of culture entities in the sentence is as following: <br> cannoli: 里考塔芝士卷(Ricotta cheese rolls), 豹油甜馅煎饼卷 (Sweet Cream pancake rolls) <br> Translate the following English text to Chinese</td>
</tr>
<tr>
<td>CSI Explanation (CE)</td>
<td>The explanation of culture entities in the sentence is as following: <br> Cannoli are Italian pastries consisting of tube-shaped shells of fried pastry dough ... <br> Translate the following English text to Chinese</td>
</tr>
<tr>
<td>Self-Explanation (SE)</td>
<td>User: Please explain cannoli in [Source Sentence] <br> LLM: [Explanation] <br> User: According to your explanations to cannoli, only translate the following English text to Chinese</td>
</tr>
<tr>
<td>Source</td>
<td>They are also commonly available at Italian-American bakeries in the United States, alongside other Italian pastries like cannoli and sfogliatelle.</td>
</tr>
<tr>
<td>Knowledge</td>
<td>Translations: cannoli: 里考塔芝士卷(Ricotta cheese rolls), 豹油甜馅煎饼卷 (Sweet Cream pancake rolls) <br> Explanation: Cannoli are Italian pastries consisting of tube-shaped shells of fried pastry dough ...</td>
</tr>
</tbody>
</table>
<p>Table 3: Prompting strategy examples (Top) and a source with cultural knowledge for En-Zh translation (Bottom).
the prompts, we include CSIs along with their corresponding translations prior to the basic translation instruction BI.</p>
<ul>
<li>External CSI Explanation (CE) CSIs may not have a direct equivalence in the target language's culture. Therefore, it becomes necessary to translate based on the explanation of the CSI to assist the target audience in better understanding the content. To assess the impact of explanations, we include the CSI explanation obtained from Wikipedia in the prompt before the basic translation instructions.</li>
<li>Self-Explanation (SE) We also examine LLMs' internal knowledge for explaining the meaning of CSIs. Inspired by Chain-of-Thought (CoT) (Wei et al., 2022; Kojima et al., 2022), we treat the explanation of CSIs in a source sentence as an intermediate reasoning step before translating the whole sentence. We design the explanation prompting strategy in two steps for machine translation. First, we prompt the LLM to explain the meaning of all CSIs in the source sentence. Second, we ask the LLM to translate the whole sentence by combining the LLM's explanation with another prompt instruction.</li>
</ul>
<h2>6 Results and Analysis</h2>
<p>In this section, we 1) compare the CSI translation performances of LLM-based MT systems with that of NMT systems (§6.1); 2) evaluate dictionarybased terminology translation methods to explore if they work on CSI translations (§6.2); 3) compare four prompting strategies of LLM-based MTs to explore how different prompts affect the LLMs' cultural awareness (§6.3); 4) conduct human eval-
uation to verify the correlation between automatic evaluation metrics and human assessment (§6.4).</p>
<h3>6.1 Evaluating LLM-based MT v.s. NMT</h3>
<p>To compare the cultural awareness of LLM-based MT systems with that of NMT systems, We employ two automatic metrics (CSI-Match and PTA) to evaluate 4 MT systems: the vanilla NLLB and Google Translate, and the BI prompting of LLaMA2 and GPT-3.5.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: CSI-Match results on six language pairs.
NMTs Excel in CSI-Match on Low-resource
Languages We evaluate the accuracy of CSI translations using CSI-Match across six language pairs, as shown in Figure 3. For the two Romance languages (French and Spanish), the performances of four MT systems are quite similar. However, Google Translate generally exhibits more consistent performance in non-Romance languages compared to LLM-based MT. NLLB's poor performance on EN-ZH is due to its limited translation capacity on EN-ZH, as validated in previous bench-</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: PTA results on English-Chinese translations.</p>
<p>Marking work (Aharoni et al., 2019; Akinade et al., 2023). Specifically, NLLB and Google Translate outperform LLaMA2 and GPT-3.5 in translating three Indian languages: Hindi, Tamil, and Telugu. Additionally, for low-resource languages like Tamil and Telugu, the translation performance of LLM-MTs remains limited on traditional translation metrics (see Table 10). Therefore, LLM-MTs cannot yet be considered efficient multilingual translation tools for these low-resource languages.</p>
<h3>GPT-3.5 Produces Better Pragmatic Translation on CSIs with No Established Translations</h3>
<p>Given the cost of evaluation by commercial tools and human experts across all language pairs, we focus on English-Chinese in both translation directions when evaluating the pragmatic translation quality by PTA. Figure 4 presents the PTA assessed by GPT-4o for four MT systems' output compared to the reference sentences. In addition to PTA across the entire dataset, we separately evaluate PTA of samples containing CSIs with no established translations (<strong>NT</strong>-<strong>PTA</strong>). Notably, GPT-3.5 performs better than any other MT systems on NT-PTA, which potentially suggests that the instruction-tuning of LLMs beyond the translation task may be beneficial for the model to generate free translations that are easily understood by the target culture, especially for non-translation CSIs.</p>
<h3>6.2 Evaluating Dictionary-based Methods</h3>
<p>LLaMA is More Robust at Leveraging CSI Dictionaries than NLLB. We evaluate two dictionary-based terminology methods on NLLB and LLaMA for English-Chinese translations, as shown in Table 4. We find that straightforward strategies using dictionaries of CSIs, such as Replace and Append are effective for both NLLB and LLaMA on metrics that rely on string-matching (i.e. CSI-Match), as well as other semantic matching metrics (see Table 10). However, the appending strategy significantly benefits LLaMA more than NLLB. This suggests that LLaMA's ability for in-context learning and instruction-following enables the flexible integration of cultural knowledge at test time, a capability not present in traditional NMT systems like NLLB. Furthermore, traditional terminology translation methods can improve the PTA across the entire dataset. Without dictionaries, they still encounter challenges in improving the comprehensibility of translations that contain CSIs.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th></th>
<th>Method</th>
<th>CSI-Match</th>
<th>PTA</th>
</tr>
</thead>
<tbody>
<tr>
<td>NLLB</td>
<td>EN-ZH</td>
<td>Vanilla</td>
<td>53.1</td>
<td>17.1</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Append</td>
<td>58.3▲</td>
<td>17.7▲</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Replace</td>
<td>78.7▲</td>
<td>20.5▲</td>
</tr>
<tr>
<td></td>
<td>ZH-EN</td>
<td>Vanilla</td>
<td>64.9</td>
<td>6.7</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Append</td>
<td>65.5▲</td>
<td>4.6▼</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Replace</td>
<td>79.8▲</td>
<td>9.2▲</td>
</tr>
<tr>
<td>LLAMA2</td>
<td>EN-ZH</td>
<td>Vanilla</td>
<td>45.0</td>
<td>12.1</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Append</td>
<td>80.2▲</td>
<td>16.8▲</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Replace</td>
<td>67.1▲</td>
<td>15.3▲</td>
</tr>
<tr>
<td></td>
<td>ZH-EN</td>
<td>Vanilla</td>
<td>70.9</td>
<td>12.0</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Append</td>
<td>85.6▲</td>
<td>17.5▲</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Replace</td>
<td>80.6▲</td>
<td>16.5▲</td>
</tr>
</tbody>
</table>
<h3>6.3 Evaluating Prompting Strategies</h3>
<p>Table 4: Evaluation of traditional dictionary-based methods on English-Chinese translations. ▲/▼ means the score is better or worse than the vanilla model.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Method</th>
<th>CSI-Match</th>
<th>PTA</th>
<th>NT-PTA</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-3.5</td>
<td>BI</td>
<td>66.2</td>
<td>33.2</td>
<td>31.7</td>
</tr>
<tr>
<td></td>
<td>CT</td>
<td>84.0▲</td>
<td>35.6▲</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>CE</td>
<td>67.1▲</td>
<td>35.8▲</td>
<td>41.3▲</td>
</tr>
<tr>
<td></td>
<td>SE</td>
<td>67.7▲</td>
<td>36.7▲</td>
<td>36.5▲</td>
</tr>
<tr>
<td>LLaMA2</td>
<td>BI</td>
<td>43.7</td>
<td>11.3</td>
<td>11.1</td>
</tr>
<tr>
<td></td>
<td>CT</td>
<td>82.2▲</td>
<td>16.6▲</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>CE</td>
<td>43.3▼</td>
<td>10.8▼</td>
<td>15.9▲</td>
</tr>
<tr>
<td></td>
<td>SE</td>
<td>47.8▲</td>
<td>10.3▼</td>
<td>12.7▲</td>
</tr>
</tbody>
</table>
<p>Table 5: Evaluation of different prompting strategies on English-to-Chinese translations. ▲/▼ means the score is better or worse than the vanilla model.</p>
<p>LLM-based MTs open up the opportunity to incorporate free-form external knowledge to enhance the pragmatic translation quality of CSIs, especially for those without dictionaries. We ex-</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Strategy</th>
<th style="text-align: left;">Outputs</th>
<th style="text-align: center;">PTA of GPT-4o</th>
<th style="text-align: center;">PTA of Human</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">BI</td>
<td style="text-align: left;">就像意大利的polenta concia一样，它可以作为主菜食用。</td>
<td style="text-align: center;">Lose</td>
<td style="text-align: center;">Lose</td>
</tr>
<tr>
<td style="text-align: left;">CT</td>
<td style="text-align: left;">和在意大利一样，波伦塔(transliteration) 在意大利被当作主菜。</td>
<td style="text-align: center;">Lose</td>
<td style="text-align: center;">Lose</td>
</tr>
<tr>
<td style="text-align: left;">CE</td>
<td style="text-align: left;">就像意大利的奶酪玉米粥(sheese corn porridge)一样，它可以作为主菜食用。</td>
<td style="text-align: center;">Win</td>
<td style="text-align: center;">Win</td>
</tr>
<tr>
<td style="text-align: left;">SE</td>
<td style="text-align: left;">就像意大利的奶酪玉米粥(sheese corn porridge)一样，它可以作为主菜食用。 <br> Explanation by GPT-3.5: Polenta is a traditional Italian dish that originated in Northern Italy. It is a <br> type of porridge made from cornmeal, and is similar in consistency to grits or cornmeal mush.</td>
<td style="text-align: center;">Win</td>
<td style="text-align: center;">Win</td>
</tr>
<tr>
<td style="text-align: left;">Source</td>
<td style="text-align: left;">Just like polenta concia in Italy, it is eaten as a main dish.</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">Reference</td>
<td style="text-align: left;">就像意大利的玉米粥 (corn porridge)一样，它可以作为主菜食用。</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">Knowledge</td>
<td style="text-align: left;">Translation: 波伦塔 (transliteration) <br> Explanation: Polenta is a dish of boiled cornmeal that was historically made from other grains. <br> The dish comes from Italy. It may be served served as a hot porridge.</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 6: The output example of four prompting strategies on GPT-3.5 for En-Zh translation.
plore various prompting strategies by integrating additional cultural knowledge, including dictionaries and explanations, to improve translations. We compare different prompting strategies for English-to-Chinese translations, employing 2-shot prompting approaches to obtain results from GPT-3.5 and LLaMA2. Table 5 shows the evaluation results.</p>
<h2>External CSI Knowledge Improves LLM-MT.</h2>
<p>When comparing the strategies of using external knowledge in prompts (i.e., CT and CE), we observe that LLMs can effectively leverage both direct translations and indirect explanations. Specifically, CT enhances the CSI-Match score for CSI translations. However, CT is not effective when CSIs have no existing translations. In contrast, the 2-shot CE approach using GPT-3.5 improves NTPTA from 31.7 to 41.3 in English-to-Chinese translations. This suggests that CSI explanations can notably aid in translating CSIs, particularly those without well-known translations. For LLaMA, the PTA score is similar to the baseline (with differences of fewer than 10 examples out of 778 data points) due to the limitations of LLaMA2-7B's capacity for English-to-Chinese translations. However, CE and SE approaches with LLaMA still show an improvement in NT-PTA, indicating that LLaMA2-7B can also leverage external explanations to improve the translation quality of CSIs without existing direct translations.</p>
<p>LLMs' CSI Explanations Also Help. We use SE to elicit LLMs' internal knowledge and find that the 2-shot SE approach with GPT-3.5 improves translation performance across all metrics for English-to-Chinese translations. This suggests that GPT-3.5 may already possess a significant amount of cultural knowledge about CSIs and can integrate this knowledge into the translation process. For LLaMA2, the PTA of SE is close to the
baseline, and the improvement in NT-PTA is also limited, indicating that LLaMA2-7B may not have sufficient cultural knowledge of CSIs for English-to-Chinese translations.</p>
<h2>Prompting with CSI Explanations Encourages</h2>
<p>LLMs to Do Free Translations. In Table 6, we provide examples of the CSI "polenta", an Italian corn porridge. Its Chinese translation on Wikidata is merely a transliteration. Under the CT strategy, GPT-3.5 directly copies this transliteration into the output, which may be considered correct but not comprehensible for native speakers of Chinese. In contrast, using the CE strategy, GPT-3.5 integrates the CSI explanation into the translation, freely translating the term "corn porridge" into Chinese. This makes it easier for readers to understand the nature of "polenta". Furthermore, The SE strategy successfully generates an explanation for "polenta" and incorporates it into the translation as "corn porridge", which leads to better comprehension for Chinese native speakers, as is reflected in the ratings of GPT-4o and the human annotator.</p>
<h3>6.4 Human Evaluation</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Metrics</th>
<th style="text-align: center;">Human Acc.</th>
<th style="text-align: center;">Human PTA</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">BLEU</td>
<td style="text-align: center;">79.6</td>
<td style="text-align: center;">86.2</td>
</tr>
<tr>
<td style="text-align: left;">BLEURT</td>
<td style="text-align: center;">80.6</td>
<td style="text-align: center;">86.6</td>
</tr>
<tr>
<td style="text-align: left;">COMET</td>
<td style="text-align: center;">77.8</td>
<td style="text-align: center;">89.3</td>
</tr>
<tr>
<td style="text-align: left;">Exact-Match</td>
<td style="text-align: center;">77.0</td>
<td style="text-align: center;">81.7</td>
</tr>
<tr>
<td style="text-align: left;">CSI-Match</td>
<td style="text-align: center;">$\mathbf{8 8 . 7}$</td>
<td style="text-align: center;">90.0</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4o PTA</td>
<td style="text-align: center;">87.1</td>
<td style="text-align: center;">$\mathbf{9 5 . 7}$</td>
</tr>
</tbody>
</table>
<p>Table 7: Pearson's Coefficients between automatic metrics and human evaluation on CSI translation</p>
<p>To compare the consistency between automatic metrics and human evaluation, we conduct a human evaluation on a subset of 200 English-to-Chinese translations. We assess the outputs from eight MT</p>
<p>systems: NLLB, LLaMA2, Google Translate, and GPT-3.5 across zero-shot BI, and two-shot BI, CT, CE, and SE settings. The native Chinese speaker evaluates the accuracy and PTA of the outputs. We then calculate Pearson's correlation coefficients between automatic evaluation metrics and human assessments. Specifically, we compare the performance of CSI-Match and PTA with four traditional automatic evaluation metrics: BLEU, BLEURT, COMET, and Exact-Match. The results, presented in Table 7, indicate that CSI-Match exhibits the highest correlation with human accuracy, while GPT-4o PTA shows the highest correlation with human PTA. These findings suggest that CSI-Match and PTA are effective evaluation metrics for assessing the translation quality of CSIs, which can better capture cultural nuances than traditional metrics.</p>
<h2>7 Conclusion</h2>
<p>To advance culturally-aware machine translation, we curate a high-quality, diverse parallel corpus (CAMT) with rich CSI annotations in 6 language pairs using an automated pipeline. We introduce two evaluation metrics, CSI-Match and PTA, to assess translation quality concerning cultural nuances. Our evaluation of LLM-based MT and NMT systems using CAMT reveals that LLMs can effectively incorporate external cultural knowledge, enhancing the pragmatic translation quality of CSIs. Our work provides essential data sources and insights for advancing culturally-aware machine translation, laying the groundwork for future investigation in this field.</p>
<h2>Limitations</h2>
<p>Language Pairs in Evaluation Our work takes a significant step toward toward understanding and evaluating the cultural awareness of machine translation on CSIs. We provide a culturally sensitive parallel corpus with rich annotations on culturalspecific items in six languages pairs. However, due to the cost of evaluation by commercial LLMs and human experts across all language pairs, we conduct parts of our experiments on English-Chinese translations, whose data quality is also verified by human experts. Building on our insights into English-Chinese translation, we hope to encourage future work to verify our findings on other language pairs, and we will release our code repository to streamline further investigations.</p>
<p>Cultural-Awareness Definition In this study, we focus on the evaluation of cultural-specific items (CSIs). However, evaluating cultural awareness beyond individual entities also deserves further investigation. Besides CSIs, many other types of cultural errors persist in the translation process, such as those related to linguistic style and slang (Hershcovich et al., 2022). Our work aims to mitigate cultural errors by starting with CSIs, promoting advancements in culturally-aware machine translation datasets, models, and evaluation methods. This is crucial for enabling machine translation to play a larger role in cross-cultural communications.</p>
<p>Evaluation by LLM Recent research has shown that GPT-4 demonstrates a high correlation with human experts in evaluating generation performance (Rafailov et al., 2023; Kocmi and Federmann, 2023; Li et al., 2024). However, using GPT4 as an evaluator may still pose fairness issues due to internal biases and unbalanced language capabilities of LLMs. In this study, we aim to advance beyond traditional semantic alignment evaluation metrics to assess pragmatic translation quality in English-Chinese translations using GPT-4. Further investigation is needed to improve GPT-4's effectiveness as an translation evaluator.</p>
<p>Prompting strategies We only try 4 prompting strategies in our study, due to our work's focus on benchmarking the cultural awareness of current LLM-based MT systems. In the future, we'll test other methods, such as instruction tuning, to improve the performance of LLM-based MT.</p>
<h2>Ethical Considerations</h2>
<p>Although our study designs a suite of simple but effective prompting strategies to enhance the cultural awareness of LLM-based machine translation, we still observe the weakness of LLM-based translation on cultural concepts in certain regions (e.g., Asia) and hallucinations on low-frequency entities. Potential usage of these LLM translation outputs may still result in the spread of misinformation. Before deploying our methods to create reliable content such as creating translations of Wikipedia articles, practitioners should ensure another round of human post-editing. During the annotation process, the annotators (native speakers of the target languages) consist of the authors of this article, who know the goals of the study clearly.</p>
<h2>Acknowledgements</h2>
<p>We sincerely appreciate the valuable feedback provided by our reviewers, which greatly helped to improve the manuscript. BY and JH are supported by the Wisconsin Alumni Research Foundation. MJ is partially supported by the National Science Foundation (IIS-2438420). The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Science Foundation.</p>
<h2>References</h2>
<p>Roee Aharoni, Melvin Johnson, and Orhan Firat. 2019. Massively multilingual neural machine translation. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 3874-3884, Minneapolis, Minnesota. Association for Computational Linguistics.</p>
<p>Idris Akinade, Jesujoba Alabi, David Adelani, Clement Odoje, and Dietrich Klakow. 2023. Varepsilon kú mask: Integrating Yorùbú cultural greetings into machine translation. In Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP), pages 1-7, Dubrovnik, Croatia. Association for Computational Linguistics.</p>
<p>Antonios Anastasopoulos, Laurent Besacier, James Cross, Matthias Gallé, Philipp Koehn, Vassilina Nikoulina, et al. 2021. On the evaluation of machine translation for terminology consistency. arXiv preprint arXiv:2106.11891.</p>
<p>Philip Arthur, Graham Neubig, and Satoshi Nakamura. 2016. Incorporating discrete translation lexicons into neural machine translation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1557-1567, Austin, Texas. Association for Computational Linguistics.</p>
<p>Sumit Asthana and Aaron Halfaker. 2018. With few eyes, all hoaxes are deep. Proceedings of the ACM on Human-Computer Interaction, 2(CSCW):1-18.</p>
<p>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877-1901. Curran Associates, Inc.</p>
<p>Yong Cao, Yova Kementchedjhieva, Ruixiang Cui, Antonia Karamolegkou, Li Zhou, Megan Dare, Lucia Donatelli, and Daniel Hershcovich. 2024. Cultural adaptation of recipes. Transactions of the Association for Computational Linguistics, 12:80-99.</p>
<p>Georgiana Dinu, Prashant Mathur, Marcello Federico, and Yaser Al-Onaizan. 2019. Training neural machine translation to apply terminology constraints. arXiv preprint arXiv:1906.01105.</p>
<p>Ana Fernández Guerra. 2012. Translating culture: problems, strategies and practical realities. Sic: časopis za književnost, kulturu i književno prevođenje, 3(1):00.</p>
<p>Xavier Garcia and Orhan Firat. 2022. Using natural language prompts for machine translation. arXiv preprint arXiv:2202.11822.</p>
<p>Marjan Ghazvininejad, Hila Gonen, and Luke Zettlemoyer. 2023. Dictionary-based phrase-level prompting of large language models for machine translation. arXiv preprint arXiv:2302.07856.</p>
<p>Naman Goyal, Cynthia Gao, Vishrav Chaudhary, PengJen Chen, Guillaume Wenzek, Da Ju, Sanjana Krishnan, Marc'Aurelio Ranzato, Francisco Guzmán, and Angela Fan. 2022. The flores-101 evaluation benchmark for low-resource and multilingual machine translation. Transactions of the Association for Computational Linguistics, 10:522-538.</p>
<p>Amr Hendy, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, and Hany Hassan Awadalla. 2023. How good are gpt models at machine translation? a comprehensive evaluation. arXiv preprint arXiv:2302.09210.</p>
<p>Daniel Hershcovich, Stella Frank, Heather Lent, Miryam de Lhoneux, Mostafa Abdou, Stephanie Brandl, Emanuele Bugliarello, Laura Cabello Piqueras, Ilias Chalkidis, Ruixiang Cui, et al. 2022. Challenges and strategies in cross-cultural nlp. arXiv preprint arXiv:2203.10020.</p>
<p>Junjie Hu, Hiroaki Hayashi, Kyunghyun Cho, and Graham Neubig. 2022. DEEP: DEnoising entity pretraining for neural machine translation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1753-1766, Dublin, Ireland. Association for Computational Linguistics.</p>
<p>Junjie Hu, Mengzhou Xia, Graham Neubig, and Jaime Carbonell. 2019. Domain adaptation of neural machine translation by lexicon induction. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2989-3001, Florence, Italy. Association for Computational Linguistics.</p>
<p>Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing Wang, and Zhaopeng Tu. 2023. Is chatgpt a good translator? a preliminary study. arXiv preprint arXiv:2301.08745.</p>
<p>Yova Kementchedjhieva, Di Lu, and Joel Tetreault. 2020. The apposcorpus: A new multilingual, multi-domain dataset for factual appositive generation. arXiv preprint arXiv:2011.03287.</p>
<p>Urvashi Khandelwal, Angela Fan, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. 2021. Nearest neighbor machine translation. In International Conference on Learning Representations.</p>
<p>Nikzad Khani, Isidora Tourni, Mohammad Sadegh Rasooli, Chris Callison-Burch, and Derry Tanti Wijaya. 2021. Cultural and geographical influences on image translatability of words across languages. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 198-209, Online. Association for Computational Linguistics.</p>
<p>Tom Kocmi and Christian Federmann. 2023. Large language models are state-of-the-art evaluators of translation quality. arXiv preprint arXiv:2302.14520.</p>
<p>Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners. In Advances in Neural Information Processing Systems.</p>
<p>Vladimir I Levenshtein et al. 1966. Binary codes capable of correcting deletions, insertions, and reversals. In Soviet physics doklady, volume 10, pages 707-710. Soviet Union.</p>
<p>Shuang Li, Jiangjie Chen, Siyu Yuan, Xinyi Wu, Hao Yang, Shimin Tao, and Yanghua Xiao. 2024. Translate meanings, not just words: Idiomkb's role in optimizing idiomatic translation with language models. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 18554-18563.</p>
<p>Daniel Liebling, Katherine Heller, Samantha Robertson, and Wesley Deng. 2022. Opportunities for humancentered evaluation of machine translation systems. In Findings of the Association for Computational Linguistics: NAACL 2022, pages 229-240, Seattle, United States. Association for Computational Linguistics.</p>
<p>Peter Newmark. 1988. A textbook of translation, volume 66. Prentice hall New York.</p>
<p>NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, and Jeff Wang.
2022. No language left behind: Scaling humancentered machine translation.</p>
<p>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002a. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311-318.</p>
<p>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002b. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311-318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.</p>
<p>Ulrika Persson. 2015. Culture-specific items: Translation procedures for a text about australian and new zealand children's literature.</p>
<p>Denis Peskov and Viktor Hangya. 2021. Adapting entities across languages and cultures. Findings of the Association for Computational Linguistics: EMNLP 2021.</p>
<p>Denis Peskov, Viktor Hangya, Jordan Boyd-Graber, and Alexander Fraser. 2021. Adapting entities across languages and cultures. In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3725-3750, Punta Cana, Dominican Republic. Association for Computational Linguistics.</p>
<p>Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D Manning, and Chelsea Finn. 2023. Direct preference optimization: Your language model is secretly a reward model. arXiv preprint arXiv:2305.18290.</p>
<p>Ricardo Rei, Craig Stewart, Ana C Farinha, and Alon Lavie. 2020a. Comet: A neural framework for mt evaluation. arXiv preprint arXiv:2009.09025.</p>
<p>Ricardo Rei, Craig Stewart, Ana C Farinha, and Alon Lavie. 2020b. COMET: A neural framework for MT evaluation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2685-2702, Online. Association for Computational Linguistics.</p>
<p>Parker Riley, Timothy Dozat, Jan A Botha, Xavier Garcia, Dan Garrette, Jason Riesa, Orhan Firat, and Noah Constant. 2022. Frmt: A benchmark for few-shot region-aware machine translation. arXiv preprint arXiv:2210.00193.</p>
<p>Parker Riley, Timothy Dozat, Jan A Botha, Xavier Garcia, Dan Garrette, Jason Riesa, Orhan Firat, and Noah Constant. 2023. Frmt: A benchmark for fewshot region-aware machine translation. Transactions of the Association for Computational Linguistics, $11: 671-685$.</p>
<p>Michael Ringgaard, Rahul Gupta, and Fernando CN Pereira. 2017. Sling: A framework for frame semantic parsing. arXiv preprint arXiv:1710.07032.</p>
<p>Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, et al. 2022. Bloom: A 176bparameter open-access multilingual language model. arXiv preprint arXiv:2211.05100.</p>
<p>Thibault Sellam, Dipanjan Das, and Ankur Parikh. 2020. BLEURT: Learning robust metrics for text generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7881-7892, Online. Association for Computational Linguistics.</p>
<p>Rico Sennrich and Martin Volk. 2010. MT-based sentence alignment for OCR-generated parallel texts. In Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers, Denver, Colorado, USA. Association for Machine Translation in the Americas.</p>
<p>Seongjin Shin, Sang-Woo Lee, Hwijeen Ahn, Sungdong Kim, HyoungSeok Kim, Boseop Kim, Kyunghyun Cho, Gichang Lee, Woomyoung Park, Jung-Woo Ha, and Nako Sung. 2022. On the effect of pretraining corpora on in-context learning by a large-scale language model. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5168-5186, Seattle, United States. Association for Computational Linguistics.</p>
<p>Jörg Tiedemann. 2016. Opus-parallel corpora for everyone. Baltic Journal of Modern Computing, 4(2).</p>
<p>Jean-Paul Vinay and Jean Darbelnet. 1995. Comparative stylistics of French and English: A methodology for translation, volume 11. John Benjamins Publishing.</p>
<p>Xing Wang, Zhaopeng Tu, Deyi Xiong, and Min Zhang. 2017. Translating phrases in neural machine translation. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1421-1431, Copenhagen, Denmark. Association for Computational Linguistics.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903.</p>
<p>Ellen Woolford. 1983. Bilingual code-switching and syntactic theory. Linguistic inquiry, 14(3):520-536.</p>
<p>Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu, Shujian Huang, Lingpeng Kong, Jiajun Chen, and Lei Li. 2023. Multilingual machine translation with large language models: Empirical results and analysis. arXiv preprint arXiv:2304.04675.</p>
<h2>A Data Examples</h2>
<p>In Table 8, we present a data example from the English-Chinese corpus. Each data point consists of a pair of sentences. We meticulously annotate all culture-specific items (CSI) within the sentences. For each culture-specific item, we provide information including its category, country of origin, translations in the target language, descriptions in both the source and target languages, and an explanation. To illustrate the challenges that culturalspecific items pose for current Machine Translation (MT) systems, we provide translations from both Google Translate and ChatGPT for this example. It is noted that both Google and ChatGPT erroneously rendered the Chinese translation of "Wiener Schnitzel" as "pork chops" instead of the correct translation, which is "steak". This misinterpretation not only misleads Chinese readers but also introduces confusion to the entire sentence, whose meaning is "The Shanghai-style pork chops are a twist on Austria's national dish, Wiener fried pork chops, which are more street food than steak."</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Aspect</th>
<th style="text-align: center;">Content</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Source (EN)</td>
<td style="text-align: center;">The Shanghai-style Fried Pork Chop is <br> a modification from Wiener Schnitzel <br> the national dish of Austria, and a fried pork <br> chop is more a street food than a beef steak. <br> 上海炸猪排的做法改良日奥地利国菜 <br> 做也纳炸牛排 (Wiener fried steak)，而炸猪排 <br> 与牛排不同，它显得更加市井。</td>
</tr>
<tr>
<td style="text-align: center;">Cultural-Specific Item</td>
<td style="text-align: center;">Wiener Schnitzel</td>
</tr>
<tr>
<td style="text-align: center;">Category</td>
<td style="text-align: center;">Culture.Food and drink</td>
</tr>
<tr>
<td style="text-align: center;">Country of Origin</td>
<td style="text-align: center;">Austria</td>
</tr>
<tr>
<td style="text-align: center;">Translation (ZH)</td>
<td style="text-align: center;">做也纳炸牛排 (Wiener fried steak)</td>
</tr>
<tr>
<td style="text-align: center;">Description (EN) <br> Description (ZH)</td>
<td style="text-align: center;">breaded veal schnitzel <br> 面包黄小牛肉炒肉排</td>
</tr>
<tr>
<td style="text-align: center;">Explanation</td>
<td style="text-align: center;">The entity, sometimes spelled Wienerschnitzel, <br> is a type of schnitzel made of a thin, <br> breaded, pan-fried veal carlet. It is one of <br> the best known specialities of Viennese cuisine, <br> and one of the national dishes of Austria.</td>
</tr>
<tr>
<td style="text-align: center;">NLLB</td>
<td style="text-align: center;">上海风格的炸猪肉切片是从奥地利 <br> 国家菜的做也纳施尼切尔(transliteration)改制而成。</td>
</tr>
<tr>
<td style="text-align: center;">LLaMA2</td>
<td style="text-align: center;">上海炒猪排是一种来自奥地利 <br> 的牛肉炒肉块 (Beef stir-fried cubes)的改良型, <br> 而炒猪排更像是一道削头小吃而非牛肉炒肉块。</td>
</tr>
<tr>
<td style="text-align: center;">Google Translate</td>
<td style="text-align: center;">海派炸猪排是奥地利国菜 <br> 做也纳炸猪排 (Wiener fried pork chops) <br> 的改良版，炸猪排与其说是牛排， <br> 不如说是削头小吃。</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">上海式炸猪排是从奥地利的国菜 <br> 做也纳炸猪排 (Wiener fried pork chops) <br> 改编而来，而炸猪排比牛排， <br> 更像是削边食物。</td>
</tr>
</tbody>
</table>
<p>Table 8: A Data Example in the English-Chinese Corpus: in parentheses, we explain what the Chinese translation means.</p>
<table>
<thead>
<tr>
<th>CSI Category</th>
<th>Wikiproject Category</th>
<th>CSI Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Material Culture</td>
<td>Culture.Food and drink</td>
<td>Cotoletta (Italy)</td>
</tr>
<tr>
<td></td>
<td>Culture.Visual arts.Architecture</td>
<td>the Summer Palace (China)</td>
</tr>
<tr>
<td></td>
<td>History and Society.Transportation</td>
<td>Kan-Etsu Expressway (Japan)</td>
</tr>
<tr>
<td>Social Culture</td>
<td>Culture.Sports</td>
<td>RKC Waalwijk (Netherlands)</td>
</tr>
<tr>
<td></td>
<td>Culture.Media.Entertainment</td>
<td>Far Rockaway (USA)</td>
</tr>
<tr>
<td>Organisations,</td>
<td>History and Society.Politics and government</td>
<td>Europe Ecology - The Greens (France)</td>
</tr>
<tr>
<td>Customs and Ideas</td>
<td>Culture.Philosophy and Religion</td>
<td>Fuller Theological Seminary (USA)</td>
</tr>
<tr>
<td></td>
<td>Culture.Literature</td>
<td>Der Spiegel (German)</td>
</tr>
<tr>
<td></td>
<td>Culture.Visual arts.Visual arts*</td>
<td>The Headless Horseman Pursuing Ichabod Crane (USA)</td>
</tr>
<tr>
<td></td>
<td>Culture.Visual arts.Fashion</td>
<td>Bottega Veneta (Italy)</td>
</tr>
<tr>
<td></td>
<td>Culture.Visual arts.Comics and Anime</td>
<td>Dragon Ball (Japan)</td>
</tr>
<tr>
<td></td>
<td>Culture.Performing arts</td>
<td>Just Dance (USA)</td>
</tr>
<tr>
<td></td>
<td>Culture.Media.Music</td>
<td>Trident Studios (UK)</td>
</tr>
<tr>
<td></td>
<td>Culture.Media.Films</td>
<td>A Few Good Men (USA)</td>
</tr>
<tr>
<td></td>
<td>Culture.Media.Books</td>
<td>Moby-Dick (USA)</td>
</tr>
<tr>
<td></td>
<td>History and Society.History</td>
<td>Tusculum (Italy)</td>
</tr>
<tr>
<td>Ecology</td>
<td>STEM.Biology</td>
<td>Kapok (Netherlands)</td>
</tr>
<tr>
<td></td>
<td>Geography.Regions.*</td>
<td>Qualicum Beach (Canada)</td>
</tr>
<tr>
<td>Gestures and Habits</td>
<td>-</td>
<td></td>
</tr>
</tbody>
</table>
<p>Table 9: CSI vs. Wikiproject mapping table.</p>
<h2>B CSI vs. Wikiproject Mapping Table</h2>
<p>The mapping table between CSI definitions (5 categories in total) and Wikiproject categories ( 18 categories) are shown in Table 9. Additionally, we provide examples for each category to clarify the respective meanings. The tool we used for Wikiproject category classification is drafttopic ${ }^{3}$.</p>
<h2>C Wikipedia Parallel Corpus Collection</h2>
<p>To collect the English-Chinese parallel corpus from Wikipedia, we use the bilingual Wikipedia articles translated through Wikipedia's content translate tool ${ }^{4}$. This tool allows confirmed editors to translate Wikipedia articles from the source language to a target language with a machine translation system. By tracking their editing logs, we obtain the text triples consisting of the original text in a source language, the machine-translated text, and the human post-edited text in the target language. We then use a sentence alignment tool bleu-align ${ }^{5}$ (Sennrich and Volk, 2010) to obtain a sentence-level parallel corpus. To obtain more language pairs, we reuse open-source data from OPUS, which includes Wikipediav1.0 ${ }^{6}$ for English-French and English-</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Spanish, as well as Samanantarv0.2 ${ }^{7}$ for EnglishHindi, English-Tamil, and English-Telugu.</p>
<h2>D Data Characteristics</h2>
<p>Data Statistics Table 2 shows the statistics of our parallel corpora for the evaluation of MT systems on six language pairs. Particularly, for each language pair, we count the total number of detected CSIs by CSIs Counts and the number of unique CSIs by CSIs Types. It's noted that not all the CSIs have translations on Wikidata, so we determine the number of CSIs containing translations in WikiData by CSI Translations. Considering that many CSIs only exist within a specific culture group, which can't be located in the parallel corpus, CSIs that don't have a translation in other languages should take a higher proportion in the real-world corpus than in our dataset.</p>
<p>Data Diversity Culture is intricately linked to specific regions, and its manifestations can exhibit substantial variations across diverse regions and categories. Therefore, our dataset encompasses culturally specific items sourced from a wide array of regions and categories. Figure 5 shows the distribution of categories. Specifically, we mapped 18 Wikiproject categories into 5 culture categories. Since there is no Wikiproject category matching</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>the CSI category gestures and habits, we excluded this label from further consideration. Regarding the regions, we show the top 15 origin countries in our dataset in Figure 6. Among these regions, CSIs originating from English-speaking countries (e.g., the United States and the United Kingdom) have the highest representation. This is because we conduct entity-linking on the English source texts, resulting in a predominance of CSIs from English-speaking countries. However, the entity linking tool SLING is multilingual, making it feasible to use our pipeline to include more CSIs from non-English speaking countries. This inclusive approach allows us to comprehensively evaluate the performance of machine translation models across a broad spectrum of cultural contexts.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Category distribution on categories.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Data characteristics on regions.</p>
<h2>E Evaluation Prompts of GPT-4o</h2>
<p>It has been shown that GPT-4 can be an effective tool for evaluating the quality of generation tasks in DPO (Rafailov et al., 2023). We apply a similar prompt method for the pragmatic translation quality evaluation of CSIs. The prompt is as follows, with the system output and reference randomly shuffled into choices A and B:</p>
<p>Assuming you're a Chinese native speaker, which of the following translations has a more understandable translation in Chinese of following culture-specific item: "Goubuli"? Please only compare the items' translation by ignoring the translation quality and length of the whole sentence.</p>
<p><Source></p>
<p>Translation A: <A></p>
<p>Translation B: <B></p>
<p>FIRST, provide a one-sentence comparison of the two translations, explaining which you prefer and why. SECOND, on a new line, if the translations of cultural-specific items: "Goubuli" in "A" and "B" are different, state "A" or "B" to indicate your choice, otherwise, use "C" to indicate your choice. Your response should use the format:</p>
<p>Comparison: <one-sentence comparison and explanation></p>
<p>Preferred: &lt;"A" or "B" or "C"&gt;</p>
<p>For the human evaluation, we also use the same prompt as instructions to align the human evaluations with GPT-4o evaluations.</p>
<h2>F Experiment Settings</h2>
<p>The experiment settings of different models included in our paper are as follows:</p>
<ul>
<li><strong>NLLB</strong> We use NLLB-200-1.3B-distilled for our experiments. We use fairseq to conduct the inference. The beam is set as 4, and the length penalty is set as 1.0.</li>
<li><strong>LLaMA2</strong> We use LLaMA-2-7B-hf for testing. The sampling is set as True, leading to a multinomial sampling searching method.</li>
</ul>
<p><sup>9</sup>https://github.com/facebookresearch/fairseq/tree/nllb?tab=readme-ov-file</p>
<p><sup>10</sup>https://github.com/facebookresearch/fairseq</p>
<p><sup>11</sup>https://huggingface.co/meta-llama/Llama-2-7b-hf</p>
<ul>
<li>GPT-3.5 We examine version gpt-3.5-turbo-1106. We use the ChatCompletion API provided by OpenAPI For the generation, we set the parameters as default, for which the temperature is 1, top_p is 1, and frequency_penalty as 0.</li>
<li>GPT-4o For GPT-4o, we use the latest version gpt-4o-2024-05-13 on Microsoft Azure platform by ChatCompletion, and we set the parameters as following: the temperature is 0 for a stable generation, top_p is 1, and frequency_penalty as 0.</li>
<li>Google translate We call the Google Translate API of Google Translate to get translations from it.</li>
</ul>
<h2>Appendix G Overall Automatic Evaluation</h2>
<p>We evaluate the translation outputs using traditional automatic metrics such as BLEU [papineni2002leu], BLEURT [sellam2020bleurt], and COMET [rei2020comet]. To be consistent with the evaluation method of NLLB, we calculate spBLEU [goyal2022spleu] for BLEU scores. In addition to traditional machine translation evaluation metrics, we also use CSI-Match to evaluate the translation quality of CSIs (described in §4). Table 10 shows the results of eight MT systems across six language pairs in two directions.</p>
<p>As shown in Table 10, both CSI dictionary incorporation (NLLB-A) and term replacement strategies (NLLB-R) enhance the translation quality of CSI for most language pairs, without significantly compromising the overall sentence translation regarding other metrics. Notably, NLLB-R outperforms other MT systems on CSI-Match, even including LLM-based MT. Interestingly, LLaMA2-7B shows an obvious drop in both traditional evaluation metrics and CSI-Match scores when translating English to three Indian languages and vice versa. One possible explanation is because of the insufficient Indian data during the pre-training of LLaMA2. Both CSI-involving translation strategies are beneficial for LLaMA-based translation. In non-Romance languages (i.e., Chinese, Hindi, Tamil, and Telugu), LLaMA2-A tends to yield better performances, whereas LLaMA2-R performs</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>better in Romance languages (i.e., French and Spanish), which potentially suggests that injecting cultural knowledge through code-switching similar Romance languages works better than distant languages for LLM-based models. Furthermore, we assess the translation performances of ChatGPT and Google Translate. Both MT systems exhibit commendable performance in CSI translation, with Google Translate demonstrating superior translation results. Notably, Google Translate showcases consistent translation abilities, particularly in handling relatively low-resource languages like Tamil and Telugu.</p>
<h2>H PTA Evaluation Results Across Languages</h2>
<p>We evaluate the PTA of two more language pairs. The evaluation result is shown in Figure 7. As with CSI-match on these two languages, the PTA performances of the 4 MT systems are pretty close. However, GPT-3.5 still shows superior performance on PTA compared to NMTs, indicating that GPT-3.5 has better capabilities to generate free translations for CSIs which can be easily understood by native speakers in the target culture.</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: PTA results on En-Fr and En-Es translations.</p>
<h2>I Generation Data Examples of Non-translation CSIs</h2>
<p>Table 11 shows the results of the four prompting strategies on the CSI "milk toast" from English to Chinese, which has no known translations. Under the BI strategy, GPT-3.5 translates the American breakfast dish as "toast", failing to capture the defining feature of the dish, which is that it is soaked in milk. CT similarly fails, yielding the</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Language Pair</th>
<th style="text-align: center;">Method</th>
<th style="text-align: center;">BLEU</th>
<th style="text-align: center;">BLEURT</th>
<th style="text-align: center;">COMET</th>
<th style="text-align: center;">CSI-Match</th>
<th style="text-align: center;">BLEU</th>
<th style="text-align: center;">BLEURT</th>
<th style="text-align: center;">COMET</th>
<th style="text-align: center;">CSI-Match</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">English-Chinese</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-ZH</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">ZH-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB</td>
<td style="text-align: center;">23.2</td>
<td style="text-align: center;">0.558</td>
<td style="text-align: center;">77.0</td>
<td style="text-align: center;">53.1</td>
<td style="text-align: center;">27.0</td>
<td style="text-align: center;">0.594</td>
<td style="text-align: center;">76.5</td>
<td style="text-align: center;">64.9</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB-A</td>
<td style="text-align: center;">17.3</td>
<td style="text-align: center;">0.447</td>
<td style="text-align: center;">62.8</td>
<td style="text-align: center;">58.3</td>
<td style="text-align: center;">21.9</td>
<td style="text-align: center;">0.531</td>
<td style="text-align: center;">69.4</td>
<td style="text-align: center;">65.5</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB-R</td>
<td style="text-align: center;">23.9</td>
<td style="text-align: center;">0.555</td>
<td style="text-align: center;">76.8</td>
<td style="text-align: center;">78.7</td>
<td style="text-align: center;">25.3</td>
<td style="text-align: center;">0.591</td>
<td style="text-align: center;">75.4</td>
<td style="text-align: center;">79.8</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2</td>
<td style="text-align: center;">17.1</td>
<td style="text-align: center;">0.529</td>
<td style="text-align: center;">75.8</td>
<td style="text-align: center;">45.0</td>
<td style="text-align: center;">26.1</td>
<td style="text-align: center;">0.595</td>
<td style="text-align: center;">77.9</td>
<td style="text-align: center;">70.9</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2-A</td>
<td style="text-align: center;">18.3</td>
<td style="text-align: center;">0.518</td>
<td style="text-align: center;">74.4</td>
<td style="text-align: center;">80.2</td>
<td style="text-align: center;">29.1</td>
<td style="text-align: center;">0.629</td>
<td style="text-align: center;">79.0</td>
<td style="text-align: center;">85.6</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2-R</td>
<td style="text-align: center;">19.2</td>
<td style="text-align: center;">0.547</td>
<td style="text-align: center;">76.8</td>
<td style="text-align: center;">78.1</td>
<td style="text-align: center;">27.7</td>
<td style="text-align: center;">0.618</td>
<td style="text-align: center;">78.9</td>
<td style="text-align: center;">80.6</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">29.3</td>
<td style="text-align: center;">0.642</td>
<td style="text-align: center;">82.9</td>
<td style="text-align: center;">67.2</td>
<td style="text-align: center;">32.5</td>
<td style="text-align: center;">0.668</td>
<td style="text-align: center;">80.9</td>
<td style="text-align: center;">77.7</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Google</td>
<td style="text-align: center;">38.3</td>
<td style="text-align: center;">0.679</td>
<td style="text-align: center;">84.2</td>
<td style="text-align: center;">71.9</td>
<td style="text-align: center;">41.1</td>
<td style="text-align: center;">0.697</td>
<td style="text-align: center;">82.2</td>
<td style="text-align: center;">79.5</td>
</tr>
<tr>
<td style="text-align: center;">English-French</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-FR</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">FR-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB</td>
<td style="text-align: center;">37.4</td>
<td style="text-align: center;">0.585</td>
<td style="text-align: center;">78.3</td>
<td style="text-align: center;">77.7</td>
<td style="text-align: center;">36.3</td>
<td style="text-align: center;">0.634</td>
<td style="text-align: center;">77.8</td>
<td style="text-align: center;">88.9</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB-A</td>
<td style="text-align: center;">37.4</td>
<td style="text-align: center;">0.582</td>
<td style="text-align: center;">78.0</td>
<td style="text-align: center;">77.4</td>
<td style="text-align: center;">35.4</td>
<td style="text-align: center;">0.628</td>
<td style="text-align: center;">77.2</td>
<td style="text-align: center;">88.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB-R</td>
<td style="text-align: center;">37.0</td>
<td style="text-align: center;">0.577</td>
<td style="text-align: center;">77.8</td>
<td style="text-align: center;">92.6</td>
<td style="text-align: center;">36.6</td>
<td style="text-align: center;">0.635</td>
<td style="text-align: center;">77.7</td>
<td style="text-align: center;">92.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2</td>
<td style="text-align: center;">34.4</td>
<td style="text-align: center;">0.558</td>
<td style="text-align: center;">76.2</td>
<td style="text-align: center;">77.9</td>
<td style="text-align: center;">27.6</td>
<td style="text-align: center;">0.462</td>
<td style="text-align: center;">66.0</td>
<td style="text-align: center;">72.5</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2-A</td>
<td style="text-align: center;">35.0</td>
<td style="text-align: center;">0.568</td>
<td style="text-align: center;">67.8</td>
<td style="text-align: center;">82.7</td>
<td style="text-align: center;">34.7</td>
<td style="text-align: center;">0.633</td>
<td style="text-align: center;">77.7</td>
<td style="text-align: center;">92.8</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2-R</td>
<td style="text-align: center;">34.7</td>
<td style="text-align: center;">0.550</td>
<td style="text-align: center;">75.6</td>
<td style="text-align: center;">89.8</td>
<td style="text-align: center;">30.2</td>
<td style="text-align: center;">0.620</td>
<td style="text-align: center;">76.8</td>
<td style="text-align: center;">93.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">36.2</td>
<td style="text-align: center;">0.594</td>
<td style="text-align: center;">78.9</td>
<td style="text-align: center;">78.7</td>
<td style="text-align: center;">37.6</td>
<td style="text-align: center;">0.629</td>
<td style="text-align: center;">77.8</td>
<td style="text-align: center;">89.8</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Google</td>
<td style="text-align: center;">31.1</td>
<td style="text-align: center;">0.573</td>
<td style="text-align: center;">77.5</td>
<td style="text-align: center;">77.9</td>
<td style="text-align: center;">36.1</td>
<td style="text-align: center;">0.632</td>
<td style="text-align: center;">77.2</td>
<td style="text-align: center;">88.9</td>
</tr>
<tr>
<td style="text-align: center;">English-Spanish</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-ES</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">ES-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB</td>
<td style="text-align: center;">48.8</td>
<td style="text-align: center;">0.707</td>
<td style="text-align: center;">83.4</td>
<td style="text-align: center;">78.4</td>
<td style="text-align: center;">50.7</td>
<td style="text-align: center;">0.718</td>
<td style="text-align: center;">83.5</td>
<td style="text-align: center;">90.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB-A</td>
<td style="text-align: center;">48.3</td>
<td style="text-align: center;">0.705</td>
<td style="text-align: center;">83.3</td>
<td style="text-align: center;">78.7</td>
<td style="text-align: center;">49.9</td>
<td style="text-align: center;">0.713</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">90.8</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB-R</td>
<td style="text-align: center;">47.9</td>
<td style="text-align: center;">0.696</td>
<td style="text-align: center;">82.9</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">50.9</td>
<td style="text-align: center;">0.717</td>
<td style="text-align: center;">83.4</td>
<td style="text-align: center;">95.2</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2</td>
<td style="text-align: center;">44.6</td>
<td style="text-align: center;">0.679</td>
<td style="text-align: center;">81.6</td>
<td style="text-align: center;">76.9</td>
<td style="text-align: center;">45.3</td>
<td style="text-align: center;">0.704</td>
<td style="text-align: center;">82.6</td>
<td style="text-align: center;">89.9</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2-A</td>
<td style="text-align: center;">44.5</td>
<td style="text-align: center;">0.674</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">82.0</td>
<td style="text-align: center;">46.6</td>
<td style="text-align: center;">0.706</td>
<td style="text-align: center;">82.7</td>
<td style="text-align: center;">93.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2-R</td>
<td style="text-align: center;">44.5</td>
<td style="text-align: center;">0.675</td>
<td style="text-align: center;">81.3</td>
<td style="text-align: center;">93.0</td>
<td style="text-align: center;">44.2</td>
<td style="text-align: center;">0.702</td>
<td style="text-align: center;">82.3</td>
<td style="text-align: center;">94.7</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">47.9</td>
<td style="text-align: center;">0.711</td>
<td style="text-align: center;">83.6</td>
<td style="text-align: center;">79.3</td>
<td style="text-align: center;">50.7</td>
<td style="text-align: center;">0.712</td>
<td style="text-align: center;">83.4</td>
<td style="text-align: center;">92.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Google</td>
<td style="text-align: center;">42.9</td>
<td style="text-align: center;">0.704</td>
<td style="text-align: center;">82.0</td>
<td style="text-align: center;">79.1</td>
<td style="text-align: center;">49.8</td>
<td style="text-align: center;">0.722</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">90.9</td>
</tr>
<tr>
<td style="text-align: center;">English-Hindi</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-HI</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">HI-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB</td>
<td style="text-align: center;">32.8</td>
<td style="text-align: center;">0.637</td>
<td style="text-align: center;">0.747</td>
<td style="text-align: center;">73.9</td>
<td style="text-align: center;">38.4</td>
<td style="text-align: center;">0.683</td>
<td style="text-align: center;">83.5</td>
<td style="text-align: center;">93.7</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB-A</td>
<td style="text-align: center;">32.1</td>
<td style="text-align: center;">0.630</td>
<td style="text-align: center;">0.734</td>
<td style="text-align: center;">78.7</td>
<td style="text-align: center;">38.4</td>
<td style="text-align: center;">0.676</td>
<td style="text-align: center;">82.8</td>
<td style="text-align: center;">90.9</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB-R</td>
<td style="text-align: center;">32.9</td>
<td style="text-align: center;">0.639</td>
<td style="text-align: center;">0.748</td>
<td style="text-align: center;">83.6</td>
<td style="text-align: center;">38.4</td>
<td style="text-align: center;">0.684</td>
<td style="text-align: center;">83.5</td>
<td style="text-align: center;">98.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2</td>
<td style="text-align: center;">7.3</td>
<td style="text-align: center;">0.438</td>
<td style="text-align: center;">0.493</td>
<td style="text-align: center;">60.6</td>
<td style="text-align: center;">12.6</td>
<td style="text-align: center;">0.441</td>
<td style="text-align: center;">63.8</td>
<td style="text-align: center;">67.5</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2-A</td>
<td style="text-align: center;">7.0</td>
<td style="text-align: center;">0.439</td>
<td style="text-align: center;">0.493</td>
<td style="text-align: center;">81.9</td>
<td style="text-align: center;">18.9</td>
<td style="text-align: center;">0.546</td>
<td style="text-align: center;">74.3</td>
<td style="text-align: center;">79.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2-R</td>
<td style="text-align: center;">8.2</td>
<td style="text-align: center;">0.444</td>
<td style="text-align: center;">0.502</td>
<td style="text-align: center;">80.0</td>
<td style="text-align: center;">14.8</td>
<td style="text-align: center;">0.480</td>
<td style="text-align: center;">67.7</td>
<td style="text-align: center;">67.7</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">24.1</td>
<td style="text-align: center;">0.592</td>
<td style="text-align: center;">0.701</td>
<td style="text-align: center;">72.2</td>
<td style="text-align: center;">32.0</td>
<td style="text-align: center;">0.649</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">93.4</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Google</td>
<td style="text-align: center;">33.8</td>
<td style="text-align: center;">0.651</td>
<td style="text-align: center;">0.753</td>
<td style="text-align: center;">77.2</td>
<td style="text-align: center;">39.9</td>
<td style="text-align: center;">0.690</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">94.5</td>
</tr>
<tr>
<td style="text-align: center;">English-Tamil</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-TA</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">TA-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB</td>
<td style="text-align: center;">25.8</td>
<td style="text-align: center;">0.706</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">64.4</td>
<td style="text-align: center;">31.5</td>
<td style="text-align: center;">0.645</td>
<td style="text-align: center;">80.4</td>
<td style="text-align: center;">92.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB-A</td>
<td style="text-align: center;">25.5</td>
<td style="text-align: center;">0.698</td>
<td style="text-align: center;">82.3</td>
<td style="text-align: center;">70.5</td>
<td style="text-align: center;">31.0</td>
<td style="text-align: center;">0.639</td>
<td style="text-align: center;">79.8</td>
<td style="text-align: center;">94.9</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB-R</td>
<td style="text-align: center;">25.8</td>
<td style="text-align: center;">0.707</td>
<td style="text-align: center;">82.9</td>
<td style="text-align: center;">81.6</td>
<td style="text-align: center;">31.5</td>
<td style="text-align: center;">0.645</td>
<td style="text-align: center;">80.4</td>
<td style="text-align: center;">97.9</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2</td>
<td style="text-align: center;">1.7</td>
<td style="text-align: center;">0.309</td>
<td style="text-align: center;">39.6</td>
<td style="text-align: center;">44.0</td>
<td style="text-align: center;">4.3</td>
<td style="text-align: center;">0.331</td>
<td style="text-align: center;">51.9</td>
<td style="text-align: center;">54.4</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2-A</td>
<td style="text-align: center;">1.2</td>
<td style="text-align: center;">0.341</td>
<td style="text-align: center;">39.6</td>
<td style="text-align: center;">88.9</td>
<td style="text-align: center;">9.1</td>
<td style="text-align: center;">0.417</td>
<td style="text-align: center;">61.5</td>
<td style="text-align: center;">87.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2-R</td>
<td style="text-align: center;">1.4</td>
<td style="text-align: center;">0.321</td>
<td style="text-align: center;">40.0</td>
<td style="text-align: center;">73.9</td>
<td style="text-align: center;">5.1</td>
<td style="text-align: center;">0.305</td>
<td style="text-align: center;">53.7</td>
<td style="text-align: center;">68.7</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">10.4</td>
<td style="text-align: center;">0.496</td>
<td style="text-align: center;">62.5</td>
<td style="text-align: center;">62.6</td>
<td style="text-align: center;">16.9</td>
<td style="text-align: center;">0.539</td>
<td style="text-align: center;">72.2</td>
<td style="text-align: center;">87.4</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Google</td>
<td style="text-align: center;">26.9</td>
<td style="text-align: center;">0.712</td>
<td style="text-align: center;">82.7</td>
<td style="text-align: center;">68.7</td>
<td style="text-align: center;">31.4</td>
<td style="text-align: center;">0.649</td>
<td style="text-align: center;">80.4</td>
<td style="text-align: center;">91.9</td>
</tr>
<tr>
<td style="text-align: center;">English-Telugu</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-TE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">TE-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB</td>
<td style="text-align: center;">31.4</td>
<td style="text-align: center;">0.628</td>
<td style="text-align: center;">81.1</td>
<td style="text-align: center;">80.6</td>
<td style="text-align: center;">34.7</td>
<td style="text-align: center;">0.643</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">87.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB-A</td>
<td style="text-align: center;">29.2</td>
<td style="text-align: center;">0.624</td>
<td style="text-align: center;">80.4</td>
<td style="text-align: center;">81.9</td>
<td style="text-align: center;">34.5</td>
<td style="text-align: center;">0.635</td>
<td style="text-align: center;">80.5</td>
<td style="text-align: center;">89.8</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NLLB-R</td>
<td style="text-align: center;">31.4</td>
<td style="text-align: center;">0.628</td>
<td style="text-align: center;">81.1</td>
<td style="text-align: center;">89.8</td>
<td style="text-align: center;">34.7</td>
<td style="text-align: center;">0.643</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">94.7</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2</td>
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">0.207</td>
<td style="text-align: center;">41.0</td>
<td style="text-align: center;">52.0</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">0.190</td>
<td style="text-align: center;">41.6</td>
<td style="text-align: center;">33.2</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2-A</td>
<td style="text-align: center;">4.0</td>
<td style="text-align: center;">0.244</td>
<td style="text-align: center;">42.3</td>
<td style="text-align: center;">88.8</td>
<td style="text-align: center;">5.8</td>
<td style="text-align: center;">0.356</td>
<td style="text-align: center;">56.7</td>
<td style="text-align: center;">78.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLaMA2-R</td>
<td style="text-align: center;">4.0</td>
<td style="text-align: center;">0.237</td>
<td style="text-align: center;">42.0</td>
<td style="text-align: center;">77.0</td>
<td style="text-align: center;">2.3</td>
<td style="text-align: center;">0.269</td>
<td style="text-align: center;">48.8</td>
<td style="text-align: center;">44.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">16.8</td>
<td style="text-align: center;">0.484</td>
<td style="text-align: center;">67.3</td>
<td style="text-align: center;">69.3</td>
<td style="text-align: center;">23.3</td>
<td style="text-align: center;">0.567</td>
<td style="text-align: center;">74.8</td>
<td style="text-align: center;">78.8</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Google</td>
<td style="text-align: center;">32.7</td>
<td style="text-align: center;">0.635</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">81.6</td>
<td style="text-align: center;">34.9</td>
<td style="text-align: center;">0.653</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">89.5</td>
</tr>
</tbody>
</table>
<p>Table 10: Automatic evaluation of all MT methods on six language pairs from both translation directions.
term "milk bread". "Milk" as an adjective does not adequately describe the dish, and "bread" no longer specifies the toasted aspect. The former issue likewise arises with CE, a literal translation
of "milk toast". In contrast, using SE, GPT-3.5 integrates the CSI explanation into the translation, freely translating the term as "toasted bread soaked in milk". This makes it easier for Chinese readers</p>
<p>to understand the meaning of "milk toast", as is reflected in the ratings of GPT-4 and the human annotator.</p>
<h2>J Generation Examples of LLaMA</h2>
<p>Table 12 shows the results of four prompting strategies on the CSI "burrito" from English to Chinese, defined as a "flour tortilla wrapped into a sealed cylindrical shape around various ingredients." Under the BI and CE strategies, LLaMA translates it as "bag" and "shell" respectively, failing to capture the essential feature of the dish, which is its rolled shape. The CT strategy successfully copies the dictionary translation. Interestingly, CE freely translates the word into "American southwest breakfast roll," accurately describing the food's shape. Additionally, CE prompts LLaMA to leverage related cultural knowledge to include the region description in the translation of the CSI.</p>
<h2>K Performance Across Regions</h2>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Avg.CSI-Match by regions.
Culture is often associated with a specific region, and its expressions can vary significantly across different regions and categories. To gain a deeper
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 9: Percentage of translation strategies.
understanding of the influence of region on CSI translation, we categorized CSI into three groups: CSI originating from countries primarily using the source language, countries predominantly using the target language, and countries utilizing languages other than the source and target languages. In the six groups of English-to-XX translations, we calculated the average CSI-Match values of these three CSI groups respectively, shown in Figure 8.</p>
<p>Given that target CSIs must have the translation in the target language, translating target CSIs is akin to back translation. However, when translating the source CSI or other CSIs, the translation may either not exist in the target language or exist with lower word frequency. Consequently, the model is expected to yield better results for the target CSI. Surprisingly, our analysis reveals that most models excel at translating the target CSI back into the target language in Romance languages (i.e., French and Spanish). Notably, Google Translate consistently achieves superior translations across all languages. ChatGPT demonstrates better translation performance in Chinese and Tamil, while LLaMA2 succeeds in Hindi and Tamil for target CSI translation. In contrast, traditional translation models NLLB struggle with all non-Romance languages, failing to outperform the source CSI translation. This suggests that LLMs may possess enhanced learning capabilities for translating culture-related content. However, it is important to note that the current translation performance is not consistently stable.</p>
<h2>L Comparison of Translation Strategies</h2>
<p>Translation Strategies To explore potential factors benefiting pragmatic translation quality, we let a human annotator examine the models' translation</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Strategy</th>
<th style="text-align: left;">Outputs</th>
<th style="text-align: center;">PTA of GPT-4o</th>
<th style="text-align: center;">PTA of Human</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">BI</td>
<td style="text-align: left;">该书中最终包含了1850种食谱，其中有烤面包（toast）。</td>
<td style="text-align: center;">Lose</td>
<td style="text-align: center;">Lose</td>
</tr>
<tr>
<td style="text-align: left;">CT</td>
<td style="text-align: left;">该书最终收录了1850个食谱，比如牛奶面包（milk bread）。</td>
<td style="text-align: center;">Lose</td>
<td style="text-align: center;">Lose</td>
</tr>
<tr>
<td style="text-align: left;">CE</td>
<td style="text-align: left;">这本书最终包含了1850个食谱，其中有牛奶土司（fiteral translation）。</td>
<td style="text-align: center;">Same</td>
<td style="text-align: center;">Same</td>
</tr>
<tr>
<td style="text-align: left;">SE</td>
<td style="text-align: left;">该书最终包含了1850个配方，其中有烤面包浸牛奶（toasted bread soaked in milk）。</td>
<td style="text-align: center;">Win</td>
<td style="text-align: center;">Win</td>
</tr>
<tr>
<td style="text-align: left;">Source</td>
<td style="text-align: left;">The book eventually contained 1,850 recipes including milk toast.</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">Reference</td>
<td style="text-align: left;">书中收录了1850个食谱，其中有牛奶土司（fiteral Translation）。</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">Knowledge</td>
<td style="text-align: left;">Translation: No existing Chinese translations <br> Explanation: the entity is a breakfast dish consisting of toasted bread in warm milk, typically with sugar and butter...</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 11: Non-translation CSI output examples of prompting strategy on GPT-3.5 and a source-reference sentence pair with cultural knowledge for En-Zh translations.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Strategy</th>
<th style="text-align: left;">Outputs</th>
<th style="text-align: center;">PTA of GPT-4o</th>
<th style="text-align: center;">PTA of Human</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">BI</td>
<td style="text-align: left;">爱尔兰早餐卷的制作方式类似于一顿早餐休闲袋（breakfast relaxing bag）。</td>
<td style="text-align: center;">Lose</td>
<td style="text-align: center;">Lose</td>
</tr>
<tr>
<td style="text-align: left;">CT</td>
<td style="text-align: left;">爱尔兰早饭卷饼是与墨西哥卷饼(copy the dictionary)准确相似的。</td>
<td style="text-align: center;">Win</td>
<td style="text-align: center;">Win</td>
</tr>
<tr>
<td style="text-align: left;">CE</td>
<td style="text-align: left;">爱尔兰早餐卷的制作方式与美国西南部的早餐卷(American southwest breakfast roll)一样。</td>
<td style="text-align: center;">Win</td>
<td style="text-align: center;">Win</td>
</tr>
<tr>
<td style="text-align: left;">SE</td>
<td style="text-align: left;">爱尔兰的早餐卷是和早餐完(breakfast shell)。</td>
<td style="text-align: center;">Win</td>
<td style="text-align: center;">Win</td>
</tr>
<tr>
<td style="text-align: left;">Source</td>
<td style="text-align: left;">The breakfast roll of Ireland is prepared similarly to a breakfast burrito.</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">Reference</td>
<td style="text-align: left;">爱尔兰的早餐面包卷制作方法亦类似于此（Replace the term with it）。</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">Knowledge</td>
<td style="text-align: left;">Translation:墨西哥卷饼 <br> Explanation: The entity is a dish in Mexican and Tex-Mex cuisine, consisting of <br> a flour tortilla wrapped into a sealed cylindrical shape around various ingredients...</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 12: CSI output examples of prompting strategy on LLaMA and a source-reference sentence pair with cultural knowledge for En-Zh translations.
strategies. We categorize the translation strategies of CSIs based on prior translation theories (Newmark, 1988; Persson, 2015). These theories define different categorizations of strategies to improve the comprehensibility of CSIs while maintaining cultural integrity. We select 4 strategies that are common to our dataset. They're 1) Transliteration that phonetically translates source CSIs; 2) Literal translation that directly translates word-by-word; 3) Description that integrates CSI descriptions of the CSIs into the translation; 4) Substitution that replace source CSIs by a semantically equivalent item in the target language; 5) Copy that directly copies the source language of CSI into the target language; 6) Wrong that indicates entirely incorrect translations; and 7) Other that employs other strategies in translation. Figure 9 shows the ratio of each strategy in four MT systems. We find that models with higher PTA (e.g., ChatGPT and Google translate) use description and substitution at a significantly higher rate, indicating that these two strategies help improve the understanding of CSI for target-language speakers. Notably, LLaMA2 incorporates a higher frequency of substitution and description methods compared to traditional NLLB. However, this increased diversity in
translation output comes at the cost of reduced stability in the outputs. As a result, LLaMA2 tends to yield more inaccurate translations, whereas NLLB relies more on Literal Translation and Transliteration to translate CSIs.
<img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Figure 10: Comparison of Translation Strategies: The value in each grid represents the win rate of the method on the x -axis in comparison to the method on the y -axis.</p>
<p>In order to further compare the impact of different translation strategies on pragmatic translation quality, we analyzed the comparison between</p>
<p>different translation strategies based on the ranking results of human evaluation. Specifically, we also rank the different translation strategies used by the MT systems according to the rank of the MT system's comprehensibility given by humans, which is shown in Figure 10. It's shown that the win rate of descriptions for all methods surpasses 0.5 , and the win rate of substitutions, excluding descriptions, significantly exceeds 0.5 . This implies that translations employing these two strategies are generally deemed more comprehensible by human annotators. Moreover, Literal Translation outperforms Transliteration, highlighting that transliteration may diminish the clarity of CSI in translation compared to a literal approach. Notably, the win rate of copying for both Literal Translation and Transliteration hovers around 50\%, indicating that these two methods may introduce confusion, and their readability underperforms directly copying the original word.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{12}$ https://platform.openai.com/ docs/guides/text-generation/ chat-completions-api
${ }^{13}$ https://cloud.google.com/translate/ docs/reference/rest&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{7}$ https://opus.nlpl.eu/Samanantar-v0.2. php&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>