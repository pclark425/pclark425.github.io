<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4821 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4821</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4821</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-103.html">extraction-schema-103</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <p><strong>Paper ID:</strong> paper-30e010ab295e5973c924088947608bf4a57e9b70</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/30e010ab295e5973c924088947608bf4a57e9b70" target="_blank">CGMI: Configurable General Multi-Agent Interaction Framework</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This work proposes a tree-structured methodology for the assignment, detection, and maintenance of agent personality, and designed a cognitive architecture equipped with a skill library based on the ACT* model, which contains memory, reflection, and planning modules.</p>
                <p><strong>Paper Abstract:</strong> Benefiting from the powerful capabilities of large language models (LLMs), agents based on LLMs have shown the potential to address domain-specific tasks and emulate human behaviors. However, the content generated by these agents remains somewhat superficial, owing to their limited domain expertise and the absence of an effective cognitive architecture. To address this, we present the Configurable General Multi-Agent Interaction (CGMI) framework, designed to replicate human interactions in real-world scenarios. Specifically, we propose a tree-structured methodology for the assignment, detection, and maintenance of agent personality. Additionally, we designed a cognitive architecture equipped with a skill library based on the ACT* model, which contains memory, reflection, and planning modules. We have also integrated general agents to augment the virtual environment's realism. Using the CGMI framework, we simulated numerous classroom interactions between teacher and students. The experiments indicate that aspects such as the teaching methodology, curriculum, and student performance closely mirror real classroom settings. We will open source our work.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4821.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4821.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CGMI agents (GPT-3.5)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Configurable General Multi-Agent Interaction agents instantiated with OpenAI gpt-3.5-turbo-16k</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Role-based agents (teacher, students, assistants, supervisors) instantiated with GPT-3.5-turbo-16k inside the CGMI framework and augmented with a cognitive architecture that explicitly records and retrieves memories for reflection and planning in a simulated classroom.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>CGMI role agents (GPT-3.5-turbo-16k)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Multiple role agents (teacher, students) and supporting general agents (teaching assistant, process supervisor, consistency checker) implemented by calling OpenAI's gpt-3.5-turbo-16k; each agent is assigned persona and a cognitive architecture (working, declarative, procedural memories and a skill library) to enable reflection, planning and role-consistent behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>working memory, declarative memory, procedural memory, skill library (domain knowledge)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>During interaction agents store transient inputs into Working Memory (M^w), then distill those using Chain-of-Thought (CoT) and Chain-of-Action (CoA) prompts into Declarative (M^d) and Procedural (M^p) memories; the Skill Library (L) provides domain-specific retrieval during reflection/planning; memories are retrieved to produce reflections R(t) and next actions ACT(t+1).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Classroom teaching simulation / multi-agent social simulation</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Simulate classroom teaching (teacher and multiple student agents plus assistant/supervisory agents) to generate interaction transcripts, reflect and plan across class sessions, and evaluate interaction realism using Flanders Interaction Analysis System and qualitative analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Qualitative claim: agents equipped with the cognitive memory architecture and persona retention produced deeper, more specialized reflections and plans and more realistic multi-turn classroom behavior compared to baselines without structured memory/persona; no numeric performance delta reported.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>No numeric evaluation of memory benefit; reliance on single LLM (gpt-3.5) for generation; LLM tendencies include forgetting roles over long dialogue and context-window limits; potential memory growth and management issues discussed but not quantitatively characterized.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Explicitly extracting and storing declarative and procedural memories via CoT/CoA and retrieving them with a skill library enables richer reflection and planning in LLM-driven agents; combining persona memory with supervisory checks reduces role-forgetting and stabilizes behavior in long multi-turn interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CGMI: Configurable General Multi-Agent Interaction Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4821.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4821.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cognitive architecture (M^w, M^d, M^p, L)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cognitive architecture with Working Memory, Declarative Memory, Procedural Memory, and Skill Library</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ACT*-inspired cognitive architecture where M^w (working memory) is condensed into M^d (declarative) and M^p (procedural) memories using CoT/CoA; Skill Library (L) provides domain knowledge retrieved during reflection and planning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Cognitive architecture (M^w, M^d, M^p, L)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Architecture components used by agents: Working Memory (M^w) collects immediate observations; Chain-of-Thought (P_cot) and Chain-of-Action (P_coa) prompts convert M^w into condensed Declarative (M^d) and Procedural (M^p) memories; Skill Library (L) stores domain-specific skills for retrieval during reflection/planning.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic/transformed working memory + declarative and procedural memory + external skill library</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Implementation described algorithmically: M_d(t) = F_sum(P_cot + M_w(F_get(t))); M_p(t) = F_sum(P_coa + M_w(F_get(t))). Reflection uses M_d(t) and L to produce R(t), which together with P(t) and current M_w produce actions ACT(t+1). Memory is used for multi-turn reflection, planning across sessions, and deriving procedural steps.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Enabling multi-turn reflection and planning in simulated classroom agents</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Used to let teacher agent reflect on classroom events, adapt plans between lessons, and produce context-aware utterances across sessions—i.e., multi-session pedagogical adaptation and in-session decision making.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Paper reports qualitative improvements: architecture allows parallel/bidirectional planning and deeper domain-specialized reflections versus a linear planning approach; no quantitative ablation isolating each memory component.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Growth of memory content and how to manage long-term scaling is noted but not empirically evaluated; retrieval noise, memory consolidation strategies, and costs of maintaining skill library vs context-window tradeoffs are not measured.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Combining CoT (for declarative knowledge) and CoA (for procedural knowledge) to populate structured memories plus a domain skill library supports richer agent reflection and cross-session adaptation; explicit memory modules help overcome LLM role-forgetting and shallow outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CGMI: Configurable General Multi-Agent Interaction Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4821.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4821.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tree-structured persona memory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tree-structured persona model for assignment, detection, and maintenance of agent personality</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hierarchical persona representation (root -> Big Five coarse nodes -> fine-grained leaf nodes) used to assign, test, and restore persona traits efficiently, reducing context-window usage and improving persona stability over long dialogues.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Tree-structured persona memory</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Persona represented as a tree T = {N1..Nn} with each node containing description and score; personality assignment by DFS traversal; randomized multi-level testing is used to detect persona forgetting and restore persona values when inconsistencies are found.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>structured persona memory (hierarchical trait store)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Persona values stored in a tree; during maintenance a random testing method probes coarse then fine nodes and, on mismatch, supplies true values back to the agent to restore persona memory—designed to save context window and avoid persona drift.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Preserving role-consistent behavior in long multi-turn dialogues (classroom simulation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Maintain consistent personality-driven behavior of student/teacher agents across many turns and across sessions to ensure realistic, individualized dialogue and decision-making (e.g., willingness to answer questions).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Qualitative comparison: agents with explicit persona memory produced more diverse, persona-consistent utterances; agents without persona allocation produced uniform, less differentiated expressions. No numeric metrics for persona retention reported.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Persona forgetting still possible without supervisory checks; testing and restoration incurs extra system steps; quantitative robustness under very long horizons not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>A compact hierarchical persona store plus randomized multilevel tests is an efficient way to maintain role memory and reduce context-window pressure for LLM agents, improving behavioral diversity and consistency.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CGMI: Configurable General Multi-Agent Interaction Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4821.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4821.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Answer-willingness judgment agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Agent that judges students' willingness to answer based on persona and classroom state</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A general assistant agent in CGMI that recommends which student should answer teacher questions by consulting persona, classroom dynamics and subject mastery; compared against random selection to show differences in recommended answer counts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Answer willingness judgment agent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A scenario-adapted general agent that uses stored persona traits and classroom state to score each student's willingness to answer and recommend students when the teacher poses questions.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>persona memory + short-term classroom state (working memory) used for scoring</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Computes willingness scores conditioned on persona and current STA(t) (classroom state) and selects recommenders; scores and selection counts are reported across a lesson to compare with random selection.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Student selection for teacher questions</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>When teacher asks whole-class questions, the agent computes willingness intensities per student and recommends who should answer to create more realistic and rational interaction flow.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Selection counts when using willingness-judgment: John 4, Emily 9, Ryan 6, Samantha 1, Ying Zheng 8 (counts over a complete lesson as reported).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Selection counts with random selection: John 7, Emily 3, Ryan 4, Samantha 6, Ying Zheng 8 (counts over a complete lesson as reported).</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Using persona-aware willingness scoring produced recommendations much more aligned with character traits (e.g., Emily more often recommended) versus random selection which produced less plausible distributions; paper treats this as evidence of increased interaction rationality but does not provide statistical tests.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>No formal evaluation of downstream learning outcomes or user-perceived realism; counts shown are small-sample illustrative results from simulated sessions, not large-scale benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Incorporating persona and situational memory into selection heuristics yields qualitatively more plausible interaction choices than random selection, demonstrating a clear use-case where lightweight memory retrieval improves multi-agent coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CGMI: Configurable General Multi-Agent Interaction Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4821.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4821.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Supervisory / Consistency-checker agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Supervisory agent and consistency checker for persona and process control</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Agents that monitor classroom progress, detect persona forgetting and process deviations, and intervene to restore persona or control lesson stage transitions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Supervisory / Consistency-checker agents (Atup / consistency checker)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>General agents in CGMI: Atup (teaching process supervisor) monitors teaching plan and stage transitions, producing SIG(t); consistency checker inspects statements against persona memory and restores or corrects persona when deviations are detected.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>persona memory monitoring, plan and stage state (working memory / supervisory state)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Continuously compares agent outputs to stored persona values and to the decomposed teaching plan TP+TS; if discrepancies are found, it informs role agents of true persona values or enforces stage transitions per plan.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Ensure persona consistency and adherence to teaching plan</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Detect 'personality forgetting', ensure teacher follows lesson plan, and decide when to transition between teaching phases or end discussion.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Paper argues supervisory agents mitigate role-forgetting and off-topic drift by restoring persona and enforcing plan stages; no quantitative ablation provided.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Intervention criteria and false-positive/false-negative rates for persona-detection not measured; extra complexity added to the multi-agent loop.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>External supervisory agents that check and restore persona-memory are a practical mechanism to counteract LLM drift/forgetting in long multi-agent interactions and to keep multi-stage tasks on-track.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CGMI: Configurable General Multi-Agent Interaction Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Generative Agents: Interactive Simulacra of Human Behavior <em>(Rating: 2)</em></li>
                <li>LLM-powered Autonomous Agents <em>(Rating: 2)</em></li>
                <li>ReAct: Synergizing Reasoning and Acting in Language Models <em>(Rating: 2)</em></li>
                <li>CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society <em>(Rating: 1)</em></li>
                <li>A spreading activation theory of memory <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4821",
    "paper_id": "paper-30e010ab295e5973c924088947608bf4a57e9b70",
    "extraction_schema_id": "extraction-schema-103",
    "extracted_data": [
        {
            "name_short": "CGMI agents (GPT-3.5)",
            "name_full": "Configurable General Multi-Agent Interaction agents instantiated with OpenAI gpt-3.5-turbo-16k",
            "brief_description": "Role-based agents (teacher, students, assistants, supervisors) instantiated with GPT-3.5-turbo-16k inside the CGMI framework and augmented with a cognitive architecture that explicitly records and retrieves memories for reflection and planning in a simulated classroom.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "CGMI role agents (GPT-3.5-turbo-16k)",
            "agent_description": "Multiple role agents (teacher, students) and supporting general agents (teaching assistant, process supervisor, consistency checker) implemented by calling OpenAI's gpt-3.5-turbo-16k; each agent is assigned persona and a cognitive architecture (working, declarative, procedural memories and a skill library) to enable reflection, planning and role-consistent behavior.",
            "memory_type": "working memory, declarative memory, procedural memory, skill library (domain knowledge)",
            "memory_description": "During interaction agents store transient inputs into Working Memory (M^w), then distill those using Chain-of-Thought (CoT) and Chain-of-Action (CoA) prompts into Declarative (M^d) and Procedural (M^p) memories; the Skill Library (L) provides domain-specific retrieval during reflection/planning; memories are retrieved to produce reflections R(t) and next actions ACT(t+1).",
            "task_name": "Classroom teaching simulation / multi-agent social simulation",
            "task_description": "Simulate classroom teaching (teacher and multiple student agents plus assistant/supervisory agents) to generate interaction transcripts, reflect and plan across class sessions, and evaluate interaction realism using Flanders Interaction Analysis System and qualitative analyses.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "Qualitative claim: agents equipped with the cognitive memory architecture and persona retention produced deeper, more specialized reflections and plans and more realistic multi-turn classroom behavior compared to baselines without structured memory/persona; no numeric performance delta reported.",
            "limitations_or_challenges": "No numeric evaluation of memory benefit; reliance on single LLM (gpt-3.5) for generation; LLM tendencies include forgetting roles over long dialogue and context-window limits; potential memory growth and management issues discussed but not quantitatively characterized.",
            "key_insights": "Explicitly extracting and storing declarative and procedural memories via CoT/CoA and retrieving them with a skill library enables richer reflection and planning in LLM-driven agents; combining persona memory with supervisory checks reduces role-forgetting and stabilizes behavior in long multi-turn interactions.",
            "uuid": "e4821.0",
            "source_info": {
                "paper_title": "CGMI: Configurable General Multi-Agent Interaction Framework",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Cognitive architecture (M^w, M^d, M^p, L)",
            "name_full": "Cognitive architecture with Working Memory, Declarative Memory, Procedural Memory, and Skill Library",
            "brief_description": "An ACT*-inspired cognitive architecture where M^w (working memory) is condensed into M^d (declarative) and M^p (procedural) memories using CoT/CoA; Skill Library (L) provides domain knowledge retrieved during reflection and planning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Cognitive architecture (M^w, M^d, M^p, L)",
            "agent_description": "Architecture components used by agents: Working Memory (M^w) collects immediate observations; Chain-of-Thought (P_cot) and Chain-of-Action (P_coa) prompts convert M^w into condensed Declarative (M^d) and Procedural (M^p) memories; Skill Library (L) stores domain-specific skills for retrieval during reflection/planning.",
            "memory_type": "episodic/transformed working memory + declarative and procedural memory + external skill library",
            "memory_description": "Implementation described algorithmically: M_d(t) = F_sum(P_cot + M_w(F_get(t))); M_p(t) = F_sum(P_coa + M_w(F_get(t))). Reflection uses M_d(t) and L to produce R(t), which together with P(t) and current M_w produce actions ACT(t+1). Memory is used for multi-turn reflection, planning across sessions, and deriving procedural steps.",
            "task_name": "Enabling multi-turn reflection and planning in simulated classroom agents",
            "task_description": "Used to let teacher agent reflect on classroom events, adapt plans between lessons, and produce context-aware utterances across sessions—i.e., multi-session pedagogical adaptation and in-session decision making.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "Paper reports qualitative improvements: architecture allows parallel/bidirectional planning and deeper domain-specialized reflections versus a linear planning approach; no quantitative ablation isolating each memory component.",
            "limitations_or_challenges": "Growth of memory content and how to manage long-term scaling is noted but not empirically evaluated; retrieval noise, memory consolidation strategies, and costs of maintaining skill library vs context-window tradeoffs are not measured.",
            "key_insights": "Combining CoT (for declarative knowledge) and CoA (for procedural knowledge) to populate structured memories plus a domain skill library supports richer agent reflection and cross-session adaptation; explicit memory modules help overcome LLM role-forgetting and shallow outputs.",
            "uuid": "e4821.1",
            "source_info": {
                "paper_title": "CGMI: Configurable General Multi-Agent Interaction Framework",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Tree-structured persona memory",
            "name_full": "Tree-structured persona model for assignment, detection, and maintenance of agent personality",
            "brief_description": "A hierarchical persona representation (root -&gt; Big Five coarse nodes -&gt; fine-grained leaf nodes) used to assign, test, and restore persona traits efficiently, reducing context-window usage and improving persona stability over long dialogues.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Tree-structured persona memory",
            "agent_description": "Persona represented as a tree T = {N1..Nn} with each node containing description and score; personality assignment by DFS traversal; randomized multi-level testing is used to detect persona forgetting and restore persona values when inconsistencies are found.",
            "memory_type": "structured persona memory (hierarchical trait store)",
            "memory_description": "Persona values stored in a tree; during maintenance a random testing method probes coarse then fine nodes and, on mismatch, supplies true values back to the agent to restore persona memory—designed to save context window and avoid persona drift.",
            "task_name": "Preserving role-consistent behavior in long multi-turn dialogues (classroom simulation)",
            "task_description": "Maintain consistent personality-driven behavior of student/teacher agents across many turns and across sessions to ensure realistic, individualized dialogue and decision-making (e.g., willingness to answer questions).",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "Qualitative comparison: agents with explicit persona memory produced more diverse, persona-consistent utterances; agents without persona allocation produced uniform, less differentiated expressions. No numeric metrics for persona retention reported.",
            "limitations_or_challenges": "Persona forgetting still possible without supervisory checks; testing and restoration incurs extra system steps; quantitative robustness under very long horizons not reported.",
            "key_insights": "A compact hierarchical persona store plus randomized multilevel tests is an efficient way to maintain role memory and reduce context-window pressure for LLM agents, improving behavioral diversity and consistency.",
            "uuid": "e4821.2",
            "source_info": {
                "paper_title": "CGMI: Configurable General Multi-Agent Interaction Framework",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Answer-willingness judgment agent",
            "name_full": "Agent that judges students' willingness to answer based on persona and classroom state",
            "brief_description": "A general assistant agent in CGMI that recommends which student should answer teacher questions by consulting persona, classroom dynamics and subject mastery; compared against random selection to show differences in recommended answer counts.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Answer willingness judgment agent",
            "agent_description": "A scenario-adapted general agent that uses stored persona traits and classroom state to score each student's willingness to answer and recommend students when the teacher poses questions.",
            "memory_type": "persona memory + short-term classroom state (working memory) used for scoring",
            "memory_description": "Computes willingness scores conditioned on persona and current STA(t) (classroom state) and selects recommenders; scores and selection counts are reported across a lesson to compare with random selection.",
            "task_name": "Student selection for teacher questions",
            "task_description": "When teacher asks whole-class questions, the agent computes willingness intensities per student and recommends who should answer to create more realistic and rational interaction flow.",
            "benchmark_name": null,
            "performance_with_memory": "Selection counts when using willingness-judgment: John 4, Emily 9, Ryan 6, Samantha 1, Ying Zheng 8 (counts over a complete lesson as reported).",
            "performance_without_memory": "Selection counts with random selection: John 7, Emily 3, Ryan 4, Samantha 6, Ying Zheng 8 (counts over a complete lesson as reported).",
            "has_performance_with_without_memory": true,
            "memory_comparison_summary": "Using persona-aware willingness scoring produced recommendations much more aligned with character traits (e.g., Emily more often recommended) versus random selection which produced less plausible distributions; paper treats this as evidence of increased interaction rationality but does not provide statistical tests.",
            "limitations_or_challenges": "No formal evaluation of downstream learning outcomes or user-perceived realism; counts shown are small-sample illustrative results from simulated sessions, not large-scale benchmarks.",
            "key_insights": "Incorporating persona and situational memory into selection heuristics yields qualitatively more plausible interaction choices than random selection, demonstrating a clear use-case where lightweight memory retrieval improves multi-agent coordination.",
            "uuid": "e4821.3",
            "source_info": {
                "paper_title": "CGMI: Configurable General Multi-Agent Interaction Framework",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Supervisory / Consistency-checker agent",
            "name_full": "Supervisory agent and consistency checker for persona and process control",
            "brief_description": "Agents that monitor classroom progress, detect persona forgetting and process deviations, and intervene to restore persona or control lesson stage transitions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Supervisory / Consistency-checker agents (Atup / consistency checker)",
            "agent_description": "General agents in CGMI: Atup (teaching process supervisor) monitors teaching plan and stage transitions, producing SIG(t); consistency checker inspects statements against persona memory and restores or corrects persona when deviations are detected.",
            "memory_type": "persona memory monitoring, plan and stage state (working memory / supervisory state)",
            "memory_description": "Continuously compares agent outputs to stored persona values and to the decomposed teaching plan TP+TS; if discrepancies are found, it informs role agents of true persona values or enforces stage transitions per plan.",
            "task_name": "Ensure persona consistency and adherence to teaching plan",
            "task_description": "Detect 'personality forgetting', ensure teacher follows lesson plan, and decide when to transition between teaching phases or end discussion.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "Paper argues supervisory agents mitigate role-forgetting and off-topic drift by restoring persona and enforcing plan stages; no quantitative ablation provided.",
            "limitations_or_challenges": "Intervention criteria and false-positive/false-negative rates for persona-detection not measured; extra complexity added to the multi-agent loop.",
            "key_insights": "External supervisory agents that check and restore persona-memory are a practical mechanism to counteract LLM drift/forgetting in long multi-agent interactions and to keep multi-stage tasks on-track.",
            "uuid": "e4821.4",
            "source_info": {
                "paper_title": "CGMI: Configurable General Multi-Agent Interaction Framework",
                "publication_date_yy_mm": "2023-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Generative Agents: Interactive Simulacra of Human Behavior",
            "rating": 2
        },
        {
            "paper_title": "LLM-powered Autonomous Agents",
            "rating": 2
        },
        {
            "paper_title": "ReAct: Synergizing Reasoning and Acting in Language Models",
            "rating": 2
        },
        {
            "paper_title": "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society",
            "rating": 1
        },
        {
            "paper_title": "A spreading activation theory of memory",
            "rating": 1
        }
    ],
    "cost": 0.011899499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>CGMI: Configurable General Multi-Agent Interaction Framework</h1>
<p>Jinxin Shi ${ }^{1}$, Jiabao Zhao ${ }^{1 *}$, Yilei Wang ${ }^{1}$, Xingjiao $\mathbf{W u}^{2}$, Jiawen $\mathbf{L i}^{1}$, Liang $\mathbf{H e}^{1}$<br>${ }^{1}$ School of Computer Science and Technology, East China Normal University, Shanghai, China<br>${ }^{2}$ School of Computer Science, Fudan University, Shanghai, China<br>52275901016@stu.ecnu.edu.cn, jbzhao@mail.ecnu.edu.cn, wangyilei@mail.ecnu.edu.cn, xjwu_cs@fudan.edu.cn, 52275901026@stu.ecnu.edu.cn, lhe@cs.ecnu.edu.cn</p>
<h4>Abstract</h4>
<p>Benefiting from the powerful capabilities of large language models (LLMs), agents based on LLMs have shown the potential to address domain-specific tasks and emulate human behaviors. However, the content generated by these agents remains somewhat superficial, owing to their limited domain expertise and the absence of an effective cognitive architecture. To address this, we present the Configurable General Multi-Agent Interaction (CGMI) framework, designed to replicate human interactions in real-world scenarios. Specifically, we propose a tree-structured methodology for the assignment, detection, and maintenance of agent personality. Additionally, we designed a cognitive architecture equipped with a skill library based on the ACT* model, which contains memory, reflection, and planning modules. We have also integrated general agents to augment the virtual environment's realism. Using the CGMI framework, we simulated numerous classroom interactions between teacher and students. The experiments indicate that aspects such as the teaching methodology, curriculum, and student performance closely mirror real classroom settings. We will open source our work.</p>
<h2>Introduction</h2>
<p>Agent-based social simulation (ABSS) simulates social interactions in a virtual environment. By observing agent behavior, we can explore complex social phenomena and verify the effects of different social strategies in a controlled setting(Davidsson and Paul 2002). However, improving simulation accuracy and designing complex agents remain key challenges(Aher, Arriaga, and Kalai 2023). With the capabilities of large language models (LLMs) such as GPT4 (OpenAI 2023), we can construct more complex environment and create more realistic agents to simulate social phenomena. However, when using LLMs to complete ABSS tasks, the following issues need to be addressed: (1) How to trigger the capabilities of LLMs to solve complex problems? (2) How to ensure that agents have a stable role and behavior output based on LLMs without forgetting? (3) How to design a communication mechanism for LLMs-based agents to truly simulate interactions?</p>
<p>Existing LLMs-based agents are mainly divided into action agents (Yao et al. 2023; Press et al. 2023) and plan-andexecute agents (Wang et al. 2023a). Action agents make decisions based on previous outputs and are suitable for small tasks. Plan-and-execute agents formulate and execute action
plans, suitable for long-term goal tasks. However, in complex scenarios, LLMs-based agents may produce mechanical and superficial content or not execute according to the plan. Inspired by the Adaptive Control of Thought (ACT*) model (Anderson and R 1983), we designed a cognitive architecture equipped with skill library for agents. Specifically, we employ the Chain of Thought (CoT) and Chain of Action (CoA) methods to extract declarative and procedural memories from the agent's working memory. During the reflection and planning processes, content is retrieved from the skill library, ensuring deeper and more specialized insights.</p>
<p>Assigning each intelligent agent with a unique identity, personality, and capability (Wang et al. 2023c) can offer a more humanized and emotional interactive experience, and also enhance the realism of simulating complex social scenarios (Argyle et al. 2023). Although LLMs like GPT4 possess strong role-playing capabilities, we found that LLMs tend to forget the original character settings in multi-turn dialogues and make decisions that are inconsistent with the character's design. Additionally, due to the limitations of the context window, it's challenging to set roles comprehensively and in fine detail. To address these issues, this paper introduces a tree-structured persona model for character assignment, detection, and maintenance, which is beneficial for agent interaction performance.</p>
<p>Influenced by assistant repeats instruction, infinite loop of messages, and conversation termination conditions, it remains challenging for chat agents to automatically collaborate to accomplish tasks in specific scenarios(Li et al. 2023). Setting scenario-adapted general agents is used to solve scenario-specific tasks for role agents, can help role agents avoid the aforementioned problems and enhance the realism of virtual scenes. For this purpose, this paper explores a Configurable General Multi-Agent Interaction Framework (CGMI), that can simulate real-life scenarios by binding general agents with role agents.</p>
<p>In this work, we take the "classroom teaching scenario" as an example, employing the CGMI framework to simulate the teaching process between "teacher" and "students", including teacher agent, student agents, assistant agents and supervisory agents. The experimental results indicate that the interactions in the virtual classroom aligns with actual teaching. It helps to assist in teacher instruction, evaluate teaching competencies, and validate teaching hypotheses.</p>
<p>In summary, the major contributions of this paper are threefold:</p>
<ul>
<li>The introduction of cognitive structure equipped with skill library, combining human cognition and skill library retrieval, enabling agents to engage in deep reflection and planning.</li>
<li>Designed a tree-structured approach for assigning, detecting, and maintaining the personal traits of agents, which reduces memory pressure on agents and improves stability.</li>
<li>The construction of a Configurable General Multi-agent Interaction framework (CGMI), supporting social experimental research in specific scenarios.</li>
</ul>
<h2>Related Work</h2>
<p>In this section, we will review agent research for solving domain problems, as well as agent research for simulating real human interaction processes.</p>
<h2>Agents for Solving Domain Problems</h2>
<p>Recent studies in LLMs have explored the utilization of agent systems for domain-specific tasks across various sectors. In healthcare, <em>Nair et al. (2023)</em> introduced a multi-agent system that enhances treatment recommendations via communication feedback. <em>Qian et al. (2023)</em> presented CHATDEV: a simulated development team where agents oversee design, coding, testing, and documentation, thereby ensuring effective game development coordination. <em>Alexandru et al. (2015)</em> designed a multi-agent e-learning environment tailored for education, providing customized support for instructional decisions. ChemCrow, highlighted in <em>Bran et al. (2023)</em>, formulated a framework that grants agents access to external knowledge repositories, consequently amplifying their efficacy in areas like organic synthesis, drug discovery, and materials design. <em>Wang et al. (2023b)</em> unveiled the DEPS interactive planning technique, addressing long-term planning challenges within the Minecraft game. Collectively, these investigations illuminate agent applications tailored to particular domains and hurdles.</p>
<h2>Agents for Simulating Human Interactions</h2>
<p>A subsequent line of research focuses on crafting agents that emulate human social behaviors. <em>Park et al. (2022)</em> fashioned a multi-agent town emulating authentic human activities, including orchestrating social parties. <em>Li et al. (2023)</em> delved into an agent communication framework that facilitates varied social roles and simulates AI social patterns. Emphasizing the importance of social situational learning, <em>Krishna et al. (2022)</em> developed an interactive agent capable of querying individuals online to assimilate visual knowledge. In the educational realm, <em>Markel et al. (2023)</em> employed GPT and other LLMs to mimic students, thus offering tangible training avenues for educators. <em>Jiang et al. (2023)</em> explored the simulation of consistent personality and gender variations using conditional language models. Cumulatively, these studies accentuate agents’ capacities to assimilate or mimic human social interactions.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Tree structure of the Big Five Personality Scale. The root node has five sub-nodes, representing five coarse personalities. Their dimension values range from 5-25, and each coarse personality has five fine-grained leaf nodes, with dimension values ranging from 1-5. The larger the value, the more pronounced the characteristics of agents.</p>
<h2>Method</h2>
<p>In this section, the tree-structured approach for personality assignment, detection and maintenance, the cognitive structure model enhanced with a skill library, and the construction process of CGMI will be introduced respectively. As shown in Figure 2, the process of reconstructing the "classroom teaching" scenario based on CGMI is displayed.</p>
<h3>Tree-Structured Persona Model</h3>
<p>Agent entities with unique personalities can not only complete specific tasks, but also enhance the authenticity of interactions <em>Qian et al. (2018); Mara Pudane and Radin (2017)</em>. In addition to setting specific personalities for agent entities, it is also necessary to set related styles according to the application scenario. For example, in teaching, teacher and students can have their own teaching and learning styles. However, if only a rough persona is set for agents, the personalized differences in its interactions are not obvious, and its stability will decrease as the complexity of roles, scenarios, and the length of the context increase <em>Jiang et al. (2023)</em>.</p>
<p>To solve this problem, this work proposes a tree-structured persona model for personality assignment, detection, and maintenance. We referred to the Big Five Personality Scale <em>John et al. (1999)</em>, the teaching style scale <em>Grigorenko and Sternberg (1993)</em>, and the learning style scale <em>Soloman and Felder (2005)</em>, and designed a tree structure to help agents remember and set different personas. Taking personality setting as an example, as shown in Figure 1, we built a personality scale T = {N1, N2, …, Nn} based on the Big Five Personality Scale, where n = 26. N1 is the root node, and N2 to Nn are child nodes. Each node Ni includes a description D_{i} and a score S_{i}. As shown in Algorithm 1, we use depth-first traversal to set personality traits for the intelligent entity A.</p>
<p>During the detection and maintenance process, this paper adopts an efficient random testing method, with the following specific steps: (1) Randomly select m coarse-grained</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Based on CGMI, a classroom teaching scenario is constructed. This scenario includes 3 general intelligent agents (teaching assistant agent, teaching process supervisor agent, consistency checker agent) and 6 role agents (teacher Mrs. Smith, student Ying Zheng, student Emily, student John, student Ryan and student Samantha). After the user inputs the course topic, the virtual classroom teaching scenario launches. The teaching assistant agent generates corresponding teaching plans and distributes them to Mrs. Smith and the teaching process supervisor agent. Mrs. Smith divides the teaching process into stages according to the plan. The teaching process supervisor agent monitors whether the current stage has ended and decides whether to enter the next stage. Before each role agent's statement, the consistency checker agent detects and maintains consistency between its personality and statement content. When Mrs. Smith asks the class questions, the consistency checker agent judges each student's willingness to answer based on personality and classroom status, simulating real hand-raising.</p>
<div class="codehilite"><pre><span></span><code><span class="nx">Algorithm</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="w"> </span><span class="nx">The</span><span class="w"> </span><span class="nx">process</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="nx">endowing</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">Big</span><span class="w"> </span><span class="nx">Five</span><span class="w"> </span><span class="nx">personalities</span><span class="w"> </span><span class="nx">through</span><span class="w"> </span><span class="nx">Deep</span><span class="w"> </span><span class="nx">First</span><span class="w"> </span><span class="nx">Traverse</span><span class="w"> </span><span class="p">(</span><span class="nx">DFS</span><span class="p">)</span><span class="w"> </span><span class="nx">implementation</span><span class="p">.</span>
<span class="nx">Input</span><span class="p">:</span><span class="w"> </span><span class="nx">Big</span><span class="w"> </span><span class="nx">Five</span><span class="w"> </span><span class="nx">Scale</span><span class="w"> </span><span class="nx">T</span><span class="p">,</span><span class="w"> </span><span class="nx">Agent</span><span class="w"> </span><span class="nx">A</span>
<span class="nx">Output</span><span class="p">:</span><span class="w"> </span><span class="nx">A</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="p">{</span><span class="nx">T</span><span class="p">}</span>
<span class="w">    </span><span class="nx">Define</span><span class="w"> </span><span class="nx">stack</span>
<span class="w">    </span><span class="nx">Push</span><span class="w"> </span><span class="nx">root</span><span class="w"> </span><span class="nx">node</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="nx">T</span><span class="w"> </span><span class="nx">into</span><span class="w"> </span><span class="nx">stack</span>
<span class="w">    </span><span class="k">while</span><span class="w"> </span><span class="nx">stack</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="nx">empty</span><span class="w"> </span><span class="nx">do</span>
<span class="w">        </span><span class="nx">N</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nx">N</span>
<span class="w">            </span><span class="nx">i</span>
<span class="w">            </span><span class="nx">has</span><span class="w"> </span><span class="nx">child</span><span class="w"> </span><span class="nx">nodes</span><span class="w"> </span><span class="k">then</span>
<span class="w">            </span><span class="nx">Push</span><span class="w"> </span><span class="nx">all</span><span class="w"> </span><span class="nx">child</span><span class="w"> </span><span class="nx">nodes</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="nx">N</span>
<span class="w">            </span><span class="nx">end</span><span class="w"> </span><span class="k">if</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="nx">A</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="p">{</span><span class="nx">T</span><span class="p">}</span>
</code></pre></div>

<p>personalities for testing; (2) If the test is correct, select m fine-grained personalities under these m coarse-grained personalities for further testing. If the fine-grained test is also correct, it is believed that the agent's personality memory is complete; (3) If an error occurs at any stage, the real values of all selected personalities will be informed to the agent to restore its personality memory.</p>
<p>This random testing method is not only efficient and comprehensive but also saves contextual window resources. Multi-level testing can avoid the illusion of unchanged coarse-grained personality due to changes in fine-grained personality. This method can also be applied to other related character scales, as detailed in Appendix.</p>
<h3>Cognitive architecture equipped with skill library</h3>
<p>Over time, as interactions between the agent and its environment accumulate, there's a marked increase in the volume and intricacy of the agent's memory stream. (Park et al. 2023; Weng and Lilian 2023) This proliferation necessitates an advanced cognitive architecture to process the burgeoning data. However, the current cognitive architecture embedded in LLMs-based agents can only allow agents to plan and reflect in a linear fashion, reminiscent of an assembly line. To redress this shortfall, this paper introduces the cognitive architecture infused with a domain-specific skill library, rooted in the Adaptive Control of Thought (ACT*) paradigm (Anderson and R 1983). This novel architecture facilitates parallel and bidirectional planning and reflection, drawing upon the agent's memory and skill repository, thus steering agent development towards enhanced adaptive control and rational deliberation akin to human cognition.</p>
<p>Central to this cognitive framework are four pivotal components, as delineated in Figure 3. The foundational pil-</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The cognitive architecture with skill library.</p>
<p>lars of agent cognition are Declarative (M<sup>d</sup>) and Procedural Memory (M<sup>p</sup>). The former embodies the agent's library of factual knowledge, encompassing data on objects, individuals, locales, occurrences and their interconnections, serving as the cornerstone for rational deduction. Procedural memory, on the other hand, comprises operational guidelines that empower the agent to pursue objectives and surmount challenges. These guidelines operate by matching with facts stored declaratively, triggering actions geared towards achieving specific objectives. Skill Library (L) is a configurable domain knowledge base that provides domain knowledge for the reflective planning of intelligent agents. It can be viewed as a compilation of the agent's abilities to leverage its knowledge in situation-specific ways. Working Memory (M<sup>w</sup>) is an agile, self-refreshing module acting as a bridge between memory and the external milieu. It not only directs agent actions based on processed memories but also assimilates external data, subsequently refining it into declarative and procedural knowledge via the Chain of Thoughts (CoT) and Chain of Actions (CoA).</p>
<p>When starting interaction, an agent, denoted as A = {T, B} and equipped with the cognitive architecture B = {M<sup>w</sup>, M<sup>d</sup>, M<sup>p</sup>, L}, seamlessly activates these four components, ensuring prolonged engagements in multifaceted settings. Formally, the mechanism through which the agent gleans information from the external realm at a given time t is depicted as F<sub>get</sub>(t).</p>
<p>Upon temporary storage in M<sup>w</sup>, the agent A distills this information using thought and action chains, leading to the formation of Declarative and Procedural Memory:</p>
<p>$$M_d(t) = F_{sum}(P_{cot} + M_w(F_{get}(t))) \tag{1}$$</p>
<p>$$M_p(t) = F_{sum}(P_{coa} + M_w(F_{get}(t))) \tag{2}$$</p>
<p>where Pcot signifies the CoT prompt (e.g., "Summarize the class content sequentially"), while Pcoa denotes the CoA prompt (e.g., "Detail the pedagogical steps"). Fsum delineates the process of condensing information within the Working Memory. In subsequent interactions, when agent A readies its response for moment t + 1, it first taps into M<sup>d</sup>, M<sup>p</sup>, and L, extracting reflections and strategies from the preceding moment, t, which then translates into overt actions:</p>
<p>$$R(t) = F_{ref}(M_d(t) + L) \tag{3}$$</p>
<p>$$ACT(t + 1) = F_{act}(R(t) + P(t) + M_w(F_{get}(t)) \tag{4}$$</p>
<p>where Fref and Fpla illustrate the reflection and synthesis processes for Declarative and Procedural Memory at moment t, respectively. R(t) and P(t) represent the reflective and strategic outcomes at time t, while Fact encapsulates the amalgamation of these insights, plans, and the skill repertoire to forge ACT(t + 1).</p>
<h3>Configurable General Multi-Agent Interaction Framework</h3>
<p>With the support of structured persona models and enhanced cognitive models with skill libraries, a single agent can play multiple roles in specific scenarios to complete complex tasks. However, currently, using LLMs-based agents to achieve preset goals in specific tasks often fails to present real social interactions, because simulating social phenomena requires multiple Agents to interact and cooperate in a human-like manner. Therefore, this paper introduces the Configurable General Multi-Agent Interaction Framework (CGMI) that can simulate real interactions.</p>
<p>In the context of classroom teaching, this paper explores how CGMI promotes interaction and collaboration among multiple agents. In addition to virtual teacher Agent and virtual student Agents, we have also designed assistant Agents responsible for setting educational goals, planning teaching schedules, and analyzing students' willingness to speak to support teacher's teaching activities. These assistant Agents can adjust their functional configurations based on specific scenarios. To ensure the quality of the interaction process, we introduced a supervisory Agent responsible for detecting "personality forgetting", ensuring that the "teacher Agent proceeds with teaching as planned", and "determining when to end the discussion". Through the CGMI framework, each intelligent entity can engage in more in-depth personalized dialogues and task completion, collaboratively creating a realistic virtual teaching environment.</p>
<p>Using classroom teaching as an example, based on cognitive structure and persona models, the intelligent agent A = {T, B} can play different roles in specific scenarios. The state of the classroom at time t is represented as:</p>
<p>$$STA(t) = I(A_{tea}, A_{stu}, t) \tag{6}$$</p>
<p>Where I represents the interaction process, Atea represents the teacher, and Atu represents a set of students, denoted as {Atu1, Atsu2, ..., Atsu<sup>a</sup>}. Interact represents the interaction between the teacher and students.</p>
<p>When the lesson begins, the supervisory Agent Atup receives the teaching plan TP and the multi-stage teaching process TS decomposed by the teacher. Atup monitors the classroom, obtains the phase transition signal, and decides whether to proceed to the next teaching phase or end the lesson. This can be represented as:</p>
<p>$$SIG(t) = A_{sup}(TP + TS + STA(t)) \tag{7}$$</p>
<p>With the help of Atup, teachers can teach more effectively, and the interaction between teachers and students is more targeted, without deviating from the topic. During the questioning session, the supervisory Agent selects the most suitable student to ask questions based on the student's cognitive analysis of their willingness to speak. The supervisory Agent also monitors the persona status of the intelligent</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Course-ONE</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Class process: <br> Mrs. Smith: Quadratic equations can be found in various fields, from ... <br> Emily: I'm really nervous about this lesson on quadratic equations. <br> Mrs. Smith: Emily, but please know that I am here to...</td>
<td style="text-align: center;">Reflection: <br> ... student interests. I need more encouragement for my students, Emily gets nervous when facing math. Mrs. Smith utilized ... Plan: <br> - Using interesting forms and gamified teaching to stimulate students' interest in learning and reduce resistance....</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Class process: <br> Mrs. Smith: ... Can anyone explain how the coefficients ' $b$ ' and ' $c$ ' influence the quadratic function's graph?... Emily: The coefficient 'b' in the quadratic function affects ... Mrs. Smith: Excellent explanation, Emily. I'm glad to see that you're no longer afraid of mathematics! You...</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Class process: <br> Mrs. Smith: ... Remember, learning is a journey that is best enjoyed together. Let's embark on this exciting... <br> John: ...Could you provide an example for us ...</td>
<td style="text-align: center;">Reflection: <br> Mrs. Smith effectively engages and motivates students in learning about quadratic functions... <br> Plan: <br> - ...involve changing different parameters of the quadratic function (such as coefficients and constants)...</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Course-THREE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Class process: <br> Mrs. Smith: ... Remember, learning is a journey that is best enjoyed together. Let's embark on this exciting... <br> John: ...Could you provide an example for us ...</td>
<td style="text-align: center;">Reflection: <br> ...Sometimes students may not understand and they may need more examples... <br> Plan: <br> - ... their understanding and application of quadratic function....using the example of buying apples...</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Figure 4: Teacher Mrs Smith's classroom experience and her reflection and planning in virtual classroom. The red, green, and blue characters in the picture represent the events discovered by the teacher in three different classes. The teacher reflects and plans on these events, and serves as a focus in the subsequent teaching process.
agents in real-time and maintains it if there's any deviation. Users can also operate the supervisory Agent to adjust the classroom process according to their needs.</p>
<h2>Experiments</h2>
<p>In this section, we first present the "classroom teaching scenario" reconstructed using the CGMI framework and analyze the teaching behaviors during the class. Subsequently, through comparative experiments, we showcase the behavioral advantages of agents equipped with human intrinsic traits (such as personality, cognitive structures, etc.). Lastly, we analyze the significance of generic intelligent agents in enhancing the interaction logic of role-specific agents. In our experiment, we adopted OpenAI's gpt-3.5-turbo-16k model (OpenAI 2022), instantiating one teacher, five students, and four generic intelligent agents. Each agent was given a unique role setting and task objective (see appendix).</p>
<h2>Analysis of Teaching Behavior</h2>
<p>We employed the Flanders Interaction Analysis System (FIAS) to examine interactive behaviors between teachers and students across three virtual classroom sessions. We hired 2 trained experts to encode the teaching behaviors. These two encoders worked independently, encoding each sentence once and sequentially constructing a behavior sequence, ultimately achieving consistent evaluation results.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Categories</th>
<th style="text-align: left;">C1</th>
<th style="text-align: left;">C2</th>
<th style="text-align: left;">C3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">B1.Accept feeling</td>
<td style="text-align: left;">$0.35 \%$</td>
<td style="text-align: left;">$0 \%$</td>
<td style="text-align: left;">$0.30 \%$</td>
</tr>
<tr>
<td style="text-align: left;">B2.Praises or encourages</td>
<td style="text-align: left;">$19.08 \%$</td>
<td style="text-align: left;">$12.99 \%$</td>
<td style="text-align: left;">$11.98 \%$</td>
</tr>
<tr>
<td style="text-align: left;">B3.Accept ideas</td>
<td style="text-align: left;">$3.89 \%$</td>
<td style="text-align: left;">$6.39 \%$</td>
<td style="text-align: left;">$5.69 \%$</td>
</tr>
<tr>
<td style="text-align: left;">B4.Asks questions</td>
<td style="text-align: left;">$1.77 \%$</td>
<td style="text-align: left;">$1.03 \%$</td>
<td style="text-align: left;">$1.50 \%$</td>
</tr>
<tr>
<td style="text-align: left;">B5.Lecturing</td>
<td style="text-align: left;">$22.97 \%$</td>
<td style="text-align: left;">$33.61 \%$</td>
<td style="text-align: left;">$35.61 \%$</td>
</tr>
<tr>
<td style="text-align: left;">B6.Gives directions</td>
<td style="text-align: left;">$6.36 \%$</td>
<td style="text-align: left;">$7.01 \%$</td>
<td style="text-align: left;">$5.09 \%$</td>
</tr>
<tr>
<td style="text-align: left;">B7.Criticising</td>
<td style="text-align: left;">$5.65 \%$</td>
<td style="text-align: left;">$1.24 \%$</td>
<td style="text-align: left;">$1.20 \%$</td>
</tr>
<tr>
<td style="text-align: left;">B8.Pupil talk response</td>
<td style="text-align: left;">$28.62 \%$</td>
<td style="text-align: left;">$20.41 \%$</td>
<td style="text-align: left;">$21.56 \%$</td>
</tr>
<tr>
<td style="text-align: left;">B9.Pupil talk Initiation</td>
<td style="text-align: left;">$11.31 \%$</td>
<td style="text-align: left;">$17.32 \%$</td>
<td style="text-align: left;">$17.07 \%$</td>
</tr>
</tbody>
</table>
<p>Table 1: Analysis results based on FIAS</p>
<p>These sessions focused on the following topics: C1: Concept of the Quadratic Equation, C2: Methods for Solving the Quadratic Equation, and C3: Applications of the Quadratic Equation.</p>
<p>Table 1 shows the proportion of each interaction behavior in the course. Overall, the variety of interactions in the virtual classroom is rich and consistent with actual teaching, validating the effectiveness of CGMI by demonstrating its ability to effectively organize interactions and collaboration between multi-agents.</p>
<p>According to the results in table 1, teacher's behavior(B1, B2, B3, B4, B5, B6, B7) made up an average of $61.23 \%$ of the discourse in these mathematics sessions. In contrast, stu-</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 5: The influence of personal traits on agent expression.
dents' behavior(B8, B9) facilitated by teacher prompts represented an average of $23.53 \%$. Notably, the ratio of indirect influence behaviors (B1, B2, B3, B4) to direct influence behaviors (B5, B6, B7) remained below 1. This suggests that the virtual classroom is dominated by teachers who have direct control over the overall classroom. Furthermore, student-initiated interactions constituted about $15.23 \%$, suggesting that students remain engaged, deliberating, and responding to queries under the teacher's guidance.</p>
<h2>Intrinsic Characteristics of Intelligent Agents</h2>
<p>To assess the efficacy of the proposed cognitive architecture, we examined it through the lens of a teacher, Mrs. Smith, analyzing her classroom practices and her subsequent reflections and plans. As illustrated in Figure 4, we displayed the part of her reflective and planning processes within a single lesson and across two different lessons. Our analysis sought to elucidate the influence of the cognitive structure on agents, emphasizing the model's capacity for both reflection and planning. We analyzed the effectiveness of the algorithm from within and between classes.
(1) Within the lesson: In Course-ONE, student Emily conveyed her anxiety, stating, "I'm really nervous about this lesson." Mrs. Smith, attuned to this feedback, incorporated it into her reflective process and instructional planning. Drawing from a library of teaching techniques, she employed strategies such as heightened encouragement and gamified instructional methods. A parallel observation was made in Course-TWO and Course-THREE. Mrs. Smith prompted students to consider, "How do coefficients 'b' and 'c' affect the graph of a quadratic function?", and reiterated the topic in her subsequent planning. Following the actions of encouragement, Mrs. Smith's reflective records recognized her efforts in affirming and uplifting students.
(2) Between lessons: Across different courses, the proposed cognitive structure is still valid. It plays a crucial role in refining Mrs. Smith's teaching focus, deepening understanding and adapting teaching methods. For example,
through reflection on Course-ONE, Mrs Smith found that Emily exhibited anxiety when faced with mathematical challenges. This insight directly influenced Mrs.Smith reassuring statement to Emily in Course-TWO: "I'm pleased to see you've overcome your apprehension towards mathematics."</p>
<p>The effect of tree-structured persona model. To discern whether agents with varied personality traits exhibit distinguishable behaviors during interactions, we executed a comparative study depicted in Figure 5. One lesson involved personality allocation, detection, and maintenance, whereas the other lacked any defined agent personalities. In the absence of assigned traits, there was a notable uniformity in the expressions of five students, often resorting to statements like, "I'm excited...". In contrast, once unique personality traits were allocated, their expressions became more nuanced and aligned with their respective personas. For instance, the outgoing Ryan would suggest a "discussion with classmates", while the industrious Ying Zheng would exude a "passion for learning".</p>
<p>Furthermore, on the right side of Figure 5, the statements made by the student Emily throughout the class are displayed. Judging from the records of her remarks, the Emily Agent has demonstrated a consistent persona, interacting with teachers and classmates based on the previously established persona. In detail, she remarked, "I'm considerably anxious about this quadratic equations segment." at the start of the class. In the middle part of the course, she still showed her unfamiliarity and lack of confidence in the current knowledge in the interaction, expressing like, "I'm not well-versed with quadratic equations, yet I'm keen on learning and exploring various aspects...", and "Being an average student, I might require a while to fully comprehend quadratic equations".</p>
<p>By imbuing agents with human-like qualities, they can adeptly distill insights from evolving scenarios and exhibit individualized responses. In addition, it also can make agents recalibrate actions based on accumulated knowledge and abilities. This significantly augments agents' adaptive</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 6: The influence of personal traits on agent expression.
capabilities in multifaceted environments. Concurrently, the tree-structured character model introduced in this study effectively and efficiently captures and retains the personalized data of agents.</p>
<h2>Quantitative Analysis of Interaction Logic</h2>
<p>Based on the "classroom teaching" scenario restored by CGMI, this paper compares the rationality of different interaction logics under the same question.</p>
<p>Analysis of willingness to speak. As shown in the Figure 6, when the teacher posed the question to all students: "Can anyone tell me the general form of a quadratic function?", the outcomes differed between the answer willingness judgment agent and random selection methods. The former showed the students' willingness to answer intensity: John: 3, Emily: 5, Ryan: 4, Samantha: 2, Ying Zheng: 4. Notably, the students' willingness strength is highly consistent with their character traits. For instance, the expressive Emily exhibited high willingness to answer, while the introverted Samantha showed less. The random selection method, however, produced different results.</p>
<p>The discrepancy between the two methods is not coincidental. We recorded the number of students recommended by the two different methods to answer when the teacher posed questions to the entire class during a complete lesson. From the Figure 6, it can be seen that the answer willingness judgment agent, considering factors like students' personalities, classroom dynamics, and their grasp of the subject, recommended John 4 times, Emily 9 times, Ryan 6 times, Samantha 1 time, and Ying Zheng 8 times. However, with random selection, the results were John 7 times, Emily 3 times, Ryan 4 times, Samantha 6 times, and Ying Zheng 8 times. The expressive Emily only volunteered to answer 3 times, significantly undermining the rationality of the interaction process between the teacher and students in the virtual scenario.</p>
<p>The effectiveness of questioning. In addition to posing questions to all students, teachers also selectively direct questions to specific students. This selection is influenced by</p>
<h2>Teaching Plan:</h2>
<h2>Based on the students' personalities:</h2>
<ul>
<li>Ying Zheng (Academic Enthusiast): Challenge Ying Zheng with advanced problem-solving tasks and encourage him to explore additional methods for solving</li>
</ul>
<h2>Class process:</h2>
<p>Mrs. Smith: Next, we will learn about the different methods of solving quadratic equations...Ying Zheng! Exploring different methods of solving...
Ying Zheng: By trying out various approaches, we can...</p>
<p>Figure 7: The influence of personal traits on agent expression.
two aspects: (1) some teaching plans targeting particular students and (2) it's influenced by the teacher's analysis of the student's status and classroom dynamics during the teaching process. As shown in Figure 7, the teaching plan specifies that the teacher can encourage Ying Zheng to explore different solutions. As observed in the subsequent teaching process, the teacher aptly integrated this instructional arrangement during the lecture and specifically asked Ying Zheng to explore, leading to the next phase of instruction.</p>
<p>In summary, the flexible interaction logic setting ensures that the interaction process among multiple agents is no longer a random choice without considering the actual situation and role settings, nor a process where every role needs to be expressed. This introduces more possibilities for virtual scenarios.</p>
<h2>Conclusion</h2>
<p>This paper introduces a multi-agent interaction framework (CGMI) that supports personalized configurations, enabling multiple agents to engage in anthropomorphic interactions and collaborations. It also can simulate domain-specific social phenomena. We designed a cognitive architecture equipped with domain skill library. It allows agents to combine domain knowledge for reflection and planning, and condense the working memory into declarative and procedural memories. With the assistance of general agents, the authenticity of scenarios can be further enhanced. Moreover, we employed a virtual "classroom teaching" scenario to simulate the teaching process between teachers and students, and conducted comparative analysis of their interaction content and logic, verifying the effectiveness of CGMI.</p>
<p>In the future, we hope that the social scenarios simulated by multiple agents will not only provide users with valuable social experimental data, aiding the development of large models, but also support industrial applications, such as assisting teaching and gamified teaching.</p>
<h2>References</h2>
<p>Aher, G. V.; Arriaga, R. I.; and Kalai, A. T. 2023. Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies. In Krause, A.; Brunskill, E.; Cho, K.; Engelhardt, B.; Sabato, S.; and Scarlett, J., eds., Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, 337-371. PMLR.
Alexandru, A.; Tirziu, E.; Tudora, E.; and Bica, O. 2015. Enhanced education by using intelligent agents in multiagent adaptive e-learning systems. Studies in Informatics and Control, 24(1): 13-22.
Anderson; and R, J. 1983. A spreading activation theory of memory. Journal of verbal learning and verbal behavior, 22(3): 261-295.
Argyle, L. P.; Busby, E. C.; Fulda, N.; Gubler, J. R.; Rytting, C.; and Wingate, D. 2023. Out of one, many: Using language models to simulate human samples. Political Analysis, 31(3): 337-351.
Bran, A. M.; Cox, S.; White, A. D.; and Schwaller, P. 2023. ChemCrow: Augmenting large-language models with chemistry tools. arXiv:2304.05376.
Davidsson; and Paul. 2002. Agent based social simulation: A computer science view. Journal of artificial societies and social simulation, 5(1).
Grigorenko, E.; and Sternberg, R. 1993. Thinking styles in teaching inventory. unpublished test, Yale University.
Jiang, H.; Zhang, X.; Cao, X.; and Kabbara, J. 2023. PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences. arXiv:2305.02547.
John, O. P.; Srivastava, S.; et al. 1999. The Big-Five trait taxonomy: History, measurement, and theoretical perspectives. Krishna, R.; Lee, D.; Fei-Fei, L.; and Bernstein, M. S. 2022. Socially situated artificial intelligence enables learning from human interaction. Proceedings of the National Academy of Sciences, 119(39): e2115730119.
Li, G.; Hammoud, H. A. A. K.; Itani, H.; Khizbullin, D.; and Ghanem, B. 2023. CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society. arXiv:2303.17760.
Mara Pudane, E. L.; and Radin, M. A. 2017. Human Emotional Behavior Simulation in Intelligent Agents: Processes and Architecture. Procedia Computer Science, 104: 517524. ICTE 2016, Riga Technical University, Latvia.</p>
<p>Markel, J. M.; Opferman, S. G.; Landay, J. A.; and Piech, C. 2023. GPTeach: Interactive TA Training with GPT Based Students.
Nair, V.; Schumacher, E.; Tso, G.; and Kannan, A. 2023. DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents. arXiv:2303.17071. OpenAI. 2022. OpenAI. Introducing chatgpt. https://openai. com/blog/chatgpt. Accessed: 2023-03-1.
OpenAI. 2023. GPT-4 Technical Report. arXiv:2303.08774.
Park, J. S.; O’Brien, J. C.; Cai, C. J.; Morris, M. R.; Liang, P.; and Bernstein, M. S. 2023. Generative Agents: Interactive Simulacra of Human Behavior. arXiv:2304.03442.</p>
<p>Park, J. S.; Popowski, L.; Cai, C.; Morris, M. R.; Liang, P.; and Bernstein, M. S. 2022. Social Simulacra: Creating Populated Prototypes for Social Computing Systems. In Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology, UIST '22. New York, NY, USA: Association for Computing Machinery. ISBN 9781450393201.
Press, O.; Zhang, M.; Min, S.; Schmidt, L.; Smith, N. A.; and Lewis, M. 2023. Measuring and Narrowing the Compositionality Gap in Language Models. arXiv:2210.03350.
Qian, C.; Cong, X.; Yang, C.; Chen, W.; Su, Y.; Xu, J.; Liu, Z.; and Sun, M. 2023. Communicative Agents for Software Development. arXiv:2307.07924.
Qian, Q.; Huang, M.; Zhao, H.; Xu, J.; and Zhu, X. 2018. Assigning Personality/Profile to a Chatting Machine for Coherent Conversation Generation. In Ijcai, 4279-4285.
Soloman, B. A.; and Felder, R. M. 2005. Index of learning styles questionnaire. NC State University. Available online at: http://www. engr. ncsu. edu/learningstyles/ilsweb. html (last visited on 14.05. 2010), 70.
Wang, L.; Xu, W.; Lan, Y.; Hu, Z.; Lan, Y.; Lee, R. K.-W.; and Lim, E.-P. 2023a. Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models. arXiv:2305.04091.
Wang, Z.; Cai, S.; Liu, A.; Ma, X.; and Liang, Y. 2023b. Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents. arXiv:2302.01560.
Wang, Z.; Mao, S.; Wu, W.; Ge, T.; Wei, F.; and Ji, H. 2023c. Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona SelfCollaboration. arXiv:2307.05300.
Weng and Lilian. 2023. LLM-powered Autonomous Agents. https://lilianweng.github.io/posts/2023-06-23-agent/. Accessed: 2023-06-23.
Yao, S.; Zhao, J.; Yu, D.; Du, N.; Shafran, I.; Narasimhan, K.; and Cao, Y. 2023. ReAct: Synergizing Reasoning and Acting in Language Models. arXiv:2210.03629.</p>
<h2>Appendix</h2>
<p>The appendix presents the character settings for each character, a tree-structured learning style scale, and a teaching style scale.</p>
<h2>Role Set</h2>
<p>In this work, the initialization of role agents is mainly carried out from the perspectives of the career, name, basic information, personalities, and teaching or learning styles. Figure 8 shows Teacher Mrs Smith's character settings. Figures 9, 10, 11,12 , and 13 show the character settings of students Ryan, John, Emily, Samantha, and Ying Zheng, respectively.</p>
<h2>Sternberg Thinking Styles in Teaching</h2>
<p>Mrs. Smith's teaching style can be described by Sternberg Thinking Styles in Teaching Inventory with a tree-structured format (Figure 14). Each Level-2 node has its score, representing the degree of match between the description provided and the actual teaching style, with a maximum of 7 and a minimum of 1 . Each Level-1 node also has its corresponding score, which is the sum of the scores of all its child nodes. The higher the value, the higher the degree of matching.</p>
<h2>Solomon's Learning Styles</h2>
<p>Students learning styles can be described by Solomon's Learning Styles Inventory with a tree-structured format (Figure 15). Each Level-1 node has its type to represent your type in four different dimensions. When selecting 11 subnodes, a is selected more times than b, then the category represented is the former in the description, otherwise, it is the latter. Each Level-2 node has its description and choice to indicate your selection for the current evaluation question.</p>
<p>C
Career: Teacher
Name: Mrs. Smith
Description: Mrs. Smith is a strict but caring teacher. She wants the best for her students and pushes them to achieve their potential.
Personality (Big Five Personality): [16, 4, 4, 2, 4, 2], [19, 5, 4, 2, 5, 3], [22, 5, 5, 2, 5, 5], $[14,3,3,3,2,3],[18,4,3,3,5,3]]$
Teaching Style (Sternberg Thinking Styles in Teaching): [25, 3, 5, 4, 3, 4, 5, 3], [15, 2, 3, $2,3,2,1,2],[22,4,3,4,5,3,1,2],[19,4,3,2,3,2,3,2],[12,2,1,2,2,2,1,2],[16,2,3,2$, $2,3,2,2],[24,4,4,4,5,3,2,2]]$</p>
<p>Figure 8: Character setting for Mrs. Smith.</p>
<p>C
Career: Student
Name: Ryan
Description: Ryan is a Social Butterfly student who social skills and leadership abilities give him a broad influence in school and the community. He is willing to help others and are good at coordinating and resolving conflicts. He might focus too much on social activities, neglecting personal development and academic learning. He may depend too heavily on the approval of others, overlooking the discovery and realization of his own value.
Personality (Big Five Personality): [19, 5, 5, 2, 5, 2], [22, 5, 5, 2, 5, 5], [15, 3, 3, 3, 3, 3], $[14,4,2,3,3,2],[15,3,3,3,4,2]]$
Learning Style (Solomon's Learning Styles): [[Active-7, a, a, a, a, a, b, b, a, a, a, a], [Sensory-10, a, a, a, a, b, a, a, a, a, a, a, a, b, b, a, b, b, b], [Sequential-10, a, a, a, a, a, a, b, a, a, a, a]]</p>
<p>Figure 9: Character setting for Ryan.</p>
<p>C
Career: Student
Name: John
Description: John is a Athletic Star student who physical fitness and team spirit allow him to excel in various sports activities. The resilience and determination he demonstrate when faced with challenges are also significant strengths. He might neglect academic learning and artistic development because he devote most of his time and energy to sports activities. He might also rely too heavily on sports, overlooking the need for a balanced physical and mental well-being.
Personality (Big Five Personality): [21, 5, 5, 3, 5, 3], [18, 4, 3, 3, 4, 4], [18, 4, 4, 3, 4, 3], $[16,4,3,3,3,3],[16,3,3,3,4,3]]$
Learning Style (Solomon's Learning Styles): [[Active-3, a, a, a, a, a, b, b, a, a, b, b], [Sensory-10, a, a, a, a, b, a, a, a, a, a, a,], [Visual-11, a, a, a, a, a, a, a, a, a, a, a], [Sequential$10, \mathrm{a}, \mathrm{a}, \mathrm{a}, \mathrm{a}, \mathrm{a}, \mathrm{a}, \mathrm{b}, \mathrm{a}, \mathrm{a}, \mathrm{a}, \mathrm{a}, \mathrm{a}]$</p>
<p>Figure 10: Character setting for John.</p>
<p>C
Career: Student
Name: Emily
Description: Emily is a Art Prodigy student who creativity and technical skills in the arts allow her to produce impressive works. Her sensitive and expressive artistic vision is also a major strength. She might be so engrossed in artistic creation that she overlook learning in other disciplines. She may have excessively high expectations for her artistic achievements, leading her to feel frustrated or overly stressed when facing creative difficulties.
Personality (Big Five Personality): [17, 4, 3, 3, 5, 2], [19, 4, 4, 3, 4, 4], [18, 4, 4, 3, 3, 4], $[18,4,3,4,4,3],[20,5,5,2,4,4]]$
Learning Style (Solomon's Learning Styles): [[Reflective-3, b, b, b, b, b, a, a, b, b, a, a], [Intuitive-10, b, b, b, b, a, b, b, b, b, b, b], [Verbal-1, a, a, a, a, b, b, b, a, b, b, b], [Global-10, b, b, b, b, b, a, b, b, b, b]]]</p>
<p>Figure 11: Character setting for Emily.</p>
<p>C
Career: Student
Name: Samantha
Description: Samantha is a The Contemplator student who introversion and independent thinking abilities allow her to excel in problem-solving and independent research. She find a source of self-fulfillment and satisfaction in thinking and reflection. She might be so introverted that she feel uncomfortable in social activities. She might focus too much on her own thoughts, neglecting interactions and cooperation with others.
Personality (Big Five Personality): [13, 1, 1, 5, 1, 5], [13, 2, 3, 4, 2, 2], [22, 5, 5, 2, 5, 5], $[14,4,4,2,2,2],[21,5,5,1,5,5]]$
Learning Style (Solomon's Learning Styles): [[Reflective-7, b, b, b, b, a, a, b, b, b, b], [Intuitive-10, b, b, b, b, a, b, b, b, b, b, b], [Visual-1, b, b, b, b, a, a, a, b, a, a, a], [Global-10, b, b, b, b, b, b, a, b, b, b, b]]]</p>
<p>Figure 12: Character setting for Samantha.</p>
<p>C
Career: Student
Name: Samantha
Description: Ying Zheng is a Academic Enthusiast student who passion for learning and focus lead to remarkable academic achievements. He is open to challenges, good at independent research, and have a strong desire to acquire new knowledge. He might be so focused on academic achievements that he sacrifice interaction time with friends and family. His high expectations for academic success could place tremendous pressure on him, and he might sometimes be too demanding of himself.
Personality (Big Five Personality): [13, 2, 2, 4, 1, 4], [15, 4, 3, 3, 3, 2], [22, 5, 5, 2, 5, 5], $[15,2,4,3,3,3],[21,5,5,1,5,5]]$
Learning Style (Solomon's Learning Styles): [[Reflective-3, b, b, b, b, b, a, a, b, b, a, a], [Intuitive-10, b, b, b, b, a, b, b, b, b, b, b], [Verbal-1, b, b, a, b, a, a, a, b, a, b, b], [Global-0, b, b, b, b, b, a, b, b, b, b]]</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 14: The Sternberg Thinking Styles in Teaching Inventory.</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 15: The Solomon's Learning Styles Inventory.</p>            </div>
        </div>

    </div>
</body>
</html>