<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3388 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3388</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3388</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-77.html">extraction-schema-77</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving puzzle games that require spatial knowledge (such as Sudoku), including details about the models, the puzzles, the methods used, performance, and any analysis of how the models solve these tasks.</div>
                <p><strong>Paper ID:</strong> paper-c59d685a21f5b8f4750a28a5733a80fbaa0f410b</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/c59d685a21f5b8f4750a28a5733a80fbaa0f410b" target="_blank">Making New Connections: LLMs as Puzzle Generators for The New York Times' Connections Word Game</a></p>
                <p><strong>Paper Venue:</strong> Artificial Intelligence and Interactive Digital Entertainment Conference</p>
                <p><strong>Paper TL;DR:</strong> This paper investigates the ability of the GPT family of Large Language Models (LLMs) to generate challenging and creative word games for human players and proposes a method for generating Connections puzzles using LLMs by adapting a Tree of Thoughts prompting approach.</p>
                <p><strong>Paper Abstract:</strong> The Connections puzzle is a word association game published daily by The New York Times (NYT). In this game, players are asked to find groups of four words that are connected by a common theme. While solving a given Connections puzzle requires both semantic knowledge and abstract reasoning, generating novel puzzles additionally requires a form of metacognition: generators must be able to accurately model the downstream reasoning of potential solvers. In this paper, we investigate the ability of the GPT family of Large Language Models (LLMs) to generate challenging and creative word games for human players. We start with an analysis of the word game Connections and the unique challenges it poses as a Procedural Content Generation (PCG) domain. We then propose a method for generating Connections puzzles using LLMs by adapting a Tree of Thoughts (ToT) prompting approach. We evaluate this method by conducting a user study, asking human players to compare AI- against human-generated Connections puzzles. Our findings show that LLMs are capable puzzle creators, and can generate diverse sets of enjoyable, challenging, and creative Connections puzzles as judged by human users.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3388.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3388.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving puzzle games that require spatial knowledge (such as Sudoku), including details about the models, the puzzles, the methods used, performance, and any analysis of how the models solve these tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tree-of-Thoughts (ToT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tree of Thoughts prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting paradigm that breaks a task into a tree of intermediate subtasks; the LLM is queried to produce multiple child nodes per step and leaves are scored so higher-scoring nodes are greedily expanded, enabling deliberative search over reasoning trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Tree of thoughts: Deliberate problem solving with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>various LLMs (GPT-family referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A prompting / multi-query algorithm applied on top of pre-trained autoregressive LLMs to generate multiple candidate reasoning paths, evaluate them with a scoring function, and expand promising nodes; not a single model architecture but a method for steering existing LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Sudoku (and Game of 24 mentioned)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Sudoku is a combinatorial constraint-satisfaction puzzle on a 9x9 grid that requires arranging digits so each row, column, and 3x3 block contains all digits 1–9; Game of 24 is a small-arithmetic reasoning puzzle — both have verifiable solutions enabling score-based search.</td>
                        </tr>
                        <tr>
                            <td><strong>input_representation</strong></td>
                            <td>Not specified in this paper; cited work treats puzzles as verifiable symbolic problems (e.g., Sudoku given as a numeric/textual grid) which enables scoring of candidate completions.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Tree-of-Thoughts (explicit multi-step candidate generation + scoring); contrasted with Chain-of-Thought prompting which is single linear chain reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>spatial_reasoning_analysis</strong></td>
                            <td>Paper notes ToT helps on tasks like Sudoku because these problems admit verifiable solutions that can be scored and ranked; simpler prompting (Chain-of-Thought) can fail on such combinatorial/verifiable tasks, while ToT's exploration-and-ranking better finds correct solutions. The paper itself does not provide internal ablations or attention analyses — it reports the prior finding that ToT improved performance on Sudoku (citing Long 2023 and Yao et al. 2023).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>No numeric results reported in this paper for Sudoku; the paper cites prior work stating ToT improved performance on Sudoku and Game of 24 where Chain-of-Thought failed, but gives no accuracy/success-rate figures here.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>The paper reiterates the general limitation that ToT requires a verifiable scoring function to rank candidate leaves; it therefore applies best to tasks with objectively checkable solutions (like Sudoku) and is less directly applicable to open-ended creative tasks where quality is hard to define.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models_or_humans</strong></td>
                            <td>The paper states ToT outperforms simpler prompting (Chain-of-Thought) on Sudoku-like verifiable tasks (citing Yao et al. and Long 2023) but provides no numeric head-to-head stats or comparisons to human solvers within this text.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Making New Connections: LLMs as Puzzle Generators for The New York Times' Connections Word Game", 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3388.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3388.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving puzzle games that require spatial knowledge (such as Sudoku), including details about the models, the puzzles, the methods used, performance, and any analysis of how the models solve these tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Long 2023 ToT application</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Model Guided Tree-ofThought</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced study applying LLM-guided Tree-of-Thought techniques to Sudoku (and similar tasks), reporting that ToT improves performance where simpler Chain-of-Thought prompting fails.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Large Language Model Guided Tree-ofThought</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified LLM(s) in the cited work</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Cited work applied ToT-style guided search using large autoregressive language models; this paper does not give the exact model family or sizes used by Long (2023).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Sudoku</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Standard Sudoku; a combinatorial grid-based constraint satisfaction problem requiring spatial/structural reasoning over rows, columns, and blocks.</td>
                        </tr>
                        <tr>
                            <td><strong>input_representation</strong></td>
                            <td>Not specified here; the citation implies symbolic/textual grid representation appropriate for LLM input and verification.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Tree-of-Thoughts / multi-branch deliberative prompting (per Long 2023 as cited).</td>
                        </tr>
                        <tr>
                            <td><strong>spatial_reasoning_analysis</strong></td>
                            <td>Paper cites Long (2023) to indicate ToT yields better search over combinatorial states for Sudoku, implying that LLMs can benefit from explicit tree-structured deliberation for spatial/constraint tasks; no further internal analysis is provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>This paper does not provide numerical metrics from Long (2023); it only reports the qualitative claim that ToT improved performance on Sudoku relative to CoT.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>As above: applicability depends on the availability of verifiable scoring; details of failure modes in Sudoku are not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models_or_humans</strong></td>
                            <td>Paper reports that Chain-of-Thought prompting can fail on tasks like Sudoku whereas ToT helps, per Long (2023); no quantitative comparisons to humans or non-LLM solvers are given here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Making New Connections: LLMs as Puzzle Generators for The New York Times' Connections Word Game", 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3388.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3388.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving puzzle games that require spatial knowledge (such as Sudoku), including details about the models, the puzzles, the methods used, performance, and any analysis of how the models solve these tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MarioGPT (level generation)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MarioGPT: Open-Ended Text2Level Generation through Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A model that fine-tunes GPT-2 to generate 2D platformer (Super Mario Bros.) levels, conditioned on target characteristics; demonstrates LLMs can model and produce spatial level content.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>MarioGPT: Open-Ended Text2Level Generation through Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-2 (fine-tuned; referred to as MarioGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-2 fine-tuned on level data to output level sequences conditioned on desired properties (e.g., number of jumps, coins, enemies); treats levels as token sequences suitable for autoregressive generation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Super Mario Bros. level generation (grid/sequence level creation)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Generation of 2D platformer levels represented as grids/sequences of tiles and objects; requires spatial/layout reasoning to ensure playability and affordances.</td>
                        </tr>
                        <tr>
                            <td><strong>input_representation</strong></td>
                            <td>Levels represented as token sequences derived from grid-based level encodings (textual/sequential representation used for GPT-2 fine-tuning).</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Model is fine-tuned (supervised) to generate levels conditioned on textual or numeric target characteristics rather than zero/few-shot prompting at inference.</td>
                        </tr>
                        <tr>
                            <td><strong>spatial_reasoning_analysis</strong></td>
                            <td>The paper notes that pre-training on language provides useful priors for grid-world generation; MarioGPT demonstrates that autoregressive language models can capture spatial/layout structure when trained on level corpora. No deep internal analysis of spatial representations is provided in this paper beyond citing that such results exist.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>This paper does not provide quantitative metrics for MarioGPT; it summarizes prior work's conclusion that the resulting model can generate novel and playable levels when conditioned appropriately.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>The parent paper notes that training LLMs from scratch on sparse level data is infeasible and thus fine-tuning with level-specific data is necessary; no detailed failure modes from MarioGPT are reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models_or_humans</strong></td>
                            <td>The cited MarioGPT work demonstrates GPT-2 fine-tuned levels can be playable; no direct comparison to human-designed levels or non-LLM generators is provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Making New Connections: LLMs as Puzzle Generators for The New York Times' Connections Word Game", 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3388.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3388.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving puzzle games that require spatial knowledge (such as Sudoku), including details about the models, the puzzles, the methods used, performance, and any analysis of how the models solve these tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sokoban level generation (Todd et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Level Generation Through Large Language Models (Sokoban experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior work that fine-tunes GPT-2 and GPT-3 to generate Sokoban puzzle levels, showing LLMs can produce novel and playable grid-based puzzle levels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Level Generation Through Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-2 and GPT-3 (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-family models fine-tuned on Sokoban level data to output level representations; used as sequence generators for grid-based puzzles.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Sokoban level generation</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Sokoban is a box-pushing puzzle played on a 2D grid where the player must push boxes to target locations obeying movement constraints; levels require spatial planning and physically plausible layouts.</td>
                        </tr>
                        <tr>
                            <td><strong>input_representation</strong></td>
                            <td>Grid levels encoded as text/sequence tokens for autoregressive modeling (specific encoding not detailed in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Fine-tuning on level corpora (supervised generation), not purely zero-shot prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>spatial_reasoning_analysis</strong></td>
                            <td>The paper references that despite being trained on language, LLMs fine-tuned on grid-world levels learn useful priors for spatial layout generation; no internal probing or attention analysis is provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>This paper reports the cited prior result that fine-tuned GPT-2/GPT-3 were capable of generating novel and playable Sokoban levels but does not include specific quantitative evaluation metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>The main limitation noted is data sparsity for level generation and that pretraining on language is necessary but not sufficient; exact failure cases for Sokoban generation are not enumerated in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models_or_humans</strong></td>
                            <td>The referenced work demonstrates LLMs can match baseline functionality for generating playable levels; this paper does not include quantitative head-to-head comparisons to human designers or non-LLM generators.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Making New Connections: LLMs as Puzzle Generators for The New York Times' Connections Word Game", 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Tree of thoughts: Deliberate problem solving with large language models. <em>(Rating: 2)</em></li>
                <li>Large Language Model Guided Tree-ofThought <em>(Rating: 2)</em></li>
                <li>MarioGPT: Open-Ended Text2Level Generation through Large Language Models <em>(Rating: 2)</em></li>
                <li>Level Generation Through Large Language Models <em>(Rating: 2)</em></li>
                <li>Large language models and games: A survey and roadmap <em>(Rating: 1)</em></li>
                <li>Large Language Model Guided Tree-ofThought <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3388",
    "paper_id": "paper-c59d685a21f5b8f4750a28a5733a80fbaa0f410b",
    "extraction_schema_id": "extraction-schema-77",
    "extracted_data": [
        {
            "name_short": "Tree-of-Thoughts (ToT)",
            "name_full": "Tree of Thoughts prompting",
            "brief_description": "A prompting paradigm that breaks a task into a tree of intermediate subtasks; the LLM is queried to produce multiple child nodes per step and leaves are scored so higher-scoring nodes are greedily expanded, enabling deliberative search over reasoning trajectories.",
            "citation_title": "Tree of thoughts: Deliberate problem solving with large language models.",
            "mention_or_use": "mention",
            "model_name": "various LLMs (GPT-family referenced)",
            "model_description": "A prompting / multi-query algorithm applied on top of pre-trained autoregressive LLMs to generate multiple candidate reasoning paths, evaluate them with a scoring function, and expand promising nodes; not a single model architecture but a method for steering existing LLMs.",
            "model_size": null,
            "puzzle_name": "Sudoku (and Game of 24 mentioned)",
            "puzzle_description": "Sudoku is a combinatorial constraint-satisfaction puzzle on a 9x9 grid that requires arranging digits so each row, column, and 3x3 block contains all digits 1–9; Game of 24 is a small-arithmetic reasoning puzzle — both have verifiable solutions enabling score-based search.",
            "input_representation": "Not specified in this paper; cited work treats puzzles as verifiable symbolic problems (e.g., Sudoku given as a numeric/textual grid) which enables scoring of candidate completions.",
            "prompting_method": "Tree-of-Thoughts (explicit multi-step candidate generation + scoring); contrasted with Chain-of-Thought prompting which is single linear chain reasoning.",
            "spatial_reasoning_analysis": "Paper notes ToT helps on tasks like Sudoku because these problems admit verifiable solutions that can be scored and ranked; simpler prompting (Chain-of-Thought) can fail on such combinatorial/verifiable tasks, while ToT's exploration-and-ranking better finds correct solutions. The paper itself does not provide internal ablations or attention analyses — it reports the prior finding that ToT improved performance on Sudoku (citing Long 2023 and Yao et al. 2023).",
            "performance_metrics": "No numeric results reported in this paper for Sudoku; the paper cites prior work stating ToT improved performance on Sudoku and Game of 24 where Chain-of-Thought failed, but gives no accuracy/success-rate figures here.",
            "limitations_or_failure_modes": "The paper reiterates the general limitation that ToT requires a verifiable scoring function to rank candidate leaves; it therefore applies best to tasks with objectively checkable solutions (like Sudoku) and is less directly applicable to open-ended creative tasks where quality is hard to define.",
            "comparison_to_other_models_or_humans": "The paper states ToT outperforms simpler prompting (Chain-of-Thought) on Sudoku-like verifiable tasks (citing Yao et al. and Long 2023) but provides no numeric head-to-head stats or comparisons to human solvers within this text.",
            "uuid": "e3388.0",
            "source_info": {
                "paper_title": "Making New Connections: LLMs as Puzzle Generators for The New York Times' Connections Word Game",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Long 2023 ToT application",
            "name_full": "Large Language Model Guided Tree-ofThought",
            "brief_description": "A referenced study applying LLM-guided Tree-of-Thought techniques to Sudoku (and similar tasks), reporting that ToT improves performance where simpler Chain-of-Thought prompting fails.",
            "citation_title": "Large Language Model Guided Tree-ofThought",
            "mention_or_use": "mention",
            "model_name": "unspecified LLM(s) in the cited work",
            "model_description": "Cited work applied ToT-style guided search using large autoregressive language models; this paper does not give the exact model family or sizes used by Long (2023).",
            "model_size": null,
            "puzzle_name": "Sudoku",
            "puzzle_description": "Standard Sudoku; a combinatorial grid-based constraint satisfaction problem requiring spatial/structural reasoning over rows, columns, and blocks.",
            "input_representation": "Not specified here; the citation implies symbolic/textual grid representation appropriate for LLM input and verification.",
            "prompting_method": "Tree-of-Thoughts / multi-branch deliberative prompting (per Long 2023 as cited).",
            "spatial_reasoning_analysis": "Paper cites Long (2023) to indicate ToT yields better search over combinatorial states for Sudoku, implying that LLMs can benefit from explicit tree-structured deliberation for spatial/constraint tasks; no further internal analysis is provided here.",
            "performance_metrics": "This paper does not provide numerical metrics from Long (2023); it only reports the qualitative claim that ToT improved performance on Sudoku relative to CoT.",
            "limitations_or_failure_modes": "As above: applicability depends on the availability of verifiable scoring; details of failure modes in Sudoku are not provided in this paper.",
            "comparison_to_other_models_or_humans": "Paper reports that Chain-of-Thought prompting can fail on tasks like Sudoku whereas ToT helps, per Long (2023); no quantitative comparisons to humans or non-LLM solvers are given here.",
            "uuid": "e3388.1",
            "source_info": {
                "paper_title": "Making New Connections: LLMs as Puzzle Generators for The New York Times' Connections Word Game",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "MarioGPT (level generation)",
            "name_full": "MarioGPT: Open-Ended Text2Level Generation through Large Language Models",
            "brief_description": "A model that fine-tunes GPT-2 to generate 2D platformer (Super Mario Bros.) levels, conditioned on target characteristics; demonstrates LLMs can model and produce spatial level content.",
            "citation_title": "MarioGPT: Open-Ended Text2Level Generation through Large Language Models",
            "mention_or_use": "mention",
            "model_name": "GPT-2 (fine-tuned; referred to as MarioGPT)",
            "model_description": "GPT-2 fine-tuned on level data to output level sequences conditioned on desired properties (e.g., number of jumps, coins, enemies); treats levels as token sequences suitable for autoregressive generation.",
            "model_size": null,
            "puzzle_name": "Super Mario Bros. level generation (grid/sequence level creation)",
            "puzzle_description": "Generation of 2D platformer levels represented as grids/sequences of tiles and objects; requires spatial/layout reasoning to ensure playability and affordances.",
            "input_representation": "Levels represented as token sequences derived from grid-based level encodings (textual/sequential representation used for GPT-2 fine-tuning).",
            "prompting_method": "Model is fine-tuned (supervised) to generate levels conditioned on textual or numeric target characteristics rather than zero/few-shot prompting at inference.",
            "spatial_reasoning_analysis": "The paper notes that pre-training on language provides useful priors for grid-world generation; MarioGPT demonstrates that autoregressive language models can capture spatial/layout structure when trained on level corpora. No deep internal analysis of spatial representations is provided in this paper beyond citing that such results exist.",
            "performance_metrics": "This paper does not provide quantitative metrics for MarioGPT; it summarizes prior work's conclusion that the resulting model can generate novel and playable levels when conditioned appropriately.",
            "limitations_or_failure_modes": "The parent paper notes that training LLMs from scratch on sparse level data is infeasible and thus fine-tuning with level-specific data is necessary; no detailed failure modes from MarioGPT are reported here.",
            "comparison_to_other_models_or_humans": "The cited MarioGPT work demonstrates GPT-2 fine-tuned levels can be playable; no direct comparison to human-designed levels or non-LLM generators is provided in this paper.",
            "uuid": "e3388.2",
            "source_info": {
                "paper_title": "Making New Connections: LLMs as Puzzle Generators for The New York Times' Connections Word Game",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Sokoban level generation (Todd et al.)",
            "name_full": "Level Generation Through Large Language Models (Sokoban experiments)",
            "brief_description": "Prior work that fine-tunes GPT-2 and GPT-3 to generate Sokoban puzzle levels, showing LLMs can produce novel and playable grid-based puzzle levels.",
            "citation_title": "Level Generation Through Large Language Models",
            "mention_or_use": "mention",
            "model_name": "GPT-2 and GPT-3 (fine-tuned)",
            "model_description": "GPT-family models fine-tuned on Sokoban level data to output level representations; used as sequence generators for grid-based puzzles.",
            "model_size": null,
            "puzzle_name": "Sokoban level generation",
            "puzzle_description": "Sokoban is a box-pushing puzzle played on a 2D grid where the player must push boxes to target locations obeying movement constraints; levels require spatial planning and physically plausible layouts.",
            "input_representation": "Grid levels encoded as text/sequence tokens for autoregressive modeling (specific encoding not detailed in this paper).",
            "prompting_method": "Fine-tuning on level corpora (supervised generation), not purely zero-shot prompting.",
            "spatial_reasoning_analysis": "The paper references that despite being trained on language, LLMs fine-tuned on grid-world levels learn useful priors for spatial layout generation; no internal probing or attention analysis is provided here.",
            "performance_metrics": "This paper reports the cited prior result that fine-tuned GPT-2/GPT-3 were capable of generating novel and playable Sokoban levels but does not include specific quantitative evaluation metrics.",
            "limitations_or_failure_modes": "The main limitation noted is data sparsity for level generation and that pretraining on language is necessary but not sufficient; exact failure cases for Sokoban generation are not enumerated in this paper.",
            "comparison_to_other_models_or_humans": "The referenced work demonstrates LLMs can match baseline functionality for generating playable levels; this paper does not include quantitative head-to-head comparisons to human designers or non-LLM generators.",
            "uuid": "e3388.3",
            "source_info": {
                "paper_title": "Making New Connections: LLMs as Puzzle Generators for The New York Times' Connections Word Game",
                "publication_date_yy_mm": "2024-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Tree of thoughts: Deliberate problem solving with large language models.",
            "rating": 2
        },
        {
            "paper_title": "Large Language Model Guided Tree-ofThought",
            "rating": 2
        },
        {
            "paper_title": "MarioGPT: Open-Ended Text2Level Generation through Large Language Models",
            "rating": 2
        },
        {
            "paper_title": "Level Generation Through Large Language Models",
            "rating": 2
        },
        {
            "paper_title": "Large language models and games: A survey and roadmap",
            "rating": 1
        },
        {
            "paper_title": "Large Language Model Guided Tree-ofThought",
            "rating": 1
        }
    ],
    "cost": 0.0124265,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Making New Connections: LLMs as Puzzle Generators for The New York Times' Connections Word Game</h1>
<p>Tim Merino ${ }^{1}$, Sam Earle ${ }^{1}$, Ryan Sudhakaran ${ }^{2}$, Shyam Sudhakaran ${ }^{2}$, Julian Togelius ${ }^{1}$<br>${ }^{1}$ New York University,<br>${ }^{2}$ Jester Labs,<br>tm3477@nyu.edu, sam.earle@nyu.edu, ryan@jesterlabs.ai, shyam@jesterlabs.ai, julian@togelius.com</p>
<h4>Abstract</h4>
<p>The Connections puzzle is a word association game published daily by The New York Times (NYT). In this game, players are asked to find groups of four words that are connected by a common theme. While solving a given Connections puzzle requires both semantic knowledge and abstract reasoning, generating novel puzzles additionally requires a form of metacognition: generators must be able to accurately model the downstream reasoning of potential solvers. In this paper, we investigate the ability of the GPT family of Large Language Models (LLMs) to generate challenging and creative word games for human players. We start with an analysis of the word game Connections and the unique challenges it poses as a Procedural Content Generation (PCG) domain. We then propose a method for generating Connections puzzles using LLMs by adapting a Tree of Thoughts (ToT) prompting approach. We evaluate this method by conducting a user study, asking human players to compare AI-generated puzzles against published Connections puzzles. Our findings show that LLMs are capable puzzle creators, and can generate diverse sets of enjoyable, challenging, and creative Connections puzzles as judged by human users.</p>
<h2>Introduction</h2>
<p>Word games, in which game mechanics revolve around manipulating, parsing, and/or inventing words, have been around for a very long time. While crosswords as we know them today have only been around for just over a century, word puzzles have existed at least since the Romans (Raphael 2020). More recently, online word games have seen increased popularity, including several novel word games published by the New York Times. While some research has been done on solving human-authored word games, the challenge of generating novel word games has seen scant attention from AI researchers.</p>
<p>In this paper, we study the popular word game Connections. This is a game about semantic clustering: the player is given 16 words and must sort them into four categories. The apparent simplicity of this game belies a significant depth owing to the large numbers of different organizing principles for these categories, as well as various deceptive strategies in generating these puzzles.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>In this work, we present a method for generating and evaluating Connections puzzles using LLMs and validate our approach with a user study that compares AI generated puzzles against those authored by humans.</p>
<p>The impact of our work is manifold. First, we provide a new source of puzzles for a game that, at time of writing, has only 380 published puzzles. In addition, our prompting approach provides a framework that can be applied to other word games, paving the way for new applications in procedural content generation. Our study of puzzle generation methods also shines light on the design of the Connections puzzle itself-through our user study we can observe the effects of various puzzle-generating strategies or heuristics on the end user experience. Finally, through our experiments we gain some insight into the capabilities and weaknesses of the underlying large language models and highlight valuable avenues for future work. ${ }^{1}$</p>
<h2>Related Work</h2>
<h2>LLMs for games</h2>
<p>While LLMs are a relatively recent invention, there is already burgeoning literature on applying LLMs to games, as catalogued by (Gallotta et al. 2024). This includes using LLMs to play games, generate games, generate dialogue, implement game mechanics, and more.</p>
<p>Several studies have investigated the application of LLMs to level generation. MarioGPT (Sudhakaran et al. 2023) finetunes GPT-2 to generate levels in the side-scrolling platformer Super Mario Bros., conditioned on target characteristics of the generated level such as number of jumps, coins and enemies. Similarly, Todd et al. fine-tune GPT-2 and GPT-3 to generate Sokoban levels. In both cases, the resulting models are capable of generating novel and playable levels.</p>
<p>These prior LLM-based level-generation works above focus on embodied grid-worlds. Though these representations can be thought of as existing at a sub-linguistic level, results seem to suggest that pre-training on vast amount of natural language data seems to nonetheless result in useful priors for this task. In this paper, we investigate generating "levels" in</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<h2>How to play Connections</h2>
<p>Find groups of four items that share something in common.</p>
<ul>
<li>Select four items and tap 'Submit' to check if your guess is correct.</li>
<li>Find the groups without making 4 mistakes!</li>
</ul>
<h2>Category Examples</h2>
<ul>
<li>FISH: Bass, Flounder, Salmon, Trout</li>
<li>FIRE $\qquad$ : Ant, Drill, Island, Opal</li>
</ul>
<p>Categories will always be more specific than "5-LETTER WORDS," "NAMES" or "VERBS."</p>
<p>Each puzzle has exactly one solution. Watch out for words that seem to belong to multiple categories!</p>
<p>Each group is assigned a color, which will be revealed as you solve:
Straightforward
Tricky
Have general feedback? Let us know!
Figure 1: The help page of the Connections puzzle
a game that operates instead directly at the level of language. Unlike in grid-worlds, training a model from scratch strictly on human-generated levels would be a virtually infeasible approach (due to the sparsity of level data relative to the vast semantic complexity of human language), and pre-training on a vast corpus of human knowledge is a necessary prerequisite for generating any novel puzzles at all.</p>
<p>Though generation of Connections puzzles is an unexplored domain, recent research has studied solving language-based games. Jaramillo et al. implement and evaluate various AI agents for the social board game Codenames. Codenames, similar to Connections, uses semantic clustering of seemingly unrelated words as a core game mechanic. They find that a GPT-2 word embedding based bot outperforms non-vector approaches such as TF-IDF and NaiveBayes. We continue this exploration of Language Models for word association games, utilizing the latest GPT models.</p>
<p>Recent work has studied LLMs in the domain of Connections. Todd et al. (2024) first study the task of solving NYT Connections puzzles, finding that GPT-4 is able to solve $38.93 \%$ of puzzles using Chain of Thought prompting. They find that sentence embedding models, using a cosine similarity guessing strategy, are able to solve $11.6 \%$ of puzzles, outperforming the GPT-3.5 model. Later work further explores Connections solving via LLMs, categorizing the knowledge types required to solve the puzzle and evaluating a variety of LLMs on a modified version of the solving task (Treutlein et al. 2024). The best performing model, GPT-4o, is only able to solve $8 \%$ of puzzles. They note that certain "reasoning types" present in categories are significantly harder for LLMs to solve, highlighting the diversity of semantic reasoning inherent to the game.</p>
<h2>The Connections Puzzle</h2>
<p>Connections is a category-matching word game published daily by The New York Times. The game debuted on June 12, 2023, and quickly became one of their most played games. A Connections game board is represented by a grid of sixteen English words or names. The arrangement of words in the grid is semi-random ${ }^{2}$ and can be arbitrarily reshuffled by the player. In order to submit a guess, the player selects a set of four words they believe are connected under a common theme. If the guess is correct (i.e. the four words belong to the same category) then the category is revealed and the words are removed from the grid. If three of the four words belong to the same category, this fact is indicated to the player with the message "One away!", but neither the words nor the category are revealed. If two or fewer words belong to the same category then no additional information is provided to the player. If the player makes four incorrect guesses, the puzzle is failed.</p>
<p>Each category within a puzzle has an assigned color which represent the its difficulty. In order of ascending difficulty, these colors are: yellow (most straightforward), green, blue, and purple (trickiest). Straightforward categories often use the most common definition of words. An example given by the tutorial is the category FISH, containing "bass", "flounder", "salmon", and "trout". For trickier groups, the connection between words can be much more complex. Purple groups may use rhymes, homophones, anagrams, or "fill in the blank" clues such as FIRE $\qquad$ (Aronow and Levine 2023).</p>
<p>Wyna Liu, who creates the daily game boards for Connections, has discussed some aspects of puzzle creation in articles published by The Times (Liu 2023). Connections puzzles are created in three steps: First, a puzzle creator compiles a candidate puzzle. This puzzle is given to a puzzle editor, who tests and edits the game board. Finally, a panel of testers evaluate the quality and challenge level of the puzzle.</p>
<p>For a puzzle to feel challenging and satisfying, Liu notes there has to be a mix of category "types", such as wordplay categories and synonym categories. She cites three axes along which difficulty may be modulated: familiarity of words, ambiguity of their categorization, and variety of the wordplay (Liu 2023).</p>
<p>Generation of puzzles that match both the challenge and satisfaction of those published by The New York Times requires both creativity, abstract reasoning, and deep semantic</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Figure 2: A Connections puzzle, published by The New York Times on Jan 19, 2024</p>
<p>understanding. Categories must have a range of difficulties, and incorporate abstract connections. Words must logically fit into a category, without being too obvious for the player. As a whole, the words and categories of a puzzle must play off each other, with interplay between words to trick the player. Satisfying all of these constraints makes Connections a unique challenge for modern LLM systems.</p>
<h2>Prompting</h2>
<p>Because LLMs are trained auto-regressively to fill in or complete sequences of tokens from the training data, their output at inference time depends entirely on the "prompt" which they are provided—i.e. the piece of text which they are effectively asked to complete.</p>
<p>As a result, LLM performance on downstream tasks can be strongly influenced by the technique used to generate the prompt.</p>
<p>A vast amount of research has studied how to most effectively prompt language models (Schulhoff et al. 2024). In Chain-of-Thought (Wei et al. 2022), for example, an LLM is asked to show its reasoning step by step. Results suggest that by mimicking a more deliberate and thorough thought process, the LLM is less likely to jump to incorrect conclusions, and more inclined toward coherent reasoning. In its simplest form, Chain-of-Thought amounts to appending the phrase "let's think step-by-step" to the prompt.</p>
<p>In the Tree-of-Thought prompting approach (ToT) (Yao et al. 2023), tasks are explicitly broken down into subtasks by the human user. Each sub-task is considered as a level in a tree, and the LLM is queried multiple times (while varying random seed or other hyperparameters) to produce multiple child nodes at each level. Then, some evaluation metric is calculated for each leaf-node in the tree, and tree nodes are expanded greedily, prioritising higher-scoring nodes. ToT has been shown to improve performance on challenging tasks such as the Game of 24 (Yao et al. 2023) and Sodoku (Long 2023), where simpler prompting techniques such as Chain of Thought (Wei et al. 2022) fail. In these tasks, there are verifiable solutions to the problem, allowing for the explicit scoring and ranking of candidate solutions generated by an LLM. In more open-ended tasks, where success is much more difficult to define, there is no simple way to measure the quality of an LLM generator's output.</p>
<p>One such task is the creative writing task explored by Yao et al. (2023). They generate 4 random sentences, and task the LLM with generating a four paragraph passage where each paragraph ends with one of the random sentences. While there is a simple constraint that can be checked (whether each paragraph ends with the sentence provided), evaluating the quality of the writing as a whole is much more complex. Separate LLM agents can be used to evaluate and rate these outputs, but existing research shows they may be biased towards LLM-generated text (Koo et al. 2023).</p>
<h2>Methodology</h2>
<p>Our generative pipeline is loosely inspired by the creative process used by the New York Times and consists of three components: a puzzle creator, a puzzle editor, and a human
puzzle evaluator. GPT-4 serves as the puzzle creator, generating sets of puzzles using an iterative approach loosely based on the Tree of Thoughts algorithm. This set of generated puzzles is passed to the puzzle editor-a separate LLM instance that can make minor changes to the category names. Next, the set of edited puzzles is manually evaluated to determine the "best" puzzles. We evaluate the quality of our generated puzzles by testing the evaluator's top puzzles in a user study.</p>
<h2>Identifying Puzzle Constraints</h2>
<p>Unlike their Crossword puzzle (Aronow 2021), The New York Times does not publish rules or guidelines for creating a Connections game board. We start by identifying constraints that define valid Connections puzzles. By looking at existing puzzles and the in-game tutorial (Fig 1), we infer some basic constraints that a Connections puzzle must satisfy:</p>
<ol>
<li>The puzzle contains 16 unique words.</li>
<li>The puzzle has 4 unique groups of 4 words.</li>
<li>All words in a group share a connection.</li>
<li>Each word is used exactly once.</li>
<li>The puzzle has exactly one solution.</li>
<li>Categories are more specific than 5-LETTER WORDS, NAMES, or VERBS.</li>
</ol>
<p>This basic set of constraints defines a large puzzle space, containing all possible combinations of 4 valid word groups. The vast majority of these puzzles are trivially easy to solve-players will notice the obvious semantic clustering of words in the puzzle, eliminating the satisfaction of playing the game. In order to generate puzzles that are challenging and fun to play, we identify general principles that are followed by the Times puzzle creators. We incorporate these principles into our prompts to guide puzzle creation towards the style of puzzle published by the Times. These principles include:
Varied Categories: Categories within a given puzzle must be thematically distinct (i.e. a COLORS category will not share a puzzle with a PRIMARY COLORS category)
Unique Names: Words in the category name can't be appear as part of that category (i.e. the word GREEN will not appear in the category SHADES OF GREEN)
Spelling Matters: Words must belong to their group in the given spelling (i.e. BE will not appear in the category INSECT, but BEE might).</p>
<h2>Puzzle Difficulty</h2>
<p>Making engaging puzzles requires a certain level of difficulty. One aspect of this is explicitly stated in the tutorial of the game: "Watch out for words that seem to belong to multiple categories!" (see Figure 1). From this, we deduce that a "good" Connections puzzle must entice the player to make mistakes by using "misleading" words.</p>
<p>We identify two distinct ways this occurs in official Connections puzzles. The first is using "overlap words"-words that seem to belong to multiple categories. An example of this can be seen in Figure 2. Words like "fudge" and "nuts"</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>(a) A generated "False Group" puzzle. The "false group" is circled in red, but is not a correct group in the puzzle's solution. The correct groups are circled in their respective color.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>(c) Illustration showing the process for generating groups in the "False Group" pipeline</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>(b) A generated "Intentional Overlap" puzzle. The correct groups are circled in their respective color. Each group after the first appears to include an extra word from a separate group.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>(d) Illustration showing the process for generating new groups in the "Intentional Overlap" pipeline</p>
<p>Figure 3: Overview of LLM-driven pipelines for generating <em>Connections</em> puzzles with false or intentionally overlapping groups.</p>
<p>seem like they could belong in the <em>PHOOEY!</em> category, but actually belong to <em>SUNDAE TOPPINGS</em>. The presence of these words forces the player to shift focus and consider multiple potential groups at once in order to disambiguate the group membership of individual words. This is cited as a key feature that is sought out by the <em>Times'</em> puzzle editors: "More overlap makes a harder puzzle." (Aronow and Levine 2023)</p>
<p>The other form of difficulty is what we name "false groups". These are connections between words that a player may spot, but in actuality are not related to any of the puzzle's true groups. An example of a false connection in Figure 2 could be "rats" and "woodchuck" both being <em>rodents</em>, or "cherry" and "peppers" both being <em>red foods</em>. Whether a puzzle appears to present a false group is ultimately as much a function of the player as it is of the puzzle itself. Nevertheless, even if these dead ends don't actually elicit an incorrect guess from the player, they arguably make the process of solving the puzzle more engaging by adding richness to the puzzle's semantic landscape.</p>
<p>We select overlap words and false groups as the main avenues by which to incorporate challenge into our generated puzzles.</p>
<h3>Puzzle Creation pipeline</h3>
<p>We decompose the task of <em>Connections</em> puzzle generation into an iterative process: each generative step equals the creation a word group, composed of a category name along with a pool of words that belong to it. Although the puzzle could be decomposed further, with every step providing a single word or category name, this approach would become quite computationally expensive using current LLMs. We set the pool size to be eight words. We find that this results in GPT suggesting multiple valid words of varying difficulty, without suggesting illogical words in order to meet the quota. We use <code>gpt-4-1106-preview</code> via OpenAI's API as our word group creator, as well as all other LLMs in the pipeline.</p>
<p>We use a few-shot "propose prompt" approach for word group generation, inspired by the prompts used in prior work for the Tree of Thoughts Crossword Solving task (Yao et al. 2023). This approach prompts an LLM to generate one or many word groups in a single context, which are then parsed out to become individual "nodes". In some puzzle types, such as the "intentional overlap" puzzles, we generate two distinct categories and word pools in each prompt. In others, only one category is taken at each step.</p>
<p>One issue facing GPT models is limited variety in output. In early experiments, our group-generation LLM would frequently propose the same limited set of categories and words, such as <em>BOARD GAMES</em>: "chess", "checkers", "monopoly", "life". Varying seed and temperature did little to curb this behavior.</p>
<p>We solve this problem by injecting semi-random text into the first group-generation prompt. We add a task to the LLM's system prompt: first, write a short story using user-provided words, then use that story as inspiration for creating your categories. In the user prompt, we inject four randomly selected words from published <em>Connections</em> puzzles. We find this prompting technique leads to much higher diversity of output, with very few repeated categories across our set of generated puzzles.</p>
<p>These proposed categories still lacked the challenging and abstract categories present in real <em>Connections</em> puzzles, as the LLM has no knowledge of the <em>Connections</em> puzzle it-</p>
<p>self. To solve this, we analyzed published Connections puzzles and identified common category “styles”, and collect a set of example category names. Some example styles are “Synonyms or Slang”, “Wordplay”, and “Fill in the blank” categories. We add these category styles, along with a brief description and three example category names, into all proposal prompts. The LLM is instructed to only craft categories that fit one of the given styles. This leads to more complex proposed categories, such as WORDS THAT CAN FOLLOW “FIRE”.</p>
<p>Intentional Overlap and False Connection trees We build two different styles of puzzle, which are distinct in the way the LLM introduces tricky word interplay. Both methods use the same prompt to generate the “root” word group, but differ in followup group generation.</p>
<p>In intentional overlap trees, we first create groups of four words from the word pool, and include these previously generated groups as context in the next group-generation prompt. For each previously used word, the LLM proposes an alternate category using a different meaning of the word. It then selects one alternate category, and generates a new pool of eight words that could fit under it. This introduces the “overlap” difficulty into the puzzle—each followup group appears to include one additional word from a different group. This process is illustrated in Figure 3d</p>
<p>In false connection trees, the root group becomes the “false group”, which is not directly included in the puzzle. Instead, each of the four words from the false group are used as a basis for an entirely new word group, using an alternate definition. Only these followup groups are used to form the final puzzle (See Figure 3c). This introduces the “false connection” difficulty: there appears to be five valid groupings of words—the root group and four followup groups—but only the latter four are valid.</p>
<p>Creating groups of four Initial experiments indicate that LLMs struggle to estimate the difficulty of Connections word groups, and fail to select subsets of four words in a way that aligns with human judgement. Rather than using an LLM to group words together, we use a text embedding similarity metric to groups words from the word pools created by the LLM. This provides two benefits: we eliminate a failure point from our pipeline stemming from LLM hallucinations and stochasticity, and are able to create and assign a “difficulty” score to all possible combinations of four words.</p>
<p>We use the MPNET embedding model from the Sentence-Transformers library, which had the top performance in the task of solving the Connections puzzle (Todd et al. 2024). We infer that the high performance in the solving task means the MPNET model encodes a word’s semantic information in a way most similar to their usage in the Connections puzzle.</p>
<p>We first test our hypothesis that intra-group embedding similarity is a proxy for word group difficulty on published Connections puzzles. We compute the average pairwise cosine similarity between embeddings of all words in existing puzzle groups, shown in Table 1. We then average these score across groups of the same color. We find that the cosine similarity metric aligns with the The New York Times difficulty scale, with yellow groups having higher similarity, and purple groups having lower similarity.</p>
<p>For each LLM-proposed word pool, we compute this similarity metric for all combinations of four words. We then create four groups corresponding to the color-difficulty levels. Yellow and Purple groups are the combinations with highest and lowest similarity, respectively, with green and blue groups selected as the combinations closest to ¼(max_similarity – min_similarity) and ¾(max_similarity – min_similarity)</p>
<p>This method results in 24 final versions of a single puzzle—each word group has four distinct “difficulty” groupings, with different words but the same category.</p>
<h3>Puzzle editing</h3>
<p>Due to the stochastic nature of LLMs and their sensitivity to prompts, not all final puzzles are perfect. A common failure mode we observe is when there is a clear connection between words in a group, but the category name misrepresents that connection. An example is the generated group HAWK THE WARES: “wares”, “items”, “goods”, “merchandise”. HAWK THE WARES does not accurately describe how these words are connected, but THINGS FOR SALE would. For Connections puzzles, a small mistake like this in a word or category name can ruin the solving experience.</p>
<p>To increase the efficiency of our method, we use a “Puzzle Editor” prompt. First, it identifies the connecting theme between each word group in a complete puzzle. Then, it evaluates whether the existing category name is accurate. If not, it rewrites the category name so that it truthfully represents the connection. This often fixes otherwise invalid word groups, and rewritten category names are often much closer in style to real Connections categories.</p>
<p>The final component in our generation pipeline is color-coded difficulty ranking. While we assign colors based on the similarity metric generated via our embedding model, we consider puzzles where two groups are the same “color” during evaluation. Additionally, this method of assigning colors does not consider the relative difficulty of other groups in the puzzle. To create a puzzle with all four colors, we pass generated puzzles to a final LLM using a “difficulty ranking” prompt. This LLM assigns colors (yellow, green, blue, purple) to the groups of each puzzle based on the LLM’s perception of their difficulty.</p>
<p>Table 1: Average intra-group pairwise cosine similarity by group color across 150 Connections puzzles</p>
<table>
<thead>
<tr>
<th>Color</th>
<th>Average similarity score</th>
<th>Variance</th>
</tr>
</thead>
<tbody>
<tr>
<td>Yellow</td>
<td>0.4017</td>
<td>0.0285</td>
</tr>
<tr>
<td>Green</td>
<td>0.3536</td>
<td>0.0214</td>
</tr>
<tr>
<td>Blue</td>
<td>0.2905</td>
<td>0.0123</td>
</tr>
<tr>
<td>Purple</td>
<td>0.2664</td>
<td>0.0108</td>
</tr>
</tbody>
</table>
<h2>Human Preference Experiment</h2>
<h2>Datasets</h2>
<p>To evaluate the appeal of our AI-generated Connection puzzles, we conduct a user study to evaluate human preferences between AI generated and real Connections puzzles.</p>
<p>We create four sets of AI generated puzzles:</p>
<ol>
<li>A baseline "one-step" LLM generated set</li>
<li>An "intentional overlap" LLM generated set</li>
<li>A "false connection" LLM generated set</li>
<li>A "false connection" LLM generated set, where the "false group" is taken from a real Connections puzzle</li>
</ol>
<p>Baseline Set To evaluate the effectiveness of our iterative pipeline over simpler prompting methods, we generate a set of "One-Step" puzzles to act as a baseline for LLM puzzle generation. In this method, we ask an LLM to generate a complete Connections puzzle in a single prompt. We provide a condensed version of the prompts used in the iterative approach, as well as few-shot examples of real Connections puzzles.</p>
<p>Iteratively Generated Set We generate three sub-types of puzzle using the iterative generation strategy described in Methodology. For each sub-type, we generate 15 complete sets of puzzles, and 5 puzzles are manually selected for inclusion into the user study. We use gpt-4-1106-preview via OpenAI's chat completion API, with temperature 1 for all generation and editing prompts.</p>
<p>5 puzzles use the "intentional overlap" method, where each category after the first is created by using an alterate definition of a previous groups' word.</p>
<p>10 puzzles are generated using the "false group" method. In half of these puzzles, the LLM proposes its own false group category and word pool, and the group of four words with the highest similarity metric (the "yellow" group) is used. We refer to these as "LLM False Group" puzzles. In the other half, we manually select word groups from existing Connections puzzles to act as the false group. We manually select groups where each word has a clear alternate definition, so that a valid puzzle with thematically distinct categories can be generated (See Table 3 for exact groups).</p>
<p>We include this "seeded" set of false-group puzzles as an initial exploration into human-in-the-loop generation of Connections puzzles. While fully-automated PCG systems allow for infinite artifacts with no human intervention, it is rare that such systems perform perfectly. We seek to explore how including some human creativity into the generation process, by way of real puzzle groups, affects human evaluation of the puzzles.</p>
<p>Real set Finally, we randomly sample 20 previously published New York Times Connections puzzles to form our real puzzle set.</p>
<h2>Experiment setup</h2>
<p>We implement a web-based replica of the Connections interface, following the same rules used by the New York Times.</p>
<p>Table 2: Solve rates of puzzles by type</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Type</th>
<th style="text-align: center;">Solve rate</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">One-Step</td>
<td style="text-align: center;">$58.06 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Intentional Overlap</td>
<td style="text-align: center;">$31.25 \%$</td>
</tr>
<tr>
<td style="text-align: left;">False group (LLM)</td>
<td style="text-align: center;">$55.56 \%$</td>
</tr>
<tr>
<td style="text-align: left;">False group (seeded)</td>
<td style="text-align: center;">$92.86 \%$</td>
</tr>
<tr>
<td style="text-align: left;">All AI</td>
<td style="text-align: center;">$58.51 \%$</td>
</tr>
<tr>
<td style="text-align: left;">NYT</td>
<td style="text-align: center;">$69.07 \%$</td>
</tr>
</tbody>
</table>
<p>Players are allowed four incorrect guesses before failing the puzzle. They are able to randomly shuffle the game board, and are told when their guess is "one away" from a correct answer. The puzzles are integrated into a survey page, where users are asked to play two Connections puzzles and answer a series of questions. If the user does not successfully solve the puzzle, all categories are revealed so the user can evaluate the complete puzzles.</p>
<p>Pairs of Connections puzzles, one AI-generated and one from the Times, are randomly selected at the start of each survey. The ordering in which the two puzzles is randomized.</p>
<p>We collect gameplay from the user's play sessions on both puzzles, including all guesses made and whether or not they completed the puzzle. After completing both puzzles, the user is asked the following questions:</p>
<ol>
<li>What is your English Proficiency?</li>
<li>How often do you play Connections?</li>
<li>Have you seen either puzzle before?</li>
<li>Which puzzle was more creative?</li>
<li>Which puzzle was harder?</li>
<li>Which puzzle did you like more?</li>
</ol>
<p>For questions 4-6, users can select "Puzzle 1", "Puzzle 2", or "Tie/Neither". Optional free response questions are included for questions 4-6, allowing users to explain their reasoning. A final free response is included for miscellaneous comments.</p>
<p>To avoid potential bias in user responses, we do not explicitly state which puzzle is from which source, nor that the puzzles are AI generated. Additionally, we ask users to self-report if they have seen either puzzle before. We do not include responses where a user recognized a puzzle in our analysis.</p>
<h2>Results</h2>
<p>We collect 78 responses from 52 unique users (by username), sharing links to the survey via social media. We encouraged participants to complete the survey multiple times, with the most completions by a single user being 6.</p>
<h2>AI vs Real Puzzles</h2>
<p>Figure 4 shows user preferences on AI generated puzzles versus real New York Times puzzles. We compare the percentage of user responses to questions 4-6 across all AIgenerated puzzles, as well as by sub-type. In roughly half</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 4: User response data for survey questions 4-6. Colored bars represent AI puzzle preference, while gray bars represent "Tie / Neither". AI-generated puzzles with LLM-generated false groups, in particular, are competitive with NYT puzzles in terms of user preference and perceived creativity, while being judged generally more difficult.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 5: Number of mistakes made by percentage of puzzle plays, grouped by puzzle sub-type. AI-generated puzzles involving intentional overlaps proved most difficult to human players, while those seeded with false groups from existing NYT puzzles proved significantly easier than actual NYT puzzles.</p>
<p>of head-to-head comparisons against expert <em>Times</em> puzzles, generated <em>Connections</em> puzzles were judged to be equally or more enjoyable, creative, and difficult.</p>
<h3>One-step vs Iterative Puzzles</h3>
<p>One-step puzzles were largely rated as being less enjoyable and less creative than their <em>Times</em> counterparts, but performed better in terms of difficulty. Our best performing group in terms of overall enjoyment (as indicated by responses to question 6) was LLM false group puzzles, beating <em>Times</em> puzzles in 42.86% of responses and tying in 14.29%. Users found intentional overlap puzzles the hardest, rating them more difficult than their NYT counterparts in 60% of responses and equally difficult in 20% of responses. This difficulty is reflected in playthrough data, where intentional overlap puzzles have the lowest overall solve rate. In terms of creativity (question 4), intentional overlap puzzles perform best, though LLM-generated false group puzzles are strictly preferred more often.</p>
<p>In general, difficulty is the category where generated puzzles appear to come closest to the <em>Times</em>.</p>
<h4>Solve rate</h4>
<p>We find a significant relationship between the puzzle sub-type and the solve rate, $$X^2(4, N=194) = 19.71$$, $$p &lt; .01$$. The difference in solve rate between <em>Times</em> puzzles and all AI methods taken together is not statistically significant, though noticeable differences appear when investigating by AI puzzle sub-type. Intentional overlap puzzles were by far the most difficult for users, being solved in only 31.25% of play sessions. On the contrary, seeded false group puzzles seem trivially easy, being solved in 92.86% of play sessions.</p>
<p>The mistake distribution of AI-generated puzzles (Figure 5) tells an interesting story. We find significantly different distributions within each sub-type. In intentional overlap puzzles, players made four mistakes in the majority of plays (68.75%), and very rarely completed the puzzle with none.</p>
<p>Conversely, players solved seeded false groups perfectly in the majority of plays ( $53.57 \%$ ), and very rarely failed the puzzle overall.</p>
<h2>Difficulty</h2>
<p>We analyzed users' play data to determine whether our attempts to add interplay via false groups worked as we expected. For each false group puzzle, we calculated how often players made a false group guess: selecting any subset of the false group (2, 3, or 4 words). We found significant differences between the LLM- and NYT-seeded versions. For all LLM-seeded false group puzzles, players guessed a subset of the false group in half or more of the total play sessions. In one puzzle, every single attempt included one of these false group guesses.</p>
<p>For seeded false group puzzles, players weren't tricked as easily. While 2 puzzles elicited false group guesses, 3 puzzles had no false group guesses.</p>
<p>Players often used the free response section of the survey to provide their opinions on puzzle difficulty. Users were surprisingly perceptive in identifying the manner in which difficulty was introduced into generated puzzles. One user, playing an intentional overlap puzzle, writes "There was a bit more overlap in words to categories." Some users cite the difficulty as a reason they enjoyed the puzzled more: "Too many word overlaps in the second puzzle, but it was more interesting and accurate to their categories".</p>
<p>Users were split on whether this ambiguity in groupings was a positive or negative. Six users specifically call out ambiguity and overlap in the AI puzzle as a negative, while seven cite it as a positive and reason for preferring the puzzle overall.</p>
<p>Additionally, despite not disclosing that AI was used as a source for any puzzles, multiple users wrote that they felt a puzzle was AI generated, though they weren't always accurate in their selection.</p>
<h2>Discussion</h2>
<h2>Difficulty discrepancy</h2>
<p>Seeded false groups stand as an outlier in our data-they are by far the easiest to solve. We hypothesize that this is due to the "difficulty" of the false groups. In particular, seeded false groups were drawn randomly from NYT puzzles, and therefore sometimes involved obscure connections. As a result, these groups were less likely to "jump out" at and distract players, whereas LLM-generated false groups were liable to be more generic, eye-catching, and therefore distracting, leading to more false group guesses.</p>
<p>We further note that LLM false groups were selected as the most similar set words in the candidate pool as measured by cosine similarity. The average similarity score for NYT-seeded false groups in our user study is indeed lower ( 0.47 ) than the average score for LLM-generated false groups ( 0.52 ). Further, two seeded groups have high similarity scores ( 0.51 and 0.60 ), while the other three have much lower similarity ( $&lt;0.43$ ). We note that the two groups with high similarity elicited false group guesses from users, and the three with low similarity elicited none.</p>
<p>Difficulty is the category in which our generated puzzles perform best against NYT puzzles. Intentional overlap puzzles were rated as more difficult in the majority of cases, similar to LLM false groups. This is likely due to the way we intentionally introduce the overlap or false connection difficulty into every group in the puzzles. While NYT puzzles may incorporate just a few overlapping words, or small false connection groups, we try to maximize these types of difficulty in their respective puzzle types. This may lead to difficulty that exceeds the average NYT puzzle. Decreasing this difficulty, by removing the difficulty incentives from generated group prompts, may help align the difficulty with what players have come to expect from Connections.</p>
<h2>Interpretation of user preferences</h2>
<p>We intentionally limit the number of questions in the survey to reduce user fatigue. One notable metric that we do not include in our survey relates to puzzle "fairness". A puzzle that uses uncommon vocabulary or illogical groupings may be much harder for players, but not particularly fair in its difficulty. Although we use the Puzzle Editor LLM to try to combat these issues, it is not perfect at correcting puzzles.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Category</th>
<th style="text-align: left;">Words</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">NBA TEAMS</td>
<td style="text-align: left;">"bucks", "heat", "jazz", "nets"</td>
</tr>
<tr>
<td style="text-align: left;">SLANG FOR TOILET</td>
<td style="text-align: left;">"can", "head", "john", "throne"</td>
</tr>
<tr>
<td style="text-align: left;">THINGS WITH WINGS</td>
<td style="text-align: left;">"airplane", "angel", "bird", "pegasus"</td>
</tr>
<tr>
<td style="text-align: left;">NFL PLAYERS</td>
<td style="text-align: left;">"bear", "bill", "brown", "commander"</td>
</tr>
<tr>
<td style="text-align: left;">$\ldots . . R O A D$</td>
<td style="text-align: left;">"abbey", "high", "rocky", "silk"</td>
</tr>
</tbody>
</table>
<p>Table 3: Connections groups from published puzzles used as false groups</p>
<h2>Connections as a PCG domain</h2>
<p>Generating convincing Connections puzzle is a uniquely difficult domain. To generate a puzzle on-par with the original, a method must be capable of proposing unique and clever categories, on the same level as professional puzzle builders. Connections is published by a single source-the Timesand players have come to expect a distinct level of quality and challenge from their daily puzzles. Group themes can't be too obvious, but they also can't be "reaches". This necessitates an advanced semantic understanding, combined with a sufficient model of human logic.</p>
<p>On top of this, user feedback shows the importance of the unspoken yet understood "principles" underlying Connections. While some constraints are easily verifiable (Unique Names), others are harder to measure (Varied Categories). When even one of these principles is broken, players feel frustrated and cheated rather than accomplished.</p>
<p>Despite these challenges, a direct comparison to The New York Times doesn't tell the whole story. Though many generated puzzles may not beat real puzzles in direct comparison, users still enjoy solving them, and in some cases prefer them. Though small flaws are common, we find some surprising ability for cleverness and wordplay by LLMs. With further refinement of prompts, particularly in distilling the abstract concepts that make Connections so widely enjoyed,</p>
<p>we believe this method could produce more consistent results.</p>
<h2>Game generation as design research</h2>
<p>While the perhaps most obvious use case for the method we are developing here is to actually generate Connections puzzles, one can also see this work as a contribution to game design research. The implemented generator can be seen as a test of a theory of how Connections puzzles are designed. The implemented theory is based on Wyna Liu's article describing her own puzzle creation methodology, and the success of the method in creating good Connections puzzles can be seen as corroboration of that theory. One might then iteratively refine the theory and the corresponding process to arrive at an even better theory of what makes for a good Connections puzzle.</p>
<h2>Limitations</h2>
<h2>Cost</h2>
<p>Our ability to perform ablation studies of various prompting techniques, as well as generate large quantities of puzzles was limited by computational budget. The GPT-4 API is significantly slower and more expensive than other models, such as gpt-3.5-turbo or open source LLMs such as Llama 3 or Mistral. Open-source LLMs can be run locally without cost, enabling more in-depth state evaluation, thought generation, and editing steps that are costprohibitive with paid APIs. However, preliminary experiments indicate they are not as capable at following the complicated system prompts we author for GPT-4.</p>
<h2>User study data</h2>
<p>We rely on user's self-reporting whether or not they have seen a particular Connections puzzle before. This may not be $100 \%$ accurate, leading to some bias if users were able to identify previous NYT puzzles. Our analysis and confidence in our conclusions are limited by the number of responses, as well as our methodology. Connections puzzles are inherently challenging to parse, forcing players to process a scrambled grid of seemingly unrelated words. Comparing two puzzles side-by-side may not be an optimal way of measuring a puzzle's difficulty.</p>
<h2>Future Work</h2>
<p>While our experiments show that-somewhat remarkablyConnections puzzles generated entirely by A.I. can be competitive with puzzles generated by human experts along several axes, perhaps a more interesting end goal is to explore how such generative pipelines could ultimately assist human designers. Our method could easily be adapted to add to one or more groups or overarching group themes, provided by a human designer. We explore LLMs as puzzle editors, but not as evaluators or editors of human-designed puzzles. LLM agents acting in these roles can facilitate a designer's creative flow and amplify their expressive ability (e.g. by providing incremental twists or edits on a partially complete puzzle when a designer is stuck, or calling on the immense
knowledge base encoded in LLMs to enhance their level of reference).</p>
<h2>Ethical Considerations</h2>
<p>There is ongoing, high-profile legal debate around the intellectual property of LLM-generated outputs-whether such models can be trained on copyrighted text, and how to properly attribute credit to output from models trained on such material. Because the model used here is not trained on any bona fide NYT Connections puzzles, it is incapable of plagiarizing the copyrighted work of human designers by stealthily regurgitating or paraphrasing what it may have memorized during training. On the other hand, we do fewshot prompt the model with some examples of NYT Connections puzzles for the sake of demonstration and inspiration. We do not find that the model borrows from these puzzles in any kind of conspicuous fashion, though users of our system should be careful to compare outputs against human puzzles injected into prompts.</p>
<h2>Conclusion</h2>
<p>In this work, we present a method of generating word puzzles for The New York Times' Connections game using Large Language Models. The results of our user study show that the puzzles generated by our method are often competitive in terms of player preferences, and comparable in terms of difficulty. We argue that, with careful, domain-specific prompting, LLMs (i.e. OpenAI's GPT-4) are capable of generating novel and challenging Connections puzzles, and could ultimately serve as viable design assistants for Connections, or other, similar lateral thinking games relying on semantic understanding and creative associations between words and concepts.</p>
<p>Our puzzle generation pipeline involves a novel iterative prompting approach that combines LLM-generated categories, words and distractors with a sentence embedding cosine similarity metric to dynamically select for group difficulty. We incorporate design principles from Connections (namely, false groups and intentional overlap distractors) into our generation pipeline, and find that these lead to significant differences in puzzle difficulty and preference among human players. We additionally demonstrate the compatibility of our method with a human-in-the-loop approach, showing how user-provided "false groups" can be used to seed viable synthetic puzzles.</p>
<p>Still, generating entire Connections puzzles remains a challenge requiring further study. The puzzle design principles incorporated into our method are far from exhaustive, and our user study is strictly an initial exploration: it stands to reason that repeated exposure to these synthetic puzzles could eventually lead to player fatigue, whereas human designers may adapt their approach in real-time to provide a dynamic experience for repeat players. Future work should seek to study the utility of such generative pipelines to puzzle designers themselves, and investigate ways in which the puzzle design principles integrated into the LLM prompting pipeline may be modified by designers to adapt to design goals that evolve over time.</p>
<h1>References</h1>
<p>Aronow, I. 2021. Crossword Constructor Resource Guide. The New York Times.
Aronow, I.; and Levine, E. 2023. How to line up a great connections solve. The New York Times.
Gallotta, R.; Todd, G.; Zammit, M.; Earle, S.; Liapis, A.; Togelius, J.; and Yannakakis, G. N. 2024. Large language models and games: A survey and roadmap. arXiv preprint arXiv:2402.18659.
Jaramillo, C.; Charity, M.; Canaan, R.; and Togelius, J. 2020. Word Autobots: Using Transformers for Word Association in the Game Codenames. Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, 16(1): 231-237.
Koo, R.; Lee, M.; Raheja, V.; Park, J. I.; Kim, Z. M.; and Kang, D. 2023. Benchmarking cognitive biases in large language models as evaluators. arXiv preprint arXiv:2309.17012.
Liu, W. 2023. How our new game, connections, is put together. The New York Times.
Long, J. 2023. Large Language Model Guided Tree-ofThought. arXiv preprint arXiv:2305.08291.
Raphael, A. 2020. A Brief History of Word Games. The Paris Review.
Schulhoff, S.; Ilie, M.; Balepur, N.; Kahadze, K.; Liu, A.; Si, C.; Li, Y.; Gupta, A.; Han, H.; Schulhoff, S.; et al. 2024. The Prompt Report: A Systematic Survey of Prompting Techniques. arXiv preprint arXiv:2406.06608.
Sudhakaran, S.; González-Duque, M.; Glanois, C.; Freiberger, M.; Najarro, E.; and Risi, S. 2023. MarioGPT: Open-Ended Text2Level Generation through Large Language Models. arXiv:2302.05981.
Todd, G.; Earle, S.; Nasir, M. U.; Green, M. C.; and Togelius, J. 2023. Level Generation Through Large Language Models. In Proceedings of the 18th International Conference on the Foundations of Digital Games, 1-8.
Todd, G.; Merino, T.; Earle, S.; and Togelius, J. 2024. Missed Connections: Lateral Thinking Puzzles for Large Language Models. arXiv preprint arXiv:2404.11730.
Treutlein, J.; Choi, D.; Betley, J.; Anil, C.; Marks, S.; Grosse, R. B.; and Evans, O. 2024. Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data. arXiv preprint arXiv:2406.14546.
Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Xia, F.; Chi, E.; Le, Q. V.; Zhou, D.; et al. 2022. Chain-ofthought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35: 24824-24837.
Yao, S.; Yu, D.; Zhao, J.; Shafran, I.; Griffiths, T. L.; Cao, Y.; and Narasimhan, K. 2023. Tree of thoughts: Deliberate problem solving with large language models. arXiv preprint arXiv:2305.10601.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ Some puzzles have intentionally spelled out phrases in the first row of words, though this phrase is never a word group&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{1}$ We make our code, the dataset of Times puzzles, our generated puzzles, and full set of prompts available at https://anonymous. 4open.science/r/making-new-connections-78D1&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>