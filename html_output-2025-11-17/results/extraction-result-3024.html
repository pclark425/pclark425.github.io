<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3024 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3024</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3024</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-74.html">extraction-schema-74</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <p><strong>Paper ID:</strong> paper-267499950</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2402.03578v2.pdf" target="_blank">LLM Multi-Agent Systems: Challenges and Open Problems</a></p>
                <p><strong>Paper Abstract:</strong> This paper explores multi-agent systems and identify challenges that remain inadequately addressed. By leveraging the diverse capabilities and roles of individual agents, multi-agent systems can tackle complex tasks through agent collaboration. We discuss optimizing task allocation, fostering robust reasoning through iterative debates, managing complex and layered context information, and enhancing memory management to support the intricate interactions within multi-agent systems. We also explore potential applications of multi-agent systems in blockchain systems to shed light on their future development and application in real-world distributed systems.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3024.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3024.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>short-term memory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Short-term memory (working memory)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Ephemeral, immediate memory an LLM holds during an ongoing interaction to support working reasoning and conversation state; it exists only for the duration of the interaction and is not persisted.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LLM agent (working memory)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Generic single-LLM agent using its context/window as transient working memory to hold recent conversational state and intermediate reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>short-term memory (working memory / context window)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Information is held in the model's immediate context (token window) during a session; it is read/written implicitly by continuing the conversation and is not persisted beyond the session.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Short-term (working) memory is necessary for immediate multi-step reasoning and conversation; the paper highlights it as ephemeral and scoped to a single interaction.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Limited capacity (context window), transient (not persisted), and scaling beyond window requires external mechanisms; potential for forgetting earlier parts of long interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM Multi-Agent Systems: Challenges and Open Problems', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3024.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3024.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>long-term memory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Long-term memory (persistent histories / vector DB)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Persistent memory storing historical queries and responses (chat histories) in external storage (e.g., vector databases) to support future inferences and recall.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LLM agent (long-term memory)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Generic single- or multi-agent setup that persists past interactions externally (often in vector stores) so agents can retrieve relevant history for new tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>long-term memory (external persistent storage / vector database)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Interactions and important outputs are stored externally (e.g., vector embeddings in a database); retrieval uses similarity search to fetch relevant past items which are then injected into the model context for reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Long-term memory stored in external databases enables recall of past interactions to inform future inferences; survey highlights it as a common approach for persistence across sessions.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Requires retrieval accuracy, indexing/maintenance overhead, potential privacy/security concerns, and alignment of retrieved items with current task context.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM Multi-Agent Systems: Challenges and Open Problems', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3024.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3024.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval-Augmented Generation (external data storage)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-augmented mechanism where an LLM queries an external datastore (e.g., vector DB) for relevant documents which are injected into the model context to ground responses for knowledge-intensive tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Retrieval-augmented generation for knowledgeintensive nlp tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LLM + RAG</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An LLM architecture augmented with a retriever module and external vector/document store; retriever returns relevant passages that are appended to the model context to improve factuality and grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented / external database</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Queries are transformed to embeddings, nearest-neighbor search returns supporting documents from an external index, and the retrieved text is composed into the prompt/context for the LLM to condition its generation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>knowledge-intensive NLP tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks requiring up-to-date or large factual knowledge beyond the model's parameterized knowledge (e.g., open-domain QA, fact-checking).</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>question answering / knowledge-grounded generation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>RAG-style external storage is cited as a standard approach to augment LLMs with persistent, updatable knowledge and improve grounding and relevance of outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Retrieval failures and noisy or irrelevant documents can degrade outputs; integration and prompt design are nontrivial; privacy and access-control concerns for shared stores.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM Multi-Agent Systems: Challenges and Open Problems', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3024.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3024.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>episodic memory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Episodic memory (multi-agent)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A stored collection of past multi-agent interactions (episodes) that agents can reference when confronted with new tasks to improve relevance and accuracy by leveraging contextually similar past episodes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>multi-agent episodic memory</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A mechanism in multi-agent systems that records sequences of interactions (episodes) among agents and allows retrieval of whole episodes or episode fragments to inform reasoning on new, related problems.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic memory (interaction history)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Episodes (logs of agent interactions and outcomes) are indexed and retrieved when new tasks have contextual similarity; retrieved episodes provide precedents, strategies, or factual context to inform current agent decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Used when agents face new tasks or queries that are similar to past interactions; supports transfer of past solutions or strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step reasoning / adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Episodic memory allows multi-agent systems to leverage previously encountered interaction patterns to improve accuracy and relevance on new, similar tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Selecting which episodes are relevant is challenging; storage and retrieval scaling, privacy of recorded episodes, and ensuring up-to-date consistency across agents are open problems.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM Multi-Agent Systems: Challenges and Open Problems', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3024.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3024.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>consensus memory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Consensus memory (shared skill library)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A unified shared memory used across agents to store common knowledge, shared skills, or canonical information to align agents' understanding and strategies during collaboration.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>multi-agent consensus memory</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Shared repository (e.g., 'skill library') accessible to collaborating agents to read/write consensus facts, domain knowledge, or agreed-upon strategies to maintain coherence across the system.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>shared / consensus memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>A centralized or federated store holds canonical items (skills, rules, common-sense facts). Agents consult this store to align decisions; updates require agreement protocols or access controls to maintain integrity.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Used in collaborative tasks where agents must share and align on domain knowledge or capabilities to coordinate effectively.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-agent coordination / collaborative reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Consensus memory is important to align multi-agent behaviors and prevent inconsistent outputs; a skill library is cited as an example implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Access control, integrity (tampering), and synchronization are major challenges; also deciding what to store in consensus memory vs. private memory is unresolved.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM Multi-Agent Systems: Challenges and Open Problems', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3024.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3024.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative Agents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework (Park et al., 2023) that simulates interactive agent behavior in environments; cited here as an example of agents that rely on recorded interactions/memory to behave plausibly over time.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Generative agents (Park et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agents designed to simulate human-like behavior in interactive environments by recording, storing, and using memory of past interactions to inform future actions and dialogue.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic / long-term memory (recorded interactions)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Agents record interaction traces which are indexed and retrieved to guide later behavior; memories support continuity, personalization, and context in subsequent interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>interactive simulation of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Simulate believable, long-running agent behavior in virtual environments where recall of prior interactions and personal facts is needed to maintain coherent behavior and narrative.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>simulation / interactive environment / dialogue</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The survey cites generative agents as an example where memory is central to producing coherent, contextually consistent behavior over time.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Not detailed in this survey; general challenges include which memories to store, retrieval relevance, scaling, and privacy of stored personal interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM Multi-Agent Systems: Challenges and Open Problems', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Retrieval-augmented generation for knowledgeintensive nlp tasks <em>(Rating: 2)</em></li>
                <li>Generative agents: Interactive simulacra of human behavior <em>(Rating: 2)</em></li>
                <li>Mot: Memory-of-thought enables chatgpt to self-improve <em>(Rating: 2)</em></li>
                <li>Augmenting language models with long-term memory <em>(Rating: 2)</em></li>
                <li>Configurable general multi-agent interaction framework <em>(Rating: 2)</em></li>
                <li>Promptguided retrieval augmentation for non-knowledgeintensive tasks <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3024",
    "paper_id": "paper-267499950",
    "extraction_schema_id": "extraction-schema-74",
    "extracted_data": [
        {
            "name_short": "short-term memory",
            "name_full": "Short-term memory (working memory)",
            "brief_description": "Ephemeral, immediate memory an LLM holds during an ongoing interaction to support working reasoning and conversation state; it exists only for the duration of the interaction and is not persisted.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "agent_name": "LLM agent (working memory)",
            "agent_description": "Generic single-LLM agent using its context/window as transient working memory to hold recent conversational state and intermediate reasoning.",
            "memory_used": true,
            "memory_type": "short-term memory (working memory / context window)",
            "memory_mechanism_description": "Information is held in the model's immediate context (token window) during a session; it is read/written implicitly by continuing the conversation and is not persisted beyond the session.",
            "task_name": "",
            "task_description": "",
            "task_type": "",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": false,
            "key_findings": "Short-term (working) memory is necessary for immediate multi-step reasoning and conversation; the paper highlights it as ephemeral and scoped to a single interaction.",
            "limitations_or_challenges": "Limited capacity (context window), transient (not persisted), and scaling beyond window requires external mechanisms; potential for forgetting earlier parts of long interactions.",
            "uuid": "e3024.0",
            "source_info": {
                "paper_title": "LLM Multi-Agent Systems: Challenges and Open Problems",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "long-term memory",
            "name_full": "Long-term memory (persistent histories / vector DB)",
            "brief_description": "Persistent memory storing historical queries and responses (chat histories) in external storage (e.g., vector databases) to support future inferences and recall.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "agent_name": "LLM agent (long-term memory)",
            "agent_description": "Generic single- or multi-agent setup that persists past interactions externally (often in vector stores) so agents can retrieve relevant history for new tasks.",
            "memory_used": true,
            "memory_type": "long-term memory (external persistent storage / vector database)",
            "memory_mechanism_description": "Interactions and important outputs are stored externally (e.g., vector embeddings in a database); retrieval uses similarity search to fetch relevant past items which are then injected into the model context for reasoning.",
            "task_name": "",
            "task_description": "",
            "task_type": "",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": false,
            "key_findings": "Long-term memory stored in external databases enables recall of past interactions to inform future inferences; survey highlights it as a common approach for persistence across sessions.",
            "limitations_or_challenges": "Requires retrieval accuracy, indexing/maintenance overhead, potential privacy/security concerns, and alignment of retrieved items with current task context.",
            "uuid": "e3024.1",
            "source_info": {
                "paper_title": "LLM Multi-Agent Systems: Challenges and Open Problems",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "RAG",
            "name_full": "Retrieval-Augmented Generation (external data storage)",
            "brief_description": "A retrieval-augmented mechanism where an LLM queries an external datastore (e.g., vector DB) for relevant documents which are injected into the model context to ground responses for knowledge-intensive tasks.",
            "citation_title": "Retrieval-augmented generation for knowledgeintensive nlp tasks",
            "mention_or_use": "mention",
            "agent_name": "LLM + RAG",
            "agent_description": "An LLM architecture augmented with a retriever module and external vector/document store; retriever returns relevant passages that are appended to the model context to improve factuality and grounding.",
            "memory_used": true,
            "memory_type": "retrieval-augmented / external database",
            "memory_mechanism_description": "Queries are transformed to embeddings, nearest-neighbor search returns supporting documents from an external index, and the retrieved text is composed into the prompt/context for the LLM to condition its generation.",
            "task_name": "knowledge-intensive NLP tasks",
            "task_description": "Tasks requiring up-to-date or large factual knowledge beyond the model's parameterized knowledge (e.g., open-domain QA, fact-checking).",
            "task_type": "question answering / knowledge-grounded generation",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": false,
            "key_findings": "RAG-style external storage is cited as a standard approach to augment LLMs with persistent, updatable knowledge and improve grounding and relevance of outputs.",
            "limitations_or_challenges": "Retrieval failures and noisy or irrelevant documents can degrade outputs; integration and prompt design are nontrivial; privacy and access-control concerns for shared stores.",
            "uuid": "e3024.2",
            "source_info": {
                "paper_title": "LLM Multi-Agent Systems: Challenges and Open Problems",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "episodic memory",
            "name_full": "Episodic memory (multi-agent)",
            "brief_description": "A stored collection of past multi-agent interactions (episodes) that agents can reference when confronted with new tasks to improve relevance and accuracy by leveraging contextually similar past episodes.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "agent_name": "multi-agent episodic memory",
            "agent_description": "A mechanism in multi-agent systems that records sequences of interactions (episodes) among agents and allows retrieval of whole episodes or episode fragments to inform reasoning on new, related problems.",
            "memory_used": true,
            "memory_type": "episodic memory (interaction history)",
            "memory_mechanism_description": "Episodes (logs of agent interactions and outcomes) are indexed and retrieved when new tasks have contextual similarity; retrieved episodes provide precedents, strategies, or factual context to inform current agent decisions.",
            "task_name": "",
            "task_description": "Used when agents face new tasks or queries that are similar to past interactions; supports transfer of past solutions or strategies.",
            "task_type": "multi-step reasoning / adaptation",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": false,
            "key_findings": "Episodic memory allows multi-agent systems to leverage previously encountered interaction patterns to improve accuracy and relevance on new, similar tasks.",
            "limitations_or_challenges": "Selecting which episodes are relevant is challenging; storage and retrieval scaling, privacy of recorded episodes, and ensuring up-to-date consistency across agents are open problems.",
            "uuid": "e3024.3",
            "source_info": {
                "paper_title": "LLM Multi-Agent Systems: Challenges and Open Problems",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "consensus memory",
            "name_full": "Consensus memory (shared skill library)",
            "brief_description": "A unified shared memory used across agents to store common knowledge, shared skills, or canonical information to align agents' understanding and strategies during collaboration.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "agent_name": "multi-agent consensus memory",
            "agent_description": "Shared repository (e.g., 'skill library') accessible to collaborating agents to read/write consensus facts, domain knowledge, or agreed-upon strategies to maintain coherence across the system.",
            "memory_used": true,
            "memory_type": "shared / consensus memory",
            "memory_mechanism_description": "A centralized or federated store holds canonical items (skills, rules, common-sense facts). Agents consult this store to align decisions; updates require agreement protocols or access controls to maintain integrity.",
            "task_name": "",
            "task_description": "Used in collaborative tasks where agents must share and align on domain knowledge or capabilities to coordinate effectively.",
            "task_type": "multi-agent coordination / collaborative reasoning",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": false,
            "key_findings": "Consensus memory is important to align multi-agent behaviors and prevent inconsistent outputs; a skill library is cited as an example implementation.",
            "limitations_or_challenges": "Access control, integrity (tampering), and synchronization are major challenges; also deciding what to store in consensus memory vs. private memory is unresolved.",
            "uuid": "e3024.4",
            "source_info": {
                "paper_title": "LLM Multi-Agent Systems: Challenges and Open Problems",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Generative Agents",
            "name_full": "Generative agents: Interactive simulacra of human behavior",
            "brief_description": "A framework (Park et al., 2023) that simulates interactive agent behavior in environments; cited here as an example of agents that rely on recorded interactions/memory to behave plausibly over time.",
            "citation_title": "Generative agents: Interactive simulacra of human behavior",
            "mention_or_use": "mention",
            "agent_name": "Generative agents (Park et al., 2023)",
            "agent_description": "Agents designed to simulate human-like behavior in interactive environments by recording, storing, and using memory of past interactions to inform future actions and dialogue.",
            "memory_used": true,
            "memory_type": "episodic / long-term memory (recorded interactions)",
            "memory_mechanism_description": "Agents record interaction traces which are indexed and retrieved to guide later behavior; memories support continuity, personalization, and context in subsequent interactions.",
            "task_name": "interactive simulation of human behavior",
            "task_description": "Simulate believable, long-running agent behavior in virtual environments where recall of prior interactions and personal facts is needed to maintain coherent behavior and narrative.",
            "task_type": "simulation / interactive environment / dialogue",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": false,
            "key_findings": "The survey cites generative agents as an example where memory is central to producing coherent, contextually consistent behavior over time.",
            "limitations_or_challenges": "Not detailed in this survey; general challenges include which memories to store, retrieval relevance, scaling, and privacy of stored personal interactions.",
            "uuid": "e3024.5",
            "source_info": {
                "paper_title": "LLM Multi-Agent Systems: Challenges and Open Problems",
                "publication_date_yy_mm": "2024-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Retrieval-augmented generation for knowledgeintensive nlp tasks",
            "rating": 2,
            "sanitized_title": "retrievalaugmented_generation_for_knowledgeintensive_nlp_tasks"
        },
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior",
            "rating": 2,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        },
        {
            "paper_title": "Mot: Memory-of-thought enables chatgpt to self-improve",
            "rating": 2,
            "sanitized_title": "mot_memoryofthought_enables_chatgpt_to_selfimprove"
        },
        {
            "paper_title": "Augmenting language models with long-term memory",
            "rating": 2,
            "sanitized_title": "augmenting_language_models_with_longterm_memory"
        },
        {
            "paper_title": "Configurable general multi-agent interaction framework",
            "rating": 2,
            "sanitized_title": "configurable_general_multiagent_interaction_framework"
        },
        {
            "paper_title": "Promptguided retrieval augmentation for non-knowledgeintensive tasks",
            "rating": 1,
            "sanitized_title": "promptguided_retrieval_augmentation_for_nonknowledgeintensive_tasks"
        }
    ],
    "cost": 0.01190175,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LLM Multi-Agent Systems: Challenges and Open Problems
12 May 2025</p>
<p>Shanshan Han 
Qifan Zhang 
Yuhang Yao 
Weizhao Jin 
Zhaozhuo Xu 
LLM Multi-Agent Systems: Challenges and Open Problems
12 May 20251EF720C3A98962BEA24A15FE7E3E02EDarXiv:2402.03578v2[cs.MA]
This paper explores multi-agent systems and identify challenges that remain inadequately addressed.By leveraging the diverse capabilities and roles of individual agents, multi-agent systems can tackle complex tasks through agent collaboration.We discuss optimizing task allocation, fostering robust reasoning through iterative debates, managing complex and layered context information, and enhancing memory management to support the intricate interactions within multiagent systems.We also explore potential applications of multi-agent systems in blockchain systems to shed light on their future development and application in real-world distributed systems.</p>
<p>Introduction</p>
<p>Multi-agent systems enhance the capabilities of single LLM agents by leveraging collaborations among agents and their specialized abilities (Talebirad &amp; Nadiri, 2023;Zhang et al., 2023a;Park et al., 2023;Li et al., 2023;Jinxin et al., 2023).It utilizing collaboration and coordination among agents to execute tasks that are beyond the capability of any individual agent.In multi-agent systems, each agent is equipped with distinctive capabilities and roles, collaborating towards the fulfillment of some common objectives.Such collaboration, characterized by activities such as debate and reflection, has proven particularly effective for tasks requiring deep thought and innovation.Recent works include simulating interactive environments (Park et al., 2023;Jinxin et al., 2023), roleplaying (Li et al., 2023), reasoning (Du et al., 2023;Liang et al., 2023), demonstrating the huge potential of multi-agent systems in handling complex real-world scenarios.</p>
<p>While existing works have demonstrated the impressive capabilities of multi-agent systems, the potential for advanced multi-agent systems far exceeds the progress made to date.</p>
<p>A large number of existing works focus on devising planning strategies within a single agent by breaking down the tasks into smaller, more manageable tasks (Chen et al., 2022;Ziqi &amp; Lu, 2023;Yao et al., 2023;Long, 2023;Besta et al., 2023;Wang et al., 2022b).Yet, multi-agent systems involve agents of various specializations and more complex interactions and layered context information, which poses challenges to the designing of the work flow as well as the whole system.Also, existing literature pays limited attention to memory storage, while memory plays a critical role in collaborations between agents.It enables agents to access to some common sense, aligning context with their tasks, and further, learn from past work flows and adapt their strategies accordingly.</p>
<p>To date, multiple significant challenges that differentiate multi-agent systems and single-agent systems remain inadequately addressed.We summarize them as follows.</p>
<p> Optimizing task allocation to leverage agents' unique skills and specializations.</p>
<p> Fostering robust reasoning through iterative debates or discussions among a subset of agents to enhance intermediate results.</p>
<p> Managing complex and layered context information, such as context for overall tasks, single agents, and some common knowledge between agents, while ensuring alignment to the general objective.</p>
<p> Managing various types of memory that serve for different objectives in coherent to the interactions in multiagent systems</p>
<p>This paper explores multi-agent systems, offering a survey of the existing works while shedding light on the challenges and open problems in it.We study major components in multi-agent systems, including planning and memory storage, and address unique challenges posed by multiagent systems, compared with single-agent systems.We also explore potential application of multi-agent systems in blockchain systems from two perspectives, including 1) utilizing multi-agent systems as tools, and 2) assigning an agent to each blockchain node to make it represent the user, such that the agent can can complete some tasks on behalf of the user in the blockchain network.</p>
<p>Overview</p>
<p>Structure of Multi-agent Systems</p>
<p>The structure of multi-agent systems can be categorized into various types, based on the each agent's functionality and their interactions.</p>
<p>Equi-Level Structure.LLM agents in an equi-level system operate at the same hierarchical level, where each agent has its role and strategy, but neither holds a hierarchical advantage over the other, e.g., DMAS (Chen et al., 2023); see Figure 1(a).The agents in such systems can have same, neutral, or opposing objectives.Agents with same goals collaborate towards a common goal without a centralized leadership.The emphasis is on collective decision-making and shared responsibilities (Li et al., 2019).With opposing objectives, the agents negotiate or debate to convince the others or achieve some final solutions (Terekhov et al., 2023;Du et al., 2023;Liang et al., 2023;Chan et al., 2023).</p>
<p>Hierarchical Structure.Hierarchical structures (Gronauer &amp; Diepold, 2022;Ahilan &amp; Dayan, 2019) 2006) fall into this category (Harris et al., 2023).This type of game is distinguished by this leadership-followership dynamic and the sequential nature of decision-making.Agents make decisions in a sequential order, where the leader player first generate an output (e.g., instructions) then the follower players take an action based on the leader's instruction.</p>
<p>Nested Structure.Nested structures, or hybrid structures, constitute sub-structures of equi-level structures and/or hierarchical structures in a same multi-agent system (Chan et al., 2023); see Figure 1(c).The "big picture" of the system can be either equi-level or hierarchical, however, as some agents have to handle complex tasks, they break down the tasks into small ones and construct a sub-system, either equi-level or hierarchical, and "invite" several agents to help with those tasks.In such systems, the interplay between different levels of hierarchy and peer-to-peer interaction contributes to complexity.Also, the interaction among those different structures can lead to intricate dynamics, where strategies and responses become complicated due to the presence of various influencing factors, including external elements like context or environment.</p>
<p>Dynamic Structure.Dynamic structures mean that the states of the multi-agent system, e.g., the role of agents, their relations, and the number of agents in the multi-agent system, may change (Talebirad &amp; Nadiri, 2023) over time.</p>
<p>As an example, (Talebirad &amp; Nadiri, 2023) enables addition and removal of agents to make the system to suit the tasks at hand.A multi-agent system may also be contextually adaptive, with the interaction patterns inside the system being modified based on internal system states or external factors, such as contexts.Agents in such systems can dynamically reconfigure their roles and relationships in response to changing conditions.</p>
<p>Overview of Challenges in Multi-Agent Systems</p>
<p>This paper surveys various components of multi-agent systems and discusses the challenges compared with singleagent systems.We discuss planning, memory management, as well as potential applications of multi-agent systems on distributed systems, e.g., blockchain systems.</p>
<p>Planning.In a single-agent system, planning involves the LLM agent breaking down large tasks into a sequence of small, manageable tasks to achieve specific goals efficiently while enhancing interpretability, controllability, and flexibility (Li et al., 2024;Zhang et al., 2023b;Nye et al., 2021;Wei et al., 2022).The agent can also learn to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), or connect LLMs with websites, software, and tools (Patil et al., 2023;Zhou et al., 2023;Cai et al., 2023) to help reasoning and improve performance.While agents in a multi-agent system have same capabilities with single-agent systems, they encounter challenges inherited from the work flow in multiagent systems.In 3, we discuss partitioning work flow and allocating the sub-tasks to agents; we name this process as "global planning"; see 3.1.We then discuss task decomposition in each single-agent.Different from planning in a single-agent systems, agents in multi-agent systems must deal with more sophisticated contexts to reach alignment inside the multi-agent system, and further, achieve consistency towards the overall objective; see 3.2.</p>
<p>Memory management.Memory management in singleagent systems include short-term memory during a conversation, long-term memory that store historical conversations, and, if any, external data storage that serves as a complementary information source for inferences, e.g., RAG (Lewis et al., 2020).Memory management in multi-agent systems must handle complex context data and sophisticated interaction and history information, thus requires advanced design for memories.We classify the memories involved in multiagent systems in 4.1 and then discuss potential challenges posed by the sophisticated structure of memory in 4.2.</p>
<p>Application.We discuss applications of multi-agent systems in blockchain, a distributed system that involves sophisticated design of layers and applications.Basically, multiagent systems can serve as a tool due to its ability to handle sophisticated tasks in blockchain; see 5.1.Blockchain can also be integrated with multi-agent systems due to their distributed nature, where an intelligent agent can be allocated to an blockchain node to perform sophisticated actions, such as negotiations, on behalf of the agent; see 5.2.</p>
<p>Planning</p>
<p>Planning in multi-agent systems involves understanding the overall tasks and design work flow among agents based on their roles and specializations, (i.e., global planning) and breaking down the tasks for each agent into small manageable tasks (i.e., local planning).Such process must account for functionalities of the agents, dynamic interactions among the agents, as well as a more complex context compared with single-agent systems.This complexity introduces unique challenges and opportunities in the multi-agent systems.</p>
<p>Global Planning</p>
<p>Global planning refers to understanding the overall task and split the task into smaller ones and coordinate the subtasks to the agents.It requires careful consideration of task decomposition and agent coordination.Below we discuss the unique challenges in global planning in multi-agent systems.</p>
<p>Designing effective work flow based on the agents' specializations.Partitioning responsibilities and designing effective work flows for agents is crucial for ensuring that the tasks for each agent are executable while meaningful and directly contributes to the overall objective in systems.</p>
<p>The biggest challenge lies in the following perspectives: 1) the partition of work flow should maximize the utilization of each agent's unique capabilities, i.e., each agent can handle a part of the task that matches its capabilities and expertise; 2) each agent's tasks must align with the overall goal; and 3) the design must understand and consider the context for the overall tasks as well as each agent.This requires a deep understanding of the task at hand and the specific strengths and limitations of each agent in the system.</p>
<p>Introducing loops for a subset of agents to enhance intermediate results.Multi-agent systems can be integrated with loops inside one or multiple subsets of agents to improve the quality of the intermediate results, or, local optimal answers.In such loops, agents debate or discuss to achieve an optimal results that are accepted by the agents in the loop.The iterative process can refine the intermediate results, leading to a deeper exploration of the task.</p>
<p>The agents in the loop can adjust their reasoning process and plans during the loop, thus have better capabilities in handling uncertainties of the task.</p>
<p>Game Theory.Game theory provides a well-structured framework for understanding strategic interactions in multiagent systems, particularly for systems that involve complex interactions among agents such as debates or discussions.A crucial concept in game theory is equilibrium, e.g., Nash Equilibrium (Kreps, 1989) and Stackelberg Equilibrium (Von Stackelberg, 2010;Conitzer &amp; Sandholm, 2006), that describes a state where, given the strategies of others, no agent benefits from unilaterally changing their strategy.Game theory has been applied in multi-agent systems, especially Stackelberg equilibrium (Gerstgrasser &amp; Parkes, 2023;Harris et al., 2023), as the structure of Stackelberg equilibrium contains is a leader agent and multiple follower agents, and such hierarchical architectures are wildely considered in multi-agent systems.(Gerstgrasser &amp; Parkes, 2023) designs a general multi-agent framework to identify Stackelberg Equilibrium in Markov games, and (Harris et al., 2023) extend the Stackelberg model to allow agents to consider external context information, such as traffic and weather, etc.However, some problems are still challenging in multi-agent systems, such as defining an appropriate payoff structure for both the collective strategy and individual agents based on the context of the overall tasks, and efficiently achieving equilibrium states.These unresolved issues highlight the ongoing need for refinement in the application of game theory to complex multi-agent scenarios.</p>
<p>Single-Agent Task Decomposition</p>
<p>Task decomposition in a single agent involves generating a series of intermediate reasoning steps to complete a task or arrive at an answer.This process can be represented as transforming direct input-output (input  output) mappings into the input  rational  output mappings (Wei et al., 2022;Zhang et al., 2023b).Task composition can be of different formats, as follows.</p>
<p>i) Chain of Thoughts (CoT) (Wei et al., 2022) that transforms big tasks into step-by-step manageable tasks to represent interpretation of the agents' reasoning (or thinking) process.</p>
<p>ii) Multiple CoTs (Wang et al., 2022a) that explores multiple independent CoT reasoning paths and return the one with the best output.</p>
<p>iii) Program-of-Thoughts (PoT) (Chen et al., 2022) that uses language models to generate text and programming language statements, and finally an answer.</p>
<p>iv) Table-of-Thoughts (Tab-CoT) (Ziqi &amp; Lu, 2023) that utilize a tabular-format for reasoning, enabling the complex reasoning process to be explicitly modelled in a highly structured manner.</p>
<p>v) Tree-of-Thoughts (ToT) (Yao et al., 2023;Long, 2023) that extends CoT by formulating a tree structure to explore multiple reasoning possibilities at each step.It enables generating new thoughts based on a given arbitrary thought and possibly backtracking from it.</p>
<p>vi) Graph-of-Thoughts-Rationale (GoT-Rationale) (Besta et al., 2023) that explores an arbitrary graph to enable aggregating arbitrary thoughts into a new one and enhancing the thoughts using loops.</p>
<p>vii) Rationale-Augmented Ensembles (Wang et al., 2022b) that automatically aggregate across diverse rationales to overcome the brittleness of performance to sub-optimal rationales.</p>
<p>In multi-agent systems, task decomposition for a single agent becomes more intricate.Each agent must understand layered and sophisticated context, including 1) the overall tasks, 2) the specific context of the agent's individual tasks, and 3) the contextual information provided by other agents in the multi-agent system.Moreover, the agents must align these complex, multi-dimensional contexts into their decomposed tasks to ensure coherent and effective functioning within the overall task.We summarize the challenges for single agent planning as follows.</p>
<p>Aligning Overall Context.Alignment of goals among different agents is crucial in multi-agent systems.Each LLM agent must have a clear understanding of its role and how it fits into the overall task, such that the agents can perform their functions effectively.Beyond individual roles, agents need to recognize how their tasks fit into the bigger picture, such that their outputs can harmonize with the outputs of other agents, and, further, ensuring all efforts are directed towards the common goal.</p>
<p>Aligning Context Between Agents.Agents in multiagent systems process tasks collectively, and each agent must understand and integrate the contextual information provided by other agents within the system to ensure that the information provided by other agents is fully utilized.</p>
<p>Aligning Context for Decomposed Tasks.When tasks of each agents are broken down into smaller, more manageable sub-tasks, aligning the complex context in multi-agent systems becomes challenging.Each agent's decomposed task must fit their individual tasks and the overall goal while integrating with contexts of other agents.Agents must adapt and update their understanding of the task in response to context provided by other agents, and further, plan the decomposed tasks accordingly.</p>
<p>Consistency in Objectives.</p>
<p>In multi-agent systems, consistency in objectives is maintained across various levels, i.e., from overall goals down to individual agent tasks and their decomposed tasks.Each agent must understand and effectively utilize the layered contexts while ensuring its task and the decomposed sub-tasks to remain aligned with the overall goals.(Harris et al., 2023) extends the Stackelberg model (Von Stackelberg, 2010;Conitzer &amp; Sandholm, 2006) to enable agents to incorporate external context information, such as context (or insights) provided by other agents.However, aligning the complex context with the decomposed tasks during reasoning remains unresolved.</p>
<p>Agent Memory and Information Retrieval</p>
<p>The memory in single-LLM agent systems refers to the agent's ability to record, manage, and utilize data, such as past historical queries and some external data sources, to help inference and enhance decision-making and reasoning (Yao et al., 2023;Park et al., 2023;Li &amp; Qiu, 2023;Wang et al., 2023;Guo et al., 2023).While the memory in a single-LLM agent system primarily focuses on internal data management and utilization, a multi-agent system requires agents to work collaboratively to complete some tasks, necessitating the individual memory capabilities of each agent as well as a sophisticated mechanism for sharing, integrating, and managing information across agents, thus poses challenges to memory and information retrieval.</p>
<p>Classifications of Memory in Multi-agent Systems</p>
<p>Based on the work flow of a multi-agent system, we categorize memory in multi-agent system as follows.</p>
<p> Short-term memory: This is the immediate, transient memory used by a Large Language Model (LLM) during a conversation or interaction, e.g., working memory in (Jinxin et al., 2023).It is ephemeral, existing only for the duration of the ongoing interaction and does not persist once the conversation ends.</p>
<p> Long-term Memory: This type of memory stores historical queries and responses, essentially chat histories from earlier sessions, to support inferences for future interactions.Typically, this memory is stored in external data storage, such as a vector database, to facilitate recall of past interactions. External data storage: This is an emerging area in LLM research where models are integrated with external data storage like vector databases, such that the agents can access additional knowledge from these databases, enhancing their ability to ground and enrich their responses (Lewis et al., 2020).This allows the LLM to produce responses that are more informative, accurate, and highly relevant to the specific context of the query. Episodic Memory: This type of memory encompasses a collection of interactions within multi-agent systems.</p>
<p>It plays a crucial role when agents are confronted with new tasks or queries.By referencing past interactions that have contextual similarities to the current query, agents can significantly enhance the relevance and accuracy of their responses.Episodic Memory allows for a more informed approach to reasoning and problemsolving, enabling a more adaptive and intelligent response mechanism, thus serves as a valuable asset in the multi-agent system,  Consensus Memory: In a multi-agent system where agents work on a task collaboratively, consensus memory acts as a unified source of shared information, such as common sense, some domain-specific knowledge, etc, e.g., skill library in (Jinxin et al., 2023).Agents utilize consensus memory to align their understanding and strategies with the tasks, thus enhancing an effective and cohesive collaboration among agents.</p>
<p>While both single-agent and multi-agent systems handle short-term memory and long-term memory, multi-agent systems introduce additional complexities due to the need for inter-agent communication, information sharing, and adaptive memory management.</p>
<p>Challenges in Multi-agent Memory Management</p>
<p>Managing memory in multi-agent systems is fraught with challenges and open problems, especially in the realms of safety, security, and privacy.We outline these as follows:</p>
<p>Hierarchical Memory Storage: In a multi-agent system, different agents often have varied functionalities and access needs.Some agents may have to query their sensitive data, but they don't want such data to be accessed by other parties.</p>
<p>While ensuring the consensus memory to be accessible to all clients, implementing robust access control mechanisms is crucial to ensure sensitive information of an agent is not accessible to all agents.Additionally, as the agents in a sys-tem collaborative on one task, and their functionalities share same contexts, their external data storage and memories may overlap.If the data and functionalities of these agents are not sensitive, adopting an unified data storage can effectively manage redundancy among the data, and furthermore, ensure consistency across the multi-agent system, leading to more efficient and precise maintenance of memory.</p>
<p>Maintenance of Consensus Memory: As consensus memory is obtained by all agents when collaborating on a task, ensuring the integrity of shared knowledge is critical to ensure the correct execution of the tasks in the multi-agent systems.Any tampering or unauthorized modification of consensus memory can lead to systemic failures of the execution.Thus, a rigorous access control is important to mitigate risks of data breaches.</p>
<p>Communication and information exchange: Ensuring effective communication and information exchange between agents is essential in multi-agent systems.Each agent may hold critical pieces of information, and seamless integration of these is vital for the overall system performance.</p>
<p>Management of Episodic Memory.Leveraging past interactions within the multi-agent system to enhance responses to new queries is challenging in multi-agent systems.Determining how to effectively recall and utilize contextually relevant past interactions among agents for current problemsolving scenarios is important.</p>
<p>These challenges underscore the need for continuous research and development in the field of multi-agent systems, focusing on creating robust, secure, and efficient memory management methodologies.</p>
<p>Applications in Blockchain</p>
<p>Multi-agent systems offer significant advantages to blockchain systems by augmenting their capabilities and efficiency.Essentially, these multi-agent systems serve as sophisticated tools for various tasks on blockchain and Web3 systems.Also, blockchain nodes can be viewed as agents with specific roles and capabilities (Ankile et al., 2023).</p>
<p>Given that both Blockchain systems and multi-agent systems are inherently distributed, the blockchain networks can be integrated with multi-agent systems seamlessly.By assigning a dedicated agent to each blockchain node, it's possible to enhance data analyzing and processing while bolstering security and privacy in the chain.</p>
<p>Multi-Agent Systems As a Tool</p>
<p>To cast a brick to attract jade, we give some potential directions that multi-agents systems can act as tools to benefit blockchain systems.Fraud Detection.Fraud detection is one of the most important task in financial monitoring.As an example, (Ankile et al., 2023) studies fraud detection through the perspective of an external observer who detects price manipulation by analyzing the transaction sequences or the price movements of a specific asset.Multi-agent systems can benefit fraud detection in blockchain as well.Agents can be deployed with different roles, such as monitoring transactions for fraudulent activities and analyzing user behaviors.Each agent could also focus on different behavior patterns to improve the accuracy and efficiency of the fraud detection process.</p>
<p>Blockchain Nodes as Agents</p>
<p>( Ankile et al., 2023) identifies blockchain nodes as agents, and studies fraud detection in the chain from the perspective an external observer.However, as powerful LLM agents with analyzing and reasoning capabilities, there are much that the agents can do, especially when combined with game theory and enable the agents to negotiate and debate.Below we provide some perspectives.</p>
<p>Smart Contract Management and Optimization.Smart contracts are programs that execute the terms of a contract between a buyer and a seller in a blockchain system.The codes are fixed, and are self-executed when predetermined conditions are met.Multi-agent systems can automate and optimize the execution of smart contracts with more flexible terms and even dynamic external information from users.</p>
<p>Agents can negotiate contract terms on behalf of their users, manage contract execution, and even optimize gas fees (in the context of Ethereum (Wood et al., 2014).The agents can analyze context information , such as past actions and predefined criteria, and utilize the information with flexibility.Such negotiations can also utilize game theory, such as Stackelberg Equilibrium (Von Stackelberg, 2010;Conitzer &amp; Sandholm, 2006) when there is a leader negotiator and Nash Equilibrium (Kreps, 1989) when no leader exists.</p>
<p>Conclusion</p>
<p>The exploration of multi-agent systems in this paper underscores their significant potential in advancing the capabilities of LLM agents beyond the confines of single-agent paradigms.By leveraging the specialized abilities and collaborative dynamics among agents, multi-agent systems can tackle complex tasks with enhanced efficiency and innovation.Our study has illuminated challenges that need to be addressed to harness the power of multi-agent systems better, including optimizing task planning, managing complex context information, and improving memory management.Furthermore, the potential applications of multi-agent systems in blockchain technologies reveal new avenues for development, which suggests a promising future for these systems in distributed computing environments.</p>
<p>Figure 1 .
1
Figure 1.Structures of multi-agent systems.</p>
<p>Smart Contract Analysis.Smart contracts are programs stored on a blockchain that run when predetermined conditions are met.Multi-agents work together to analyze and audit smart contracts.The agents can have different specializations, such as identifying security vulnerabilities, legal compliance, and optimizing contract efficiency.Their collaborative analysis can provide a more comprehensive review than a single agent could achieve alone.
Consensus Mechanism Enhancement. Consensus mech-anisms like Proof of Work (PoW) (Gervais et al., 2016) orProof of Stake (PoS) (Saleh, 2021) are critical for validatingtransactions and maintaining network integrity. Multi-agentsystems can collaborate to monitor network activities, an-alyze transaction patterns, and identify potential securitythreats. By working together, these agents can proposeenhancements to the consensus mechanism, making theblockchain more secure and efficient.
University of California, Irvine, CA, USA
Carnegie Mellon University, Pittsburgh, PA, USA
University of Southern California, Los Angeles, CA,
USA 4 Stevens Institute of Technology, Hoboken, NJ, USA. Correspondence to: Shanshan Han <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#115;&#104;&#97;&#110;&#115;&#104;&#97;&#110;&#46;&#104;&#97;&#110;&#64;&#117;&#99;&#105;&#46;&#101;&#100;&#117;">&#115;&#104;&#97;&#110;&#115;&#104;&#97;&#110;&#46;&#104;&#97;&#110;&#64;&#117;&#99;&#105;&#46;&#101;&#100;&#117;</a>.</p>
<p>Feudal multi-agent hierarchies for cooperative reinforcement learning. S Ahilan, P Dayan, arXiv:1901.084922019arXiv preprint</p>
<p>I see you! robust measurement of adversarial behavior. L Ankile, M X Ferreira, D Parkes, Multi-Agent Security Workshop@ NeurIPS'23. 2023</p>
<p>Graph of thoughts: Solving elaborate problems with large language models. M Besta, N Blach, A Kubicek, R Gerstenberger, L Gianinazzi, J Gajda, T Lehmann, M Podstawski, H Niewiadomski, P Nyczyk, arXiv:2308.096872023arXiv preprint</p>
<p>T Cai, X Wang, T Ma, X Chen, D Zhou, arXiv:2305.17126Large language models as tool makers. 2023arXiv preprint</p>
<p>C.-M Chan, W Chen, Y Su, J Yu, W Xue, S Zhang, J Fu, Z Liu, arXiv:2308.07201Towards better llm-based evaluators through multi-agent debate. 2023arXiv preprint</p>
<p>Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. W Chen, X Ma, X Wang, W W Cohen, arXiv:2211.125882022arXiv preprint</p>
<p>Scalable multi-robot collaboration with large language models: Centralized or decentralized systems?. Y Chen, J Arkin, Y Zhang, N Roy, Fan , C , arXiv:2309.159432023arXiv preprint</p>
<p>Computing the optimal strategy to commit to. V Conitzer, T Sandholm, Proceedings of the 7th ACM conference on Electronic commerce. the 7th ACM conference on Electronic commerce2006</p>
<p>Improving factuality and reasoning in language models through multiagent debate. Y Du, S Li, A Torralba, J B Tenenbaum, I Mordatch, arXiv:2305.143252023arXiv preprint</p>
<p>Oracles &amp; followers: Stackelberg equilibria in deep multi-agent reinforcement learning. M Gerstgrasser, D C Parkes, International Conference on Machine Learning. PMLR2023</p>
<p>On the security and performance of proof of work blockchains. A Gervais, G O Karame, K Wst, V Glykantzis, H Ritzdorf, S Capkun, Proceedings of the 2016 ACM SIGSAC conference on computer and communications security. the 2016 ACM SIGSAC conference on computer and communications security2016</p>
<p>Multi-agent deep reinforcement learning: a survey. S Gronauer, K Diepold, Artificial Intelligence Review. 2022</p>
<p>Promptguided retrieval augmentation for non-knowledgeintensive tasks. Z Guo, S Cheng, Y Wang, P Li, Y Liu, arXiv:2305.176532023arXiv preprint</p>
<p>Stackelberg games with side information. K Harris, S Wu, M F Balcan, Multi-Agent Security Workshop@ NeurIPS'23. 2023</p>
<p>S Jinxin, Z Jiabao, W Yilei, W Xingjiao, L Jiawen, H Liang, Cgmi, arXiv:2308.12503Configurable general multi-agent interaction framework. 2023arXiv preprint</p>
<p>Nash equilibrium. D M Kreps, Game Theory. Springer1989</p>
<p>Retrieval-augmented generation for knowledgeintensive nlp tasks. P Lewis, E Perez, A Piktus, F Petroni, V Karpukhin, N Goyal, H Kttler, M Lewis, W.-T Yih, T Rocktschel, Advances in Neural Information Processing Systems. 202033</p>
<p>G Li, H A A K Hammoud, H Itani, D Khizbullin, B Ghanem, Camel, arXiv:2303.17760Communicative agents for" mind" exploration of large scale language model society. 2023arXiv preprint</p>
<p>Mot: Memory-of-thought enables chatgpt to self-improve. X Li, X Qiu, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language Processing2023</p>
<p>Multi-agent discussion mechanism for natural language generation. X Li, M Sun, P Li, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence201933</p>
<p>Y Li, H Wen, W Wang, X Li, Y Yuan, G Liu, J Liu, W Xu, X Wang, Y Sun, arXiv:2401.05459Personal llm agents: Insights and survey about the capability, efficiency and security. 2024arXiv preprint</p>
<p>Encouraging divergent thinking in large language models through multi-agent debate. T Liang, Z He, W Jiao, X Wang, Y Wang, R Wang, Y Yang, Z Tu, S Shi, arXiv:2305.191182023arXiv preprint</p>
<p>Large language model guided tree-of-thought. J Long, arXiv:2305.082912023arXiv preprint</p>
<p>Show your work: Scratchpads for intermediate computation with language models. M Nye, A J Andreassen, G Gur-Ari, H Michalewski, J Austin, D Bieber, D Dohan, A Lewkowycz, M Bosma, D Luan, arXiv:2112.001142021arXiv preprint</p>
<p>Generative agents: Interactive simulacra of human behavior. J S Park, J O'brien, C J Cai, M R Morris, P Liang, M S Bernstein, Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. the 36th Annual ACM Symposium on User Interface Software and Technology2023</p>
<p>S G Patil, T Zhang, X Wang, J E Gonzalez, Gorilla, arXiv:2305.15334Large language model connected with massive apis. 2023arXiv preprint</p>
<p>Blockchain without waste: Proof-of-stake. The Review of financial studies. F Saleh, 202134</p>
<p>Multi-agent collaboration: Harnessing the power of intelligent llm agents. Y Talebirad, A Nadiri, arXiv:2306.033142023arXiv preprint</p>
<p>Second-order jailbreaks: Generative agents successfully manipulate through an intermediary. M Terekhov, R Graux, E Neville, D Rosset, G Kolly, Multi-Agent Security Workshop@ NeurIPS'23. 2023</p>
<p>Market structure and equilibrium. Von Stackelberg, H , 2010Springer Science &amp; Business Media</p>
<p>W Wang, L Dong, H Cheng, X Liu, X Yan, J Gao, F Wei, arXiv:2306.07174Augmenting language models with long-term memory. 2023arXiv preprint</p>
<p>Self-consistency improves chain of thought reasoning in language models. X Wang, J Wei, D Schuurmans, Q Le, E Chi, S Narang, A Chowdhery, D Zhou, arXiv:2203.111712022aarXiv preprint</p>
<p>X Wang, J Wei, D Schuurmans, Q Le, E Chi, D Zhou, arXiv:2207.00747Rationale-augmented ensembles in language models. 2022barXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, F Xia, E Chi, Q V Le, D Zhou, Advances in Neural Information Processing Systems. 202235</p>
<p>Ethereum: A secure decentralised generalised transaction ledger. Ethereum project yellow paper. G Wood, 2014. 2014151</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. S Yao, D Yu, J Zhao, I Shafran, T L Griffiths, Y Cao, K Narasimhan, arXiv:2305.106012023arXiv preprint</p>
<p>Exploring collaboration mechanisms for llm agents: A social psychology view. J Zhang, X Xu, S Deng, 2023a</p>
<p>Igniting language intelligence: The hitchhiker's guide from chainof-thought reasoning to language agents. Z Zhang, Y Yao, A Zhang, X Tang, X Ma, Z He, Y Wang, M Gerstein, R Wang, G Liu, arXiv:2311.117972023barXiv preprint</p>
<p>S Zhou, F F Xu, H Zhu, X Zhou, R Lo, A Sridhar, X Cheng, Y Bisk, D Fried, U Alon, arXiv:2307.13854A realistic web environment for building autonomous agents. 2023arXiv preprint</p>
<p>Tab-CoT: Zero-shot tabular chain of thought. J Ziqi, W Lu, doi: 10.18653Findings of the Association for Computational Linguistics: ACL 2023. A Rogers, J Boyd-Graber, N Okazaki, Toronto, CanadaAssociation for Computational LinguisticsJuly 2023</p>
<p>URL. </p>            </div>
        </div>

    </div>
</body>
</html>