<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1600 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1600</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1600</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-31.html">extraction-schema-31</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <p><strong>Paper ID:</strong> paper-249538495</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2206.04561v1.pdf" target="_blank">Functional Code Building Genetic Programming</a></p>
                <p><strong>Paper Abstract:</strong> General program synthesis has become an important application area for genetic programming (GP), and for artificial intelligence more generally. Code Building Genetic Programming (CBGP) is a recently introduced GP method for general program synthesis that leverages reflection and first class specifications to support the evolution of programs that may use arbitrary data types, polymorphism, and functions drawn from existing codebases. However, neither a formal description nor a thorough benchmarking of CBGP have yet been reported. In this work, we formalize the method of CBGP using algorithms from type theory. Specially, we show that a functional programming language and a Hindley-Milner type system can be used to evolve type-safe programs using the process abstractly described in the original CBGP paper. Furthermore, we perform a comprehensive analysis of the search performance of this functional variant of CBGP compared to other contemporary GP program synthesis methods.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1600.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1600.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CBGP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Code Building Genetic Programming (functional variant)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A genetic programming system that evolves variable-length linear genomes (plushy-style) which are compiled via a stack-based process into type-safe functional programs (ASTs) using a Hindley–Milner type system; genomes are evaluated as host-language source code (Clojure) and evolved with lexicase selection and mutation-only variation (UMAD).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Code building genetic programming</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Functional Code Building Genetic Programming (CBGP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CBGP represents candidate solutions as variable-length linear genomes (plushy genomes) that are translated into nested push-sequences and compiled (via two stacks) into typed abstract syntax trees (ASTs) in a functional host language. The compilation enforces type safety via Hindley–Milner type inference and unification, supports parametric polymorphism, anonymous functions, higher-order functions and let-bindings, and emits human-readable source code. Evolution is generational with lexicase selection; genomes are instantiated from a curated genetic source (function set). Variation in the experiments reported uses Uniform Mutation by Additions and Deletions (UMAD) as the sole genetic operator; candidate programs are evaluated on supervised input–output training cases, with penalty errors for compilation or runtime failures. Successful individuals are simplified by hill-climbing to improve generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Uniform Mutation by Additions and Deletions (UMAD) as used in the experiments: genomes are altered by uniformly adding or deleting genes drawn from the genetic source; the paper states UMAD is the only genetic operator used in these CBGP experiments (no crossover).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Executability / correctness measured by (a) compilation producing a type-safe AST matching the target return type, (b) runtime behavior on training examples measured by an error function producing an error vector (sum-of-errors used as total error), (c) penalty errors assigned if no valid AST is produced or if runtime errors occur, and (d) generalization measured by re-testing any training-perfect program on 300 unseen random test cases (solution only reported if it passes all 300).</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Experimental protocol: 100 runs per problem; each run uses 100 training cases and 300 unseen test cases. CBGP solved 7 of 14 PSB1 problems with success rates near or at 100% on those problems, and solutions exhibit very high generalization rates (often 1.0 on the 300-case test set). On the remaining problems CBGP's success rate drops to near zero for some tasks. Exact per-problem percentages are reported in Table 3 of the paper (not enumerated here).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>Qualitative discussion only: the authors hypothesize that CBGP's representation and compilation (genome growth does not necessarily imply larger emitted programs) may limit overfitting and bloat, which could explain the unusually high generalization rates; no quantitative tradeoff curve between novelty and executability is presented.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Program synthesis (PSB1 benchmark problems)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>PushGP, Grammar-Guided GP (G3P), Grammatical Evolution (GE)</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CBGP (functional variant) uses UMAD-only variation (no crossover in reported experiments) and enforces type-safe compilation; it finds small, highly generalizable programs on a subset of PSB1 tasks (7/14 problems with near/at-100% success rates on those), while failing on others. The emitted programs are small (few AST nodes) and generalize well to 300 unseen cases; genomes themselves may contain unused genes, so genome size and program size are decoupled. The representation appears to reduce bloat-based overfitting, but no explicit novelty or diversity metrics were measured. Lexicase selection is used to select parents, which encourages selection of specialists but diversity was not quantified.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Functional Code Building Genetic Programming', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1600.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1600.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>UMAD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Uniform Mutation by Additions and Deletions</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mutation operator for program-genome representations that uniformly adds or deletes genome elements (genes/instructions); used in this paper as the sole genetic operator for CBGP experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Program Synthesis Using Uniform Mutation by Addition and Deletion</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Uniform Mutation by Additions and Deletions (UMAD)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>UMAD is a genome-level mutation operator that makes structural edits by adding new genes from the genetic source or deleting existing genes from a linear genome; it was used here as the only variation operator for producing offspring from parents (no crossover) to produce CBGP offspring.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Uniform additions and deletions of genes: new genes are inserted or existing genes removed from the linear plushy genome according to the UMAD rule (the paper states UMAD was used as the only genetic operator but does not re-specify implementation details beyond the cited UMAD paper).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Program synthesis (used to mutate genomes that compile to programs)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The authors used UMAD as the only genetic operator for CBGP runs to match prior PushGP experimental setups; this choice means reported CBGP performance arises from mutation-only variation plus lexicase selection and not from crossover-based recombination.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Functional Code Building Genetic Programming', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1600.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1600.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PushGP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Push-based Genetic Programming (PushGP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GP representation that evolves linear plushy genomes mapping to Push programs executed on multiple typed stacks; known for allowing free mutation and crossover without producing syntactic or execution errors because of its stack-based, type-aware execution model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The Push3 execution stack and the evolution of control</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PushGP (Push-based Genetic Programming)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PushGP represents programs as linear genomes (plushy genomes) that map to programs in the Push language, which uses multiple typed stacks for data and control; because of the stack-based execution model Push programs can be mutated and crossed over freely while avoiding syntax errors, enabling arbitrary data/control structures in evolved programs.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Mentioned generically: Push genomes (plushy linear genomes) can be freely crossed over; the paper notes that Push permits crossover and mutation without risking syntax or execution errors, but does not provide the detailed crossover mechanism in this text.</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Mentioned generically: Push genomes can be freely mutated; specific mutation operators are not detailed in this paper (see PushGP references for precise operators).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Program synthesis (historical strong baseline for general program synthesis tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>CBGP compares performance against published PushGP results</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>PushGP is referenced as a successful program-synthesis representation whose plushy genomes permit safe crossover and mutation across rich type/control structures; the paper uses PushGP results (from literature) as a comparison baseline but does not re-implement PushGP in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Functional Code Building Genetic Programming', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1600.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1600.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>G3P</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Grammar-Guided Genetic Programming (G3P)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Grammar-guided GP methods that evolve programs by ensuring syntactic validity with grammars; used as a comparison class in the paper for program synthesis benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Grammar Design Pattern for Arbitrary Program Synthesis Problems in Genetic Programming</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Grammar-Guided Genetic Programming (G3P)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>G3P uses problem-specific grammars (often type-tuned) to produce syntactically valid programs in a conventional language; grammars constrain search to valid program forms and typically employ grammar-aware crossover and mutation operators so offspring remain syntactically correct.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Not specified in this paper; in general G3P/grammar-based systems use grammar-aware crossover that produces syntactically valid offspring, but the current paper only cites G3P results and does not detail operator mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Not specified in this paper; grammar-aware mutations are typically used to alter derivation rules or tokens while preserving grammar constraints, but the present paper does not provide details.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Program synthesis (PSB1 benchmarks; type-tuned grammars)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>CBGP compares to published G3P results</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Grammar-based approaches guarantee syntactic validity and provide human-readable code output, but in the comparisons reported here G3P sometimes performs worse than CBGP on problems where CBGP succeeds; the paper does not detail grammar-specific operators or diversity/novelty measures.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Functional Code Building Genetic Programming', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1600.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1600.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Grammatical Evolution (GE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An evolutionary approach that maps linear genomes to programs via a grammar; referenced in the paper as a comparator and noted in literature exploring novelty and domain knowledge for program synthesis.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>On Domain Knowledge and Novelty to Improve Program Synthesis Performance with Grammatical Evolution</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Grammatical Evolution (GE)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GE evolves linear genomes which are decoded via grammars into programs; grammar tuning and domain knowledge can be used to focus search, and prior GE work has explored integrating novelty measures to improve program synthesis performance (the present paper cites such work but does not adopt novelty techniques).</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Not detailed in this paper; GE typically uses standard GA crossover on genotypes or grammar-aware operators, but the present paper only cites GE results and notes prior GE work that explored novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Not detailed in this paper; GE commonly uses point-wise genome mutation and mapping-to-grammar behavior, but no implementation details are given here.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Program synthesis (cited as a baseline and prior art; GE literature has explored novelty metrics but the current paper did not use them)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>CBGP compares to published GE baseline results</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper acknowledges GE work that has used novelty and domain knowledge to improve synthesis, but the CBGP experiments deliberately do not adopt novelty-based measures; thus GE is only a comparative reference here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Functional Code Building Genetic Programming', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Program Synthesis Using Uniform Mutation by Addition and Deletion <em>(Rating: 2)</em></li>
                <li>The Push3 execution stack and the evolution of control <em>(Rating: 2)</em></li>
                <li>Code building genetic programming <em>(Rating: 2)</em></li>
                <li>A Grammar Design Pattern for Arbitrary Program Synthesis Problems in Genetic Programming <em>(Rating: 2)</em></li>
                <li>On Domain Knowledge and Novelty to Improve Program Synthesis Performance with Grammatical Evolution <em>(Rating: 2)</em></li>
                <li>Improving Generalization of Evolved Programs through Automatic Simplification <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1600",
    "paper_id": "paper-249538495",
    "extraction_schema_id": "extraction-schema-31",
    "extracted_data": [
        {
            "name_short": "CBGP",
            "name_full": "Code Building Genetic Programming (functional variant)",
            "brief_description": "A genetic programming system that evolves variable-length linear genomes (plushy-style) which are compiled via a stack-based process into type-safe functional programs (ASTs) using a Hindley–Milner type system; genomes are evaluated as host-language source code (Clojure) and evolved with lexicase selection and mutation-only variation (UMAD).",
            "citation_title": "Code building genetic programming",
            "mention_or_use": "use",
            "system_name": "Functional Code Building Genetic Programming (CBGP)",
            "system_description": "CBGP represents candidate solutions as variable-length linear genomes (plushy genomes) that are translated into nested push-sequences and compiled (via two stacks) into typed abstract syntax trees (ASTs) in a functional host language. The compilation enforces type safety via Hindley–Milner type inference and unification, supports parametric polymorphism, anonymous functions, higher-order functions and let-bindings, and emits human-readable source code. Evolution is generational with lexicase selection; genomes are instantiated from a curated genetic source (function set). Variation in the experiments reported uses Uniform Mutation by Additions and Deletions (UMAD) as the sole genetic operator; candidate programs are evaluated on supervised input–output training cases, with penalty errors for compilation or runtime failures. Successful individuals are simplified by hill-climbing to improve generalization.",
            "input_type": "programs",
            "crossover_operation": null,
            "mutation_operation": "Uniform Mutation by Additions and Deletions (UMAD) as used in the experiments: genomes are altered by uniformly adding or deleting genes drawn from the genetic source; the paper states UMAD is the only genetic operator used in these CBGP experiments (no crossover).",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Executability / correctness measured by (a) compilation producing a type-safe AST matching the target return type, (b) runtime behavior on training examples measured by an error function producing an error vector (sum-of-errors used as total error), (c) penalty errors assigned if no valid AST is produced or if runtime errors occur, and (d) generalization measured by re-testing any training-perfect program on 300 unseen random test cases (solution only reported if it passes all 300).",
            "executability_results": "Experimental protocol: 100 runs per problem; each run uses 100 training cases and 300 unseen test cases. CBGP solved 7 of 14 PSB1 problems with success rates near or at 100% on those problems, and solutions exhibit very high generalization rates (often 1.0 on the 300-case test set). On the remaining problems CBGP's success rate drops to near zero for some tasks. Exact per-problem percentages are reported in Table 3 of the paper (not enumerated here).",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "Qualitative discussion only: the authors hypothesize that CBGP's representation and compilation (genome growth does not necessarily imply larger emitted programs) may limit overfitting and bloat, which could explain the unusually high generalization rates; no quantitative tradeoff curve between novelty and executability is presented.",
            "frontier_characterization": null,
            "benchmark_or_domain": "Program synthesis (PSB1 benchmark problems)",
            "comparison_baseline": "PushGP, Grammar-Guided GP (G3P), Grammatical Evolution (GE)",
            "key_findings": "CBGP (functional variant) uses UMAD-only variation (no crossover in reported experiments) and enforces type-safe compilation; it finds small, highly generalizable programs on a subset of PSB1 tasks (7/14 problems with near/at-100% success rates on those), while failing on others. The emitted programs are small (few AST nodes) and generalize well to 300 unseen cases; genomes themselves may contain unused genes, so genome size and program size are decoupled. The representation appears to reduce bloat-based overfitting, but no explicit novelty or diversity metrics were measured. Lexicase selection is used to select parents, which encourages selection of specialists but diversity was not quantified.",
            "uuid": "e1600.0",
            "source_info": {
                "paper_title": "Functional Code Building Genetic Programming",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "UMAD",
            "name_full": "Uniform Mutation by Additions and Deletions",
            "brief_description": "A mutation operator for program-genome representations that uniformly adds or deletes genome elements (genes/instructions); used in this paper as the sole genetic operator for CBGP experiments.",
            "citation_title": "Program Synthesis Using Uniform Mutation by Addition and Deletion",
            "mention_or_use": "use",
            "system_name": "Uniform Mutation by Additions and Deletions (UMAD)",
            "system_description": "UMAD is a genome-level mutation operator that makes structural edits by adding new genes from the genetic source or deleting existing genes from a linear genome; it was used here as the only variation operator for producing offspring from parents (no crossover) to produce CBGP offspring.",
            "input_type": "programs",
            "crossover_operation": null,
            "mutation_operation": "Uniform additions and deletions of genes: new genes are inserted or existing genes removed from the linear plushy genome according to the UMAD rule (the paper states UMAD was used as the only genetic operator but does not re-specify implementation details beyond the cited UMAD paper).",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Program synthesis (used to mutate genomes that compile to programs)",
            "comparison_baseline": null,
            "key_findings": "The authors used UMAD as the only genetic operator for CBGP runs to match prior PushGP experimental setups; this choice means reported CBGP performance arises from mutation-only variation plus lexicase selection and not from crossover-based recombination.",
            "uuid": "e1600.1",
            "source_info": {
                "paper_title": "Functional Code Building Genetic Programming",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "PushGP",
            "name_full": "Push-based Genetic Programming (PushGP)",
            "brief_description": "A GP representation that evolves linear plushy genomes mapping to Push programs executed on multiple typed stacks; known for allowing free mutation and crossover without producing syntactic or execution errors because of its stack-based, type-aware execution model.",
            "citation_title": "The Push3 execution stack and the evolution of control",
            "mention_or_use": "mention",
            "system_name": "PushGP (Push-based Genetic Programming)",
            "system_description": "PushGP represents programs as linear genomes (plushy genomes) that map to programs in the Push language, which uses multiple typed stacks for data and control; because of the stack-based execution model Push programs can be mutated and crossed over freely while avoiding syntax errors, enabling arbitrary data/control structures in evolved programs.",
            "input_type": "programs",
            "crossover_operation": "Mentioned generically: Push genomes (plushy linear genomes) can be freely crossed over; the paper notes that Push permits crossover and mutation without risking syntax or execution errors, but does not provide the detailed crossover mechanism in this text.",
            "mutation_operation": "Mentioned generically: Push genomes can be freely mutated; specific mutation operators are not detailed in this paper (see PushGP references for precise operators).",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Program synthesis (historical strong baseline for general program synthesis tasks)",
            "comparison_baseline": "CBGP compares performance against published PushGP results",
            "key_findings": "PushGP is referenced as a successful program-synthesis representation whose plushy genomes permit safe crossover and mutation across rich type/control structures; the paper uses PushGP results (from literature) as a comparison baseline but does not re-implement PushGP in these experiments.",
            "uuid": "e1600.2",
            "source_info": {
                "paper_title": "Functional Code Building Genetic Programming",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "G3P",
            "name_full": "Grammar-Guided Genetic Programming (G3P)",
            "brief_description": "Grammar-guided GP methods that evolve programs by ensuring syntactic validity with grammars; used as a comparison class in the paper for program synthesis benchmarks.",
            "citation_title": "A Grammar Design Pattern for Arbitrary Program Synthesis Problems in Genetic Programming",
            "mention_or_use": "mention",
            "system_name": "Grammar-Guided Genetic Programming (G3P)",
            "system_description": "G3P uses problem-specific grammars (often type-tuned) to produce syntactically valid programs in a conventional language; grammars constrain search to valid program forms and typically employ grammar-aware crossover and mutation operators so offspring remain syntactically correct.",
            "input_type": "programs",
            "crossover_operation": "Not specified in this paper; in general G3P/grammar-based systems use grammar-aware crossover that produces syntactically valid offspring, but the current paper only cites G3P results and does not detail operator mechanisms.",
            "mutation_operation": "Not specified in this paper; grammar-aware mutations are typically used to alter derivation rules or tokens while preserving grammar constraints, but the present paper does not provide details.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Program synthesis (PSB1 benchmarks; type-tuned grammars)",
            "comparison_baseline": "CBGP compares to published G3P results",
            "key_findings": "Grammar-based approaches guarantee syntactic validity and provide human-readable code output, but in the comparisons reported here G3P sometimes performs worse than CBGP on problems where CBGP succeeds; the paper does not detail grammar-specific operators or diversity/novelty measures.",
            "uuid": "e1600.3",
            "source_info": {
                "paper_title": "Functional Code Building Genetic Programming",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "GE",
            "name_full": "Grammatical Evolution (GE)",
            "brief_description": "An evolutionary approach that maps linear genomes to programs via a grammar; referenced in the paper as a comparator and noted in literature exploring novelty and domain knowledge for program synthesis.",
            "citation_title": "On Domain Knowledge and Novelty to Improve Program Synthesis Performance with Grammatical Evolution",
            "mention_or_use": "mention",
            "system_name": "Grammatical Evolution (GE)",
            "system_description": "GE evolves linear genomes which are decoded via grammars into programs; grammar tuning and domain knowledge can be used to focus search, and prior GE work has explored integrating novelty measures to improve program synthesis performance (the present paper cites such work but does not adopt novelty techniques).",
            "input_type": "programs",
            "crossover_operation": "Not detailed in this paper; GE typically uses standard GA crossover on genotypes or grammar-aware operators, but the present paper only cites GE results and notes prior GE work that explored novelty.",
            "mutation_operation": "Not detailed in this paper; GE commonly uses point-wise genome mutation and mapping-to-grammar behavior, but no implementation details are given here.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Program synthesis (cited as a baseline and prior art; GE literature has explored novelty metrics but the current paper did not use them)",
            "comparison_baseline": "CBGP compares to published GE baseline results",
            "key_findings": "The paper acknowledges GE work that has used novelty and domain knowledge to improve synthesis, but the CBGP experiments deliberately do not adopt novelty-based measures; thus GE is only a comparative reference here.",
            "uuid": "e1600.4",
            "source_info": {
                "paper_title": "Functional Code Building Genetic Programming",
                "publication_date_yy_mm": "2022-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Program Synthesis Using Uniform Mutation by Addition and Deletion",
            "rating": 2,
            "sanitized_title": "program_synthesis_using_uniform_mutation_by_addition_and_deletion"
        },
        {
            "paper_title": "The Push3 execution stack and the evolution of control",
            "rating": 2,
            "sanitized_title": "the_push3_execution_stack_and_the_evolution_of_control"
        },
        {
            "paper_title": "Code building genetic programming",
            "rating": 2,
            "sanitized_title": "code_building_genetic_programming"
        },
        {
            "paper_title": "A Grammar Design Pattern for Arbitrary Program Synthesis Problems in Genetic Programming",
            "rating": 2,
            "sanitized_title": "a_grammar_design_pattern_for_arbitrary_program_synthesis_problems_in_genetic_programming"
        },
        {
            "paper_title": "On Domain Knowledge and Novelty to Improve Program Synthesis Performance with Grammatical Evolution",
            "rating": 2,
            "sanitized_title": "on_domain_knowledge_and_novelty_to_improve_program_synthesis_performance_with_grammatical_evolution"
        },
        {
            "paper_title": "Improving Generalization of Evolved Programs through Automatic Simplification",
            "rating": 1,
            "sanitized_title": "improving_generalization_of_evolved_programs_through_automatic_simplification"
        }
    ],
    "cost": 0.01492375,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Functional Code Building Genetic Programming
9 Jun 2022</p>
<p>Edward Pantridge 
Swoop Cambridge
MassachusettsUSA</p>
<p>Functional Code Building Genetic Programming
9 Jun 2022DED2D5D46C9FE79E577B6F2CDD5A010210.1145/3512290.3528866arXiv:2206.04561v1[cs.AI]automatic programminggenetic programminginductive program synthesis
General program synthesis has become an important application area for genetic programming (GP), and for artificial intelligence more generally.Code Building Genetic Programming (CBGP) is a recently introduced GP method for general program synthesis that leverages reflection and first class specifications to support the evolution of programs that may use arbitrary data types, polymorphism, and functions drawn from existing codebases.However, neither a formal description nor a thorough benchmarking of CBGP have yet been reported.In this work, we formalize the method of CBGP using algorithms from type theory.Specially, we show that a functional programming language and a Hindley-Milner type system can be used to evolve type-safe programs using the process abstractly described in the original CBGP paper.Furthermore, we perform a comprehensive analysis of the search performance of this functional variant of CBGP compared to other contemporary GP program synthesis methods.CCS CONCEPTS• Software and its engineering → Genetic programming.</p>
<p>INTRODUCTION</p>
<p>A variety of genetic programming (GP) methods have been developed for general program synthesis applications, in which the goal is to automatically produce programs of the kind that humans routinely write [25].Such programs usually make use of a range of data and control structures.</p>
<p>Among the most successful recent approaches are those using a multi-type stack-based language called Push [12,26] and those rooted in the use of grammars, such as Grammatical Evolution (GE) [14] and Grammar Guided Genetic Programming (G3P) [5,6].</p>
<p>In the Push approach, evolved programs are expressed in a novel language that was designed to allow for the use of arbitrary data and control structures without imposing constraints on program syntax.This is accomplished by arranging for the passing of arguments between instructions to take place via typed data stacks.The result is that Push programs (or, more commonly, linear "plushy" genomes that map in a straightforward way to Push programs) can be freely mutated and crossed over without risking syntax or execution errors, even when multiple types, conditionals, loops, and more sophisticated data and control structures are being used [18].</p>
<p>PushGP systems-GP systems that evolve Push programs-have produced some of the best general program synthesis results to date, but the interactions between Push programs, human programming practices, and human-written codebases leave something to be desired.For example, although it is possible to "wrap" arbitrary functions as Push instructions that can then be used in evolved Push programs, this is a cumbersome, manual process that becomes impossible with the introduction of polymorphic types and functions.If one wants to use an evolved Push program in software that is written in a conventional programming language, then one either has to translate the evolved Push program into the conventional language or to include a Push interpreter in the software.Because is difficult for humans to read, understand, debug, or modify Push programs, translation is not always straightforward, and inclusion of evolved Push programs in production software may raise quality and reliability concerns.</p>
<p>By contrast, grammar-based approaches support general program synthesis by embracing the syntactic specification of data and control structures, and by employing methods that always generate syntactically valid programs in a conventional programming language.This provides a better interface to human programming practices and codebases.However, polymorphism is still problematic because grammars do not fully capture type information, which limits the possibly of real-world applications.In addition, these methods do not yet appear to be able to solve benchmark software synthesis problems quite as reliably as PushGP.</p>
<p>Code building genetic programming (CBGP) is a recently developed method that takes some inspiration from both of these approaches.It uses linear genomes that are similar to PushGP's plushy genomes, and which are compiled in a manner similar to Push program execution [18].With CBGP, however, this compilation process produces code in a conventional programming language, which can be read and understood by humans, and which can also make use of arbitrary (and possibly polymorphic) functions.As noted in the original CBGP paper [19], this appears to provide benefits both in terms of problem-solving power and potential for interaction with human programming practices.</p>
<p>The original CBGP paper, however, was a preliminary report, which provided neither a formal description of the algorithm nor a thorough benchmarking of CBGP relative to other methods.In this paper we fill those gaps.We formalize CBGP using a functional, Hindley-Milner type system, and we describe our new functional CBGP system on the basis of this formalization.We then perform a comprehensive analysis of the search performance of this system, comparing it to other contemporary GP program synthesis methods.</p>
<p>In the next section we review the results demonstrated in the original CBGP paper and flesh out the goals for the present work.</p>
<p>In the subsequent section we present tools from type theory that we will use in our formalization.We then present functional CBGP in detail.This is followed by a section on the design of our experiments, and then by a section on our experimental results.We conclude with a discussion of the implications of our results and of avenues for future work.</p>
<p>CODE BUILDING GENETIC PROGRAMMING</p>
<p>CBGP is a method of evolving programs using a stack-based compiler which folds variable length, linear, genomes into type-safe abstract syntax trees (AST).The introduction of CBGP in 2020 included demonstrations of novel capabilities such as:</p>
<p>• Type safe programs that call polymorphic functions.</p>
<p>• Anonymous functions defined inside evolved programs.</p>
<p>• Higher order functions for control flow.</p>
<p>• Use of user-defined data types, such as classes.</p>
<p>• Dynamic generation of the function set (aka genetic source [11]).</p>
<p>In addition, the evolved programs are generated as source code in a conventional programming language, a feature which was previously only possible using grammar based GP methods.These features were demonstrated on a small set of simple benchmark problems [19].This paper focuses on a subset of these capabilities and aims to clarify and standardize the implementation by leveraging properties of functional programming and type theory.In particular, the functional CBGP system described in this paper uses parametric polymorphism, anonymous function creation, and higher order functions.We only consider a finite set of data types common to other GP program synthesis systems such as PushGP, GE, and G3P.Also, the function set used in this version of CBGP was manually implemented and curated to be as similar as possible to the function sets found in other contemporary GP program synthesis systems.</p>
<p>The "host language" of a program synthesis system is the language in which synthesized programs are expressed.The version of CBGP proposed in this paper requires a functional programming language, and Clojure was selected because the LISP syntax makes it trivial to convert ASTs into source code and vice versa.The choice of host language is an implementation decision and the algorithms detailed in this paper are applicable to any functional host language.</p>
<p>TOOLS FROM TYPE THEORY</p>
<p>Since the invention of simply typed lambda calculus by Church in 1940, the field of type theory has been developing algorithms for analyzing the validity of functional programs based solely on their structure [2].One relatively modern manifestation of these ideas is the Hindley-Milner (HM) type system, which is commonly used by compilers of modern functional programming languages [15,17].It analyses programs represented as abstract syntax trees (AST) to prove the program is type safe.Furthermore, the HM system can provide the (possibly polymorphic) data type returned by the AST.We briefly describe the kinds of AST expressions the HM type system can analyze in the following paragraphs.</p>
<p>The atomic expressions, or leaves of the ASTs, are literals (aka constants) and variables.A variable is a symbol that will be translated into a known value when the program is executed.It is assumed the data type of a literal is trivially known and the data type of a variable is given by a mapping called the "type environment" denoted as Γ.</p>
<p>Larger expression trees can be created by composing literals and variables with function abstraction, function application, and let binding expressions.A function abstraction expression denotes the creation of a function with some fresh (new and unique) variables as arguments and an expression tree representing the body.A function application expression denotes the calling of a function on some arguments, each given by a child expression.A let binding expression defines a local variable which will take the value of a given child expression.</p>
<p>Figure 1a and 1b show the source code and AST of an example program that the HM type system is capable of analysing.</p>
<p>Types</p>
<p>The primitive, atomic, types in the HM system are called "ground" types.The set of ground types typically includes: , , , ℎ , and although there is some variation between implementations.In our work, we consider a ground type.A type constructor is an operator that builds a type from one or more other types.Collection types such as , , and are type constructors that must be provided the data type of their elements to build the full type.For example, we denote a set of strings as [ ].The function type constructor takes one or more argument types and a return type.For example, the function type of the string length function is ( ) → .The Hindley-Milner type system supports abstract types using a form of parametric polymorphism called type "schemes" [3,15].The canonical example of a type scheme is the identity function.The argument type of the identity function can be any type, but the return type will always match the argument type.The type of the identity function is ∀ .→ which is read as "for all possible types , the function type from to ".</p>
<p>A more complex example is the polymorphic type of the map higher order function.</p>
<p>∀ , .(( → ), [ ]) → [ ]</p>
<p>We read this as: "For all possible types and , a function which takes a function from to and a sequence of and returns a Python f = lambda x : max ( 0 , x ) map ( f , i n p u t )</p>
<p>Haskell  1c.
l e t f = \ x −&gt; max 0 x i n map f i n p u t LISP (Clojure) ( l e t [ f ( f n [ x ] ( max 0 x ) ) ] ( map f i n p u t ) )(
sequence of ." The parameters of a scheme are referred to as "type variables".In the examples above, and are type variables.</p>
<p>Unification</p>
<p>The Hindley-Milner type system is often used by compilers and code analyzers to perform type checking and type inference of abstract syntax trees.A crucial component of these algorithms is unification; a procedure which produces a set of type substitutions that will bind free type variables to concrete types, if possible.Unification has roots in theorem proving and solving systems of symbolic equations [16,22].</p>
<p>To illustrate the use of unification, suppose we have a function, , with the type ∀ .([ ]) → , and an expression, , of type [ ].To determine if a type safe expression can be created by applying to , we unify the argument type of with the type of .The unification algorithm will succeed and provide the substitution :=</p>
<p>. Using this, we can replace all instances of with in the type of the new composite expression to determine that ( ) has type .If the unification of two types requires a type variable be bound to more than one concrete type, or if unification requires two different non-variable types to be the same, for example = , the AST fails type checking.</p>
<p>FUNCTIONAL CODE BUILDING GP</p>
<p>In this section, we describe how functional CBGP uses HM types, schemes, and unification to produce type safe programs during evolution. 1</p>
<p>Genomes</p>
<p>CBGP uses a variable length linear genome, which is translated into a type-safe AST using a compilation process.Specifically, the plushy genome structure commonly used in PushGP systems is used in CBGP [18].The categories of genes that can be in a genome sequence are: literals, variables, local variables, stack instructions, and structure tokens. 1 The source code for our implementation is available at https://github.com/erp12/cbgp-lite.  Literal and variable expressions (as described in Section 3), as well as local variable genes, correspond to the production of leaves in the resulting ASTs.Local variable genes contain a baked-in index (natural number) value that will resolve to a variable during the compilation process, as discussed below.</p>
<p>The stack instruction genes affect the construction of the internal nodes of the compiled ASTs.In contrast to PushGP, only a small set of stack instructions are required to implement CBGP.Each stack instruction corresponds one of the non-leaf expression types of ASTs described in Section 3. Specifically, the full set of stack instruction gene types is: APP, ABS, and LET.The APP gene produces a new subtree for function application, and the LET gene produces a new subtree for local variable binding.Function abstraction genes are annotated with the data type of the function's arguments.For example, the ABS[Int] gene will attempt to compile an AST that creates a single-argument function with the argument type of .This is a distinct gene from ABS[Int,String].The ABS[] gene denotes a zero-argument function.</p>
<p>The "structure tokens" of plushy genomes can be either an open or close gene.These denote the start and end of nested "chunks" of genome, which are leveraged by the compilation process discussed in Section 4.2.Using the plushy translation algorithm, the linear genomes are transformed into nested sequences such that slices of genome between corresponding open and close tokens are included in a nested sequence.This translation process is robust to unbalanced numbers of open and close genes [18].</p>
<p>The initial population's genomes are generated using random sampling of a set of possible genes known as the genetic source [11].The sampling is weighted according to a target distribution of gene categories given in Table 1.1: The distribution of gene categories for randomly generated genes and genomes, which is used to create the initial population and supply genes for mutation operators.Some literal genes are sampled from a discrete set dependent on the problem, while others were created via ephemeral random constant (ERC) generators [20].This distribution was selected on the basis of human intuition and is potentially sub-optimal.</p>
<p>Gene Category</p>
<p>Compilation to AST</p>
<p>Linear genomes are translated into nested sequences prior to compilation.These nested sequences are referred to as push sequences because they are compiled using stacks by a process similar to the program execution model of PushGP systems.There are 2 stacks involved in compilation, one for typed ASTs and one for push subsequences called "chunks".</p>
<p>In addition to a push sequence, the compilation algorithm requires the type signature of the target program and a type environment containing the data types of each non-local variable.The type signature has 3 components: the return type, argument names, and argument types of the target program.Argument names are stored in an indexed collection of "local" variable names.Argument types are implicitly added to the type environment.</p>
<p>The compilation algorithm considers the elements of the push sequence one at a time and manipulates the stacks according to the kind of element.When literal or variable expressions are encountered, they are pushed to the AST stack because they are valid, single-node, ASTs.Local variable genes, represented as an index, are resolved to a valid variable by looking up the variable name at position
( , | |)
where is the index provided by the gene and is the set of local variables names containing, at least, the program's inputs.This is done because the full set of local variables that are "in-scope" at any particular point of compilation is not known ahead of time.The resulting variable expression is pushed to the AST stack.</p>
<p>When an function application instruction, APP, is encountered the AST stack is searched from top to bottom to find an AST with a function type.This could be a variable that corresponds to a function (such as ℎ, +, and ) or an AST corresponding to a function abstraction expression.If no function type AST is found, the APP instruction is a noop.The compilation algorithm will then search for a collection of ASTs from the stack to use as arguments to the function AST.These argument ASTs must return a type compatible with the function's argument types.The search algorithm in Figure 3  2 ← ( , )
5: ← ( ( , ), 2 ) 6:
← ( , )</p>
<p>7:</p>
<p>if ≠ then
8: ← ( 2 , .) 9:
← ( , )</p>
<p>10:</p>
<p>end if 11: end for 12: return Figure 3: The algorithm for finding ASTs which will be typesafe arguments to the function being applied by the APP stack instruction.The result is a list of ASTs with values in the positions where no AST of a compatible type was found on the stack.find an AST for any argument, the APP instruction is a noop.Otherwise, the function AST and all argument ASTs are removed from the AST stack and a new composite AST with an APP root node is pushed on top of the AST stack.</p>
<p>If the function type of the function AST selected by the APP instruction is polymorphic (has a type scheme with a type variable), the call to the unification algorithm (Figure 3, line 8) will bind the free type variables to the concrete type of the argument AST.These bindings are substituted in later argument types (Figure 3, line 4) to ensure that all instances of the type variable are bound to the same type.For example, when compiling an APP with the function with type ∀ .([ ], ) → [ ], the first argument can be satisfied by any sequence type.If the top-most AST with a sequence type has the type [ ] then will be bound to which will become the second argument type of this particular application of .When a nested push sequence is encountered, it is pushed to the chunk stack.Function abstraction instructions and LET instructions use these chunks to compile a body of code that may reference the local variables created by those constructs, as described below.</p>
<p>When a function abstraction instruction (ie.ABS[Int]) is encountered new local variables are created to serve as the function's argument variables.No elements of the AST stack contain references to these new arguments names.The body of the function must be compiled from a push sequence within a new scope, or environment, that includes the new argument variables.To compile the body of the new function, the compilation algorithm makes a recursive call to itself with a new environment based on the ABS instruction's argument types and passes a push sequence from the chunk stack.During this nested call, local variable genes may resolve to one of the new local variables included in the environment.If the recursive compilation call does not produce any ASTs, for example if the chunk is empty or does not contain any leaf nodes from which to build ASTs, subsequent items of the chunk stack are</p>
<p>Require:</p>
<p>← the ABS instruction Require:</p>
<p>← the AST stack Require: ℎ ← the Push chunk stack Require:</p>
<p>← the list of local variables Require: Γ ← the type environment
1: ′ ← 2: Γ ′ ← Γ 3: ← [] 4: for all ← . do 5: ← ℎ () 6: ← ( ,) 7:
′ ← ( ′ , )</p>
<p>8:
Γ ′ ← (Γ ′ , [ := ]) 9: end for 10: for all ℎ ← ℎ do 11: ← ( ℎ , ′ , Γ ′ ) 12: if ≠ then 13:
return ( , ))</p>
<p>14:</p>
<p>end if 15: end for 16: return Figure 4: The algorithm for compiling a function abstraction stack instruction.The result is an AST which with a ABS expression as the root.The type of AST is a function type with the argument types from the stack instruction and a return type determined by the type of the "body" expression compiled from the chunk.compiled until an AST is found or no chunks remain on the stack.The latter scenario triggers the ABS instruction to noop. Figure 4 details the process of compiling a function abstraction expression in pseudocode.</p>
<p>When a let instruction is encountered, it is compiled similarly to a function abstraction instruction.A new local variable is created and the AST on top of the stack is used as its definition, which also determines its type.A push sequence from the chunk stack is then compiled with the new variable added to the set of local variables and the type environment.The AST resulting from the chunk compilation is used as the body of the let expression.</p>
<p>After all elements of the push sequence have been compiled, the AST stack will be a collection of type-safe ASTs that can be evaluated as programs.To select the single AST associated with the compiled genome, the top-most AST with a data type matching the target program's return type is selected.</p>
<p>Figure 2 shows one possible genome that compiles to the solution of the negative-to-zero problem shown in Figure 1.The slice of genome between the first pair of OPEN and CLOSE genes will be saved as chunk that will compile into a function body when the ABS[Int] stack instruction is processed.The first LocalVar(1) gene will resolve to the argument of the anonymous function created by ABS [Int].The AST created by ABS[Int] will become the definition of the local variable produced by the LET at the end of the genome.The slice of genome between the second pair of OPEN and CLOSE genes will be saved as a chunk that is compiled into the body of the LET expression, and the second LocalVar(1) will resolve to the local variable defined by the LET.Notice that the LET expression is the root node of the AST (and the root symbol of the Clojure code in Figure 1a), therefore it is the last gene in the genome.</p>
<p>The genome in Figure 2 is artificially simple for demonstration purposes.During evolution, most genomes are much longer and contain genes that either noop or build additional ASTs which do not get selected as the program because they do not return the correct data type for the problem or are buried deep in the stack at the end of compilation.</p>
<p>Evolution</p>
<p>For this work, a standard generational genetic algorithm was used to evolve programs.An initial population of random genomes was produced using the method described in Section 4.1.Genomes are compiled into a type-safe ASTs (Section 4.2) which are executed identically to a native function in the host language.These programs are evaluated based on a set of training cases in the form of input-output pairs.The program's error on each training case is determined by a user provided error function.The collection of errors across all training cases is referred to as an individual's "error vector".If no AST with the problem's target return type is produced after compilation the individual is given a penalty error on every training case.If the compiled AST produces a runtime error, such as "index out of bounds, " when called on a training case, it is given a penalty error.</p>
<p>Parents are selected from the population of evaluated individuals on the basis of error vectors using Lexicase Selection [10,13].The next generation of genomes is produced through variation of parent genomes.</p>
<p>If a individual is found to have an error of zero on all training cases, or if the maximum number of generations is reached, evolution is stopped and the individual with the lowest total error, given by the sum of its error vector, is returned.If this individual has a total error of zero, it is called a "solution."</p>
<p>Simplification</p>
<p>The best individual found during evolution is extracted for simplification.It has been shown that simplification acts as a form of regularization which improves the program's generalizability to unseen data cases [8].In addition, a simplified program may be easier for a human to understand.The best individual from evolution is simplified using a hill-climbing algorithm, as follows:</p>
<p>( The best individual's program after all iterations of simplification is reported as the output of the evolutionary search.For our experiments, this is the program that is tested for generalization on an unseen set of test cases.</p>
<p>EXPERIMENTAL DESIGN</p>
<p>We assess the ability of CBGP to perform automatic program synthesis using a subset of 14 problems from the program synthesis benchmark suite PSB1 [12].The problems in PSB1 originate from introductory computer science textbooks, allowing us to assess how the system performs on the types of programming problems we ask new programmers to solve.We chose 14 problems that represent a wide range of requirements, such as data types and control flow, and difficulties.We purposefully avoided some problems that have typically been most difficult for other GP techniques and we have not yet benchmarked CBGP using the more recent (and difficult) problems of the suite PSB2 [7], since this is CBGP's first benchmarking (and easier problems seem warranted) and because there is more data available for comparing CBGP with other program synthesis systems.However, assessing performance on PSB2 soon would supplement our experiments here.</p>
<p>Each problem is specified by a set of input/output examples defining the desired behavior of the program, in the form of supervised learning.Each run uses 100 training cases composed of handcoded examples and a subset of a large set of randomly-generated inputs.Additionally, we use a set of 300 additional random examples to test each program that passes the training set for generalization; only those programs that perfectly pass all 300 examples are reported as solutions.The error functions used to measure the differences between program outputs and correct outputs are the same ones described in PSB1 [12].</p>
<p>We conduct 100 runs of CBGP per problem, and primarily report the success rate for each problem as measured by generalizing solutions.The generational genetic algorithm was configured with the hyperparameters given in Table 2.This configuration was selected due to its similarity to the configuration of PushGP in published results on the same set of benchmark problems.We leave the optimization of this configuration to future research.</p>
<p>With an aim to enhancing comparability between systems, we created a genetic source (function set) that largely matches that used in the comparison PushGP runs [9,12].However, due to representational differences, there is not a one-to-one match between the genetic sources.The functions handling data operations are largely the same, but control flow is handled quite differently in CBGP with a functional host language compared to Push or the grammar-based programs of G3P and GE.In particular, much of the control flow in this implementation of CBGP is handled by higher-order functions that iterate over lists, such as map, filter, and reduce.</p>
<p>The description of the problems in PSB1 recommends not using every single available function for every problem [11,12].For example, including functions that manipulate strings when solving a problem that only relates to lists of integers would expand the search space unnecessarily.As such, we follow these recommendations by creating type-tuned genetic sources for each problem in the fashion recommended by PSB1: for each problem, only include functions that manipulate the data types deemed relevant by PSB1.This ensures that we do not cherry-pick instructions known to be useful for a problem, while not including instructions that have no bearing on it.</p>
<p>Comparison Methods</p>
<p>We compare our CBGP results with those of other GP representations: PushGP, G3P, and GE.We choose comparison results from papers using comparable evolutionary hyperparameters as much as possible.</p>
<p>For PushGP, we use results from the paper introducing Uniform Mutation by Additions and Deletions (UMAD) [9].Like this paper, our CBGP runs use UMAD as the only genetic operator, making a reasonable comparison.</p>
<p>We use the paper introducing grammar design patterns as the results for G3P [5].The paper uses similarly type-tuned grammars to determine the instructions available to evolving programs.</p>
<p>Our reported GE results are taken from a paper exploring the use of domain knowledge and novelty in program synthesis [14].Since neither of those ideas are used in our work here, we use the baseline control results reported in the paper.</p>
<p>RESULTS</p>
<p>Table 3 compares the success rates of CBGP to other GP representations on the 14 benchmark problems.CBGP performs quite well on 7 of the problems, producing success rates near or at 100.On all of these problems except number-io, at least one of the other methods performs significantly worse than CBGP.On the other hand, CBGP performs significantly worse than at least one other method on the last 6 problems.</p>
<p>The last column in Table 3 gives the proportion of solutions on the training data that perfectly generalize to the unseen test set.Compared to the other three GP representations, which have typically produced low generalization rates on some, but not all, of these problems, the generalization rate of CBGP solutions is quite high across the board.For example, compare-string-lengths, last-index-of-zero, median, and negative-to-zero all produced generalization rates lower than 0.75, while almost no problem exhibited a generalization rate of 1.0, in a study of generalization using PushGP [8].  4 presents the sizes of solution programs found for each problem solved by CBGP.Program size is measured in number of nodes in the Clojure S-expression representation of the program, which is identical to the number of nodes in the AST.We find that three of these problems have been solved by programs containing only 4 nodes, while the remainder have been solved by programs with 10 or fewer nodes.Interestingly, the mean solution sizes preand post-simplification tend to be quite close to the minimum sizes.This means that evolved solutions rarely have unnecessary code in the programs themselves.Note that genomes, on the other hand, may have lots of unnecessary genes that either produce unused ASTs or have no effect on AST compilation.It seems that removing such unnecessary genes during simplification does not result in dramatically simpler programs, as the mean post-simplification program size is not much smaller than pre-simplification.</p>
<p>Generalized</p>
<p>Example Solution Programs</p>
<p>The supplementary materials to this paper include a file containing every solution evolved by CBGP.In Figure 5 we give some examples of those solution programs and note some of their interesting features below.</p>
<p>The solution to negative-to-zero interestingly maps the subtract function over two copies of the input vector, which produces a vector entirely made of zeros.It then maps the max function over the zeros and the input vector, changing every negative integer into 0 as required.</p>
<p>The vector-average solution behaves as expected.One thing to note is that it converts the length of the input vector to a , since the count function is typed to return an .Future work into allowing for subtyping or type classes could allow for all expressions to be considered valid expressions, but for now, the conversion must happen explicitly.</p>
<p>The smallest problem requires the program to find the minimum of four inputs.Instead of simply applying the min function 3 times, this solution unnecessarily defines a new function that finds the min of input4 and its argument, and then applies that function to input1.</p>
<p>The last-index-of-zero problem requires the program to find the last index where 0 appears in the input list.This solution reverses the input, finds the first index of zero, and then subtracts that from the decremented length of the input.This strategy is similar to some solutions to this problem that have been evolved in PushGP.</p>
<p>DISCUSSION AND FUTURE WORK</p>
<p>CBGP has demonstrated that it can readily find solutions to some problems, but on others the solution rate of CBGP quickly drops to zero.These trends correlate somewhat to the problems found difficult by other GP representations; however, there are some problems that CBGP solves readily that others do not and vice versa.
) input1)) input2)) (defn last-index-of-zero [input1] (-(count (butlast input1)) (index-of (reverse input1) 0)))
Figure 5: A sample of solution Clojure programs evolved by CBGP.Anonymous function argument symbols were generated using a unique natural number prefixed with an a-.</p>
<p>Whitespace was adjusted for readability.</p>
<p>When initially tested on the PSB1 benchmark problems, the other genetic programming systems saw similar trends, and have since increased performance as the methods mature through continued research.We hope to see a similar rise in the search performance of CBGP in the future.The large variety in which problems each system finds easier or harder points to the importance of program representation for search performance.This area is not well understood in GP, and we hope that CBGP can help better illuminate important differences in representation.We suggest this as an area of future research such that we can understand what makes problems difficult under a given representation.</p>
<p>One hypothesis regarding different representations producing wildly different results on some problems is the impact of representations on the size of programs needed to form a particular computation.Solutions to problems with high solution rates tend to be smaller than solutions to problems with a low success rate, regardless of representation.The problems that CBGP solves most readily have small solution programs, and similar results have been shown for PushGP on the same problems [12].We do not know if similarly small solution programs are possible for the problems that CBGP did not solve, and it simply did not find them, or if they require larger programs and therefore are more difficult to find in the search space.Further research into CBGP solutions to these problems could help us understand whether it is simply the size of the solution programs preventing them from being solved, or whether CBGP has issues traversing the search space effectively regardless of solution size for some problems.</p>
<p>The exceptionally high generalization rate of CBGP is not easily explained.When considered in combination with the inability to find solutions on harder problems, this may be an indication that CBGP cannot fall back on memorizing or bloating the program into something that overfits the training data.In CBGP, an increase in genome size does not necessarily cause an increase in program size because additional genes may simply result in more ASTs being left on the stack after compilation, rather than larger ASTs.This hypothesis is further supported by the minimum and average program sizes of solutions found by CBG.The problems with high solution (and generalization) rates are solved by small programs.</p>
<p>When looking through solution programs, we found very few instances of programs that define and use anonymous functions effectively.Defining such functions is an integral part of functional programming for human programmers.Thus one piece of important future work is to try to assess why CBGP is not making use of function definition, and considering ways to encourage this behavior.</p>
<p>One insight from this research that may be helpful to the wider research fields of genetic programming and program synthesis is the value of introducing formalisms, such as type theory, into our systems.The body of work accumulated in fields of theoretical computation provide the program synthesis community with tools to guide synthesis towards programs with desirable properties, such as type safety.</p>
<p>Functional CBGP can, in theory, represent programs using any data type or language construct supported by the type system, and the unification algorithm in particular.A valuable direction of future research is to implement the common extensions to the Hindley-Milner type system which add support for function overloading, sub-types, and variadic functions [1,4,21,23].The primary benefit of these extensions would be the ability to represent programs using all the features of a modern functional programming language and possibly approach any programming task that can be well-specified by types.Another benefit of supporting additional kinds of polymorphism is the ability to use a smaller genetic source with considerably fewer, more general, functions which could dramatically reduce the search space and improve solution rates on complex problems.</p>
<p>CONCLUSION</p>
<p>In this paper we present functional Code Building Genetic Programming and show how it leverages type theory to ensure synthesized programs are type safe while also allowing polymorphic functions, anonymous functions, and higher order functions to be expressed.We report on empirical benchmarks that show CBGP can find solution programs more consistently than other contemporary GP methods on some problem, while it struggles to find any solutions on others.Investigations into solution programs show repeated use of polymorphic functions and higher order functions, but little use of anonymous function definitions.</p>
<p>When CBGP does find a solution on training data, we observe an exceedingly high rate of generalization to unseen test data.This phenomenon is in contrast to the comparatively low generalization rates of all other GP systems included in our comparison [5,8,24].Furthermore, the solution programs found by CBGP are small, even without the use of typical genome simplification techniques.</p>
<p>Finally, we direct future research towards a deeper utilization of type theory in general program synthesis systems.We also suggest the genetic programming field perform broader studies into the impact of representation on problem difficulty.</p>
<p>[</p>
<p>OPEN, LocalVar(1), Literal(0), Var(max), APP, CLOSE, ABS[Int], OPEN, Var(input), LocalVar(1), Var(map), APP, CLOSE, LET]</p>
<p>Figure 2 :
2
Figure 2: One possible genome which compiles to the AST shown Figure 1b under the type environment in Figure 1c.</p>
<p>3 :
3
is used to find argument ASTs.If the algorithm fails to Require: ←the AST stack Require: ← the function AST for all ← .do 4:</p>
<p>(</p>
<p>defn negative-to-zero [input1] (map max (map -input1 input1) input1)) (defn vector-average [input1] (safe-div (reduce + input1) (float (count input1)))) (defn smallest [input1 input2 input3 input4] (min (min input3 ((fn [a-639347] (min input4 a-639347)</p>
<p>An example program which solves the negative-to-zero benchmark problem.The HM type system is able to prove that this program is type safe and will return a [ ] given the variable types provided by the environment in Figure
LETfABSAPPVarTypexAPPmapfinputinputSeq[Int]max0 : Intxmax map∀ , .(( → ),(Int, Int) → Int [ ]) → <a href="b"> </a> The abstract syntax tree of the program.(c) The type environment used to prove the typeABS denotes function abstraction and APPsafety of the AST. Notice that the types of locala) The source code in a variety of lan-denotes function application. Literals arevariables, and , are not required because theyguages.tagged with their data type.can be inferred.Figure 1:</p>
<p>Table
ProportionVariable0.2Local Variable0.15Literal0.15Literal (via ERC)0.1Abstraction0.15Application0.15Open &amp; Close0.1</p>
<p>Table 2 :
2
The evolutionary hyperparameters used for all runs of CBGP associated with the results presented in this paper.
1) Create a new genome using an order-preserving randomsubset of the best individual's genome.(2) Compile and evaluate the new genome to create a new indi-vidual.(3) If the total error of the new individual is equal to, or lowerthan, the current best individual it replaces the best individ-ual.(4) If iteration limit is reached, return best individual. Other-wise, return to step 1.</p>
<p>Table 3 :
3
Percentage of runs that found a generalized solution on each problem.Underlined values indicate the comparison method has a statistically significantly worse solution rate than CBGP according to a chi-squared test with at a p-value of 0.05.Values in bold indicate a statistically significantly better success rate using the same test.The generalization rate column denotes the proportion of runs for which the program which solved all training cases also solved the unseen test data.
Solution RateGeneralization</p>
<p>Table 4 :
4
Solution sizes for each problem that CBGP solved.Min gives the minimum size of any solution program, while Pre and Post give the mean sizes before and after applying automatic simplification to the solution genomes.
ProblemMinPre Postsmallest77.557.18mirror-image44.544.06number-io44.924.03vectors-summed44.254.00negative-to-zero77.907.02median9 10.52 10.03vector-average79.748.89compare-string-lengths10 12.34 11.79last-index-of-zero8 12.42 10.33Table
ACKNOWLEDGMENTSThis material is based upon work supported by the National Science Foundation under Grant No. 1617087.Any opinions, findings, and conclusions or recommendations expressed in this publication are those of the authors and do not necessarily reflect the views of the National Science Foundation.
An Extension of System F with Subtyping. L Cardelli, S Martini, J C Mitchell, A Scedrov, 10.1006/inco.1994.1013Information and Computation. 1091994. 1994</p>
<p>A Formulation of the Simple Theory of Types. Alonzo Church, The Journal of Symbolic Logic. 51940. 1940</p>
<p>Principal type-schemes for functional programs. Luis Damas, Robin Milner, Proceedings of the 9th ACM SIGPLAN-SIGACT symposium on Principles of programming languages. the 9th ACM SIGPLAN-SIGACT symposium on Principles of programming languages1982</p>
<p>Polymorphism, Subtyping, and Type Inference in MLsub. Stephen Dolan, Alan Mycroft, 10.1145/3093333.3009882SIGPLAN Not. 522017. jan 2017</p>
<p>A Grammar Design Pattern for Arbitrary Program Synthesis Problems in Genetic Programming. Stefan Forstenlechner, David Fagan, Miguel Nicolau, O' Michael, Neill, 10.1007/978-3-319-55696-3_17Proceedings of the 20th European Conference on Genetic Programming. the 20th European Conference on Genetic ProgrammingAmsterdamSpringer Verlag2017. 201710196</p>
<p>Extending Program Synthesis Grammars for Grammar-Guided Genetic Programming. Stefan Forstenlechner, David Fagan, Miguel Nicolau, O' Michael, Neill, Parallel Problem Solving from Nature -PPSN XV. ChamSpringer International Publishing2018</p>
<p>PSB2: The Second Program Synthesis Benchmark Suite. Thomas Helmuth, Peter Kelly, 10.1145/3449639.34592852021 Genetic and Evolutionary Computation Conference (GECCO '21). Lille, FranceACM2021</p>
<p>Improving Generalization of Evolved Programs through Automatic Simplification. Thomas Helmuth, Nicholas Freitag Mcphee, Edward Pantridge, Lee Spector, 10.1145/3071178.3071330Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceBerlin, Germany; New York, NY, USAAssociation for Computing Machinery2017</p>
<p>Program Synthesis Using Uniform Mutation by Addition and Deletion. Thomas Helmuth, Nicholas Freitag Mcphee, Lee Spector, Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceKyoto, JapanGECCO2018</p>
<p>. 10.1145/3205455.3205603ACMNew York, NY, USA</p>
<p>Association for Computing Machinery. Thomas Helmuth, Edward Pantridge, Lee Spector, 10.1145/3321707.3321875Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferencePrague, Czech Republic; New York, NY, USA2019Lexicase Selection of Specialists</p>
<p>Genetic Source Sensitivity and Transfer Learning in Genetic Programming. Thomas Helmuth, Edward Pantridge, Grace Woolson, Lee Spector, 10.1162/isal_a_00326Artificial Life Conference Proceedings. MIT Press2020</p>
<p>General Program Synthesis Benchmark Suite. Thomas Helmuth, Lee Spector, 10.1145/2739480.2754769Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation. the 2015 Annual Conference on Genetic and Evolutionary ComputationMadrid, Spain; New York, NY, USA2015Association for Computing Machinery</p>
<p>Solving Uncompromising Problems with Lexicase Selection. Thomas Helmuth, Lee Spector, James Matheson, 10.1109/TEVC.2014.2362729IEEE Transactions on Evolutionary Computation. 192015. Oct. 2015</p>
<p>On Domain Knowledge and Novelty to Improve Program Synthesis Performance with Grammatical Evolution. Erik Hemberg, Jonathan Kelly, Una-May O' Reilly, 10.1145/3321707.3321865Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferencePrague, Czech Republic; New York, NY, USA2019Association for Computing Machinery</p>
<p>The principal type-scheme of an object in combinatory logic. Roger Hindley, Transactions of the american mathematical society. 1461969. 1969</p>
<p>An Efficient Unification Algorithm. Alberto Martelli, Ugo Montanari, 10.1145/357162.357169ACM Trans. Program. Lang. Syst. 421982. apr 1982</p>
<p>A theory of type polymorphism in programming. Robin Milner, 10.1016/0022-0000(78)90014-4J. Comput. System Sci. 171978. 1978</p>
<p>Comparison of Linear Genome Representations For Software Synthesis. Edward Pantridge, Thomas Helmuth, Lee Spector, ; Xvii, Wolfgang Banzhaf, Erik Goodman, Leigh Sheneman, 10.1007/978-3-030-39958-0_13Genetic Programming Theory and Practice. Leonardo Trujillo, Bill Worzel, East Lansing, MI, USASpringer2019</p>
<p>Code building genetic programming. Edward Pantridge, Lee Spector, Proceedings of the 2020 Genetic and Evolutionary Computation Conference. the 2020 Genetic and Evolutionary Computation Conference2020</p>
<p>A field guide to genetic programming. Riccardo Poli, William B Langdon, Nicholas Freitag Mcphee, J. R. Koza2008</p>
<p>Type Inference in the Presence of Subtyping: from Theory to Practice. François Pottier, RR-3483. INRIA1998Research Report</p>
<p>A machine-oriented logic based on the resolution principle. John Alan, Robinson , Journal of the ACM (JACM). 121965. 1965</p>
<p>Polymorphic Type Inference for Languages with Overloading and Subtyping. Geoffrey Seward, Smith , GAX92- 04023Ph. D. Dissertation. USA. UMI Order. 1992</p>
<p>On the Generalizability of Programs Synthesized by Grammar-Guided Genetic Programming. Dominik Sobania, 10.1007/978-3-030-72812-0_9EuroGP 2021: Proceedings of the 24th European Conference on Genetic Programming. Ting Hu, Nuno Lourenco, Eric Medvet, Springer Verlag, Virtual Event202112691</p>
<p>Dominik Sobania, Dirk Schweim, Franz Rothlauf, arXiv:2108.12227Recent Developments in Program Synthesis with Evolutionary Algorithms. 2021. 2021arXiv preprint</p>
<p>The Push3 execution stack and the evolution of control. Lee Spector, Jon Klein, Maarten Keijzer, 10.1145/1068009.10682922005</p>            </div>
        </div>

    </div>
</body>
</html>