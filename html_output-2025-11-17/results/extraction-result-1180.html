<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1180 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1180</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1180</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-28.html">extraction-schema-28</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <p><strong>Paper ID:</strong> paper-220302018</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2007.00798v1.pdf" target="_blank">Deliberate Exploration Supports Navigation in Unfamiliar Worlds</a></p>
                <p><strong>Paper Abstract:</strong> To perform tasks well in a new domain, one must first know something about it. This paper reports on a robot controller for navigation through unfamiliar indoor worlds. Based on spatial affordances, it integrates planning with reactive heuristics. Before it addresses specific targets, however, the system deliberately explores for high-level connectivity and captures that data in a cognitive spatial model. Despite limited exploration time, planning in the resultant model is faster and better supports successful travel in a challenging, realistic space.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1180.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1180.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SemaFORR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SemaFORR robot controller</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An affordance-based robot navigation controller that integrates deliberative planning on a learned coarse topological skeleton with reactive commonsense heuristics (voted controllers); it uses an initial deliberate exploration phase (HLC) to build a passage-oriented spatial model used for A* planning over regions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>GCWorld</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>A realistic, built indoor environment (office/floor plan) with many jogs, interior posts, narrow doorways and rooms; domain: indoor robot navigation with a 0.8m-wide mobile robot (Freight).</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td>Narrow doorways and numerous doorway access points with unknown possibilities at each doorway; no locked/conditional doors are reported (constraints are geometric/narrowing rather than key-locked).</td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Sparse, passage-focused topology: a passage network (graph of labeled 1m×1m passage grid cells) where edges are added if robot traversed between cells or views labeled adjacent cells unobstructed; a coarser skeleton of circular regions (nodes) connected by edges indicating direct transitions between regions (edge labels include metric distance and crossing endpoints). The skeleton emphasizes high-connectivity thoroughfares (hallways) and omits most low-connectivity areas until experienced.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Skeleton averaged ~205 vertices and ~248 edges at end of a task; a fine-grained grid-based planning graph had ~85,000 vertices and ~170,000 edges; passage grid resolution is 1m × 1m.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>SemaFORR (and ablation SemaFORR-A)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Hybrid controller: (1) a deliberate exploration module (HLC) that discovers passages and builds a passage network and skeleton; (2) A* planning on the learned skeleton to generate waypoint sequences; (3) reactive heuristics (commonsense and model-based rules) whose votes guide execution when plans are occluded or sensors/actuators err. SemaFORR-A is an ablated variant that constructs the model gradually without initial HLC exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Coverage fraction of world footprint (1m×1m grid), exploration time (seconds), planning time per task (seconds), travel time and travel distance, percent of heuristic decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>Average initial exploration time (for SemaFORR) 1084.10 seconds; initial coverage after HLC 12.65%; final coverage after attempting all targets 27.94%; planning in skeleton averaged 3.56 seconds per task (vs ~15s for grid A* and ~60s for model-based A*); SemaFORR (tasks only) travel time 5608.93 s and distance 4610.87 m; SemaFORR (tasks + exploration) travel time 6693.02 s and distance 5769.50 m; SemaFORR-A travel time 8216.45 s and distance 5889.49 m; heuristic decision usage: SemaFORR 49.0% vs SemaFORR-A 63.8%.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>70.60%</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Hybrid planning-based policy over a coarse topological skeleton augmented with reactive heuristics (planning + reactive voting); initial deliberate exploration to build the topology improves planning reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Deliberate exploration that finds high-connectivity passages yields a compact skeleton that dramatically reduces planning graph size (≈205 nodes vs ≈85k grid nodes), speeds up planning (3.56s vs 15s or ~60s), increases success rate (70.6% vs 46.17% for the ablated system), and reduces task travel time and distance; conversely, missing detail in low-connectivity side-rooms/dead-ends causes failures and necessitates more heuristic-driven behavior. The planner prefers regions with high degree and proximity (score s = -5 * distance + degree), showing explicit use of local connectivity (degree) in endpoint selection.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Compared representations: the learned skeleton (coarse region graph) vs a detailed grid-based A* graph vs a model-based A* graph. The skeleton is several orders of magnitude smaller (≈205 nodes) and yields much faster planning and robust task performance; grid A* planning was ~15s and model-based A* ~60s per plan. Systems with no initial HLC exploration (SemaFORR-A) produced less effective models and worse success/time metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Policies that combine coarse topological planning (A* on skeleton) with reactive heuristics outperform largely reactive policies in this environment: SemaFORR relied less on heuristics (49%) than the ablated SemaFORR-A (63.8%). Incompleteness in topology (missing side rooms / dead-ends) increases reliance on heuristics and causes failures, indicating that environments with many dead-ends require policies with backtracking and mechanisms to incorporate newly observed local topology into planning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deliberate Exploration Supports Navigation in Unfamiliar Worlds', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1180.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1180.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HLC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>High-Level Connectivity (HLC) exploration algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A one-time, view-based, time-limited exploration procedure that detects stretches (candidate passages), labels passage grid cells, grows a passage network, and compiles a coarser skeleton of circular regions to capture long-range connectivity (hallways) for downstream planning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>GCWorld</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Same realistic indoor GCWorld used in experiments: multiple hallways, rooms, narrow doorways, posts and irregular obstacles; domain: indoor robot navigation (robot: Freight, laser rangefinder).</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td>Geometric/visibility constraints at doorways (narrow passages, variable visibility). No mention of locked or action-conditional doors.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>HLC builds a passage network (nodes = labeled 1m×1m passage cells) with edges formed by robot traversal or unobstructed adjacent views; from that it composes a skeleton of non-overlapping circular regions connected when the robot traversed directly between them. Connectivity emphasis is on long-range thoroughfares (passages/hallways); the skeleton captures major connectivity but omits many low-connectivity areas until experienced.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Passage grid uses 1m×1m cells; HLC initial coverage after 20 minutes was 12.65% of unobstructed footprint; HLC captured on average 82.88% of 8 principal hallways; final skeleton ~205 regions and ~248 edges on average.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>HLC (exploration module)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Heuristic, opportunistic decision process: actions are forward moves (six lengths) and rotations (four sizes). It detects 'stretches' (long thin unobstructed views, min length parameter d, used with d=7m), prioritizes candidates (larger/most recent first), labels passage grid cells via occupancy mapping (passes vs hits), explores until termination criteria (end-of-stretch, large reorientation >45°, or room detected), and uses BFS on the passage network to navigate to new candidate starts.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Coverage fraction of passage grid, percent of principal hallways detected, time-limited exploration (20 minutes or 750 decisions per candidate), lengths of candidate stretches, and resulting improvement in downstream planning time and success.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>Exploration capped at 20 minutes; average exploration time reported for SemaFORR overall 1084.10 s; initial coverage after HLC 12.65%; HLC covered on average 82.88% of 8 recognized hallways; candidate minimum stretch length used was 7 m; occupancy labeling uses 1m grid cells.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Deliberate, view-based exploration to generate a coarse topological map that supports planning-based downstream policies (i.e., exploration-first then planning).</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>HLC's prioritization of long, highly-connected stretches produces a skeleton that reduces planning graph size and increases planning speed and success; limited but focused exploration (targeting high-connectivity passages) yields high marginal benefit for navigation performance, while missing stretches (e.g., side rooms) can cause failures for specific targets.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>A topology produced by HLC favors a planning-first policy (A* on skeleton) with fallback reactive heuristics; when HLC fails to capture local low-connectivity areas (dead-ends/rooms), the policy must rely on heuristics and repeated attempts/experience to augment the skeleton.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deliberate Exploration Supports Navigation in Unfamiliar Worlds', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>From cognitive maps to cognitive graphs <em>(Rating: 2)</em></li>
                <li>Wormholes in virtual space: From cognitive maps to cognitive graphs <em>(Rating: 2)</em></li>
                <li>DD-PPO: Learning near-perfect pointgoal navigators from 2.5 billion frames <em>(Rating: 2)</em></li>
                <li>MINOS: Multimodal indoor simulator for navigation in complex environments <em>(Rating: 2)</em></li>
                <li>FastSLAM 2.0 <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1180",
    "paper_id": "paper-220302018",
    "extraction_schema_id": "extraction-schema-28",
    "extracted_data": [
        {
            "name_short": "SemaFORR",
            "name_full": "SemaFORR robot controller",
            "brief_description": "An affordance-based robot navigation controller that integrates deliberative planning on a learned coarse topological skeleton with reactive commonsense heuristics (voted controllers); it uses an initial deliberate exploration phase (HLC) to build a passage-oriented spatial model used for A* planning over regions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "GCWorld",
            "environment_description": "A realistic, built indoor environment (office/floor plan) with many jogs, interior posts, narrow doorways and rooms; domain: indoor robot navigation with a 0.8m-wide mobile robot (Freight).",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": true,
            "dead_ends_count": null,
            "door_constraints_present": true,
            "door_constraints_description": "Narrow doorways and numerous doorway access points with unknown possibilities at each doorway; no locked/conditional doors are reported (constraints are geometric/narrowing rather than key-locked).",
            "graph_connectivity": "Sparse, passage-focused topology: a passage network (graph of labeled 1m×1m passage grid cells) where edges are added if robot traversed between cells or views labeled adjacent cells unobstructed; a coarser skeleton of circular regions (nodes) connected by edges indicating direct transitions between regions (edge labels include metric distance and crossing endpoints). The skeleton emphasizes high-connectivity thoroughfares (hallways) and omits most low-connectivity areas until experienced.",
            "environment_size": "Skeleton averaged ~205 vertices and ~248 edges at end of a task; a fine-grained grid-based planning graph had ~85,000 vertices and ~170,000 edges; passage grid resolution is 1m × 1m.",
            "agent_name": "SemaFORR (and ablation SemaFORR-A)",
            "agent_description": "Hybrid controller: (1) a deliberate exploration module (HLC) that discovers passages and builds a passage network and skeleton; (2) A* planning on the learned skeleton to generate waypoint sequences; (3) reactive heuristics (commonsense and model-based rules) whose votes guide execution when plans are occluded or sensors/actuators err. SemaFORR-A is an ablated variant that constructs the model gradually without initial HLC exploration.",
            "exploration_efficiency_metric": "Coverage fraction of world footprint (1m×1m grid), exploration time (seconds), planning time per task (seconds), travel time and travel distance, percent of heuristic decisions.",
            "exploration_efficiency_value": "Average initial exploration time (for SemaFORR) 1084.10 seconds; initial coverage after HLC 12.65%; final coverage after attempting all targets 27.94%; planning in skeleton averaged 3.56 seconds per task (vs ~15s for grid A* and ~60s for model-based A*); SemaFORR (tasks only) travel time 5608.93 s and distance 4610.87 m; SemaFORR (tasks + exploration) travel time 6693.02 s and distance 5769.50 m; SemaFORR-A travel time 8216.45 s and distance 5889.49 m; heuristic decision usage: SemaFORR 49.0% vs SemaFORR-A 63.8%.",
            "success_rate": "70.60%",
            "optimal_policy_type": "Hybrid planning-based policy over a coarse topological skeleton augmented with reactive heuristics (planning + reactive voting); initial deliberate exploration to build the topology improves planning reliability.",
            "topology_performance_relationship": "Deliberate exploration that finds high-connectivity passages yields a compact skeleton that dramatically reduces planning graph size (≈205 nodes vs ≈85k grid nodes), speeds up planning (3.56s vs 15s or ~60s), increases success rate (70.6% vs 46.17% for the ablated system), and reduces task travel time and distance; conversely, missing detail in low-connectivity side-rooms/dead-ends causes failures and necessitates more heuristic-driven behavior. The planner prefers regions with high degree and proximity (score s = -5 * distance + degree), showing explicit use of local connectivity (degree) in endpoint selection.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "Compared representations: the learned skeleton (coarse region graph) vs a detailed grid-based A* graph vs a model-based A* graph. The skeleton is several orders of magnitude smaller (≈205 nodes) and yields much faster planning and robust task performance; grid A* planning was ~15s and model-based A* ~60s per plan. Systems with no initial HLC exploration (SemaFORR-A) produced less effective models and worse success/time metrics.",
            "policy_structure_findings": "Policies that combine coarse topological planning (A* on skeleton) with reactive heuristics outperform largely reactive policies in this environment: SemaFORR relied less on heuristics (49%) than the ablated SemaFORR-A (63.8%). Incompleteness in topology (missing side rooms / dead-ends) increases reliance on heuristics and causes failures, indicating that environments with many dead-ends require policies with backtracking and mechanisms to incorporate newly observed local topology into planning.",
            "uuid": "e1180.0",
            "source_info": {
                "paper_title": "Deliberate Exploration Supports Navigation in Unfamiliar Worlds",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "HLC",
            "name_full": "High-Level Connectivity (HLC) exploration algorithm",
            "brief_description": "A one-time, view-based, time-limited exploration procedure that detects stretches (candidate passages), labels passage grid cells, grows a passage network, and compiles a coarser skeleton of circular regions to capture long-range connectivity (hallways) for downstream planning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "GCWorld",
            "environment_description": "Same realistic indoor GCWorld used in experiments: multiple hallways, rooms, narrow doorways, posts and irregular obstacles; domain: indoor robot navigation (robot: Freight, laser rangefinder).",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": true,
            "dead_ends_count": null,
            "door_constraints_present": true,
            "door_constraints_description": "Geometric/visibility constraints at doorways (narrow passages, variable visibility). No mention of locked or action-conditional doors.",
            "graph_connectivity": "HLC builds a passage network (nodes = labeled 1m×1m passage cells) with edges formed by robot traversal or unobstructed adjacent views; from that it composes a skeleton of non-overlapping circular regions connected when the robot traversed directly between them. Connectivity emphasis is on long-range thoroughfares (passages/hallways); the skeleton captures major connectivity but omits many low-connectivity areas until experienced.",
            "environment_size": "Passage grid uses 1m×1m cells; HLC initial coverage after 20 minutes was 12.65% of unobstructed footprint; HLC captured on average 82.88% of 8 principal hallways; final skeleton ~205 regions and ~248 edges on average.",
            "agent_name": "HLC (exploration module)",
            "agent_description": "Heuristic, opportunistic decision process: actions are forward moves (six lengths) and rotations (four sizes). It detects 'stretches' (long thin unobstructed views, min length parameter d, used with d=7m), prioritizes candidates (larger/most recent first), labels passage grid cells via occupancy mapping (passes vs hits), explores until termination criteria (end-of-stretch, large reorientation &gt;45°, or room detected), and uses BFS on the passage network to navigate to new candidate starts.",
            "exploration_efficiency_metric": "Coverage fraction of passage grid, percent of principal hallways detected, time-limited exploration (20 minutes or 750 decisions per candidate), lengths of candidate stretches, and resulting improvement in downstream planning time and success.",
            "exploration_efficiency_value": "Exploration capped at 20 minutes; average exploration time reported for SemaFORR overall 1084.10 s; initial coverage after HLC 12.65%; HLC covered on average 82.88% of 8 recognized hallways; candidate minimum stretch length used was 7 m; occupancy labeling uses 1m grid cells.",
            "success_rate": null,
            "optimal_policy_type": "Deliberate, view-based exploration to generate a coarse topological map that supports planning-based downstream policies (i.e., exploration-first then planning).",
            "topology_performance_relationship": "HLC's prioritization of long, highly-connected stretches produces a skeleton that reduces planning graph size and increases planning speed and success; limited but focused exploration (targeting high-connectivity passages) yields high marginal benefit for navigation performance, while missing stretches (e.g., side rooms) can cause failures for specific targets.",
            "comparison_across_topologies": false,
            "topology_comparison_results": "",
            "policy_structure_findings": "A topology produced by HLC favors a planning-first policy (A* on skeleton) with fallback reactive heuristics; when HLC fails to capture local low-connectivity areas (dead-ends/rooms), the policy must rely on heuristics and repeated attempts/experience to augment the skeleton.",
            "uuid": "e1180.1",
            "source_info": {
                "paper_title": "Deliberate Exploration Supports Navigation in Unfamiliar Worlds",
                "publication_date_yy_mm": "2020-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "From cognitive maps to cognitive graphs",
            "rating": 2,
            "sanitized_title": "from_cognitive_maps_to_cognitive_graphs"
        },
        {
            "paper_title": "Wormholes in virtual space: From cognitive maps to cognitive graphs",
            "rating": 2,
            "sanitized_title": "wormholes_in_virtual_space_from_cognitive_maps_to_cognitive_graphs"
        },
        {
            "paper_title": "DD-PPO: Learning near-perfect pointgoal navigators from 2.5 billion frames",
            "rating": 2,
            "sanitized_title": "ddppo_learning_nearperfect_pointgoal_navigators_from_25_billion_frames"
        },
        {
            "paper_title": "MINOS: Multimodal indoor simulator for navigation in complex environments",
            "rating": 2,
            "sanitized_title": "minos_multimodal_indoor_simulator_for_navigation_in_complex_environments"
        },
        {
            "paper_title": "FastSLAM 2.0",
            "rating": 1,
            "sanitized_title": "fastslam_20"
        }
    ],
    "cost": 0.0129255,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Deliberate Exploration Supports Navigation in Unfamiliar Worlds</p>
<p>Raj Korpan 
Susan L Epstein 
Deliberate Exploration Supports Navigation in Unfamiliar Worlds</p>
<p>To perform tasks well in a new domain, one must first know something about it. This paper reports on a robot controller for navigation through unfamiliar indoor worlds. Based on spatial affordances, it integrates planning with reactive heuristics. Before it addresses specific targets, however, the system deliberately explores for high-level connectivity and captures that data in a cognitive spatial model. Despite limited exploration time, planning in the resultant model is faster and better supports successful travel in a challenging, realistic space.</p>
<p>Fig. 1: How would you travel in GCWorld from * to A?</p>
<p>Combined with planning in a detailed metric map, these affordances improved SemaFORR's ability to contend with large, novel, irregular spaces. Here, however, we assume the robot has no map, and instead have it actively seek out more global affordances beyond its immediate perceptual range. A vehicle highway system is in some ways analogous to GCWorld's network of hallways. A plan to travel to a specified destination through a connected system of highways requires an initial path to the system itself, travel along some portion of it, and a final path to the destination. Highways, like hallways, provide long-distance segments with high-level connectivity. Highways' restricted on-off access, however, reduces opportunities for inefficient digressions. In contrast, a navigator in GCWorld faces unknown possibilities at every doorway. Highway systems are intended to facilitate travel; we assume here that architects design buildings with the same intent. Thus SemaFORR treats hallways the way navigation apps treat highways -it plans with them. But to use such a network, SemaFORR must first discover it.</p>
<p>The next section describes related work on exploration and navigation. Subsequent sections detail new algorithms that learn high-level connectivity by deliberate exploration, and build a cognitive spatial model to navigate an unfamiliar world. The paper then describes our navigation experiments, analyzes their results, and discusses current and future work. To travel in an unknown world, a navigator explores, represents observed space, and then plans with that representation. One such representation is a metric map that accurately positions every obstacle. The state-of-the-art algorithm to build a detailed metric map of the world for robot navigation is Probabilistic SLAM (Simultaneous Localization and Mapping) [4]. To produce end-to-end plans, however, SLAM-based navigation typically requires complete coverage of a world. This requires painstaking travel along each wall, particularly burdensome in large, complex spaces like GCWorld with its jogs and connecting rooms. SLAM must also contend with loop-closing and it treats all space as equally important.</p>
<p>Several approaches to a metric map prioritize exploration. Frontier-based exploration repeatedly moves to the closest unknown space while any remains [5]. This can be inefficient. Recent work used context and the location of a goal to bias frontier-based exploration [6]. In contrast, our approach prioritizes exploration of space with high connectivity for navigation to any goal.</p>
<p>Instead of a metric map, many human navigators formulate a cognitive spatial model based on prior knowledge, external cues, and sensory input (e.g., vision and proprioception). Place cells and grid cells in the human hippocampus construct a spatial model [7]. People learn a labeled graph that captures topological information with metric labels [8]. With deliberate but relatively limited exploration, SemaFORR also learns a labeled graph that captures the highly connected, most salient spatial relations in the robot's world.</p>
<p>Several hierarchical representations of the world that capture connectivity require the robot to navigate through every part of its world [9]. People, in contrast, do not require a complete map or physical traversal along every wall to navigate well. Instead, they look for highly-connected thoroughfares that facilitate efficient travel [10]. Our approach enables hierarchical planning at different levels of abstraction, similar to the way a human brain constructs, represents, and uses hierarchical plans [11].</p>
<p>Without a spatial representation, reinforcement learning for navigation often struggles with large, realistic worlds [12]. Although one recent approach achieved near perfect success this way, it learned from billions of simulations of robots equipped with three sensors [13]. In contrast, our approach learns to navigate successfully with limited exploration, a range finder, and a cognitive spatial model.</p>
<p>Classical graph planning algorithms (e.g., breadth-first search and A<em> [14]) construct a graph and search it for shortest paths. Such graphs can be very large because they locate many vertices in every spatial area. Instead, sampling-based methods (e.g., probabilistic roadmap and rapidly-exploring random tree (RRT)) create smaller graphs by randomly sampling free space. Such graphs may not include the shortest paths, however. While other sampling-based methods (e.g., RRT</em> [15] and DeRRT* [16]) find near optimal paths, they still require a spatial representation of the entire world, and their paths can come close to obstacles. Our approach uses a classical planning algorithm on a labeled graph whose vertices avoid obstacles in explored areas instead of a graph based on a metric map.</p>
<p>An affordance is a characteristic of the world that enables the execution of some action [17]. Affordance-based theories of spatial cognition posit a tight relationship between the specific dynamics of the environment and the decisions made by an individual [18]. To the best of our knowledge, only one system other than SemaFORR has addressed navigation and spatial representation hierarchically and with affordances [19]. The space it explored, however, was an order of magnitude smaller and hardly more complex than Figure 2. Its model also required world-specific deep learning offline and designated semantic labels for room types. In contrast, SemaFORR produces a cognitive spatial model based on spatial affordances, and learns online, both from deliberate exploration and task-driven experience.</p>
<p>III. EXPLORATION FOR HIGH-LEVEL CONNECTIVITY Faced with a novel task, people often prefer to explore for relevant global information, rather than take the most immediately rewarding action [20]. This section details HLC (High Level Connectivity), a one-time, view-based process to explore built, indoor spaces. Figure 3 resulted from 20 minutes of exploration with HLC in GCWorld. This exploration is heuristic, opportunistic, and time-limited.</p>
<p>Confronted with a new built world, HLC seeks passages, relatively far-reaching, relatively narrow, relatively regular extents intended to approximate hallways. Based solely on the robot's views, HLC identifies likely passages (candidates) for exploration. The remainder of this section describes how HLC identifies and stores candidates, carefully examines one at a time, and reformulates its knowledge into a graph that supports planning.</p>
<p>A. Finding candidates</p>
<p>In HLC, exploration is a sequence of decision points. At each decision point, HLC selects and executes one action. Allowable actions are forward moves of six different lengths and four sizes of rotation, both clockwise and counterclockwise. For every decision point, HLC records the robot's pose and view, along with the features in Table I. Within a view, a potential passage first appears to the robot as a stretch, a long, thin, unobstructed area of length at least d. A candidate is a stretch and its start, the pose where it was detected. Initially, HLC rotates the robot in place to find its first candidate. Although HLC pursues only one candidate at a time, the robot may glimpse other stretches as it pursues its current candidate. HLC saves qualified stretches for future exploration on its candidate list. A candidate is placed at the front of the list if its average length is more than 2 * d; otherwise it is placed at the back. This prioritizes exploration of the largest, most recently glimpsed stretches first.</p>
<p>To qualify as a candidate, a stretch and the pose where it is detected must satisfy four conditions. First, the stretch's length must exceed its width. Second, the stretch is not similar to any candidate on the list or any previously considered one. (Two stretches are judged similar if the distance between them is within 1m and some Allen interval condition applies [21] with an overlap of at least 1/3 the average of their lengths.) Third, the stretch must potentially provide new, useful information. To determine this, HLC keeps a passage grid of 1m × 1m cells superimposed on the footprint of the world. Each cell there can be labeled as part of a passage, labeled as obstructed (by a process described below), or left unlabeled. HLC gauges the potential for new, useful information based on the start, midpoint and end of the stretch. The third condition is that none of those points is labeled as obstructed in the grid, and no more than one is labeled as part of a passage. The fourth condition is that the candidate may not be classified as a room.</p>
<p>Large rooms can be mistaken for a stretch when they are actually dead ends. To prevent their candidacy, the view statistics in Table 1 were used to distinguish between a large room and a legitimate continuation of a passage. Offline, a large set of unlabelled views was drawn from earlier experiments, and described by the features in Table 1. We clustered this data with k-means into two sets, which had natural labels as rooms and passages in the world. We labeled each data point by its cluster, learned a decision tree on this labeled data, and made its top two rules a classifier that distinguished between a passage and a room.</p>
<p>B. From candidate to passage</p>
<p>To explore a candidate, HLC assigns it a passage number and then navigates to reach the farthest position along its stretch. As it moves the robot, HLC records the passage number at each grid cell it enters. Real hallways, however, are not necessarily smooth; they often have minor jogs and slight irregularities. If the robot comes too close to an obstruction on its left or right while it traverses the stretch, HLC has it turn slightly away from the obstruction, take a step, and then continue down the stretch.</p>
<p>Of course, a passage may be longer than a candidate's stretch initially suggests. For example, the passage might curve slightly or exceed the range finder's limit. To contend with these possibilities, exploration of a candidate stops only when one of three conditions is satisfied. First, the robot has reached the end of the passage (i.e., lies within 0.5m of the end of the stretch or has only 0.1m directly in front of it). Second, the robot has just made so hard a turn that it would pursue a different passage (i.e., its current orientation differs by more than 45 • from its average orientation in the current passage thus far). Third, the robot may find itself in a large space or room, detected when the space around the robot noticeably widens (i.e., the current passage's length plus the maximum visible distance in front of the robot is less than 1.5 times the average maximum width detected by the views on the passage thus far). While this last condition eliminates exploration of most rooms, it remains a heuristic, as demonstrated by the three rooms circled in Figure 3.</p>
<p>While passages are likely to be more than 1m wide, realworld walls are unlikely to align neatly with any grid's arbitrary cell borders. HLC uses occupancy mapping to add qualified cells on the robot's immediate left and right to a passage. This technique distinguishes between distance readings that extend beyond a neighboring cell (passes) and readings that end within the cell (hits). For a cell with p passes and h hits in a given view, when h/(h + p) ≤ 0.5 the cell is termed unobstructed; otherwise it is obstructed. At each decision point, HLC adds a cell to a passage only if the cell is unobstructed in the current view and adjacent (within 2m of the robot and to its immediate right or left). Such a cell is labeled with the current passage number in the passage grid. Obstructed cells within 4m are labeled as such in the passage grid. Occupancy mapping results in the jagged nature of the passages in Figure 3, where some space beyond open doorways is recorded as unobstructed and some cells near obstacles as obstructed.</p>
<p>C. The passage network and the skeleton</p>
<p>Passages produce connectivity only when they link to one another. Thus, as it extends a candidate, HLC also builds a passage network, a graph where each vertex represents a labeled passage grid cell. The network records an edge between two vertices if the robot ever travels between the grid cells successfully, or if some view ever labeled an adjacent cell as unobstructed. HLC grows and uses this network while it explores for passages.</p>
<p>Once HLC completes exploration of a candidate, it removes candidates one at a time from the top of the candidate list until it finds one whose stretch remains uncovered in the passage grid and is dissimilar from any already explored candidate. HLC assigns that candidate a new passage number, but then must travel to the candidate's start and orient the robot in the direction of the stretch. If the robot is near (within 1m) the new start, HLC moves to within 0.5m of it; otherwise, the robot must find its way to the new start.</p>
<p>Before the robot returns to a new candidate's start, the robot is already in some passage and the candidate was first glimpsed during exploration along some (possibly different) passage. In that case, HLC finds the shortest path in the passage network from the robot's current location to the candidate's start with breadth-first search. (The heuristic formation of the network does not support an appropriate underestimate for use with A*.) To transform that sequence of passage grid cells into a path, HLC replaces each cell with two decision points: the one closest to the center of that cell and the one closest to the center of the next cell in the sequence. This path is guaranteed to lead to the new candidate's start. Exploration of the world continues until no candidates remain or a specified time has elapsed. If the candidate list becomes empty, HLC makes one last attempt to find additional candidates -it travels to the labeled cell farthest from its current position in the passage grid.</p>
<p>HLC also builds a skeleton, a graph of connected, unobstructed areas that supports long-range planning. After exploration, only the skeleton is preserved to support path planning. The skeleton re-represents each passage as a chain of regions, non-overlapping, circular areas built from the decision points during the passage's exploration. An edge in the skeleton indicates that the robot moved directly from one region to the other without passing through any intervening region. The shortest of those transitions produces the label for that edge: its metric distance and the two endpoints where the robot crossed the circumference of each region. Figure  4 shows an example of a learned skeleton in GCWorld. Learning during subsequent travel continues to update the skeleton.</p>
<p>IV. PLANNING AND NAVIGATION</p>
<p>To contend with unanticipated and long-term challenges, people combine their learned spatial model with decisionmaking heuristics that balance reactivity and planning [22]. SemaFORR also integrates planning with reactive heuristics. A plan here is a sequence of waypoints, intermediate subgoals on the way to a target. Given a target, SemaFORR's high-level reasoning structure makes a plan to reach it, and tries to execute that plan, guided by two rules: "go to the next unobstructed, unvisited waypoint" and "avoid moves into obstructed locations."</p>
<p>Ideally, SemaFORR would simply go from one waypoint in its plan to the next. The next waypoint, however, may be occluded or out of range, more than one action may adequately address it, or the robot's sensors or actuators may err. Because exploration captures only limited, passageoriented data, the robot may also not be near the first region in its skeleton-based plan and the target may not be near the last one. In all these cases, SemaFORR relies on the combined opinions of its heuristics, which capture commonsense (e.g., "move in the direction of the target") and model-based reasoning (e.g., "leave a dead-end that does not contain the target"). (See [3] for additional details.)</p>
<p>Previously, when given a target, SemaFORR applied A* search to a graph built from a fine-grained grid superimposed on a map of the world, with edge costs modified by its spatial model. In large worlds, however, the model's coverage of the world was determined by the targets set for the robot. HLC changes the way SemaFORR plans.</p>
<p>With HLC, SemaFORR now deliberately explores for high-level connectivity first, and then plans in the (far smaller) skeleton instead of in a detailed metric map. The planner uses A* on the skeleton to find the shortest path between the robot and the target location. If the target is in a region, it uses that region as a vertex. In the more likely case where the target is outside a region, the planner first tries to find a region with visibility, where a view associated with that region is able to detect the target. If no region has visibility, then the planner scores each region with s = −5 * distance + degree, where distance is the Euclidean distance from the target to the region's center and degree is the region's degree in the skeleton. This expresses a preference for regions that are not isolated and yet close by. The planner then designates the region with the maximum score as the endpoint for the plan. If the robot is not in a region, a similar process selects some region as the first point in the plan.</p>
<p>The resultant partial plan is a sequence of waypoints that interleave the regions' centers with their connecting edges' endpoints and the midpoint on the path between the regions. Figure 5 shows a sequence of waypoints in part of a skeleton. The robot must rely on voting among its heuristics for the initial and final legs of its travel.</p>
<p>V. EXPERIMENTAL DESIGN AND RESULTS To evaluate the impact of exploration on navigation, we conducted multiple simulation experiments in GCWorld with Freight, a Fetch Robotics robot. GCWorld's many jogs, interior posts, and narrow doorways, provide substantial challenges for Freight's 0.8m-wide body. Fifteen times per second, the view from Freight's laser range finder measures 660 distances to the nearest obstruction within 25m (every 1/3 • along a 220 • arc). SemaFORR selects each action; the simulator executes it and reports the resultant pose and view.</p>
<p>Freight's task is to visit a preselected ordered list of 40 randomly chosen targets. An experiment repeats each of 5 different tasks 5 times, for a total of 25 runs. Freight fails on a target if it does not reach it within 750 actions. The robot begins every run in the same pose, and begins on each target after the first from its final pose on the previous one.</p>
<p>This experiment was executed with exploration (Se-maFORR) and with SemaFORR-A, an ablated version that gradually constructs the model without an initial exploration phase. Performance metrics, averaged over 25 runs, were total travel time in seconds, total travel distance in meters, percentage of targets reached successfully, and coverage, the fraction of the world's unobstructed footprint covered by the spatial model, as evaluated in a 1m × 1m grid.</p>
<p>Parameter values were based on preliminary analysis. HLC's exploration was limited to 750 decisions per candidate and 20 minutes, with moves of 0.8m to match Freight's size. Freight moved away from any obstruction within 0.15m. A stretch had to be at least 7m, and passage orientation was averaged over the last 40 decision points. Statistically significant differences appear in boldface (p = 0.05).</p>
<p>SemaFORR was significantly more successful than SemaFORR-A in this experiment. (See Table II.) Table III compares their travel time and distance, and breaks out the task-only data from SemaFORR. Even when exploration is included, SemaFORR required significantly less time than SemaFORR-A. Although SemaFORR explored for an average of 1084.10 seconds, that initial effort saved more than twice as much time when it went on to address the tasks.</p>
<p>Travel distance for the tasks was also significantly shorter. Even when exploration distance is included, SemaFORR did not travel significantly further than SemaFORR-A. SemaFORR-A made 63.80% of its decisions with heuristics, while SemaFORR, whose plans were more reliable, resorted to heuristics significantly less often (49%).</p>
<p>SemaFORR's coverage of GCWorld was 12.65% after exploration, and twice that after it had attempted all its targets. Figure 6 shows the frequency with which HLC captured each passage grid cell. Clearly it found GCWorld's principal hallways and avoided most other areas. On average, HLC covered 82.88% of the 8 readily recognized hallways in Figure 1. Table II shows that SemaFORR-A's final model covers less of GCWorld than SemaFORR's does. Indeed, although the two systems covered about as much of GCWorld with their model, SemaFORR's model was clearly more effective. SemaFORR's planning in the skeleton averaged 3.56 seconds per task. In previous work, we showed that A<em> planning on the GCWorld grid for similar tasks averaged about 15 seconds, and planning with a model-based A</em> graph averaged about 1 minute. This speedup occurs because the scale of the skeleton graph (205 vertices and 248 edges on average at the end of a task) is several magnitudes smaller than the grid-based graph (85,000 vertices and 170,000 edges). The skeleton captures a far coarser representation of the world and yet does not require the metric details of an A* graph to produce relatively successful travel.</p>
<p>VI. DISCUSSION</p>
<p>Human skill at navigation in novel worlds inspired this work. Although an early version of SemaFORR proved successful in a variety of worlds like Figure 2, it had difficulty as they became more complex. Moreover, embodiment with an industrial-sized robot in far larger, more realistic spaces like GCWorld repeatedly stymied that version with its complexity and the deceptive proximity of targets just beyond some nearby wall. SemaFORR seemed to need a map in which to plan. Instead we augmented it with self-guided exploration.</p>
<p>Given Figure 3 or a road map, most people and efficient, direction-giving algorithms quickly notice lengthy, readily navigable spaces like our passages. They identify nearby ones and then search to reach them from their current location and from the target. SemaFORR shows that even limited exploration provides a sufficiently robust model for planning without a map. We have tested this premise successfully on other, differently configured floors in the same building as GCWorld, and are currently examining it in a building whose footprint is not rectangular.</p>
<p>SemaFORR continues to modify its skeleton after exploration, when it visits targets. As a result, the original pure passage network becomes embellished with chains of regions that represent shorter stretches or dead-ends (rooms). Although planning may become less efficient as the skeleton grows, the expanded cognitive model also supports more informed decisions and planning within previously unvisited areas. Prioritization of the regions that originated within passages is a subject of current work.</p>
<p>We considered planning in a labeled topological graph where nodes represented passages and edges represented their intersections. That graph would be even smaller than the skeleton. An intersection there would afford extensive travel, and thus be a place of interest and a potential landmark. It would require considerable computation, however, to construct this graph from the passage grid, which is not well-aligned with obstructions in the world, has cells larger than many regions, and must retain the full decision history in memory. A better approach, currently under development, is to coalesce the regions in the obstruction-free, more memory-efficient skeleton to produce a representation more like human cognitive spatial models.</p>
<p>When SemaFORR failed on a task here, it was usually because the skeleton or the spatial model lacked sufficient detail in a relevant area. For example, the adjacent but poorly connected rooms nearby to the room labeled B in Figure  4 make navigation particularly difficult. Such rooms are analogous to a side street off of a main road off a highway, where knowledge of the highway network is not enough to get to that side street. As the skeleton grows with experience, however, SemaFORR is able to succeed on such failed targets upon new attempts. (About 62.5% of initial failures averaged over three runs were successful after repeated attempts.)</p>
<p>There are several caveats with our approach. Only exhaustive exploration can guarantee perfect knowledge of an environment. Without it, navigation and plans for it can be less than ideal. (For example, a shorter path in Figure 5 goes undetected because of a gap in the skeleton.) Moreover, HLC can only learn passages if can find at least one stretch to explore. Like architects, we had our robot enter its world for the first time where it would detect a stretch (i.e., at the elevators). Search for a first stretch instead is future work, as is extension to three dimensions. In addition, we assumed near-perfect localization, that is, that the robot knew exactly where it and the target were. In built spaces this can be achieved with additional sensors.</p>
<p>Finally, the cognitive spatial model described here has other uses. It is a descriptive device for designers of indoor spaces, and could be predictive for floors of the same building. It can also be used to generate user-friendly expla-nations even when a robot is governed by another controller. Assuming you begin facing to the right in Figure 1, for example, a solution could be described at a high level as "go to the end of the hallway, turn left, go to the end of that hallway, turn right, and your destination will be just before the end of that hallway, on your left." Meanwhile, limited exploration provides a robust model for navigation in unfamiliar worlds.</p>
<p>Fig. 2 :
2A robot's view arXiv:2007.00798v1 [cs.RO] 1 Jul 2020 II. RELATED WORK</p>
<p>Fig. 3 :
3Passages (blue) and obstructed cells (pink) learned after 20 minutes of exploration. Rooms that eluded the termination condition are circled.</p>
<p>Fig. 4 :
4Regions (circles) and edges form a skeleton.</p>
<p>Fig. 5 :
5In part of a skeleton, waypoints form a plan from the robot (square) to its target (star).</p>
<p>TABLE I :
IFeatures captured at each decision point Distance in front of the robot (average, maximum and minimum) Distance to the robot's left (average and maximum) Distance to the robot's right (average and maximum) Full view of all distances (average, maximum, minimum, median, and standard deviation)</p>
<p>TABLE II :
IISuccess and CoverageNavigator 
Success Rate Initial Coverage Final Coverage 
SemaFORR-A 
46.17% 
0.00% 
22.97% 
SemaFORR 
70.60% 
12.65% 
27.94% </p>
<p>TABLE III :
IIITravel Time and DistanceNavigator 
Travel Time Distance 
SemaFORR-A 
8216.45 
5889.49 
SemaFORR (tasks only) 
5608.93 
4610.87 
SemaFORR (tasks and exploration) 
6693.02 
5769.50 </p>
<p>Fig. 6: Average passage coverage over 25 runs in GCWorld. 
Darker cells were detected more often. </p>
<p>From cognitive maps to cognitive graphs. E Chrastil, W Warren, PLOS One. 911E. Chrastil and W. Warren, "From cognitive maps to cognitive graphs," PLOS One, vol. 9, no. 11, 2014.</p>
<p>Human wayfinding and cognitive maps. R G G Golledge ; R, Golledge, Wayfinding behavior: Cognitive mapping and other spatial processes. JHU PressR. G. Golledge, "Human wayfinding and cognitive maps," in Wayfind- ing behavior: Cognitive mapping and other spatial processes, R. G. Golledge, Ed. JHU Press, 1999, ch. 1, pp. 5-45.</p>
<p>Planning and explanations with a learned spatial model. S L Epstein, R Korpan, International Conference on Spatial Information Theory. Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik. S. L. Epstein and R. Korpan, "Planning and explanations with a learned spatial model," in International Conference on Spatial Information Theory. Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2019.</p>
<p>FastSLAM 2.0," in FastSLAM: A scalable method for the simultaneous localization and mapping problem in robotics. M Montemerlo, S Thrun, SpringerM. Montemerlo and S. Thrun, "FastSLAM 2.0," in FastSLAM: A scal- able method for the simultaneous localization and mapping problem in robotics. Springer, 2007, pp. 63-90.</p>
<p>A frontier-based approach for autonomous exploration. B Yamauchi, Proceedings of International Symposium on Computational Intelligence in Robotics and Automation. International Symposium on Computational Intelligence in Robotics and AutomationIEEEB. Yamauchi, "A frontier-based approach for autonomous exploration," in Proceedings of International Symposium on Computational Intelli- gence in Robotics and Automation. IEEE, 1997, pp. 146-151.</p>
<p>Planning beyond the sensing horizon using a learned context. M Everett, J Miller, J P How, IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEEM. Everett, J. Miller, and J. P. How, "Planning beyond the sensing horizon using a learned context," in IEEE/RSJ International Confer- ence on Intelligent Robots and Systems. IEEE, 2019.</p>
<p>Navigating cognition: Spatial codes for human thinking. J L Bellmund, P Gärdenfors, E I Moser, C F Doeller, Science. 36264156766J. L. Bellmund, P. Gärdenfors, E. I. Moser, and C. F. Doeller, "Navigating cognition: Spatial codes for human thinking," Science, vol. 362, no. 6415, p. eaat6766, 2018.</p>
<p>Wormholes in virtual space: From cognitive maps to cognitive graphs. W H Warren, D B Rothman, B H Schnapp, J D Ericson, Cognition. 166W. H. Warren, D. B. Rothman, B. H. Schnapp, and J. D. Ericson, "Wormholes in virtual space: From cognitive maps to cognitive graphs," Cognition, vol. 166, pp. 152-163, 2017.</p>
<p>Factoring the mapping problem: Mobile robot map-building in the hybrid SSH. P Beeson, J Modayil, B Kuipers, The International Journal of Robotics Research. P. Beeson, J. Modayil, and B. Kuipers, "Factoring the mapping prob- lem: Mobile robot map-building in the hybrid SSH," The International Journal of Robotics Research, pp. 428-459, 2010.</p>
<p>Capturing indoor wayfinding strategies and differences in spatial knowledge with space syntax. C Hölscher, M Brösamle, 6th International Space Syntax Symposium. C. Hölscher and M. Brösamle, "Capturing indoor wayfinding strategies and differences in spatial knowledge with space syntax," in 6th International Space Syntax Symposium, 2007, pp. 043-01.</p>
<p>Neural mechanisms of hierarchical planning in a virtual subway network. J Balaguer, H Spiers, D Hassabis, C Summerfield, Neuron. 904J. Balaguer, H. Spiers, D. Hassabis, and C. Summerfield, "Neural mechanisms of hierarchical planning in a virtual subway network," Neuron, vol. 90, no. 4, pp. 893-903, 2016.</p>
<p>MINOS: Multimodal indoor simulator for navigation in complex environments. M Savva, A X Chang, A Dosovitskiy, T Funkhouser, V Koltun, arXiv:1712.03931arXiv preprintM. Savva, A. X. Chang, A. Dosovitskiy, T. Funkhouser, and V. Koltun, "MINOS: Multimodal indoor simulator for navigation in complex environments," arXiv preprint arXiv:1712.03931, 2017.</p>
<p>DD-PPO: Learning near-perfect pointgoal navigators from 2.5 billion frames. E Wijmans, A Kadian, A Morcos, S Lee, I Essa, D Parikh, M Savva, D Batra, 1911arXivE. Wijmans, A. Kadian, A. Morcos, S. Lee, I. Essa, D. Parikh, M. Savva, and D. Batra, "DD-PPO: Learning near-perfect pointgoal navigators from 2.5 billion frames," arXiv, pp. arXiv-1911, 2019.</p>
<p>Search: A survey of recent results. R E Korf, Exploring Artificial Intelligence: Survey Talks from the National Conferences on Artificial Intelligence. Morgan KaufmannR. E. Korf, "Search: A survey of recent results," in Exploring Artificial Intelligence: Survey Talks from the National Conferences on Artificial Intelligence. Morgan Kaufmann, 2014, pp. 197-237.</p>
<p>Sampling-based algorithms for optimal motion planning. S Karaman, E Frazzoli, The international journal of robotics research. 307S. Karaman and E. Frazzoli, "Sampling-based algorithms for optimal motion planning," The international journal of robotics research, vol. 30, no. 7, pp. 846-894, 2011.</p>
<p>Deep sequential models for sampling-based planning. Y.-L Kuo, A Barbu, B Katz, IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEEY.-L. Kuo, A. Barbu, and B. Katz, "Deep sequential models for sampling-based planning," in IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 2018, pp. 6490-6497.</p>
<p>The theory of affordances. J J Gibson, Perceiving, Acting, and Knowing: Toward and Ecological Psychology. J. J. Gibson, "The theory of affordances," Perceiving, Acting, and Knowing: Toward and Ecological Psychology, pp. 67-82, 1977.</p>
<p>Spatial perception and action. B R Fajen, F Phillips, American Psychological AssociationB. R. Fajen and F. Phillips, Spatial perception and action. American Psychological Association, 2013, pp. 67-80.</p>
<p>Deep spatial affordance hierarchy: Spatial knowledge representation for planning in large-scale environments. A Pronobis, F Riccio, R P Rao, ICAPS Workshop on Planning and Robotics. A. Pronobis, F. Riccio, and R. P. Rao, "Deep spatial affordance hierarchy: Spatial knowledge representation for planning in large-scale environments," in ICAPS Workshop on Planning and Robotics, 2017.</p>
<p>Epistemic drive and memory manipulations in explore-exploit problems. N Collignon, C Lucas, Proceedings of Cognitive Science Conference. Cognitive Science ConferenceN. Collignon and C. Lucas, "Epistemic drive and memory manip- ulations in explore-exploit problems," in Proceedings of Cognitive Science Conference, 2019, pp. 1540-1546.</p>
<p>Maintaining knowledge about temporal intervals. J F Allen, Communications of the ACM. 2611J. F. Allen, "Maintaining knowledge about temporal intervals," Com- munications of the ACM, vol. 26, no. 11, pp. 832-843, 1983.</p>
<p>Wayfinding strategies in behavior and language: a symmetric and interdisciplinary approach to cognitive processes. T Tenbrink, J M Wiener, Spatial Cognition V. SpringerT. Tenbrink and J. M. Wiener, "Wayfinding strategies in behavior and language: a symmetric and interdisciplinary approach to cognitive processes," in Spatial Cognition V. Springer, 2006, pp. 401-420.</p>            </div>
        </div>

    </div>
</body>
</html>