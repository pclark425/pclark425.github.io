<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-692 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-692</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-692</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-267897516</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2402.15301v2.pdf" target="_blank">Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Causal graph recovery is traditionally done using statistical estimation-based methods or based on individual's knowledge about variables of interests. They often suffer from data collection biases and limitations of individuals' knowledge. The advance of large language models (LLMs) provides opportunities to address these problems. We propose a novel method that leverages LLMs to deduce causal relationships in general causal graph recovery tasks. This method leverages knowledge compressed in LLMs and knowledge LLMs extracted from scientific publication database as well as experiment data about factors of interest to achieve this goal. Our method gives a prompting strategy to extract associational relationships among those factors and a mechanism to perform causality verification for these associations. Comparing to other LLM-based methods that directly instruct LLMs to do the highly complex causal reasoning, our method shows clear advantage on causal graph quality on benchmark datasets. More importantly, as causality among some factors may change as new research results emerge, our method show sensitivity to new evidence in the literature and can provide useful information for updating causal graphs accordingly.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e692.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e692.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LACR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM Assisted Causal Recovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-augmented LLM pipeline that performs constraint-based causal graph recovery by extracting conditional associational relationships from LLM background knowledge and retrieved scientific documents, then aggregating those judgments and applying constraint-based rules to produce a causal skeleton and orient edges.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>LACR (LLM Assisted Causal Recovery)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>LACR breaks causal discovery into (1) edge-existence verification (skeleton construction) and (2) orientation. For skeleton construction it uses a deterministic Constraint‑Based (CC) prompt to extract conditional associational judgments α_KB(ij | V') from multiple knowledge bases (KBs): LLM background (BG), retrieved documents (DOC), and optional numerical output from a statistical CD method (PC). For each variable pair it issues a chain of LLM queries: background reminder, association verifier (zero-order association), association-type verifier (direct vs indirect—i.e., existence of a conditioning set that d‑separates), and association rechecker (verify mediators lie within V). Each KB yields one of {INDEPENDENT, DIRECTLY ASSOCIATED, INDIRECTLY ASSOCIATED, UNKNOWN}, mapped to ζ_KB(ij) ∈ {0,1} (edge absent/present). LACR then aggregates KB opinions by a simple additive scoring S (+=1 for DIRECTLY ASSOCIATED, +=-1 for INDEPENDENT or INDIRECTLY ASSOCIATED, UNKNOWN ignored) with a slight bias: remove edge if S ≤ 0. Orientation (LACR2) uses direct LLM causal-direction queries over adjacent pairs. Retrieval-Augmented Generation (RAG) fetches relevant scientific papers per variable pair to strengthen associational evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Real-world domain datasets (ASIA, SACHS, CORONARY)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Static observational datasets (medical/biological/social domains) used as validation. These are not interactive or open-ended virtual labs; LACR instead uses retrieved literature and optional numerical datasets for evidence aggregation and inference.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detection of indirect associations via conditional-independence style judgments: the CC prompt chain (association verifier → association type verifier → rechecker) asks the LLM to identify mediating (third) factors from the variable set V and to determine whether conditioning on them removes the association. Aggregation via majority voting across KBs and injection of PC algorithm outputs are used to counter spurious signals.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Confounding/mediated associations (indirect paths), selection bias and dataset collection bias (discussed), measurement error/unmeasured confounders (recognized as limitations), and irrelevant/external-variable-mediated associations.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>LLM-based evidence extraction: analyze documents and background knowledge to answer whether pairwise association holds (α_KB(ij)) and whether there exists a mediating conditioning set within V that eliminates the association (mapping to INDIRECTLY ASSOCIATED). The rechecker step specifically verifies whether alleged mediators belong to V (to avoid external-distractor confounding). UNKNOWN responses indicate insufficient evidence and are discarded.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Score aggregation (S) across KB voters: each KB vote contributes +1 for DIRECTLY ASSOCIATED and -1 for INDEPENDENT or INDIRECTLY ASSOCIATED; UNKNOWN votes are ignored. Edge removal occurs if S ≤ 0, introducing an intentional bias toward removing edges. Optionally PC algorithm outputs are added as additional ±1 votes.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Refutation is performed by (1) verifying that mediating variables are within the considered variable set (association rechecker), (2) treating UNKNOWN as unusable (discarding weak evidence), and (3) cross-checking/augmenting LLM-based judgments with statistical CD outputs (PC) and multiple independent document KBs (wisdom-of-the-crowd aggregation) to overturn spurious associations supported by single sources.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Reported per-knowledge-base experiments: On ASIA, using only BG (LLM background) LACR1 recovered the full skeleton (AP=1.0, AR=1.0, F1=1.0). Adding retrieved documents (DOC) reduced AP from 1.0 to 0.57 and F1 from 1.0 to 0.73, but adding PC outputs increased F1 back to 0.86. On CORONARY, BG-only gave AP/AR/F1=0.625; adding DOC+PC raised metrics to 0.875. On SACHS, BG-only was best, adding DOC decreased F1 slightly (~0.01) and adding PC decreased F1 to 0.46. Orientation (LACR2) achieved TEA=1.0 (perfect orientation of recovered true-positive edges) on ASIA and SACHS across KB variants.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baseline 'direct causal prompt' methods and some pure statistical baselines were compared; LACR (BG) outperformed several LLM baselines on ASIA and SACHS in skeleton recovery. Exact baseline numbers vary by dataset; e.g., pure LLM baselines reported worse skeleton recovery than LACR BG on ASIA (specific baseline figures not all enumerated in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LACR explicitly targets spurious/indirect associations by asking LLMs to identify mediators and by mapping conditional-association judgments to constraint‑based causal rules; aggregating multiple independent KBs (documents + background + PC outputs) via a voting scheme reduces reliance on any single (possibly spurious) source. Empirically, the choice of KB matters: background knowledge alone gave perfect skeleton recovery on ASIA but adding literature sometimes reduced agreement with legacy ground-truths (indicating either spurious signals in KBs or outdated ground-truths), and adding PC outputs generally helped recover/rectify edges. The rechecker and UNKNOWN policy help avoid making claims from weak/out-of-domain evidence. Limitations include no explicit handling of unmeasured confounders, dependence on retrieval quality, and non-interactive (non-experimental) setting.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e692.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e692.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CCGC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Constraint-based Causal Graph Construction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of constraint-based causal discovery procedures that infer skeletons by testing conditional independences and then orienting edges using rules derived from d-separation (e.g., PC-style algorithms).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Constraint-based Causal Graph Construction (CCGC)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>CCGC infers causal skeletons by examining conditional associational relationships α(ij | V') across conditioning sets V'. If some V' d‑separates i and j (α(ij | V') = 0), the undirected edge is removed; otherwise it is kept. Orientation proceeds with standard constraint-based rules (v‑structures, propagation). LACR designs prompts to emulate the CCGC phase via LLM-extracted conditional-association judgments and then maps them to ζ_KB(ij).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Statistical observational data / knowledge base (KB)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Typically applied to observational datasets or any KB that can provide estimates of conditional independences; not inherently interactive.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Explicit conditional-independence testing across candidate conditioning sets (i.e., searching for sets V' that d-separate pairs) which can reveal mediators and indirect associations, thereby removing edges induced by measured confounders/mediators.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Measured confounding (mediators), indirect associations via measured third variables, and selection bias insofar as it affects conditional independence tests (selection bias acknowledged as a threat).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Systematic search over conditioning sets and CI tests (in LACR this is approximated by LLM answers about whether conditioning on particular V' eliminates association).</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Removal of edges when a conditioning set produces independence (i.e., deterministically downweighting direct-edge hypotheses by CI evidence).</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>If any conditioning set yields independence, the direct edge hypothesis is refuted (ζ=0). The method relies on faithfulness and correct CI determination.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CCGC provides the theoretical foundation for LACR's prompting strategy: converting conditional-independence judgments into edge presence/absence decisions. The paper leverages CCGC to reduce LLM task complexity (associational reasoning rather than direct causal assertion) which improves reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e692.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e692.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PC algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A classical constraint-based causal discovery algorithm that recovers causal skeletons and orients edges by iterative conditional independence testing and application of orientation rules.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An algorithm for fast recovery of sparse causal graphs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>PC algorithm (Spirtes & Glymour family)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>PC starts from a complete undirected graph and performs conditional independence tests of increasing conditioning set sizes to remove edges when a conditioning set d‑separates two nodes; after skeleton recovery it orients edges using v‑structure identification and propagation. In this paper PC is used as an injected numerical KB: its outputs are converted to ±1 votes in LACR's KB-aggregation score to supplement LLM/document judgments.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Observational datasets (bnlearn package datasets used for validation)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Standard static observational datasets (ASIA, SACHS, CORONARY) where conditional independence tests can be computed numerically; not an interactive environment.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Explicit conditional independence testing across candidate conditioning sets; removal of edges when conditioning removes association, thus detecting and removing edges due to measured mediators/confounders.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Measured confounding/mediated associations and statistical artefacts resulting from sampling; limited against unmeasured confounders and selection bias unless corrected.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Classical statistical CI tests applied to data (in experiments via PC). In LACR the PC result is imported as an additional KB vote to detect/refute edges.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Edge removal after CI indicates independence (i.e., refutation rather than soft downweighting); in LACR the PC result contributes a +1/-1 vote to aggregate score S.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>If PC determines a pair is d-separated by some V', it refutes the direct-edge hypothesis (ζ=0).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>When PC outputs were injected into LACR aggregation: on ASIA adding PC to DOC increased F1 from 0.73 to 0.86; on CORONARY adding PC improved metrics to 0.875; on SACHS adding PC decreased F1 to 0.46 (indicating dataset-specific interactions).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>PC-only baseline numbers are reported in aggregate comparisons but specific standalone PC metrics vary by dataset; the paper shows that augmenting LLM/document evidence with PC sometimes helps and sometimes harms depending on alignment between data and literature.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>PC outputs can serve as a useful additional, independent vote to refute spurious edges when the underlying observational data align with literature evidence, but can degrade performance when the statistical data are out-of-date or misaligned with current domain knowledge; PC performs classical measured-confounder detection via CI testing but cannot address unmeasured confounding or selection bias without further corrections.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e692.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e692.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Direct causal prompt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Direct causal prompting of LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A straightforward prompting approach that asks an LLM directly whether variable A causes variable B (e.g., 'Is A a cause of B?'), requiring the model to perform complex causal reasoning from background knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Direct causal prompt</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Directly queries LLMs for causal edge existence/direction for each pair of variables, supplying definitions and variable descriptions. The paper frames this as a baseline and argues it is high-complexity for LLMs because ascertaining ζ(ij)=0 requires reasoning over an exponential number of conditioning sets in the worst case.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>N/A (prompting paradigm)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Not an experimental environment per se; a prompting strategy applied to LLMs using available KBs.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Reported to be less reliable than LACR's associational prompting approach; the paper argues such prompts require extensive causal reasoning capabilities from LLMs and are therefore less trustworthy.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Direct causal prompts are conceptually simple but demand that LLMs implicitly enumerate/consider all possible conditioning sets or possess deep causal reasoning; LACR instead reduces complexity by decomposing the task into associational queries aligned with constraint-based discovery, improving reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>An algorithm for fast recovery of sparse causal graphs <em>(Rating: 2)</em></li>
                <li>Recovering from selection bias in causal and statistical inference <em>(Rating: 2)</em></li>
                <li>Differentiable causal discovery under unmeasured confounding <em>(Rating: 2)</em></li>
                <li>Efficient causal graph discovery using large language models <em>(Rating: 2)</em></li>
                <li>Integrating large language models in causal discovery: A statistical causal approach <em>(Rating: 1)</em></li>
                <li>Are Large Language Models Simply Causal Parrots? <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-692",
    "paper_id": "paper-267897516",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "LACR",
            "name_full": "LLM Assisted Causal Recovery",
            "brief_description": "A retrieval-augmented LLM pipeline that performs constraint-based causal graph recovery by extracting conditional associational relationships from LLM background knowledge and retrieved scientific documents, then aggregating those judgments and applying constraint-based rules to produce a causal skeleton and orient edges.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "LACR (LLM Assisted Causal Recovery)",
            "method_description": "LACR breaks causal discovery into (1) edge-existence verification (skeleton construction) and (2) orientation. For skeleton construction it uses a deterministic Constraint‑Based (CC) prompt to extract conditional associational judgments α_KB(ij | V') from multiple knowledge bases (KBs): LLM background (BG), retrieved documents (DOC), and optional numerical output from a statistical CD method (PC). For each variable pair it issues a chain of LLM queries: background reminder, association verifier (zero-order association), association-type verifier (direct vs indirect—i.e., existence of a conditioning set that d‑separates), and association rechecker (verify mediators lie within V). Each KB yields one of {INDEPENDENT, DIRECTLY ASSOCIATED, INDIRECTLY ASSOCIATED, UNKNOWN}, mapped to ζ_KB(ij) ∈ {0,1} (edge absent/present). LACR then aggregates KB opinions by a simple additive scoring S (+=1 for DIRECTLY ASSOCIATED, +=-1 for INDEPENDENT or INDIRECTLY ASSOCIATED, UNKNOWN ignored) with a slight bias: remove edge if S ≤ 0. Orientation (LACR2) uses direct LLM causal-direction queries over adjacent pairs. Retrieval-Augmented Generation (RAG) fetches relevant scientific papers per variable pair to strengthen associational evidence.",
            "environment_name": "Real-world domain datasets (ASIA, SACHS, CORONARY)",
            "environment_description": "Static observational datasets (medical/biological/social domains) used as validation. These are not interactive or open-ended virtual labs; LACR instead uses retrieved literature and optional numerical datasets for evidence aggregation and inference.",
            "handles_distractors": true,
            "distractor_handling_technique": "Detection of indirect associations via conditional-independence style judgments: the CC prompt chain (association verifier → association type verifier → rechecker) asks the LLM to identify mediating (third) factors from the variable set V and to determine whether conditioning on them removes the association. Aggregation via majority voting across KBs and injection of PC algorithm outputs are used to counter spurious signals.",
            "spurious_signal_types": "Confounding/mediated associations (indirect paths), selection bias and dataset collection bias (discussed), measurement error/unmeasured confounders (recognized as limitations), and irrelevant/external-variable-mediated associations.",
            "detection_method": "LLM-based evidence extraction: analyze documents and background knowledge to answer whether pairwise association holds (α_KB(ij)) and whether there exists a mediating conditioning set within V that eliminates the association (mapping to INDIRECTLY ASSOCIATED). The rechecker step specifically verifies whether alleged mediators belong to V (to avoid external-distractor confounding). UNKNOWN responses indicate insufficient evidence and are discarded.",
            "downweighting_method": "Score aggregation (S) across KB voters: each KB vote contributes +1 for DIRECTLY ASSOCIATED and -1 for INDEPENDENT or INDIRECTLY ASSOCIATED; UNKNOWN votes are ignored. Edge removal occurs if S ≤ 0, introducing an intentional bias toward removing edges. Optionally PC algorithm outputs are added as additional ±1 votes.",
            "refutation_method": "Refutation is performed by (1) verifying that mediating variables are within the considered variable set (association rechecker), (2) treating UNKNOWN as unusable (discarding weak evidence), and (3) cross-checking/augmenting LLM-based judgments with statistical CD outputs (PC) and multiple independent document KBs (wisdom-of-the-crowd aggregation) to overturn spurious associations supported by single sources.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Reported per-knowledge-base experiments: On ASIA, using only BG (LLM background) LACR1 recovered the full skeleton (AP=1.0, AR=1.0, F1=1.0). Adding retrieved documents (DOC) reduced AP from 1.0 to 0.57 and F1 from 1.0 to 0.73, but adding PC outputs increased F1 back to 0.86. On CORONARY, BG-only gave AP/AR/F1=0.625; adding DOC+PC raised metrics to 0.875. On SACHS, BG-only was best, adding DOC decreased F1 slightly (~0.01) and adding PC decreased F1 to 0.46. Orientation (LACR2) achieved TEA=1.0 (perfect orientation of recovered true-positive edges) on ASIA and SACHS across KB variants.",
            "performance_without_robustness": "Baseline 'direct causal prompt' methods and some pure statistical baselines were compared; LACR (BG) outperformed several LLM baselines on ASIA and SACHS in skeleton recovery. Exact baseline numbers vary by dataset; e.g., pure LLM baselines reported worse skeleton recovery than LACR BG on ASIA (specific baseline figures not all enumerated in the paper).",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "LACR explicitly targets spurious/indirect associations by asking LLMs to identify mediators and by mapping conditional-association judgments to constraint‑based causal rules; aggregating multiple independent KBs (documents + background + PC outputs) via a voting scheme reduces reliance on any single (possibly spurious) source. Empirically, the choice of KB matters: background knowledge alone gave perfect skeleton recovery on ASIA but adding literature sometimes reduced agreement with legacy ground-truths (indicating either spurious signals in KBs or outdated ground-truths), and adding PC outputs generally helped recover/rectify edges. The rechecker and UNKNOWN policy help avoid making claims from weak/out-of-domain evidence. Limitations include no explicit handling of unmeasured confounders, dependence on retrieval quality, and non-interactive (non-experimental) setting.",
            "uuid": "e692.0",
            "source_info": {
                "paper_title": "Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "CCGC",
            "name_full": "Constraint-based Causal Graph Construction",
            "brief_description": "A class of constraint-based causal discovery procedures that infer skeletons by testing conditional independences and then orienting edges using rules derived from d-separation (e.g., PC-style algorithms).",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "Constraint-based Causal Graph Construction (CCGC)",
            "method_description": "CCGC infers causal skeletons by examining conditional associational relationships α(ij | V') across conditioning sets V'. If some V' d‑separates i and j (α(ij | V') = 0), the undirected edge is removed; otherwise it is kept. Orientation proceeds with standard constraint-based rules (v‑structures, propagation). LACR designs prompts to emulate the CCGC phase via LLM-extracted conditional-association judgments and then maps them to ζ_KB(ij).",
            "environment_name": "Statistical observational data / knowledge base (KB)",
            "environment_description": "Typically applied to observational datasets or any KB that can provide estimates of conditional independences; not inherently interactive.",
            "handles_distractors": true,
            "distractor_handling_technique": "Explicit conditional-independence testing across candidate conditioning sets (i.e., searching for sets V' that d-separate pairs) which can reveal mediators and indirect associations, thereby removing edges induced by measured confounders/mediators.",
            "spurious_signal_types": "Measured confounding (mediators), indirect associations via measured third variables, and selection bias insofar as it affects conditional independence tests (selection bias acknowledged as a threat).",
            "detection_method": "Systematic search over conditioning sets and CI tests (in LACR this is approximated by LLM answers about whether conditioning on particular V' eliminates association).",
            "downweighting_method": "Removal of edges when a conditioning set produces independence (i.e., deterministically downweighting direct-edge hypotheses by CI evidence).",
            "refutation_method": "If any conditioning set yields independence, the direct edge hypothesis is refuted (ζ=0). The method relies on faithfulness and correct CI determination.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "CCGC provides the theoretical foundation for LACR's prompting strategy: converting conditional-independence judgments into edge presence/absence decisions. The paper leverages CCGC to reduce LLM task complexity (associational reasoning rather than direct causal assertion) which improves reliability.",
            "uuid": "e692.1",
            "source_info": {
                "paper_title": "Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "PC",
            "name_full": "PC algorithm",
            "brief_description": "A classical constraint-based causal discovery algorithm that recovers causal skeletons and orients edges by iterative conditional independence testing and application of orientation rules.",
            "citation_title": "An algorithm for fast recovery of sparse causal graphs",
            "mention_or_use": "use",
            "method_name": "PC algorithm (Spirtes & Glymour family)",
            "method_description": "PC starts from a complete undirected graph and performs conditional independence tests of increasing conditioning set sizes to remove edges when a conditioning set d‑separates two nodes; after skeleton recovery it orients edges using v‑structure identification and propagation. In this paper PC is used as an injected numerical KB: its outputs are converted to ±1 votes in LACR's KB-aggregation score to supplement LLM/document judgments.",
            "environment_name": "Observational datasets (bnlearn package datasets used for validation)",
            "environment_description": "Standard static observational datasets (ASIA, SACHS, CORONARY) where conditional independence tests can be computed numerically; not an interactive environment.",
            "handles_distractors": true,
            "distractor_handling_technique": "Explicit conditional independence testing across candidate conditioning sets; removal of edges when conditioning removes association, thus detecting and removing edges due to measured mediators/confounders.",
            "spurious_signal_types": "Measured confounding/mediated associations and statistical artefacts resulting from sampling; limited against unmeasured confounders and selection bias unless corrected.",
            "detection_method": "Classical statistical CI tests applied to data (in experiments via PC). In LACR the PC result is imported as an additional KB vote to detect/refute edges.",
            "downweighting_method": "Edge removal after CI indicates independence (i.e., refutation rather than soft downweighting); in LACR the PC result contributes a +1/-1 vote to aggregate score S.",
            "refutation_method": "If PC determines a pair is d-separated by some V', it refutes the direct-edge hypothesis (ζ=0).",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "When PC outputs were injected into LACR aggregation: on ASIA adding PC to DOC increased F1 from 0.73 to 0.86; on CORONARY adding PC improved metrics to 0.875; on SACHS adding PC decreased F1 to 0.46 (indicating dataset-specific interactions).",
            "performance_without_robustness": "PC-only baseline numbers are reported in aggregate comparisons but specific standalone PC metrics vary by dataset; the paper shows that augmenting LLM/document evidence with PC sometimes helps and sometimes harms depending on alignment between data and literature.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "PC outputs can serve as a useful additional, independent vote to refute spurious edges when the underlying observational data align with literature evidence, but can degrade performance when the statistical data are out-of-date or misaligned with current domain knowledge; PC performs classical measured-confounder detection via CI testing but cannot address unmeasured confounding or selection bias without further corrections.",
            "uuid": "e692.2",
            "source_info": {
                "paper_title": "Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Direct causal prompt",
            "name_full": "Direct causal prompting of LLMs",
            "brief_description": "A straightforward prompting approach that asks an LLM directly whether variable A causes variable B (e.g., 'Is A a cause of B?'), requiring the model to perform complex causal reasoning from background knowledge.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Direct causal prompt",
            "method_description": "Directly queries LLMs for causal edge existence/direction for each pair of variables, supplying definitions and variable descriptions. The paper frames this as a baseline and argues it is high-complexity for LLMs because ascertaining ζ(ij)=0 requires reasoning over an exponential number of conditioning sets in the worst case.",
            "environment_name": "N/A (prompting paradigm)",
            "environment_description": "Not an experimental environment per se; a prompting strategy applied to LLMs using available KBs.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": "Reported to be less reliable than LACR's associational prompting approach; the paper argues such prompts require extensive causal reasoning capabilities from LLMs and are therefore less trustworthy.",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Direct causal prompts are conceptually simple but demand that LLMs implicitly enumerate/consider all possible conditioning sets or possess deep causal reasoning; LACR instead reduces complexity by decomposing the task into associational queries aligned with constraint-based discovery, improving reliability.",
            "uuid": "e692.3",
            "source_info": {
                "paper_title": "Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "An algorithm for fast recovery of sparse causal graphs",
            "rating": 2,
            "sanitized_title": "an_algorithm_for_fast_recovery_of_sparse_causal_graphs"
        },
        {
            "paper_title": "Recovering from selection bias in causal and statistical inference",
            "rating": 2,
            "sanitized_title": "recovering_from_selection_bias_in_causal_and_statistical_inference"
        },
        {
            "paper_title": "Differentiable causal discovery under unmeasured confounding",
            "rating": 2,
            "sanitized_title": "differentiable_causal_discovery_under_unmeasured_confounding"
        },
        {
            "paper_title": "Efficient causal graph discovery using large language models",
            "rating": 2,
            "sanitized_title": "efficient_causal_graph_discovery_using_large_language_models"
        },
        {
            "paper_title": "Integrating large language models in causal discovery: A statistical causal approach",
            "rating": 1,
            "sanitized_title": "integrating_large_language_models_in_causal_discovery_a_statistical_causal_approach"
        },
        {
            "paper_title": "Are Large Language Models Simply Causal Parrots?",
            "rating": 1,
            "sanitized_title": "are_large_language_models_simply_causal_parrots"
        }
    ],
    "cost": 0.014700499999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models
18 Jun 2024</p>
<p>Yuzhe Zhang 
Yipeng Zhang 
Yidong Gan yidong.gan@sydney.edu.au 
University of Sydney</p>
<p>CSIROData61 
Lina Yao 
University of New South Wales Sydney
Australia</p>
<p>Chen Wang 
Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models
18 Jun 20246CDA87B73FC078D3CC13F7FEAC3945CAarXiv:2402.15301v2[cs.CL]
Causal graph recovery is traditionally done using statistical estimation-based methods or based on individual's knowledge about variables of interests.They often suffer from data collection biases and limitations of individuals' knowledge.The advance of large language models (LLMs) provides opportunities to address these problems.We propose a novel method that leverages LLMs to deduce causal relationships in general causal graph recovery tasks.This method leverages knowledge compressed in LLMs and knowledge LLMs extracted from scientific publication database as well as experiment data about factors of interest to achieve this goal.Our method gives a prompting strategy to extract associational relationships among those factors and a mechanism to perform causality verification for these associations.Comparing to other LLM-based methods that directly instruct LLMs to do the highly complex causal reasoning, our method shows clear advantage on causal graph quality on benchmark datasets.More importantly, as causality among some factors may change as new research results emerge, our method show sensitivity to new evidence in the literature and can provide useful information for updating causal graphs accordingly.</p>
<p>Introduction</p>
<p>Estimating causal effect between variables from observational data is a fundamental problem to many domains including medical science (Höfler, 2005), social science (Angrist et al., 1996), and economics (Imbens and Rubin, 2015;Yao et al., 2021).It enables reliable decision-making from complex data with entangled associations.</p>
<p>While it is usually expensive and infeasible to investigate causal effects by the golden standard-randomized experiments-researchers employ causal inference (Pearl, 2010) to estimate causal effects from observational data.There are two main frameworks for causal inference: the potential outcome framework (Rubin, 1974) and the structural causal model (SCM) (Pearl, 1995).Priori causal structures, usually represented as Directed Graphical Causal Models (DGCMs) (Pearl, 2000;Spirtes et al., 2001), are often used to represent and analyze the causal relationships.These causal graphs help disentangle the complex interdependencies and facilitate the analysis of causal effects.Recovering causal graphs often relies on experts' knowledge or statistical estimation on experimental data (Spirtes and Glymour, 1991).Causal Discovery (CD) algorithms (Spirtes and Glymour, 1991) are the main statistical estimation-based methods that use conditional independence tests to assess associational relationships (called associational reasoning) for inferring causal connections (Spirtes et al., 2001;Chickering, 2002;Shimizu et al., 2006;Sanchez-Romero et al., 2018).</p>
<p>Consequently, the reliability of these algorithms is affected by the quality of data, which can be compromised by issues such as measurement error (Zhang et al., 2017), selection bias (Bareinboim et al., 2014) and unmeasured confounders (Bhattacharya et al., 2021) (See Example A.1 in Appendix A.1). Additionally, CD algorithms often assume certain distribution, such as Gaussian about data, which may fail to accurately reflect the complexity of real-world scenarios.</p>
<p>To mitigate the limitations, Large Language Models (LLMs) (Zhao et al., 2023) have recently been employed for causal graph recovery (Zhou et al., 2023).There are two main streams of these work: 1) directly outputting causal graphs (Choi et al., 2022;Long et al., 2022;Kıcıman et al., 2023); 2) assisting in refining causal graphs generated by statistical estimation-based methods Vashishtha et al. (2023); Ban et al. (2023).Most work have a straightforward way of using LLMs.They directly query the causal relationship between each pair of variables (Choi et al., 2022;Long et al., 2022;Kıcıman et al., 2023) by prompting LLMs with the definition of causality, task details and description of the variables of interest.They require LLMs to have extensive domain knowledge and capabilities to perform complex causal reasoning.Whether LLMs have sufficient knowledge in specific domains or whether they have causal reasoning capabilities are questionable (Kandpal et al., 2023;Zečević et al., 2023).</p>
<p>An alternative approach is to exploit LLMs' capabilities on associational reasoning, e.g., querying the conditional independences (CIs) and recover causal graphs based on extracted associations using CD algorithms (Cohrs et al., 2023).However, it remains difficult for LLMs to understand the CIs between variables, especially the independence conditioned on a large set of variables.(Jiralerspong et al., 2024) tries to inject statistical CI results into LLMs to improve direct causal relationship query results, but the efficacy varies among datasets.</p>
<p>We propose the LLM Assisted Causal Recovery (LACR) method to address these challenges.LACR enhances the knowledge base of LLMs with Retrieval Augmented Generation (RAG) (Lewis et al., 2020;Borgeaud et al., 2022) for reliable associational reasoning.We retrieve highly related knowledge base from a large scientific corpus that contains valuable insight hidden in datasets about associational/causal relationships among variables.We further enhance the accuracy of LCAR's causal recovery results by aggregating the collective extracted information from related literature according the Wisdom of the Crowd principle (Grofman et al., 1983).LACR also uses an associaitonal reasoning-based causal recovery prompt strategy which elaborately instructs the LLMs the mathematical intuitions behind conditional independence, and builds a surjection from conditional independences extracted by LLMs to causal relationships between variables.LACR is data-driven and dos not rely on task-specific knowledge for document retrieval or prompt design.It can serve as a causal graph recovery tool for generic tasks.</p>
<p>Our methodology provides a structured and systematic approach to inferring causal relationships, as it is grounded in a broader evidentiary base and subject to systematic validation.As LACR conducts associational reasoning on a reliable knowledge base, most of which provide evidences based on experimental data analysis, LACR largely overcomes the collection bias problem in statistical estimation-based CD algorithms.We discuss this in detail in Section 4 by pointing out the causal conflict between the well-known causal discovery results and recent research results extracted by LACR.</p>
<p>Our Contributions:</p>
<p>• We introduce a novel RAG-based causal graph recovery method that achieves better associational reasoning.The method shows its potential in accurate causal graph construction and overcoming data collection bias issues in traditional methods.</p>
<p>• We design an associational reasoning-based prompting strategy that reduce LLMs' task complexity to simple associational reasoning to improve the reliability of LLMs' results.The reliability gain further improve the quality of recovered causasl graphs.</p>
<p>• We conduct experiments in several well-known real-world causal graphs and demonstrate the efficacy of LACR.More importantly, based on the scientific evidence returned by our method, we show bias exists in the validation datasets widely used in the CD community, and suggest ways to improve.</p>
<p>Background</p>
<p>In this section, we introduce the preliminaries of the directed graphical causal models (DGCM) and the causal graph recovery problem.</p>
<p>Directed Graphical Causal Models</p>
<p>A Directed Graphical Causal Model (DGCM) is a tuple M = ⟨G, P ⟩.In the model, G = ⟨V, E⟩ is a Directed Acyclic Graph (DAG), also known as a causal graph, where the set of nodes
V = {v 1 , • • • , v n } represents random variables (with |V | = n), and E ⊆ {(v i , v j ) | v i , v j ∈ V, v i ̸ = v j } is a set of directed edges, also called causal edges, that encode causal relationships. Let Ḡ = ⟨V, Ē⟩ be the skeleton of DAG G, where each (v i , v j ) ∈ Ē
is an undirected edge, and it indicates that one of
(v i , v j ) and (v j , v i ) is in E. Let a sequence of distinct nodes ℓ = (v j 1 , v j 2 , • • • , v jm ) denote a path, such that for each i ∈ {1, 2, • • • , m − 1}, (v j i , v j i+1 ) ∈ Ē. A path is a causal path from v j 1 to v jm if for each i ∈ {1, 2, • • • , m − 1}, (v j i , v j i+1 ) ∈ E.
The joint probability distribution of all variables is denoted by P .Note that we do not consider any variable other than those in V , that is, we assume there is no so-called latent or exogenous variable.</p>
<p>Constraints of causal graphs.A causal graph is subject to a series of constraints on variables' associational relationships.Especially, the causal edges specify the causal relationships between variables.Given
(v i , v j ) ∈ E, v i is a direct cause of v j .
That is, when holding the other variables constant, varying the value of v i triggers a corresponding change in the value of v j , but not vice versa.This causal relationship thus entails the associational relationship between the variables, i.e., their marginal probability distributions P (v i ) and P (v j ) are associated (or correlated), which does not have the direction attribute.Notice that two variables can be associated even though they do not have a direct causal relationship between each other.Typical examples are that two variables linked by a causal path, and two variables pointed to by two causal paths that have the same starting node (which is usually called a covariate).The precise constraints follow an assumption of the causal graph called the Causal Markov Assumption.Assumption 2.1 (Causal Markov Assumption).In any causal graph, each variable is independent of its non-descendants conditioned on its parents in the causal graph.</p>
<p>Therefore, the structure of a causal graph implies graphical constraints called d-separation (Pearl, 2000) that specify a conditional associational relationship between variables.In the rest of this paper, for any given variable pair v i , v j ∈ V , we constantly use V ′ to denote an arbitrary subset of V \ {v i , v j }, unless otherwise specified.Definition 2.2 (d-separation).A variable set V ′ blocks a path ℓ if (i) ℓ contains at least one arrowemitting variable belonging to V ′ , or (ii) ℓ contains at least one collider (variable
v i is a collider if (v j i−1 , v j i ), (v j i+1 , v j i ) ∈ E) that does not belong to V ′ and has no descendant belonging to V ′ . If V ′ blocks all paths from v i to v j , V ′ is said to d-separate v i and v j .
If V ′ d-separates v i and v j , then the joint probability distribution P encodes that the two variables are independent conditioned on V ′ .Assumption 2.1 is a necessary condition for the encoding of the associaitonal relationship constraints in P .On the other hand, the following faithfulness assumption is a sufficient condition that P encodes such constraints.Assumption 2.3 (Causal Faithfulness Assumption).A joint distribution P does not encode additional conditional associational relationships other than those consistent with G's d-separation information.We call such P is faithful to G.</p>
<p>We now formally define the constraints that follow distribution P faithful to causal graph G. Let α(ij | V ′ ) ∈ {0, 1} be the conditional associational relationship between variables v i , v j ∈ V conditioned on variable set V ′ .α(ij | V ′ ) = 0 denotes that v i and v j are independent conditioned on V ′ according to P , and α(ij
| V ′ ) = 1 denotes associated. We write α(ij) when V ′ = ∅.
Then, by Assumptions 2.1 and 2.3 and Definition 2.2, we have that for
v i , v j ∈ V : 1. V ′ d-separates v i and v j =⇒ α(ij | V ′ ) = 0; 2. α(ij) = 1 and (v i , v j ) / ∈ Ē =⇒ ∃V ′ s.t. α(ij | V ′ ) = 0; 3. (v i , v j ) ∈ Ē =⇒ ∄V ′ s.t. α(ij | V ′ ) = 0.</p>
<p>Methodology</p>
<p>We now start to introduce our LLM-based method, called large language model assisted causal recovery (LACR), that uses a prompt strategy elaborately designed following the process of a statistical estimation-based CD method, called the constraintbased causal graph construction (CCGC).We first show how CCGC works.</p>
<p>Constraint-based Causal Graph</p>
<p>Construction: From Data to Causation</p>
<p>Based on Assumptions 2.1 and 2.3, we are able to partially construct the causal graph G from a knowledge base KB that is faithful to G by a statistical estimation-based method.In a nutshell, KB can be but not limited to data, the LLM's background knowledge, and external documents.For more details, see Section 3.2.1.We take data as the KB in CCGC.A KB is called faithful to G if it estimates a joint distribution that is faithful to G.</p>
<p>The process of CCGC can be divided into two phases: the edge existence verification phase, which first constructs the skeleton, and the orientation phase, which determines the direction of each undirected edge.LACR only uses the CCGC-based prompt strategy to conduct the edge existence verification, and therefore, we only introduce the first phase of CCGC.</p>
<p>For each pair of variables v i , v j ∈ V , we verify the existence of the undirected edge in between (i.e., whether (v i , v j ) ∈ Ē or not) by statistically testing whether v i and v j can be d-separated by any variable set
V ′ . Let αKB (ij | V ′ ) ∈ {0, 1} be an estimator of α(ij | V ′ ), based on KB. Next, based on a given KB that is faithful to G, we define ζ KB : V × V → {0, 1} as the causal edge existence mapping, such that ζ KB (ij) = 0 if ∃V ′ s.t. αKB (ij | V ′ ) = 0, otherwise ζ KB (ij) = 1.
ζ KB (ij) = 0 implies that we estimate there is no edge between v i and v j , since the pair of variables can be d-separated by at least one variable set.See Appendix A.1 for an example of CCGC's process.</p>
<p>Compared with LACR, most existing LLMbased causal graph construction methods directly query LLMs the causal relationships.With the introduction of CCGC, we next illustrate the limited reliability of such methods.</p>
<p>Limited Reliability of Direct Causal Prompt.We name the prompt used in such direct query of causal relationships as the direct causal prompt.Examples include "Is A a cause of B?" and "Does the change of A cause the change of B", which are wildly used in related work (Kıcıman et al., 2023;Choi et al., 2022;Long et al., 2022).Such prompt directly queries the causal edge existence (ζ KB (•)) and the causal direction.We argue that such direct prompting requires extensive causal reasoning capability from LLMs.The following proposition shows the high complexity hidden behind a direct causal prompt.Proof.To verify if ζ KB (ij) = 0, by the definition of ζ(ij), we need to check whether there exists a variable set V ′ such that V ′ d-separates v i and v j .That is, α KB (ij | V ′ ) = 0.Then, the worst case is that we need to check every combination of
V ′ ⊆ V {v i , v j }, which needs O(2 n−2 ) time.
We now start formally introducing the large language model assisted causal recovery (LACR) method, which first extracts the conditional associational relationships between variables, and determines the causal relationships following the process of CCGC (see Section 3.1).We implement such a process by a series of separated queries using the constraint-based causal prompt.The LACR consists of two steps: the edge existence verification (LACR 1) and orientation (LACR 2).See all of the original prompts in Appendix A.3.</p>
<p>LACR 1: Edge Existence Verification</p>
<p>In this phase, we construct the skeleton of the causal graph, i.e., verifying the existence of each edge without clarifying its direction.We use LLMs to mine the statistical evidence to verify the conditional associational relationship between each pair of variables and determine the existence of a causal edge (recall Section 3.1), from the retrieved scientific documents (corresponding to documentbased query), LLMs' internal knowledge (corresponding to background-based query), and statistical estimation-based output.To achieve this target, we design a prompt strategy that encodes the statistical principles of CCGC.</p>
<p>Constraint-Based Causal (CC) Prompt</p>
<p>In LACR, KB can be the LLM's background knowledge, external documents, and datasets.For each variable pair, namely v i and v j , we clarify their conditional associational relationship by mining the statistical evidence from KB.We conduct a chain of 4 queries to determine the final opinion of each piece of KB, namely, the background reminder, the association verifier, the association type verifier, and the association rechecker.However, if any KB does not contain sufficient information to determine the value of αKB (ij | V ′ ), we ask the LLM to give an answer UNKNOWN.We classify such knowledge bases as unusable, and they are discarded during the decision-making phase.</p>
<p>Background reminder.This prompt component helps the LLM to understand the full picture of the task, and avoid misinterpretation of variables' meaning.We aim to provide minimum external information about the task other than the names of the variables to the LLM.Therefore, we only give the full FACTOR list (i.e., the names of the variables), and specify the DOMAINS from which the variables are.For example, in the ASIA experiment dataset (see Section 4), all variables are from the domains of MEDICAL, BIOLOGY, AND SOCIAL SCIENCE.Finally, we ask the LLM to specify the meaning of each variable, as well as the interaction among them.</p>
<p>Association verifier.The component utilizes KR to verify the zero-order associational relationship between v i and v j , i.e., αKB (ij).The LLM is provided with an ASSOCIATION CONTEXT (an instruction of how to determine whether v i and v j is associated or not) and KB.Then, the LLM determines the relationship as ASSOCIATED (if
αKB (ij) = 1), INDEPENDENT (if αKB (ij) = 0),
or UNKNOWN, based on the statistical evidence extracted from KB.If the decision is an association, the LACR goes to the next query.</p>
<p>Association type verifier.Upon determining AS-SOCIATED between v i and v j , we further need to determine whether this association is "indirect" or "direct", i.e., whether there exists V ′ that can dseparate v i and v j .Based on the given KB and reasoning, the LLM is asked to read an ACCUSA-TION TYPE CONTEXT (an instruction of how to judge whether the association is indirect or direct based on KB).Intuitively, the ACCUSATION TYPE CONTEXT illustrates that if the association between v i and v j is mediated by variables from V ′ , then, the association is indirect, otherwise it is direct.To align precisely with CCGC, the ACCUSATION TYPE CONTEXT further explains that "the association mediated by third variables" means that the association is eliminated if we control the third variables constantly.The LACR goes to the final query if the decision is an INDIRECTLY ASSOCIATED.</p>
<p>Association rechecker.Considering the potential that the LLM can return INDIRECTLY ASSOCIATED because it judges that the association between v i and v j is mediated by external variables that are not from V .Since we do not consider external variables, we ask the LLM to verify whether the set of mediating variables includes any from V \ {v i , v j }.If yes, the association type should be corrected to DIRECTLY ASSOCIATED.</p>
<p>The CC Prompt is Deterministic</p>
<p>Using the above prompt strategy, we demonstrate that the LLM's return can determine the existence of causal edges based on a given KB.We first specify that the LLM's return based on the above prompt must be one from set {INDEPENDENT, DI-RECTLY ASSOCIATED, INDIRECTLY ASSOCIATED, UNKNOWN}.If the return is UNKNOWN, the KB is unusable.Then, for each usable KB, we have the following proposition showing that each usable KB can make decision deterministically.Proposition 3.2.For each variable pair v i and v j , the mapping from the conditional associational relationship space of v i and v j to the return set of each usable KB is a surjection, and the mapping from the return set of each usable KB to the range of ζ ij , i.e., {0, 1}, is also a surjection.We first show the first half of the proposition, i.e., the mapping from the conditional associational relationship space between v i and v j , i.e., (α KB (ij | V ′ )) V ′ ⊆V {v i ,v j } , to LLM's return space based on each usable KB, i.e., {INDEPEN-
DENT, DIRECTLY ASSOCIATED, INDIRECTLY AS- SOCIATED} is a surjection. Note that (α KB (ij | V ′ )) V ′ ⊆V {v i ,v j } forms a 2 |V |−2 -dimensional vec- tor, recording α KB (ij | V ′ ) ∈ {0
, 1} for all possible V ′ .We discuss three exclusive cases:</p>
<ol>
<li>
<p>αKB (ij) = 0.That is, the zero-order conditional associational relationship between v i and v j is independent.This case is mapped to LLM return INDEPENDENT.</p>
</li>
<li>
<p>For all possible V ′ , αKB (ij | V ′ ) = 1.The case denotes that v i and v j are always associated conditioned on any possible V ′ , and therefore, this case is mapped to LLM return DIRECTLY ASSOCIATED.</p>
</li>
</ol>
<p>αKB (ij) = 1 and ∃V
′ such that |V ′ | ≥ 1 and αKB (ij | V ′ ) = 0.
In this case, controlling variables in V ′ , the statistical association between v i and v j is eliminated, and then it is mapped to LLM return INDIRECT ASSOCI-ATED.</p>
<p>We then show the second half of the proposition, i.e., the mapping from {INDEPENDENT,
DIRECTLY ASSOCIATED, INDIRECTLY ASSOCI- ATED} to {ζ KB (ij) = 0, ζ KB (ij) = 1} is a surjec- tion.
If the return is DIRECTLY ASSOCIATED, the KB specifies that v i and v j cannot be d-separated, and therefore, it is mapped to ζ KB (ij) = 1.On the other hand, if LLM return is INDEPENDENT or IN-DIRECTLY ASSOCIATED, then, it indicates that V ′ exists that can d-separate v i and v j , where INDE-PENDENT corresponds to V ′ = ∅.Therefore, these two last cases correspond to ζ KB (ij) = 0.</p>
<p>LACR 1</p>
<p>With the above CC prompt, we are ready to introduce LACR 1 (Algorithm 1).We initialize the algorithm by setting the skeleton graph Ḡ as a complete undirected graph Ḡc , giving each variable pair v i , v j a pre-retrieved set of k relevant scientific documents as the documentbased knowledge base
DOC = {DOC ij = {DOC 1 ij , • • • , DOC k ij }} v i ,v j ∈V, s.t., v i ̸ =v j . Then, for Algorithm 1 LACR 1 1: Input: Ḡ ← Ḡc , DOC, D 2: for ∀v i , v j ∈ V , s.t., v i ̸ = v j do 3: S = 0 4: for KB ∈ DOC ij ∪ {BG} do 5: if ζKB (ij) = 1 then 6: S+ = 1 7:
else if ζKB (ij) = 0 then 8:
S+ = −1 9:
if S ≤ 0 then 10: Note that using the score S to aggregate each KB's "opinion" for each variable pair is equivalent to making the collective decision of ζ(ij) by the simple majority voting rule (Brandt et al., 2016).We slightly bias the decision towards ζKB (ij) = 0 by the setting of removing an edge if S ≤ 0, since generally, the LLM's decision biases towards DI-RECTLY ASSOCIATED.We use this biased setting because (1) almost KBs cannot load the evidence showing αKB (ij | V ′ ) for all possible V ′ , and (2) if most retrieved documents are unusable (no research report on v i and v j 's association), then, it is more possible that v i and v j are not associated.By the theory of the Wisdom of the Crowd, LACR's decision tends to be more accurate than querying a single knowledge base, and it can be improved by adding more relevant documents (see a detailed description in Appendix 3.2.3).
Ḡ ← Ḡ(v i , v</p>
<p>LACR Expects To Enhance Skeleton Estimation Accuracy</p>
<p>The theory of Wisdom of the Crowd (Grofman et al., 1983) states that if (1) each individual voter can make the correct decision better than random decision (e.g., by a toss), and (2) voters make their decision independently, then, the accuracy of the collective decision made by simple majority monotonically increases with the number of voters.In LACR, each KB can be seen as a voter.Generally the above conditions tend to be guaranteed because (1) both BG and DOC have high quality and the delivered information is better than random information, and (2) different research papers deliver their results in a relatively independent way because of scientific integrity.Therefore, LACR's decision tends to be more accurate than querying single knowledge base, and it can be improved by adding more relevant documents.</p>
<p>LACR 2: Orientation</p>
<p>Starting at the skeleton output by LACR 1, we continue to determine the direction of each edge in the skeleton.In LACR 2, we simply utilize direct query to LLM for the orientation task due to LLMs' high performance on causal orientation tasks (Kıcıman et al., 2023).For each pair of adjacent variables in the skeleton, we use a two-step prompt strategy: Background reminder.Similar to LACR 1, we provide the main variables and the domain information of the task, and ask the LLM to clarify the variables' meanings, as well as their interaction.</p>
<p>Orienting.With the above clarification, we ask the LLM to thoroughly understand the given KB and a CAUSAL DIRECTION CONTEXT, that specifies that if variable A is the cause of variable B, then, the change of A's value causes a change of B's value, but not vice versa.Then, we ask the LLM to give its decision based on all of the above information.</p>
<p>Experiments</p>
<p>In this section, we first introduce the ground truth datasets and how we collect three research literature pools.Then we introduce the settings of our solution and baselines.Finally, we evaluate the pruning and orienting results, respectively.</p>
<p>Experiment Data</p>
<p>Validation datasets.We validate our method on four datasets (namely, ASIA, SACHS, and CORO-NARY).All datasets have reported causal graphs (see Appendix A.2) based on real-world data.It is worth noting that, we only limit the selection of validation datasets to real-world datasets because LACR uses a realistic knowledge base.ASIA (lau, 1988).The ASIA dataset has 8 nodes (from domains of medical, biology, and social sci-ence) and 8 edges, revealing the potential reasons and symptoms of lung diseases.SACHS (Sachs et al., 2005).The SACHS dataset has 11 nodes (from the medical and biological domains) and 16 edges.It uncovers the interaction among proteins related to several human diseases.CORONARY (Reinis et al., 1981).The CORO-NARY dataset has 6 nodes (from the medical and biological domains) and 9 undirected edges, revealing the causal relationship among several potential reasons of coronary heart disease.We only use it to validate LACR 1 because the edges are undirected.</p>
<p>Experimental Settings</p>
<p>We use GPT-4o in the following experiments.</p>
<p>Research document pool construction.In our experiment, we automatically build the pre-retrieved document set for each variable pair (Initialization in Algorithm 1) in two steps:</p>
<p>(1) Relevant paper search: We search 20 paper titles by querying "name[v i ] and name[v j ]" to the Google Scholar engine using the SerpApi (Ser-pApi), and rank the papers by Google Scholar's default relevance ranking.</p>
<p>(2) Paper download: Based on the aforementioned ranked paper title list, we use the PubMed API 1 to download the papers.For each paper title, we prioritize downloading the full document from the PubMed Central (PMC) database, and only download the abstract document from the PubMed database if the full version is not available in PMC. for each variable pair, we download up to 10 documents from the top of the ranked title list (note that some papers are unavailable in PubMed).Statistical causal discovery method.In the validation of LACR 1, additional to LLM, we also test the impact of injecting statistical estimation-based results into the decision-making phase.That is, adding point 1 (resp.−1) to score S if the statistical estimation-based method determines ζKB (ij) = 1 (resp.ζKB (ij) = 0) in Algorithm 1, where KB is numerical data.We use the Peter-Clark (PC) (Spirtes et al., 2001) algorithm as the statistical estimationbased method.We import the data from the bnlearn package (Scutari et al., 2019).Baseline methods.We survey recent LLM-based causal graph construction methods, and for each dataset, we select the baseline method with the best performance.For each dataset, we present two types of baseline LLMs: baseline LLM1, which is a pure LLM-based method, and baseline LLM2, which is a hybrid method combining a statistical estimation-based and an LLM-based method.We do not compare LACR to any baseline method on the CORONARY dataset as the dataset's absence in such methods' validation.</p>
<p>Validation metrics.We measure LACR 1 and LACR 2 by different metrics.For LACR 1, we show the the adjacency precision (AP), the adjacency recall (AR), the F1 score, and the Normalized Hamming Distance (NHD), as follows.First, we count three attributes of each graph: true positive (TP): the number of edges that are successfully recovered, false positive (FP): the number of edges that are recovered but different from the ground truth graph, and false negative (FN): the number of edges that exist in the ground truth but not recovered in our constructed graph.Then, we compute AP: TP TP+FP , AR: TP TP+FN , F1: 2AP * AR AP +AR , and NHD: FP+FN n 2 , where n is the number of variables.Intuitively, NHD is the number different edges between two graphs, normalized by n 2 .</p>
<p>In the validation of LACR 2, we simply compute the True Edge Accuracy (TEA), i.e., the ratio of correctly oriented edges among all true positive edges in LACR 1's output skeleton.</p>
<p>Evaluation</p>
<p>We now first present observations based on experimental results for three datasets, which contains Edge Existence Verification (Section 4.3.1)and Orientation (Section 4.3.2),followed by a comprehensive analysis of the overall results (Section 4.3.3).</p>
<p>ASIA SACHS LACR2 (BG
) 1 1 LACR2 (DOC) 1 1 LACR2 (PC) 1 1
Table 2: The TEA of LACR 2 on datasets of ASIA, SACHS, based on LACR 1's output skeleton on KB of BG, DOC, and PC, respectively.</p>
<p>Observation on Edge Existence Verification</p>
<p>We present the performance of LACR 1 on causation existence verification with different knowledge bases KB in the section.The orienting performance will be shown in the next section.Table 1 lists the performance of all compared methods, where BG denotes only LLM's background knowledge, DOC denotes both LLM's background knowledge and the fixed number of documents, and PC denotes DOC plus the results output by the PC algorithm.</p>
<p>We have the following observations:</p>
<p>ASIA.We have three observations from the experimental results on the ASIA dataset.First, LACR 1 achieves the best performance when relying solely on BG.It successfully recovers the full skeleton and outperforms the high performance of the pure LLM method in (Jiralerspong et al., 2024).Second, adding retrieved documents into KB reduces performance (AP from 1 to 0.57, and F1 score from 1 to 0.73) according to the given ground truth in (lau, 1988).Third, by further aggregating the output of the PC algorithm, the F1 score increases from 0.73 to 0.86 compared to the ground truth in (lau, 1988).</p>
<p>CORONARY (CORO).</p>
<p>The results differ notably from those based on the ASIA dataset, LACR 1 with only the LLM's background knowledge achieves the worst performance, with values of 0.625 for all of AP, AR, and F1 scores.By adding documents and the PC algorithm into KB, all metrics increase, reaching 0.875.</p>
<p>SACHS.</p>
<p>We have three observations from the results on the SACHS dataset.First, the best performance of LACR 1 is achieved using only the LLM's background knowledge, outperforming the baseline method (combined method of LLM and hybrid statistical methods of DirectLiNGAM).Second, adding documents as the knowledge base slightly decreases the F1 score by 0.01.Third, with the PC algorithm's output, the F1 score reduces to 0.46, which is worse than the baseline method.</p>
<p>LACR 2: Orientation</p>
<p>The results of LACR 2, shown in Table 2, show that TEA is 1 (i.e., orienting all TP edges correctly) on both ASIA and SACHS, based on all KB.We can observe that, upon successfully recovering causal edges by LACR 1, the orientation accuracy is high, reaching 1 for all knowledge bases and all datasets.It demonstrates the efficacy of the orientation prompt as well as LLM's capability for causal orientation reasoning.We conjecture that the success of this task strongly depends on the rich evidence stored in the scientific literature, and the easy understandability of such evidence, compared to the extraction of associational relationship.</p>
<p>Overall Results Analysis</p>
<p>By summarizing the overall performance of LACR, it is worth noticing the following points: LACR's performance tends to monotonically increase by taking more KB with high quality and readability.Observing LACR's performance on ASIA and CORONARY, we notice that our methods generally perform better with high-quality and readability of the input documents and statistical results.While we discuss the performance drop of LACR1 (DOC) on the ASIA dataset later, the overall trend coincides with the Condorcet theorem (Grofman et al., 1983) in voting theory, which suggests that aggregating diverse, high-quality inputs leads to better outcomes.LACR performs differently on tail and non-tail data.We observe that LACR performs better on ASIA and CORONARY datasets compared to the SACHS dataset.This is because the terms in ASIA and CORONARY are more common to LLMs during training.In contrast, SACHS mainly contains symbols with specific meanings in a specific area.Despite feeding scientific documents to LACR on all datasets, the lack of prior knowledge of these symbols in the training phase limits LLMs' understanding of their meanings, resulting in hallucinations.This has been observed in RAG-based legal research tools (Magesh et al., 2024).</p>
<p>Updating on the current ground truth causal graphs is necessary.We found, through LACR's responses, strong evidence from domain research (see details in Appendix 4.4.1)indicating that an update to the ground truth causal graphs is necessary.For example, on the ASIA dataset, the ground truth being outdated led to reduced performance when using additional documents.Similarly, for the CORONARY dataset, the improvement in performance with added documents and the PC algorithm suggests that the ground truth for CORO-NARY is more current compared to ASIA.</p>
<p>Refining the Ground Truth (ASIA and CORONARY)</p>
<p>The ground truth causal graph needs refinement because it is outdated and significantly differs from current SOTA domain knowledge.Additionally, we aim to determine if the LLM can identify new causal relationships based on SOTA literature.In this part, we present the observations and analyses on the refined ground truth causal graphs based on the refined ASIA and CORONARY datasets.</p>
<p>We first show the evidences returned by the LACR supporting the refinement of the ground truths in Section 4.4.1, and then we discuss how refined graph truth affects performance from three perspectives: causal inferring based on LLM'S background knowledge BG, external literature DOC, and statistic data PC in Section 4.4.2.</p>
<p>Evidences of Ground Truth Refinement</p>
<p>ASIA Smoking and Tuberculosis In the documents (Wang and Shen, 2009;Horne et al., 2012;Kim et al., 2022;Wang et al., 2018;Gupta et al., 2022;Lindsay et al., 2014;Amere et al., 2018;Alavi-Naini et al., 2012) fed into LLM as the KB, strong evidence shows that Smoking and Tuberculosis are associated, and the association cannot be eliminated by controlling the other variables in the ASIA dataset.This conflicts against the conditional associational relationship between these two variables in the ground truth causal graph (Appendix A.2), since both of the only two paths have a collider, which indicates that Smoking and Tuberculosis are independent from each other.Based on the scientific evidence returned by LACR, a causal link exists between the two factors.</p>
<p>Bronchitis and X-ray Documents based on LACR's response, (Jin et al., 2023;Ntiamoah et al., 2021) show that an association exists between Bronchitis and Positive X-ray.(Chen et al., 2020) further develops a deep-learning-based method to detect bronchitis directly from X-ray reports for children with age from 1-17 years old.The evidence shows an association between the two variables, and the association is not mediated by the variable "Smoking" as shown in the causal graph.Therefore, we add a causal edge between Bronchitis and X-ray in the ground truth causal graph.</p>
<p>CORONARY Strenuous Mental Work and Family Anamnesis Of Coronary Heart Disease</p>
<p>According to the ground truth causal graph skeleton (Reinis et al., 1981), there is a direct causal relationship between variable Strenuous Mental Work and variable Family Anamnesis Of Coronary Heart Disease.However, according to the evidence returned by our method and the intuitive description in (Reinis et al., 1981), we observe that this causal linkage should be removed with high probability.By (Edwards, 2000) (p.26), this edge is not intuitively expected though it is recovered by the Bayesian learning method.Additionally, non of LACR's responses suggests the direct association between the two variables, and moreover, it returns evidences showing the positive probability to remove the edge.(Wright et al., 2007) shows that people with Family Anamnesis Of Coronary Heart Disease are easier to react to mental stress from work by higher Systolic Blood Pressure.(Hintsa et al., 2010) shows that the association between psychosocial factors at work and coronary heart disease is largely independent from the Family Anamnesis Of Coronary Heart Disease.</p>
<p>Systolic Blood Pressure and Family Anamnesis Of Coronary Heart Disease LACR also returns evidence (Barrett-Connor and Khaw, 1984) showing that Family Anamnesis of Coronary Heart Disease and Systolic Blood Pressure are associated even after the adjustment of several variables including Smoking.We therefore also add this edge between the two variables.</p>
<p>Validation On The Refined Ground Truth</p>
<p>Background Knowledge BG.The performance relying solely on background knowledge BG varies between the two datasets.In the ASIAN dataset, all results slightly drop down, whereas in the dataset, results improve.A possible reason is that the background knowledge BG related to ASIA is outdated, while the knowledge BG for CORONARY is more current.Consequently, when the ground truth is updated based on new domain-specific knowledge, the outcomes are different significantly between the datasets.External Literature DOC.Incorporating DOC significantly increases performance for both datasets, as the refind ground truth better aligns with SOTA research trends, demonstrating the importance of up-to-date and relevant domain knowledge in im- proving model accuracy.</p>
<p>Statistic Data PC.Different from the results of incorporating DOC, adding PC's results consistently worsens performance, highlighting the PC-based solution is using an outdated dataset compared to updated SOTA knowledge.As the ground truth evolves to reflect current research advancements, the relative performance of PC-based results diminishes.These findings emphasize the importance of up-to-date domain-specific knowledge for accurate causal graph recovery.</p>
<p>Conclusion</p>
<p>In this paper, we proposed a novel LLM-based causal graph construction method called LACR which uses the constraint-based causal prompt strategy designed according to the constraint-based causal graph construction (CCGC) method.Comparing to most existing LLM-based causal graph construction methods, that use the direct causal prompt to query LLMs to do highly complex causal reasoning, LACR mainly relies on LLMs to do low-complexity associational reasoning, and follows the process of CCGC to determine the causal relationships.For accurate associational reasoning, we utilize LLMs' RAG feature to extract statistical evidence with high relevance and quality from a large scientific corpus.Lastly, we validate LACR's efficacy on several well-known datasets and show LACR's outstanding performance among LLM-based methods.More importantly, LACR's responses show the conflict between the ground truths and SOTA domain research, which requests a refinement of the validation ground truths.</p>
<p>Limitations</p>
<p>We first address three technical limitations of the current version of LACR.The first is the paper search accuracy.The pre-retrieved document set needs high quality and relevance to provide relevant evidence.Therefore, we conjecture that using refined queries and other search engines can enhance the performance.The second limitation is LLMs' understanding on highly professional documents.Through our experiments, we found that LLMs' poor comprehension capability on specific domains, e.g., the SACHS dataset, limits LACR's performance.An optional solution is to fine-tune LLMs to better understand such documents.The third is the complexity of LACR.The method needs to query each variable pair (O(n 2 )), and for each variable pair, multiple documents need to be queried.</p>
<p>We then address other practical limitations.What comes first is the need of up-to-data practical validation datasets and causal graphs in causal discovery community.Many validation datasets are synthesized, which are not usable in such practical knowledge-based methods.The second practical limitation is the access of scientific papers.In our experiment, we focus on biomedical datasets for the accessibility of research papers in PubMed, however, the full contexts of most of the papers are not open accessible.It would open the possibility of overall better understanding of causal relationships if full documents are accessible in more research domains and broader scientific databases.Yu Zhou, Xingyu Wu, Beicheng Huang, Jibin Wu, Liang Feng, and Kay Chen Tan.2024.Causalbench: A comprehensive benchmark for causal learning capability of large language models.arXiv preprint arXiv:2404.06349.</p>
<p>A Appendix</p>
<p>A.1 Examples</p>
<p>As follows, we first show an example of statistical estimation-based methods' vulnerability to a type of data bias, the so-called selection bias (Bareinboim et al., 2014).</p>
<p>Example A.1.Consider that we would like to investigate the causal relationship of three variables: A (human age), G (human gender), and D (some disease).Assume that the true causal graph is the left figure in Figure 1.Generally speaking, human age and gender are associated because female has a longer average lifespan.Assuming that this association is only significant for A ≥ 60.However, if each point in a dataset has age under 60, we cannot observe significant difference between the population of male and female.Then, we would recover the causal graph as the right figure in Figure 1.</p>
<p>The second example shows the processing of a well-known constraint-based causal graph discovery algorithm called PC algorithm.</p>
<p>A.2 Additional Experiment Details</p>
<p>The ground truth causal graphs of all datasets in Section 4.  (Sachs et al., 2005).</p>
<p>A.3 Prompts</p>
<p>A.3.1 Association Context</p>
<p>The association relationship between two factors A and B can be associated or independent , and this association relationship can be clarified by the following principles :</p>
<p>1.If A and B are statistically associted or correlated , they are associated , otherwise they are independent .2. The association relationship can be strongly clarified if there is statistical evidence supporting it .3. If there is no obvious statistical evidence supporting the association relationship between A and B , it can also be clarified if there is any evidence showing that A and B are likely to be associated or independent statistically .4. If there is no evidence to clarify the association relationship between A and B , then it is unknown .</p>
<p>A.3.2 Association Type Context</p>
<p>If two factors A and B are associated , they may be directly associated or indirectly associated with respect to a set of Given Third Factors , and it can be clarified by the following principle :</p>
<p>1.The first principle is to try to find statistical evidence from the given knowledge to clarify the following association types .If you cannot find statistical evidence , at lease find evidence that is likely to be able to statistically clarify the association type between A and B .If no obvious evidence can be found , the association type is unknown .</p>
<p>A.3.3 Association Background Reminder</p>
<p>As a scientific researcher in the domains of { domain }, you need to clarify the statistical relationship between some pairs of factors .You first need to get clear of the meanings of the factors in { factors } , which are from your domains , and clarify the interaction between each pair of those factors .</p>
<p>A.3.4 LLM Association Query (with documents)</p>
<p>Your task is to thoroughly read the given ' Document '.Then , based on the knowledge from the given ' Document ', try to find statistical evidence to clarify the association relationship between the pair of ' Main factors ' according to the ' Association Context ' ( delimited by double dollar signs ) .Consider the given document and the association context .Answer the ' Association Question ' , write your thoughts , and give the reference in the given document .Respond according to the first expected format ( delimited by double backticks ) .Your task is to thoroughly read the ' Given document ' to solve a task .Your task is : based on the ' Given document ' , try to find statistical evidence to clarify the direction of the causal relationship between the pair of ' Main factors ' according to the ' Causal direction context ' ( delimited by double dollar signs ) .</p>
<p>Proposition 3. 1 .
1
Assuming that estimating αKB (ij | V ′ ) for a given V ′ needs O(1) time, inferring ζ KB (ij) requires O(2 n−2 ), where n = |V |.</p>
<p>Proof.For each usable knowledge base KB, any possible return through the CC prompt must from the set {DIRECTLY ASSOCIATED, INDIRECTLY AS-SOCIATED, INDEPENDENT}.</p>
<p>Example A. 2 .Figure 1 :Figure 2 :
212
Figure 1: Causal graphs in Example A.1: left-the truth causal graph; right-recovered causal graph by the biased data.</p>
<ol>
<li>If the evidence shows that any factors from the Given Third Factors mediate the association between A and B , then A and B are indirectly associated via these factors .3. If the evidence shows that by controlling any factors from the Given Third Factors , A and B are not associated any more , then A and B are associated indirectly .4. If the evidence shows that A and B are still associated even if we control any of the given third factors , then A and B are directly associated . 5. If you think A and B are indirectly associated via any of the given third factors , it must be true that : (1) A and the third factors are directly associated ; (2) B and the third factors are directly associated .</li>
</ol>
<p>if you chose option C above .Otherwise , provide a supporting sentence from the document for your choice ] `À.3.5LLMAssociation Type Query (with documents)Read and understand the Association Type Context .Consider carefully the role of any of the third factors appearing according to the Association Type Context .Then , based on your thoughts so far , answer the ' Association Type Question ' with the ' Given Third Factors ', write your thoughts , and give your reference in the given document .Respond according to the expected format ( delimited by triple backticks except for { factorA } and { factorB } Association Type Question : Are { factorA } and { factorB } directly associated or indirectly associated if you chose option C above .Otherwise , provide a supporting sentence from the document for your choice ] Intermediary Factors : [ Skip this if you did not choose D or C above .Otherwise list all factors involved in this indirect association relationship , each separated by a comma ] <code>À .3.6 LLM Association Query (with background knowledge) Your task is to thoroughly use the knowledge in your training data to solve a task .Your task is : based on your background knowledge , try to find statistical evidence to clarify the association relationship between the pair of ' Main factors ' according to the ' Association Context ' ( delimited by double dollar signs ) .Consider your background knowledge and the association context .Answer the ' Association Question ', and write your thoughts .Respond according to the ' First Expected Format ' ( delimited by double backticks ) .Read and understand the ' Association Type Context '.Consider carefully the role of any of the third factors appearing according to the Association Type Context .Then , based on your thoughts so far , answer the ' Association Type Question ' with the ' Given Third Factors ' , and write your thoughts .Respond according to the Second Expected Format ( delimited by except for { factorA } and { factorB } Association Type Question : Are { factorA } and { factorB } directly associated or indirectly associated if you did not choose D or C above .Otherwise list all factors involved in this indirect association relationship , each separated by a comma ]</code>À .3.8 LLM Rethink Query If none of the Intermediary Factors you found is not in the Given Third Factor list , then , the association type between A and B is direct association .Check your above response , and answer the Association Type Question again .Respond according to the Second Expected Format ( delimited by triple backticks ).Given Third Factors : { factors } except for { factorA } and { factorB } Association Type Question : Are { factorA } and { factorB } directly associated or indirectly associated if you did not choose D or C above .Otherwise list all factors involved in this indirect association relationship , each separated by a comma ] ``À .3.9 Causal Background Reminder As a scientific researcher in the domains of { domain } , you need to clarify the statistical relationship between some pairs of factors .You first need to get clear of the meanings of { factorA } and { factorB } , which are from your domains , and clarify the interaction between them .A.3.10 LLM Causal Direction Query (with background knowledge) Your task is to thoroughly use the knowledge in your training data to solve a task .Your task is : based on your background knowledge , try to find statistical evidence to clarify the direction of the causal relationship between the pair of ' Main factors ' according to the ' Causal direction context ' ( delimited by double dollar signs ) .Consider according to your background knowledge and the ' Causal direction context '.Answer the ' Causal direction question ', and write your thoughts .Respond according to the ' Expected Format ' ( delimited by double backticks ) .</p>
<p>each variable pair, we query the LLM by the CC prompt to estimate ζKB (ij) based on each of the given documents provided in DOC ij and the LLM's background knowledge BG.If the decision of the LLM is INDIRECTLY ASSOCIATED or IN-</p>
<p>j ) 11: Return:Ḡ DEPENDENT, i.e., ζKB (ij) = 0, by Proposition 3.2, we add -1 point to the score S, if the decision is DIRECTLY ASSOCIATED (i.e., ζKB (ij) = 1), we add 1 point to S, otherwise, we do not change S if LLM answers UNKNOWN based on KB.After considering all of the LLM's decisions for v i and v j , if the final score S &gt; 0, we keep the undirected edge (v i , v j ); otherwise, we remove it from Ḡ. Finally, the algorithm returns the skeleton after querying each variable pair based on all KBs.</p>
<p>First thoroughly read and understand the Given document and the ' Causal direction context '.Then , Answer the ' Causal direction question ', and write your thoughts .Respond according to the ' Expected Format ' ( delimited by double backticks ) .
Local computations with probabilities on graphical structures and their application to expert systems. Journal of the Royal Statistical Society: Series B (Methodological). 502</p>
<p>Association between tuberculosis and smoking. Roya Alavi-Naini, Batool Sharifi-Mood, Maliheh Metanat, International journal of high risk behaviors &amp; addiction. 12712012</p>
<p>Contribution of smoking to tuberculosis incidence and mortality in high-tuberculosis-burden countries. Pratibha Genet A Amere, Nayak, D Argita, Salindri, Matthew J Venkat Narayan, Magee, American journal of epidemiology. 18792018</p>
<p>Identification of causal effects using instrumental variables. Joshua D Angrist, Guido W Imbens, Donald B Rubin, Journal of the American statistical Association. 914341996</p>
<p>From query tools to causal architects: Harnessing large language models for advanced causal discovery from data. Taiyu Ban, Lyvzhou Chen, Xiangyu Wang, Huanhuan Chen, 2023</p>
<p>Recovering from selection bias in causal and statistical inference. Elias Bareinboim, Jin Tian, Judea Pearl, 10.1609/aaai.v28i1.9074Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence201428</p>
<p>Family history of heart attack as an independent predictor of death due to cardiovascular disease. Elizabeth Barrett, -Connor , K-T Khaw, Circulation. 6961984</p>
<p>Differentiable causal discovery under unmeasured confounding. Rohit Bhattacharya, Tushar Nagarajan, Daniel Malinsky, Ilya Shpitser, The 24th International Conference on Artificial Intelligence and Statistics, AISTATS 2021. PMLR2021. April 13-15, 2021130of Proceedings of Machine Learning Research</p>
<p>Improving language models by retrieving from trillions of tokens. Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, International conference on machine learning. PMLR2022</p>
<p>Handbook of computational social choice. Felix Brandt, Vincent Conitzer, Ulle Endriss, Jérôme Lang, Ariel D Procaccia, 2016Cambridge University Press</p>
<p>Diagnosis of common pulmonary diseases in children by x-ray images and deep learning. Kai-Chi Chen, Hong-Ren Yu, Wei-Shiang Chen, Wei-Che Lin, Yi-Chen Lee, Hung-Hsun Chen, Jyun-Hong Jiang, Ting-Yi Su, Chang-Ku Tsai, Ti-An Tsai, Scientific Reports. 101173742020</p>
<p>Optimal structure identification with greedy search. David Maxwell, Chickering , Journal of machine learning research. 32002. Nov</p>
<p>Kristy Choi, Chris Cundy, Sanjari Srivastava, Stefano Ermon, arXiv:2210.12530Lmpriors: Pre-trained language models as task-specific priors. 2022arXiv preprint</p>
<p>Vasileios Sitokonstantinou, Gherardo Varando, and Gustau Camps-Valls. Kai-Hendrik Cohrs, Emiliano Diaz, AAAI 2024 Workshop on. 2023Are Large Language Models Simply Causal Parrots?</p>
<p>Introduction to graphical modelling. David Edwards, 2000Springer Science &amp; Business Media</p>
<p>Thirteen theorems in search of the truth. N Bernard, Guillermo Grofman, Scott L Owen, Feld, Theory and Decision. 151983</p>
<p>Prevalence of tobacco consumption and smoking and its effect on outcome among microbiologically confirmed new pulmonary tuberculosis patients on daily regimen of dots in amritsar city. Himanshu Gupta, Sanjeev Mahajan, Mohan Lal, Adarshjot Kaur Toor, Shyam Sunder Deepti, Naresh Chawla, Journal of Family Medicine and Primary Care. 1152022</p>
<p>Do family history of chd, education, paternal social class, number of siblings and height explain the association between psychosocial factors at work and coronary heart disease? the whitehall ii study. Hintsa, Shipley, Gimeno, Elovainio, Chandola, L Jokela, J Keltikangas-Järvinen, Vahtera, Marmot, Kivimäki, Occupational and environmental medicine. 6753302010</p>
<p>Causal inference based on counterfactuals. Marc Höfler, BMC medical research methodology. 512005</p>
<p>Association between smoking and latent tuberculosis in the us population: an analysis of the national health and nutrition examination survey. Monica David J Horne, Justin R Campo, Eyal Ortiz, Matthew Oren, Kristina Arentz, Masahiro Crothers, Narita, PloS one. 711e490502012</p>
<p>Guido W Imbens, Donald B Rubin, Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction. Cambridge University Press2015</p>
<p>Tropheryma whipplei-induced plastic bronchitis in children: a case report. Xuefeng Jin, Caiyun Zhang, Chao Chen, Xiaoning Wang, Jing Dong, Yuanyuan He, Peng Zhang, Frontiers in Pediatrics. 1111855192023</p>
<p>Efficient causal graph discovery using large language models. Thomas Jiralerspong, Xiaoyin Chen, Yash More, Vedant Shah, Yoshua Bengio, 2024</p>
<p>Large language models struggle to learn long-tail knowledge. Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, Colin Raffel, International Conference on Machine Learning. PMLR2023</p>
<p>Emre Kıcıman, Robert Ness, Amit Sharma, Chenhao Tan, arXiv:2305.00050Causal reasoning and large language models: Opening a new frontier for causality. 2023arXiv preprint</p>
<p>Association of weight change following smoking cessation with the risk of tuberculosis development: A nationwide population-based cohort study. Seung Hoon, Kim , Yong-Moon Park, Kyungdo Han, Seung , Hyun Ko, Shin Young Kim, So Hyang Song, Chi Hong Kim, Kyu Yeon Hur, Sung Kyoung Kim, Plos one. 174e02662622022</p>
<p>Retrieval-augmented generation for knowledge-intensive nlp tasks. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-Tau Yih, Tim Rocktäschel, Advances in Neural Information Processing Systems. 202033</p>
<p>The association between active and passive smoking and latent tuberculosis infection in adults and children in the united states: results from nhanes. Sanghyuk S Ryan P Lindsay, Richard S Shin, Melanie La Garfein, Thomas E Rusch, Novotny, PloS one. 93e931372014</p>
<p>Can large language models build causal graphs?. Stephanie Long, Tibor Schuster, Alexandre Piché, NeurIPS 2022 Workshop on Causality for Real-world Impact. 2022</p>
<p>Varun Magesh, Faiz Surani, Matthew Dahl, Mirac Suzgun, Christopher D Manning, Daniel E Ho, arXiv:2405.20362Hallucination-free? assessing the reliability of leading ai legal research tools. 2024arXiv preprint</p>
<p>Recycling plastic: diagnosis and management of plastic bronchitis among adults. Prince Ntiamoah, Sanjay Mukhopadhyay, Subha Ghosh, Atul C Mehta, European Respiratory Review. 161302021</p>
<p>Causal diagrams for empirical research. Judea Pearl, Biometrika. 8241995</p>
<p>Judea Pearl, Causality: Models, Reasoning and Inference. New YorkCambridge University Press2000</p>
<p>Causal inference. Causality: objectives and assessment. Judea Pearl, 2010</p>
<p>Prognostic value of the risk profile in the prevention of ischemic heart disease. Reinis, Pokornỳ, Bazika, Tiserova, Gorican, Horakova, Stuchlikova, Havranek, Hrabovskỳ, Bratislavske Lekarske Listy. 7621981</p>
<p>Estimating causal effects of treatments in randomized and nonrandomized studies. Donald B Rubin, Journal of educational Psychology. 6656881974</p>
<p>Causal protein-signaling networks derived from multiparameter single-cell data. Karen Sachs, Omar Perez, Dana Pe'er, Douglas A Lauffenburger, Garry P Nolan, Science. 30857212005</p>
<p>Causal discovery of feedback networks with functional magnetic resonance imaging. Ruben Sanchez-Romero, Joseph D Ramsey, Kun Zhang, Biwei Mr K Glymour, Clark Huang, Glymour, bioRxiv. 2459362018</p>
<p>Package 'bnlearn'. Bayesian network structure learning, parameter learning and inference. Marco Scutari, Maintainer Marco Scutari, Hiton-Pc Mmpc, R package version. 20194</p>
<p>Google scholar api. Serpapi, </p>
<p>A linear nongaussian acyclic model for causal discovery. Shohei Shimizu, Patrik O Hoyer, Aapo Hyvärinen, Antti Kerminen, Michael Jordan, Journal of Machine Learning Research. 7102006</p>
<p>An algorithm for fast recovery of sparse causal graphs. Peter Spirtes, Clark Glymour, 10.1177/089443939100900106Social Science Computer Review. 911991</p>
<p>Causation, Prediction, and Search. Peter Spirtes, Clark Glymour, Richard Scheines, 10.7551/mitpress/1754.001.00012001The MIT Press</p>
<p>Masayuki Takayama, Tadahisa Okuda, Thong Pham, Tatsuyoshi Ikenoue, Shingo Fukuma, Shohei Shimizu, Akiyoshi Sannai, arXiv:2402.01454Integrating large language models in causal discovery: A statistical causal approach. 2024arXiv preprint</p>
<p>Vineeth N Balasubramanian, and Amit Sharma. 2023. Causal inference using llm-guided discovery. Aniket Vashishtha, Gowtham Abbavaram, Abhinav Reddy, Saketh Kumar, Bachu, </p>
<p>Review of cigarette smoking and tuberculosis in china: intervention is needed for smoking cessation among tuberculosis patients. Jianming Wang, Hongbing Shen, BMC public health. 92009</p>
<p>Association between tobacco smoking and drug-resistant tuberculosis. Infection and drug resistance. Ming-Gui Wang, Wei-Wei Huang, Yu Wang, Yun-Xia Zhang, Miao-Miao Zhang, Shou-Quan Wu, Andrew J Sandford, Jian-Qing He, 2018</p>
<p>Family history of cardiovascular disease is associated with cardiovascular responses to stress in healthy young men and women. Caroline E Wright, Katie O' Donnell, Lena Brydon, Jane Wardle, Andrew Steptoe, International Journal of Psychophysiology. 6332007</p>
<p>A survey on causal inference. Liuyi Yao, Zhixuan Chu, Sheng Li, Yaliang Li, Jing Gao, Aidong Zhang, ACM Transactions on Knowledge Discovery from Data (TKDD). 1552021</p>
<p>Causal parrots: Large language models may talk causality but are not causal. Matej Zečević, Moritz Willig, Devendra Singh Dhami, Kristian Kersting, Transactions on Machine Learning Research. 2023</p>
<p>Causal discovery in the presence of measurement error: Identifiability conditions. Kun Zhang, Mingming Gong, Joseph Ramsey, Kayhan Batmanghelich, Peter Spirtes, Clark Glymour, arXiv:1706.037682017arXiv preprint</p>
<p>Kun Wayne Xin Zhao, Junyi Zhou, Tianyi Li, Xiaolei Tang, Yupeng Wang, Yingqian Hou, Beichen Min, Junjie Zhang, Zican Zhang, Dong, arXiv:2303.18223A survey of large language models. 2023arXiv preprint</p>
<p>Emerging synergies in causality and deep generative models: A survey. Guanglin Zhou, Shaoan Xie, Guangyuan Hao, Shiming Chen, Biwei Huang, Xiwei Xu, Chen Wang, Liming Zhu, Lina Yao, Kun Zhang, 2023</p>            </div>
        </div>

    </div>
</body>
</html>