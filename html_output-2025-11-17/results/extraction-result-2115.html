<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2115 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2115</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2115</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-54.html">extraction-schema-54</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how automated or AI-driven scientific discovery systems validate their results, including the type of validation used (fabricated, simulated, or experimental), the fidelity and accuracy of validation approaches, domain-specific validation standards, and cases where validation succeeded or failed.</div>
                <p><strong>Paper ID:</strong> paper-281079256</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2509.01398v1.pdf" target="_blank">The Need for Verification in AI-Driven Scientific Discovery</a></p>
                <p><strong>Paper Abstract:</strong> Artificial intelligence (AI) is transforming the practice of science. Machine learning and large language models (LLMs) can generate hypotheses at a scale and speed far exceeding traditional methods, offering the potential to accelerate discovery across diverse fields. However, the abundance of hypotheses introduces a critical challenge: without scalable and reliable mechanisms for verification, scientific progress risks being hindered rather than being advanced. In this article, we trace the historical development of scientific discovery, examine how AI is reshaping established practices for scientific discovery, and review the principal approaches, ranging from data-driven methods and knowledge-aware neural architectures to symbolic reasoning frameworks and LLM agents. While these systems can uncover patterns and propose candidate laws, their scientific value ultimately depends on rigorous and transparent verification, which we argue must be the cornerstone of AI-assisted discovery.</p>
                <p><strong>Cost:</strong> 0.023</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2115.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2115.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how automated or AI-driven scientific discovery systems validate their results, including the type of validation used (fabricated, simulated, or experimental), the fidelity and accuracy of validation approaches, domain-specific validation standards, and cases where validation succeeded or failed.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI-Descartes</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI-Descartes (neuro-symbolic generator-verifier framework)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generator-verifier neuro-symbolic system that couples symbolic regression with formal reasoning: hypotheses are generated from data and then checked against background theory using theorem proving to compute a reasoning distance and empirical error for ranking.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Combining data and theory for derivable scientific discovery with AI-Descartes</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI-Descartes</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Modular generator-verifier pipeline: a symbolic regression (MINLP) enumerates candidate symbolic formulas from sparse/noisy data; a reasoning module (theorem prover) computes a reasoning error (discrepancy between model predictions and formulas derivable from a background theory) and combines it with empirical error to rank candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Physical sciences (equation discovery), broadly applicable to domains with formalizable background theory</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational_proof</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Validation is performed post hoc by a theorem-proving based reasoning module that (1) accepts a background theory B expressed in logical form, (2) computes a reasoning distance/error β(f) by attempting to derive or relate the candidate formula to consequences of B, and (3) combines β(f) with empirical error ε(f) from the dataset to rank and filter hypotheses. The system can reason over unmeasured variables and compare alternative background theories by computing reasoning errors for each.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>not applicable (formal logical derivability / symbolic reasoning rather than simulation); accuracy depends on completeness and correctness of B and capabilities of the theorem prover</td>
                        </tr>
                        <tr>
                            <td><strong>validation_sufficiency</strong></td>
                            <td>Paper argues computational proof is sufficient for domains where background theory can be formalized (physical sciences) but notes insufficiency when B is incomplete or inconsistent; domain norms: physical sciences favor formal/theoretical derivability plus empirical corroboration.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_accuracy</strong></td>
                            <td>No single numeric accuracy provided; success depends qualitatively on reasoning distance and empirical fit; reported as effective in prior physical-science examples but no universal error bounds given.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_details</strong></td>
                            <td>No wet-lab or physical experiments reported; validation is entirely logical/theorem-proving combined with empirical error on supplied datasets. The paper notes this is appropriate for physical-science problems where background theory exists, and identifies lack of experimental validation as a general limitation for domains lacking formal axioms.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_comparison</strong></td>
                            <td>Compares post-hoc formal verification (AI-Descartes) to purely data-driven SR approaches: AI-Descartes filters numerically-accurate but theoretically-inconsistent hypotheses, but no quantitative head-to-head metrics reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_failures</strong></td>
                            <td>Limitations occur when the background theory B is incomplete or inconsistent: theorem proving cannot certify derivability (β may be large) and useful hypotheses can be missed or only approximately verified; also the sequential generator-then-verifier design prevents joint exploitation of data and theory.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_cases</strong></td>
                            <td>Paper and prior work (Cornelio et al., 2023a) report cases in physical sciences where hypotheses that fit data but violate theory are filtered out and where derivable formulas are successfully identified when B is complete; specific datasets (e.g., binary star example in appendix) show LLMs can sometimes derive correct forms when assisted, though AI-Descartes' formal verifier provides stronger guarantees.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_comparison</strong></td>
                            <td>Results are evaluated against known ground-truth laws when available via empirical error ε(f) and by checking derivability from B; no universal numeric benchmarks reported here but the method explicitly uses known laws in B as ground truth when B is complete.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_replication</strong></td>
                            <td>Paper discusses methodology and prior published system (Cornelio et al., 2023a) but does not present independent replications in this review; reproducibility depends on availability of background theories and theorem-proving tooling.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Formal reasoning with theorem provers and MINLP symbolic search can be computationally costly; paper notes modular design but does not give concrete runtime or cost numbers—identifies verification as a bottleneck that needs automation to scale.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_norms</strong></td>
                            <td>Physical sciences: formal derivability and empirical predictive power are normative; the paper argues verification by formal reasoning plus empirical fit aligns with domain norms where background theory exists.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Uncertainty handled via multi-objective scores (empirical error ε and reasoning error β); no probabilistic confidence intervals reported for theorem-proving outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Sequential generator-first design prevents simultaneous use of data/theory, reliant on completeness/consistency of B, no wet-lab experiments, and scalability concerns for theorem proving and enumerative SR.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_details</strong></td>
                            <td>Combines empirical data-fit (computational/simulated/observational) with computational proof (theorem proving) to validate hypotheses; the hybrid is sequential: generate from data, then verify logically.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2115.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2115.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how automated or AI-driven scientific discovery systems validate their results, including the type of validation used (fabricated, simulated, or experimental), the fidelity and accuracy of validation approaches, domain-specific validation standards, and cases where validation succeeded or failed.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI-Hilbert</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI-Hilbert (theory-integrated polynomial discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A theory-guided optimization framework that integrates background algebraic axioms during hypothesis generation, producing algebraic certificates of derivability (or approximate certificates) via SOS/semidefinite reformulations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evolving scientific discovery by unifying data and background knowledge with ai hilbert</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI-Hilbert</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Searches for polynomial (or rational) formulas consistent with a background theory by casting a constrained polynomial discovery problem as a semidefinite (SOS) or linear optimization; if the discovered polynomial q(x) is exactly derivable from B then AI-Hilbert returns a certificate (representation as combination of axioms and multipliers); otherwise returns approximate certificate measuring distance d_c.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Physical sciences and any domain where relations can be expressed as polynomials/rationals and background axioms are algebraic</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational_proof</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Validation occurs during synthesis: algebraic axioms in B are enforced as constraints in the optimization problem; after solving via SOS/semidefinite programming the method either returns an exact certificate of derivability (d_c = 0) or an approximate certificate when d_c > 0, thus providing formal algebraic evidence of consistency with B while fitting data.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>not applicable (symbolic/algebraic certificates); fidelity corresponds to exact algebraic derivation when B and polynomial hypothesis space are appropriate; limitations arise if true relation is non-polynomial.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_sufficiency</strong></td>
                            <td>Paper claims sufficiency when the sought laws are in the polynomial/rational class and B is complete; however acknowledges insufficiency if the true law is outside restricted functional class or B is incomplete/inconsistent.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_accuracy</strong></td>
                            <td>When d_c = 0, certificate is exact (mathematical guarantee); otherwise only approximate derivability quantified by d_c. No numeric error rates across domains provided beyond this certificate semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_details</strong></td>
                            <td>No physical experiments; validation is algorithmic/algebraic. Paper emphasizes generation of certificates as sufficing for derivability claims within algebraic regimes but notes limits for non-polynomial laws and for domains lacking algebraic axioms.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_comparison</strong></td>
                            <td>Compared conceptually with post-hoc verification (AI-Descartes): AI-Hilbert enforces axioms during generation (reducing search) but restricts hypothesis class (polynomial/rational); trade-offs discussed qualitatively, no empirical numeric comparisons in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_failures</strong></td>
                            <td>Fails or returns approximate certificates when background theory is inconsistent or incomplete, or when the true law is not polynomial/rational; paper flags these as key limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_cases</strong></td>
                            <td>Success when the target relation is polynomial/rational and B contains sufficient algebraic axioms; in such cases exact SOS certificates provide formal derivability.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_comparison</strong></td>
                            <td>Verification is grounded in algebraic certificates against B rather than experimental ground truth; empirical error on data is also minimized as part of optimization, enabling comparison to observations.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_replication</strong></td>
                            <td>Method described; reproducibility contingent on solver tooling (mixed-integer conic/SOS solvers) and specification of B and hyperparameters; no reports of independent replications in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Solving mixed-integer conic and SOS problems can be computationally expensive; paper notes reformulation steps and reliance on conic/SOS solvers but provides no concrete time/cost numbers in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_norms</strong></td>
                            <td>Paper argues algebraic certificates align with norms in mathematics/physical sciences where algebraic axioms apply; less applicable in biology/chemistry where algebraic formalization is harder.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Approximate derivability is expressed via distance d_c; uncertainty is represented as deviation from exact algebraic certificate rather than probabilistic intervals.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Restricted hypothesis class (polynomial/rational), dependency on algebraic expressibility of background theory, solver scalability, and inability to provide wet-lab confirmation within framework.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_details</strong></td>
                            <td>Hybrid in the sense that AI-Hilbert jointly optimizes fit to data (empirical validation) and algebraic consistency with background theory (formal certificate) within a single optimization problem.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2115.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2115.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how automated or AI-driven scientific discovery systems validate their results, including the type of validation used (fabricated, simulated, or experimental), the fidelity and accuracy of validation approaches, domain-specific validation standards, and cases where validation succeeded or failed.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PINNs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Physics-Informed Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Neural networks trained to approximate solutions of PDEs by minimizing a composite loss that includes data fidelity, PDE residuals (physics loss), and boundary/initial condition penalties.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Physics-Informed Neural Networks (PINNs)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Trains neural networks u_theta(x) to minimize L_total = λ_d L_data + λ_f L_physics + λ_b L_boundary where L_physics penalizes violation of PDE residuals; used to replace or augment numerical solvers for forward/inverse PDE problems.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Computational physics, fluid mechanics, heat diffusion, quantum mechanics, PDE-constrained problems</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>simulated</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Validation usually performed by (1) measuring data loss against observed/simulated data, (2) evaluating PDE residuals across collocation points (physics loss), and (3) checking boundary/initial condition satisfaction. Often validated against numerical solvers or analytic solutions in benchmark problems.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Varies: can be high-fidelity when PDEs and boundary conditions are exact and collocation dense; in practice fidelity limited by network architecture, loss weighting, and collocation strategy—sensitivity to hyperparameters can reduce effective fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_sufficiency</strong></td>
                            <td>Paper notes PINNs are powerful when governing PDEs are known but warns sufficiency depends on careful balancing of loss terms and architecture choices; in many domains computational validation (matching PDE residuals) may suffice, but experimental validation is still needed for empirical claims.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_accuracy</strong></td>
                            <td>No single numeric accuracy given in this review; domain papers report strong accuracy on benchmark PDEs but sensitivity to hyperparameters can reduce accuracy—paper emphasizes need for systematic hyperparameter tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_details</strong></td>
                            <td>Discussion focuses on computational validation and matching analytical/numerical solutions rather than wet-lab experiments; paper highlights PINNs' mesh-free capability but flags practical sensitivity and need for hyperparameter optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_comparison</strong></td>
                            <td>Compared conceptually to traditional numerical solvers (PINNs can be mesh-free and high-dimensional) but empirical comparisons and numeric error statistics are not provided in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_failures</strong></td>
                            <td>Failure modes include poor balancing of loss terms, architecture mis-specification, and inability to exploit problem-specific structure—leading to degraded accuracy despite PDE penalty terms.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_cases</strong></td>
                            <td>Reported success across domains like fluid mechanics and quantum mechanics in prior work when governing equations are known and implementations are carefully tuned.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_comparison</strong></td>
                            <td>Typically compared to analytic solutions or high-resolution numerical solvers as ground truth in benchmarking work (not enumerated numerically here).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_replication</strong></td>
                            <td>Reproducibility depends on hyperparameter choices; paper calls for systematic tuning strategies to improve reproducibility across problems.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Training PINNs can be computationally intensive due to collocation/residual evaluations and hyperparameter sweeps; paper stresses need for efficient optimization and adaptive weighting but gives no numerical cost estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_norms</strong></td>
                            <td>In computational physics, matching PDE residuals and comparators to established numerical solvers are acceptable validations; experimental/physical validation may still be required for empirical claims.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Typically limited; PINNs in standard form minimize deterministic losses and do not inherently provide calibrated uncertainty; paper suggests need for uncertainty-aware extensions.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Sensitivity to loss weighting and architecture, lack of formal guarantees on constraint satisfaction (soft constraints), and limited interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_details</strong></td>
                            <td>Often used in a hybrid fashion combining simulated/numerical ground-truth comparisons and observed data, but not combined with formal proof methods.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2115.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2115.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how automated or AI-driven scientific discovery systems validate their results, including the type of validation used (fabricated, simulated, or experimental), the fidelity and accuracy of validation approaches, domain-specific validation standards, and cases where validation succeeded or failed.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HNN / LNN / KAN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hamiltonian Neural Networks / Lagrangian Neural Networks / Kolmogorov-Arnold Networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Physics-inspired neural architectures that embed structural priors: HNNs enforce energy conservation by learning a Hamiltonian, LNNs learn a Lagrangian and derive equations of motion, and KANs replace weights with learnable univariate functions to produce interpretable relations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>HNN / LNN / KAN</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>HNNs and LNNs incorporate conservation laws into the architecture (derive dynamics from learned Hamiltonian/Lagrangian), while KANs use learnable univariate functions for interpretable approximations; these architectures enforce specific structural properties by design.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Mechanics, dynamical systems, physical modeling, interpretable modeling</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>simulated</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Validation typically involves checking that structural properties (e.g., conserved energy for HNNs) hold on trajectories from simulation or data, and measuring predictive error on future state prediction; validation is limited to those enforced structural properties rather than full derivability.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Depends on dataset and whether validated against high-fidelity simulations; structural enforcement gives good fidelity for conserved quantities but does not guarantee correctness of other physical relations.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_sufficiency</strong></td>
                            <td>Paper states validation is limited: satisfying structural property (e.g., energy conservation) is necessary but not sufficient for scientific correctness; domain norms require broader theoretical consistency and often empirical validation.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_accuracy</strong></td>
                            <td>No numeric accuracies provided in this review; prior works report improved conservation of invariants but may still have prediction errors in dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_details</strong></td>
                            <td>No experimental protocols in this review; validation described is computational (trajectory prediction, invariants monitoring).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_comparison</strong></td>
                            <td>Compared conceptually to data-driven black-box NNs and to formal methods: offers structural guarantees but lacks formal reasoning about broader background theory.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_failures</strong></td>
                            <td>Can produce models that respect enforced invariants yet fail to capture underlying laws or generalize outside training regimes.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_cases</strong></td>
                            <td>Successful at preserving conservation laws and improving sample efficiency for systems governed by those laws.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_comparison</strong></td>
                            <td>Typically validated against simulated trajectories or analytic dynamics when available; specifics not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_replication</strong></td>
                            <td>Replicable insofar as architectures and datasets are shared; no independent replication results discussed in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Comparable to training other neural networks; cost grows with model complexity and data size but no numbers provided.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_norms</strong></td>
                            <td>Conservation-of-invariants checks are a norm but not a full substitute for derivability or empirical confirmation in physics.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Standard deterministic training; explicit uncertainty quantification not inherent.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Guarantees limited to encoded structural properties; do not provide formal derivability or proofs; may still hallucinate relations outside constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_details</strong></td>
                            <td>Not inherently hybrid in sense of combining formal proof; can be combined with data-driven validation but paper does not report formal hybridization.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2115.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2115.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how automated or AI-driven scientific discovery systems validate their results, including the type of validation used (fabricated, simulated, or experimental), the fidelity and accuracy of validation approaches, domain-specific validation standards, and cases where validation succeeded or failed.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Symbolic Regression Tools</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Symbolic regression engines (PySR, AI Feynman, TuringBot, RSRM, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Evolutionary/heuristic and physics-inspired symbolic regression methods that search for parsimonious symbolic formulas fitting data, sometimes augmented with physics heuristics or derivative information.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Symbolic Regression Tools (PySR, AI Feynman, TuringBot, RSRM)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Use evolutionary search, annealing, Monte Carlo Tree Search, or physics-inspired heuristics to propose parsimonious analytic expressions that fit observed data; some incorporate derivative information or physics heuristics to improve candidate quality.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General equation discovery across physics, engineering, dynamical systems, reinforcement learning control, etc.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>simulated</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Validation is primarily empirical: measure empirical error on datasets, parsimony (complexity) and sometimes physics-inspired heuristics or derivative-matching; some works include counterexample-guided refinement or constraint checks over sampled points.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Depends on underlying data; fidelity is empirical fit-based (low-to-medium depending on data noisiness); lacks formal guarantees.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_sufficiency</strong></td>
                            <td>Paper argues these approaches lack formal reasoning and thus their validation (empirical fit) is insufficient to claim scientific derivability in domains with formal theories; domain norms often require formal/theoretical consistency beyond fit.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_accuracy</strong></td>
                            <td>No universal accuracy numbers reported; some prior benchmarks (AI Feynman datasets, rediscovery tasks) serve as ground truth for evaluation but may be subject to memorization.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_details</strong></td>
                            <td>Mostly validated on synthetic or real datasets by measuring fit and complexity; no wet-lab experiments described here.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_comparison</strong></td>
                            <td>Compared unfavorably to formal-verifier approaches (AI-Descartes/AI-Hilbert) because they lack provability; they perform well on rediscovery benchmarks but vulnerable to spurious formulas that generalize poorly.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_failures</strong></td>
                            <td>Can return formulas that fit training data but violate domain theory or generalize poorly; prone to overfitting and producing superficially plausible but incorrect expressions.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_cases</strong></td>
                            <td>Work well in rediscovery tasks and when data are abundant and low-noise; AI Feynman successes on physics-inspired benchmark tasks cited as examples.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_comparison</strong></td>
                            <td>Benchmarked on rediscovery datasets (AI Feynman, SciBench, MATH-style tasks) where ground truth is known; these benchmarks may not reflect open-ended discovery settings and can be memorization-prone.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_replication</strong></td>
                            <td>Reproducible when algorithms and datasets are shared; paper highlights shortcoming of benchmarks that allow memorization rather than true discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Search-based methods can be computationally intensive depending on search complexity; no concrete costs provided.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_norms</strong></td>
                            <td>Empirical fit and parsimony are common norms but not sufficient in domains that require formal derivability or experimental validation.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Typically limited to error metrics and complexity trade-offs; probabilistic uncertainty measures not standard.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>No formal guarantees; vulnerable to overfitting and lack of theoretical grounding; benchmark limitations can mask deficiencies.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_details</strong></td>
                            <td>Some methods incorporate constraint checks or physics heuristics (soft enforcement), but not formal proofs.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2115.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2115.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how automated or AI-driven scientific discovery systems validate their results, including the type of validation used (fabricated, simulated, or experimental), the fidelity and accuracy of validation approaches, domain-specific validation standards, and cases where validation succeeded or failed.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMs / LLM-Agents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Models and LLM-based scientific agents (e.g., GPT-4, GPT-5, ChemCrow, SciAgents, LLM-SR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Generative LLMs and agent frameworks used to propose hypotheses, extract literature knowledge, generate candidate equations, and orchestrate tools; validation primarily via human feedback, benchmarks, integrated tool calls, or simulated tests, but lacks formal scientific verification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Large Language Models and LLM-based agents (GPT-4/5, ChemCrow, SciAgents, LLM-SR)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>LLMs used as hypothesis proposers, numeric-to-symbolic generators, or multi-tool agents that can call domain-specific tools (reaction predictors, simulators) to design and partially test hypotheses; LLMs may be fine-tuned with RLHF to steer outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Broad: materials science, chemistry, biology, equation discovery, interdisciplinary research copilots</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>none</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Validation for LLM outputs in the literature is commonly limited to: (1) RLHF/human-preference tuning (improves plausibility), (2) benchmark evaluation on rediscovery or simulated tasks (LLM-SRBench, LLM-SR), and (3) integrated tool/simulator calls for in-silico checks. The paper emphasizes that RLHF measures plausibility not truth and that LLM outputs frequently hallucinate or fabricate references.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>When used with simulators/tools, fidelity depends on those external tools (could be high-fidelity physics-based or empirical); LLM native outputs have no fidelity guarantee.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_sufficiency</strong></td>
                            <td>Paper argues these validation approaches are insufficient for scientific discovery: plausibility (RLHF) and benchmark performance do not equal rigorous verification; domain norms often require formal proofs or experimental/clinical trials depending on field.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_accuracy</strong></td>
                            <td>No reliable accuracy numbers; paper reports known failure modes (hallucinations of legal cases, fabricated biomedical references, algebraic/physical inconsistencies) and shows mixed LLM performance on symbolic reasoning tasks (GPT-4 failed on some prompts while GPT-5 succeeded in examples).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_details</strong></td>
                            <td>Paper does not report wet-lab validations performed by LLMs; notes agentic frameworks (ChemCrow, AtomAgents, SciAgents) can orchestrate experimental pipelines but the review highlights that many reported 'discoveries' remain unvalidated experimentally due to cost and throughput limits.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_comparison</strong></td>
                            <td>Paper contrasts RLHF/human-preference validation with formal theorem-proving and algebraic certificates, arguing RLHF is insufficient; benchmarks (rediscovery) can overestimate capabilities due to memorization.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_failures</strong></td>
                            <td>Documented failures include hallucinated legal cases, fabricated biomedical references, algebraic inconsistencies, and incorrect symbolic derivations from LLMs (GPT-4 examples). The paper cites several reviews documenting these failures.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_cases</strong></td>
                            <td>LLM improvements observed: GPT-5 performed better than GPT-4 on some symbolic reasoning prompts in the appendix, and LLMs integrated with domain tools (e.g., ChemCrow) can carry out parts of workflows successfully when the external tools are reliable.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_comparison</strong></td>
                            <td>Benchmarks and rediscovery datasets provide ground truth comparisons but are often in-distribution; the paper stresses need for out-of-distribution, novelty-focused benchmarks to reliably evaluate discovery capability.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_replication</strong></td>
                            <td>Paper notes reproducibility and memorization concerns in benchmarks; no widespread independent replications of AI-led wet-lab discoveries discussed here.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Human-in-the-loop RLHF and experimental validation can be costly; integrated agent pipelines that call external simulators/experiments incur additional resource/time costs; no quantitative cost estimates provided.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_norms</strong></td>
                            <td>Paper emphasizes domain norms: proof in mathematics, wet-lab experiments in biology/chemistry, randomized controlled trials in clinical science; LLM-level plausibility checks do not meet these norms.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>LLMs typically produce point outputs and calibrated confidence is limited; the paper criticizes RLHF for not providing principled uncertainty quantification for scientific truth claims.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Plausibility vs truth mismatch, hallucination risk, lack of formal guarantees, benchmark memorization, and limited integration of formal reasoning; domain-appropriate empirical validation often missing.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_details</strong></td>
                            <td>Often combined with external simulators, symbolic regressors, or toolchains (e.g., LLM-SR uses LLMs for symbolic regression; ChemCrow integrates GPT-4 with chemistry tools). But the paper stresses that such hybrids still frequently lack formal verification or experimental follow-through.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2115.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2115.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how automated or AI-driven scientific discovery systems validate their results, including the type of validation used (fabricated, simulated, or experimental), the fidelity and accuracy of validation approaches, domain-specific validation standards, and cases where validation succeeded or failed.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Formal Proof Assistants</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Lean / Coq / Isabelle (formal theorem provers and proof assistants)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Interactive and automated proof assistants for expressing and mechanically verifying mathematical theorems; can be coupled with LLMs to translate informal proofs into formal statements for verification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Formal proof assistants (Lean, Coq, Isabelle)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Dependently-typed or higher-order logic systems that allow formalization of axioms and mechanical checking of derivations; used to verify mathematical theorems and potentially to check derivability of scientific claims when axioms are formalized.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Mathematics primarily; referenced for potential use in physical sciences if background axioms can be formalized</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational_proof</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Validation is exact proof checking: theorems are formalized in the assistant's language and checked mechanically; systems have been used in projects (e.g., Lean) to fully verify textbooks and have been paired with LLMs (AlphaProof) to translate informal statements to Lean.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Not applicable; proofs give exact logical certainty within chosen axiomatic system.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_sufficiency</strong></td>
                            <td>Sufficient in mathematics where axioms are agreed; the paper notes insufficiency for natural sciences because no commonly accepted complete axioms exist for many scientific domains (e.g., quantum mechanics vs gravity conflict).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_accuracy</strong></td>
                            <td>Proof assistants provide absolute correctness guarantees relative to encoded axioms; accuracy is binary (proof accepted/rejected), not a percentage metric.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_details</strong></td>
                            <td>No physical experiments—validation is formal logical verification. Paper cites AlphaProof achieving high performance on IMO problems via Lean translations but cautions about translation errors from informal to formal statements.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_comparison</strong></td>
                            <td>Contrasted with RLHF and plausibility checks: proof assistants provide guarantees absent from RLHF, but translation and axiomatization burdens limit applicability in empirical sciences.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_failures</strong></td>
                            <td>Failure modes include incorrect formalization of informal statements, missing axioms, and inability to axiomatize complex empirical sciences fully.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_cases</strong></td>
                            <td>AlphaProof translated many informal problems to Lean enabling automated theorem solving; formal verification of mathematical textbooks cited as a success.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_comparison</strong></td>
                            <td>In mathematics ground truth is the axiomatic system; in sciences the absence of agreed axioms limits ground-truth use.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_replication</strong></td>
                            <td>Formal proofs are fully reproducible by checking in the assistant; reproducibility is strong for formalized content.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Formalization and translation of informal statements is labor-intensive and time-consuming; computational checking is efficient but formalization is costly.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_norms</strong></td>
                            <td>Mathematics requires formal proof; in natural sciences formal proofs are less common and experiments are normative.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not probabilistic; proof either holds or does not relative to axioms.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Translation from informal/empirical claims to formal statements is error-prone; lack of common axioms for many sciences restricts applicability.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_details</strong></td>
                            <td>Often combined with ML (LLMs) to automate translation (e.g., AlphaProof) or used alongside data-driven methods in hybrid verification pipelines like AI-Descartes.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2115.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2115.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how automated or AI-driven scientific discovery systems validate their results, including the type of validation used (fabricated, simulated, or experimental), the fidelity and accuracy of validation approaches, domain-specific validation standards, and cases where validation succeeded or failed.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Benchmarks / Rediscovery Datasets</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Rediscovery and discovery benchmarks (AI Feynman, SciBench, LLM-SRBench, MATH, ScienceQA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Datasets and benchmarks used to evaluate equation discovery and scientific problem solving, typically composed of rediscovery tasks or textbook-style problems that provide ground-truth solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Rediscovery/Discovery Benchmarks (AI Feynman, SciBench, LLM-SRBench, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Collections of synthetic and real tasks for evaluating symbolic regression and LLM capabilities; commonly used to test whether systems can 'rediscover' known laws or solve textbook-style problems.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Physics, mathematics, general scientific problem-solving</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>simulated</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Validation on these benchmarks is performed by comparing outputs to known ground-truth equations or textbook answers; metrics include exact-match of symbolic formula, prediction error on held-out data, and problem-solving accuracy on question-answering tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Benchmarks are often synthetic or curated from textbooks (high fidelity to canonical examples) but may not reflect open-ended discovery complexity; risk of in-distribution memorization.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_sufficiency</strong></td>
                            <td>Paper argues these benchmarks are insufficient for evaluating true open-ended discovery since they emphasize rediscovery and can be captured by memorization rather than reasoning; domain norms call for out-of-distribution novelty and theory-based validation.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_accuracy</strong></td>
                            <td>Varies by benchmark and system; no universal numbers reported here. The paper states that LLMs may score well on these rediscovery tasks but that this does not imply genuine discovery capability.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_details</strong></td>
                            <td>Benchmarks are computational; no real-world experiments incorporated in benchmark evaluation described in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_comparison</strong></td>
                            <td>Benchmarks compare different algorithmic approaches (SR, LLM, hybrids) but the paper criticizes them for not requiring formal-theory verification or experimental corroboration.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_failures</strong></td>
                            <td>Benchmarks can lead to overestimation of capabilities due to memorization; do not test generalizability or novelty robustly.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_cases</strong></td>
                            <td>Useful for measuring rediscovery and baseline capabilities; AI Feynman and similar datasets have demonstrated progress in symbolic regression methods.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_comparison</strong></td>
                            <td>Explicit ground truth available for rediscovery benchmarks enabling direct comparison; paper emphasizes need for benchmarks that require reasoning beyond memorized solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_replication</strong></td>
                            <td>Benchmarks are reproducible but may not reflect real discovery settings; reproducibility of lead results depends on dataset and evaluation protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Computational evaluation cost depends on benchmark scale; no concrete numbers provided.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_norms</strong></td>
                            <td>Benchmarks align with community norms for evaluating algorithmic capabilities but not necessarily for asserting scientific discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Benchmarks typically report point metrics (accuracy/error) rather than calibrated uncertainty measures.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Rediscovery focus, in-distribution biases, and lack of theory/experiment checks limit their use for evaluating true scientific discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_details</strong></td>
                            <td>Benchmarks may be used to evaluate hybrid approaches but are themselves computational evaluation suites rather than hybrid validation pipelines.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Combining data and theory for derivable scientific discovery with AI-Descartes <em>(Rating: 2)</em></li>
                <li>Evolving scientific discovery by unifying data and background knowledge with ai hilbert <em>(Rating: 2)</em></li>
                <li>Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations <em>(Rating: 2)</em></li>
                <li>Hamiltonian neural networks <em>(Rating: 2)</em></li>
                <li>AI Feynman: A physics-inspired method for symbolic regression <em>(Rating: 2)</em></li>
                <li>PySR: Fast & parallelized symbolic regression in Python/Julia <em>(Rating: 1)</em></li>
                <li>Fine-tuning language models from human preferences <em>(Rating: 1)</em></li>
                <li>AI achieves silver-medal standard solving international mathematical olympiad problems <em>(Rating: 1)</em></li>
                <li>LLM-SRBench: A new benchmark for scientific equation discovery with large language models <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2115",
    "paper_id": "paper-281079256",
    "extraction_schema_id": "extraction-schema-54",
    "extracted_data": [
        {
            "name_short": "AI-Descartes",
            "name_full": "AI-Descartes (neuro-symbolic generator-verifier framework)",
            "brief_description": "A generator-verifier neuro-symbolic system that couples symbolic regression with formal reasoning: hypotheses are generated from data and then checked against background theory using theorem proving to compute a reasoning distance and empirical error for ranking.",
            "citation_title": "Combining data and theory for derivable scientific discovery with AI-Descartes",
            "mention_or_use": "use",
            "system_name": "AI-Descartes",
            "system_description": "Modular generator-verifier pipeline: a symbolic regression (MINLP) enumerates candidate symbolic formulas from sparse/noisy data; a reasoning module (theorem prover) computes a reasoning error (discrepancy between model predictions and formulas derivable from a background theory) and combines it with empirical error to rank candidates.",
            "scientific_domain": "Physical sciences (equation discovery), broadly applicable to domains with formalizable background theory",
            "validation_type": "computational_proof",
            "validation_description": "Validation is performed post hoc by a theorem-proving based reasoning module that (1) accepts a background theory B expressed in logical form, (2) computes a reasoning distance/error β(f) by attempting to derive or relate the candidate formula to consequences of B, and (3) combines β(f) with empirical error ε(f) from the dataset to rank and filter hypotheses. The system can reason over unmeasured variables and compare alternative background theories by computing reasoning errors for each.",
            "simulation_fidelity": "not applicable (formal logical derivability / symbolic reasoning rather than simulation); accuracy depends on completeness and correctness of B and capabilities of the theorem prover",
            "validation_sufficiency": "Paper argues computational proof is sufficient for domains where background theory can be formalized (physical sciences) but notes insufficiency when B is incomplete or inconsistent; domain norms: physical sciences favor formal/theoretical derivability plus empirical corroboration.",
            "validation_accuracy": "No single numeric accuracy provided; success depends qualitatively on reasoning distance and empirical fit; reported as effective in prior physical-science examples but no universal error bounds given.",
            "experimental_validation_performed": false,
            "experimental_validation_details": "No wet-lab or physical experiments reported; validation is entirely logical/theorem-proving combined with empirical error on supplied datasets. The paper notes this is appropriate for physical-science problems where background theory exists, and identifies lack of experimental validation as a general limitation for domains lacking formal axioms.",
            "validation_comparison": "Compares post-hoc formal verification (AI-Descartes) to purely data-driven SR approaches: AI-Descartes filters numerically-accurate but theoretically-inconsistent hypotheses, but no quantitative head-to-head metrics reported in this paper.",
            "validation_failures": "Limitations occur when the background theory B is incomplete or inconsistent: theorem proving cannot certify derivability (β may be large) and useful hypotheses can be missed or only approximately verified; also the sequential generator-then-verifier design prevents joint exploitation of data and theory.",
            "validation_success_cases": "Paper and prior work (Cornelio et al., 2023a) report cases in physical sciences where hypotheses that fit data but violate theory are filtered out and where derivable formulas are successfully identified when B is complete; specific datasets (e.g., binary star example in appendix) show LLMs can sometimes derive correct forms when assisted, though AI-Descartes' formal verifier provides stronger guarantees.",
            "ground_truth_comparison": "Results are evaluated against known ground-truth laws when available via empirical error ε(f) and by checking derivability from B; no universal numeric benchmarks reported here but the method explicitly uses known laws in B as ground truth when B is complete.",
            "reproducibility_replication": "Paper discusses methodology and prior published system (Cornelio et al., 2023a) but does not present independent replications in this review; reproducibility depends on availability of background theories and theorem-proving tooling.",
            "validation_cost_time": "Formal reasoning with theorem provers and MINLP symbolic search can be computationally costly; paper notes modular design but does not give concrete runtime or cost numbers—identifies verification as a bottleneck that needs automation to scale.",
            "domain_validation_norms": "Physical sciences: formal derivability and empirical predictive power are normative; the paper argues verification by formal reasoning plus empirical fit aligns with domain norms where background theory exists.",
            "uncertainty_quantification": "Uncertainty handled via multi-objective scores (empirical error ε and reasoning error β); no probabilistic confidence intervals reported for theorem-proving outcomes.",
            "validation_limitations": "Sequential generator-first design prevents simultaneous use of data/theory, reliant on completeness/consistency of B, no wet-lab experiments, and scalability concerns for theorem proving and enumerative SR.",
            "hybrid_validation_approach": true,
            "hybrid_validation_details": "Combines empirical data-fit (computational/simulated/observational) with computational proof (theorem proving) to validate hypotheses; the hybrid is sequential: generate from data, then verify logically.",
            "uuid": "e2115.0"
        },
        {
            "name_short": "AI-Hilbert",
            "name_full": "AI-Hilbert (theory-integrated polynomial discovery)",
            "brief_description": "A theory-guided optimization framework that integrates background algebraic axioms during hypothesis generation, producing algebraic certificates of derivability (or approximate certificates) via SOS/semidefinite reformulations.",
            "citation_title": "Evolving scientific discovery by unifying data and background knowledge with ai hilbert",
            "mention_or_use": "use",
            "system_name": "AI-Hilbert",
            "system_description": "Searches for polynomial (or rational) formulas consistent with a background theory by casting a constrained polynomial discovery problem as a semidefinite (SOS) or linear optimization; if the discovered polynomial q(x) is exactly derivable from B then AI-Hilbert returns a certificate (representation as combination of axioms and multipliers); otherwise returns approximate certificate measuring distance d_c.",
            "scientific_domain": "Physical sciences and any domain where relations can be expressed as polynomials/rationals and background axioms are algebraic",
            "validation_type": "computational_proof",
            "validation_description": "Validation occurs during synthesis: algebraic axioms in B are enforced as constraints in the optimization problem; after solving via SOS/semidefinite programming the method either returns an exact certificate of derivability (d_c = 0) or an approximate certificate when d_c &gt; 0, thus providing formal algebraic evidence of consistency with B while fitting data.",
            "simulation_fidelity": "not applicable (symbolic/algebraic certificates); fidelity corresponds to exact algebraic derivation when B and polynomial hypothesis space are appropriate; limitations arise if true relation is non-polynomial.",
            "validation_sufficiency": "Paper claims sufficiency when the sought laws are in the polynomial/rational class and B is complete; however acknowledges insufficiency if the true law is outside restricted functional class or B is incomplete/inconsistent.",
            "validation_accuracy": "When d_c = 0, certificate is exact (mathematical guarantee); otherwise only approximate derivability quantified by d_c. No numeric error rates across domains provided beyond this certificate semantics.",
            "experimental_validation_performed": false,
            "experimental_validation_details": "No physical experiments; validation is algorithmic/algebraic. Paper emphasizes generation of certificates as sufficing for derivability claims within algebraic regimes but notes limits for non-polynomial laws and for domains lacking algebraic axioms.",
            "validation_comparison": "Compared conceptually with post-hoc verification (AI-Descartes): AI-Hilbert enforces axioms during generation (reducing search) but restricts hypothesis class (polynomial/rational); trade-offs discussed qualitatively, no empirical numeric comparisons in this review.",
            "validation_failures": "Fails or returns approximate certificates when background theory is inconsistent or incomplete, or when the true law is not polynomial/rational; paper flags these as key limitations.",
            "validation_success_cases": "Success when the target relation is polynomial/rational and B contains sufficient algebraic axioms; in such cases exact SOS certificates provide formal derivability.",
            "ground_truth_comparison": "Verification is grounded in algebraic certificates against B rather than experimental ground truth; empirical error on data is also minimized as part of optimization, enabling comparison to observations.",
            "reproducibility_replication": "Method described; reproducibility contingent on solver tooling (mixed-integer conic/SOS solvers) and specification of B and hyperparameters; no reports of independent replications in this review.",
            "validation_cost_time": "Solving mixed-integer conic and SOS problems can be computationally expensive; paper notes reformulation steps and reliance on conic/SOS solvers but provides no concrete time/cost numbers in this review.",
            "domain_validation_norms": "Paper argues algebraic certificates align with norms in mathematics/physical sciences where algebraic axioms apply; less applicable in biology/chemistry where algebraic formalization is harder.",
            "uncertainty_quantification": "Approximate derivability is expressed via distance d_c; uncertainty is represented as deviation from exact algebraic certificate rather than probabilistic intervals.",
            "validation_limitations": "Restricted hypothesis class (polynomial/rational), dependency on algebraic expressibility of background theory, solver scalability, and inability to provide wet-lab confirmation within framework.",
            "hybrid_validation_approach": true,
            "hybrid_validation_details": "Hybrid in the sense that AI-Hilbert jointly optimizes fit to data (empirical validation) and algebraic consistency with background theory (formal certificate) within a single optimization problem.",
            "uuid": "e2115.1"
        },
        {
            "name_short": "PINNs",
            "name_full": "Physics-Informed Neural Networks",
            "brief_description": "Neural networks trained to approximate solutions of PDEs by minimizing a composite loss that includes data fidelity, PDE residuals (physics loss), and boundary/initial condition penalties.",
            "citation_title": "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations",
            "mention_or_use": "mention",
            "system_name": "Physics-Informed Neural Networks (PINNs)",
            "system_description": "Trains neural networks u_theta(x) to minimize L_total = λ_d L_data + λ_f L_physics + λ_b L_boundary where L_physics penalizes violation of PDE residuals; used to replace or augment numerical solvers for forward/inverse PDE problems.",
            "scientific_domain": "Computational physics, fluid mechanics, heat diffusion, quantum mechanics, PDE-constrained problems",
            "validation_type": "simulated",
            "validation_description": "Validation usually performed by (1) measuring data loss against observed/simulated data, (2) evaluating PDE residuals across collocation points (physics loss), and (3) checking boundary/initial condition satisfaction. Often validated against numerical solvers or analytic solutions in benchmark problems.",
            "simulation_fidelity": "Varies: can be high-fidelity when PDEs and boundary conditions are exact and collocation dense; in practice fidelity limited by network architecture, loss weighting, and collocation strategy—sensitivity to hyperparameters can reduce effective fidelity.",
            "validation_sufficiency": "Paper notes PINNs are powerful when governing PDEs are known but warns sufficiency depends on careful balancing of loss terms and architecture choices; in many domains computational validation (matching PDE residuals) may suffice, but experimental validation is still needed for empirical claims.",
            "validation_accuracy": "No single numeric accuracy given in this review; domain papers report strong accuracy on benchmark PDEs but sensitivity to hyperparameters can reduce accuracy—paper emphasizes need for systematic hyperparameter tuning.",
            "experimental_validation_performed": false,
            "experimental_validation_details": "Discussion focuses on computational validation and matching analytical/numerical solutions rather than wet-lab experiments; paper highlights PINNs' mesh-free capability but flags practical sensitivity and need for hyperparameter optimization.",
            "validation_comparison": "Compared conceptually to traditional numerical solvers (PINNs can be mesh-free and high-dimensional) but empirical comparisons and numeric error statistics are not provided in this review.",
            "validation_failures": "Failure modes include poor balancing of loss terms, architecture mis-specification, and inability to exploit problem-specific structure—leading to degraded accuracy despite PDE penalty terms.",
            "validation_success_cases": "Reported success across domains like fluid mechanics and quantum mechanics in prior work when governing equations are known and implementations are carefully tuned.",
            "ground_truth_comparison": "Typically compared to analytic solutions or high-resolution numerical solvers as ground truth in benchmarking work (not enumerated numerically here).",
            "reproducibility_replication": "Reproducibility depends on hyperparameter choices; paper calls for systematic tuning strategies to improve reproducibility across problems.",
            "validation_cost_time": "Training PINNs can be computationally intensive due to collocation/residual evaluations and hyperparameter sweeps; paper stresses need for efficient optimization and adaptive weighting but gives no numerical cost estimates.",
            "domain_validation_norms": "In computational physics, matching PDE residuals and comparators to established numerical solvers are acceptable validations; experimental/physical validation may still be required for empirical claims.",
            "uncertainty_quantification": "Typically limited; PINNs in standard form minimize deterministic losses and do not inherently provide calibrated uncertainty; paper suggests need for uncertainty-aware extensions.",
            "validation_limitations": "Sensitivity to loss weighting and architecture, lack of formal guarantees on constraint satisfaction (soft constraints), and limited interpretability.",
            "hybrid_validation_approach": true,
            "hybrid_validation_details": "Often used in a hybrid fashion combining simulated/numerical ground-truth comparisons and observed data, but not combined with formal proof methods.",
            "uuid": "e2115.2"
        },
        {
            "name_short": "HNN / LNN / KAN",
            "name_full": "Hamiltonian Neural Networks / Lagrangian Neural Networks / Kolmogorov-Arnold Networks",
            "brief_description": "Physics-inspired neural architectures that embed structural priors: HNNs enforce energy conservation by learning a Hamiltonian, LNNs learn a Lagrangian and derive equations of motion, and KANs replace weights with learnable univariate functions to produce interpretable relations.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "HNN / LNN / KAN",
            "system_description": "HNNs and LNNs incorporate conservation laws into the architecture (derive dynamics from learned Hamiltonian/Lagrangian), while KANs use learnable univariate functions for interpretable approximations; these architectures enforce specific structural properties by design.",
            "scientific_domain": "Mechanics, dynamical systems, physical modeling, interpretable modeling",
            "validation_type": "simulated",
            "validation_description": "Validation typically involves checking that structural properties (e.g., conserved energy for HNNs) hold on trajectories from simulation or data, and measuring predictive error on future state prediction; validation is limited to those enforced structural properties rather than full derivability.",
            "simulation_fidelity": "Depends on dataset and whether validated against high-fidelity simulations; structural enforcement gives good fidelity for conserved quantities but does not guarantee correctness of other physical relations.",
            "validation_sufficiency": "Paper states validation is limited: satisfying structural property (e.g., energy conservation) is necessary but not sufficient for scientific correctness; domain norms require broader theoretical consistency and often empirical validation.",
            "validation_accuracy": "No numeric accuracies provided in this review; prior works report improved conservation of invariants but may still have prediction errors in dynamics.",
            "experimental_validation_performed": false,
            "experimental_validation_details": "No experimental protocols in this review; validation described is computational (trajectory prediction, invariants monitoring).",
            "validation_comparison": "Compared conceptually to data-driven black-box NNs and to formal methods: offers structural guarantees but lacks formal reasoning about broader background theory.",
            "validation_failures": "Can produce models that respect enforced invariants yet fail to capture underlying laws or generalize outside training regimes.",
            "validation_success_cases": "Successful at preserving conservation laws and improving sample efficiency for systems governed by those laws.",
            "ground_truth_comparison": "Typically validated against simulated trajectories or analytic dynamics when available; specifics not provided here.",
            "reproducibility_replication": "Replicable insofar as architectures and datasets are shared; no independent replication results discussed in this review.",
            "validation_cost_time": "Comparable to training other neural networks; cost grows with model complexity and data size but no numbers provided.",
            "domain_validation_norms": "Conservation-of-invariants checks are a norm but not a full substitute for derivability or empirical confirmation in physics.",
            "uncertainty_quantification": "Standard deterministic training; explicit uncertainty quantification not inherent.",
            "validation_limitations": "Guarantees limited to encoded structural properties; do not provide formal derivability or proofs; may still hallucinate relations outside constraints.",
            "hybrid_validation_approach": false,
            "hybrid_validation_details": "Not inherently hybrid in sense of combining formal proof; can be combined with data-driven validation but paper does not report formal hybridization.",
            "uuid": "e2115.3"
        },
        {
            "name_short": "Symbolic Regression Tools",
            "name_full": "Symbolic regression engines (PySR, AI Feynman, TuringBot, RSRM, etc.)",
            "brief_description": "Evolutionary/heuristic and physics-inspired symbolic regression methods that search for parsimonious symbolic formulas fitting data, sometimes augmented with physics heuristics or derivative information.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Symbolic Regression Tools (PySR, AI Feynman, TuringBot, RSRM)",
            "system_description": "Use evolutionary search, annealing, Monte Carlo Tree Search, or physics-inspired heuristics to propose parsimonious analytic expressions that fit observed data; some incorporate derivative information or physics heuristics to improve candidate quality.",
            "scientific_domain": "General equation discovery across physics, engineering, dynamical systems, reinforcement learning control, etc.",
            "validation_type": "simulated",
            "validation_description": "Validation is primarily empirical: measure empirical error on datasets, parsimony (complexity) and sometimes physics-inspired heuristics or derivative-matching; some works include counterexample-guided refinement or constraint checks over sampled points.",
            "simulation_fidelity": "Depends on underlying data; fidelity is empirical fit-based (low-to-medium depending on data noisiness); lacks formal guarantees.",
            "validation_sufficiency": "Paper argues these approaches lack formal reasoning and thus their validation (empirical fit) is insufficient to claim scientific derivability in domains with formal theories; domain norms often require formal/theoretical consistency beyond fit.",
            "validation_accuracy": "No universal accuracy numbers reported; some prior benchmarks (AI Feynman datasets, rediscovery tasks) serve as ground truth for evaluation but may be subject to memorization.",
            "experimental_validation_performed": false,
            "experimental_validation_details": "Mostly validated on synthetic or real datasets by measuring fit and complexity; no wet-lab experiments described here.",
            "validation_comparison": "Compared unfavorably to formal-verifier approaches (AI-Descartes/AI-Hilbert) because they lack provability; they perform well on rediscovery benchmarks but vulnerable to spurious formulas that generalize poorly.",
            "validation_failures": "Can return formulas that fit training data but violate domain theory or generalize poorly; prone to overfitting and producing superficially plausible but incorrect expressions.",
            "validation_success_cases": "Work well in rediscovery tasks and when data are abundant and low-noise; AI Feynman successes on physics-inspired benchmark tasks cited as examples.",
            "ground_truth_comparison": "Benchmarked on rediscovery datasets (AI Feynman, SciBench, MATH-style tasks) where ground truth is known; these benchmarks may not reflect open-ended discovery settings and can be memorization-prone.",
            "reproducibility_replication": "Reproducible when algorithms and datasets are shared; paper highlights shortcoming of benchmarks that allow memorization rather than true discovery.",
            "validation_cost_time": "Search-based methods can be computationally intensive depending on search complexity; no concrete costs provided.",
            "domain_validation_norms": "Empirical fit and parsimony are common norms but not sufficient in domains that require formal derivability or experimental validation.",
            "uncertainty_quantification": "Typically limited to error metrics and complexity trade-offs; probabilistic uncertainty measures not standard.",
            "validation_limitations": "No formal guarantees; vulnerable to overfitting and lack of theoretical grounding; benchmark limitations can mask deficiencies.",
            "hybrid_validation_approach": false,
            "hybrid_validation_details": "Some methods incorporate constraint checks or physics heuristics (soft enforcement), but not formal proofs.",
            "uuid": "e2115.4"
        },
        {
            "name_short": "LLMs / LLM-Agents",
            "name_full": "Large Language Models and LLM-based scientific agents (e.g., GPT-4, GPT-5, ChemCrow, SciAgents, LLM-SR)",
            "brief_description": "Generative LLMs and agent frameworks used to propose hypotheses, extract literature knowledge, generate candidate equations, and orchestrate tools; validation primarily via human feedback, benchmarks, integrated tool calls, or simulated tests, but lacks formal scientific verification.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Large Language Models and LLM-based agents (GPT-4/5, ChemCrow, SciAgents, LLM-SR)",
            "system_description": "LLMs used as hypothesis proposers, numeric-to-symbolic generators, or multi-tool agents that can call domain-specific tools (reaction predictors, simulators) to design and partially test hypotheses; LLMs may be fine-tuned with RLHF to steer outputs.",
            "scientific_domain": "Broad: materials science, chemistry, biology, equation discovery, interdisciplinary research copilots",
            "validation_type": "none",
            "validation_description": "Validation for LLM outputs in the literature is commonly limited to: (1) RLHF/human-preference tuning (improves plausibility), (2) benchmark evaluation on rediscovery or simulated tasks (LLM-SRBench, LLM-SR), and (3) integrated tool/simulator calls for in-silico checks. The paper emphasizes that RLHF measures plausibility not truth and that LLM outputs frequently hallucinate or fabricate references.",
            "simulation_fidelity": "When used with simulators/tools, fidelity depends on those external tools (could be high-fidelity physics-based or empirical); LLM native outputs have no fidelity guarantee.",
            "validation_sufficiency": "Paper argues these validation approaches are insufficient for scientific discovery: plausibility (RLHF) and benchmark performance do not equal rigorous verification; domain norms often require formal proofs or experimental/clinical trials depending on field.",
            "validation_accuracy": "No reliable accuracy numbers; paper reports known failure modes (hallucinations of legal cases, fabricated biomedical references, algebraic/physical inconsistencies) and shows mixed LLM performance on symbolic reasoning tasks (GPT-4 failed on some prompts while GPT-5 succeeded in examples).",
            "experimental_validation_performed": false,
            "experimental_validation_details": "Paper does not report wet-lab validations performed by LLMs; notes agentic frameworks (ChemCrow, AtomAgents, SciAgents) can orchestrate experimental pipelines but the review highlights that many reported 'discoveries' remain unvalidated experimentally due to cost and throughput limits.",
            "validation_comparison": "Paper contrasts RLHF/human-preference validation with formal theorem-proving and algebraic certificates, arguing RLHF is insufficient; benchmarks (rediscovery) can overestimate capabilities due to memorization.",
            "validation_failures": "Documented failures include hallucinated legal cases, fabricated biomedical references, algebraic inconsistencies, and incorrect symbolic derivations from LLMs (GPT-4 examples). The paper cites several reviews documenting these failures.",
            "validation_success_cases": "LLM improvements observed: GPT-5 performed better than GPT-4 on some symbolic reasoning prompts in the appendix, and LLMs integrated with domain tools (e.g., ChemCrow) can carry out parts of workflows successfully when the external tools are reliable.",
            "ground_truth_comparison": "Benchmarks and rediscovery datasets provide ground truth comparisons but are often in-distribution; the paper stresses need for out-of-distribution, novelty-focused benchmarks to reliably evaluate discovery capability.",
            "reproducibility_replication": "Paper notes reproducibility and memorization concerns in benchmarks; no widespread independent replications of AI-led wet-lab discoveries discussed here.",
            "validation_cost_time": "Human-in-the-loop RLHF and experimental validation can be costly; integrated agent pipelines that call external simulators/experiments incur additional resource/time costs; no quantitative cost estimates provided.",
            "domain_validation_norms": "Paper emphasizes domain norms: proof in mathematics, wet-lab experiments in biology/chemistry, randomized controlled trials in clinical science; LLM-level plausibility checks do not meet these norms.",
            "uncertainty_quantification": "LLMs typically produce point outputs and calibrated confidence is limited; the paper criticizes RLHF for not providing principled uncertainty quantification for scientific truth claims.",
            "validation_limitations": "Plausibility vs truth mismatch, hallucination risk, lack of formal guarantees, benchmark memorization, and limited integration of formal reasoning; domain-appropriate empirical validation often missing.",
            "hybrid_validation_approach": true,
            "hybrid_validation_details": "Often combined with external simulators, symbolic regressors, or toolchains (e.g., LLM-SR uses LLMs for symbolic regression; ChemCrow integrates GPT-4 with chemistry tools). But the paper stresses that such hybrids still frequently lack formal verification or experimental follow-through.",
            "uuid": "e2115.5"
        },
        {
            "name_short": "Formal Proof Assistants",
            "name_full": "Lean / Coq / Isabelle (formal theorem provers and proof assistants)",
            "brief_description": "Interactive and automated proof assistants for expressing and mechanically verifying mathematical theorems; can be coupled with LLMs to translate informal proofs into formal statements for verification.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Formal proof assistants (Lean, Coq, Isabelle)",
            "system_description": "Dependently-typed or higher-order logic systems that allow formalization of axioms and mechanical checking of derivations; used to verify mathematical theorems and potentially to check derivability of scientific claims when axioms are formalized.",
            "scientific_domain": "Mathematics primarily; referenced for potential use in physical sciences if background axioms can be formalized",
            "validation_type": "computational_proof",
            "validation_description": "Validation is exact proof checking: theorems are formalized in the assistant's language and checked mechanically; systems have been used in projects (e.g., Lean) to fully verify textbooks and have been paired with LLMs (AlphaProof) to translate informal statements to Lean.",
            "simulation_fidelity": "Not applicable; proofs give exact logical certainty within chosen axiomatic system.",
            "validation_sufficiency": "Sufficient in mathematics where axioms are agreed; the paper notes insufficiency for natural sciences because no commonly accepted complete axioms exist for many scientific domains (e.g., quantum mechanics vs gravity conflict).",
            "validation_accuracy": "Proof assistants provide absolute correctness guarantees relative to encoded axioms; accuracy is binary (proof accepted/rejected), not a percentage metric.",
            "experimental_validation_performed": false,
            "experimental_validation_details": "No physical experiments—validation is formal logical verification. Paper cites AlphaProof achieving high performance on IMO problems via Lean translations but cautions about translation errors from informal to formal statements.",
            "validation_comparison": "Contrasted with RLHF and plausibility checks: proof assistants provide guarantees absent from RLHF, but translation and axiomatization burdens limit applicability in empirical sciences.",
            "validation_failures": "Failure modes include incorrect formalization of informal statements, missing axioms, and inability to axiomatize complex empirical sciences fully.",
            "validation_success_cases": "AlphaProof translated many informal problems to Lean enabling automated theorem solving; formal verification of mathematical textbooks cited as a success.",
            "ground_truth_comparison": "In mathematics ground truth is the axiomatic system; in sciences the absence of agreed axioms limits ground-truth use.",
            "reproducibility_replication": "Formal proofs are fully reproducible by checking in the assistant; reproducibility is strong for formalized content.",
            "validation_cost_time": "Formalization and translation of informal statements is labor-intensive and time-consuming; computational checking is efficient but formalization is costly.",
            "domain_validation_norms": "Mathematics requires formal proof; in natural sciences formal proofs are less common and experiments are normative.",
            "uncertainty_quantification": "Not probabilistic; proof either holds or does not relative to axioms.",
            "validation_limitations": "Translation from informal/empirical claims to formal statements is error-prone; lack of common axioms for many sciences restricts applicability.",
            "hybrid_validation_approach": true,
            "hybrid_validation_details": "Often combined with ML (LLMs) to automate translation (e.g., AlphaProof) or used alongside data-driven methods in hybrid verification pipelines like AI-Descartes.",
            "uuid": "e2115.6"
        },
        {
            "name_short": "Benchmarks / Rediscovery Datasets",
            "name_full": "Rediscovery and discovery benchmarks (AI Feynman, SciBench, LLM-SRBench, MATH, ScienceQA)",
            "brief_description": "Datasets and benchmarks used to evaluate equation discovery and scientific problem solving, typically composed of rediscovery tasks or textbook-style problems that provide ground-truth solutions.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Rediscovery/Discovery Benchmarks (AI Feynman, SciBench, LLM-SRBench, etc.)",
            "system_description": "Collections of synthetic and real tasks for evaluating symbolic regression and LLM capabilities; commonly used to test whether systems can 'rediscover' known laws or solve textbook-style problems.",
            "scientific_domain": "Physics, mathematics, general scientific problem-solving",
            "validation_type": "simulated",
            "validation_description": "Validation on these benchmarks is performed by comparing outputs to known ground-truth equations or textbook answers; metrics include exact-match of symbolic formula, prediction error on held-out data, and problem-solving accuracy on question-answering tasks.",
            "simulation_fidelity": "Benchmarks are often synthetic or curated from textbooks (high fidelity to canonical examples) but may not reflect open-ended discovery complexity; risk of in-distribution memorization.",
            "validation_sufficiency": "Paper argues these benchmarks are insufficient for evaluating true open-ended discovery since they emphasize rediscovery and can be captured by memorization rather than reasoning; domain norms call for out-of-distribution novelty and theory-based validation.",
            "validation_accuracy": "Varies by benchmark and system; no universal numbers reported here. The paper states that LLMs may score well on these rediscovery tasks but that this does not imply genuine discovery capability.",
            "experimental_validation_performed": false,
            "experimental_validation_details": "Benchmarks are computational; no real-world experiments incorporated in benchmark evaluation described in this review.",
            "validation_comparison": "Benchmarks compare different algorithmic approaches (SR, LLM, hybrids) but the paper criticizes them for not requiring formal-theory verification or experimental corroboration.",
            "validation_failures": "Benchmarks can lead to overestimation of capabilities due to memorization; do not test generalizability or novelty robustly.",
            "validation_success_cases": "Useful for measuring rediscovery and baseline capabilities; AI Feynman and similar datasets have demonstrated progress in symbolic regression methods.",
            "ground_truth_comparison": "Explicit ground truth available for rediscovery benchmarks enabling direct comparison; paper emphasizes need for benchmarks that require reasoning beyond memorized solutions.",
            "reproducibility_replication": "Benchmarks are reproducible but may not reflect real discovery settings; reproducibility of lead results depends on dataset and evaluation protocols.",
            "validation_cost_time": "Computational evaluation cost depends on benchmark scale; no concrete numbers provided.",
            "domain_validation_norms": "Benchmarks align with community norms for evaluating algorithmic capabilities but not necessarily for asserting scientific discoveries.",
            "uncertainty_quantification": "Benchmarks typically report point metrics (accuracy/error) rather than calibrated uncertainty measures.",
            "validation_limitations": "Rediscovery focus, in-distribution biases, and lack of theory/experiment checks limit their use for evaluating true scientific discovery.",
            "hybrid_validation_approach": false,
            "hybrid_validation_details": "Benchmarks may be used to evaluate hybrid approaches but are themselves computational evaluation suites rather than hybrid validation pipelines.",
            "uuid": "e2115.7"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Combining data and theory for derivable scientific discovery with AI-Descartes",
            "rating": 2
        },
        {
            "paper_title": "Evolving scientific discovery by unifying data and background knowledge with ai hilbert",
            "rating": 2
        },
        {
            "paper_title": "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations",
            "rating": 2
        },
        {
            "paper_title": "Hamiltonian neural networks",
            "rating": 2
        },
        {
            "paper_title": "AI Feynman: A physics-inspired method for symbolic regression",
            "rating": 2
        },
        {
            "paper_title": "PySR: Fast & parallelized symbolic regression in Python/Julia",
            "rating": 1
        },
        {
            "paper_title": "Fine-tuning language models from human preferences",
            "rating": 1
        },
        {
            "paper_title": "AI achieves silver-medal standard solving international mathematical olympiad problems",
            "rating": 1
        },
        {
            "paper_title": "LLM-SRBench: A new benchmark for scientific equation discovery with large language models",
            "rating": 2
        }
    ],
    "cost": 0.02254225,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>The Need for Verification in AI-Driven Scientific Discovery
1 Sep 2025</p>
<p>Cristina Cornelio c.cornelio@samsung.com 
Samsung AI
CambridgeUK</p>
<p>Takuya Ito 
IBM Research
Yorktown Heights
USA</p>
<p>Ryan Cory-Wright 
Imperial Business School
LondonUK</p>
<p>Sanjeeb Dash 
IBM Research
Yorktown Heights
USA</p>
<p>Lior Horesh 
IBM Research
Yorktown Heights
USA</p>
<p>The Need for Verification in AI-Driven Scientific Discovery
1 Sep 202545C4E3C2E7946BC55E73773029B9338EarXiv:2509.01398v1[cs.AI]
Artificial intelligence (AI) is transforming the practice of science.Machine learning and large language models (LLMs) can generate hypotheses at a scale and speed far exceeding traditional methods, offering the potential to accelerate discovery across diverse fields.However, the abundance of hypotheses introduces a critical challenge: without scalable and reliable mechanisms for verification, scientific progress risks being hindered rather than being advanced.In this article, we trace the historical development of scientific discovery, examine how AI is reshaping established practices for scientific discovery, and review the principal approaches, ranging from data-driven methods and knowledge-aware neural architectures to symbolic reasoning frameworks and LLM agents.While these systems can uncover patterns and propose candidate laws, their scientific value ultimately depends on rigorous and transparent verification, which we argue must be the cornerstone of AI-assisted discovery.</p>
<p>Introduction</p>
<p>The overarching goal of science is to provide a set of universal, accurate, and interpretable explanations that describe the natural world.This involves discovering natural laws that not only make accurate predictions but are also corroborated by existing scientific literature.Such laws have historically been discovered through the scientific method, a systematic process that begins with a question and proceeds through a study phase during which researchers gather all prior knowledge and data pertaining to the phenomenon under investigation.This leads to the formulation of hypotheses, empirical validation, and iterative refinement.The scientific method enables the discovery of verifiable scientific truths by relying on substantiated and repeatable evidence, lending science its legitimacy and credibility.</p>
<p>The shift from dogmatic belief systems to a framework grounded in scientific theory and empirical verification, epitomized by the 16th-century transition from religious authority to human reason through the work of Copernicus, Galileo, and Bruno, marked a fundamental epistemological transformation leading to the Scientific Revolution [Leveillee, 2011].Indeed, Kepler's mathematical description of planetary motion, grounded in Tycho Brahe's observational data and Bacon's advocacy for inductive reasoning, established the foundation for modern empirical science [Bacon, 1878, Westfall, 1977].Critically, the consequences of this verification-driven methodology have been profound in the modern age.Verified discoveries such as germ theory [Latour, 1993], high-yield agricultural practices [Borlaug, 1970], and thermodynamic principles [Smil, 2004] have transformed medicine, food production, and energy systems.These advances were achieved through a disciplined integration of theoretical models and experimental validation.</p>
<p>However, the rate of major discoveries has declined in both absolute and relative terms over the past several decades [Bloom et al., 2020, Bhattacharya and Packalen, 2020, Arora et al., 2018].This decline is arguably due to the exhaustion of simple, low-dimensional theories, and the increasing complexity of modern scientific problems [Cowen, 2011] (see Fig. 1A).Amid these challenges, the rise of machine learning and artificial intelligence has introduced promising tools to augment hypothesis generation and data analysis for scientific discovery.However, many existing implementations of these data-driven systems lack formal mechanisms for logical inference that are essential for verifiable scientific discovery [Platt, 1964].In particular, generative AI models have shown remarkable capacity to rapidly generate novel scientific hypotheses [Gottweis et al., 2025, Yamada et al., 2025, Lu et al., 2024, Jumper et al., 2021].However, these outputs often lack empirical grounding and are frequently disconnected from established theoretical frameworks or domain-specific knowledge.This disconnect has led to an overwhelming influx of unverified hypotheses, straining verification pipelines that are essential for validating scientific discoveries [Beel et al., 2025, Gridach et al., 2025, Kulkarni et al., 2025] (see Fig. 1B).Consequently, developing robust methods to refine and verify hypotheses from data-driven approaches is critical to unlocking the full potential of AI in accelerating scientific progress (Fig. 1C).</p>
<p>Traditional scientific pipeline AI-assisted scientific pipeline</p>
<p>Verification bottleneck</p>
<p>Widen verification via automated verification</p>
<p>Accelerate scientific discoveries</p>
<p>Hypotheses crafted from theory and ontology</p>
<p>Rapid &amp; abundant AI-generated hypotheses</p>
<p>The Need for Improved Verification Methods</p>
<p>AI-generated hypotheses</p>
<p>Hypotheses Many Many Few Scientific Discoveries</p>
<p>A B C</p>
<p>Figure 1: The scientific method in the age of AI.A) In the traditional scientific method, theories guide the generation of testable hypotheses, which are then validated through experiments and data.B) However, with generative AI, hypotheses can be rapidly produced from data, but verification still relies on slow, manual evaluation by domain experts.C) Without widening this verification bottleneck (e.g., through automated/integrated verification) the pace of discovery remains limited, despite the acceleration promised by AI.</p>
<p>To address the limitations of purely data-driven approaches, several recent works propose hybrid frameworks.These approaches integrate machine learning with elements of symbolic reasoning, constraints imposition, and formal logic, aiming to ensure scientific validity alongside predictive accuracy (e.g., see Wiberg et al. [2025] for a review on integration between AI/ML and Operations Research techniques).For example, Kolmogorov-Arnold Networks (KANs) [Liu et al., 2025] replace fixed linear weights with learnable univariate functions, producing interpretable approximations of scientific relations.Hamiltonian Neural Networks (HNNs) [Greydanus et al., 2019] similarly enforce energy conservation by learning a Hamiltonian and deriving system dynamics from Hamilton's equations.While the learned models from both systems respect structural embeddings, verification for both systems is limited to their specific structural property.More recently, AI-Descartes [Cornelio et al., 2023a] introduced a general verification mechanism, where hypotheses were generated via a data-driven approach and later verified against known theory via theorem proving.Building upon that work, AI-Hilbert [Cory-Wright et al., 2024] integrated data and theory directly during the hypothesis generation stage, thereby constraining the search to expressions consistent with both data and theory.While both these approaches provide scientifically verifiable results, their application is limited to specific problem formulations in the physical sciences.Thus, while emerging computational tools offer great promise for broadly accelerating scientific discovery, their effectiveness hinges on ensuring resulting insights are not only predictive but also interpretable, verifiable, and aligned with foundational scientific knowledge.</p>
<p>In this article, we review recent progress in AI-driven scientific discovery, while underscoring the critical importance of verifying these methods throughout the discovery process.We begin by highlighting key historical examples where the failure to rigorously verify computational methods led to the collapse of critical missions, resulting in significant loss of life and financial cost.Next, we examine recent data-driven approaches to scientific discovery, highlighting their ability to uncover patterns and generate hypotheses from large datasets, particularly in domains where theoretical models are incomplete or unavailable.This is followed by a comparison with knowledge-aware methods, the emergence of derivable models that integrate symbolic reasoning, and the growing role of large language models (LLMs) in automating and augmenting scientific workflows.We conclude with a broader perspective on the heterogeneous role of verification across scientific domains, outlining current challenges and suggesting promising approaches for future research.</p>
<p>The Importance of Verification: Evidence from Examples</p>
<p>In 1999, NASA's Mars Climate Orbiter was lost when thruster data delivered in pounds per second was interpreted as Newtons per second, a unit mismatch that sent a $125 million spacecraft into the Martian atmosphere [NASA, 1999].Similarly, in 1983, Air Canada Flight 143 ("Gimli Glider") ran out of fuel mid-air after the ground crew incorrectly converted pounds to kilograms during Canada's metric transition, leaving the aircraft with roughly half the required fuel and forcing a dangerous emergency landing [Lockwood, 1985].Similar errors have been documented in hospitals: children given incorrect doses when weights noted in pounds were treated as kilograms [Bokser, 2013]; in a review of 1, 291 weight-related medication error reports to the Pennsylvania Patient Safety Authority, 23.2% involved pounds-kilograms confusion [Bailey et al., 2016]; and selection of high-strength heparin vials (10, 000 U/mL) were mistaken for low-strength ones [Institute for Safe Medication Practices Canada, 2008].The lesson from these domains is clear: without rigorous, automated verification, minor trivial errors can scale into disasters.</p>
<p>In automated scientific discovery, the same principle applies.Automated model-generation tools have transformed scientific discovery.Symbolic regression engines such as PySR [Cranmer, 2020] and AI Feynman [Udrescu and Tegmark, 2020], as well as neural architectures like Kolmogorov-Arnold Networks (KANs) [Liu et al., 2025], Hamiltonian Neural Networks (HNNs) [Greydanus et al., 2019], and Lagrangian Neural Networks (LNNs) [Cranmer et al., 2020a], now produce many new hypotheses quickly.This proliferation creates a new bottleneck: distinguishing between formulas that merely fit the data and those that are scientifically meaningful (Fig. 1).Without rigorous verification, the flood of generated hypotheses risks overwhelming the scientific process with plausible but superficial results.Thus, verification is an essential filter that separates genuine scientific discoveries from hallucinations or mere noisy interpolations that fail to generalize beyond the observed data.</p>
<p>The challenge of verification is further exacerbated by the rise of LLM-based tools whose reliability can be strongly questioned [Marcus, 2025, Kambhampati, 2024].Well-publicized examples of hallucinations from LLMs include the hallucination of legal cases cited in court filings [Weiss, 2023], the fabrication of biomedical references [Gravel et al., 2023], and outputs violating basic algebraic [Hendrycks et al., 2021] or physical consistency [Wang et al., 2023b].We refer to Zhang et al. [2025] for a recent review of LLMs and their use in scientific discovery.</p>
<p>One might argue that the latest generation of Large Language Models (LLMs), which utilize Reinforcement Learning from Human Feedback (RLHF) to steer outputs toward preferred outputs, already provide a form of verification [Ziegler et al., 2019].However, such feedback is not equivalent to scientific verification for several reasons.First, RLHF operates at the level of plausibility rather than truth: models are rewarded for producing outputs that appear correct to human evaluators.Second, the feedback is inherently partial and subjective, relying on limited annotations that cannot exhaustively cover the space of possible outputs.Third, RLHF provides no guarantees: models fine-tuned with feedback still generate confident but false statements and mathematically inconsistent expressions.</p>
<p>Thus, while reinforcement learning can improve the style and surface reliability of generated hypotheses, it does not address the deeper need for principled, automated verification against background theory and empirical constraints.For scientific discovery, this distinction is crucial: plausibility without proof cannot serve as the foundation of knowledge.</p>
<p>In the mathematical literature, the use of formal proof assistants for verification, such as Lean [De Moura et al., 2015], Coq [Bertot and Castéran, 2013], and Isabelle [Nipkow et al., 2002], has attracted considerable attention.These systems enable mathematical theorems to be expressed in a dependently typed language and verified computationally.For example, they can be used to verify that every result in an introductory analysis textbook is correct [Tao, 2025].Moreover, some recent works pair this technology with LLMs.For instance, the AlphaProof system from DeepMind [AlphaProof and AlphaGeometry teams, 2024] achieved a silver medal at the 2024 International Mathematics Olympiad by translating one million informal mathematical problems into Lean using natural language processing, allowing AlphaProof to be trained using reinforcement learning.However, since there is no commonly agreed-upon set of axioms for the natural sciences (e.g., quantum mechanics and gravity are not consistent), and the process of translating informal problems into formal statements can introduce errors unless verified by a user, a Lean-reinforcement learning approach cannot be broadly applied to scientific discovery.Finally, the growing recognition of verification challenges in AI-driven scientific discovery has catalyzed significant government investment in bridging formal methods with statistical AI approaches.In the United States, DARPA's portfolio is an example of this trend, featuring programs such as expMath [DARPA, 2025], which seeks to accelerate mathematics by developing AI systems capable of proposing and proving abstractions, and The Right Space (TRS) [DARPA, 2024c], which applies scientific machine learning to uncover tractable transformations for complex models.Other initiatives [DARPA, 2024b[DARPA, ,a,d, 2018]], including ReMath, PROVERS, V-SPELLS, and the completed HACMS program, further underscore the emphasis on formal verification in critical domains.These funding priorities reflect an acknowledgment that while generative AI excels at quick hypothesis generation and pattern discovery, scientific applications require the reliability and guarantees that only formal verification methods can provide.</p>
<p>AI Methods for Scientific Discovery</p>
<p>Motivated by the increasing importance of verification in scientific discovery and other domains involving AI, we next review the state-of-the-art methods used for scientific discovery.Figure 2 provides a qualitative map of the landscape, positioning the different major methods categories along three dimensions: the degree to which they are data-driven, the degree to which they are knowledge-driven and their associated computational complexity.We also discuss the limitations of the existing approaches and suggest strategies for future improvement.</p>
<p>Data-driven Methods</p>
<p>The data-driven discovery of symbolic formulae is a long-standing challenge in Artificial Intelligence [Kitano, 2016], and the central difficulty remains how to incorporate verification into the process.A variety of approaches have been proposed [Landajuela et al., 2022], ranging from neural networks designed to mimic human physical reasoning [Iten et al., 2020], to tree-structured LSTMs for handling symbolic expression trees and formula verification [Arabshahi et al., 2018], to logic-constrained GANs for image generation [Marra et al., 2018].Symbolic regression (SR) has played a prominent role in this space, with applications to extracting explicit relations from graph neural networks [Cranmer et al., 2020b], constructing analytic models for reinforcement learning control [Derner et al., 2019], or combining regression with Bayesian models [Jin et al., 2019].The AI Feynman family of methods [Udrescu andTegmark, 2020, Udrescu et al., 2020] exemplifies the integration of neural fitting with physics-inspired heuristics, while tools such as PySR [Cranmer, 2020, Cranmer et al., 2020b] and TuringBot [Schmidt and Lipson, 2009] use evolutionary or annealing-based search strategies to identify parsimonious equations.More recent methods, such as RSRM, combine Monte Carlo Tree Search with reinforcement learning for efficient symbolic exploration [Xu et al., 2024].Despite the progress, none of these approaches incorporates formal reasoning, leaving their outputs vulnerable to producing expressions that fit the data but lack theoretical grounding.</p>
<p>To address this gap, several works have attempted to combine SR or neural methods with logical consistency checking.The LGML system [Scott et al., 2020] augments learning with a module that verifies whether candidate functions satisfy constraints on their functional form, while LGGA [Ashok et al., 2021] extends this approach with genetic algorithms and auxiliary mathematical expressions.Similar ideas appear in Błądek and Krawiec [2019] counterexample-guided SR, in Kubalík et al. [2020,</p>
<p>Knowledge-driven discovery</p>
<p>Derivable models</p>
<p>Knowledge-aware NNs (PINNs, HNNs, LNNs)</p>
<p>Symbolic regression</p>
<p>Data-driven discovery</p>
<p>Automated theorem provers</p>
<p>Computational complexity</p>
<p>Linear regression</p>
<p>Kernel regression</p>
<p>Interactive theorem provers</p>
<p>Nonlinear regression (NNs, trees, etc.) Unsupervised (PCA, ICA, clustering, etc.)</p>
<p>Bayesian modeling</p>
<p>Program synthesis</p>
<p>Inductive Logic Programming</p>
<p>Figure 2: Qualitative Landscape of Computational Methods for Scientific Discovery.Different approaches span the spectrum between data-driven and knowledge-driven discovery.Data-driven methods, such as neural networks, can rapidly generate hypotheses but lack verifiability, whereas theory-driven methods, like automated theorem provers, offer rigorous verification but are often slow and undecidable.Derivable or science-aware approaches aim to bridge this gap by combining datadriven modeling with symbolic guarantees.The associated computational complexity reflects trade-offs between speed, interpretability, and verifiability.Note that this figure provides a qualitative illustration of the landscape of computational tools for scientific discovery, highlighting general trends across major categories.The position of specific methods in these categories may vary depending on data type, approach, or hybrid usage.2021] multi-objective framework that enforces nonlinear constraints as discrete data points, and in Engle and Sahinidis [2021] deterministic mixed-integer programming formulation with derivative constraints.These methods, however, remain limited to constraints on functional form rather than incorporating background-theory axioms that describe the scientific environment itself.</p>
<p>In parallel, the broader neuro-symbolic community has explored the integration of logic constraints into machine learning tools.Approaches include penalizing constraint violations in neural networks [Xu et al., 2018, Wang andPan, 2020] and embedding logical rules in the training process [Cornelio et al., 2023b, Li and Srikumar, 2019, Daniele and Serafini, 2020, Xie et al., 2019, Li et al., 2019].Inductive logic programming and rule induction [Tamaddoni-Nezhad et al., 2021, Sen et al., 2022, Evans and Grefenstette, 2018, Sadeghian et al., 2019, Law et al., 2018] provide another way of extracting logical knowledge from data, while program synthesis has gained renewed interest as a means of combining symbolic reasoning with statistical learning [Sun et al., 2022, Nye et al., 2020, Parisotto et al., 2017, Valkov et al., 2018, Yang et al., 2017].Yet, across all these efforts, formal verification of discovered formulas remains elusive: constraints typically ensure plausibility, not provability.The result is that many systems generate equations that appear valid but are not guaranteed to align with the underlying laws of nature.</p>
<p>Knowledge-aware methods</p>
<p>Scientific discovery and artificial intelligence have traditionally followed separate paradigms: the former rooted in theory and verification, and the latter in data-driven learning.As scientific problems become increasingly complex and data become increasingly abundant yet noisy or incomplete, there is a growing interest in integrating scientific knowledge into machine learning models.The resulting hybrid methods aim to combine the flexibility of learning-based approaches with the structure and generalizability offered by physical laws.</p>
<p>This section surveys approaches that leverage scientific knowledge in AI model design and training.We distinguish between physics-informed models, which learn the unknown solution of known governing equations by training neural networks to minimize data and physics residuals, and physics-inspired models, that encode known structures, such as conservation laws, directly in the network's architecture.We also consider symmetry-informed networks that embed invariance or equivariance directly into model operations, so that transformations of the input induce consistent transformations of the output.</p>
<p>Physics-Informed Neural Networks (PINNs).Physics-Informed Neural Networks (PINNs) incorporate governing physical laws into the learning process by embedding partial differential equations (PDEs) directly into the loss function [Raissi et al., 2019, Cuomo et al., 2022].These models are not intended to discover the governing equations themselves, but rather to approximate their solutions.The key idea is to replace or augment traditional numerical solvers by training a neural network that minimizes a composite loss consisting of: 1) A data loss term measuring the fit to observed data; 2) A physics loss term penalizing violation of the PDE; and 3) A boundary condition loss term ensuring physical consistency.Mathematically, for a PDE of the form F (x, u, ∇u, ∇ 2 u) = 0, the PINN approximates the solution u(x) with a neural network u θ (x), and minimizes:
L total = λ d L data + λ f L physics + λ b L boundary .
This approach has demonstrated success across various domains, including fluid mechanics, heat diffusion, and quantum mechanics.It provides an elegant, mesh-free framework capable of solving high-dimensional PDEs with limited data.</p>
<p>While PINNs represent a significant advance in scientific computing, the method requires carefully balancing multiple loss terms, and is therefore sensitive to network architecture choices.This highlights the importance of systematic hyperparameter optimization strategies.Additionally, the current approach relies on known governing equations as constraints, and the generic network architectures employed do not yet fully exploit problem-specific structural information.These characteristics have motivated active research directions focused on adaptive loss weighting schemes, physics-informed architecture design, and methods for discovering unknown governing equations from data [Lu et al., 2021].</p>
<p>Physics-inspired Neural Networks.Physics-inspired neural networks take a complementary approach: instead of embedding the governing equations into the training loss, they encode physical structure directly into the model architecture.These models are well-suited to systems governed by conservation laws, such as those following Hamiltonian or Lagrangian dynamics.</p>
<p>In Hamiltonian neural networks (HNNs) [Greydanus et al., 2019], the model learns a scalar-valued Hamiltonian function H(q, p), where q and p are generalized coordinates and momenta.The dynamics are then obtained by differentiating H according to Hamilton's equations:
dq dt = ∂H ∂p , dp dt = − ∂H ∂q .
enforcing conservation of energy by design.</p>
<p>Lagrangian neural networks (LNNs) [Cranmer et al., 2020a] instead model the Lagrangian L(q, q) and derive equations of motion via the Euler-Lagrange equations.This enables the incorporation of constraints and yields coordinate-invariant representations.</p>
<p>Physics-inspired networks, thus, encode domain knowledge directly into the architecture, allowing them to model both the its state and evolution in a structured way.However, as noted by Newman et al. [2024], these approaches do not discover the underlying laws; instead, they assume them, modeling the dynamics within the specified structural form.Furthermore, incorporating multiple types of physical constraints simultaneously (e.g., energy and momentum conservation alongside symmetry constraints) remains an open challenge.</p>
<p>Equivariant Neural Networks.Many physical systems exhibit symmetries such as translation, rotation, or permutation invariance.Equivariant neural networks explicitly incorporate such symmetries by ensuring that transformations of the input correspond to equivalent transformations of the output [Cohen and Welling, 2016].Formally, a function f is equivariant with respect to a group G if:
f (g • x) = g • f (x), ∀g ∈ G.
Equivariant Convolutional Neural Networks (G-CNNs), Spherical CNNs, and SE(3)-equivariant graph networks have been developed to model molecular systems, fluid dynamics, and lattice structures, among others [Weiler et al., 2021, Batzner et al., 2022].These networks often lead to improved sample efficiency and generalization.Symmetry-informed networks [Akhound-Sadegh et al., 2023] extend this concept to more general forms of structure, potentially including conservation laws and geometric constraints.These methods can be viewed as a broader class of equivariant models.However, as with physics-inspired networks, they often require manual specification of symmetry constraints and may not scale well when multiple symmetries coexist.</p>
<p>Knowledge-aware AI methods, while promising, still face ongoing challenges as they continue to evolve.Current approaches typically depend on experts to manually encode physical laws, architectural choices, or symmetry constraints into models, which limits scalability and automation.Moreover, the simultaneous incorporation of multiple physical principles presents significant computational and theoretical challenges.The interpretability of these models remains a key concern, as they often function as black boxes that provide limited insight into the underlying physical mechanisms they approximate.Most critically, existing methods typically lack formal guarantees regarding constraint satisfaction.Physical laws are commonly enforced through soft constraints via penalty terms in the loss function, which cannot ensure that the learned models rigorously adhere to all governing physical principles.These challenges underscore the need for formal frameworks that unify data-driven modeling with principled use of background knowledge, supporting rigorous verification.</p>
<p>Derivable models</p>
<p>A different line of work is represented by the methods of AI-Descartes [Cornelio et al., 2023a] and AI-Hilbert [Cory-Wright et al., 2024], which explicitly introduce background theory into the process of scientific discovery.In contrast to most existing methods, which either constrain functional forms or encode structural biases, these frameworks embed general scientific axioms and use them to guide or validate the discovery of candidate laws.AI-Descartes takes a verification-oriented perspective, generating hypotheses from data and then employing formal reasoning to test their consistency with background theory.AI-Hilbert, on the other hand, integrates theory directly into the hypothesis generation process, reducing the search space and enforcing consistency during model generation.[Cornelio et al., 2023a] is a neuro-symbolic framework for automated scientific discovery that couples symbolic regression with formal reasoning.The system adopts a generator-verifier paradigm, where any hypothesis generator can be paired with any formal verifier, allowing the generation of arbitrarily defined models without restrictions on functional classes, grammar, or structure.This modular yet sequential design ensures flexibility but prevents data and theory from being leveraged simultaneously: hypotheses are generated from data first and only then verified, a separation that limits the exploitation of their complementary strengths.</p>
<p>AI-Descartes. AI-Descartes</p>
<p>Formally, the system seeks to discover an unknown symbolic model y = f * (x), where x = (x 1 , . . ., x n ) are independent variables and y is the dependent variable.The inputs are defined as a 4-tuple ⟨B, C, D, M⟩, where B denotes the background knowledge, consisting of domain-specific axioms; C is the hypothesis class, describing the admissible symbolic models via a grammar and functional constraints; D is the dataset of m examples; and M specifies modeler preferences, such as acceptable error bounds or complexity measures.The discovery task is then framed as a multi-objective problem: the candidate function f must fit the data, remain consistent with B, and have bounded complexity and prediction error.</p>
<p>As outlined above, the AI-Descartes architecture is organized around two main modules following a generator-verifier design.The first is a symbolic regression (SR) module, formulated as a mixed-integer nonlinear programming (MINLP) problem, which enumerates candidate formulas that approximate the data and remains effective with very few, noisy data points.The second is a reasoning module, based on a theorem prover, that evaluates the logical relationship between a candidate model and the background theory.In particular, AI-Descartes introduces the concept of a reasoning distance, which measures the discrepancy between predictions of a candidate model f and the predictions of a formula derivable from B (assumed to be complete, i.e., containing all the axioms necessary to derive the ground-truth law).Each candidate hypothesis is evaluated both in terms of its empirical error ε(f ) relative to the data D, and its reasoning error β(f ) relative to the axioms in B. These two scores are combined to rank the hypotheses, with the top-ranked model being selected as the best candidate.The interplay between these two main components allows AI-Descartes to filter out spurious hypotheses that, while numerically accurate, violate known physical or logical constraints.</p>
<p>Unlike prior efforts that embed only structural constraints, AI-Descartes incorporates full background theories, expressed in logical form.This enables it to reason over unmeasured variables not present in the data and over non-obvious relations that go beyond the data itself.Building on this capability, AI-Descartes can also compare alternative background theories (possibly inconsistent to each other) by computing reasoning errors for each and selecting the set of axioms that is the most consistent with the data.</p>
<p>AI Hilbert.AI-Hilbert [Cory-Wright et al., 2024] is a theory-guided framework for automated scientific discovery that integrates background knowledge directly into hypothesis generation.In contrast to post hoc verification, AI-Hilbert couples data and theory in a single synthesis problem: candidate laws are constructed to satisfy the axioms as they are fit to the data.However, the method restricts the hypothesis space to polynomial (or, when admissible, rational) expressions, which enables algebraic constraints from the background theory to be enforced exactly or with controlled slack.</p>
<p>More formally, AI-Hilbert aims to discover an unknown polynomial formula q(•) ∈ R[x] which describes a physical phenomenon, and is consistent with both a background theory and a collection of experimental data.The inputs to AI-Hilbert are a four-tuple (B, D, C(Λ), d c ), where: 1) B denotes the relevant background theory, expressed as a collection of axioms: the union of the inequalities {g 1 (x) ≥ 0, . . ., g k (x) ≥ 0} defining G and the equalities {h 1 (x) = 0, . . ., h l (x) = 0} defining H, where g i , h j ∈ R[x] n (the ring of real polynomials in the n-tuple of variables x ∈ R n ).B is defined over n variables x 1 , . . ., x n .However, only t of these n variables can be measured and are directly relevant for explaining the observed phenomenon.In particular, we let x 1 denote the target variable.The remaining n − t variables appear in the background theory but are not directly observable.The background theory B is defined as complete if it contains all the axioms necessary to formally prove the target formula, and incomplete otherwise.Moreover, B is called inconsistent if it contains axioms that contradict each other, and consistent otherwise.A special case of inconsistency is when a formula that incorrectly describes the studied phenomenon is added to a consistent background theory.2) D := {x i } i∈[m] denotes a collection of data points, or measurements of an observed physical phenomenon, which may be few and noisy.3) C denotes a set of constraints and bounds which depend on a set of hyper-parameters Λ (e.g., bound on the degree of the polynomial q).4) d c (•, G ∩ H) denotes a distance function from an arbitrary polynomial to the background theory.</p>
<p>The AI-Hilbert algorithm has 4 main steps: Pr sd using a mixed-integer conic optimization solver, outputting a candidate formula and a set of
multipliers {α i } k i=1 , {β j } l j=1 .
The formula is of the form q(x) = 0 (where the only monomials with nonzero coefficients are those that only contain the variables x 1 , . . ., x t , the observable variables) and such that q
(x) = α 0 (x) + k i=1 α i (x)g i (x) + l j=1 β j (x)h j (x) if d c (q, G ∩ H) = 0,
which is a certificate of the fact that q is derivable from the complete background theory.If d c &gt; 0, for example, when the background theory is inconsistent or incomplete, then AI-Hilbert returns a certificate that q is approximately derivable from the background theory.</p>
<p>LLMs for Scientific Discovery</p>
<p>Recent advances in generative AI, and particularly large language models (LLMs), have opened new avenues for accelerating scientific discovery [Reddy and Shojaee, 2025].In materials discovery, generative graph-based models such as GNoME have drastically expanded the set of known stable materials, representing an order-of-magnitude increase in crystallographic diversity [Merchant et al., 2023a].More recently, LLMs have been used to extract domain knowledge from scientific literature, generate new material compositions, and guide experimental design, as demonstrated in systems like AtomAgents, which integrate LLM reasoning with alloy design pipelines [Ghafarollahi and Buehler, 2024].</p>
<p>Transformer-based models treat equation discovery as a numeric-to-symbolic generation task [Kamienny et al., 2022].However, state-of-the-art general-purpose LLMs, such as OpenAI GPT-5, still have limitations when it comes to symbolic discovery, often producing only relatively simple functional forms (e.g., when prompted with the binary star data in Cornelio et al. [2023a]).At the same time, their ability to make inferences from simple axiom systems has improved notably compared to older models (see Appendix A for more details).In parallel, multimodal approaches like SNIP embed equations and numerical data into smoother joint spaces to improve search efficiency [Meidani et al., 2024], while systems such as LLM-SR explore the use of LLMs as "scientist agents" that evolve equations in search of governing laws [Shojaee et al., 2024].Benchmarks, such as LLM-SRBench, have recently been introduced to systematically evaluate these methods in scientific equation discovery [Shojaee et al., 2025].These works highlight the growing role of generative and language-based models in pushing symbolic regression beyond handcrafted algorithms toward more generalizable AI-driven discovery.</p>
<p>Alongside these task-specific methods, domain-specialized scientific LLMs are being developed to serve as general-purpose research copilots.NatureLM [Xia et al., 2025] is a foundation model designed to unify the "languages of nature" across molecules, proteins, DNA, RNA, and materials, enabling cross-domain generation and design of drug molecules, protein binders, and CRISPR guides.Similarly, Galactica [Taylor et al., 2022], trained on 106B scientific tokens spanning papers, textbooks, chemical sequences, proteins, and code, outperforms general LLMs on scientific benchmarks and introduces specialized reasoning tokens for step-by-step problem solving.These models illustrate how domain-curated corpora and tailored architectures can significantly advance LLM-based scientific discovery.</p>
<p>Finally, LLMs can be framed as agents rather than passive tools: by coupling their broad knowledge bases with external tool integration, LLM-based agents can design, test, and refine hypotheses in ways that approximate the iterative scientific method.ChemCrow [M.Bran et al., 2024], for example, integrates GPT-4 with chemistry-specific tools for reaction prediction, retrosynthesis planning, and safety assessment, enabling both reasoning and validation within chemical workflows.Multi-agent frameworks, such as SciAgents, extend this paradigm by coordinating specialized LLM-based agents to collaboratively explore biomaterials design [Ghafarollahi and Buehler, 2025].Alongside general frameworks for opendomain hypothesis generation in the social sciences [Yang et al., 2024], biomedicine [Qi et al., 2023], and rediscovery settings such as MOOSE-Chem in chemistry [Yang et al., 2025], these systems demonstrate the potential of LLMs and generative models not only to accelerate discovery in targeted domains such as chemistry and materials science, but also to serve as versatile, reasoning-driven collaborators in the broader pursuit of new scientific laws.</p>
<p>Verification in the age of AI-driven science</p>
<p>Modern engineering industries regularly employ verification in the development and deployment of mission-critical technologies, including those in aerospace, medical devices, and autonomous systems.The rigorous process of verifying the accurate implementation of such technologies ensures that these complex systems function precisely as intended, mitigating risks of failure that could lead to catastrophic loss of life, environmental damage, or severe economic disruption.Through meticulous testing, simulation, and formal methods, verification tests validate the design integrity, software reliability, and hardware performance of technologies where even minor deviations can have profound consequences.Given the potentially far-reaching impacts and high costs of scientific research, why isn't a stringent and widespread culture of independent verification more commonly embedded within modern scientific research, rather than being largely limited to industrial applications?In this section, we illustrate examples of the importance of verification across research communities and outline ways to incorporate verification into scientific research to enhance the rigor of the scientific method for the modern age.</p>
<p>The role of verification across scientific domains</p>
<p>The proliferation of AI models in scientific research presents a transformative opportunity to accelerate the pace of scientific discovery.In particular, generative AI models have demonstrated the ability to produce novel hypotheses at rapid scales and speeds.However, the rapid generation of scientific hypotheses presents significant challenges.Many of these AI-generated hypotheses lack empirical verification and are often disconnected from established theoretical frameworks or domain-specific knowledge.However, the strength of a scientific theory lies in its empirical predictive power [Popper, 1959].Without iterative refinement through empirical verification of hypotheses, scientific theories fail to progress and remaining unable to make useful empirical predictions (see Fig. 3).The strength of a scientific theory lies in its empirical predictive power.Thus, the development of a scientific theory requires iterative empirical verification, with stronger theories offering more accurate predictions of observable phenomena.However, the balance between theoretical strength and predictive power varies across scientific domains, and often depends on the epistemic goals and maturity of each field, as well as the nature of the theories (e.g., formal versus ontological theories).</p>
<p>Empirical</p>
<p>In many applied scientific domains, such as drug discovery or materials science, the term "discovery" often refers primarily to the generation of hypotheses -such as identifying a promising molecular compound or material configuration -rather than their empirical verification [Reidenbach et al., 2025, Merchant et al., 2023b, Jain et al., 2022, Anstine and Isayev, 2023, Takeda et al., 2023].This usage underscores the importance of distinguishing between the act of proposing a candidate and the subsequent process of validating its efficacy, safety, or theoretical soundness.As a result, researchers are increasingly confronted with a deluge of unverified hypotheses, clogging (and potentially slowing) verification pipelines that are critical to validating scientific discoveries.However, verification strategies across scientific domains differ greatly in approach and empirical requirements due to differences in their theories and ontologies, as well as the epistemic goals of each field.Here we briefly discuss the variation of verification strategies across a few scientific domains, namely physical, biological and complex sciences, and clinical sciences.</p>
<p>In the physical sciences, verification is tightly coupled with formal theories and mathematical models.Hypotheses are often derived from well-established physical laws, and their verification typically involves controlled experiments or data-driven simulations that yield quantifiable and reproducible results that integrate and conform to these background laws [Udrescu and Tegmark, 2020].This tight integration of theory and data allows for the use of automated verification techniques that derive data from physical laws and theory [Cornelio et al., 2023a, Cory-Wright et al., 2024].</p>
<p>In contrast, however, many chemical, biological, and cognitive sciences present a more complex landscape for verification [Mock et al., 2024].Unlike physics, chemical, materials, and biological theories are often less formalized and more context-dependent, reflecting the inherent complexity of these systems and the variability of the epistemic goals across scientific domains.For example, verification in biology typically involves manual experimentation, such as genetic manipulation or behavioral observation, and relies heavily on ontological frameworks like evolutionary theory or systems biology, and less on explicit, quantitative laws.Though quantification is still important, it is often within the context of multi-variable and dynamical systems that are difficult to quantitatively derive from first principles.Nevertheless, efforts to build-in background knowledge (or incorporate a knowledgeconstrained search space) can improve the quality and validity of discovered hypotheses, thereby improving (and accelerating) scientific discovery in these domains (e.g., in chemistry [Yang et al., 2025], and in cognitive science [Castro et al., 2025]).</p>
<p>In medical and clinical sciences, there are additional layers of complexity.These tend to be shaped by ethical constraints, human variability, and pragmatic demands of clinical practice.Moreover, theories in clinical research are often probabilistic and population-based, rather than deterministic.Importantly, though the gold standard for verification strategies in clinical trials are randomized control trials, due to practical constraints of clinical research, verification strategies also include observational studies and meta-analyses of existing data.However, in all these cases, verification relies on statistical inference to assess efficacy and safety that are informed by ontological systems such as disease classifications and diagnostic criteria, which evolve over time.</p>
<p>Similar domain-specific variations in verification strategies are evident across various fields, including complex system sciences, earth sciences, social sciences, and engineering, among others, and each is shaped by its unique epistemic and methodological contexts.Despite the diversity of verification strategies across scientific domains, a unifying thread is the reliance on logical reasoning as the foundation for hypothesis testing and theory refinement.Whether through deductive modeling in physics, experimental inference in biology, or statistical evaluation in clinical sciences, the process of verification is fundamentally driven by structured, iterative reasoning.This echoes John Platt's notion of strong inference [Platt, 1964], where progress in science stems from the disciplined application of logic to generate, test, and eliminate hypotheses.While the form and tools of logical inference vary -from mathematical formalism (e.g., physical sciences) to ontological frameworks (e.g., biological sciences) to probabilistic models (e.g., clinical sciences) -the underlying commitment to rational analysis and verification remains constant.</p>
<p>Final Remarks and Future Challenges</p>
<p>In this work, we reviewed how AI is reshaping scientific discovery, with verification as a central open challenge.We reviewed a spectrum of methods, spanning from data-driven models to knowledge-based and hybrid approaches, illustrating their potential to accelerate hypothesis generation while also raising important concerns about their interpretability and reliability.The landscape we outlined highlights both the potential and the limits of contemporary AI, while pointing to the need to advance automated verification methods to improve AI-driven scientific discovery.There are many challenges ahead.In the next section we outline the most critical ones and discuss how they open promising directions for future research.</p>
<p>Challenges in AI-Driven Scientific Discovery</p>
<p>A major challenge for AI-driven scientific discovery is building benchmarks that genuinely capture open-ended scientific discovery and are not captured in the training distribution of existing AI systems.Existing datasets-such as AI Feynman [Udrescu and Tegmark, 2020], SciBench [Wang et al., 2023a], ScienceQA [Lu et al., 2022], and MATH [Hendrycks et al., 2021] focus on rediscovery or textbook-style problem solving, which neglects the complexity of theory formation.This is problematic because LLMs may depend on memorization rather than reasoning [Carlini et al., 2021, Wu et al., 2023], and unlike in theorem proving, most benchmarks lack explicit underlying theory, making verification-based evaluation nearly impossible.Indeed, whether an LLM is capable of making a scientific discovery often depends on the precise prompt used and even the notation used to describe a scientific discovery setting.Recent advances, such as simulated domains for scientific discovery [M.Bran et al., 2024, Shojaee et al., 2024] and the newly proposed LLM-SRBench [Shojaee et al., 2025], take steps toward mitigating memorization and evaluating true discovery.Nonetheless, key gaps remain in creating benchmarks that rigorously test novelty, generalizability, and scientific consistency [Cranmer et al., 2020b].</p>
<p>A second key challenge in AI-driven science is the unification of theory and data, since most existing methods focus either on empirical modeling or formal reasoning in isolation.While LLMs have shown promise in theorem proving [Jiang et al., 2023] and equation discovery from data [Shojaee et al., 2024], integrating these capabilities into a holistic framework remains an open problem.Efforts such as AI-Descartes [Cornelio et al., 2023a] and AI-Hilbert [Cory-Wright et al., 2024], as well as work in neuro-symbolic AI [De Raedt andKimmig, 2015, Ahmed et al., 2022], point toward promising directions for future development.However, challenges persist in deriving rigorous hypotheses from data, combining symbolic and neural approaches, and handling uncertainty within formal reasoning.</p>
<p>A third challenge in AI-driven discovery is ensuring that the use of AI does not overly homogenize science.The traditional scientific method is implemented differently by each scientist.This diversity, including the fact that scientists occasionally make mistakes, is a fundamental strength of science, as it enables different individuals to make distinct discoveries [Elliott, 2004].For instance, Alexander Fleming discovered penicillin by accident [Tan and Tatsumura, 2015], a "mistake" that an AI scientist would be unlikely to make.Ensuring that organic "mistakes" remain a part of the scientific method is another key challenge in the age of AI-driven discovery.</p>
<p>Conclusions</p>
<p>A key conclusion is that AI-driven scientific discovery compels us to reconsider the very notion of the "scientific method" itself.Traditionally, science has been portrayed as a systematic process of hypothesis generation, experimentation, and validation, but this narrative has been repeatedly challenged by philosophers such as Feyerabend [Feyerabend, 1975], who argue that rigid methodological rules neither capture nor enable true scientific progress.With the advent of generative models and inspired by industrial practices, however, we may be entering a new era in which verification becomes not just essential but also the primary bottleneck in scientific discovery.This shift would mark a departure from the traditional scientific method, reframing discovery as an iterative dialogue between creativity and verification, potentially laying the new groundwork for a new scientific paradigm.</p>
<p>[Step 1] The background theory B and data D are combined to generate a polynomial optimization problem Pr which targets a specific concept identified by the target variable x 1 .This is achieved by minimizing the distance d c , the model complexity and the error on the data, while integrating the bounds and constraints C. [Step 2] Pr is then reformulated as a semidefinite (or linear if no inequalities are present in the background theory) optimization problem Pr sd , by leveraging standard techniques from SOS optimization.[Step 3] Next, AI-Hilbert solves</p>
<p>Figure 3 :
3
Figure3: The role of verification in the development of scientific theories.The strength of a scientific theory lies in its empirical predictive power.Thus, the development of a scientific theory requires iterative empirical verification, with stronger theories offering more accurate predictions of observable phenomena.However, the balance between theoretical strength and predictive power varies across scientific domains, and often depends on the epistemic goals and maturity of each field, as well as the nature of the theories (e.g., formal versus ontological theories).</p>
<p>Figure 4 :
4
Figure 4: Prompt given to GPT-5 for binary star data used in AI Descartes (with variables relabeled as (d, m 1 , m 2 , p) → (x, y, z, u) and data columns permuted compared to the original dataset) and the output returned by GPT-5.The desired formula is u =</p>
<p>Figure 5 :
5
Figure5: Prompt and output given to GPT-4 for a simple artificial (not arising from any physical theory) example of the type used in AI Descartes.GPT-4 did not return a correct answer, which is f (d, k, z, g) = kzg z−d , whereas GPT-5 did (see Figure6for a comparison with GPT-5 on the same prompt).</p>
<p>Figure 6 :
6
Figure6: Prompt and output given to GPT-5 for a simple artificial (not arising from any physical theory) example of the type used in AI Descartes.GPT-4 did not return a correct answer, which is f (d, k, z, g) = kzg z−d , whereas GPT-5 did (see Figure5for a comparison with GPT-4 on the same prompt).</p>
<p>A AppendixIn this section, we give two examples of simple scientific discovery related queries given to a state-ofthe-art LLM, specifically GPT-5, the latest version of ChatGPT.In the first, we take data given in AI Descartes[Cornelio et al., 2023a]for two binary stars revolving around a common center of gravity and ask GPT-5 to find a function that best fits the data.The target function in this example is Kepler's third law of planetary motion.The data is scaled in such a manner that the period of revolution p is equal towhere d is the distance between the binary stars, and m 1 and m 2 stand for their masses.We rename the variables, (d, m 1 , m 2 , p) → (x, y, z, u), to avoid giving away information about the problem to GPT-5.In Figure4we show the prompt given to GPT-5 and its output.One can see that GPT-5 tries out a number of different functional forms -in other words it performs a limited symbolic regression exercise -and does not produce the desired function as a candidate solution.In Figure5we give the prompt at the top to GPT-4 and show its output, while in Figure6we show instead the output of GPT-5 on the same prompt.It is clear that GPT-4 fails to reason accurately with the axioms and comes up with the correct expression of the functional form relating the variables other than x, whereas GPT-5 produces the correct answer f (d, k, z, g) = kzg z−d and also the correct derivation.
Semantic probabilistic layers for neuro-symbolic learning. K Ahmed, S Teso, K.-W Chang, G Van Den Broeck, A Vergari, Advances in Neural Information Processing Systems. 202235</p>
<p>problems-at-silver-medal-level/. Announces AlphaProof (Lean-based formal reasoning) and AlphaGeometry 2. T Akhound-Sadegh, L Perreault-Levasseur, J Brandstetter, M Welling, S Ravanbakhsh, arXiv:2311.04293Lie point symmetry and physics informed networks. 2023. 20247arXiv preprintAi achieves silver-medal standard solving international mathematical olympiad problems. system scored 28/42 on IMO 2024</p>
<p>Generative Models as an Emerging Paradigm in the Chemical Sciences. D M Anstine, O Isayev, 10.1021/jacs.2c13467Journal of the American Chemical Society. 0002-786314516Apr. 2023American Chemical Society</p>
<p>Combining symbolic expressions and black-box function evaluations in neural programs. F Arabshahi, S Singh, A Anandkumar, In ICLR. 2018</p>
<p>The decline of science in corporate R&amp;D. A Arora, S Belenzon, A Patacconi, Strategic Management Journal. 3912018</p>
<p>Logic guided genetic algorithms (student abstract). D Ashok, J Scott, S J Wetzel, M Panju, V Ganesh, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial IntelligenceMay 202135</p>
<p>F Bacon, Novum organum. Clarendon press1878</p>
<p>Update on medication errors associated with incorrect patient weights. B R Bailey, M J Gaunt, M J Grissinger, Pennsylvania Patient Safety Advisory. 13206 2016Analysis found. 2% of events involved pounds-kilograms confusion (N=1,291</p>
<p>E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials. S Batzner, A Musaelian, L Sun, M Geiger, J P Mailoa, M Kornbluth, N Molinari, T E Smidt, B Kozinsky, Nature Communications. 1312022</p>
<p>Evaluating sakana's ai scientist for autonomous research: Wishful thinking or an emerging reality towards' artificial research intelligence. J Beel, M.-Y Kan, M Baumgart, arXiv:2502.142972025arXiv preprint</p>
<p>Interactive theorem proving and program development: Coq'Art: the calculus of inductive constructions. Y Bertot, P Castéran, 2013Springer Science &amp; Business Media</p>
<p>Stagnation and scientific incentives. J Bhattacharya, M Packalen, 2020National Bureau of Economic ResearchTechnical report</p>
<p>Solving symbolic regression problems with formal constraints. I Błądek, K Krawiec, The Genetic and Evolutionary Computation Conference (GECCO '19). Prague, Czech RepublicACMJuly 13-17, 2019. 2019</p>
<p>Are ideas getting harder to find?. N Bloom, C I Jones, J Van Reenen, M Webb, American Economic Review. 11042020</p>
<p>S J Bokser, A weighty mistake. Agency for Healthcare Research and Quality (AHRQ). PSNet WebM&amp;M case commentary2013</p>
<p>Nobel lecture: The green revolution, peace, and humanity. N Borlaug, 1970</p>
<p>Extracting training data from large language models. N Carlini, F Tramer, E Wallace, M Jagielski, A Herbert-Voss, K Lee, A Roberts, T Brown, D Song, U Erlingsson, 30th USENIX Security Symposium (USENIX Security 21). 2021</p>
<p>Discovering Symbolic Cognitive Models from Human and Animal Behavior. P S Castro, N Tomasev, A Anand, N Sharma, R Mohanta, A Dev, K Perlin, S Jain, K Levin, N Éltető, W Dabney, A Novikov, G C Turner, M K Eckstein, N D Daw, K J Miller, K L Stachenfeld, 10.1101/2025.02.05.636732v1Feb. 2025New ResultsSection</p>
<p>T Cohen, M Welling, Group equivariant convolutional networks. International Conference on Machine Learning (ICML). 2016</p>
<p>Combining data and theory for derivable scientific discovery with AI-Descartes. C Cornelio, S Dash, V Austel, T R Josephson, J Goncalves, K L Clarkson, N Megiddo, B El Khadir, L Horesh, Nature Communications. 14117772023aNature Publishing Group</p>
<p>Learning where and when to reason in neuro-symbolic inference. C Cornelio, J Stuehmer, S X Hu, T Hospedales, International Conference on Learning Representations. 2023b</p>
<p>Evolving scientific discovery by unifying data and background knowledge with ai hilbert. R Cory-Wright, C Cornelio, S Dash, B El Khadir, L Horesh, Nature Communications. 15159222024</p>
<p>The great stagnation: How America ate all the low-hanging fruit of modern history, got sick, and will (eventually) feel better: A Penguin eSpecial from Dutton. T Cowen, 2011Penguin</p>
<p>PySR: Fast &amp; parallelized symbolic regression in Python/Julia. M Cranmer, 10.5281/zenodo.4041459Sept. 2020</p>
<p>M Cranmer, S Greydanus, S Hoyer, P Battaglia, D Spergel, S Ho, Lagrangian neural networks. International Conference on Learning Representations (ICLR). 2020a</p>
<p>Discovering symbolic models from deep learning with inductive biases. M Cranmer, A Sanchez-Gonzalez, P Battaglia, R Xu, K Cranmer, D Spergel, S Ho, NeurIPS. 2020. 2020b</p>
<p>Scientific machine learning through physics-informed neural networks: Where we are and what's next. S Cuomo, V Di Cola, F Giampaolo, G Rozza, M Raissi, F Piccialli, 10.1007/s10915-022-01939-z.pdfJournal of Scientific Computing. 9232022</p>
<p>A Daniele, L Serafini, arXiv:, 2009.06087Neural networks enhancement with logical knowledge. 2020</p>
<p>DARPA. High assurance cyber military systems (HACMS). 2018</p>
<p>reasoning-of-verifiers-enabling-robust-systems. DARPA. Pipelined reasoning of verifiers enabling robust systems (PROVERS). 2024a</p>
<p>DARPA. Recovery of symbolic mathematics from code. 2024bReMath</p>
<p>DARPA. The right space (TRS). 2024c</p>
<p>verified-security-and-performance-enhancement-of-large-legacy-software. DARPA. Verified security and performance enhancement of large legacy software V-SPELLS. 2024d</p>
<p>Exponentiating mathematics (expMath. DARPA. 2025</p>
<p>The lean theorem prover (system description. L De Moura, S Kong, J Avigad, F Van Doorn, J Raumer, International Conference on Automated Deduction. Springer2015</p>
<p>Probabilistic (logic) programming concepts. L De Raedt, A Kimmig, 10.1007/s10994-015-5494-z.pdfMachine Learning. 2015100</p>
<p>Symbolic regression for constructing analytic models in reinforcement learning. E Derner, J Kubalík, N Ancona, R Babuska, arXiv:, 1903.114832019</p>
<p>Error as means to discovery. K Elliott, Philosophy of Science. 7122004</p>
<p>Deterministic symbolic regression with derivative information: General methodology and application to equations of state. M R Engle, N V Sahinidis, AIChE Journal. e174572021</p>
<p>Learning explanatory rules from noisy data. R Evans, E Grefenstette, Journal of Artificial Intelligence Research. 612018</p>
<p>Against Method: Outline of an Anarchistic Theory of Knowledge. P Feyerabend, New Left Books. 1975</p>
<p>Atomagents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence. A Ghafarollahi, M J Buehler, arXiv:2407.100222024arXiv preprint</p>
<p>Sciagents: automating scientific discovery through bioinspired multi-agent intelligent graph reasoning. A Ghafarollahi, M J Buehler, 10.1002/adma.202413523Advanced Materials. 372224135232025</p>
<p>Towards an ai co-scientist. J Gottweis, W.-H Weng, A Daryin, T Tu, A Palepu, P Sirkovic, A Myaskovsky, F Weissenberger, K Rong, R Tanno, arXiv:2502.188642025arXiv preprint</p>
<p>Learning to fake it: Limited responses and fabricated references provided by chatgpt for medical questions. J Gravel, M D'amours-Gravel, E Osmanlliu, 10.1016/j.mcpdig.2023.05.004Mayo Clinic Proceedings: Digital Health. 132023. 2023 Sep</p>
<p>Hamiltonian neural networks. S Greydanus, M Dzamba, J Yosinski, Advances in Neural Information Processing Systems. 201932</p>
<p>Agentic ai for scientific discovery: A survey of progress, challenges, and future directions. M Gridach, J Nanavati, K Z E Abidine, L Mendes, C Mack, arXiv:2503.089792025arXiv preprint</p>
<p>Institute for Safe Medication Practices Canada. Enhancing safety with unfractionated heparin: A national and international area of focus. D Hendrycks, C Burns, S Kadavath, A Arora, S Basart, E Tang, D Song, J Steinhardt, Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks. the Neural Information Processing Systems Track on Datasets and Benchmarks2021. 2008. 20088Bulletin reference #5 cites the ISMP Medication Safety Alert!. on heparin errors</p>
<p>Discovering physical concepts with neural networks. R Iten, T Metger, H Wilming, L Rio, R Renner, Physical Review Letters. 1242020</p>
<p>Biological Sequence Design with GFlowNets. M Jain, E Bengio, A Hernandez-Garcia, J Rector-Brooks, B F P Dossou, C A Ekbote, J Fu, T Zhang, M Kilgour, D Zhang, L Simine, P Das, Y Bengio, Proceedings of the 39th International Conference on Machine Learning. the 39th International Conference on Machine LearningPMLRJune 2022</p>
<p>Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. A Q Jiang, S Welleck, J P Zhou, W Li, J Liu, M Jamnik, T Lacroix, Y Wu, G Lample, International Conference on Learning Representations. 2023</p>
<p>Bayesian symbolic regression. Y Jin, W Fu, J Kang, J Guo, J Guo, arXiv[Methodology]:, 1910.088922019</p>
<p>Highly accurate protein structure prediction with AlphaFold. J Jumper, R Evans, A Pritzel, T Green, M Figurnov, O Ronneberger, K Tunyasuvunakool, R Bates, A Žídek, A Potapenko, A Bridgland, C Meyer, S A A Kohl, A J Ballard, A Cowie, B Romera-Paredes, S Nikolov, R Jain, J Adler, T Back, S Petersen, D Reiman, E Clancy, M Zielinski, M Steinegger, M Pacholska, T Berghammer, S Bodenstein, D Silver, O Vinyals, A W Senior, K Kavukcuoglu, P Kohli, D Hassabis, 10.1038/s41586-021-03819-2Nature. 1476-46875967873Aug. 2021Nature Publishing Group</p>
<p>Can large language models reason and plan?. S Kambhampati, Annals of the New York Academy of Sciences. 153412024</p>
<p>End-to-end symbolic regression with transformers. P.-A Kamienny, S Ascoli, G Lample, F Charton, Advances in Neural Information Processing Systems. S Koyejo, S Mohamed, A Agarwal, D Belgrave, K Cho, A Oh, Curran Associates, Inc202235</p>
<p>Artificial intelligence to win the Nobel prize and beyond: Creating the engine for scientific discovery. H Kitano, AI Magazine. 371Apr. 2016</p>
<p>Symbolic regression driven by training data and prior knowledge. J Kubalík, E Derner, R Babuška, Proceedings of the 2020 Genetic and Evolutionary Computation Conference. the 2020 Genetic and Evolutionary Computation Conference2020</p>
<p>Multi-objective symbolic regression for physics-aware dynamic modeling. J Kubalík, E Derner, R Babuška, Expert Systems with Applications. 1821152102021</p>
<p>A Kulkarni, F Alotaibi, X Zeng, L Wu, T Zeng, B M Yao, M Liu, S Zhang, L Huang, D Zhou, arXiv:2505.04651Scientific hypothesis generation and validation: Methods, datasets, and future directions. 2025arXiv preprint</p>
<p>A unified framework for deep symbolic regression. M Landajuela, C S Lee, J Yang, R Glatt, C P Santiago, T N Mundhenk, I Aravena, G Mulcahy, B Petersen, Advances in Neural Information Processing Systems (NeurIPS). 2022</p>
<p>The Pasteurization of France. B Latour, 1993Harvard University Press</p>
<p>Inductive learning of answer set programs from noisy examples. M Law, A Russo, K Broda, arXiv:, 1808.084412018</p>
<p>Copernicus, galileo, and the church: Science in a religious world. N P Leveillee, Inquiries Journal. 3052011</p>
<p>T Li, V Srikumar, arXiv:, 1906.06298Augmenting neural networks with first-order logic. 2019</p>
<p>T Li, V Gupta, M Mehta, V Srikumar, arXiv:, 1909.00126A logic-driven framework for consistency of neural models. 2019</p>
<p>KAN: Kolmogorov-arnold networks. Z Liu, Y Wang, S Vaidya, F Ruehle, J Halverson, M Soljačić, T Y Hou, M Tegmark, International Conference on Learning Representations (ICLR). 2025</p>
<p>G H Lockwood, Final report of the board of inquiry: Accident involving air canada boeing 767 c-gaun at gimli, manitoba. Lockwood23 july 1983. 1985Government catalogue confirms publication details</p>
<p>The ai scientist: Towards fully automated open-ended scientific discovery. C Lu, C Lu, R T Lange, J Foerster, J Clune, D Ha, arXiv:2408.062922024arXiv preprint</p>
<p>Learning nonlinear operators via deeponet based on the universal approximation theorem of operators. L Lu, P Jin, G Pang, Z Zhang, G E Karniadakis, 10.1038/s42256-021-00302-5Nature Machine Intelligence. 332021</p>
<p>Learn to explain: Multimodal reasoning via thought chains for science question answering. P Lu, S Mishra, T Xia, L Qiu, K.-W Chang, S.-C Zhu, O Tafjord, P Clark, A Kalyan, Advances in Neural Information Processing Systems. 202235</p>
<p>Augmenting large language models with chemistry tools. A M Bran, S Cox, O Schilter, C Baldassari, A D White, P Schwaller, Nature Machine Intelligence. 652024</p>
<p>Llms are not like you and me-and never will be. G Marcus, 2025</p>
<p>G Marra, F Giannini, M Diligenti, M Gori, arXiv:, 1807.09202Constraint-based visual generation. 2018</p>
<p>SNIP: Bridging mathematical symbolic and numeric realms with unified pre-training. K Meidani, P Shojaee, C K Reddy, A B Farimani, The Twelfth International Conference on Learning Representations. 2024</p>
<p>Scaling deep learning for materials discovery. A Merchant, S Batzner, S S Schoenholz, M Aykol, G Cheon, E D Cubuk, Nature. 62479902023a</p>
<p>Scaling deep learning for materials discovery. A Merchant, S Batzner, S S Schoenholz, M Aykol, G Cheon, E D Cubuk, 10.1038/s41586-023-06735-9Nature. 1476-46876247990Dec. 2023b</p>
<p>Recent advances in generative biology for biotherapeutic discovery. M Mock, C J Langmead, P Grandsard, S Edavettal, A Russell, 10.1016/j.tips.2024.01.003Trends in Pharmacological Sciences. 0165-6147453Mar. 2024Elsevier</p>
<p>NASA. Mars climate orbiter mishap investigation board phase i report. 1999</p>
<p>Stable tensor neural networks for efficient deep learning. E Newman, L Horesh, H Avron, M E Kilmer, 10.3389/fdata.2024.1363978/pdfFrontiers in Big Data. 713639782024</p>
<p>Isabelle/HOL: a proof assistant for higher-order logic. T Nipkow, M Wenzel, L C Paulson, 2002Springer</p>
<p>Learning compositional rules via neural program synthesis. M Nye, A Solar-Lezama, J Tenenbaum, B M Lake, Advances in Neural Information Processing Systems. H Larochelle, M Ranzato, R Hadsell, M Balcan, H Lin, Curran Associates, Inc202033</p>
<p>E Parisotto, A -R. Mohamed, R Singh, L Li, D Zhou, P Kohli, Neuro-symbolic program synthesis. International Conference on Learning Representations. 2017</p>
<p>Strong Inference. J R Platt, 10.1126/science.146.3642.347Science. 1463642Oct. 1964American Association for the Advancement of Science</p>
<p>The logic of scientific discovery. K R Popper, 1959Publisher: Basic Books</p>
<p>Large language models are zero shot hypothesis proposers. B Qi, K Zhang, H Li, K Tian, S Zeng, Z.-R Chen, B Zhou, NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following. 2023</p>
<p>Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. M Raissi, P Perdikaris, G E Karniadakis, Journal of Computational Physics. 3782019</p>
<p>Towards scientific discovery with generative ai: Progress, opportunities, and challenges. C K Reddy, P Shojaee, 10.1609/aaai.v39i27.35084Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial IntelligenceApr. 202539</p>
<p>Applications of Modular Co-Design for De Novo 3D Molecule Generation. D Reidenbach, F Nikitin, O Isayev, S Paliwal, arXiv:2505.18392May 2025</p>
<p>Drum: End-to-end differentiable rule mining on knowledge graphs. A Sadeghian, M Armandpour, P Ding, D Z Wang, Advances in Neural Information Processing Systems. H Wallach, H Larochelle, A Beygelzimer, F Alché-Buc, E Fox, R Garnett, Curran Associates, Inc201932</p>
<p>Distilling free-form natural laws from experimental data. M Schmidt, H Lipson, Science. 32459232009</p>
<p>J Scott, M Panju, V Ganesh, LGML: Logic Guided Machine Learning. 2006.03626, 2020</p>
<p>Neuro-symbolic inductive logic programming with logical neural networks. P Sen, B W S R De Carvalho, R Riegel, A G Gray, AAAI. 222022</p>
<p>Llm-sr: Scientific equation discovery via programming with large language models. P Shojaee, K Meidani, S Gupta, A B Farimani, C K Reddy, arXiv:2404.184002024arXiv preprint</p>
<p>LLM-SRBench: A new benchmark for scientific equation discovery with large language models. P Shojaee, N.-H Nguyen, K Meidani, A B Farimani, K D Doan, C K Reddy, Forty-second International Conference on Machine Learning. 2025</p>
<p>Enriching the Earth: Fritz Haber, Carl Bosch, and the Transformation of World Food Production. V Smil, 2004MIT Press</p>
<p>. J J Sun, M Tjandrasuwita, A Sehgal, A Solar-Lezama, S Chaudhuri, Y Yue, O Costilla-Reyes, arXiv:2210.050502022Neurosymbolic programming for science. arXiv preprint</p>
<p>Foundation Model for Material Science. S Takeda, A Kishimoto, L Hamada, D Nakano, J R Smith, 10.1609/aaai.v37i13.26793Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202337</p>
<p>Humanmachine scientific discovery. A Tamaddoni-Nezhad, D A Bohan, G A Milani, A Raybould, S Muggleton, Human-like machine intelligence. Oxford University Press2021</p>
<p>Alexander fleming (1881-1955): discoverer of penicillin. S Y Tan, Y Tatsumura, Singapore medical journal. 5673662015</p>
<p>A lean companion to "analysis i. T Tao, 2025</p>
<p>R Taylor, M Kardas, G Cucurull, T Scialom, A Hartshorn, E Saravia, A Poulton, V Kerkez, R Stojnic, arXiv:2211.09085Galactica: A large language model for science. 2022arXiv preprint</p>
<p>AI Feynman 2.0: Paretooptimal symbolic regression exploiting graph modularity. S Udrescu, A Tan, J Feng, O Neto, T Wu, M Tegmark, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems. H Larochelle, M Ranzato, R Hadsell, M Balcan, H Lin, NeurIPS2020. 2020. December 6-12, 2020, virtual, 2020</p>
<p>AI Feynman: A physics-inspired method for symbolic regression. S.-M Udrescu, M Tegmark, Science Advances. 6162020</p>
<p>Houdini: Lifelong learning as program synthesis. L Valkov, D Chaudhari, A Srivastava, C Sutton, S Chaudhuri, Advances in Neural Information Processing Systems. 201831</p>
<p>Integrating deep learning with logic fusion for information extraction. W Wang, S J Pan, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202034</p>
<p>Scibench: Evaluating college-level scientific problem-solving abilities of large language models. X Wang, Z Hu, P Lu, Y Zhu, J Zhang, S Subramaniam, A R Loomba, S Zhang, Y Sun, W Wang, arXiv:2307.106352023aarXiv preprint</p>
<p>NEWTON: Are large language models capable of physical reasoning?. Y Wang, J Duan, D Fox, S Srinivasa, 10.18653/v1/2023.findings-emnlp.652Findings of the Association for Computational Linguistics: EMNLP 2023. SingaporeAssociation for Computational Linguistics2023b</p>
<p>Judge finds out why brief cited nonexistent cases-ChatGPT did the research. M Weiler, P Forré, E Verlinde, M Welling, arXiv:2106.06020Coordinate independent convolutional networks-isometry and gauge equivariant convolutions on riemannian manifolds. 2021. 2023arXiv preprint</p>
<p>R S Westfall, The Construction of Modern Science: Mechanisms and Mechanics. Cambridge University Press1977</p>
<p>Synergizing artificial intelligence and operations research: Perspectives from informs fellows on the next frontier. H Wiberg, T Dai, H Lam, R Kulkarni, INFORMS Journal on Data Science. 2025</p>
<p>Reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks. Z Wu, L Qiu, A Ross, E Akyürek, B Chen, B Wang, N Kim, J Andreas, Y Kim, arXiv:2307.024772023arXiv preprint</p>
<p>Nature language model: Deciphering the language of nature for scientific discovery. Y Xia, P Jin, S Xie, L He, C Cao, R Luo, G Liu, Y Wang, Z Liu, Y.-J Chen, Z Guo, Y Bai, P Deng, Y Min, Z Lu, H Hao, H Yang, J Li, C Liu, J Zhang, J Zhu, R Bi, K Wu, W Zhang, K Gao, Q Pei, Q Wang, X Liu, Y Li, H Zhu, Y Lu, M Ma, Z Wang, T Xie, K Maziarz, M Segler, Z Yang, Z Chen, Y Shi, S Zheng, L Wu, C Hu, P Dai, T.-Y Liu, H Liu, T Qin, arXiv:2502.075272025arXiv preprint</p>
<p>Embedding symbolic knowledge into deep networks. Y Xie, Z Xu, M S Kankanhalli, K S Meel, H Soh, Advances in neural information processing systems. 201932</p>
<p>A semantic loss function for deep learning with symbolic knowledge. J Xu, Z Zhang, T Friedman, Y Liang, G Broeck, International conference on machine learning. PMLR2018</p>
<p>Reinforcement symbolic regression machine. Y Xu, Y Liu, H Sun, The Twelfth International Conference on Learning Representations. 2024</p>
<p>The ai scientist-v2: Workshop-level automated scientific discovery via agentic tree search. Y Yamada, R T Lange, C Lu, S Hu, C Lu, J Foerster, J Clune, D Ha, arXiv:2504.080662025arXiv preprint</p>
<p>Differentiable learning of logical rules for knowledge base reasoning. F Yang, Z Yang, W W Cohen, 201730Advances in neural information processing systems</p>
<p>Large language models for automated open-domain scientific hypotheses discovery. Z Yang, X Du, J Li, J Zheng, S Poria, E Cambria, ACL 2024 findings. 2024</p>
<p>Moose-chem: Large language models for rediscovering unseen chemistry scientific hypotheses. Z Yang, W Liu, B Gao, T Xie, Y Li, W Ouyang, S Poria, E Cambria, D Zhou, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Exploring the role of large language models in the scientific method: from hypothesis to discovery. Y Zhang, S A Khan, A Mahmud, H Yang, A Lavin, M Levin, J Frey, J Dunnmon, J Evans, A Bundy, Artificial Intelligence. 11142025</p>
<p>D M Ziegler, N Stiennon, J Wu, T B Brown, A Radford, D Amodei, P Christiano, G Irving, arXiv:1909.08593Fine-tuning language models from human preferences. 2019arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>