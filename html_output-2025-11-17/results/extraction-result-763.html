<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-763 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-763</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-763</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-88516099</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1612.05678v2.pdf" target="_blank">Causal Discovery as Semi-Supervised Learning</a></p>
                <p><strong>Paper Abstract:</strong> We frame causal discovery as a semi-supervised machine learning task. The idea is to allow direct learning of a causal graph by treating indicators of causal influence between variables as"labels". Available data on the variables of interest are used to provide features for the labelling task. Background knowledge or any available interventional data provide labels on some edges in the graph and the remaining edges are treated as unlabelled. To illustrate the key ideas, we develop a distance-based approach (based on simple bivariate histograms) within a semi-supervised manifold regularization framework. We present empirical results on three different biological datasets (including data where causal effects can be verified by experimental intervention), which demonstrate the efficacy and highly general nature of the approach as well as its simplicity from a user's point of view.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e763.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e763.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SSCD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Semi-Supervised Causal Discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A direct machine-learning approach that frames causal edge detection as a semi-supervised label-learning problem, using bivariate featurization and manifold-regularized learning to predict which variable pairs are causal given partial interventional/background labels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Semi-Supervised Causal Discovery (SSCD)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Treats each ordered variable pair (i,j) as an object with binary label Y_k indicating presence/absence of a causal effect. Featurizes each pair by estimating its bivariate distribution (here via a bivariate histogram, PCA-reduced), defines an L2 metric between pairwise density estimates, converts distances to a similarity matrix W = exp(-d^2/(2σ^2)), builds the (normalized) graph Laplacian L, and solves a manifold-regularization objective that trades label-fitting on known (interventional/background) labels against smoothness of the label function over the similarity graph; optimization has a closed-form solution and yields real-valued scores and binary label estimates. Implementation details: data truncated to [-3,3]^2, histogram bin width 0.2, PCA to 100 dims, computational cost O(m^3) where m is number of pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Biological experimental datasets (Yeast knockout, Kinase inhibitor time-course, TCGA proteomics)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Three real biological data domains: (D1) yeast gene-knockout experiments with many interventional samples (knockouts) and observational samples; (D2) kinase inhibitor time-course experiments on cell lines with several interventional regimes and timepoints; (D3) observational human cancer proteomic samples (TCGA) with a literature-derived reference causal graph. These are real experimental data environments that include explicit interventions in D1 and D2 (i.e. active experimentation was performed by the experimentalists), not a synthetic/virtual lab or simulated interactive environment.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>No explicit distractor-detection module is proposed. The method leverages partial interventional/background labels to disambiguate spurious associations and uses manifold-smoothness regularization on a similarity graph (built from bivariate density distances) which implicitly encourages consistent label assignments and reduces sensitivity to isolated noisy pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>No explicit taxonomy is given; in practice the method addresses spurious bivariate associations indirectly via use of interventional/background labels and similarity-based smoothing (so may mitigate irrelevant variable correlations and some measurement noise), but confounding and selection bias are not explicitly resolved by specialized techniques in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Implicit via similarity weighting (W) and Laplacian smoothness regularizer: pairs that are distant in the learned density-metric have exponentially small similarity weights and thus contribute less to the smoothness term, which reduces influence of inconsistent/noisy pairs; explicit downweighting of spurious signals is not developed.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Evaluation uses held-out interventional data as gold-standard to test/refute predicted causal edges (i.e. empirical refutation via unseen interventions), but the algorithm itself does not implement an internal refutation procedure to reject spurious causal claims beyond thresholding scored outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Qualitative: SSCD achieved markedly higher AUC than baseline methods (Pearson/Kendall, Lasso, IDA) across the yeast dataset (D1) and outperformed others on TCGA (D3); in some cell-line cases (D2) SSCD was competitive with a specialized Bayesian model and outperformed baselines for certain cell lines. Performance improves as the fraction ρ of known labels increases. Exact numeric AUCs are reported in Figures 1-4 but not quoted as point values in text.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baselines (Pearson/Kendall, Lasso, IDA) produced lower AUCs across the same evaluation tasks; no direct ablation isolating the effect of label-usage vs. pure unsupervised SSCD variant is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Framing causal discovery as semi-supervised learning (SSCD) yields substantial gains in detecting causal effects when partial interventional/background labels are available; a simple bivariate histogram featurization plus manifold regularization generalizes across diverse biological datasets. The approach disambiguates many spurious bivariate regularities by leveraging labeled edges, but the paper does not offer explicit procedures targeted at distractor detection/removal or formal guarantees against confounding or selection bias; performance increases with more labelled edges and is lower in harder sampling regimes (e.g. row-wise held-out rows of the adjacency matrix).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e763.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e763.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ManifoldReg</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Manifold Regularization (Belkin et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph-based semi-supervised learning framework that regularizes a classifier to be smooth with respect to the geometry of the data-manifold encoded by a similarity graph and its Laplacian.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Manifold regularization: A geometric framework for learning from labeled and unlabeled examples</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Manifold regularization (graph Laplacian smoothing)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Construct similarity matrix W from sample-wise distances, form graph Laplacian L = D - W (or normalized Laplacian), and solve an objective combining empirical loss on labelled data with a Laplacian-based smoothness penalty that penalizes large differences in function values between similar data points; closed-form solutions exist for some settings and this approach leverages both labelled and unlabelled data geometry.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same as SSCD (biological datasets D1-D3)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Used on pairwise-featurized objects derived from biological experimental datasets; the learning environment is batch semi-supervised classification over a graph of variable-pair objects rather than an interactive/active experimental environment.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Not explicitly designed for distractor detection; smoothness regularization decreases the influence of isolated noisy/unrepresentative objects relative to manifold-consistent clusters, which can reduce the impact of some irrelevant/spurious patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Implicitly mitigates isolated noisy samples and inconsistent pairwise signals by promoting label-smoothness across similar objects; does not explicitly address confounding or selection bias.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Similarity weighting via W and Laplacian penalty reduces influence of points dissimilar to labeled clusters.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Used as the core semi-supervised engine in SSCD; contributes to improved AUC in empirical evaluations when combined with bivariate featurization and partial labels.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Not separately ablated in paper; manifold regularization is central to SSCD's performance but no direct comparison to other semi-supervised learners is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Manifold regularization provides an effective mechanism to propagate partial interventional labels across similar variable-pair objects, improving causal edge prediction over simple unsupervised distance-thresholding; the geometric smoothness prior helps stabilize predictions but is not a dedicated distractor-robust module.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e763.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e763.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BivHistFeat</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bivariate histogram featurization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple featurization that represents each variable pair by a histogram-based estimate of its bivariate density (PCA-reduced), used to compute distances between pairs for graph construction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Bivariate histogram featurization (histogram DE + PCA)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>For each variable pair, truncate/standardize data to a compact domain, compute an m×m regular grid histogram estimator (bin width h; here bins of width 0.2 and h≈0.2), form vectorized histogram frequencies, reduce dimensionality via PCA (to 100 dims in experiments), and use L2 distance between estimated densities (or between histogram feature vectors) as the pairwise distance for similarity weighting.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same biological datasets (D1-D3)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied to observational and interventional samples drawn from biological experiments; a low-cost density estimator used for featurization in semi-supervised causal learning.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Measurement noise and finite-sample estimation error are addressed by consistent histogram estimation and PCA reduction (reduces variance), but no explicit method for confounders or irrelevant variables is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Enables efficient O(1) evaluation per pair (histogram lookup) and with manifold regularization leads to superior AUC vs. baselines in experiments; histogram choice trades statistical rate for computational speed but was adequate empirically.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Not separately ablated; no explicit comparison to other featurizations reported in main experiments (kernel embeddings mentioned but not used).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>A simple, consistent histogram-based density featurization combined with PCA suffices to produce effective pairwise features for semi-supervised causal discovery, offering computational advantages though not optimizing statistical rates relative to kernel density estimators.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e763.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e763.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KernelEmbed (Lopez-Paz)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Kernel embedding / supervised cause-effect learning (Lopez-Paz et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A supervised approach to cause-effect inference that uses kernel mean embeddings of joint and marginal distributions to featurize pairs for learning causal directionality.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Towards a learning theory of causation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Kernel-embedding-based supervised causal learning</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Featurizes bivariate distributions using kernel mean embeddings (or other kernel-based statistics) and trains a classifier to predict causal relations from these features; Lopez-Paz et al. developed supervised learning formulations for cause-effect inference using such embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Mentioned as related supervised causal-learning approach (no specific environment in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Originally applied to synthetic and benchmark cause-effect pairs; in this paper it is mentioned as a contrasting supervised featurization strategy (kernel embeddings) rather than employed.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Not evaluated in this paper; cited as a prior supervised featurization approach (paper contrasts its histogram choice with the kernel embedding of Lopez-Paz et al.).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Kernel embeddings are a plausible featurization for supervised causal learning, but here the authors preferred a histogram estimator for computational reasons; no claims about distractor robustness are made in the present text.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e763.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e763.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IDA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Intervention-calculus when the DAG is Absent (IDA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that estimates bounds on causal effects from observational data by combining structure learning (CPDAG) with adjustment/calculus to produce estimates of total causal effects when the true DAG is unknown.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Estimating high-dimensional intervention effects from observational data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>IDA (Maathuis et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Estimates a CPDAG from observational data, enumerates DAGs in the equivalence class, computes intervention effects for each DAG (via do-calculus/adjustment), and reports bounds/estimates (often a conservative lower bound) for possible total effects; used here as a baseline comparing predicted causal scores to interventional gold-standards.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Used as baseline on the biological datasets (D1-D3)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied to the same observational/training data matrices (no use of background interventional labels) and evaluated against held-out interventional results.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Not specifically designed to handle distractors beyond structural learning; correctness depends on faithfulness/Markov assumptions and adequate structure estimation, so spurious associations due to unmeasured confounding can break guarantees.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Does not explicitly target measurement-level distractors; susceptible to unmeasured confounding and model misspecification.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Baseline performance in experiments was generally worse (lower AUC) than SSCD on the tested datasets according to Figures 1-4; no quantitative breakdown against distractor scenarios is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Used as a standard causal baseline; under the experimental conditions in this paper (partial interventional labels available to SSCD), IDA performed worse than SSCD, suggesting benefits of leveraging background interventional labels and semi-supervised learning in these tasks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e763.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e763.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Lasso</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>L1-penalized regression (Lasso)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Penalized regression using an L1 penalty for variable selection; used here as a baseline by regressing each target variable on others and using nonzero coefficients as putative causal predictors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Regression shrinkage and selection via the lasso</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Lasso (L1-penalized regression)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>For each target variable j, regress j on all other variables i ≠ j with an L1 penalty to encourage sparse predictors; nonzero regression coefficients are used as an indicator of potential causal influence in baseline comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Applied as baseline on biological datasets D1-D3</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Standard observational regression analysis on batch datasets; not an interactive experimental design.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>L1 regularization performs implicit variable selection by shrinking many coefficients to zero, which can reduce the influence of irrelevant predictors (a form of distractor suppression under appropriate conditions).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Can mitigate irrelevant/weakly predictive variables but does not by itself resolve confounding or selection bias; susceptible to correlated predictors and model mis-specification.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Variable selection via coefficient shrinkage and thresholding.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Penalization (L1) shrinks coefficients of less predictive variables toward zero.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Served as a baseline with lower AUC than SSCD in experiments; no targeted distractor robustness evaluation reported.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Simple penalized regression is a reasonable baseline that can reduce influence of irrelevant predictors via L1 regularization, but in the evaluated tasks it underperformed SSCD which exploited partial interventional labels and manifold smoothing.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e763.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e763.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>InvPred</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Invariant prediction (Peters, Bühlmann, Meinshausen)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method for causal inference that exploits invariance of conditional distributions across environments to identify causal variables and provide confidence intervals for causal coefficients.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal inference using invariant prediction: Identification and confidence intervals</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Invariant prediction</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Searches for subsets of predictors for which the conditional distribution of the target given the subset remains invariant across different environments/interventions; variables in the stable subset are inferred to be causal (invariant predictors) and the method can provide confidence intervals under assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Mentioned in references as related causal method; not used in experiments here</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Designed for settings with multiple environments/interventions (an interactive/experimental flavor) and explicitly targets spurious correlations by leveraging invariance across contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detects and removes spurious correlates by testing invariance across environments: features whose predictive relationship changes between environments are downweighted or excluded from the stable causal set.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Specifically addresses spurious correlations due to environment-specific associations and some classes of confounding that vary across environments; provides formal identification under assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Statistical tests for invariance of conditional distributions across environments; non-invariant predictors flagged as spurious.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Exclusion or non-selection of non-invariant variables; inference focuses on invariant subsets.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Uses cross-environmental tests to refute non-invariant (spurious) predictor-target relationships; constructs confidence intervals for causal parameters under invariance assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Not evaluated in the experiments of this paper, but cited as a method specifically designed to exploit multi-environment/interventional data to remove spurious signals.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Although not used in the present experiments, invariant prediction is directly relevant to the query: it is an explicit technique to detect and refute spurious/unstable associations by leveraging multiple environments; the authors include it in references as related literature but do not combine it with SSCD.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Manifold regularization: A geometric framework for learning from labeled and unlabeled examples <em>(Rating: 2)</em></li>
                <li>Towards a learning theory of causation <em>(Rating: 2)</em></li>
                <li>Estimating high-dimensional intervention effects from observational data <em>(Rating: 2)</em></li>
                <li>Causal inference using invariant prediction: Identification and confidence intervals <em>(Rating: 2)</em></li>
                <li>Context specificity in causal signaling networks revealed by phosphoprotein profiling <em>(Rating: 1)</em></li>
                <li>Inferring network structure from interventional timecourse experiments <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-763",
    "paper_id": "paper-88516099",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "SSCD",
            "name_full": "Semi-Supervised Causal Discovery",
            "brief_description": "A direct machine-learning approach that frames causal edge detection as a semi-supervised label-learning problem, using bivariate featurization and manifold-regularized learning to predict which variable pairs are causal given partial interventional/background labels.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Semi-Supervised Causal Discovery (SSCD)",
            "method_description": "Treats each ordered variable pair (i,j) as an object with binary label Y_k indicating presence/absence of a causal effect. Featurizes each pair by estimating its bivariate distribution (here via a bivariate histogram, PCA-reduced), defines an L2 metric between pairwise density estimates, converts distances to a similarity matrix W = exp(-d^2/(2σ^2)), builds the (normalized) graph Laplacian L, and solves a manifold-regularization objective that trades label-fitting on known (interventional/background) labels against smoothness of the label function over the similarity graph; optimization has a closed-form solution and yields real-valued scores and binary label estimates. Implementation details: data truncated to [-3,3]^2, histogram bin width 0.2, PCA to 100 dims, computational cost O(m^3) where m is number of pairs.",
            "environment_name": "Biological experimental datasets (Yeast knockout, Kinase inhibitor time-course, TCGA proteomics)",
            "environment_description": "Three real biological data domains: (D1) yeast gene-knockout experiments with many interventional samples (knockouts) and observational samples; (D2) kinase inhibitor time-course experiments on cell lines with several interventional regimes and timepoints; (D3) observational human cancer proteomic samples (TCGA) with a literature-derived reference causal graph. These are real experimental data environments that include explicit interventions in D1 and D2 (i.e. active experimentation was performed by the experimentalists), not a synthetic/virtual lab or simulated interactive environment.",
            "handles_distractors": null,
            "distractor_handling_technique": "No explicit distractor-detection module is proposed. The method leverages partial interventional/background labels to disambiguate spurious associations and uses manifold-smoothness regularization on a similarity graph (built from bivariate density distances) which implicitly encourages consistent label assignments and reduces sensitivity to isolated noisy pairs.",
            "spurious_signal_types": "No explicit taxonomy is given; in practice the method addresses spurious bivariate associations indirectly via use of interventional/background labels and similarity-based smoothing (so may mitigate irrelevant variable correlations and some measurement noise), but confounding and selection bias are not explicitly resolved by specialized techniques in the paper.",
            "detection_method": null,
            "downweighting_method": "Implicit via similarity weighting (W) and Laplacian smoothness regularizer: pairs that are distant in the learned density-metric have exponentially small similarity weights and thus contribute less to the smoothness term, which reduces influence of inconsistent/noisy pairs; explicit downweighting of spurious signals is not developed.",
            "refutation_method": "Evaluation uses held-out interventional data as gold-standard to test/refute predicted causal edges (i.e. empirical refutation via unseen interventions), but the algorithm itself does not implement an internal refutation procedure to reject spurious causal claims beyond thresholding scored outputs.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Qualitative: SSCD achieved markedly higher AUC than baseline methods (Pearson/Kendall, Lasso, IDA) across the yeast dataset (D1) and outperformed others on TCGA (D3); in some cell-line cases (D2) SSCD was competitive with a specialized Bayesian model and outperformed baselines for certain cell lines. Performance improves as the fraction ρ of known labels increases. Exact numeric AUCs are reported in Figures 1-4 but not quoted as point values in text.",
            "performance_without_robustness": "Baselines (Pearson/Kendall, Lasso, IDA) produced lower AUCs across the same evaluation tasks; no direct ablation isolating the effect of label-usage vs. pure unsupervised SSCD variant is provided.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Framing causal discovery as semi-supervised learning (SSCD) yields substantial gains in detecting causal effects when partial interventional/background labels are available; a simple bivariate histogram featurization plus manifold regularization generalizes across diverse biological datasets. The approach disambiguates many spurious bivariate regularities by leveraging labeled edges, but the paper does not offer explicit procedures targeted at distractor detection/removal or formal guarantees against confounding or selection bias; performance increases with more labelled edges and is lower in harder sampling regimes (e.g. row-wise held-out rows of the adjacency matrix).",
            "uuid": "e763.0"
        },
        {
            "name_short": "ManifoldReg",
            "name_full": "Manifold Regularization (Belkin et al.)",
            "brief_description": "A graph-based semi-supervised learning framework that regularizes a classifier to be smooth with respect to the geometry of the data-manifold encoded by a similarity graph and its Laplacian.",
            "citation_title": "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples",
            "mention_or_use": "use",
            "method_name": "Manifold regularization (graph Laplacian smoothing)",
            "method_description": "Construct similarity matrix W from sample-wise distances, form graph Laplacian L = D - W (or normalized Laplacian), and solve an objective combining empirical loss on labelled data with a Laplacian-based smoothness penalty that penalizes large differences in function values between similar data points; closed-form solutions exist for some settings and this approach leverages both labelled and unlabelled data geometry.",
            "environment_name": "Same as SSCD (biological datasets D1-D3)",
            "environment_description": "Used on pairwise-featurized objects derived from biological experimental datasets; the learning environment is batch semi-supervised classification over a graph of variable-pair objects rather than an interactive/active experimental environment.",
            "handles_distractors": null,
            "distractor_handling_technique": "Not explicitly designed for distractor detection; smoothness regularization decreases the influence of isolated noisy/unrepresentative objects relative to manifold-consistent clusters, which can reduce the impact of some irrelevant/spurious patterns.",
            "spurious_signal_types": "Implicitly mitigates isolated noisy samples and inconsistent pairwise signals by promoting label-smoothness across similar objects; does not explicitly address confounding or selection bias.",
            "detection_method": null,
            "downweighting_method": "Similarity weighting via W and Laplacian penalty reduces influence of points dissimilar to labeled clusters.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Used as the core semi-supervised engine in SSCD; contributes to improved AUC in empirical evaluations when combined with bivariate featurization and partial labels.",
            "performance_without_robustness": "Not separately ablated in paper; manifold regularization is central to SSCD's performance but no direct comparison to other semi-supervised learners is reported.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Manifold regularization provides an effective mechanism to propagate partial interventional labels across similar variable-pair objects, improving causal edge prediction over simple unsupervised distance-thresholding; the geometric smoothness prior helps stabilize predictions but is not a dedicated distractor-robust module.",
            "uuid": "e763.1"
        },
        {
            "name_short": "BivHistFeat",
            "name_full": "Bivariate histogram featurization",
            "brief_description": "A simple featurization that represents each variable pair by a histogram-based estimate of its bivariate density (PCA-reduced), used to compute distances between pairs for graph construction.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Bivariate histogram featurization (histogram DE + PCA)",
            "method_description": "For each variable pair, truncate/standardize data to a compact domain, compute an m×m regular grid histogram estimator (bin width h; here bins of width 0.2 and h≈0.2), form vectorized histogram frequencies, reduce dimensionality via PCA (to 100 dims in experiments), and use L2 distance between estimated densities (or between histogram feature vectors) as the pairwise distance for similarity weighting.",
            "environment_name": "Same biological datasets (D1-D3)",
            "environment_description": "Applied to observational and interventional samples drawn from biological experiments; a low-cost density estimator used for featurization in semi-supervised causal learning.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Measurement noise and finite-sample estimation error are addressed by consistent histogram estimation and PCA reduction (reduces variance), but no explicit method for confounders or irrelevant variables is provided.",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Enables efficient O(1) evaluation per pair (histogram lookup) and with manifold regularization leads to superior AUC vs. baselines in experiments; histogram choice trades statistical rate for computational speed but was adequate empirically.",
            "performance_without_robustness": "Not separately ablated; no explicit comparison to other featurizations reported in main experiments (kernel embeddings mentioned but not used).",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "A simple, consistent histogram-based density featurization combined with PCA suffices to produce effective pairwise features for semi-supervised causal discovery, offering computational advantages though not optimizing statistical rates relative to kernel density estimators.",
            "uuid": "e763.2"
        },
        {
            "name_short": "KernelEmbed (Lopez-Paz)",
            "name_full": "Kernel embedding / supervised cause-effect learning (Lopez-Paz et al.)",
            "brief_description": "A supervised approach to cause-effect inference that uses kernel mean embeddings of joint and marginal distributions to featurize pairs for learning causal directionality.",
            "citation_title": "Towards a learning theory of causation",
            "mention_or_use": "mention",
            "method_name": "Kernel-embedding-based supervised causal learning",
            "method_description": "Featurizes bivariate distributions using kernel mean embeddings (or other kernel-based statistics) and trains a classifier to predict causal relations from these features; Lopez-Paz et al. developed supervised learning formulations for cause-effect inference using such embeddings.",
            "environment_name": "Mentioned as related supervised causal-learning approach (no specific environment in this paper)",
            "environment_description": "Originally applied to synthetic and benchmark cause-effect pairs; in this paper it is mentioned as a contrasting supervised featurization strategy (kernel embeddings) rather than employed.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": "Not evaluated in this paper; cited as a prior supervised featurization approach (paper contrasts its histogram choice with the kernel embedding of Lopez-Paz et al.).",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Kernel embeddings are a plausible featurization for supervised causal learning, but here the authors preferred a histogram estimator for computational reasons; no claims about distractor robustness are made in the present text.",
            "uuid": "e763.3"
        },
        {
            "name_short": "IDA",
            "name_full": "Intervention-calculus when the DAG is Absent (IDA)",
            "brief_description": "A method that estimates bounds on causal effects from observational data by combining structure learning (CPDAG) with adjustment/calculus to produce estimates of total causal effects when the true DAG is unknown.",
            "citation_title": "Estimating high-dimensional intervention effects from observational data",
            "mention_or_use": "use",
            "method_name": "IDA (Maathuis et al.)",
            "method_description": "Estimates a CPDAG from observational data, enumerates DAGs in the equivalence class, computes intervention effects for each DAG (via do-calculus/adjustment), and reports bounds/estimates (often a conservative lower bound) for possible total effects; used here as a baseline comparing predicted causal scores to interventional gold-standards.",
            "environment_name": "Used as baseline on the biological datasets (D1-D3)",
            "environment_description": "Applied to the same observational/training data matrices (no use of background interventional labels) and evaluated against held-out interventional results.",
            "handles_distractors": null,
            "distractor_handling_technique": "Not specifically designed to handle distractors beyond structural learning; correctness depends on faithfulness/Markov assumptions and adequate structure estimation, so spurious associations due to unmeasured confounding can break guarantees.",
            "spurious_signal_types": "Does not explicitly target measurement-level distractors; susceptible to unmeasured confounding and model misspecification.",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Baseline performance in experiments was generally worse (lower AUC) than SSCD on the tested datasets according to Figures 1-4; no quantitative breakdown against distractor scenarios is provided.",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Used as a standard causal baseline; under the experimental conditions in this paper (partial interventional labels available to SSCD), IDA performed worse than SSCD, suggesting benefits of leveraging background interventional labels and semi-supervised learning in these tasks.",
            "uuid": "e763.4"
        },
        {
            "name_short": "Lasso",
            "name_full": "L1-penalized regression (Lasso)",
            "brief_description": "Penalized regression using an L1 penalty for variable selection; used here as a baseline by regressing each target variable on others and using nonzero coefficients as putative causal predictors.",
            "citation_title": "Regression shrinkage and selection via the lasso",
            "mention_or_use": "use",
            "method_name": "Lasso (L1-penalized regression)",
            "method_description": "For each target variable j, regress j on all other variables i ≠ j with an L1 penalty to encourage sparse predictors; nonzero regression coefficients are used as an indicator of potential causal influence in baseline comparisons.",
            "environment_name": "Applied as baseline on biological datasets D1-D3",
            "environment_description": "Standard observational regression analysis on batch datasets; not an interactive experimental design.",
            "handles_distractors": true,
            "distractor_handling_technique": "L1 regularization performs implicit variable selection by shrinking many coefficients to zero, which can reduce the influence of irrelevant predictors (a form of distractor suppression under appropriate conditions).",
            "spurious_signal_types": "Can mitigate irrelevant/weakly predictive variables but does not by itself resolve confounding or selection bias; susceptible to correlated predictors and model mis-specification.",
            "detection_method": "Variable selection via coefficient shrinkage and thresholding.",
            "downweighting_method": "Penalization (L1) shrinks coefficients of less predictive variables toward zero.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Served as a baseline with lower AUC than SSCD in experiments; no targeted distractor robustness evaluation reported.",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Simple penalized regression is a reasonable baseline that can reduce influence of irrelevant predictors via L1 regularization, but in the evaluated tasks it underperformed SSCD which exploited partial interventional labels and manifold smoothing.",
            "uuid": "e763.5"
        },
        {
            "name_short": "InvPred",
            "name_full": "Invariant prediction (Peters, Bühlmann, Meinshausen)",
            "brief_description": "A method for causal inference that exploits invariance of conditional distributions across environments to identify causal variables and provide confidence intervals for causal coefficients.",
            "citation_title": "Causal inference using invariant prediction: Identification and confidence intervals",
            "mention_or_use": "mention",
            "method_name": "Invariant prediction",
            "method_description": "Searches for subsets of predictors for which the conditional distribution of the target given the subset remains invariant across different environments/interventions; variables in the stable subset are inferred to be causal (invariant predictors) and the method can provide confidence intervals under assumptions.",
            "environment_name": "Mentioned in references as related causal method; not used in experiments here",
            "environment_description": "Designed for settings with multiple environments/interventions (an interactive/experimental flavor) and explicitly targets spurious correlations by leveraging invariance across contexts.",
            "handles_distractors": true,
            "distractor_handling_technique": "Detects and removes spurious correlates by testing invariance across environments: features whose predictive relationship changes between environments are downweighted or excluded from the stable causal set.",
            "spurious_signal_types": "Specifically addresses spurious correlations due to environment-specific associations and some classes of confounding that vary across environments; provides formal identification under assumptions.",
            "detection_method": "Statistical tests for invariance of conditional distributions across environments; non-invariant predictors flagged as spurious.",
            "downweighting_method": "Exclusion or non-selection of non-invariant variables; inference focuses on invariant subsets.",
            "refutation_method": "Uses cross-environmental tests to refute non-invariant (spurious) predictor-target relationships; constructs confidence intervals for causal parameters under invariance assumptions.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": "Not evaluated in the experiments of this paper, but cited as a method specifically designed to exploit multi-environment/interventional data to remove spurious signals.",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Although not used in the present experiments, invariant prediction is directly relevant to the query: it is an explicit technique to detect and refute spurious/unstable associations by leveraging multiple environments; the authors include it in references as related literature but do not combine it with SSCD.",
            "uuid": "e763.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples",
            "rating": 2,
            "sanitized_title": "manifold_regularization_a_geometric_framework_for_learning_from_labeled_and_unlabeled_examples"
        },
        {
            "paper_title": "Towards a learning theory of causation",
            "rating": 2,
            "sanitized_title": "towards_a_learning_theory_of_causation"
        },
        {
            "paper_title": "Estimating high-dimensional intervention effects from observational data",
            "rating": 2,
            "sanitized_title": "estimating_highdimensional_intervention_effects_from_observational_data"
        },
        {
            "paper_title": "Causal inference using invariant prediction: Identification and confidence intervals",
            "rating": 2,
            "sanitized_title": "causal_inference_using_invariant_prediction_identification_and_confidence_intervals"
        },
        {
            "paper_title": "Context specificity in causal signaling networks revealed by phosphoprotein profiling",
            "rating": 1,
            "sanitized_title": "context_specificity_in_causal_signaling_networks_revealed_by_phosphoprotein_profiling"
        },
        {
            "paper_title": "Inferring network structure from interventional timecourse experiments",
            "rating": 1,
            "sanitized_title": "inferring_network_structure_from_interventional_timecourse_experiments"
        }
    ],
    "cost": 0.01595925,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Causal Discovery as Semi-Supervised Learning</p>
<p>Chris J Oates 
Newcastle University
Steven M. Hill</p>
<p>DZNEDuncan A Blythe 
University of Cambridge</p>
<p>Sach Bonn 
University of Cambridge</p>
<p>DZNEBonn Mukherjee 
University of Cambridge</p>
<p>Causal Discovery as Semi-Supervised Learning</p>
<p>We frame causal discovery as a semi-supervised machine learning task. The idea is to allow direct learning of a causal graph by treating indicators of causal influence between variables as "labels". Available data on the variables of interest are used to provide features for the labelling task. Background knowledge or any available interventional data provide labels on some edges in the graph and the remaining edges are treated as unlabelled. To illustrate the key ideas, we develop a distance-based approach (based on simple bivariate histograms) within a semi-supervised manifold regularization framework. We present empirical results on three different biological datasets (including data where causal effects can be verified by experimental intervention), which demonstrate the efficacy and highly general nature of the approach as well as its simplicity from a user's point of view. arXiv:1612.05678v2 [stat.ML] 1 Aug 2018 on variable j (we make these notions more precise below). Let A(G) be the binary adjacency matrix corresponding to the unknown true causal graph G. The idea is to treat the entries in A as binary "labels" in a machine learning sense (as inLopez-Paz et al., 2015). From this point of view, the task of constructing the estimatorĜ(X, Φ) is essentially one of learning the labels A ij given data and some known labels (derived from Φ). We treat this task within a semi-supervised learning framework.Causal discovery is usually addressed either using explicitly causal approaches (e.g. following Pearl, 2009) or by constraining models using details of the underlying science (e.g. suitable nonlinearities, as inOates et al., 2014). In contrast, it may seem crude to attempt to directly learn the causal graph. However, we note that the claim that there exists an approach -based on any modeling framework -which allows causal discovery using available data and knowledge is equivalent to the claim that there exists an estimator of the formĜ(X, Φ) which performs well at the labelling task. If such an estimator exists, direct learning may be effective.The remainder of the paper is organised as follows. We first introduce some notation and discuss in more detail how causal discovery can be viewed as a semi-supervised learning task. Our formulation is general and shows how essentially any existing semi-supervised approach can be adapted for causal discovery. To fix ideas, we then propose a specific approach, based on manifold regularization using a simple bivariate featurization. Using this specific approach -which we call Semi-Supervised Causal Discovery (SSCD) -we present empirical results using three biological datasets. The results cover a range of scenarios and include examples with explicitly interventional data that allow us to objectively assess the performance of SSCD.</p>
<p>Introduction</p>
<p>Causal discovery is concerned with identifying causal relationships between variables. Consider a set of p variables indexed V = {1 . . . p}. The version of the causal discovery task we focus on here is to determine, for each pair (i, j) ∈ V × V , whether or not i exerts a causal influence on j. We focus on the binary "detection" problem (of determining whether or not i exerts a causal influence on j) rather than estimation of the magnitude of any causal effect.</p>
<p>Models with explicit causal semantics, such as (causal) directed acyclic graphs (DAGs) are a natural and popular choice for causal discovery (Pearl, 2009;Maathuis et al., 2009;Spencer et al., 2015). Such formulations specify a multivariate data-generating model with structure and parameters that encode causal relationships. In a different vein, there have been some interesting recent efforts in the direction of labelling pairs of variables as causal or otherwise, such as in Lopez-Paz et al. (2015) and . Our work is in this latter vein. Specifically, we frame causal discovery as a task in semi-supervised learning. We address essentially the same task as a traditional causal discovery -that of estimating a causal graph over a defined set of verticesbut via a "direct" machine learning approach that allows the inclusion of any available information concerning known cause-effect relationships.</p>
<p>In general terms the idea is as follows: Let X denote the available data and Φ denote any available knowledge on causal relationships among the variables indexed in V (e.g. based on background knowledge or experimental intervention). Then, the causal discovery task amounts to constructing an estimator of the formĜ(X, Φ), whereĜ is a directed graph with vertex set V and edge set E(Ĝ), with (i, j) ∈ E(Ĝ) corresponding to the claim that variable i has a causal influence 2 Methods</p>
<p>Notation</p>
<p>Let V = {1 . . . p} index a set of variables whose mutual causal relationships are of interest. The object of estimation is a directed graph G with vertex set V and edge set E, with (i, j) ∈ E indicating that variable i has a causal influence on j. That is, G is the unknown true causal graph. In general, the graph G need not be acyclic. We restrict discussion to the case where a variable i either does or does not have such an influence on j. The precise nature of causal influences to be considered will depend on the application but could include, for example, direct or indirect causes. Where useful, we use V (G), E(G) to denote the vertex and edge sets respectively of a graph G.</p>
<p>Let A(G) be the binary adjacency matrix corresponding to graph G. To make the mapping between causal discovery and machine learning more transparent, we introduce linear indexing by k of the pairs (i, j). That is, k refers to a pair (i, j) ∈ V ×V . Where needed, we make the correspondence explicit, denoting by (i(k), j(k)) the variable pair corresponding to linear index k and by k(i, j) the linear index for pair (i, j). Let Y k = A i(k),j(k) be a binary variable corresponding to an entry in the adjacency matrix A. These Y k 's are the labels or outputs to be learned. The available data are denoted X. Depending on the specific problem X may comprise observational and/or interventional data. Available knowledge about causal relationships between the variables V is denoted Φ.</p>
<p>Causal Discovery as Semi-Supervised Learning</p>
<p>Thus, the task is to estimate the Y k 's using X and Φ. This is done using a semi-supervised estimator Y (X, Φ) (we make the connection to semi-supervised learning explicit shortly). For now assume availability of such an estimator (we discuss one specific approach below). Then fromŶ we have an estimate of the graph of interest asĜ(X, Φ) = (V, E(Ĝ(X, Φ))) (recall that the vertex set V is known) with the edge set specified via the semi-supervised learner as
(i, j) ∈ E(Ĝ(X, Φ)) ⇐⇒Ŷ (X, Φ) k(i,j) = 1.(1)
Background knowledge Φ could be based on relevant science or on available interventional data. For example, in a given scientific setting, certain cause-effect information may be known from previous work or theory. Alternatively, if some interventional data are available in the study at hand, this gives information on some cause-effect pairs. Whatever the source of the information, assume that it is known that certain pairs (i, j) are either causal pairs (positive information) or not causal pairs (negative information). Using the notation above, this amounts to knowing, for some pairs k, the value of Y k . In the language of semi-supervised learning, the pairs whose causal status is known correspond to the labelled objects and the remaining pairs are the unlabelled objects.</p>
<p>For each pair k, some of the data, or some transformation thereof will be used as predictors or inputs, denote these generically as g k (X). That is, g k is a featurization of the data, with the featurization specific to variables i(k), j(k). Let K be the set of linear indices (i.e. k ∈ K is a variable pair), L ⊂ K be the variable pairs with labels available (via Φ) and U = K \ L be the set of unlabelled pairs. Let Y L be a binary vector comprising the m L = |L| available labels and Y U be an unknown binary vector of length m U = |U |. The available labels are determined by the background information Φ and we can write Y L (Φ) to make this explicit. A semi-supervised learner gives estimates for the unlabelled objects, given the data and available labels, i.e. an estimate of the formŶ U (g(X), Y L (Φ)). With these in hand we have estimates for all labels and therefore for the edge set of the causal graph via (1).</p>
<p>Formulated in this way, it is clear that essentially any combination of featurization g and semisupervised learner can be used to provide a causal discovery approach. Below, as a practical example, we explore graph-based manifold learning (following Belkin et al., 2006) combined with a simple bivariate featurization.</p>
<p>A Bivariate Featurization</p>
<p>For distance-based learning, we require a distance measure between objects (here, variable pairs) k, k ∈ K. The simplest candidate distance between variable pairs k, k is based only on the bivariate distribution for the variables comprising the pairs (we make this notion precise below). Proofs of propositions appearing in this Section are provided in Appendix A.</p>
<p>Distance metrics between variable pairs</p>
<p>Let X denote the p-dimensional random variable whose n realizations comprise the rows of the data matrix X. Assume X ∈ X p = [a, b] p and that X p is endowed with the Borel σ-algebra B p = B(X p ). Let P be the set of all probability measures on (X 2 , B 2 ) that admit a twice continuously differentiable density function π = dΠ/dΛ 2 with respect to Lebesgue measure Λ 2 . Let Π k be the bivariate (marginal) distribution for components i(k), j(k) ∈ V of X. Assumption 1. Each Π k admits a density function π k ∈ P.</p>
<p>If available, the distributions Π k , Π k could be used to define a distance between the pairs k, k . Let d P : P × P → [0, ∞) denote a pseudo-metric 1 defined on the space P. Since we do not have access to the underlying distributions, we construct an analogue using the available data X. Let S n := [a, b] 2n denote the space of possible bivariate samples (the sample size is n) and S k ∈ S n denote the subset of the data for the variable pair k, i.e. S k = {X l,i(k) , X l,j(k) } l=1...n . Let κ : S n → P be a density estimator (DE). For notational simplicity we use κ(S) to refer both to the probability distribution and (if it exists) the associated density; the intended meaning will be clear from context.</p>
<p>We consider sample quantities of the form d S = d P • (κ × κ). That is, given data S k , S k ∈ S n on two pairs k, k , the DE is applied separately to produce density estimates κ(S k ) and κ(S k ), that are compared using d P to give d S (S k , S k ) = d P (κ(S k ), κ(S k )). This construction ensures that d S is a pseudo-metric without assumptions on the DE κ:</p>
<p>Proposition 1. Assume that d P is a pseudo-metric on P. Then d S is a pseudo-metric on S n . If, in addition, κ is injective and d P is a metric on P, then d S is a metric on S n .</p>
<p>Choice of distance metric</p>
<p>For semi-supervised learning we need a metric under which causal pairs are relatively "close" to each other. The metric we consider is:
d P (Π k , Π k ) = π k − π k 2 := X 2 |π k (x) − π k (x)| 2 dΛ 2 (x) 1/2 .
The right hand side exists since the integrand is continuous on a compact set and thus bounded. This can be contrasted with the kernel embedding that was proposed for supervised causal discovery in Lopez-Paz et al. (2015).</p>
<p>Proposition 2. d P is a metric on P.</p>
<p>The main requirement that we have of the DE is that it provides consistent estimation in · 2 norm when Π ∈ P. Specifically, consider a sequence S (n) in S n indexed by the number n of data points. That is, S (n) is built from n independent draws from Π (the shorthand notation S (n) ∼ Π will be used). Let π be the density function for Π. Then κ is said to be "consistent" if π − κ(S (n) ) 2 = o P (1) holds for S (n) ∼ Π and all fixed Π ∈ P.
Proposition 3. Suppose κ is consistent. Then, for S (n) ∼ Π,S (n) ∼Π, we have that d S (S (n) ,S (n) ) = d P (Π,Π) + o P (1).
Thus d S approximates the idealised metric d P in the limit of draws from Π andΠ.</p>
<p>For the experiments in this paper, motivated by computational ease, we used a simple bivariate histogram as the DE κ. To this end, partition X 2 into an m × m regular grid whose (i, j)th element is
B i,j = a + (b − a) i − 1 m , a + (b − a) i m × a + (b − a) j − 1 m , a + (b − a) j m .
The standard bandwidth notation h = m −1 will also be used. For a scatter plot S ∈ S n , let b i,j denote the number of elements that belong to the set B i,j . Then the histogram estimator is
κ(S)(x) = m i,j=1 b i,j n 1 h 2 I[x ∈ B i,j ].
This DE is consistent in the sense of Proposition 3. Indeed:</p>
<p>Proposition 4. Let the bandwidth parameter h of the histogram estimator κ be chosen such that nh 2 → ∞. Then κ is consistent. Moreover, an optimal choice of h n −1/4 leads to π−κ(S (n) ) 2 = O P (n −1/4 ).</p>
<p>We note that this histogram DE is not rate optimal for the class P (for comparison, kernel DEs attain a rate of O P (n −2/3 ) over the same class P of twice continuously differentiable bivariate densities considered here, see Wand and Jones, 1994). However, an important advantage of the histogram DE is that the subsequent evaluation of κ(S) is O(1), compared with O(n) for the kernel DE.</p>
<p>Implementation</p>
<p>The above arguments support the use of a bivariate histogram to provide a simple featurization for variable pairs. In practice, for all examples below, the data were standardised, then truncated to [−3, 3] 2 , following which a bivariate histogram with bins of fixed width 0.2 was used. The dimension of the resulting feature matrix was then reduced (to 100) using PCA.</p>
<p>Semi-Supervised Learning Using Manifold Regularization</p>
<p>Recall that the goal is to estimate binary labels Y U for a subset U ⊂ K of variable pairs given available data X and known labels Y L (Φ) for a subset L = K\U (these are taken to be obtained from available interventional experiments and/or background knowledge). For any two pairs k, k ∈ K, we also have available a distance d S (S k , S k ). This is a task in semi-supervised learning (see e.g. Belkin et al., 2006;Fergus et al., 2009) and a number of formulations and methods could be used for estimation in this setting. Here we describe a specific approach in detail, using manifold regularization methods discussed in Belkin et al. (2006).</p>
<p>Recall that m L = |L| is the number of available labels and m U = |U | the number of unlabelled pairs. Let m = m U + m L (= |K|) be the total number of pairs. Using the distance function d S we first define a m × m similarity matrix W with entries
W k,k = exp − 1 2σ 2 d S (S k , S k ) 2 .(2)
Here σ &gt; 0 must be specified and the exponential form is a heuristic only. We will use a partition of the matrix corresponding to the sets U, L as follows
W = W LL W LU W U L W U U
where we have assumed, without loss of generality, that the variable pairs are ordered so that the labelled pairs appear in the first m L places, followed by the m U = m − m L unlabelled pairs. Correspondingly let
y = y L y U ∈ {0, 1} m×2
denote a label matrix, where ones appear in the second column for those pairs k for which Y k = 1 (i.e. the columns correspond to "non-causal" and "causal" and the rows to variable pairs). The matrix y U is unknown and is the object of estimation.</p>
<p>Let D be the m × m diagonal matrix with k th diagonal entry k ∈K W k,k W k,k . DefineL = D − W and L = D −1/2L D −1/2 (i.e. the normalised graph Laplacian; all matrices with O(m 2 ) entries are denoted as bold capitals to emphasise the potential bottleneck that is associated with storage and manipulation of these matrices). Let
f = f L f U ∈ R m×2
be a matrix corresponding to a classification function f : S → R 2 evaluated at the m variable pairs K, with the superscripts indicating correspondence with the labelled and unlabelled pairs. We would like to an estimate f to agree with the known labels y L and also to take account of the manifold structure encoded in L. Following Belkin et al. (2006) we consider an objective function
J(f , y) = 1 m L tr{f L y L } + λ m 2 tr{f Lf }(3)
where the first term relates the known labels to the classification f and the second term imposes "smoothness" on the label assignment in the sense of encouraging solutions where the labels do not change quickly with respect to the distance metric (see Belkin et al. (2006) for full details). The tuning parameter λ may be set by cross-validation. We considered a coarse grid {0.001, 0.01, 0.1, 1.0} but found results to be insensitive to the choice of λ, hence for all results below we simply set λ = 0.001. Given training labels y L , label estimates are obtained by minimising the objective function described above, as described in Belkin et al. (2006). This gives
(f ,ŷ U ) = arg min f ,y U J f , y L y U(4)
where as above f ∈ R n×2 and y U ∈ {0, 1} m U ×2 . Hereŷ U provides a point estimate for the unknown labels whilef U is real-valued and can be used to rank candidate pairs. The optimization problem in Eqn. 4 admits a closed-form solution (see Sec 4.2 of Belkin et al. (2006) for details) and this was used here. The computational cost is O(m 3 ). Computation for large-scale semi-supervised learning has been studied in the literature (see e.g. Fergus et al., 2009) and a number of approaches could be used to scale up to larger problems.</p>
<p>Empirical Results</p>
<p>We tested our approach using three datasets with different characteristics. The key features of each dataset are outlined below, with a full description of each dataset appearing in the respective subsection. In all cases the goal was to predict the effect of an unseen intervention.</p>
<p>• D1: Yeast knockout data. Here, we used a dataset due to Kemmeren et al. (2014), previously considered for causal discovery in ; . The data consist of a large number of gene deletion experiments with corresponding gene expression measurements.</p>
<p>• D2: Kinase intervention data from human cancer cell lines. These data, due to Hill et al. (2017), involve a small number of interventions on human cells, with corresponding protein measurements over time.</p>
<p>• D3: Protein data from cancer patient samples. These data arise from The Cancer Genome Atlas (TCGA) and are presented in Akbani et al. (2014). There are no interventional data, but the data pertain to relatively well-understood biological processes.</p>
<p>An appealing feature of our approach is the simplicity with which it can be applied to diverse problems. In each case below, we simply concatenate available data to form the matrix X and available knowledge/interventions to form Φ, then directly apply the methods as described.</p>
<p>General Problem Set-Up</p>
<p>The basic idea in all three problems was the same: given data on a set of variables, for each (ordered) pair (i, j) of variables we sought to determine whether or not i has a causal effect on j. In the case of datasets D1 and D2 the results were directly assessed against the outcome of experiments involving explicit interventions. The availability of a large number of interventions in D1 allowed a wider range of experiments, whereas D2 is a much smaller dataset (but from human cells), allowing only a relatively limited assessment. In the case of D3, where direct interventional data (i.e. interventions on the same biological material that give rise to the training data) were not available but the relevant biological mechanisms are relatively well-understood, we compared results to a reference causal graph derived from the biochemical literature (the literature itself is in effect an encoding of extensive interventional experiments combined with biochemical knowledge).</p>
<p>Within the semi-supervised set-up, a subset of pairs were labelled at the outset and the remaining pairs were unlabelled. All empirical results below are for unlabelled pairs, i.e. in all cases the prediction of a causal effect or otherwise was unseen in the sense that the relevant interventional data on the pair of interest (or relevant entry in the reference causal graph) was not available to the estimator.</p>
<p>Note that where interventional data were available (D1 and D2), although the data allow us to read off causal effects, any such effects may be indirect: if variable j changes under intervention on variable i we can conclude that i has a causal effect on j. However the effect might be mediated by other variables that may or may not be measured. For D3, the reference causal graph encodes causal effects that may be indirect, but are at least direct relative to the set of measured variables: an edge from variable i to variable j in the reference causal graph indicates that i has a causal effect on j, and this effect is not mediated by other measured variables, but may be mediated by unmeasured variables.</p>
<p>Dataset D1: Yeast Gene Expression</p>
<p>Data. The data consisted of gene expression measurements for a total of p total = 6170 genes. Some of the data samples were measurements after knocking out a specific gene (interventional data) and the other samples were without any such intervention (observational data), with sample sizes of n int = 1479 and n obs = 160 respectively. Each of the genes intervened on was one of the p total genes. Let t(l) be the index of the gene targeted by the l th intervention. That is, the l th interventional sample was an experiment in which gene t(l) was knocked out. Let T = {t(1), . . . , t(n int )} be the subset of genes that were the target of an interventional experiment.</p>
<p>Problem set-up. Our problem set-up was as follows. We sampled a subset C ⊂ T of the genes that were intervened upon, with |C| = 50, and treated this as the vertex set of interest (i.e. setting V = C and p = |C| = 50). The goal was to uncover the mutual causal relationships between these p variables.</p>
<p>Since by design interventional data were available for all variables j ∈ C, we used these data to define an interventional "gold standard". To this end we used a robust z-score that considered the change in a variable of interest under intervention, relative to its observational variation. Let X int ij denote the measured expression level of gene j following intervention on gene i. For any pair of genes i, j ∈ C we say that i has a causal effect on j if and only if Z ij = |X int ij − M obs j |/IQR obs j &gt; τ , where M obs j is the median level of gene j (calculated using half of the observational data samples; the remaining samples were used as training data, see below), IQR obs j the corresponding interquartile range and τ = 5 was a fixed threshold. In other words, if G is the true graph of indirect causal effects between the genes in C, and A C (G) the corresponding binary adjacency matrix, we have A C (G) ij = 1 ⇐⇒ Z ij &gt; τ . To rule out absence of causal effects we required that A C (G) ij = 1 for at least 2.5% of gene pairs i, j ∈ C, i = j.</p>
<p>Given data on genes C and the corresponding ground-truth matrix A C (G), we set up the learning problem as follows. We treated a fraction ρ of the entries in A C (G) as the available labels Φ and then, using these labels and data on the variables C, we performed semi-supervised learning as described. This gave estimates for the remaining (unseen) entries in A C (G), which we compared against the corresponding true values. The data matrix X comprised expression measurements for the genes in C for n obs train = 80 observational data samples (those samples not used to calculate the robust z-scores), plus n int train interventional data samples where genes outside the set of interest were intervened upon, i.e. a subset of the 1429 genes in T \C. This set-up ensured that X include neither any of the interventional nor observational data that was used to obtain the ground-truth matrix A C (G). The total amount of training data is denoted by n train = n obs train + n int train . We considered n train = 200, 500 and 1000 (corresponding to n int train = 120, 420 and 920 respectively, sampled at random).</p>
<p>Results. We compared the proposed semi-supervised learning-based approach (SSCD) with the following methods to provide a baseline comparison (we note that none of the benchmark methods exploited the background knowledge Φ and in that sense should not be regarded as direct competitors):</p>
<p>• Pearson and Kendall correlation coefficients. A correlation coefficient was computed for each pair of variables i, j ∈ C, i = j and subsequently thresholded.</p>
<p>• Penalized regression with an L 1 penalty (Lasso; Tibshirani, 1996). Each variable j ∈ C was regressed on all other variables i ∈ C, i = j to obtain regression coefficients.</p>
<p>• Intervention-calculus when the DAG is absent (IDA; Maathuis et al., 2009Maathuis et al., , 2010. A lower bound for the total causal effect of variable i on variable j was estimated for each pair i, j ∈ C, i = j. All the methods result in a score s ij for all pairs i, j ∈ C, i = j (i.e. correlation or regression coefficients, total causal effects, or, for SSCD, the real-valuedf in (4)). For each method, these scores were thresholded and pairs (i, j) whose absolute values of the score fell above the threshold were labelled as "causal". Varying the threshold and calculating true positives and false positives with respect to the binary unseen entries in the matrix A C (G) resulted in an ROC curve. Figure 1 shows the area under the ROC curve (AUC) as a function of the proportion ρ of entries in A C (G) that were observed, for the three sample sizes. Results were averaged over 25 iterations. SSCD had a marked improvement in performance over the benchmark methods for all considered values of n train and ρ. As expected, SSCD performed better as a larger proportion of entries in A C (G) were observed (i.e. for larger ρ). For the benchmark methods, any variation in performance with ρ was solely due to the changing test set (these methods do not use the background knowledge Φ). The error bars tended to become larger with ρ due to the decreasing size of the test set. All methods had a similar performance for the three sample sizes, with some modest increases in AUC with increasing n train .</p>
<p>In the above results the pairs whose causal relationship was to be predicted were chosen at random (i.e. the set of unlabelled pairs was a random subset of the set of all pairs). In contrast, in some settings it may be relevant to predict the effect of intervening on variable i, without knowing the effect of intervening on i on any other variable. For this setting, the unlabelled set should  Figure 2: Results for dataset D1 (yeast data), row-wise sampling of causal labels. As Figure 1, except the subset of labels available in the semi-supervised set-up were obtained by sampling entire rows of the causal adjacency matrix. As before, a proportion ρ were sampled. The remaining rows were then used as test data.</p>
<p>comprise entire rows of the causal adjacency matrix A C (G). Figure 2 considers this case. To ensure a sufficient number of rows were non-empty, we imposed the additional restriction on the gene subset C that at least half of the rows had at least one causal effect. This row-wise case is a harder problem, reflected in the lower AUC values for SSCD compared with Figure 1, but we still found that SSCD outperformed the benchmark methods.</p>
<p>Dataset D2: Protein Time-Course Data</p>
<p>Data. The data consisted of protein measurements for p = 35 proteins measured at seven time points in four different "cell lines" (BT20, BT549, MCF7 and UACC812; these are laboratory models of human cancer) and under eight growth conditions. The proteins under study act as kinases (i.e. catalysts for a biochemical process known as phosphorylation) and interventions were carried out using kinase inhibitors that block the kinase activity of specific proteins. A total of four intervention regimes were considered, plus a control regime with no interventions. The data used here were a subset of the complete dataset reported in detail in Hill et al. (2017) and were also previously used in a Dialogue for Reverse Engineering Assessments and Methods (DREAM) challenge on learning causal networks (Hill et al., 2016).</p>
<p>Problem set-up. Treating each cell line as a separate, independent problem, the intervention regimes were used to define an interventional "gold standard", in a similar vein as for Dataset D1. This followed the procedure described in detail in (Hill et al., 2016) with an additional step of taking a majority vote across growth conditions to give a causal gold standard for each cell line c. For each cell line c, we formed a data matrix X c consisting of all available data for the p = 35 proteins except for one of the intervention regimes. The intervention regime not included was a kinase inhibitor targeting the protein mTOR. This intervention was entirely held out and used to provide the test labels. As background knowledge Φ c we took as training labels causal effects under the other interventions. With this set-up, the task was to determine the (indirect) causal effects of the entirely unseen intervention. Note that each cell line c was treated as an entirely different dataset and task, with its own data matrix, background knowledge and interventional test data.</p>
<p>Results. Figure 3 shows AUCs (with respect to changes seen under the test intervention) for each of the four cell lines and each of the methods. There was no single method that outperformed all others across all four cell lines. SSCD performed particularly well relative to the other methods for cell lines BT549 and MCF7, was competitive for cell line UACC812, but performed less well for cell line BT20. We note also that, for cell lines BT549 and MCF7, the performance of SSCD was competitive with the best performers in the DREAM challenge and with an analysis reported in Hill et al. (2017). The latter involved a complex Bayesian model specifically designed for such data. In contrast, SSCD was applied directly to a data matrix comprising all training samples simply collected together.</p>
<p>Dataset D3: Human Cancer Data</p>
<p>Data. The data consisted of protein measurements for p = 35 proteins measured in n = 820 human breast cancer samples (from biopsies). The data originate from The Cancer Genome Atlas (TCGA) Project, are described in Akbani et al. (2014) and were retrieved from The Cancer Proteome Atlas (TCPA) data portal (Li et al., 2013, http Level 4 data). Data for many cancer types are available, but here we focus on a single type (breast cancer) to minimize the potential for confounding by cancer type. It is at present difficult to carry out interventions in biopsy data of this kind. However, we focused on the same 35 proteins as in Dataset D2, whose mutual causal relationships are relatively well-understood, and used a reference causal graph for these proteins based on the biochemical literature (as reported in Hill et al., 2017).</p>
<p>Problem set-up. We formed data matrices X consisting of measurements for the p = 35 proteins for three different sample sizes: (i) n train = 200, (ii) n train = 500 or (iii) all n train = 820 patient samples. For (i) and (ii) patient samples were selected at random. We then used a random fraction ρ of the reference graph as background knowledge, testing output on the (unseen) remainder.</p>
<p>Results. Figure 4 shows AUCs (with respect to the held-out causal labels) as a function of the proportion ρ of causal edges that were observed, for each of the methods and for the three sample sizes. Results were averaged over 25 iterations. SSCD outperformed the other methods, with the magnitude of the gain in performance increasing with ρ, and wither performance still competitive for ρ = 0.2. Results were qualitatively similar for the three sample sizes, with increases in AUC for n train = 820 and n train = 500 relative to n train = 250, particularly for SSCD. As in Figures 1 and 2, the error bars become larger as ρ increases due to the size of the test set decreasing.</p>
<p>Discussion</p>
<p>In this paper, we proposed a way in which causal discovery can be framed as a task in semisupervised learning. The approach we propose stands in contrast to more explicitly causal methods in that it learns potentially relevant regularities directly from data. The main advantage of this approach is that it allows regularities in the data to emerge via learning, rather than having to be encoded via an explicit causal or mechanistic model.</p>
<p>In the examples we considered, the gold-standard causal relationships could be indirect. We conjecture that with suitable inputs our framework could be used to learn direct relationships. However, exploring the learning of direct causal relationships using real experimental data is challenging, since such data typically contain readouts after interventions on individual vertices (as in the yeast data). Such data are not in themselves sufficient to provide clear evidence of direct effects, since it may be that the true causal path includes an unknown and unmeasured variable.</p>
<p>We do not expect our approach -or indeed any causal discovery method -to be everywhere and always the best performer. Causal discovery remains an open area and at this stage we think it is important to explore formulations as widely as possible. Although many available approaches, including for example those based on DAGs, offer a well studied framework, we think it may be fruitful to revisit some causal inference problems within a machine learning context.
Let p i,j = B i,j πdΛ 2
be the probability mass assigned to B i,j , so that, from binomial properties, the mean and variance of the histogram estimator κ(S (n) )(x) at the point x ∈ X 2 are
m(x) = p i,j h 2 v(x) = p i,j (1 − p i,j ) nh 4 .
Let b(x) = m(x) − π(x) denote the bias of the histogram estimator. The mean square of the error π(x) − κ(S (n) )(x) at a point x ∈ X 2 can be bias-variance decomposed:
E{[π(x) − κ(S (n) )(x)] 2 } = b(x) 2 + v(x)
The aim is to obtain independent bounds on both the bias and variance terms next.</p>
<p>To bound the bias term, Taylor's theorem gives that, for x, x ∈ B i,j ,
π(x ) = π(x) + (x − x) · ∇π(x) + 1 2 (x − x) R i,j (x) (x − x)(5)
where the remainder term satisfies
R i,j (x) max ≤ sup x ∈B i,j ∇∇ π(x ) max (Taylor)
≤ sup</p>
<p>x ∈X 2 ∇∇ π(x ) max &lt; ∞ (continuous on compact domain).</p>
<p>Here M max = max{M i,j } and ∇∇ π denotes the Hessian, which exists since π is twice continuously differentiable in X 2 . Thus for x ∈ B i,j , integrating Eqn. 5:
B i,j π(x )dΛ 2 (x ) = h 2 π(x) + h 2 h 2 2i − 1 2j − 1 − x · ∇π(x) + E i,j (x)
where the new remainder term can be bounded:
|E i,j (x)| = 1 2 B i,j (x − x) R i,j (x) (x − x)dΛ 2 (x ) ≤ 1 2 B i,j x − x 2 2 dΛ 2 (x ) × sup x ∈X 2 ∇∇ π(x ) max (6) ≤ 8h 4 sup x ∈X 2 ∇∇ π(x ) max =: Ch 4
where the constant C is independent of x and i, j. The number 8 (which is not sharp) is obtained from trivial but tedious computation of the integral in Eqn. 6 and bounding each term in the result. Now, for x ∈ B i,j , the bias is expressed using Eqn. 5 as
b(x) = 1 h 2 B i,j π(x )dΛ 2 (x ) − π(x) = h 2 2i − 1 2j − 1 − x · ∇π(x) + 1 h 2 E i,j (x).
Now we integrate this expression over x ∈ B i,j :
B i,j b 2 dΛ 2 = B i,j h 2 2i − 1 2j − 1 − x · ∇π(x) + 1 h 2 E i,j (x) 2 dΛ 2 (x) ≤ B i,j h 2 2i − 1 2j − 1 − x · ∇π(x) 2 dΛ 2 (x) +2 B i,j h 2 2i − 1 2j − 1 − x · ∇π(x) 1 h 2 |E i,j (x)|dΛ 2 (x) + B i,j 1 h 4 E i,j (x) 2 dΛ 2 (x) ≤ B i,j h 2 2i − 1 2j − 1 − x · ∇π(x) 2 dΛ 2 (x) +2Ch 2 B i,j h 2 2i − 1 2j − 1 − x · ∇π(x) dΛ 2 (x) + C 2 h 2
To bound these integrals we use Cauchy-Schwarz:
B i,j h 2 2i − 1 2j − 1 − x · ∇π(x) 2 dΛ 2 (x) ≤ B i,j h 2 2i − 1 2j − 1 − x 2 2 ∇π(x) 2 2 dΛ 2 (x) ≤ h 2 2 B i,j ∇π(x) 2 2 dΛ 2 (x)(7)
and
B i,j h 2 2i − 1 2j − 1 − x · ∇π(x) dΛ 2 (x) ≤ B i,j h 2 2i − 1 2j − 1 − x 2 ∇π(x) 2 dΛ 2 (x) ≤ h √ 2 B i,j ∇π(x) 2 dΛ 2 (x).(8)
Both expressions in Eqns. 7 and 8 are finite since the integrand is continuous and the domain is compact. The total integrated bias is thus bounded as
X 2 b 2 dΛ 2 ≤ h 2 2 X 2 ∇π(x) 2 2 dΛ 2 (x) + C 2 h 2 + O(h 3 )
To bound the variance term, from the integral form of the mean value theorem we have that, for some x i,j ∈ B i,j ,
p i,j = B i,j πdΛ 2 = h 2 π(x i,j ).
The application of the integral form of the mean value theorem is valid since π is continuous on X 2 . Then:
X 2 v 2 dΛ 2 = m i,j=1 B i,j vdΛ 2 = m i,j=1 B i,j p i,j (1 − p i,j ) nh 4 dΛ 2 = 1 nh 2 − 1 nh 2 m i,j=1 p 2 i,j = 1 nh 2 − h 2 n
Figure 1 :
1Results for dataset D1 (yeast data), random sampling of causal labels. Area under the ROC curve (AUC), with respect to held-out causal influences (determined from interventional data), as a function of the fraction ρ of labels available in the semi-supervised set-up (labels were sampled at random). Results are shown for three training data sample sizes n train and for five methods: the proposed semi-supervised approach, SSCD; Pearson and Kendall correlations; Lasso regression; and intervention-calculus when the DAG is absent (IDA). Results are mean values over 25 iterations and error bars indicate standard error of the mean. See text for details.</p>
<p>Figure 3 :
3Results for dataset D2 (protein time course data). Each panel is a different cell line, with its own training and (interventional) test data. AUC is with respect to an entirely held-out intervention. See text for details.</p>
<p>Figure 4 :
4://tcpaportal.org; data release version 4.0; Pan-Can 19 Results for dataset D3 (human cancer data). Data are protein measurements from breast cancer patient samples from The Cancer Genome Atlas (TCGA). AUC is with respect to a reference causal graph based on the (causal) biochemical literature. Results are mean values over 25 iterations and error bars indicate standard error of the mean. See text for details.
recall that a pseudo-metric d satisfies all of the properties of a metric with the exception that d(x, y) = 0 =⇒ x = y.
Acknowledgements: CJO was supported by the ARC Centre of Excellence for Mathematics and Statistics, Australia, and the Lloyd's Register Foundation programme on data-centric engineering at the Alan Turing Institute, UK.Appendix AIn this appendix we provide proofs for the theoretical results in the main text.Proposition 1. Given S, S ∈ S n , we obtain from the pseudo-metric properties of d P each of (i)Suppose now that κ is injective and d P is a metric on P. Then if d S (S, S ) = d P (κ(S), κ(S )) = 0, it follows that κ(S) = κ(S ) which (from assumption on κ) implies S = S in S n . Thus under these additional assumptions, d S is a metric on S n .Proposition 2. The non-negativity, symmetry and sub-additivity properties of d P are clear, so all that remains is to establish that d P (Π, Π ) = 0 implies Π = Π . Let Π, Π have densities π, π . From the definition of P, both π and π are continuous on X 2 . The result is then immediate from the fact that, since π and π are continuous and X 2 is compact, then X 2 |π(x) − π (x)| 2 dΛ 2 (x) = 0 implies π and π must be identical as functions on X 2 . Thus Π = Π as required.Proposition 3. Observe that, using Prop. 2 for sub-additivity of the metric d P ,Since κ is consistent we have π − κ(S (n) ) 2 = o P (1) and π − κ(S (n) ) 2 = o P (1). This completes the proof.Proposition 4. This proof extends the simpler proof given for the univariate case in Theorem 6.11 ofWassermann (2006). For convenience, and without loss of generality, we suppose that X 2 = [0, 1] 2 .
. J Pearl, Causality, Cambridge University PressJ. Pearl. Causality. Cambridge University Press, 2009.</p>
<p>Estimating high-dimensional intervention effects from observational data. M H Maathuis, M Kalisch, P Bühlmann, Annals of Statistics. 376AM.H. Maathuis, M. Kalisch, and P. Bühlmann. Estimating high-dimensional intervention effects from observational data. Annals of Statistics, 37(6A):3133-3164, 2009.</p>
<p>Inferring network structure from interventional timecourse experiments. S E F Spencer, S M Hill, S Mukherjee, Annals of Applied Statistics. 91S.E.F. Spencer, S.M. Hill, and S. Mukherjee. Inferring network structure from interventional time- course experiments. Annals of Applied Statistics, 9(1):507-524, 2015.</p>
<p>Towards a learning theory of causation. D Lopez-Paz, K Muandet, B Schölkopf, I Tolstikhin, Proceedings of the 32nd International Conference on Machine Learning. the 32nd International Conference on Machine LearningD. Lopez-Paz, K. Muandet, B. Schölkopf, and I. Tolstikhin. Towards a learning theory of causation. In Proceedings of the 32nd International Conference on Machine Learning, 2015.</p>
<p>Distinguishing cause from effect using observational data: Methods and benchmarks. J M Mooij, J Peters, D Janzing, J Zscheischler, B Schölkopf, Journal of Machine Learning Research. 1732J.M. Mooij, J. Peters, D. Janzing, J. Zscheischler, and B. Schölkopf. Distinguishing cause from effect using observational data: Methods and benchmarks. Journal of Machine Learning Research, 17 (32):1-102, 2016.</p>
<p>Causal network inference using biochemical kinetics. C J Oates, F Dondelinger, N Bayani, J Korkola, J W Gray, S Mukherjee, Bioinformatics. 3017C.J. Oates, F. Dondelinger, N. Bayani, J. Korkola, J.W. Gray, and S. Mukherjee. Causal network inference using biochemical kinetics. Bioinformatics, 30(17):i468-i474, 2014.</p>
<p>Manifold regularization: A geometric framework for learning from labeled and unlabeled examples. M Belkin, P Niyogi, V Sindhwani, Journal of Machine Learning Research. 7M. Belkin, P. Niyogi, and V. Sindhwani. Manifold regularization: A geometric framework for learning from labeled and unlabeled examples. Journal of Machine Learning Research, 7:2399- 2434, 2006.</p>
<p>Kernel Smoothing. M P Wand, M C Jones, CRC PressM.P. Wand and M.C. Jones. Kernel Smoothing. CRC Press, 1994.</p>
<p>Semi-supervised learning in gigantic image collections. R Fergus, Y Weiss, A Torralba, Proceedings of the 23rd Annual Conference on Neural Information Processing Systems. the 23rd Annual Conference on Neural Information Processing SystemsR. Fergus, Y. Weiss, and A. Torralba. Semi-supervised learning in gigantic image collections. In Proceedings of the 23rd Annual Conference on Neural Information Processing Systems, pages 522-530, 2009.</p>
<p>Large-scale genetic perturbations reveal regulatory networks and an abundance of gene-specific repressors. P Kemmeren, K Sameith, L A Van De Pasch, J J Benschop, T L Lenstra, T Margaritis, E O&apos;duibhir, E Apweiler, S Van Wageningen, C W Ko, S Van Heesch, M M Kashani, G Ampatziadis-Michailidis, M O Brok, N A C H Brabers, A J Miles, D Bouwmeester, S R Van Hooff, H Bakel, E Sluiters, L V Bakker, B Snel, P Lijnzaad, D Van Leenen, M J A Groot Koerkamp, F C P Holstege, Cell. 1573P. Kemmeren, K. Sameith, L.A. van de Pasch, J.J. Benschop, T.L. Lenstra, T. Margaritis, E. O'Duibhir, E. Apweiler, S. van Wageningen, C.W. Ko, S. van Heesch, M.M. Kashani, G. Ampatziadis-Michailidis, M.O. Brok, N.A.C.H. Brabers, A.J. Miles, D. Bouwmeester, S.R. van Hooff, H. Bakel, E. Sluiters, L.V. Bakker, B. Snel, P. Lijnzaad, D. van Leenen, M.J.A. Groot Koerkamp, and F.C.P. Holstege. Large-scale genetic perturbations reveal regulatory networks and an abundance of gene-specific repressors. Cell, 157(3):740-752, 2014.</p>
<p>Causal inference using invariant prediction: Identification and confidence intervals. J Peters, P Bühlmann, N Meinshausen, Journal of the Royal Statistical Society: Series B. 785J. Peters, P. Bühlmann, and N. Meinshausen. Causal inference using invariant prediction: Iden- tification and confidence intervals. Journal of the Royal Statistical Society: Series B, 78(5): 947-1012, 2016.</p>
<p>Methods for causal inference from gene perturbation experiments and validation. N Meinshausen, A Hauser, J M Mooij, J Peters, P Versteeg, P Bühlmann, Proceedings of the National Academy of Sciences. the National Academy of Sciences113N. Meinshausen, A. Hauser, J.M. Mooij, J. Peters, P. Versteeg, and P. Bühlmann. Methods for causal inference from gene perturbation experiments and validation. Proceedings of the National Academy of Sciences, 113(27):7361-7368, 2016.</p>
<p>Context specificity in causal signaling networks revealed by phosphoprotein profiling. S M Hill, N K Nesser, K Johnson-Camacho, M Jeffress, A Johnson, C Boniface, S E F Spencer, Y Lu, L M Heiser, Y Lawrence, N T Pande, J E Korkola, J W Gray, G B Mills, S Mukherjee, P T Spellman, Cell Systems. 41S.M. Hill, N.K. Nesser, K. Johnson-Camacho, M. Jeffress, A. Johnson, C. Boniface, S.E.F. Spencer, Y. Lu, L.M. Heiser, Y. Lawrence, N.T. Pande, J.E. Korkola, J.W. Gray, G.B. Mills, S. Mukherjee, and P.T. Spellman. Context specificity in causal signaling networks revealed by phosphoprotein profiling. Cell Systems, 4(1):73-83, 2017.</p>
<p>A pan-cancer proteomic perspective on The Cancer Genome Atlas. R Akbani, P K S Ng, H M Werner, M Shahmoradgoli, F Zhang, Z Ju, W Liu, J Y Yang, K Yoshihara, J Li, S Ling, E G Seviour, P T Ram, J D Minna, L Diao, P Tong, J V Heymach, S M Hill, F Dondelinger, N Städler, L A Byers, F Meric-Bernstam, J N Weinstein, B M Broom, R G W Verhaak, H Liang, S Mukherjee, Y Lu, G B Mills, Nature Communications. 53887R. Akbani, P.K.S. Ng, H.M. Werner, M. Shahmoradgoli, F. Zhang, Z. Ju, W. Liu, J.Y. Yang, K. Yoshihara, J. Li, S. Ling, E.G. Seviour, P.T. Ram, J.D. Minna, L. Diao, P. Tong, J.V. Heymach, S.M. Hill, F. Dondelinger, N. Städler, L.A. Byers, F. Meric-Bernstam, J.N. Weinstein, B.M. Broom, R.G.W. Verhaak, H. Liang, S. Mukherjee, Y. Lu, and G.B. Mills. A pan-cancer proteomic perspective on The Cancer Genome Atlas. Nature Communications, 5:3887, 2014.</p>
<p>Regression shrinkage and selection via the lasso. R Tibshirani, Journal of the Royal Statistical Society: Series B. 581R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society: Series B, 58(1):267-288, 1996.</p>
<p>Predicting causal effects in large-scale systems from observational data. M H Maathuis, D Colombo, M Kalisch, P Bühlmann, Nature Methods. 74M.H. Maathuis, D. Colombo, M. Kalisch, and P. Bühlmann. Predicting causal effects in large-scale systems from observational data. Nature Methods, 7(4):247-248, 2010.</p>
<p>Inferring causal molecular networks: Empirical assessment through a community-based effort. S M Hill, L M Heiser, T Cokelaer, M Unger, N K Nesser, D E Carlin, Y Zhang, A Sokolov, E O Paull, C K Wong, K Graim, A Bivol, H Wang, F Zhu, B Afsari, L V Danilova, A V Favorov, W S Lee, D Taylor, C W Hu, B L Long, D P Noren, A J Bisberg, Hpn-Dream The, G B Consortium, J W Mills, M Gray, T Kellen, S Norman, A A Friend, Y Qutub, E J Fertig, M Guan, J M Song, P T Stuart, H Spellman, G Koeppl, J Stolovitzky, S Saez-Rodriguez, Mukherjee, Nature Methods. 134S.M. Hill, L.M. Heiser, T. Cokelaer, M. Unger, N.K. Nesser, D.E. Carlin, Y. Zhang, A. Sokolov, E.O. Paull, C.K. Wong, K. Graim, A. Bivol, H. Wang, F. Zhu, B. Afsari, L.V. Danilova, A.V. Favorov, W.S. Lee, D. Taylor, C.W. Hu, B.L. Long, D.P. Noren, A.J. Bisberg, The HPN- DREAM Consortium, G.B. Mills, J.W. Gray, M. Kellen, T. Norman, S. Friend, A.A. Qutub, Y. Fertig, E.J. Guan, M. Song, J.M. Stuart, P.T. Spellman, H. Koeppl, G. Stolovitzky, J. Saez- Rodriguez, and S. Mukherjee. Inferring causal molecular networks: Empirical assessment through a community-based effort. Nature Methods, 13(4):310-318, 2016.</p>
<p>TCPA: a resource for cancer functional proteomics data. J Li, Y Lu, R Akbani, Z Ju, P L Roebuck, W Liu, J-Y. Yang, B M Broom, R G W Verhaak, D W Kane, C Wakefield, J N Weinstein, G B Mills, H Liang, Nature Methods. 1011J. Li, Y. Lu, R. Akbani, Z. Ju, P. L. Roebuck, W. Liu, J-Y. Yang, B.M. Broom, R.G.W. Verhaak, D.W. Kane, C. Wakefield, J.N. Weinstein, G.B. Mills, and H. Liang. TCPA: a resource for cancer functional proteomics data. Nature Methods, 10(11):1046-1047, 2013.</p>
<p>All of Nonparametric Statistics. L Wassermann, SpringerL. Wassermann. All of Nonparametric Statistics. Springer, 2006.</p>            </div>
        </div>

    </div>
</body>
</html>