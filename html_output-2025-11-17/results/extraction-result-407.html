<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-407 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-407</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-407</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-258547176</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2305.03063v2.pdf" target="_blank">Neuro-symbolic model for cantilever beams damage detection</a></p>
                <p><strong>Paper Abstract:</strong> In the last decade, damage detection approaches swiftly changed from advanced signal processing methods to machine learning and especially deep learning models, to accurately and non-intrusively estimate the state of the beam structures. But as the deep learning models reached their peak performances, also their limitations in applicability and vulnerabilities were observed. One of the most important reason for the lack of trustworthiness in operational conditions is the absence of intrinsic explainability of the deep learning system, due to the encoding of the knowledge in tensor values and without the inclusion of logical constraints. In this paper, we propose a neuro-symbolic model for the detection of damages in cantilever beams based on a novel cognitive architecture in which we join the processing power of convolutional networks with the interactive control offered by queries realized through the inclusion of real logic directly into the model. The hybrid discriminative model is introduced under the name Logic Convolutional Neural Regressor and it is tested on a dataset of values of the relative natural frequency shifts of cantilever beams derived from an original mathematical relation. While the obtained results preserve all the predictive capabilities of deep learning models, the usage of three distances as predicates for satisfiability, makes the system more trustworthy and scalable for practical applications. Extensive numerical and laboratory experiments were performed, and they all demonstrated the superiority of the hybrid approach, which can open a new path for solving the damage detection problem.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e407.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e407.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LCNR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Logic Convolutional Neural Regressor</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic regression architecture that combines 1D convolutional neural networks with Real Logic predicates encoded as TensorFlow graphs to predict crack position/severity from relative frequency shift (RFS) inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Logic Convolutional Neural Regressor (LCNR)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>LCNR is a hybrid neuro-symbolic system whose core is a Conv1D-based deep regression network (for processing RFS sequences) that is constrained and queried via Real Logic formulas. Real Logic formulas (predicates and quantifiers) are transformed into TensorFlow computational graphs so that the satisfiability of logical axioms becomes a differentiable objective during training. The model's training objective is to maximize formula satisfiability (a fuzzy truth value in [0,1]), which enforces symbolic constraints (distance/similarity predicates) on the neural regressor's outputs while also fitting numerical targets.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Real Logic — a first-order style fuzzy logic language with constants, variables, functions, predicates, logical connectives and quantifiers; specific predicates used are distance/similarity predicates (Euclidean, Manhattan, Minkowski) and an aggregation operator (∀ realized as pMeanError) to compute satisfiability across dataset instances.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Convolutional neural network regressor (1D Conv layers, implemented in TensorFlow) used as the function F(x) mapping RFS input tensors to predicted crack position; gradient-based optimization (GPU-accelerated) is used to learn parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Differentiable neuro-symbolic integration: Real Logic formulas are compiled into TensorFlow computational graphs so predicates produce differentiable truth values; the overall training objective maximizes satisfiability of axioms (e.g., ∀(diag(x,y), eq(F x, y))) via standard gradient descent on neural parameters (end-to-end within a TensorFlow graph). The system uses distance predicates as differentiable constraints/losses (pMeanError aggregation) applied during each epoch and monitors satisfiability for train/test sets.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Combined capabilities: (1) Intrinsic explainability/trustworthiness via explicit logical predicates and satisfiability scores; (2) Ability to enforce domain constraints (e.g., distance-based similarity) during learning improving robustness and reducing egregious errors; (3) Improved data-efficiency and better generalization to FEM and noisy experimental data compared to the same Conv1D/DNN alone; (4) Interactive querying/deductive reasoning over learned groundings (the paper emphasizes Real Logic queries for trustworthy operation); (5) Scalability for regression tasks on sequence-structured physical sensor data.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Damage detection / regression: predict crack position (mm) and severity from relative natural frequency shifts (RFS) for cantilever beams; evaluations on generated analytical dataset (36573 scenarios split 70/30), FEM-simulated test cases, and experimental laboratory beam measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>Multiple quantitative results reported: (a) Standard deviation of prediction errors (units: presumably mm or scaled error metric) for LCNR variants using different distance predicates: Euclidean SD = 10.8; Manhattan SD = 10.7; Minkowski p=2 SD = 11.5; Minkowski p=1 SD = 12.0. (b) The model achieved prediction error < 5% for both FEM and experimental datasets in reported test scenarios; (c) validation 'accuracy' reported as 0.01-0.03 in late training epochs (paper text), and individual test absolute errors in Tables 6–9 generally within a few percent of true position. (All numbers taken directly from the paper tables/text.)</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td>Baseline Conv1D (same backbone without logical part) standard deviation = 48.2; DNN regression baseline standard deviation = 51.0 (from Table 1). These values show much worse performance than LCNR with predicates (see hybrid_performance).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Empirically the LCNR generalizes better than the neural-only baselines: evaluated on FEM simulations and independent laboratory experiments (out-of-sample real-world data) with error <5%. The paper also reports K-fold cross-validation and experiments with reduced training set sizes (10%–90%) showing 'impressive accuracy even with 10% of data', indicating improved data-efficiency and robustness under reduced-data regimes. Specific formal out-of-distribution or compositional generalization tests are not provided beyond the FEM/experimental transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Interpretability arises from the declarative Real Logic layer: (1) predicates compute satisfiability scores in [0,1] that can be monitored per-instance and per-axiom, analogous to losses but interpretable as fuzzy truth; (2) Logical formulas can be queried at inference time for interactive checks; (3) The use of explicit distance predicates provides a clear semantic meaning to constraints imposed on outputs. The paper highlights 'intrinsic explainability' and 'trustworthiness' due to these properties.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Limitations reported or implied in the paper: (1) Choice of predicate/distance metric affects performance — different metrics yield different SDs and worst-case errors; (2) Some imperfect clamping scenarios produce larger errors (worst cases up to ≈7% in Table 7); (3) No purely-declarative baseline is provided, so contributions of symbolic component alone are not isolated; (4) No formal theoretical guarantees (e.g., convergence to true model under constraints) are presented; (5) The approach still depends on the quality of the logical axioms and their grounding (design of predicates), which must be hand-specified.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Practical instantiation of Real Logic / Logic Tensor Network style neuro-symbolic principle: cast logical formulas as differentiable constraints (satisfiability in [0,1]) and optimize neural groundings to maximize formula satisfiability. The paper frames the rationale as complementary strengths (CNN for pattern learning, Real Logic for symbolic constraints and explainability) but does not present a novel formal theory beyond this differentiable satisfiability optimization paradigm.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e407.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e407.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LTN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Logic Tensor Networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A previously proposed neuro-symbolic framework that combines neural networks and first-order logic using fuzzy semantics to perform learning as satisfiability optimization over logical formulas.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Logic tensor networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Logic Tensor Networks (LTN)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>LTNs are neuro-symbolic models that ground first-order logic symbols into numeric vectors/tensors and interpret logical connectives and predicates with fuzzy differentiable semantics; learning is performed by optimizing parameters so that the truth (satisfiability) of a set of formulas is maximized. They enable incorporating prior knowledge expressed as logical axioms into neural learning.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>First-order logic expressed with fuzzy semantics (Real Logic-style representation of constants, functions, predicates, quantifiers, and logical connectives).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural networks and tensor-based groundings; predicates and functions are implemented as differentiable components (e.g., neural function approximators) whose parameters are learned.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Compile logical formulas into differentiable operations over tensor groundings; optimize parameters (both network weights and numeric groundings) to maximize overall satisfiability — effectively end-to-end differentiable neuro-symbolic learning.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Allows injection of symbolic/domain knowledge into learning, improved robustness and interpretability via satisfiability monitoring, and capacity to perform supervised or semi-supervised tasks constrained by logical axioms. In principle enables reasoning over learned representations and richer queries than pure neural nets.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>General neuro-symbolic learning framework; cited applications include regression, image classification with relational knowledge, sentiment analysis, and transfer learning in related works (paper references these usages).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Reported in cited LTN literature to improve robustness and to enable transfer learning by encoding prior knowledge; in this paper LTN is referenced as motivation but no new LTN experiments are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Provides interpretable satisfiability scores for logical formulas and supports explicit logical queries over grounded knowledge; helps explain predictions via which axioms/predicates are satisfied or violated.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Not detailed in this paper beyond general neuro-symbolic caveats: requires design of appropriate logical axioms and groundings; performance depends on quality of axioms and their compatibility with data; potential computational overhead from translating logic into differentiable graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Fuzzy first-order logic grounding into vector/tensor representations; learning as satisfiability maximization (same conceptual framework LCNR builds on).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e407.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e407.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Real Logic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Real Logic (RL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A first-order style fuzzy-logic language used in this work to express predicates, quantifiers and formulas which are compiled into TensorFlow graphs and used as differentiable constraints on the neural regressor.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Real Logic (as used in LCNR)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Real Logic is used as the symbolic/declarative layer: formulas containing constants, variables, functions, predicates, connectives and quantifiers are written and then transformed into TensorFlow computational graphs; predicates compute differentiable truth values (e.g., via distance/similarity metrics) and aggregation operators (e.g., ∀ realized as pMeanError) compute dataset-level satisfiability.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>First-order fuzzy logic language (Real Logic) with explicit predicates (Euclidean, Manhattan, Minkowski distances) and quantifiers; symbolic axioms are specified over dataset input-output pairs via lcnr.diag(x,y) and eq predicates.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Not applicable as component itself, but Real Logic is integrated with an imperative Conv1D neural regressor (the neural component is described separately in LCNR).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Logical formulas are converted into TensorFlow operations (predicates yield differentiable similarity/distances; aggregators produce objectives) and combined with the neural regressor within the same computational graph so that gradient-based optimization updates neural parameters to maximize satisfiability.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables monitoring of satisfiability as an interpretable training objective, interactive querying over learned groundings, and the imposition of domain-aware constraints on learned outputs leading to improved robustness and reduced large errors.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Used within LCNR for regression of crack position from RFS; serves as the queryable symbolic constraint layer.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>When coupled with Conv1D, Real Logic constraints empirically improved generalization to FEM and experimental datasets and maintained performance under reduced training set sizes; specifics are reported for LCNR but no isolated Real Logic-only generalization experiment is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Provides satisfiability scores per formula and supports querying of logical statements at inference time, which the paper highlights as improving trustworthiness and explainability of predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Paper does not present failure modes specific to Real Logic itself but notes sensitivity to chosen predicates and that symbolic design (which predicates/axioms to include) is manual and affects results.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Real Logic provides the semantic/fuzzy-logic basis for mapping symbolic formulas to differentiable truth values; within LCNR it is the formal mechanism by which symbolic constraints are expressed and optimized.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Logic tensor networks <em>(Rating: 2)</em></li>
                <li>Logic tensor networks for semantic image interpretation <em>(Rating: 2)</em></li>
                <li>Logic tensor network with massive learned knowledge for aspect-based sentiment analysis <em>(Rating: 1)</em></li>
                <li>Logic tensor networks. S. Badreddine, A. D'Avila Garcez, L. Serafini, M. Spranger. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-407",
    "paper_id": "paper-258547176",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "LCNR",
            "name_full": "Logic Convolutional Neural Regressor",
            "brief_description": "A neuro-symbolic regression architecture that combines 1D convolutional neural networks with Real Logic predicates encoded as TensorFlow graphs to predict crack position/severity from relative frequency shift (RFS) inputs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Logic Convolutional Neural Regressor (LCNR)",
            "system_description": "LCNR is a hybrid neuro-symbolic system whose core is a Conv1D-based deep regression network (for processing RFS sequences) that is constrained and queried via Real Logic formulas. Real Logic formulas (predicates and quantifiers) are transformed into TensorFlow computational graphs so that the satisfiability of logical axioms becomes a differentiable objective during training. The model's training objective is to maximize formula satisfiability (a fuzzy truth value in [0,1]), which enforces symbolic constraints (distance/similarity predicates) on the neural regressor's outputs while also fitting numerical targets.",
            "declarative_component": "Real Logic — a first-order style fuzzy logic language with constants, variables, functions, predicates, logical connectives and quantifiers; specific predicates used are distance/similarity predicates (Euclidean, Manhattan, Minkowski) and an aggregation operator (∀ realized as pMeanError) to compute satisfiability across dataset instances.",
            "imperative_component": "Convolutional neural network regressor (1D Conv layers, implemented in TensorFlow) used as the function F(x) mapping RFS input tensors to predicted crack position; gradient-based optimization (GPU-accelerated) is used to learn parameters.",
            "integration_method": "Differentiable neuro-symbolic integration: Real Logic formulas are compiled into TensorFlow computational graphs so predicates produce differentiable truth values; the overall training objective maximizes satisfiability of axioms (e.g., ∀(diag(x,y), eq(F x, y))) via standard gradient descent on neural parameters (end-to-end within a TensorFlow graph). The system uses distance predicates as differentiable constraints/losses (pMeanError aggregation) applied during each epoch and monitors satisfiability for train/test sets.",
            "emergent_properties": "Combined capabilities: (1) Intrinsic explainability/trustworthiness via explicit logical predicates and satisfiability scores; (2) Ability to enforce domain constraints (e.g., distance-based similarity) during learning improving robustness and reducing egregious errors; (3) Improved data-efficiency and better generalization to FEM and noisy experimental data compared to the same Conv1D/DNN alone; (4) Interactive querying/deductive reasoning over learned groundings (the paper emphasizes Real Logic queries for trustworthy operation); (5) Scalability for regression tasks on sequence-structured physical sensor data.",
            "task_or_benchmark": "Damage detection / regression: predict crack position (mm) and severity from relative natural frequency shifts (RFS) for cantilever beams; evaluations on generated analytical dataset (36573 scenarios split 70/30), FEM-simulated test cases, and experimental laboratory beam measurements.",
            "hybrid_performance": "Multiple quantitative results reported: (a) Standard deviation of prediction errors (units: presumably mm or scaled error metric) for LCNR variants using different distance predicates: Euclidean SD = 10.8; Manhattan SD = 10.7; Minkowski p=2 SD = 11.5; Minkowski p=1 SD = 12.0. (b) The model achieved prediction error &lt; 5% for both FEM and experimental datasets in reported test scenarios; (c) validation 'accuracy' reported as 0.01-0.03 in late training epochs (paper text), and individual test absolute errors in Tables 6–9 generally within a few percent of true position. (All numbers taken directly from the paper tables/text.)",
            "declarative_only_performance": null,
            "imperative_only_performance": "Baseline Conv1D (same backbone without logical part) standard deviation = 48.2; DNN regression baseline standard deviation = 51.0 (from Table 1). These values show much worse performance than LCNR with predicates (see hybrid_performance).",
            "has_comparative_results": true,
            "generalization_properties": "Empirically the LCNR generalizes better than the neural-only baselines: evaluated on FEM simulations and independent laboratory experiments (out-of-sample real-world data) with error &lt;5%. The paper also reports K-fold cross-validation and experiments with reduced training set sizes (10%–90%) showing 'impressive accuracy even with 10% of data', indicating improved data-efficiency and robustness under reduced-data regimes. Specific formal out-of-distribution or compositional generalization tests are not provided beyond the FEM/experimental transfer.",
            "interpretability_properties": "Interpretability arises from the declarative Real Logic layer: (1) predicates compute satisfiability scores in [0,1] that can be monitored per-instance and per-axiom, analogous to losses but interpretable as fuzzy truth; (2) Logical formulas can be queried at inference time for interactive checks; (3) The use of explicit distance predicates provides a clear semantic meaning to constraints imposed on outputs. The paper highlights 'intrinsic explainability' and 'trustworthiness' due to these properties.",
            "limitations_or_failures": "Limitations reported or implied in the paper: (1) Choice of predicate/distance metric affects performance — different metrics yield different SDs and worst-case errors; (2) Some imperfect clamping scenarios produce larger errors (worst cases up to ≈7% in Table 7); (3) No purely-declarative baseline is provided, so contributions of symbolic component alone are not isolated; (4) No formal theoretical guarantees (e.g., convergence to true model under constraints) are presented; (5) The approach still depends on the quality of the logical axioms and their grounding (design of predicates), which must be hand-specified.",
            "theoretical_framework": "Practical instantiation of Real Logic / Logic Tensor Network style neuro-symbolic principle: cast logical formulas as differentiable constraints (satisfiability in [0,1]) and optimize neural groundings to maximize formula satisfiability. The paper frames the rationale as complementary strengths (CNN for pattern learning, Real Logic for symbolic constraints and explainability) but does not present a novel formal theory beyond this differentiable satisfiability optimization paradigm.",
            "uuid": "e407.0"
        },
        {
            "name_short": "LTN",
            "name_full": "Logic Tensor Networks",
            "brief_description": "A previously proposed neuro-symbolic framework that combines neural networks and first-order logic using fuzzy semantics to perform learning as satisfiability optimization over logical formulas.",
            "citation_title": "Logic tensor networks",
            "mention_or_use": "mention",
            "system_name": "Logic Tensor Networks (LTN)",
            "system_description": "LTNs are neuro-symbolic models that ground first-order logic symbols into numeric vectors/tensors and interpret logical connectives and predicates with fuzzy differentiable semantics; learning is performed by optimizing parameters so that the truth (satisfiability) of a set of formulas is maximized. They enable incorporating prior knowledge expressed as logical axioms into neural learning.",
            "declarative_component": "First-order logic expressed with fuzzy semantics (Real Logic-style representation of constants, functions, predicates, quantifiers, and logical connectives).",
            "imperative_component": "Neural networks and tensor-based groundings; predicates and functions are implemented as differentiable components (e.g., neural function approximators) whose parameters are learned.",
            "integration_method": "Compile logical formulas into differentiable operations over tensor groundings; optimize parameters (both network weights and numeric groundings) to maximize overall satisfiability — effectively end-to-end differentiable neuro-symbolic learning.",
            "emergent_properties": "Allows injection of symbolic/domain knowledge into learning, improved robustness and interpretability via satisfiability monitoring, and capacity to perform supervised or semi-supervised tasks constrained by logical axioms. In principle enables reasoning over learned representations and richer queries than pure neural nets.",
            "task_or_benchmark": "General neuro-symbolic learning framework; cited applications include regression, image classification with relational knowledge, sentiment analysis, and transfer learning in related works (paper references these usages).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Reported in cited LTN literature to improve robustness and to enable transfer learning by encoding prior knowledge; in this paper LTN is referenced as motivation but no new LTN experiments are reported.",
            "interpretability_properties": "Provides interpretable satisfiability scores for logical formulas and supports explicit logical queries over grounded knowledge; helps explain predictions via which axioms/predicates are satisfied or violated.",
            "limitations_or_failures": "Not detailed in this paper beyond general neuro-symbolic caveats: requires design of appropriate logical axioms and groundings; performance depends on quality of axioms and their compatibility with data; potential computational overhead from translating logic into differentiable graphs.",
            "theoretical_framework": "Fuzzy first-order logic grounding into vector/tensor representations; learning as satisfiability maximization (same conceptual framework LCNR builds on).",
            "uuid": "e407.1"
        },
        {
            "name_short": "Real Logic",
            "name_full": "Real Logic (RL)",
            "brief_description": "A first-order style fuzzy-logic language used in this work to express predicates, quantifiers and formulas which are compiled into TensorFlow graphs and used as differentiable constraints on the neural regressor.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Real Logic (as used in LCNR)",
            "system_description": "Real Logic is used as the symbolic/declarative layer: formulas containing constants, variables, functions, predicates, connectives and quantifiers are written and then transformed into TensorFlow computational graphs; predicates compute differentiable truth values (e.g., via distance/similarity metrics) and aggregation operators (e.g., ∀ realized as pMeanError) compute dataset-level satisfiability.",
            "declarative_component": "First-order fuzzy logic language (Real Logic) with explicit predicates (Euclidean, Manhattan, Minkowski distances) and quantifiers; symbolic axioms are specified over dataset input-output pairs via lcnr.diag(x,y) and eq predicates.",
            "imperative_component": "Not applicable as component itself, but Real Logic is integrated with an imperative Conv1D neural regressor (the neural component is described separately in LCNR).",
            "integration_method": "Logical formulas are converted into TensorFlow operations (predicates yield differentiable similarity/distances; aggregators produce objectives) and combined with the neural regressor within the same computational graph so that gradient-based optimization updates neural parameters to maximize satisfiability.",
            "emergent_properties": "Enables monitoring of satisfiability as an interpretable training objective, interactive querying over learned groundings, and the imposition of domain-aware constraints on learned outputs leading to improved robustness and reduced large errors.",
            "task_or_benchmark": "Used within LCNR for regression of crack position from RFS; serves as the queryable symbolic constraint layer.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": null,
            "generalization_properties": "When coupled with Conv1D, Real Logic constraints empirically improved generalization to FEM and experimental datasets and maintained performance under reduced training set sizes; specifics are reported for LCNR but no isolated Real Logic-only generalization experiment is provided.",
            "interpretability_properties": "Provides satisfiability scores per formula and supports querying of logical statements at inference time, which the paper highlights as improving trustworthiness and explainability of predictions.",
            "limitations_or_failures": "Paper does not present failure modes specific to Real Logic itself but notes sensitivity to chosen predicates and that symbolic design (which predicates/axioms to include) is manual and affects results.",
            "theoretical_framework": "Real Logic provides the semantic/fuzzy-logic basis for mapping symbolic formulas to differentiable truth values; within LCNR it is the formal mechanism by which symbolic constraints are expressed and optimized.",
            "uuid": "e407.2"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Logic tensor networks",
            "rating": 2,
            "sanitized_title": "logic_tensor_networks"
        },
        {
            "paper_title": "Logic tensor networks for semantic image interpretation",
            "rating": 2,
            "sanitized_title": "logic_tensor_networks_for_semantic_image_interpretation"
        },
        {
            "paper_title": "Logic tensor network with massive learned knowledge for aspect-based sentiment analysis",
            "rating": 1,
            "sanitized_title": "logic_tensor_network_with_massive_learned_knowledge_for_aspectbased_sentiment_analysis"
        },
        {
            "paper_title": "Logic tensor networks. S. Badreddine, A. D'Avila Garcez, L. Serafini, M. Spranger.",
            "rating": 1,
            "sanitized_title": "logic_tensor_networks_s_badreddine_a_davila_garcez_l_serafini_m_spranger"
        }
    ],
    "cost": 0.01081525,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>NEURO-SYMBOLIC MODEL FOR CANTILEVER BEAMS DAMAGE DETECTION
June 6, 2023</p>
<p>Darian Onchis darian.onchis@e-uvt.ro 
Gilbert-Rainer Gillich 
Eduard Hogea eduard.hogea00@e-uvt.ro 
Cristian Tufis cristian.tufisi@ubbcluj.ro </p>
<p>Department of Computer Science
Department of Engineering Science Babes
West University of Timisoara Timisoara
Romania</p>
<p>Department of Computer Science West
Bolyai-University Cluj-Napoca
Romania</p>
<p>Department of Engineering Science Babes
University of Timisoara Timisoara
Romania</p>
<p>Bolyai-University Cluj-Napoca
Romania</p>
<p>NEURO-SYMBOLIC MODEL FOR CANTILEVER BEAMS DAMAGE DETECTION
June 6, 2023neuro-symbolic model · deep learning · real logic · damage detection · relative frequency shifts · cantilever beams
In the last decade, damage detection approaches swiftly changed from advanced signal processing methods to machine learning and especially deep learning models, to accurately and non-intrusively estimate the state of the beam structures. But as the deep learning models reached their peak performances, also their limitations in applicability and vulnerabilities were observed. One of the most important reason for the lack of trustworthiness in operational conditions is the absence of intrinsic explainability of the deep learning system, due to the encoding of the knowledge in tensor values and without the inclusion of logical constraints. In this paper, we propose a neuro-symbolic model for the detection of damages in cantilever beams based on a novel cognitive architecture in which we join the processing power of convolutional networks with the interactive control offered by queries realized through the inclusion of real logic directly into the model. The hybrid discriminative model is introduced under the name Logic Convolutional Neural Regressor and it is tested on a dataset of values of the relative natural frequency shifts of cantilever beams derived from an original mathematical relation. While the obtained results preserve all the predictive capabilities of deep learning models, the usage of three distances as predicates for satisfiability, makes the system more trustworthy and scalable for practical applications. Extensive numerical and laboratory experiments were performed, and they all demonstrated the superiority of the hybrid approach, which can open a new path for solving the damage detection problem.</p>
<p>Introduction</p>
<p>Continuous monitoring of engineering structures (CMES) has become an increasingly common practice in the attempt to ensure their safe operation [1]. The monitoring process involves a series of actions such as data acquisition, postprocessing, and analysis. Monitoring leads, in this way, to the early identification of defects that have occurred in equipment [2] or structural elements [3]. By permanently knowing the state of the engineering structure, maintenance can be performed at the most appropriate time with lower costs and increased security of the equipment and structures in operation. This type of maintenance, known as condition-based maintenance (CMB), is becoming increasingly popular in the Industry 4.0 era. The implementation of CBM is favored by the development of cheap and reliable arXiv:2305.03063v2 [cs.LG] 2 Jun 2023 sensors and advanced data mining algorithms [4]. It is worth mentioning that CBM can be easily integrated within the manufacturing processes.</p>
<p>If we refer to structures, nondestructive control usually implies the assessment of cracks because these are the most common structural damage. Assessing cracks means finding the location and the severity, and sometimes the type of the crack [5]. The assessment of damage can be made by local methods such as visual inspection, liquid penetrant testing, magnetic particle testing, ultrasonic testing, acoustic emissions, infrared thermography, and radiographic testing. A comprehensive review is made in [6]. These methods have the disadvantage of evaluating the integrity of structures in a local area to which access is frequently required. On the other hand, global methods do not require access to the damaged area, since these assess the global health of the structure. The global methods can be divided into vibration-based [7,8,9] and static methods [10,11]. Vibration-based methods (VBM) use data obtained from multiple vibration modes in contrast to static ones that use only displacements that are similar to the data obtained for the first mode. Therefore, VBMs can better identify the location and severity of damages.</p>
<p>Considering the above-mentioned, we propose a in-here a detection method based on the analysis of the dynamic response of structures to impulsive or continuous excitations. The method makes use of the relationship existing between the modal parameters' changes and the position and geometry of a crack [12]. In section 4, we show how a dataset containing numerous crack scenarios and the resulting frequency changes is constructed. An insight into the method is also given in this section. Because of the dimension and the complexity of the dataset, finding the crack scenario producing a certain set of measured frequency changes is difficult. A good solution to overcome this problem is to use artificial intelligence (AI) techniques. Deep learning may be the answer for one such issue [13], but we also must consider the scenarios where it may fail.</p>
<p>Related works</p>
<p>Given the numerous researchers and papers that review deep learning strengths and weaknesses for CMES, concerns such as the issues of adversarial attacks, the opaqueness of the model and the extensive need for large datasets and high computational costs, made us lean towards implementing a different kind of system. These are just some issues deep learning faces, with the first one maybe playing a future important role in the next possible AI winter, considering the current overhype and unprecedented increase in funding. Papers such as [14], [15] study the effects of adversarial attacks and how simple their implementation is. Adversarial attacks can range from noise, to blocking on part of an image, to just adjusting a single pixel and the model can be easily fooled. Examples such as 3D printed turtles being classified as rifles, a bell pepper as a strainer, a bus as an ostrich and a stop sign being classified as a speed limiter are just some of those. The main problems of deep learning have been greatly identified in [16], where the author provides an explanation of the biggest concerns it faces. Among those, the ones aforementioned are also presented. A suggestion in this mentioned paper about dealing with those concerns is to supplement deep learning with other techniques, and suggests the need for hybrid models.</p>
<p>As a solution to incorporate data and logic and to overcome Deep Learning deficiencies, in [17] the Logic Tensor Networks (LTN) were proposed. These neuro-symbolic models combine neural networks and first-order logic language. With fuzzy logic, this framework provides reasoning over data, and it can be used to design a regression model. LTNs reduce the learning problem of a given formula by optimizing its satisfiability [18]. The network will try to optimize the groundings to bring the truth of the formula close to 1. Some papers where similar hybrid approaches may be useful are [19] and [20] where the Deep Learning models used for intuitive physics would benefit from having prior knowledge about dynamics. Similar approaches that use Logic Tensor Networks have been used to classify images [21], with defined relational knowledge for robustness), sentiment analysis [22], and for using prior knowledge for transfer learning [12].</p>
<p>But for the accurate processing of datasets with relative frequency shifts (RFS) that characterize the state of the beams, 1D convolutional neural networks provide superior results than feed-forward fully connected neural architectures. We base our statement in the translation invariance that Conv1D layers provide and their ability to learn local patterns within the input sequence, but also in the numerical experiments performed in this paper.Therefore, we propose in here a novel neuro-symbolic architecture under the name Logic Convolutional Neural Regressor (LCNR) that joins the advantages of convolutional neural networks (CNN) with the intrinsic explainability offered through the incorporation of Real Logic (RL) into the model design. RL is described by a first-order language that contains constants, variables, functions, predicates, and logical connectives and quantifiers. The way LCNR uses Real Logic is by transforming the provided formulas into TensorFlow computational graphs. Those formulas can then be used for querying and learning, and make it possible to have interactive accuracy and deductive reasoning over data.</p>
<p>Main Contributions</p>
<p>Our primary contribution to the field of computer applications for industry is the design and implementation of a novel Logical Convolutional Neural Regressor (LCNR) neuro-symbolic system, which performs non-invasive damage detection on a cantilever beam RFS dataset. This hybrid cognitive system combines deep learning techniques with symbolic reasoning, resulting in an intrinsically explainable model that provides insight into its decision-making process. The system employs convolutional layers to handle complex spatial patterns in the data and utilizes three distinct predicates grounded in Real Logic to apply constraints during the training of our regression model. This innovative approach allows for improved interpretability and robustness in comparison to traditional regression methods, as well as the incorporation of logical relationships between features, which can be particularly valuable in cases where the dataset is more complex.</p>
<p>By integrating neuro-symbolic networks, our model demonstrates how logical reasoning can be effectively combined with deep learning techniques, enabling the encoding of domain-specific knowledge and the extraction of meaningful relationships within the data. This approach has the potential to enhance the performance and explainability of neural networks in various industrial applications, particularly when dealing with intricate datasets. To validate the effectiveness of our model, cross-validation was utilized on a shuffled dataset, with our analysis incorporating multiple folds for each predicate. This rigorous evaluation process ensured the reliability of the model's performance across various data subsets.</p>
<p>The trained model was used to predict and compare the damage position on a real cantilever beam, demonstrating its practical applicability in real-world scenarios. Real Logic queries were employed to ensure trustworthiness in operation conditions, providing additional confidence in the model's ability to accurately assess structural damage.</p>
<p>In summary, our main contribution lies in the development of a highly interpretable and explainable LCNR neurosymbolic system, capable of effectively detecting damage in cantilever beams and offering potential for further advancements in the field of structural health monitoring and other industrial applications that require complex feature relationships and domain-specific knowledge.</p>
<p>Construction of the RFS dataset</p>
<p>This study concerns the identification of damage in cantilever beams, which can be subject to ideal or non-ideal clamping at one end. Obviously, the second end of the beam is free. For these beams, we create a dataset containing a series of scenarios regarding the clamping condition, the crack position, and the crack depth. A schematic of the beam highlighting the clamping condition and the crack parameters is presented in Figure 1 is affected by imperfect clamping conditions by using the relative frequency shift method. The algorithm for generating the training datasets was developed in previous research. The mathematical relation relies on the natural frequencies of the structure in undamaged state, the modal curvature of the first eight weak-axis vibration modes, and the severity of the transverse cracks, as established in [23]. The equation 1 is given by:
f i−D (x, a) = f i−U 1 − γ(a) [φ ′′ i (x)] 2
(1) where we noted: 
• f i−U the∆f i−D (x, a) = f i−U − f i−D (x − a) f i−U = γ(a)[φ ′′ i (x)] 2(2)
The severity γ(a) of closed and open transverse cracks can be determined by using the method presented in [23]. The squared normalized modal curvature [ϕ ′′ i (x)] 2 , for a cantilever is determined with the procedure described in another work by Gillich and Praisach in [24]. The performance of the methods is confirmed by two independent studies [25,26].</p>
<p>In addition to the transverse crack, the method also considers the possibility of imperfect fastening of the structure, simulating the real-life scenario where loosening of joints may occur. To consider this possibility, following the approach proposed in [27], relation 2 becomes 3:
∆f i−D (0, a 1 , x 2 , a 2 ) = γ 1 (a 1 ) + γ 2 (a 2 )[φ ′′ i (x 2 )] 2(3)
Where:</p>
<p>• γ 1 (a 1 ) is the severity of the clamping condition
• γ 2 (a 2 )
is the severity of the transverse crack By using relation 3 we have generated the training data considering a closed transverse crack of depth starting from 4% to 64% relative to the beam thickness.</p>
<p>Also, the training data consists of four scenarios of imperfect boundary conditions, thus permitting a small rotation at the fixed end [28]. Instead of a massless spring [29], the rotation is possible due to a crack that has the depth from 10% to 20% of the beam thickness. It resulted in a total number of 36573 possible damage scenarios, from which we use 70% for training and 30% for testing and validating.</p>
<p>The generated dataset is available on the Mendeley repository [30]. After the model is trained, we generate test datasets by means of FEM simulations and experimental laboratory measurements for several damage scenarios.</p>
<p>Logic Convolutional Neural Regressor</p>
<p>The hybrid system in Figure 2 is composed of a deep convolutional neural network and a predicate grounded in Real Logic used to make a regression on beam damage assessment data. The regression problem was solved by using a function that took the argument of a sequential model with multiple Conv1D layers, e.g., 1D Convolution. For our proposed model, data is reshaped and batched into tensors. A function F, as described in Real Logic can be any operation supported by TensorFlow. Considering the benefits of convolutional layers compared to fully connected ones, a CNN network was used. Furthermore GPUs accelerations were implemented to speed up the computational load [31].</p>
<p>The axioms for this model involve the application of an aggregation operator (∀ -pMeanError) to calculate the distance/similarity between the output of function F and the target data. The diagonal quantification of input and target data, achieved by using lcnr.diag(x, y), allows for statements concerning specific input-output pairs, such as the i-th instance of both individuals.</p>
<p>The learning phase of our model aims to maximize the satisfiability of the proposed formula by optimizing the groundings: ∀(lcnr.diag(x, y), eq(F x, y)).</p>
<p>In this formula, the F orall(∀) quantifier iterates over each input-output pair created by lcnr.diag(x, y), and the eq predicate calculates the similarity between the model's output F(x) and the target y for each pair. The pMeanError function is then used to aggregate these individual similarities, and the model's objective is to maximize the overall satisfiability with respect to the similarities of all input-output pairs.</p>
<p>This implementation aims to utilize the supervised technique to predict the crack location in any of the proposed damage scenarios. In our experiments, predicates for Euclidean, Manhattan, and Minkowski of order 1 and 2 (generalization of Manhattan and Euclidean distances) distance/similarity were defined and used to constrain the parameters of the function. During each epoch, the satisfaction levels of the Knowledge Base for both train and test inputs were constantly monitored, alongside the model's accuracy. Our model uses the RFS from the data set as input and predicts the crack position as in Figure 1. In the last training epochs, the model reached an accuracy of 0.01-0.03 for our validation data. As such, we considered it was ready for the real-world beam damage assessment scenario. For that and to emphasize that a large data set may not be always available, K-fold cross-validation was used and for each fold, a plot of residuals was made. All the data and results are available in the before mentioned Mendeley repository. Additional experiments were made and added to the paper repository, with testing on how the model behaves when only a smaller part of the training data is available (10%, 20%, 30%. . . 90%). The content for those percentages of data used in training was randomly chosen from the whole data, and the same was done for the validation data. The batch of tensors fed to the neural network, constraining function, the shape of the neural network and the metrics in measurements were kept the same. Results show impressive accuracy even with 10% of data. To prove the improvements in accuracy of LCNR, the same data was used as in the first examples and the results of different predicates can be seen in the following section.</p>
<p>Testing the algorithm with real-world data</p>
<p>To evaluate the performance of our system in a practical setting, where noise, variability, and other challenges may be present, we have decided to test it on a new set of data. A more in-depth look is also helpful to see how the system performs. As such, the following tables detail the results, with a side-by-side comparison of actual position, predicted one and the absolute difference between them. In all our test settings, cross validation was used and the worst 4 scenarios, with respect to the error, can be seen in the tables below. Changing the predicate and using a different distance metric proved to impact the performance of our system, but the results are relatively similar. This, however, is not true when we compare with a different approach like Deep Neural Network, where the results are worse as seen in both the standard deviation and the qualitative analysis of samples.</p>
<p>FEM dataset for testing</p>
<p>Throughout this study we have considered the structure as an Euler-Bernoulli cantilever beam with the elasticity module E = 2 * 105 MPa, mass density ρ = 7850 kg/m3, length L=1 m, width B=0.05 m and thickness H=0.005 m. The beam's 3D model is generated and imported in the ANSYS simulation software. The modal study is set by applying the boundary condition, i.e., fixed boundary at the left end of the beam. A fine mesh containing hexahedra elements of 1 mm maximum size was applied. After meshing, the study is run and the natural frequency for the undamaged beam is acquired. After this step, the transverse crack geometry is generated and parametrized in the ANSYS modeler. Several damage scenarios are considered. For simulating the cases with improper clamping, an extra element is defined exactly where the fastened end is, without constraining it. The thickness of this element represents the considered severity γ 1 (a 1 ). The FEM simulation setup is presented in Figure 4.</p>
<p>After the crack and clamping conditions are defined, we have generated several damage scenarios. The cases are considered having a transverse crack of depth a=1 mm, meaning a severity value γ 2 (a 2 ) = 0.0033459. The crack is located in specific positions considered from the left end, with the values presented in Table 3.   2  81  15  489  3  120  16  516  4  165  17  560  5  173  18  660  6  210  19  687  7  233  20  690  8  255  21  760  9  290  22  796  10  325  23  820  11  347  24  896  12  360  25  906  13  414  26  946 Furthermore, by considering the same crack depth and positions given in Table 3 we have defined weak clamping scenarios, by successively considering two fastening severities γ 1 (a 1 ) = 0.0033460 and γ 1 (a 1 ) = 0.0021409 which represent 24% and 16% clamping alteration, resulting in a total number of 78 damage scenarios. For all cases, the natural frequencies for the first eight weak-axis vibration modes are recorded and the RFS values are obtained by using relation 2.</p>
<p>Experimental dataset for testing</p>
<p>In the current subsection we present the methodology for generating the experimental test dataset by measuring the natural frequencies of steel cantilever beam tests in undamaged and in damaged state, also considering a case where a beam is affected by improper clamping. Every test beam is fixed in a vise, excited using generated sound waves at the desired frequencies and the eigenvalues are recorded through an accelerometer, interface, and special software. Both the excitation and data acquisition procedures are described in detail in the papers [23] [24] [27]. The experimental setup is presented in Figure 5.</p>
<p>The considered crack positions and depths for the cases with perfect clamping are presented in Table 4. For the generated damage depths, we calculate the damage severity (γ), which is also presented in the before-mentioned table.   Furthermore, for the weak clamping case, Beam 1 was considered. The setup is presented in Figure 6.</p>
<p>The obtained RFS values are summarized in Table 5. When taking into account the imperfect boundary condition, the test (Beam 1) is fastened by inserting two rubber blocks between the beam and the steel jaws of the vise.</p>
<p>We measure first the vibration response of the beams without the generated damage and estimate the natural frequencies after a procedure described in [27]. Next, we generate damage and repeat the procedure of frequency estimation. Finally, we calculate the RFS values, relation 2.</p>
<p>After the RFS values from Table 5 are obtained by using relation 2, the accuracy of the developed LCNR is tested for the defined real-life scenarios.</p>
<p>Results and discussions</p>
<p>The intelligent algorithms are trained using as input the RFS values determined analytically for predicting the position and severity of transverse cracks, even when imperfect clamping is involved. We test the accuracy of the models by using the data obtained through FEM simulations and experimental procedures.</p>
<p>Accuracy testing using the FEM results</p>
<p>We tested the accuracy of the developed model to predict the position of the transverse cracks, by introducing the RFS values obtained for the FEM simulations for all scenarios presented. The obtained results for the scenarios with perfect clamping are presented in Table 6. The error in the following tables refers to the relative discrepancy between the predicted and the actual location of the damage along a bar of 1000mm. It is calculated with the following formula 4:   The obtained results for the scenarios with 16% clamping alteration are presented in Table 7. In Table 8 the results obtained for the cases with 24% alteration.
Error [%] = Predicted − Real 1000 × 100(4)</p>
<p>Accuracy testing using the experimental measurements</p>
<p>Upon conducting experimental tests to measure the natural frequencies for the specified damage scenarios, the predictive accuracy of the Logic Convolutional Neural Regressor (LCNR) and its embedded Deep Learning (DL) network in discerning the location of the crack was evaluated separately. The findings of this investigation are delineated in Table 9, where the same inputs have been tested to the two networks. Based on study we have conducted before, the distance/similarity metric used is the one resembling the Euclidean.</p>
<p>Conclusions</p>
<p>In this study, we have proposed a neuro-symbolic algorithm, LCNR, for accurately predicting the position and severity of transverse cracks in cantilever steel beams, even under imperfect clamping conditions. Our approach combines the strength of artificial neural networks with symbolic regression. The effectiveness of the LCNR methodology was tested using both FEM simulations and experimental measurements.  Our results demonstrate that LCNR achieves high accuracy in predicting the location of transverse cracks in cantilever steel beams. The algorithm was able to predict damage scenarios with an error of less than 5% for both FEM and experimental datasets, surpassing the performance of a Deep Neural Network model used as a backbone for LCNR. This validates the effectiveness of the proposed hybrid method and highlights its potential applicability in real-world scenarios where precise damage prediction is vital. </p>
<p>Figure 1 :
1Schematic cantilever beam</p>
<p>Figure 2 :
2Schematic LCNR model.Given the goal of predicting the numerical value of the crack position, the Root Mean Square Error (RMSE) was chosen as the accuracy measurement for comparing predicted values with actual ones. However, it is important to note that the primary objective of our model during training was to maximize the satisfiability value of our axioms. Satisfiability, a concept from fuzzy logic, ranges between [0,1] and is analogous to a loss function in Machine or Deep Learning.</p>
<p>Figure 3 :
3Relationship between the predicted and actual values. The blue line represents a perfect regression.</p>
<p>Figure 4 :
4Detail on the fixed end of the model realized in ANSYS with highlighting the crack and the imperfect boundary condition.</p>
<p>Figure 5 :
5Experimental setup</p>
<p>Figure 6 :
6Imperfect (weak) clamping setup</p>
<p>natural frequency for the undamaged beam, • f i−D the natural frequency for the damaged beam • x crack position • a crack depth • γ(a) damage severity • [ϕ ′′ i (x)] 2 squared normalized modal curvature for the i-th mode of transverse vibration From equation 1 the RFS values are deduced with the following relation 2:</p>
<p>Table 1 :
1Results of LCNR (with 4 different metrics) on the FEM dataset, the same model but without the added logical part (Conv1D) and a typical DNN regression model with a similar number of parameters. The listed methods represent the predicate used in our system. The standard deviation is listed to assess the performance.Method 
Standard Deviation </p>
<p>Euclidean 
10.8 
Manhattan 
10.7 
Mink, p = 2 
11.5 
Mink, p = 1 
12.0 
Conv1D, DL 
48.2 
DNN 
51.0 </p>
<p>Table 2 :
2Distance/similarity comparison of the worst predicted scenarios.Euclidean 
Manhattan </p>
<p>Real Predicted Error[%] Real Predicted Error[%] </p>
<p>325 
376 
5.1 
466 
414 
5.2 
347 
397 
5.0 
489 
440 
4.9 
414 
460 
4.6 
516 
470 
4.6 
690 
735 
4.5 
516 
472 
4.4 </p>
<p>Minkowski of order 1 
Minkowski of order 2 </p>
<p>Real Predicted Error[%] Real Predicted Error[%] </p>
<p>690 
646 
4.4 
360 
317 
4.3 
173 
216 
4.3 
360 
402 
4.2 
255 
294 
3.9 
466 
507 
4.1 
165 
204 
3.9 
796 
834 
3.8 </p>
<p>Table 3 :
3Defined damage scenarios </p>
<p>Damage scenario Crack position x [mm] Damage scenario Crack position x [mm] </p>
<p>1 
56 
14 
466 </p>
<p>Table 4 :
4Defined damage scenariosDamage scen. 
Beam 1 Beam 2 Beam 3 Beam 4 Beam 5 </p>
<p>x [mm] 
98 
310 
569 
126 
759 
a [mm] 
2.5 
1.25 
2.5 
2.5 
2.5 
γ 2 (a) 2 
0.0262 
0.0051 
0.0262 
0.0262 
0.0262 </p>
<p>Table 5 :
5Obtained RFS values for the test beamDamage scenario 
Beam 1 
Beam 2 
Beam 3 
Beam 4 
Beam 5 
Beam 1 </p>
<p>Damage location 
98 
310 
569 
126 
759 
98 
Crack depth mm 
2.5 
1.25 
2.5 
2.5 
2.5 
2.5 
Crack depth severity 0.026224 0.005124 0.026224 0.026224 0.026224 0.026224 
Clamping type 
Perfect 
Perfect 
Perfect 
Perfect 
Perfect 
Imperfect </p>
<p>Table 6 :
6Results obtained for the damage scenarios with perfect clamping Crack position x [mm] Error [%] Crack position x [mm] Error [%]Damage Scenario 
Damage scenario </p>
<p>Real 
Predicted 
Real 
Predicted </p>
<p>1 56 
52.605 
0.340 
14 466 
423.707 
4.229 
2 81 
71.092 
0.991 
15 489 
458.925 
3.007 
3 120 
96.869 
2.313 
16 516 
460.720 
5.528 
4 165 
133.080 
3.192 
17 560 
524.264 
3.574 
5 173 
140.818 
3.218 
18 660 
644.529 
1.547 
6 210 
183.252 
2.674 
19 687 
675.843 
1.116 
7 233 
204.225 
2.877 
20 690 
680.542 
0.946 
8 255 
232.158 
2.284 
21 760 
739.184 
2.082 
9 290 
281.614 
0.838 
22 796 
766.848 
2.915 
10 325 
315.698 
0.930 
23 820 
790.347 
2.965 
11 347 
336.876 
1.012 
24 896 
882.467 
1.353 
12 360 
349.734 
1.026 
25 906 
899.799 
0.620 
13 414 
398.890 
1.511 
26 946 
964.947 
1.894 </p>
<p>Table 7 :
7Results obtained for the damage scenarios with imperfect clampingDamage Scenario 
Damage scenario </p>
<p>Crack position x [mm] Error [%] 
Crack position x [mm] Error [%] </p>
<p>Real 
Predicted 
Real 
Predicted </p>
<p>27 56 
47.987 
0.801 
40 466 
395.247 
7.075 
28 81 
68.215 
1.279 
41 489 
440.911 
4.809 
29 120 
100.212 
1.979 
42 516 
468.056 
4.794 
30 165 
139.528 
2.547 
43 560 
522.347 
3.765 
31 173 
148.006 
2.499 
44 660 
640.515 
1.949 
32 210 
184.273 
2.573 
45 687 
669.519 
1.748 
33 233 
208.066 
2.493 
46 690 
669.050 
2.095 
34 255 
237.016 
1.798 
47 760 
725.672 
3.433 
35 290 
280.431 
0.957 
48 796 
763.983 
3.202 
36 325 
316.065 
0.893 
49 820 
789.601 
3.040 
37 347 
336.730 
1.027 
50 896 
869.310 
2.669 
38 360 
336.730 
2.327 
51 906 
883.037 
2.296 
39 414 
358.597 
5.540 
52 946 
941.592 
0.441 </p>
<p>Table 8 :
8Results obtained for the damage scenarios with imperfect clamping Damage Scenario Damage scenario Crack position x [mm] Error [%] Crack position x [mm] Error [%]Real 
Predicted 
Real 
Predicted </p>
<p>53 56 
42.995 
1.301 
66 466 
418.942 
4.706 
54 81 
62.682 
1.832 
67 489 
436.844 
5.216 
55 120 
97.701 
2.230 
68 516 
468.162 
4.784 
56 165 
135.323 
2.968 
69 560 
506.787 
5.321 
57 173 
143.408 
2.959 
70 660 
639.915 
2.008 
58 210 
178.840 
3.116 
71 687 
665.192 
2.181 
59 233 
202.454 
3.055 
72 690 
667.220 
2.278 
60 255 
229.125 
2.587 
73 760 
726.848 
3.315 
61 290 
273.119 
1.688 
74 796 
764.322 
3.168 
62 325 
310.303 
1.470 
75 820 
785.755 
3.425 
63 347 
331.844 
1.516 
76 896 
863.200 
3.280 
64 360 
348.813 
1.119 
77 906 
875.503 
3.050 
65 414 
386.226 
2.777 
78 946 
927.354 
1.865 </p>
<p>Table 9 :
9Real versus Predicted values for LCNR and the DL Network within it. LCNR Conv1D Network (same as the one used in LCNR) Figure 7: Evolution of accuracy and satisfiability with the Euclidean distance/similarity predicateReal 
Predicted Error[%] 
Type 
Real 
Predicted Error[%] 
Clamping type </p>
<p>120.00 
118.72 
0.128 
Perfect 
120.00 
101.62 
1.838 
Perfect 
56.00 
57.22 
0.122 
Imperfect 56.00 
13.38 
4.262 
Imperfect 
165.00 
166.06 
0.106 
Perfect 
165.00 
168.50 
0.350 
Perfect 
81.00 
82.04 
0.104 
Imperfect 81.00 
97.70 
1.670 
Imperfect </p>
<p>AcknowledgmentsThe artificial intelligence part including the novel LCRN neuro-symbolic deep learning architecture was proposed and implemented by Darian Onchis and Eduard Hogea. The mechanical engineering part including the dataset acquisition and the experiments was realized by Gilbert-Rainer Gillich and Cristian Tufisi.
Real-time structural health monitoring and damage identification using frequency response functions along with finite element model updating technique. T Singh, S Sehgal, C Prakash, S Dixit, Sensors. 224546T. Singh, S. Sehgal, C. Prakash, and S. Dixit. Real-time structural health monitoring and damage identification using frequency response functions along with finite element model updating technique. Sensors, 22:4546, 2022.</p>
<p>Towards a practical structural health monitoring technology for patched cracks in aircraft structure. I Baker, N Rajic, C Davis, Composites Part A: Applied Science and Manufacturing. 40I. Baker, N. Rajic, and C. Davis. Towards a practical structural health monitoring technology for patched cracks in aircraft structure. Composites Part A: Applied Science and Manufacturing, 40:1340-1352, 2009.</p>
<p>Dynamic structural health monitoring for concrete gravity dams based on the bayesian inference. G Sevieri, A De Falco, Journal of Civil Structural Health Monitoring. 10G. Sevieri and A. De Falco. Dynamic structural health monitoring for concrete gravity dams based on the bayesian inference. Journal of Civil Structural Health Monitoring, 10:235-250, 2020.</p>
<p>Data fusion/data mining-based architecture for condition-based maintenance. D Raheja, J Llinas, R Nagi, C Romanowski, International Journal of Production Research. 44D. Raheja, J. Llinas, R. Nagi, and C. Romanowski. Data fusion/data mining-based architecture for condition-based maintenance. International Journal of Production Research, 44:2869-2887, 2006.</p>
<p>Wavelet-type denoising for mechanical structures diagnosis. D M Onchis, G R Gillich, World Scientific and Engineering Academy and SocietyD.M. Onchis and G.R. Gillich. Wavelet-type denoising for mechanical structures diagnosis. page 200-203. World Scientific and Engineering Academy and Society, 2010.</p>
<p>Damage detection and finite-element model updating of structural components through point cloud analysis. K Ghahremani, A Khaloo, S Mohamadi, D Lattanzi, Journal of Aerospace Engineering. 3154018068K. Ghahremani, A. Khaloo, S. Mohamadi, and D. Lattanzi. Damage detection and finite-element model updating of structural components through point cloud analysis. Journal of Aerospace Engineering, 31(5):04018068, 2018.</p>
<p>Vibration-based multiclass damage detection and localization using long short-term memory networks. S Sony, A S Gamage, J Sadh, Samarabandu, Structures. 35S. Sony, A S. Gamage, Sadh, and J. Samarabandu. Vibration-based multiclass damage detection and localization using long short-term memory networks. Structures, 35:436-451, 2022.</p>
<p>Vibration-based damage identification methods: A review and comparative study. Structural Health Monitoring. W Fan, P Qiao, 10W. Fan and P. Qiao. Vibration-based damage identification methods: A review and comparative study. Structural Health Monitoring, 10(1):83-111, 2011.</p>
<p>A review of vibration-based damage detection in civil structures: From traditional methods to machine learning and deep learning applications. A Onur, A Osama, K Serkan, H Mohammed, G Moncef, D J Inman, Mechanical Systems and Signal Processing. 147107077A. Onur, A. Osama, K. Serkan, H. Mohammed, G. Moncef, and D. J. Inman. A review of vibration-based damage detection in civil structures: From traditional methods to machine learning and deep learning applications. Mechanical Systems and Signal Processing, 147:107077, 2021.</p>
<p>A structural damage detection method using static noisy data. Engineering Structures. F Bakhtiari Nejad, A Rahai, A Esfandiari, 27F. Bakhtiari Nejad, A. Rahai, and A. Esfandiari. A structural damage detection method using static noisy data. Engineering Structures, 27(12):1784-1793, 2005.</p>
<p>Constructive reconstruction from irregular sampling in multi-window spline-type spaces. H G Feichtinger, D M Onchis, chapter General Proceedings of the 7th ISAAC Congress. LondonH.G. Feichtinger and D.M. Onchis. Constructive reconstruction from irregular sampling in multi-window spline-type spaces, chapter General Proceedings of the 7th ISAAC Congress, London, pages 257-265.</p>
<p>S R Bowman, arXiv:1312.6192Can recursive neural tensor networks learn logical reasoning. arXiv preprintS. R. Bowman. Can recursive neural tensor networks learn logical reasoning? arXiv preprint arXiv:1312.6192, 2013.</p>
<p>Observing damaged beams through their time-frequency extended signatures. D Onchis, Signal Processing. 96D. Onchis. Observing damaged beams through their time-frequency extended signatures. Signal Processing, 96:16-20, 03 2014.</p>
<p>Why deep-learning ais are so easy to fool. D Heaven, Nature. 574D. Heaven. Why deep-learning ais are so easy to fool. Nature, 574:163-166, 2019.</p>
<p>Threat of adversarial attacks on deep learning in computer vision: A survey. N Akhtar, A Mian, IEEE Access. 6N. Akhtar and A. Mian. Threat of adversarial attacks on deep learning in computer vision: A survey. IEEE Access, 6:14410-14430, 2018.</p>
<p>M Gary, arXiv:1801.00631Deep learning: A critical appraisal. arXiv preprintM. Gary. Deep learning: A critical appraisal. arXiv preprint arXiv:1801.00631, 2018.</p>
<p>S Badreddine, A D&apos;avila Garcez, L Serafini, M Spranger, Logic tensor networks. S. Badreddine, A. D'Avila Garcez, L. Serafini, and M. Spranger. Logic tensor networks, 2016.</p>
<p>Advantages of a neuro-symbolic solution for monitoring it infrastructures alerts. D M Onchis, C Istin, E F Hogea, 2022 24th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC). D.M. Onchis, C. Istin, and E.F. Hogea. Advantages of a neuro-symbolic solution for monitoring it infrastructures alerts. In 2022 24th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC), pages 189-194, 2022.</p>
<p>Learning physical intuition of block towers by example. A Lerer, S Gross, R Fergus, International conference on machine learning. PMLRA. Lerer, S. Gross, and R. Fergus. Learning physical intuition of block towers by example. In International conference on machine learning, pages 4307-4315. PMLR, 2016.</p>
<p>Humans predict liquid dynamics using probabilistic simulation. C Bates, I Yildirim, J B Tenenbaum, P W Battaglia, CogSciC. Bates, I. Yildirim, J. B. Tenenbaum, and P. W. Battaglia. Humans predict liquid dynamics using probabilistic simulation. In CogSci, 2015.</p>
<p>Logic tensor networks for semantic image interpretation. I Donadello, L Serafini, A. D&apos;avila Garcez, arXiv:1705.08968arXiv preprintI. Donadello, L. Serafini, and A. D'Avila Garcez. Logic tensor networks for semantic image interpretation. arXiv preprint arXiv:1705.08968, 2017.</p>
<p>Logic tensor network with massive learned knowledge for aspect-based sentiment analysis. Knowledge-Based Systems. H Hu, 257109943H. Hu et al. Logic tensor network with massive learned knowledge for aspect-based sentiment analysis. Knowledge- Based Systems, 257:109943, 2022.</p>
<p>A robust damage detection method based on multi-modal analysis in variable temperature conditions. G R Gillich, H Furdui, M A Wahab, Z I Korka, Mechanical Systems and Signal Processing. 115G.R. Gillich, H. Furdui, M.A. Wahab, and Z.I. Korka. A robust damage detection method based on multi-modal analysis in variable temperature conditions. Mechanical Systems and Signal Processing, 115:361-379, 2019.</p>
<p>Modal identification and damage detection in beam-like structures using the power spectrum and time-frequency analysis. G R Gillich, Z I Praisach, Signal Processing. 96G.R. Gillich and Z.I. Praisach. Modal identification and damage detection in beam-like structures using the power spectrum and time-frequency analysis. Signal Processing, 96:29-44, 2014.</p>
<p>Damage detection in beam through change in measured frequency and undamaged curvature mode shape. N Touat, M Dahak, M Kharoubi, Inverse Problems in Science and Engineering. 271N. Touat M. Dahak and M. Kharoubi. Damage detection in beam through change in measured frequency and undamaged curvature mode shape. Inverse Problems in Science and Engineering, 27(1):89-114, 2019.</p>
<p>An enhanced single damage identification in beams using natural frequency shifts and analytic modal curvatures. D T Ta, T P Le, M Burman, Journal of Science and Technology in Civil Engineering (STCE) -HUCE. 17D.T. Ta, T.P. Le, and M. Burman. An enhanced single damage identification in beams using natural frequency shifts and analytic modal curvatures. Journal of Science and Technology in Civil Engineering (STCE) -HUCE, 17:1-15, 2023.</p>
<p>A method for an accurate estimation of natural frequencies using swept-sine acoustic excitation. I C Mituletu, G R Gillich, N Mm Maia, Mechanical Systems and Signal Processing. 116I.C. Mituletu, G.R. Gillich, and N. MM. Maia. A method for an accurate estimation of natural frequencies using swept-sine acoustic excitation. Mechanical Systems and Signal Processing, 116:693-709, 2019.</p>
<p>Effect of non-ideal clamping shape on the resonance frequencies of silicon nanocantilevers. S Guillon, Nanotechnology. 2224245501S. Guillon et al. Effect of non-ideal clamping shape on the resonance frequencies of silicon nanocantilevers. Nanotechnology, 22(24):245501, 2011.</p>
<p>A continuous cracked beam vibration theory. T G Chondros, A D Dimarogonas, J Yao, Journal of Sound and Vibration. 2151T.G. Chondros, A.D. Dimarogonas, and J. Yao. A continuous cracked beam vibration theory. Journal of Sound and Vibration, 215(1):17-34, 1998.</p>
<p>Damage regression. C Tufisi, 10.17632/fzw7v49m6n.1doi: 10.17632/fzw7v49m6n.12023Tufisi C. Damage regression. https://doi.org/10.17632/fzw7v49m6n.1, 2023. doi: 10.17632/fzw7v49m6n.1.</p>
<p>Face and marker detection using gabor frames on gpus. M Gaianu, D M Onchis, Signal Processing. 96M. Gaianu and D.M. Onchis. Face and marker detection using gabor frames on gpus. Signal Processing, 96:90-93, 2014.</p>            </div>
        </div>

    </div>
</body>
</html>