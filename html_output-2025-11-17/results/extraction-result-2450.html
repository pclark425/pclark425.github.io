<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2450 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2450</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2450</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-65.html">extraction-schema-65</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-271064295</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2407.07061v2.pdf" target="_blank">Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence</a></p>
                <p><strong>Paper Abstract:</strong> The rapid advancement of large language models (LLMs) has paved the way for the development of highly capable autonomous agents. However, existing multi-agent frameworks often struggle with integrating diverse capable third-party agents due to reliance on agents defined within their own ecosystems. They also face challenges in simulating distributed environments, as most frameworks are limited to single-device setups. Furthermore, these frameworks often rely on hard-coded communication pipelines, limiting their adaptability to dynamic task requirements. Inspired by the concept of the Internet, we propose the Internet of Agents (IoA), a novel framework that addresses these limitations by providing a flexible and scalable platform for LLM-based multi-agent collaboration. IoA introduces an agent integration protocol, an instant-messaging-like architecture design, and dynamic mechanisms for agent teaming and conversation flow control. Through extensive experiments on general assistant tasks, embodied AI tasks, and retrieval-augmented generation benchmarks, we demonstrate that IoA consistently outperforms state-of-the-art baselines, showcasing its ability to facilitate effective collaboration among heterogeneous agents. IoA represents a step towards linking diverse agents in an Internet-like environment, where agents can seamlessly collaborate to achieve greater intelligence and capabilities. Our codebase has been released at \url{https://github.com/OpenBMB/IoA}.</p>
                <p><strong>Cost:</strong> 0.026</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2450.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2450.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IoA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Internet of Agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A server-client, Internet-inspired multi-agent framework that integrates heterogeneous LLM-based agents via a standardized agent integration protocol, supports dynamic nested team formation, and controls structured conversations with an LLM-driven finite-state machine and a comprehensive message protocol.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Internet of Agents (IoA)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>IoA is a layered, distributed multi-agent framework (server + client wrappers) designed to integrate heterogeneous third-party agents and enable scalable, structured multi-agent collaboration. The server provides Data, Interaction and Foundation layers (Agent Registry, Agent Query, Group Setup, Session Management, Message Routing, Milvus-backed registry). Clients wrap individual agents and provide an Interaction Layer (Team Formation, Communication), a Data Layer (Agent Contact, Group Info, Task Management using SQLite) and a Foundation Layer (Agent Integration, Network over WebSocket). Key mechanisms: agent registration & discovery (semantic search over registry), autonomous nested team formation (search_client + launch_group_chat producing group chats and recursive sub-groups), conversation flow control via an LLM-driven finite state machine (states: discussion, synchronous/asynchronous assignment, pause & trigger, conclusion) with sequential-speaking enforcement, and a structured JSON-like message protocol (header + payload with fields like sender, comm_id, state, goal, task_id, next_speaker, triggers). Agents execute tasks via a standardized integration API (run(task_desc: str) -> TaskID).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (framework supports many agents); examples in paper: 4 ReAct agents for GAIA; 2 third-party agents (AutoGPT + Open Interpreter) in open-ended experiments; 2 clients for RoCoBench; RAG setups with 2 or 3 agents; team-formation evaluation with 1500 dummy agents</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Framework-level support for arbitrary specializations; paper examples: web-browser agent (web search), code interpreter agent (execute/run code), Wikidata searcher, YouTube transcript downloader, PDF expert, scholarly-database-access agent, academic-writing specialist, AutoGPT (third-party autonomous agent), Open Interpreter (third-party code-focused agent), embodied agents with partial observation/action spaces. Role types used: idea/brainstorming agents, literature-review/data-retrieval agents, implementation agents (code execution/interpreters), tool-enabled specialized perception/processing agents (e.g., PDF/extraction), task-execution agents (run integrated third-party tools), and editors/integrators for final synthesis.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Idea generation/brainstorming, literature review/evidence retrieval, task decomposition and allocation, subtask execution (tool calls / code execution / retrieval), intermediate result reporting, synthesis and collaborative editing, final integration and conclusion; demonstrated end-to-end in walkthrough of writing a research paper and in benchmarks (GAIA, RAG, embodied coordination).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Hybrid centralized orchestration with decentralized decision-making: a central server (Agent Registry, Agent Query, Group Setup, Message Routing) manages discovery and routing, while each client/agent uses its internal LLM to decide tool calls, team formation, state transitions and next-speaker selection. Team formation is autonomous and nested (agents call search_client to find collaborators and launch_group_chat to create group chats/sub-group chats), and conversation coordination is governed by a finite-state machine controlled by clients' LLMs using a decision function f_LLM(M_t, s_t) -> (s_{t+1}, c_{t+1}). Task allocation supports synchronous (pause) and asynchronous assignment. Hierarchical nested teams reduce communication channels compared to full-mesh.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Structured message-passing over persistent WebSocket connections using a comprehensive JSON-like agent message protocol with header (sender, comm_id, state, team_members, team_up_depth, max_turns, goal) and payload fields (message_type/type: discussion/task_assignment/pause&trigger/conclusion, content, next_speaker, task_id, task_desc, task_conclusion, task_abstract, triggers). Server parses comm_id and routes messages to group members; Milvus and similarity search are used for agent discovery. Messages are encoded/decoded by clients and follow instant-messaging semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Task reporting and status fields: agents report task completion via task_conclusion and task_abstract fields to the group chat; Task Management Module stores status (pending/in_progress/completed) and conclusions. Pause & trigger messages let the group wait for specified asynchronous tasks (triggers) before continuing. Agent Contact Module records prior collaboration outcomes to inform future team formation. Evaluation in experiments uses external judges (e.g., GPT-4). Additionally, cost/communication analysis and manual deduplication were used as feedback to refine message patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>On-demand and continuous: clients maintain persistent WebSocket connections and exchange messages in real time; communication frequency is controlled by conversation state (discussion with sequential speaking), synchronous task assignment (pauses until completion), or asynchronous assignment (parallel work and later reporting). Next-speaker selection is decided at each step by client LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General multi-domain scientific/research support: demonstrated on assistant QA tasks (GAIA), open-ended instruction tasks (writing/code/math/life-assist), embodied AI coordination (RoCoBench), retrieval-augmented generation (RAG) question-answering, and a walkthrough of collaboratively writing an academic paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics include benchmark scores and win rates: GAIA validation set — IoA overall: 40.00 (Level1: 50.94, Level2: 40.70, Level3: 15.38) (Table 1). Open-ended instruction benchmark — IoA orchestration achieved win rates of 76.5% vs AutoGPT and 63.4% vs Open Interpreter (Fig.5). RoCoBench embodied tasks — IoA achieved perfect success rates (1.00) on Cabinet, Sandwich, and Sort tasks and outperformed Roco Dialog on 4/5 tasks; reported success rates (paper): Cabinet 1.00, Sandwich 1.00, Sort 1.00, Sweep 0.80, Rope 0.70 (Table 2). RAG tasks — IoA (GPT-3.5-based) performed on par with or better than GPT-4 on datasets (TriviaQA, NQ, HotpotQA, 2WikiMultiHopQA); heterogeneous knowledge setup outperformed homogeneous Apollo's Oracle on two of four datasets. Team formation precision metrics: Regular formation Top@1=41.4%, Top@10=64.9%, MR=27.4, MRR=50.1%; Nested formation Top@1=59.7%, Top@10=81.8%, MR=10.6, MRR=66.5% (Table 4). Cost metrics: standalone AutoGPT $0.39/task, Open Interpreter $0.16/task; in IoA AutoGPT $0.33, Open Interpreter $0.13; IoA communication cost $0.53 ($0.28 after dedup); IoA overall $0.99 ($0.74 dedup) (Table 5).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>IoA is compared to multiple baselines: AutoGen (multi-agent framework) — IoA outperforms AutoGen on GAIA in 2/3 levels; AutoGPT and Open Interpreter (standalone) — IoA orchestration wins 76.5% and 63.4% respectively on open-ended benchmark; Roco Dialog (specialized multi-agent embodied framework) and Central Plan (centralized oracle) — IoA outperforms Roco Dialog on 4/5 RoCoBench tasks and is comparable or superior to Central Plan in success rate though often requiring slightly more steps; Apollo's Oracle (RAG baseline) — IoA matches or surpasses Apollo configurations on some datasets and matches GPT-4 performance in many settings.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Benefits reported: improved task performance via coordinated heterogeneous agents (higher benchmark scores on GAIA than many baselines); strong orchestration gains when combining diverse third-party agents (win rates vs standalone AutoGPT/Open Interpreter); robust embodied coordination (perfect success on multiple RoCoBench tasks); improved RAG results leveraging heterogeneous evidence pools; reduced per-agent cost after task decomposition when integrated into IoA (AutoGPT cost reduced from $0.39 to $0.33; Open Interpreter from $0.16 to $0.13). Nested team formation reduces the total number of communication channels compared to full-mesh by decomposing work into subgroups. Quantitative gains: GAIA overall 40.00 (top-performing in paper's table vs many baselines), open-ended win rates 76.5% and 63.4%, team formation Top@10 up to 81.8% in nested setting.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Reported limitations include communication overhead (IoA introduced $0.53 communication cost per task), suboptimal LLM communication patterns (repetition of information, failure to switch to pause & trigger state), token cost blow-up due to repeated messages (manual deduping reduced communication cost by ~50%), need for alignment of LLMs as efficient communicators rather than chat assistants, and potential scalability/security concerns (Security Module not fully implemented). Agents sometimes fail to trigger appropriate state transitions causing stagnation.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Partial analyses: a 'dedup' manual removal of repeated messages reduced communication token counts and halved communication costs (IoA communication cost from $0.53 to $0.28 and overall cost $0.99 to $0.74). Team formation precision experiments (simulated with GPT-4-generated tasks and agent profiles) evaluate Regular vs Nested formation with Top@1/Top@10/MR/MRR metrics (Table 4). No full ablation turning off nested teams or FSM reported, but analyses highlight the cost of communication repetition and show nested formation yields higher retrieval precision.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Observations/suggestions rather than strict prescriptions: nested team formation improves precision and reduces channels; heterogeneous tool specialization (e.g., 4 ReAct agents with distinct tools) is effective on GAIA; heterogeneous knowledge (separate evidence pools) can outperform homogeneous pooled setups for some RAG datasets; 2-agent homogeneous sometimes outperforms 3-agent in certain multi-hop RAG tasks suggesting task-dependent optimal agent counts; practical implementation limits: max tool calls per client set to 10 to avoid infinite loops; sequential speaking as a simple baseline that can be extended.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2450.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2450.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AutoGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AutoGPT (Significant Gravitas, autonomous agent)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An autonomous third-party agent used as a heterogeneous architectural component integrated into IoA for open-ended instruction experiments; capable of multi-step autonomous task execution.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AutoGPT (third-party agent integrated into IoA)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>AutoGPT is used as an external third-party autonomous agent with its own multi-step planning and execution behavior; in the paper it is integrated into IoA to evaluate orchestration of heterogeneous-architecture agents. IoA orchestrates AutoGPT via the agent integration protocol and message protocol; AutoGPT receives tasks and returns execution summaries via the standardized run(task_desc) interface.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>1 (used together with Open Interpreter as a 2-agent integration in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>General autonomous task execution, planning and decomposition (used for open-ended instruction tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Task decomposition, autonomous multi-step execution, generating intermediate artifacts and conclusions (when prompted to produce a final conclusion).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Coordinated by IoA (central server + LLM-driven client decisions) via nested group chats and message protocol; AutoGPT itself internally plans but is orchestrated externally by IoA for team formation and turn-taking.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Communicates through the IoA message protocol over WebSocket, exchanging structured JSON-like messages (task assignments, next_speaker, task_id, task_desc, task_conclusion).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Reports task conclusions and abstracts back to the group chat; task status tracked in Task Management Module; judged in evaluation by GPT-4 for final answers.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>As per IoA settings: synchronous or asynchronous assignment as decided by group-state; messages exchanged on-demand during group chats.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Open-ended instruction benchmark (search & report, coding, mathematics, life assistance).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Standalone cost: $0.39 per task; when integrated in IoA cost: $0.33 per task. In pairwise evaluation (orchestrated by IoA) IoA beats standalone AutoGPT with 76.5% win rate (this is an IoA vs AutoGPT result rather than AutoGPT's internal metric).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared as a standalone to IoA-orchestrated configurations; IoA orchestration improved outcomes vs standalone AutoGPT.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Integration into IoA reduced AutoGPT's per-task cost and improved final answer win rate when orchestrated with complementary agents (as measured by GPT-4 pairwise judgment).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>No internal ablations reported for AutoGPT; challenges when integrated are IoA-wide: communication overhead and repeated messages increasing token/cost.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>No dedicated ablation for AutoGPT alone; cost dedup experiment shows communication cost reductions when removing message repetition across the IoA orchestration.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Paper reports that combining AutoGPT with complementary agents inside IoA produced better results than standalone; no single optimal AutoGPT configuration prescribed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2450.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2450.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Open Interpreter</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Open Interpreter</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A third-party agent focused on interpreting and executing code; integrated into IoA as a heterogeneous-architecture agent for open-ended instruction tasks and compared against IoA orchestration.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Open Interpreter (third-party agent integrated into IoA)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Open Interpreter provides code interpretation/execution capabilities and is integrated into IoA via the agent integration protocol so that it can be recruited for tasks requiring code execution or interpretation. In experiments it participates as one of two heterogeneous third-party agents orchestrated by IoA.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>1 (used with AutoGPT as a 2-agent integration in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Code execution, interpreting code outputs, and assisting with programming/coding subtasks within open-ended instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Implementation/execution and result generation for coding tasks, and contributing to synthesis in open-ended tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Orchestrated within IoA via group chats, state-machine driven conversation flow and the message protocol; Open Interpreter receives structured task assignments and returns summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Structured IoA protocol over WebSocket; payload fields include task_desc and task_conclusion used to pass code tasks and results.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Returns task conclusions and abstracts which are recorded in Task Management Module and shared to group for integration.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>On-demand within group chat; can be assigned synchronously (pause) or asynchronously per state.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Open-ended instruction benchmark, especially coding tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Standalone cost: $0.16 per task; when integrated into IoA cost: $0.13 per task. IoA orchestration produced a 63.4% win rate against Open Interpreter when judging final outputs (IoA vs Open Interpreter).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared as a standalone system vs IoA-orchestrated multi-agent configuration; IoA orchestration outperformed standalone Open Interpreter in pairwise judged comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Lower per-task cost when integrated into IoA and improved judged answer quality when orchestrated with complementary agents.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Subject to IoA communication overheads and LLM repetition issues described for the framework.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>No internal ablation reported; overall IoA ablations (dedup) reduced communication cost that benefits integrated agents.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Paper suggests integration of code-specialist agents with retrieval/knowledge-specialist agents in IoA is beneficial for open-ended tasks; no single optimal configuration stated.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2450.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2450.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ReAct agents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ReAct (reasoning+acting) agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Agent design pattern combining reasoning traces and tool actions (ReAct) used as basic agent types within IoA for the GAIA benchmark experiments, each equipped with a distinct tool.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ReAct-based tool-enabled agents (as instantiated in IoA)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>In GAIA experiments IoA instantiates four basic ReAct agents, each following the ReAct paradigm (interleaving language-model reasoning with tool calls) and each equipped with a distinct tool (web browser, code interpreter, Wikidata searcher, YouTube transcript downloader) to test heterogeneous-tool coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>4 (in the GAIA experiment configuration)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Web search agent (browser), code executor agent (code interpreter), knowledge-base search agent (Wikidata), multimedia transcript retriever (YouTube transcript downloader).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Evidence retrieval, reasoning and tool-mediated execution for multi-step question answering tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Orchestrated by IoA through nested group chats and FSM conversation control; agents are discovered and assigned via search_client and launch_group_chat.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>IoA message protocol over WebSocket, with task assignment and result reporting fields used to coordinate tool calls and share results.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Agents report tool outputs back into the group chat; task conclusions are aggregated for final answer.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>On-demand during group discussion and asynchronous task allocation for parallel tool use.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>GAIA benchmark (general AI assistant multi-step question answering).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>In GAIA validation results IoA (with 4 ReAct agents) achieved overall 40.00, Level1 50.94, Level2 40.70, Level3 15.38, outperforming many baselines listed in Table 1 within the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to AutoGen, GPT-4+Plugins, FRIDAY, and others on GAIA; IoA with ReAct agents achieved highest overall performance among the compared approaches in their table.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Demonstrated that even basic ReAct agents can achieve strong multi-step problem solving when coordinated effectively by IoA; improved Level 2/3 performance due to better collaborative use of heterogeneous tools.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>General LLM communication inefficiencies (repetition) persisted; integration and adaptation of tool interfaces required minor modifications.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>No isolated ablation of ReAct vs non-ReAct agents reported; overall framework analyses apply.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Using a diverse set of complementary tools (browser, code, knowledge, transcript) per agent was effective for GAIA; IoA prompt set kept constant across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2450.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2450.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AutoGen</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AutoGen (multi-agent conversation framework)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior multi-agent conversation framework cited as a state-of-the-art baseline; used in comparative evaluation on GAIA where IoA outperforms it in some measures.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autogen: Enabling next-gen LLM applications via multi-agent conversation framework</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AutoGen (referenced baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>AutoGen is a multi-agent conversation framework previously proposed for multi-agent LLM applications; in the paper it is used as a comparison point on GAIA, where AutoGen had differing tool integration approaches (fewer tool-enabled agents vs IoA's flexible integration).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (not instantiated by the paper)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Not detailed in this paper; referenced as existing multi-agent conversation framework.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>General multi-agent coordination in prior work (mentioned in related work and GAIA comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Described by citation only; not used or implemented in this paper's experiments beyond comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Not described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Not described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Not described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Prior multi-agent tasks (used as baseline on GAIA in comparison table).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AutoGen reported in Table 1: Level1 54.72, Level2 38.37, Level3 11.54, Overall 39.39 (paper's GAIA comparison).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>AutoGen is one of the SoTA baselines compared to IoA on GAIA; IoA outperformed AutoGen on overall and some levels as reported.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Not analyzed here beyond being a comparative baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not analyzed here.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Not applicable in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2450.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2450.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AgentVerse</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AgentVerse</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior framework facilitating multi-agent collaboration and emergent behavior, cited in related work; not used experimentally in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AgentVerse (referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>AgentVerse is an earlier system for simulating and enabling multi-agent interactions. The paper references it as prior work that inspired multi-agent collaboration research but does not use it directly.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (not specified in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Not specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Not specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General multi-agent simulations/experiments in prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Mentioned as related work; not used as an experimental baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Not analyzed here.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not analyzed here.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Not applicable here.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2450.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2450.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Apollo's Oracle</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Apollo's Oracle (retrieval-augmented reasoning multi-agent system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent RAG system used as a comparative baseline for retrieval-augmented generation experiments; IoA is compared to Apollo's Oracle in homogeneous and heterogeneous knowledge settings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Apollo's oracle: Retrieval-augmented reasoning in multi-agent debates</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Apollo's Oracle (referenced baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Apollo's Oracle is a prior system for retrieval-augmented generation and multi-agent debate-style reasoning. In this paper it serves as a baseline for RAG tasks; IoA (GPT-3.5-based) is compared to Apollo's Oracle under heterogeneous and homogeneous evidence-pool settings.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (not concretized in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Agents specialized in retrieving from evidence pools and debating/synthesizing answers.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Evidence retrieval, multi-agent debate/synthesis for question answering (RAG).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Debate-style multi-agent coordination (as per cited work); within this paper Apollo is used as baseline only.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Retrieval-augmented generation (RAG) QA tasks (TriviaQA, NQ, HotpotQA, 2WikiMultiHopQA).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>IoA heterogeneous knowledge scenario outperformed homogeneous Apollo's Oracle on two of four RAG tasks (specific dataset-level numbers in Table 3). IoA (3-agent homogeneous) achieved best overall performance on TriviaQA in the comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Used as an explicit comparative baseline for RAG experiments; IoA sometimes outperforms Apollo's Oracle.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Apollo's design serves as a baseline showing debate-style or multi-agent retrieval benefits; IoA demonstrates comparable-or-better performance in many settings.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not analyzed here beyond comparative performance.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Not applicable in this paper's experiments beyond comparing heterogeneous vs homogeneous agent knowledge setups.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Paper finds that agent count and knowledge configuration can be task-dependent; no single Apollo-optimal config provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2450.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2450.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Roco Dialog / RocoBench</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Roco Dialog (baseline framework) / RoCoBench (embodied benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Roco Dialog is a specialized multi-agent framework for embodied AI coordination; RoCoBench is the benchmark used to evaluate embodied multi-agent coordination in the paper. IoA is compared against Roco Dialog and Central Plan on RoCoBench tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Roco: Dialectic multi-robot collaboration with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Roco Dialog (baseline framework for embodied tasks) / RoCoBench (benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Roco Dialog is a prior multi-agent communication framework tailored to embodied robot coordination and was used as a baseline in the RoCoBench experiments. RoCoBench provides multi-agent embodied tasks requiring partial observability and distinct action spaces (Cabinet, Sweep, Sandwich, Sort, Rope). In the paper IoA was adapted to RoCoBench (two clients provided with environment observations) and compared to Roco Dialog and Central Plan.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>task-dependent; RoCoBench tasks require 2-3 agents. In paper, IoA used 2 clients for experiments (adapted per task).</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Embodied agents with partial observation and restricted action spaces; roles include opening/holding cabinet, retrieving objects, sweeping, holding bucket, coordinated movement for rope manipulation.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Perception/observation interpretation, planning/coordinated action sequencing, inter-agent communication for embodied task execution.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Roco Dialog uses specialized multi-agent dialogue protocols for embodied coordination (cited). IoA used its group chat FSM and nested group approach to mediate agent coordination for RoCoBench tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Roco Dialog's protocol (from cited work) vs IoA's structured message protocol; IoA used formatted strings parsed to action plans to interface with RoCoBench environment.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Agents output action plans in predefined format parsed by environment; IoA maintains chat history for dependent tasks and can spawn new group chats per action where steps are less interdependent.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Task-dependent; IoA used retained chat history for interdependent tasks and new group chats per action for less dependent tasks to control cost.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Embodied AI multi-agent coordination (RoCoBench tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table 2: IoA outperformed Roco Dialog on 4 of 5 tasks in success rate. IoA achieved perfect scores (1.00) on Cabinet, Sandwich, and Sort tasks while Roco Dialog had success rates around 0.70-0.75. IoA sometimes required slightly more steps than the Central Plan baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared directly against Roco Dialog (specialized multi-agent system) and Central Plan (centralized oracle) with 10-run averages reported.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>IoA's general-purpose mechanisms generalized to embodied tasks and achieved higher success rates on most RoCoBench tasks despite not being specialized for embodied AI.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>IoA required slightly more decision steps than Central Plan, and cost trade-offs led to task-specific group-chat strategies to optimize expense.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>No ablation disabling communication components reported specifically for RoCoBench; paper reports different chat management strategies per task (retain chat history vs new group chat per action) as cost/efficiency decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>For tasks with strong step interdependencies (Sort/Sandwich/Sweep), retaining chat history and continuing discussion is beneficial; for less interdependent tasks (Cabinet/Rope), creating new group chats per action can reduce cost.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Autogen: Enabling next-gen LLM applications via multi-agent conversation framework <em>(Rating: 2)</em></li>
                <li>Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors <em>(Rating: 2)</em></li>
                <li>Apollo's oracle: Retrieval-augmented reasoning in multi-agent debates <em>(Rating: 2)</em></li>
                <li>Roco: Dialectic multi-robot collaboration with large language models <em>(Rating: 2)</em></li>
                <li>GAIA: a benchmark for general AI assistants <em>(Rating: 2)</em></li>
                <li>React: Synergizing reasoning and acting in language models <em>(Rating: 1)</em></li>
                <li>AutoGPT (Significant Gravitas) <em>(Rating: 1)</em></li>
                <li>Open Interpreter <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2450",
    "paper_id": "paper-271064295",
    "extraction_schema_id": "extraction-schema-65",
    "extracted_data": [
        {
            "name_short": "IoA",
            "name_full": "Internet of Agents",
            "brief_description": "A server-client, Internet-inspired multi-agent framework that integrates heterogeneous LLM-based agents via a standardized agent integration protocol, supports dynamic nested team formation, and controls structured conversations with an LLM-driven finite-state machine and a comprehensive message protocol.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Internet of Agents (IoA)",
            "system_description": "IoA is a layered, distributed multi-agent framework (server + client wrappers) designed to integrate heterogeneous third-party agents and enable scalable, structured multi-agent collaboration. The server provides Data, Interaction and Foundation layers (Agent Registry, Agent Query, Group Setup, Session Management, Message Routing, Milvus-backed registry). Clients wrap individual agents and provide an Interaction Layer (Team Formation, Communication), a Data Layer (Agent Contact, Group Info, Task Management using SQLite) and a Foundation Layer (Agent Integration, Network over WebSocket). Key mechanisms: agent registration & discovery (semantic search over registry), autonomous nested team formation (search_client + launch_group_chat producing group chats and recursive sub-groups), conversation flow control via an LLM-driven finite state machine (states: discussion, synchronous/asynchronous assignment, pause & trigger, conclusion) with sequential-speaking enforcement, and a structured JSON-like message protocol (header + payload with fields like sender, comm_id, state, goal, task_id, next_speaker, triggers). Agents execute tasks via a standardized integration API (run(task_desc: str) -&gt; TaskID).",
            "number_of_agents": "variable (framework supports many agents); examples in paper: 4 ReAct agents for GAIA; 2 third-party agents (AutoGPT + Open Interpreter) in open-ended experiments; 2 clients for RoCoBench; RAG setups with 2 or 3 agents; team-formation evaluation with 1500 dummy agents",
            "agent_specializations": "Framework-level support for arbitrary specializations; paper examples: web-browser agent (web search), code interpreter agent (execute/run code), Wikidata searcher, YouTube transcript downloader, PDF expert, scholarly-database-access agent, academic-writing specialist, AutoGPT (third-party autonomous agent), Open Interpreter (third-party code-focused agent), embodied agents with partial observation/action spaces. Role types used: idea/brainstorming agents, literature-review/data-retrieval agents, implementation agents (code execution/interpreters), tool-enabled specialized perception/processing agents (e.g., PDF/extraction), task-execution agents (run integrated third-party tools), and editors/integrators for final synthesis.",
            "research_phases_covered": "Idea generation/brainstorming, literature review/evidence retrieval, task decomposition and allocation, subtask execution (tool calls / code execution / retrieval), intermediate result reporting, synthesis and collaborative editing, final integration and conclusion; demonstrated end-to-end in walkthrough of writing a research paper and in benchmarks (GAIA, RAG, embodied coordination).",
            "coordination_mechanism": "Hybrid centralized orchestration with decentralized decision-making: a central server (Agent Registry, Agent Query, Group Setup, Message Routing) manages discovery and routing, while each client/agent uses its internal LLM to decide tool calls, team formation, state transitions and next-speaker selection. Team formation is autonomous and nested (agents call search_client to find collaborators and launch_group_chat to create group chats/sub-group chats), and conversation coordination is governed by a finite-state machine controlled by clients' LLMs using a decision function f_LLM(M_t, s_t) -&gt; (s_{t+1}, c_{t+1}). Task allocation supports synchronous (pause) and asynchronous assignment. Hierarchical nested teams reduce communication channels compared to full-mesh.",
            "communication_protocol": "Structured message-passing over persistent WebSocket connections using a comprehensive JSON-like agent message protocol with header (sender, comm_id, state, team_members, team_up_depth, max_turns, goal) and payload fields (message_type/type: discussion/task_assignment/pause&trigger/conclusion, content, next_speaker, task_id, task_desc, task_conclusion, task_abstract, triggers). Server parses comm_id and routes messages to group members; Milvus and similarity search are used for agent discovery. Messages are encoded/decoded by clients and follow instant-messaging semantics.",
            "feedback_mechanism": "Task reporting and status fields: agents report task completion via task_conclusion and task_abstract fields to the group chat; Task Management Module stores status (pending/in_progress/completed) and conclusions. Pause & trigger messages let the group wait for specified asynchronous tasks (triggers) before continuing. Agent Contact Module records prior collaboration outcomes to inform future team formation. Evaluation in experiments uses external judges (e.g., GPT-4). Additionally, cost/communication analysis and manual deduplication were used as feedback to refine message patterns.",
            "communication_frequency": "On-demand and continuous: clients maintain persistent WebSocket connections and exchange messages in real time; communication frequency is controlled by conversation state (discussion with sequential speaking), synchronous task assignment (pauses until completion), or asynchronous assignment (parallel work and later reporting). Next-speaker selection is decided at each step by client LLMs.",
            "task_domain": "General multi-domain scientific/research support: demonstrated on assistant QA tasks (GAIA), open-ended instruction tasks (writing/code/math/life-assist), embodied AI coordination (RoCoBench), retrieval-augmented generation (RAG) question-answering, and a walkthrough of collaboratively writing an academic paper.",
            "performance_metrics": "Reported metrics include benchmark scores and win rates: GAIA validation set — IoA overall: 40.00 (Level1: 50.94, Level2: 40.70, Level3: 15.38) (Table 1). Open-ended instruction benchmark — IoA orchestration achieved win rates of 76.5% vs AutoGPT and 63.4% vs Open Interpreter (Fig.5). RoCoBench embodied tasks — IoA achieved perfect success rates (1.00) on Cabinet, Sandwich, and Sort tasks and outperformed Roco Dialog on 4/5 tasks; reported success rates (paper): Cabinet 1.00, Sandwich 1.00, Sort 1.00, Sweep 0.80, Rope 0.70 (Table 2). RAG tasks — IoA (GPT-3.5-based) performed on par with or better than GPT-4 on datasets (TriviaQA, NQ, HotpotQA, 2WikiMultiHopQA); heterogeneous knowledge setup outperformed homogeneous Apollo's Oracle on two of four datasets. Team formation precision metrics: Regular formation Top@1=41.4%, Top@10=64.9%, MR=27.4, MRR=50.1%; Nested formation Top@1=59.7%, Top@10=81.8%, MR=10.6, MRR=66.5% (Table 4). Cost metrics: standalone AutoGPT $0.39/task, Open Interpreter $0.16/task; in IoA AutoGPT $0.33, Open Interpreter $0.13; IoA communication cost $0.53 ($0.28 after dedup); IoA overall $0.99 ($0.74 dedup) (Table 5).",
            "baseline_comparison": "IoA is compared to multiple baselines: AutoGen (multi-agent framework) — IoA outperforms AutoGen on GAIA in 2/3 levels; AutoGPT and Open Interpreter (standalone) — IoA orchestration wins 76.5% and 63.4% respectively on open-ended benchmark; Roco Dialog (specialized multi-agent embodied framework) and Central Plan (centralized oracle) — IoA outperforms Roco Dialog on 4/5 RoCoBench tasks and is comparable or superior to Central Plan in success rate though often requiring slightly more steps; Apollo's Oracle (RAG baseline) — IoA matches or surpasses Apollo configurations on some datasets and matches GPT-4 performance in many settings.",
            "coordination_benefits": "Benefits reported: improved task performance via coordinated heterogeneous agents (higher benchmark scores on GAIA than many baselines); strong orchestration gains when combining diverse third-party agents (win rates vs standalone AutoGPT/Open Interpreter); robust embodied coordination (perfect success on multiple RoCoBench tasks); improved RAG results leveraging heterogeneous evidence pools; reduced per-agent cost after task decomposition when integrated into IoA (AutoGPT cost reduced from $0.39 to $0.33; Open Interpreter from $0.16 to $0.13). Nested team formation reduces the total number of communication channels compared to full-mesh by decomposing work into subgroups. Quantitative gains: GAIA overall 40.00 (top-performing in paper's table vs many baselines), open-ended win rates 76.5% and 63.4%, team formation Top@10 up to 81.8% in nested setting.",
            "coordination_challenges": "Reported limitations include communication overhead (IoA introduced $0.53 communication cost per task), suboptimal LLM communication patterns (repetition of information, failure to switch to pause & trigger state), token cost blow-up due to repeated messages (manual deduping reduced communication cost by ~50%), need for alignment of LLMs as efficient communicators rather than chat assistants, and potential scalability/security concerns (Security Module not fully implemented). Agents sometimes fail to trigger appropriate state transitions causing stagnation.",
            "ablation_studies": "Partial analyses: a 'dedup' manual removal of repeated messages reduced communication token counts and halved communication costs (IoA communication cost from $0.53 to $0.28 and overall cost $0.99 to $0.74). Team formation precision experiments (simulated with GPT-4-generated tasks and agent profiles) evaluate Regular vs Nested formation with Top@1/Top@10/MR/MRR metrics (Table 4). No full ablation turning off nested teams or FSM reported, but analyses highlight the cost of communication repetition and show nested formation yields higher retrieval precision.",
            "optimal_configurations": "Observations/suggestions rather than strict prescriptions: nested team formation improves precision and reduces channels; heterogeneous tool specialization (e.g., 4 ReAct agents with distinct tools) is effective on GAIA; heterogeneous knowledge (separate evidence pools) can outperform homogeneous pooled setups for some RAG datasets; 2-agent homogeneous sometimes outperforms 3-agent in certain multi-hop RAG tasks suggesting task-dependent optimal agent counts; practical implementation limits: max tool calls per client set to 10 to avoid infinite loops; sequential speaking as a simple baseline that can be extended.",
            "uuid": "e2450.0",
            "source_info": {
                "paper_title": "Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "AutoGPT",
            "name_full": "AutoGPT (Significant Gravitas, autonomous agent)",
            "brief_description": "An autonomous third-party agent used as a heterogeneous architectural component integrated into IoA for open-ended instruction experiments; capable of multi-step autonomous task execution.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "AutoGPT (third-party agent integrated into IoA)",
            "system_description": "AutoGPT is used as an external third-party autonomous agent with its own multi-step planning and execution behavior; in the paper it is integrated into IoA to evaluate orchestration of heterogeneous-architecture agents. IoA orchestrates AutoGPT via the agent integration protocol and message protocol; AutoGPT receives tasks and returns execution summaries via the standardized run(task_desc) interface.",
            "number_of_agents": "1 (used together with Open Interpreter as a 2-agent integration in experiments)",
            "agent_specializations": "General autonomous task execution, planning and decomposition (used for open-ended instruction tasks).",
            "research_phases_covered": "Task decomposition, autonomous multi-step execution, generating intermediate artifacts and conclusions (when prompted to produce a final conclusion).",
            "coordination_mechanism": "Coordinated by IoA (central server + LLM-driven client decisions) via nested group chats and message protocol; AutoGPT itself internally plans but is orchestrated externally by IoA for team formation and turn-taking.",
            "communication_protocol": "Communicates through the IoA message protocol over WebSocket, exchanging structured JSON-like messages (task assignments, next_speaker, task_id, task_desc, task_conclusion).",
            "feedback_mechanism": "Reports task conclusions and abstracts back to the group chat; task status tracked in Task Management Module; judged in evaluation by GPT-4 for final answers.",
            "communication_frequency": "As per IoA settings: synchronous or asynchronous assignment as decided by group-state; messages exchanged on-demand during group chats.",
            "task_domain": "Open-ended instruction benchmark (search & report, coding, mathematics, life assistance).",
            "performance_metrics": "Standalone cost: $0.39 per task; when integrated in IoA cost: $0.33 per task. In pairwise evaluation (orchestrated by IoA) IoA beats standalone AutoGPT with 76.5% win rate (this is an IoA vs AutoGPT result rather than AutoGPT's internal metric).",
            "baseline_comparison": "Compared as a standalone to IoA-orchestrated configurations; IoA orchestration improved outcomes vs standalone AutoGPT.",
            "coordination_benefits": "Integration into IoA reduced AutoGPT's per-task cost and improved final answer win rate when orchestrated with complementary agents (as measured by GPT-4 pairwise judgment).",
            "coordination_challenges": "No internal ablations reported for AutoGPT; challenges when integrated are IoA-wide: communication overhead and repeated messages increasing token/cost.",
            "ablation_studies": "No dedicated ablation for AutoGPT alone; cost dedup experiment shows communication cost reductions when removing message repetition across the IoA orchestration.",
            "optimal_configurations": "Paper reports that combining AutoGPT with complementary agents inside IoA produced better results than standalone; no single optimal AutoGPT configuration prescribed.",
            "uuid": "e2450.1",
            "source_info": {
                "paper_title": "Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Open Interpreter",
            "name_full": "Open Interpreter",
            "brief_description": "A third-party agent focused on interpreting and executing code; integrated into IoA as a heterogeneous-architecture agent for open-ended instruction tasks and compared against IoA orchestration.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Open Interpreter (third-party agent integrated into IoA)",
            "system_description": "Open Interpreter provides code interpretation/execution capabilities and is integrated into IoA via the agent integration protocol so that it can be recruited for tasks requiring code execution or interpretation. In experiments it participates as one of two heterogeneous third-party agents orchestrated by IoA.",
            "number_of_agents": "1 (used with AutoGPT as a 2-agent integration in experiments)",
            "agent_specializations": "Code execution, interpreting code outputs, and assisting with programming/coding subtasks within open-ended instructions.",
            "research_phases_covered": "Implementation/execution and result generation for coding tasks, and contributing to synthesis in open-ended tasks.",
            "coordination_mechanism": "Orchestrated within IoA via group chats, state-machine driven conversation flow and the message protocol; Open Interpreter receives structured task assignments and returns summaries.",
            "communication_protocol": "Structured IoA protocol over WebSocket; payload fields include task_desc and task_conclusion used to pass code tasks and results.",
            "feedback_mechanism": "Returns task conclusions and abstracts which are recorded in Task Management Module and shared to group for integration.",
            "communication_frequency": "On-demand within group chat; can be assigned synchronously (pause) or asynchronously per state.",
            "task_domain": "Open-ended instruction benchmark, especially coding tasks.",
            "performance_metrics": "Standalone cost: $0.16 per task; when integrated into IoA cost: $0.13 per task. IoA orchestration produced a 63.4% win rate against Open Interpreter when judging final outputs (IoA vs Open Interpreter).",
            "baseline_comparison": "Compared as a standalone system vs IoA-orchestrated multi-agent configuration; IoA orchestration outperformed standalone Open Interpreter in pairwise judged comparisons.",
            "coordination_benefits": "Lower per-task cost when integrated into IoA and improved judged answer quality when orchestrated with complementary agents.",
            "coordination_challenges": "Subject to IoA communication overheads and LLM repetition issues described for the framework.",
            "ablation_studies": "No internal ablation reported; overall IoA ablations (dedup) reduced communication cost that benefits integrated agents.",
            "optimal_configurations": "Paper suggests integration of code-specialist agents with retrieval/knowledge-specialist agents in IoA is beneficial for open-ended tasks; no single optimal configuration stated.",
            "uuid": "e2450.2",
            "source_info": {
                "paper_title": "Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "ReAct agents",
            "name_full": "ReAct (reasoning+acting) agents",
            "brief_description": "Agent design pattern combining reasoning traces and tool actions (ReAct) used as basic agent types within IoA for the GAIA benchmark experiments, each equipped with a distinct tool.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "ReAct-based tool-enabled agents (as instantiated in IoA)",
            "system_description": "In GAIA experiments IoA instantiates four basic ReAct agents, each following the ReAct paradigm (interleaving language-model reasoning with tool calls) and each equipped with a distinct tool (web browser, code interpreter, Wikidata searcher, YouTube transcript downloader) to test heterogeneous-tool coordination.",
            "number_of_agents": "4 (in the GAIA experiment configuration)",
            "agent_specializations": "Web search agent (browser), code executor agent (code interpreter), knowledge-base search agent (Wikidata), multimedia transcript retriever (YouTube transcript downloader).",
            "research_phases_covered": "Evidence retrieval, reasoning and tool-mediated execution for multi-step question answering tasks.",
            "coordination_mechanism": "Orchestrated by IoA through nested group chats and FSM conversation control; agents are discovered and assigned via search_client and launch_group_chat.",
            "communication_protocol": "IoA message protocol over WebSocket, with task assignment and result reporting fields used to coordinate tool calls and share results.",
            "feedback_mechanism": "Agents report tool outputs back into the group chat; task conclusions are aggregated for final answer.",
            "communication_frequency": "On-demand during group discussion and asynchronous task allocation for parallel tool use.",
            "task_domain": "GAIA benchmark (general AI assistant multi-step question answering).",
            "performance_metrics": "In GAIA validation results IoA (with 4 ReAct agents) achieved overall 40.00, Level1 50.94, Level2 40.70, Level3 15.38, outperforming many baselines listed in Table 1 within the paper.",
            "baseline_comparison": "Compared to AutoGen, GPT-4+Plugins, FRIDAY, and others on GAIA; IoA with ReAct agents achieved highest overall performance among the compared approaches in their table.",
            "coordination_benefits": "Demonstrated that even basic ReAct agents can achieve strong multi-step problem solving when coordinated effectively by IoA; improved Level 2/3 performance due to better collaborative use of heterogeneous tools.",
            "coordination_challenges": "General LLM communication inefficiencies (repetition) persisted; integration and adaptation of tool interfaces required minor modifications.",
            "ablation_studies": "No isolated ablation of ReAct vs non-ReAct agents reported; overall framework analyses apply.",
            "optimal_configurations": "Using a diverse set of complementary tools (browser, code, knowledge, transcript) per agent was effective for GAIA; IoA prompt set kept constant across tasks.",
            "uuid": "e2450.3",
            "source_info": {
                "paper_title": "Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "AutoGen",
            "name_full": "AutoGen (multi-agent conversation framework)",
            "brief_description": "A prior multi-agent conversation framework cited as a state-of-the-art baseline; used in comparative evaluation on GAIA where IoA outperforms it in some measures.",
            "citation_title": "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework",
            "mention_or_use": "mention",
            "system_name": "AutoGen (referenced baseline)",
            "system_description": "AutoGen is a multi-agent conversation framework previously proposed for multi-agent LLM applications; in the paper it is used as a comparison point on GAIA, where AutoGen had differing tool integration approaches (fewer tool-enabled agents vs IoA's flexible integration).",
            "number_of_agents": "variable (not instantiated by the paper)",
            "agent_specializations": "Not detailed in this paper; referenced as existing multi-agent conversation framework.",
            "research_phases_covered": "General multi-agent coordination in prior work (mentioned in related work and GAIA comparisons).",
            "coordination_mechanism": "Described by citation only; not used or implemented in this paper's experiments beyond comparison.",
            "communication_protocol": "Not described in this paper.",
            "feedback_mechanism": "Not described in this paper.",
            "communication_frequency": "Not described in this paper.",
            "task_domain": "Prior multi-agent tasks (used as baseline on GAIA in comparison table).",
            "performance_metrics": "AutoGen reported in Table 1: Level1 54.72, Level2 38.37, Level3 11.54, Overall 39.39 (paper's GAIA comparison).",
            "baseline_comparison": "AutoGen is one of the SoTA baselines compared to IoA on GAIA; IoA outperformed AutoGen on overall and some levels as reported.",
            "coordination_benefits": "Not analyzed here beyond being a comparative baseline.",
            "coordination_challenges": "Not analyzed here.",
            "ablation_studies": "Not applicable in this paper.",
            "optimal_configurations": "Not provided in this paper.",
            "uuid": "e2450.4",
            "source_info": {
                "paper_title": "Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "AgentVerse",
            "name_full": "AgentVerse",
            "brief_description": "A prior framework facilitating multi-agent collaboration and emergent behavior, cited in related work; not used experimentally in this paper.",
            "citation_title": "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors",
            "mention_or_use": "mention",
            "system_name": "AgentVerse (referenced)",
            "system_description": "AgentVerse is an earlier system for simulating and enabling multi-agent interactions. The paper references it as prior work that inspired multi-agent collaboration research but does not use it directly.",
            "number_of_agents": "variable (not specified in this paper)",
            "agent_specializations": "Not specified here.",
            "research_phases_covered": "Not specified here.",
            "coordination_mechanism": "Not detailed in this paper.",
            "communication_protocol": "Not detailed in this paper.",
            "feedback_mechanism": "Not detailed in this paper.",
            "communication_frequency": "Not detailed in this paper.",
            "task_domain": "General multi-agent simulations/experiments in prior work.",
            "performance_metrics": "Not reported in this paper.",
            "baseline_comparison": "Mentioned as related work; not used as an experimental baseline.",
            "coordination_benefits": "Not analyzed here.",
            "coordination_challenges": "Not analyzed here.",
            "ablation_studies": "Not applicable here.",
            "optimal_configurations": "Not provided here.",
            "uuid": "e2450.5",
            "source_info": {
                "paper_title": "Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Apollo's Oracle",
            "name_full": "Apollo's Oracle (retrieval-augmented reasoning multi-agent system)",
            "brief_description": "A multi-agent RAG system used as a comparative baseline for retrieval-augmented generation experiments; IoA is compared to Apollo's Oracle in homogeneous and heterogeneous knowledge settings.",
            "citation_title": "Apollo's oracle: Retrieval-augmented reasoning in multi-agent debates",
            "mention_or_use": "mention",
            "system_name": "Apollo's Oracle (referenced baseline)",
            "system_description": "Apollo's Oracle is a prior system for retrieval-augmented generation and multi-agent debate-style reasoning. In this paper it serves as a baseline for RAG tasks; IoA (GPT-3.5-based) is compared to Apollo's Oracle under heterogeneous and homogeneous evidence-pool settings.",
            "number_of_agents": "variable (not concretized in this paper)",
            "agent_specializations": "Agents specialized in retrieving from evidence pools and debating/synthesizing answers.",
            "research_phases_covered": "Evidence retrieval, multi-agent debate/synthesis for question answering (RAG).",
            "coordination_mechanism": "Debate-style multi-agent coordination (as per cited work); within this paper Apollo is used as baseline only.",
            "communication_protocol": "Not detailed in this paper.",
            "feedback_mechanism": "Not detailed in this paper.",
            "communication_frequency": "Not detailed in this paper.",
            "task_domain": "Retrieval-augmented generation (RAG) QA tasks (TriviaQA, NQ, HotpotQA, 2WikiMultiHopQA).",
            "performance_metrics": "IoA heterogeneous knowledge scenario outperformed homogeneous Apollo's Oracle on two of four RAG tasks (specific dataset-level numbers in Table 3). IoA (3-agent homogeneous) achieved best overall performance on TriviaQA in the comparisons.",
            "baseline_comparison": "Used as an explicit comparative baseline for RAG experiments; IoA sometimes outperforms Apollo's Oracle.",
            "coordination_benefits": "Apollo's design serves as a baseline showing debate-style or multi-agent retrieval benefits; IoA demonstrates comparable-or-better performance in many settings.",
            "coordination_challenges": "Not analyzed here beyond comparative performance.",
            "ablation_studies": "Not applicable in this paper's experiments beyond comparing heterogeneous vs homogeneous agent knowledge setups.",
            "optimal_configurations": "Paper finds that agent count and knowledge configuration can be task-dependent; no single Apollo-optimal config provided here.",
            "uuid": "e2450.6",
            "source_info": {
                "paper_title": "Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Roco Dialog / RocoBench",
            "name_full": "Roco Dialog (baseline framework) / RoCoBench (embodied benchmark)",
            "brief_description": "Roco Dialog is a specialized multi-agent framework for embodied AI coordination; RoCoBench is the benchmark used to evaluate embodied multi-agent coordination in the paper. IoA is compared against Roco Dialog and Central Plan on RoCoBench tasks.",
            "citation_title": "Roco: Dialectic multi-robot collaboration with large language models",
            "mention_or_use": "use",
            "system_name": "Roco Dialog (baseline framework for embodied tasks) / RoCoBench (benchmark)",
            "system_description": "Roco Dialog is a prior multi-agent communication framework tailored to embodied robot coordination and was used as a baseline in the RoCoBench experiments. RoCoBench provides multi-agent embodied tasks requiring partial observability and distinct action spaces (Cabinet, Sweep, Sandwich, Sort, Rope). In the paper IoA was adapted to RoCoBench (two clients provided with environment observations) and compared to Roco Dialog and Central Plan.",
            "number_of_agents": "task-dependent; RoCoBench tasks require 2-3 agents. In paper, IoA used 2 clients for experiments (adapted per task).",
            "agent_specializations": "Embodied agents with partial observation and restricted action spaces; roles include opening/holding cabinet, retrieving objects, sweeping, holding bucket, coordinated movement for rope manipulation.",
            "research_phases_covered": "Perception/observation interpretation, planning/coordinated action sequencing, inter-agent communication for embodied task execution.",
            "coordination_mechanism": "Roco Dialog uses specialized multi-agent dialogue protocols for embodied coordination (cited). IoA used its group chat FSM and nested group approach to mediate agent coordination for RoCoBench tasks.",
            "communication_protocol": "Roco Dialog's protocol (from cited work) vs IoA's structured message protocol; IoA used formatted strings parsed to action plans to interface with RoCoBench environment.",
            "feedback_mechanism": "Agents output action plans in predefined format parsed by environment; IoA maintains chat history for dependent tasks and can spawn new group chats per action where steps are less interdependent.",
            "communication_frequency": "Task-dependent; IoA used retained chat history for interdependent tasks and new group chats per action for less dependent tasks to control cost.",
            "task_domain": "Embodied AI multi-agent coordination (RoCoBench tasks).",
            "performance_metrics": "Table 2: IoA outperformed Roco Dialog on 4 of 5 tasks in success rate. IoA achieved perfect scores (1.00) on Cabinet, Sandwich, and Sort tasks while Roco Dialog had success rates around 0.70-0.75. IoA sometimes required slightly more steps than the Central Plan baseline.",
            "baseline_comparison": "Compared directly against Roco Dialog (specialized multi-agent system) and Central Plan (centralized oracle) with 10-run averages reported.",
            "coordination_benefits": "IoA's general-purpose mechanisms generalized to embodied tasks and achieved higher success rates on most RoCoBench tasks despite not being specialized for embodied AI.",
            "coordination_challenges": "IoA required slightly more decision steps than Central Plan, and cost trade-offs led to task-specific group-chat strategies to optimize expense.",
            "ablation_studies": "No ablation disabling communication components reported specifically for RoCoBench; paper reports different chat management strategies per task (retain chat history vs new group chat per action) as cost/efficiency decisions.",
            "optimal_configurations": "For tasks with strong step interdependencies (Sort/Sandwich/Sweep), retaining chat history and continuing discussion is beneficial; for less interdependent tasks (Cabinet/Rope), creating new group chats per action can reduce cost.",
            "uuid": "e2450.7",
            "source_info": {
                "paper_title": "Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence",
                "publication_date_yy_mm": "2024-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework",
            "rating": 2,
            "sanitized_title": "autogen_enabling_nextgen_llm_applications_via_multiagent_conversation_framework"
        },
        {
            "paper_title": "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors",
            "rating": 2,
            "sanitized_title": "agentverse_facilitating_multiagent_collaboration_and_exploring_emergent_behaviors"
        },
        {
            "paper_title": "Apollo's oracle: Retrieval-augmented reasoning in multi-agent debates",
            "rating": 2,
            "sanitized_title": "apollos_oracle_retrievalaugmented_reasoning_in_multiagent_debates"
        },
        {
            "paper_title": "Roco: Dialectic multi-robot collaboration with large language models",
            "rating": 2,
            "sanitized_title": "roco_dialectic_multirobot_collaboration_with_large_language_models"
        },
        {
            "paper_title": "GAIA: a benchmark for general AI assistants",
            "rating": 2,
            "sanitized_title": "gaia_a_benchmark_for_general_ai_assistants"
        },
        {
            "paper_title": "React: Synergizing reasoning and acting in language models",
            "rating": 1,
            "sanitized_title": "react_synergizing_reasoning_and_acting_in_language_models"
        },
        {
            "paper_title": "AutoGPT (Significant Gravitas)",
            "rating": 1,
            "sanitized_title": "autogpt_significant_gravitas"
        },
        {
            "paper_title": "Open Interpreter",
            "rating": 1,
            "sanitized_title": "open_interpreter"
        }
    ],
    "cost": 0.02583025,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Work in progress INTERNET OF AGENTS: WEAVING A WEB OF HET-EROGENEOUS AGENTS FOR COLLABORATIVE INTEL-LIGENCE
10 Jul 2024</p>
<p>Weize Chen 
Tsinghua University</p>
<p>Equal Contribution</p>
<p>Ziming You zimingyou@stu.pku.edu.cn 
Peking University</p>
<p>Equal Contribution</p>
<p>Ran Li 
Tsinghua University</p>
<p>Equal Contribution</p>
<p>Yitong Guan 
Peking University</p>
<p>Equal Contribution</p>
<p>Chen Qian 
Tsinghua University</p>
<p>Chenyang Zhao 
Tsinghua University</p>
<p>Cheng Yang 
Beijing University of Posts and Telecommunications</p>
<p>Ruobing Xie 
Tencent</p>
<p>Zhiyuan Liu 
Tsinghua University</p>
<p>Maosong Sun 
Tsinghua University</p>
<p>Group Info Block 
Work in progress INTERNET OF AGENTS: WEAVING A WEB OF HET-EROGENEOUS AGENTS FOR COLLABORATIVE INTEL-LIGENCE
10 Jul 202410595D058D7F8C6B285DA371CDCAE40DarXiv:2407.07061v2[cs.CL]
The rapid advancement of large language models (LLMs) has paved the way for the development of highly capable autonomous agents.However, existing multi-agent frameworks often struggle with integrating diverse capable third-party agents due to reliance on agents defined within their own ecosystems.They also face challenges in simulating distributed environments, as most frameworks are limited to single-device setups.Furthermore, these frameworks often rely on hard-coded communication pipelines, limiting their adaptability to dynamic task requirements.Inspired by the concept of the Internet, we propose the Internet of Agents (IoA), a novel framework that addresses these limitations by providing a flexible and scalable platform for LLM-based multi-agent collaboration.IoA introduces an agent integration protocol, an instant-messaging-like architecture design, and dynamic mechanisms for agent teaming and conversation flow control.Through extensive experiments on general assistant tasks, embodied AI tasks, and retrieval-augmented generation benchmarks, we demonstrate that IoA consistently outperforms state-of-the-art baselines, showcasing its ability to facilitate effective collaboration among heterogeneous agents.IoA represents a step towards linking diverse agents in an Internet-like environment, where agents can seamlessly collaborate to achieve greater intelligence and capabilities.Our codebase has been released at https://github.com/OpenBMB/IoA.</p>
<p>INTRODUCTION</p>
<p>The Internet has revolutionized the way people collaborate and share knowledge, connecting individuals with diverse skills and backgrounds from all around the world.This global network has enabled the creation of remarkable collaborative projects, such as Wikipedia1 and the development of the Linux operating system2 , which would have been impossible for any single person to achieve.The Internet has greatly facilitated collaboration among people, making the impossible possible and pushing the boundaries of human achievement.</p>
<p>The success of the Internet in enabling human collaboration raises an intriguing question: can we create a similar platform to facilitate collaboration among autonomous agents?With the rapid advancements in LLMs (OpenAI, 2023;Reid et al., 2024), we now have autonomous agents capable of achieving near-human performance on a wide range of tasks.These LLM-based agents have demonstrated the ability to break down complex tasks into executable steps, leverage various tools, and learn from feedback and experience (Qin et al., 2023;Wang et al., 2023c;Shinn et al., 2023; Data Layer: Serving as the information backbone, the Data Layer handles the storage and management of critical system information.The Agent Registry Block maintains a comprehensive database of registered agents, including their capabilities and current status, similar to service discovery in distributed systems (Meshkova et al., 2008;Netflix).Meanwhile, the Session Management Block manages active connections and ensures continuous communication between the server and connected clients.</p>
<p>Foundation Layer: Underpinning the entire system, the Foundation Layer provides the essential infrastructure for the server's operations.It encompasses the Data Infrastructure Block for handling data persistence and retrieval, the Network Infrastructure Block for managing network communications, and the Security Block for implementing authentication, authorization, and other security measures to maintain system integrity.</p>
<p>CLIENT ARCHITECTURE</p>
<p>The client component of IoA serves as a wrapper for individual agents, providing them with the necessary interfaces to communicate within the system.Its architecture mirrors that of the server with three layers:</p>
<p>Interaction Layer: At the forefront of agent operations, the Interaction Layer manages the agent's interactions within the system.The Team Formation Block implements the logic for identifying suitable collaborators and forming teams for the task at hand, similar to coalition formation in conventional multi-agent research (Rahwan et al., 2009).Complementing this, the Communication Block manages the agent's participation in group chats and handles message processing.</p>
<p>Data Layer: Functioning as the agent's memory, the Data Layer maintains local data relevant to the agent's operations.It includes the Agent Contact Block for storing information about other agents the current agent has interacted with, the Group Info Block for maintaining details about ongoing group chats and collaborations, and the Task Management Block for tracking the status and progress of tasks assigned to the agent.</p>
<p>Foundation Layer: Forming the base of the client architecture, the Foundation Layer provides the basic functionalities for the client's operations.The Agent Integration Block defines the protocols and interfaces for integrating third-party agents into the IoA ecosystem.Alongside this, the Data Infrastructure Block handles local data storage and retrieval, while the Network Infrastructure Block manages network communications with the server.This layered architecture enables IoA to support a wide range of agent types and collaboration scenarios.By providing a clear separation of concerns and well-defined interfaces between layers, the architecture facilitates the integration of diverse agents and allows for future extensibility.Furthermore, this design supports the key mechanisms of IoA, such as autonomous team formation and conversation flow control, which we will explore in detail in the following subsections.</p>
<p>KEY MECHANISMS</p>
<p>The effectiveness of IoA relies on several key mechanisms that enable seamless collaboration among diverse agents.These mechanisms work in concert to facilitate agent integration, team formation, task allocation, and structured communication.We detail these critical components in this section.</p>
<p>AGENT REGISTRATION AND DISCOVERY</p>
<p>To enable collaboration among distributed agents with heterogeneous architectures, tools, and environments, we propose the agent registration and discovery mechanism.This mechanism forms the foundation for collaborative interactions within IoA, enabling the integration of diverse agents into the system and facilitating their discovery on the online server by other agents for potential collaboration through the network.</p>
<p>Agent Registration: When a new agent joins the IoA, its client wrapper undergoes a registration process with the server.During registration, the agent should provide a comprehensive description of its capabilities, skills, and areas of expertise.This description, denoted as d i for an agent c i , is stored in the Agent Registry Block of the server's Data Layer.Formally, we represent the set of all registered agents as C = {c 1 , c 2 , ..., c n }, where each c i is associated with its description d i .</p>
<p>Agent Discovery: The agent discovery function leverages the information stored in the Agent Registry from the online server to enable agents to find suitable collaborators for specific tasks.When an agent needs to form a team or seek assistance, it can use the search client tool provided by the server's Agent Query Block.This tool allows an agent to search for other agents based on desired characteristics or capabilities.Formally, the agent discovery process can be described as follows: Let L d = [l 1 , l 2 , ..., l k ] be a list of desired characteristics generated by an agent seeking collaborators.The search client function can be represented as: search client : L d → P(C), where P(C) denotes the power set of C. The function returns a subset of clients C d ⊆ C whose descriptions d j match the desired characteristics in L d .The matching process between L d and d j can be implemented with various semantic matching techniques (Robertson &amp; Zaragoza, 2009;Karpukhin et al., 2020).It ensures that agents with relevant capabilities can be discovered even if their descriptions do not exactly match the search criteria.</p>
<p>AUTONOMOUS NESTED TEAM FORMATION</p>
<p>The autonomous nested team formation mechanism enables dynamic and flexible combinations of appropriate agents.This mechanism allows agents to form teams adaptively based on task requirements and to create nested sub-teams for complex, multi-faceted tasks.</p>
<p>Team Formation Process: When a client c i ∈ C is assigned a task t, it initiates the team formation process.The client has access to two essential tools provided by the server: search client and launch group chat.The LLM in the client is prompted to decide which tool to call based on the task and the current set of discovered clients.If more collaborators are needed, it calls search client with appropriate characteristics.Once suitable collaborators are found, it calls launch group chat to initiate a new group chat g ∈ G, where G is the space of all group chats.Nested Team Structure: The nested team formation allows for a hierarchical structure of teams and sub-teams.Let g 0 ∈ G be the initial group chat for task t.During the execution of t, if a client c i is assigned with a sub-task t l (the task assignment mechanism will be introduced in Section 2.3.4), and it identifies t l requires additional expertise, c i is allowed to search for appropriate agents again and initiate a new sub-group chat g l ∈ G.This process can continue recursively for the new subtasks assigned in g l , forming a tree-like structure of group chats.Formally, we can define a function h : G → P(G) that maps a group chat to its set of sub-group chats.The nested structure can be represented as: h(g 0 ) = {g 1 , g 2 , ..., g m }, h(g i ) = {g i1 , g i2 , ..., g in }, and so on.2 .However, by decomposing a task into sub-tasks and allocating them to sub-group chats, we can reduce the total number of communication channels.Let S(g) denote the set of all subgroups (including g itself) formed for a task initially assigned to group g.The total number of communication channels can then be expressed as:
c nested = gi∈S(g) |gi|(|gi|−1) 2 ≤ c full .
Fig. 2 illustrates an example of the nested team formation process.In this example, the initial group chat g 0 spawns three sub-group chats g 1 , g 2 and g 3 for specific sub-tasks during the discussion.g 1 further creates two sub-group chats g 21 and g 22 for a more specialized sub-task.</p>
<p>AUTONOMOUS CONVERSATION FLOW CONTROL</p>
<p>Effective communication is crucial for successful collaboration among autonomous agents.Inspired by Speech Act Theory (Austin, 1975;Searle, 1969) and its applications in multi-agent systems (Finin et al., 1994;Labrou et al., 1999), we introduce an autonomous conversation flow control mechanism in IoA.This mechanism enables agents to coordinate their communication and maintain a structured dialogue, enhancing the efficiency and effectiveness of their collaboration.</p>
<p>Sequential Speaking Mechanism: To manage potential conflicts and ensure clear communication, IoA adopts the most basic sequential speaking mechanism.At any given time, only one agent is permitted to speak, preventing confusion and maintaining a clear order of communication.This approach, while simple, provides a foundation for more sophisticated conversation management when combined with the following dynamic features.</p>
<p>Finite State Machine for Group Chat States: We formalize the conversation flow as a finite state machine M = (S, Σ, δ, s 0 , F ), where:</p>
<p>• S = {s d , s s , s a , s p , s c } is the set of states representing discussion, synchronous task assignment, asynchronous task assignment, pause &amp; trigger, and conclusion, respectively.• Σ is the state transition decision space.</p>
<p>• δ : S × Σ → S is the transition function mapping the current state and the transition decision made by LLMs to the next state.• s 0 = s d is the initial state, representing the start of the conversation in the discussion phase.</p>
<p>• F = {s c } is the set of final states, containing only the conclusion state.These states align with speech acts in Speech Act Theory, such as assertives (discussion), directives (task assignment), commissives (pause &amp; trigger), and declarations (conclusion) (Searle, 1976).</p>
<p>Autonomous State Transitions and Next Speaker Selection: Recent studies have demonstrated the efficacy of LLMs in autonomously managing state transitions within predefined state spaces (Liu &amp; Shuai, 2023;Wu et al., 2024a), with state machines often enhancing overall system performance (Li et al., 2024).In IoA, the LLM within each client is tasked with determining state transitions and selecting the subsequent speaker.Let M t be the set of messages exchanged up to time step t.We define the decision function of the LLM as: f LLM : M t × S → S × C, where S is the set of states and C is the set of clients.The next state s t+1 and the next speaker c t+1 are determined as: (s t+1 , c t+1 ) = f LLM (M t , s t ).This decision-making process considers factors such as the completion of assigned tasks, the need for further discussion, and the overall goals of the collaboration.The autonomous selection of the next speaker ensures that the most relevant agents are involved at appropriate times, promoting efficient information exchange and problem-solving.</p>
<p>By implementing this autonomous conversation flow control mechanism, IoA enables structured and efficient communication among agents.This approach allows for dynamic adaptation to the needs of the collaboration, facilitating more effective problem-solving and decision-making in complex multi-agent scenarios.</p>
<p>TASK ASSIGNMENT AND EXECUTION</p>
<p>The task assignment and execution mechanism in IoA is designed to efficiently distribute work among agents and manage the execution of both simple and complex tasks.This mechanism works in concert with the team formation and conversation flow control mechanisms to ensure effective collaboration and task completion.</p>
<p>Task Representation: In IoA, a task t ∈ T is represented as a tuple (d t , S t ), where d t is the task description and S t = {s 1 , s 2 , ..., s n } is the set of sub-tasks that t can be decomposed into.Initially, S t may be empty, with sub-tasks being identified dynamically during the collaboration process.</p>
<p>Task Allocation: Task allocation in IoA occurs within the context of group chats and is closely tied to the conversation flow control mechanism.There are two types of task allocation:</p>
<ol>
<li>Synchronous Task Allocation: When the group chat enters the synchronous task assignment state s s , tasks are allocated to specific agents, and the group chat is paused until the tasks are completed.2. Asynchronous Task Allocation: In the asynchronous task assignment state s a , tasks are allocated without interrupting the ongoing discussion.This allows for parallel execution of tasks.</li>
</ol>
<p>Formally, we can define a task allocation function α : T × G → P(C), which maps a task and a group chat to a subset of clients responsible for executing the task.</p>
<p>Task Execution: Once a task is allocated, the responsible agent(s) begin execution.The execution process depends on the nature of the task and the capabilities of the agent.For integrated third-party agents, task execution is handled through the Agent Integration Block in the client's Foundation Layer.This block provides a standardized interface for task execution, typically in the form: run : String → TaskID, where the input is the task description, and the output is a unique identifier for the task.Advanced features such as execution interruption could also be implemented in this stage.</p>
<p>Upon completion of a task or sub-task, the responsible agent(s) report back to the group chat.In the case of synchronous tasks, this triggers the resumption of the group chat.For asynchronous tasks, the completion is noted, and any relevant information is shared with the group.</p>
<p>The pause &amp; trigger state s p in the conversation flow control mechanism plays a crucial role in managing the completion of multiple asynchronous tasks.It allows the group chat to wait for the completion of specified asynchronous tasks before proceeding, ensuring that all necessary information is available for subsequent stages of the collaboration.</p>
<p>COMPREHENSIVE MESSAGE PROTOCOL DESIGN</p>
<p>The effectiveness of the autonomous nested team formation and conversation flow control mechanisms in IoA relies on a comprehensive message protocol.This protocol enables seamless communication and collaboration among agents by encapsulating all necessary information required for various mechanisms to function properly.</p>
<p>Protocol Overview and Key Fields The agent message protocol in IoA is designed for extensibility and flexibility, facilitating effective multi-agent collaboration.The protocol consists of two main components: a header and a payload.</p>
<p>The header contains essential metadata about the message, ensuring correct addressing and processing by receiving agents.Key fields in the header include:</p>
<p>• sender: The unique identifier of the agent sending the message.</p>
<p>• group id: The identifier of the group chat to which the message belongs.</p>
<p>The payload carries the main content of the message, varying by message type.It can include:</p>
<p>• message type: Indicates the purpose of the message (e.g., discussion, task assignment, pause &amp; trigger).• next speaker: The identifier(s) of the agent(s) expected to respond.This structure contains other fields to support the diverse functionalities of IoA effectively.A detailed explanation and example of the message protocol can be found in Appendix A.1.</p>
<p>Work in progress
T y A t u g n 1 n F N M v f K 4 n b v p i Z c v 2 C V 7 A r x I n B k p o B m q X n 7 k d k I a B 0 w C F U T r l m N H 0 E 6 I A k 4 F S 3 N u r F l E 6 I D 0 W M t Q S Q K m 2 8 n k s B Q f G 6 W D u 6 E y J Q F P 1 N 8 b C Q m 0 H g a + m Q w I 9 P W 8 N x b / 8 1 o x d G / a C Z d R D E z S 6 U P d W G A I 8 T g l 3 O G K U R B D Q w h V 3 P w V m 0 Q U o W C y z J k Q n P m T F 0 m 9 X H K u S p f 3 F 4 X K 0 S y O L D p A h 6 i I H H S N K u g O V V E N U f S M X t E 7 +
r B e r D f r 0 / q a j m a s 2 c 4 + + g N r 9 A M U b J + h &lt; / l a t e x i t &gt; launch group chat({c1, c2, c3})</p>
<p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " X G 0  To ensure seamless communication and coordination, both the client and server components of IoA implement the message protocol.When a client sends a message, it encodes it according to the protocol and transmits it to the server.The server parses the message, extracts relevant information from the header, and routes it to the appropriate group chat based on the group id.Upon receiving a message, the client decodes it and processes it accordingly.This consistent implementation ensures that all agents can understand and respond to messages correctly, regardless of their roles or tasks, maintaining a coherent and efficient collaboration process.
B P A l i n M q L h H K z c 2 a j / L Y Q 9 E 0 = " &gt; A A A C I X i c b V D L S s N A F J 3 4 r P V V d e l m s A o V p C T i o 0 v B j c s K 1 g p N K Z P p b T t 0 M g k z N 2 I J + R U 3 / o o b F 4 q 4 E 3 / G a c z C 1 4 G B w z n 3 3 O G e I J b C o O u + O z O z c / M L i 6 W l 8 v L K 6 t p 6 Z W P z 2 k S J 5 t D i k Y z 0 T c A M S K G g h Q I l 3 M Q a W B h I a A f j 8 6 n f v g V t R K S u c B J D N 2 R D J Q a C M 7 R S r 9 L w E e 4 Q M T X A N B / 5 P S 4 F K M x q f p o 7 a Z P F o G l b C x R q m B 1 Q v x + h 8 b P 9 X q X q 1 t 0 c 9 C / x C l I l B Z q 9 y p u N 8 i S 0 2 7 l k x n Q 8 N 8 Z u y j Q K L i E r + 4 m B m P E x G 0 L H U s V C M N 0 0 v z C j e 1 b p 0 0 G k 7 V N I c / V 7 I m W h M Z M w s J M h w 5 H 5 7 U 3 F / 7 x O g o N G N x U q T h A U / / p o k E i K E Z 3 W R f t C A 0 c 5 s Y T x a Q m c 8 h H T j K M t t W x L 8 H 6 f / J d cS U v K X o B s H H G c T T k W k W U e Y j i O o = " &gt; A A A C F 3 i c b V D L S g M x F M 3 U V 6 2 v q k s 3 w a J U k D I j v p Y F R V x W s A / o l J J J b 9 v Q z I P k j l i G + Q s 3 / o o b F 4 q 4 1 Z 1 / Y / p Y a P V A 4 H D O P U n u 8 S I p N N r 2 l 5 W Z m 1 9 Y X M o u 5 1 Z W 1 9 Y 3 8 p t b N R 3 G i k O V h z J U D Y 9 p k C K A K g q U 0 I g U M N + T U P c G F y O / f g d K i z C 4 x W E E L Z / 1 A t E V n K G R 2 v m S i 3 C P i I k G p n j f b X M p I M C 0 6 C Z j J 6 l c X q W H 1 O 2 E q N 3 0 o J 0 v 2 C V 7 D P q X O F N S I F N U 2 v l P E + W x b + 7 k k m n d d O w I W w l T K L i E N O f G G i L G B 6 w H T U M D 5 o N u J e O 9 U r p n l A 7 t h s q c A O l Y / Z l I m K / 1 0 P f M p M + w r 2 e 9 k f i f 1 4 y x e 9 5 K R B D F C A G f P N S N J c W Q j k q i H a G A o x w a w r g S 5 q + U 9 5 l i H E 2 V O V O C M 7 v y X 1 I 7 K j m n p Z O b 4 0 J 5 f 1 p H l u y Q X V I k D j k j Z X J N K q R K O H k g T + S F v F q P 1 r P 1 Z r 1 P R j P W N L N N f s H 6 + A Y l b K B s &lt; / l a t e x i t &gt; search client({PDF, . . . }) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 1 j e 1 V + J e m p d F v 3 b c T 7 t K L 0 c c l Y U = " &gt; A A A C B n i c b V D L S s N A F J 3 U V 6 2 v q E s R B o v i Q k p S n 8 u C G 5 c V 7 A O a E C a T a T t 0 8 n D m R i i h K z f + i h s X i r j 1 G 9 z 5 N 0 7 b L L T 1 w M D h n H u 4 c 4 + f C K 7 A s r 6 N w s L i 0 v J K c b W 0 t r 6 x u W V u 7 z R V n E r K G j Q W s W z 7 R D H B I 9 Y A D o K 1 E 8 l I 6 A v W 8 g f X Y 7 / 1 w K T i c X Q H w 4 S 5 I e l F v M s p A S 1 5 5 r 6 T U a / q 3 K c k O M H U O 8 2 Z E 8 S g n J F n l q 2 K N Q G e J 3 Z O y i h H 3 T O / d J K m I Y u A C q J U x 7 Y S c D M i g V P B R i U n V S w h d E B 6 r K N p R E K m 3 G x y x g g f a i X A 3 V j q F w G e q L 8 T G Q m V G o a + n g w J 9 N W s N x b / 8 z o p d K / c j E d J C i y i 0 0 X d V G C I 8 b g T H H D J K I i h J o R K r v + K a Z 9 I Q k E 3 V 9 I l 2 L M n z 5 N m t W J f V M 5 v z 8 q 1 o 7 y O I t p D B + g Y 2 e g S 1 d A N q q M G o u g R P a N X 9 G Y 8 G S / G u / E x H S 0 Y e W Y X / Y H x + Q P o 3 5 g Q &lt; / l a t e x i t &gt; {c2 , c3 , . . . } &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 3 i n Q y J l 1 W u K s 5 E + x 1 s k P H M o K p e A = " &gt; A A A B / H i c b V D L S s N A F J 3 U V 6 2 v a J d u B o v i Q k o i W l 0 W 3 L i s Y B / Q h D C Z T N u h k 4 c z N 0 I I 9 V f c u F D E r R / i z r 9 x 2 m a h r Q c G D u f c w 7 1 z / E R w B Z b 1 b Z R W V t f W N 8 q b l a 3 t n d 0 9 c / + g o + J U U t a m s Y h l z y e K C R 6 x N n A Q r J d I R k J f s K 4 / v p n 6 3 U c m F Y + j e 8 g S 5 o Z k G P E B p w S 0 5 J l V J 6 d e w 3 l I S X C G n S A G 5 U w 8 s 2 b V r R n w M r E L U k M F W p 7 5 p Z M 0 D V k E V B C l + r a V g J s T C Z w K N q k 4 q W I J o W M y Z H 1 N I x I y 5 e a z 4 y f 4 W C s B H s R S v w j w T P 2 d y E m o V B b 6 e j I k M F K L 3 l T 8 z + u n M L h 2 c x 4 l K b C I z h c N U o E h x t M m c M A l o y A y T Q i V X N + K 6 Y h I Q k H 3 V d E l 2 I t f X i a d 8 7 r d q F / e X d S a J 0 U d Z X S I j t A p s t E V a q J b 1 E J t R F G G n t E r e j O e j B f j 3 f i Y j 5 a M I l N F f 2 B 8 / g A x i Z R o &lt; / l a t e x i t &gt; {c6 , . . . } &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H F T S j 7 n O 6 y z 1 X n G m f I 6 R H s t l Z e M = " &gt; A A A C E 3 i c b V D L S g N B E J y N r x h f q x 6 9 D E Y h i o T d o N F j w I v H C O Y B 2 b D M T i b J k N n Z Z a Z X D E v + w Y u / 4 s W D I l 6 9 e P N v n D w O m l j Q U F R 1 0 9 0 V x I J r c J x v K 7 O 0 v L K 6 l l 3 P b W x u b e / Y u 3 t 1 H S W K s h q N R K S a A d F M c M l q w E G w Z q w Y C Q P B G s H g e u w 3 7 p n S P J J 3 M I x Z O y Q 9 y b u c E j C S b 5 9 6 w B 4 A I B U k k b T v + T 0 V J b H n 0 z 6 B U c F L q V 8 6 w 9 Q v e 6 M T 3 8 4 7 R W c C v E j c G c m j G a q + / e V 1 I p q E T A I V R O u W 6 8 T Q T o k C T g U b 5 b x E s 5 j Q A e m x l q G S h E y 3 0 8 l P I 3 x s l A 7 u R s q U B D x R f 0 + k J N R 6 G A a m M y T Q 1 / P e W P z P a y X Q v W q n X M Y J M E m n i 7 q J w B D h c U C 4 w x W j I I a G E K q 4 u R W b M B S h Y G L M m R D c + Z c X S b 1 U d M v F i 9 v z f O V o F k c W H a B D V E A u u k Q V d I O q q I Y o e k T P 6 B W 9 W U / W i / V u f U x b M 9 Z s Z h /</p>
<p>PUTTING IT ALL TOGETHER: A WALKTHROUGH OF IOA IN ACTION</p>
<p>To illustrate the integrated functionality of IoA, in Fig. 4, we present an example walkthrough of the system with an illustrative complex task: writing a research paper on the Internet of Agents.Initially, client c 1 , an AI research specialist trained additionally on AI academic paper, engages the Team Formation Block, utilizing the search client function with a list of keywords {Internet, Multi-Agent System Specialist, Paper Writing, LLM Expert}.The server returns a set of matched clients {c 2 , c 3 , c 4 , c 5 }, from which c 1 forms group g 0 with members {c 1 , c 2 , c 3 } via launch group chat, where c 2 has access to scholarly databases and c 3 specializes in academic writing.</p>
<p>Upon the formation of group chat g 0 , all clients transition to the Communication Block for g 0 , where the autonomous conversation flow control mechanism, implemented as a finite state machine, guides the collaboration.The process begins with brainstorming in the discussion state (s d ), progressing to task assignment states (s s , s a ) where agents are allocated specific responsibilities.For instance, c 2 is tasked with conducting a literature review using its access to scholarly resources.The nested team formation mechanism is demonstrated when c 2 identifies a need for specialized PDF expertise.This prompts c 2 to initiate a sub-group formation process, resulting in the creation of sub-group g 1 with a new agent c 6 , a PDF expert.Throughout the process, the conversation alternates between discussion (s d ) and asynchronous task assignment (s a ) states, facilitating parallel work on assigned tasks.The message protocol ensures efficient communication, enabling the exchange of ideas, citations, and draft segments across the nested group structure.</p>
<p>In the final integration phase, the group enters a synchronous task assignment state (s s ) for collaborative editing and refinement, demonstrating IoA's capacity for coordinating intensive, real-time collaboration among multiple agents.The process concludes with a transition to the conclusion state (s c ), where a final review is conducted and the paper is prepared for submission.</p>
<p>EXPERIMENTS</p>
<p>To demonstrate the effectiveness and versatility of IoA in integrating heterogeneous agents, we conduct comprehensive experiments across a diverse set of tasks.These experiments are designed to showcase different aspects of agent heterogeneity: tool variability (Section 3.1), architectural diversity (Section 3.2), disparate observation and action spaces (Section 3.3), and varied knowledge bases (Section 3.4).Our objective is twofold: first, to illustrate IoA's proficiency in facilitating collaboration among heterogeneous agents, and second, to highlight its adaptability across various problem domains.In this section, we present our experimental results and offer comparative analyses between IoA and state-of-the-art (SoTA) approaches for each task category.The prompts within IoA are kept the same across different tasks, and are not specifically tuned for a certain task.3</p>
<p>HETEROGENEOUS TOOLS: GAIA BENCHMARK</p>
<p>To evaluate IoA's capability in integrating agents with heterogeneous tools, we employ the GAIA benchmark (Mialon et al., 2023).This benchmark comprises a diverse set of real-world questions designed to assess an agent system's proficiency in solving complex tasks through the synergistic application of multiple skills, including natural language understanding, reasoning, and external knowledge integration.The benchmark's three-tiered difficulty structure provides a robust testbed for evaluating the capability of agent systems.</p>
<p>Experimental Setups: We instantiate IoA with four basic ReAct agents (Yao et al., 2023), each equipped with a distinct tool: a web browser, a code interpreter, a Wikidata searcher, and a YouTube video transcript downloader.This configuration allows us to assess IoA's ability to orchestrate collaboration among agents with heterogeneous tools.We benchmark IoA against several SoTA agent systems, evaluating performance across all three difficulty levels of GAIA, as well as overall performance.Detailed implementation specifics are provided in Appendix A.4.1.</p>
<p>Results and Analysis:</p>
<p>The experimental results, presented in Table 1, demonstrate IoA's superior performance across the GAIA benchmark.Despite utilizing only basic ReAct agents, IoA achieves the highest overall performance, surpassing all other approaches.Notably, IoA exhibits exceptional performance in the more challenging Level 2 and Level 3 tasks, which demand advanced reasoning and intricate collaboration.This performance underscores the efficacy of IoA's communication mechanisms and its capacity to facilitate seamless inter-agent collaboration.</p>
<p>In comparison to AutoGen, IoA demonstrates superior performance in two out of three difficulty levels.This superiority can be attributed to IoA's collaboration mechanisms and the flexibility of integrating agents with different tools, while in AutoGen, only one agent utilizes different tools, and other agents act as feedback providers.The mechanisms implemented in IoA enable adaptive team composition and efficient sub-task execution, culminating in enhanced performance on complex, multi-faceted problems.</p>
<p>The results from the GAIA benchmark underscore IoA's potential as a powerful orchestrator for diverse agents in solving real-world, multi-step problems.By providing a flexible and efficient platform for agent collaboration, IoA enables even basic agents to achieve SoTA performance, outper-  forming more sophisticated standalone agents.This outcome highlights the critical role of effective communication and coordination in multi-agent systems and validates the architectural and design choices underpinning IoA.</p>
<p>HETEROGENEOUS ARCHITECTURE: OPEN-ENDED INSTRUCTION BENCHMARK</p>
<p>To evaluate IoA's capability in integrating and orchestrating agents with heterogeneous architectures, we develop a comprehensive benchmark comprising 153 open-ended instructions with selfinstruct (Wang et al., 2023e).This benchmark spans four diverse categories: search &amp; report, coding, mathematics, and life assistance.Unlike the GAIA benchmark, which primarily focuses on question-answering tasks with deterministic answers, our curated benchmark incorporates a higher proportion of non-QA tasks requiring generative responses.This design choice aims to better reflect the diverse nature of real-world challenges that agent systems are expected to address.The curation process is elaborated at Appendix A.4.2.</p>
<p>Experimental Setups: In this experimental setup, we integrate two SoTA third-party agents with distinct architectures: AutoGPT (Significant Gravitas, 2023) and Open Interpreter (Open Interpreter, 2023), into the IoA ecosystem.The integration process, detailed in Appendix A.4.2, demonstrates IoA's versatility in accommodating agents with divergent internal structures and operational paradigms.This configuration allows us to assess IoA's efficacy in facilitating collaboration among independently developed agents with heterogeneous architectures.</p>
<p>For evaluation, we employ GPT-4-1106-preview as an impartial judge, a choice supported by previous research demonstrating high agreement between GPT models and human evaluators in assessing response quality (Chiang et al., 2023;Zheng et al., 2023a;Chan et al., 2023).To mitigate potential order-induced biases, we implement a robust evaluation approach following Zheng et al. (2023a), where the order of responses is alternated in the prompt.A "win" is only declared when one competitor is consistently judged superior across both orderings.</p>
<p>Results and Analysis:</p>
<p>The experimental results, illustrated in Fig. 5, demonstrate IoA's significant performance advantages when orchestrating the collaboration between AutoGPT and Open Interpreter.IoA consistently outperforms both individual agents across all four task categories.Overall, IoA achieves a remarkable win rate of 76.5% against AutoGPT and 63.4% against Open Interpreter.These results underscore IoA's proficiency in efficiently gathering and synthesizing information, as well as its effectiveness in facilitating collaborative problem-solving across diverse domains.</p>
<p>The demonstrated capability of IoA to seamlessly integrate and orchestrate agents with heterogeneous architectures enables the harness of the strengths of diverse, independently developed agents, making it possible to create more versatile and capable agent systems.As the landscape of specialized AI agents continues to expand, IoA's potential to integrate and facilitate collaboration among these diverse entities positions it as a promising platform for the development of increasingly sophisticated and adaptive agent systems.To evaluate IoA's efficacy in orchestrating agents with heterogeneous observation and action spaces, we conduct experiments in the domain of embodied AI.This domain presents unique challenges, requiring agents to perceive, understand, and interact with their physical environment.We utilize RoCoBench (Mandi et al., 2023), a state-of-the-art benchmark designed to assess the collaboration and communication capabilities of embodied agents.RoCoBench comprises six collaborative tasks, each mandating two or three agents with partial, often distinct action space or observations of the environment to cooperate towards a common objective.</p>
<p>Experimental Setups: We benchmark IoA against two baselines established by Mandi et al. (2023):</p>
<p>(1) Central Plan, a centralized agent has complete environmental information and control over all embodied agents, and (2) Roco Dialog, a specialized multi-agent framework designed for this task, enabling agent communication and decision-making.</p>
<p>Given that RoCoBench requires agents to output action plans in a specific format rather than interact with tools, we adapt IoA to this scenario without integrating external agents.Instead, we provide environmental observations to two IoA clients and extract their action plans from their discussion.This setup allows us to evaluate IoA's ability to manage agents with heterogeneous observation and action spaces.Detailed implementation specifics are available in Appendix A.4.3.To ensure a fair comparison, we conduct 10 runs for both IoA and Roco Dialog for each task, reporting average success rates and steps taken.Results for Central Plan are sourced directly from Mandi et al. (2023).</p>
<p>Note that the Pack Grocery task is omitted due to implementation errors in the benchmark release.</p>
<p>Results and Analysis: Table 2 presents the average success rates and steps required for task completion.Remarkably, despite not being specifically optimized for embodied tasks, IoA outperforms Roco Dialog, a framework tailored for this benchmark, in four out of five tasks in terms of success rate.IoA achieves perfect scores on the Cabinet, Sandwich, and Sort tasks, demonstrating the robustness of its communication and collaboration mechanisms in enabling embodied agents with heterogeneous observation and action spaces to work synergistically towards common goals.Even more impressive is IoA's performance relative to the Central Plan baseline, which benefits from full environmental observability.IoA's success rates are superior or comparable to Central Plan across tasks, although it generally requires slightly more decision steps for task completion.Given that IoA is a general multi-agent framework not specifically designed for embodied AI tasks, the marginal increase in step count is a reasonable trade-off for its versatility and effectiveness.</p>
<p>The success of IoA in this embodied AI scenario highlights its versatility and effectiveness.It suggests that the principles underlying IoA, e.g., autonomous conversation flow control, are fundamentally generalizable, indicating IoA's potential applicability in a wide range of real-world scenarios where agents must collaborate despite having different perspectives or capabilities.</p>
<p>HETEROGENEOUS KNOWLEDGE: RETRIEVAL-AUGMENTED GENERATION</p>
<p>To evaluate IoA's efficacy in orchestrating agents with heterogeneous knowledge, we conduct experiments on retrieval-augmented generation (RAG) tasks (Lewis et al., 2021).RAG tasks present a unique challenge where agents must retrieve relevant information from diverse sources and collaborate to synthesize accurate responses, making them an ideal testbed for assessing IoA's ability to manage knowledge heterogeneity and facilitate effective inter-agent communication.Experimental Setups: We implement IoA with GPT-3.5-turbo-0125 as the core language model, following Apollo's Oracle (Wang et al., 2023b).To evaluate knowledge heterogeneity and its impact, we design three scenarios: 1) Heterogeneous Knowledge: Two clients access different evidence pools (Wikipedia/Google), testing IoA's ability to manage knowledge heterogeneity.2) Homogeneous Knowledge (2 Agents): Two clients access both pools, serving as a control to isolate heterogeneity effects.3) Homogeneous Knowledge (3 Agents): Three clients access both pools, assessing scalability and knowledge redundancy trade-offs.</p>
<p>This design allows us to disentangle the effects of knowledge heterogeneity from agent count and knowledge redundancy.We evaluate across four datasets: TriviaQA (Joshi et al., 2017), Natural Questions (NQ) (Kwiatkowski et al., 2019), HotpotQA (Yang et al., 2018), and 2WikiMultiHopQA (2WMHQA) (Ho et al., 2020), using 250 randomly sampled question-answer pairs from each.Implementation details are in Appendix A.4.4.</p>
<p>Results and Analysis: Table 3 demonstrates IoA's remarkable performance across all datasets, often surpassing or matching GPT-4 despite being based on GPT-3.5.On two out of four tasks, IoA's heterogeneous knowledge scenario outperforms homogeneous Apollo's Oracle, showcasing IoA's effectiveness in managing knowledge diversity.This configuration achieves the best performance on NQ and competitive results on other datasets, often outperforming single-model approaches and specialized frameworks like Apollo's Oracle.This underscores IoA's efficacy in facilitating information exchange and synthesis from heterogeneous sources, effectively compensating for individual agents' knowledge gaps.</p>
<p>We also conduct experiments in homogeneous settings.IoA with 3 agents achieves the best overall performance, outperforming all baselines on TriviaQA and showing competitive results on other datasets.Interestingly, the 2-agent homogeneous configuration outperforms the 3-agent setup on HotpotQA and 2WikiMultiHopQA, suggesting that optimal agent configuration may be taskdependent.These results not only validate IoA's effectiveness in RAG tasks but also highlight its potential as a versatile platform for managing both heterogeneous and homogeneous knowledge in multi-agent systems.</p>
<p>ANALYSIS</p>
<p>TEAM FORMATION PRECISION</p>
<p>To evaluate the precision of IoA's autonomous team formation mechanism, we developed a benchmark using GPT-4, comprising 625 diverse tasks paired with 1500 dummy agent profiles.This simulated environment allows us to assess the accuracy of both regular and nested team formation in a large-scale setting.Detailed data construction processes are available in Appendix C.</p>
<p>Experimental Design: We evaluate two distinct scenarios: regular team formation and nested team formation.For regular team formation, each task is associated with 2 or more suitable agent profiles generated by GPT.For nested team formation, we generate a subtask for each original task that can or cannot be completed by the initially formed team, if not, an additional agent profile capable of addressing this subtask is generated.We evaluate whether the team can correctly decide when to enter the nested team formation stage, and evaluate the precision of the nested team formation.</p>
<p>We assess both settings using four metrics: Top@1 and Top@10 recall rates, Mean Rank (MR), and Mean Reciprocal Rank (MRR).Top@1 measures exact matches, while Top@10 accounts for semantic similarity, considering an agent as recalled if a recruited agent is among the top 10 most similar to a labeled agent.MR and MRR provide insights into the ranking quality of retrieved agents.Results and Analysis: Table 4 presents the performance of both team formation mechanisms, each evaluated on its own specific dataset and setting.In the regular team formation scenario, which assesses the ability to form initial teams for given tasks, we observe a Top@1 recall of 41.4% and a Top@10 recall of 64.9%.This indicates that the mechanism can exactly match the labeled agents 41.4% of the time, and when considering semantic similarity, the retrieved agent fall into the top 10 similar agents to the labeled agent for 64.9% of the time.The Mean Rank (MR) of 27.4 and Mean Reciprocal Rank (MRR) of 50.1% suggest that, on average, relevant agents are ranked within the top 30 results, with a tendency towards high ranking.</p>
<p>For the nested team formation scenario, which evaluates the mechanism's performance in a setting where subtasks may emerge requiring additional expertise, we see a Top@1 recall of 59.7% and a Top@10 recall of 81.8%.The MR of 10.6 and MRR of 66.5% indicate that relevant agents are typically found within the top 11 results, with a strong tendency towards very high rankings.These metrics suggest effective performance in this more dynamic setting.</p>
<p>These results demonstrate IoA's capability to form precise teams in both initial task allocation and in scenarios where task requirements may evolve.The high recall rates, especially with similarity matching (Top@10), are crucial for addressing complex tasks that require diverse or specialized skills.</p>
<p>COST AND SUB-OPTIMAL COMMUNICATION PATTERN ANALYSIS</p>
<p>To evaluate the economic feasibility and potential for optimization of the IoA, we conduct a cost analysis on the open-ended instruction benchmark (Section 3.2), where AutoGPT and Open Interpreter are integrated.We compare the average cost per task for these agents when operating individually and when integrated into the IoA.As shown in Table 5, when integrated into IoA, the costs of both agents are decreased due to the task decomposition for each task.However, the IoA introduces an additional communication cost of $0.53 per task, resulting in an overall cost of $0.99.</p>
<p>During our analysis, we observed unexpected and suboptimal communication patterns that contributed to the high communication cost.One notable pattern was the repetition of information, where the LLMs in the clients would repeat or rephrase previous chats from themselves or others, leading to a stagnation in progress.This phenomenon was particularly prevalent after several asynchronous task assignments.Although each task assignment did not require immediate waiting, as the conversation progressed, new decisions had to be made based on the conclusions from previously assigned and not yet completed asynchronous tasks.Despite providing the client LLMs with the option to switch the group chat state to pause &amp; trigger, they sometimes fail to switch, as illustrated in Fig. 6.This drawback in LLM is also observed in other multi-agent work (Li et al., 2023;Mandi et al., 2023).</p>
<p>Given the current situation, we need to reassess our strategy for achieving the goal.To quantify the impact of this suboptimal communication pattern, we manually removed the repetitions and recalculated the token numbers and corresponding costs.Surprisingly, this resulted in a nearly 50% reduction in communication costs, as shown in the "Dedup."rows of Table 5.This finding aligns with observations from other multi-agent communication frameworks, suggesting that while modern LLMs are well-aligned to be effective chatbot assistants, they may not be optimally aligned to be efficient communicating agents.Agents should not only complete the given tasks accurately but also communicate effectively with others, understanding conversation states and making proper decisions.This insight raises new research questions regarding the agent alignment of LLMs and highlights the need for further investigation in this area.</p>
<p>Despite the current cost overhead and suboptimal communication patterns, the IoA demonstrates significant potential for enabling effective collaboration among heterogeneous agents.By addressing these challenges through prompt optimization, protocol refinement, and the development of more sophisticated frameworks under the concept of IoA, we believe that the cost of communication can be significantly reduced.As research progresses, IoA and similar approaches will become increasingly attractive and economically viable solutions for complex multi-agent systems.</p>
<p>RELATED WORK</p>
<p>LLM-based Agents Recent advancements in LLMs, such as GPT (OpenAI, 2023), Claude (Anthropic, 2024) and Gemini (Reid et al., 2024), have led to the development of highly capable AI agents, which can engage in natural language interactions and perform a wide range of tasks.To enhance the capabilities of LLM-based agents, researchers have explored the integration of external tools and knowledge sources (Nakano et al., 2021;Yao et al., 2023;Schick et al., 2023;Shen et al., 2023), enabling agents to access and utilize relevant information beyond their pre-trained knowledge.The various agents have demonstrated significant progress in a wide range of domains, including operating system interactions, software engineering, and general AI applications.For instance, OS-Copilot facilitates generalist interactions across web browsers and code terminals (Wu et al., 2024b), while OpenDevin focuses on autonomous software development tasks such as coding and debugging (OpenDevin Team, 2024).Other notable developments include XAgent for complex task solving (Team, 2023) and Voyager (Wang et al., 2023a), an open-ended embodied agent leveraging LLMs for Minecraft game-playing.These advancements have laid the foundation for more sophisticated and versatile LLM-based agents, capable of autonomous task execution and continuous learning.</p>
<p>LLM-based Multi-Agent Systems Building upon the success of individual LLM-based agents, researchers have begun to explore the potential of multi-agent systems composed of these agents.</p>
<p>Early works demonstrated the feasibility of using LLMs to simulate multi-agent interactions and emergent behaviors (Park et al., 2023).Since then, various approaches have been proposed to enable effective collaboration and communication among LLM-based agents.Frameworks such as AgentVerse (Chen et al., 2023) and AutoGen (Wu et al., 2023) provide the necessary infrastructure for agent collaboration.In software development, multi-agent systems like ChatDev (Qian et al., 2023a), MetaGPT (Hong et al., 2023) have shown promising results in automating coding, testing, and debugging processes.Despite these advancements, significant limitations remain, such as the lack of support for integrating diverse third-party agents, the inability to support distributed multiagent systems, and the reliance on hard-coded communication protocols and state transitions.IoA aims to address these limitations and provide a more flexible and scalable platform for LLM-based multi-agent collaboration, paving the way for more advanced and practical systems that can tackle complex real-world problems effectively.</p>
<p>CONCLUSION</p>
<p>In this paper, we introduced IoA, a novel framework for LLM-based multi-agent collaboration inspired by the concept of the Internet.IoA addresses the limitations of existing multi-agent frameworks by providing a flexible and scalable platform for integrating diverse third-party agents, enabling distributed multi-agent collaboration, and introducing dynamic mechanisms for agent teaming and conversation flow control.Through extensive experiments on various benchmarks, we demonstrated the effectiveness of IoA in facilitating efficient collaboration among heterogeneous agents, consistently outperforming state-of-the-art baselines.As the field of LLM-based agents continues to advance, we believe that IoA will serve as a foundation for future research and development in multi-agent collaboration.By enabling the integration of diverse agents with specialized skills and knowledge, our framework opens up new possibilities for leveraging existing agents that were developed independently.We hope that our work will inspire further research in this promising direction and contribute to the development of more advanced and impactful multi-agent systems.To support the functionalities of IoA introduced in Section 2.4, we have designed a comprehensive agent message protocol that facilitates efficient communication and coordination among agents.The protocol, as illustrated in Fig. 7, consists of several fields that cater to the specific requirements of various mechanisms within the framework.</p>
<p>Firstly, the protocol includes the following header for all message types:</p>
<p>• sender (str): The name or unique identifier of the agent sending the message.• state (enum): The current state of the group chat associated with the message, which can be either team formation or communication.• comm id (str): The unique identifier of the group chat to which the message belongs.</p>
<p>To support the autonomous team formation mechanism, the protocol incorporates the following fields:</p>
<p>• goal (str): The objective or task that the current group chat aims to accomplish.</p>
<p>• team members (list[str]): The names or unique identifiers of the agents required for the current group chat.• team up depth (int): The depth of the current nested team formation, used to determine if the maximum allowed depth has been reached.• max turns (int): The maximum number of discussion turns allowed for the current group chat.</p>
<p>If exceeded, the group chat will be forced into the conclusion phase.</p>
<p>For facilitating the discussion phase, the protocol includes the following fields:</p>
<p>• content (str): The actual content of the current message.</p>
<p>• type (enum): Specifies the next dialogue state, which can be discussion, task assignment, or conclusion.• next speaker (list[str]): The name(s) or unique identifier(s) of the agent(s) expected to speak next.In the discussion state, next speaker is limited to a single agent, while in the task assignment state, it can include multiple agents, indicating that the current message contains multiple task assignments.</p>
<p>To support the task assignment mechanism, the protocol incorporates the following fields:</p>
<p>• task id (str): The automatically generated unique identifier for the current task.</p>
<p>• task desc (str): The description of the task assigned to the client, extracted from the chat.</p>
<p>• task conclusion (str): The conclusion or result provided by the client after completing the assigned task.• task abstract (str): A concise summary of the completed task.</p>
<p>Lastly, to support the pause &amp; trigger mechanism, the protocol includes the following field:</p>
<p>• triggers (list[str]): A list of task IDs that require a trigger to be set.</p>
<p>By adhering to this comprehensive agent message protocol for sending and receiving messages, clients within IoA can effectively achieve autonomous team formation and conversation flow control.The protocol ensures that all necessary information is communicated among agents, enabling seamless collaboration and coordination in various task scenarios.</p>
<p>A.2 CLIENT</p>
<p>The client component of IoA plays a crucial role in enabling the integration and collaboration of heterogeneous agents.It consists of three layers: the Foundation Layer, the Data Layer, and the Interaction Layer.Each layer comprises several modules that work together to facilitate efficient communication, data management, and agent coordination.In this subsection, we provide a detailed overview of the implementation of each module within the client's layers.</p>
<p>A.2.1 FOUNDATION LAYER</p>
<p>Network Infrastructure Module In IoA, all clients maintain a persistent connection to the server using the WebSocket protocol, similar to an instant messaging application.When a client sends a message, it is transmitted to the server, which parses the comm id field in the message and forwards it to the other clients in the corresponding group chat via their respective WebSocket connections.The real-time nature of WebSocket ensures that messages are delivered promptly, enabling clients to receive and respond to messages without delay.</p>
<p>Data Infrastructure Module To support the data storage and retrieval requirements of the upperlevel Data Layer modules, we employ SQLite as the primary database solution.SQLite provides a lightweight and efficient means of persisting and accessing data related to agent contacts, group information, and task management.By leveraging SQLite, the client can store and retrieve information about encountered agents, group chat details, and task assignments, ensuring data consistency and availability throughout the collaboration process.</p>
<p>Agent Integration Module</p>
<p>The Agent Integration Module defines the protocol that third-party agents must adhere to in order to seamlessly integrate with IoA.Currently, the agent integration protocol in IoA requires agents to implement a function def run(task desc: str) -&gt; str, which accepts a task description as input and returns a summary of the task completion.This simple yet effective protocol allows diverse agents to be incorporated into the framework, enabling them to contribute their unique capabilities to the collaboration process.As IoA evolves, the integration protocol can be extended to support more advanced functionalities and interaction patterns.</p>
<p>A.2.2 DATA LAYER</p>
<p>Agent Contact Module The Agent Contact Module is responsible for maintaining a record of the clients that the current client has previously collaborated with.It stores information such as the names and descriptions of these clients, providing a valuable reference for future collaborations.The module aims to support the client in evaluating and storing collaboration outcomes after each task, allowing it to make informed decisions when forming teams for subsequent tasks.During the team formation process, the information stored in this module is included in the prompt to assist the client in selecting the most suitable partners based on prior experiences.</p>
<p>Group Info Module</p>
<p>The Group Info Module manages all group chat-related information, including the following fields:</p>
<p>• comm id (str): The unique identifier of the group chat.</p>
<p>• goal (str): The objective or task that the group chat aims to accomplish.</p>
<p>• team members (str): The list of agents participating in the group chat.</p>
<p>• state (str): The current state of the group chat (e.g., team formation, discussion, task assignment, conclusion).• conclusion (str -None): The final outcome or conclusion reached by the group chat.</p>
<p>• team up depth (int): The depth of the nested team formation within the group chat.</p>
<p>• max turns (int): The maximum number of communication turns allowed in the group chat.</p>
<p>By organizing and persisting this information, the Group Info Module enables clients to maintain a coherent view of the ongoing collaborations and their progress.</p>
<p>Task Management Module</p>
<p>The Task Management Module is responsible for storing and tracking the tasks assigned within each group chat.It maintains the following fields for each task:</p>
<p>• task id (str): The unique identifier of the task.</p>
<p>• task desc (str): The detailed description of the task.</p>
<p>• task abstract (str): A concise summary of the task.</p>
<p>• assignee (str): The agent assigned to complete the task.</p>
<p>• status (enum): The current status of the task (e.g., pending, in progress, completed).</p>
<p>• conclusion (str -None): The final result or outcome of the task.</p>
<p>By keeping track of task-related information, the Task Management Module enables clients to monitor the progress of assigned tasks and ensures that all task-related data is readily available for reference and decision-making purposes.</p>
<p>A.2.3 INTERACTION LAYER</p>
<p>Team Formation Module As briefly introduced in Section 2.3.2, when a client receives a task, it is equipped with two essential tools: search agent(desc: list[str]) -&gt; list[agent] and launch group chat(team members: list[str] | None) -&gt; comm id.The client must decide whether to utilize the search agent tool to find agents on the server that match the specified description, or to directly call the launch group chat tool based on the discovered agents and historical collaboration information.If the client invokes launch group chat without specifying any agents, it implies that the task will be completed by a single agent.To prevent infinite loops, IoA imposes a limit on the maximum number of tool calls, set to 10 by default.If the client reaches this limit without successfully launching a group chat, it is forced to invoke the launch group chat tool to initiate the collaboration process.</p>
<p>Communication Module</p>
<p>The Communication Module handles the core functionalities of message generation and message reception.When a client generates a message, IoA processes it according to the agent message protocol.If the message type is conclusion, the client enters the conclusion phase, where it provides a final answer to the group chat goal based on the accumulated chat records and task completion information.In the case of a pause &amp; trigger message, the framework prompts the client to generate the task IDs that require triggers and broadcasts them to all group members.For discussion or task assignment messages, they are directly broadcast to all participants in the group chat.</p>
<p>Upon receiving a message, the client parses it according to the agent message protocol.If the next speaker field does not include the current client, the message is simply added to the group chat history.However, if the client is designated as the next speaker, it must take appropriate actions based on the message type.For discussion messages, the client generates a response to continue the conversation.In the case of sync or async task assignment messages, the client extracts its assigned task from the chat record, summarizes it, and specifies the relevant information to be passed to the integrated agent.The agent then executes the task based on the summarized description and relevant chat messages, returning the result upon completion.If the message type is pause &amp; trigger, the client updates the corresponding task triggers in the Task Management Module.</p>
<p>The Communication Module, in conjunction with the other modules in the Interaction Layer and Data Layer, enables seamless and structured collaboration among agents.By adhering to the welldefined agent message protocol and leveraging the functionalities provided by the various modules, clients can effectively participate in discussions, assign tasks, and coordinate their actions to achieve the desired goals.</p>
<p>A.3 SERVER</p>
<p>The server component of IoA serves as the central hub for agent coordination, communication, and management.It comprises three layers: the Foundation Layer, the Data Layer, and the Interaction Layer.Each layer contains modules that work together to facilitate agent registration, discovery, and message routing.In this subsection, we provide a detailed description of the implementation of each module within the server's layers.</p>
<p>A.3.1 FOUNDATION LAYER</p>
<p>Network Infrastructure Module and Data Infrastructure Module The Network Infrastructure Module and Data Infrastructure Module in the server are largely similar to their counterparts in the client.However, the server's Data Infrastructure Module incorporates the use of the Milvus vector database to support the construction and maintenance of the Agent Registry.Milvus enables efficient similarity search and retrieval of agent information based on their characteristics, allowing the server to provide clients with the functionality to discover and match agents effectively.</p>
<p>Security Module While the Security Module is not extensively utilized in the current implementation of IoA, we acknowledge its crucial role in ensuring the integrity and reliability of the framework in real-world deployments.This module is responsible for verifying and controlling the integration of third-party agents into the clients, preventing malicious agents from compromising the entire framework.As IoA evolves, the Security Module will be enhanced to provide robust authentication, authorization, and monitoring mechanisms, safeguarding the collaborative environment from potential security threats.</p>
<p>A.3.2 DATA LAYER</p>
<p>Agent Registry Module The Agent Registry Module maintains a comprehensive record of all clients integrated into the server.When a client connects to the server, it is required to provide a detailed description of the integrated agent, including its name and capability description.This information is stored in the Agent Registry, enabling similarity matching based on agent characteristics.The Agent Registry serves as a central repository for agent information, facilitating agent discovery and team formation processes.</p>
<p>Session Management Module</p>
<p>The Session Management Module is responsible for managing the WebSocket connections of all online agents and keeping track of the group chats they participate in.It maintains a mapping between agents and their respective WebSocket connections, as well as the associations between agents and group chats.When a client sends a message, the Session Management Module ensures that the message is properly routed to all clients involved in the corresponding group chat, guaranteeing reliable and efficient communication within the collaborative environment.</p>
<p>A.3.3 INTERACTION LAYER</p>
<p>Agent Query Module The Agent Query Module handles incoming requests from clients seeking to discover and match agents based on specific characteristics.Upon receiving a query request, the module converts the provided characteristics into vector representations and performs similarity matching against the agents stored in the Agent Registry.The implementation of this module can vary depending on the specific requirements and scalability needs of the framework.For instance, techniques such as BM25 or other information retrieval methods can be employed to enhance the matching process and improve the relevance of the returned agent results.</p>
<p>Group Setup Module</p>
<p>The Group Setup Module is responsible for handling client requests to create new group chats.When a client submits a request to set up a group chat, specifying the desired team members, the Group Setup Module processes the request and initializes a new group chat instance.It assigns a unique comm id to the newly created group chat and notifies all participating clients about their inclusion in the chat.The Group Setup Module works in conjunction with the Session Management Module to ensure that the necessary WebSocket connections and mappings are established for efficient communication within the group chat.</p>
<p>Message Routing Module The Message Routing Module plays a critical role in facilitating communication between clients within group chats.When a client sends a message, the Message Routing Module receives the message and parses it according to the agent message protocol.Based on the comm id specified in the message, the module identifies the corresponding group chat and forwards the message to all clients associated with that chat.The Message Routing Module leverages the information maintained by the Session Management Module to ensure accurate and timely delivery of messages to the intended recipients.</p>
<p>The server component of IoA, with its carefully designed modules and interactions, provides a robust and efficient infrastructure for agent coordination, communication, and management.By leveraging the capabilities of the Foundation Layer, Data Layer, and Interaction Layer, the server enables seamless agent discovery, team formation, and message exchange, fostering a collaborative environment where diverse agents can work together to achieve common goals.</p>
<p>As IoA continues to evolve, the server component will be further enhanced to incorporate advanced features such as load balancing, fault tolerance, and scalability, ensuring that the framework can handle the growing demands of real-world multi-agent systems.Additionally, the Security Module will be strengthened to provide comprehensive security measures, safeguarding the integrity and confidentiality of agent interactions within the framework.</p>
<p>A.4 IMPLEMENTATION DETAILS OF DIFFERENT EXPERIMENTS</p>
<p>In this section, we provide an overview of the implementation details for each experiment conducted to evaluate the performance of IoA.</p>
<p>A.4.1 GAIA</p>
<p>For the GAIA benchmark, IoA integrated four ReAct agents: Web Browser, Code Executor, YouTube Transcript Downloader, and Wikidata Searcher.The tools provided to Web Browser and Code Executor agents are adapted from the AutoGen framework with minor modifications to ensure compatibility with IoA.To address the YouTube-related tasks in GAIA, we develop a YouTube video transcript downloader based on PyTube4 .For videos without readily available transcripts, the tool employs the Whisper model to transcribe spoken language into text.Similarly, we adapt the Wikidata tool from Langchain5 to fit the IoA ecosystem.These adaptations showcases a key feature of IoA: when a task requires a specific tool, it can be easily integrated into the system through its implementation and agent adaptation, enabling it to participate in task completion.</p>
<p>Due to budget constraints, we conduct performance testing on the GAIA validation set.Despite this limitation, the results provide valuable insights into the effectiveness of IoA in handling complex, multi-step tasks.You are standing in the top-left cell of the matrix in the 0th second, and you must move to any adjacent cell in the four directions: up, down, left, and right.Each move you make takes 1 second.</p>
<p>Return the minimum time required in which you can visit the bottom-right cell of the matrix.If you cannot visit the bottom-right cell, then return -1.</p>
<p>Example 1: 4,3,8,6]] Output: 7 Explanation: One of the paths that we can take is the following:
Input: grid = [[0,1,3,2],[5,1,2,5],[
-at t = 0, we are on the cell (0,0).</p>
<p>[…]</p>
<p>Constraints:</p>
<p>[…] """ After you complete the function, display the content of the script as res.py directly.</p>
<p>In a country, there are cities connected by one-way roads.It's known that from any city, there is a route (possibly passing through other cities) leading to the capital.Prove that it's possible to choose one road from each city in such a way that all chosen roads lead directly or indirectly to the capital.First, we select the instructions based on the real-world complex tasks used by XAgent (Team, 2023).These instructions were categorized into the four aforementioned groups.Second, to increase the diversity of the benchmark, we manually create an additional 10 complex tasks.Finally, we use the Self-Instruct method (Wang et al., 2023e) to generate approximately 200 instructions, using the previously selected instructions as seeds.After manual screening and modification, we obtained the additional 94 instructions, resulting in a total of 153 tasks.The benchmark eventually consists of 52 search &amp; report tasks, 30 coding tasks, 30 math tasks, and 41 life assistance tasks.By incorporating a diverse set of open-ended instructions, this benchmark allows for a comprehensive evaluation of the performance and versatility of IoA in handling a wide range of real-world scenarios.We show one example instruction for each category in Fig. 8.</p>
<p>Evaluation Methodology.For IoA, we consider the final conclusion generated by the agents as the final answer.However, since AutoGPT (Significant Gravitas, 2023) and Open Interpreter (Open Interpreter, 2023) complete tasks in multiple steps and do not inherently generate a conclusion, we prompted them to provide a detailed conclusion as the final answer after task completion.</p>
<p>Inspired by the pairwise comparison evaluation method used in MT-Bench (Zheng et al., 2023b), we employ GPT-4 to evaluate the responses of IoA against AutoGPT and Open Interpreter.To mitigate potential biases introduced by the order of the responses, we alternate the order of the two responses when presenting them to GPT-4 for evaluation.A result is counted as a win for a system only when it is consistently determined to be superior to its competitor in both orderings.In cases where the performance is inconsistent across the two orderings, the result is considered a draw.</p>
<p>A.4.3 EMBODIED AGENT TASKS</p>
<p>For the RocoBench experiments, we adhere to the original paper's methodology, which relies on discussions and parsing specific formatted strings from the discussion results to determine the embodied agent's actions, rather than using agents to call tools directly.We implement two clients that communicate without integrated agents, requiring them to output strings in the RocoBench format at the conclusion stage.These strings are then parsed and used to interact with the environment using RocoBench's predefined parsing functions.This approach serves as a validation of IoA's client implementation and communication mechanism design.</p>
<p>To accommodate the varying requirements of different tasks in RocoBench, we adopt task-specific settings.For the Sort, Sandwich, and Sweep tasks, which exhibit strong interdependencies between steps, we retained the chat history and continued each new action discussion based on the previous group chat.In contrast, for the Cabinet and Rope tasks, where the steps were less interdependent, we initiated a new group chat for each action to optimize costs.Other settings remained consistent with the Roco Dialog baseline.</p>
<p>A.4.4 RETRIEVAL-AUGMENTED GENERATION</p>
<p>For the retrieval-augmented generation (RAG) question-answering task, we follow the settings outlined in Apollo's Oracle.We provide agents with two evidence pools: one derived from Wikipedia and the other from Google.For Wikipedia, we utilize Pyserini's pre-built index of Wikipedia content up to January 20, 2021, retrieving the top 10 most relevant results for each query.For Google, we directly access the Google Search API, returning the top 5 most relevant results for each query.These tools were made available to the client-side LLMs, enabling them to query relevant information during discussions and ultimately provide well-informed answers.</p>
<p>To evaluate the performance of IoA on the RAG task, we randomly sample 500 entries from the validation or test sets of the four datasets.After the model generates answers, we employ GPT-4 for answer evaluation.Specifically, we provide GPT-4 with the dataset answers and the model's answers, requiring it to output its reasoning in a Chain of Thought (CoT) manner before providing a final correctness judgment.</p>
<p>B VISUALIZATION OF ROCOBENCH</p>
<p>We provide the visualization of RocoBench at Fig. 9.The cabinet task requires three agents to collaborate: two agents open and hold the cabinet door while the third agent retrieves two cups from inside the cabinet and places them onto coasters that match the color of the cups.The sweep task involves two agents coordinating their actions: one agent controls a broom to sweep cubes, while the other agent holds a bucket to collect the cubes, and finally, they dump all the cubes into a dustbin.In the sandwich task, two agents work together to pick up ingredients and stack them according to a given recipe.The sort task requires three agents to place three cubes onto coasters with matching colors.Since each agent can only reach a limited area, they must coordinate their movements.Lastly, the rope task involves agents moving a rope into a bracket.They must communicate effectively to decide the correct path for maneuvering the rope.</p>
<p>"agent_description": "Critical to the success of the sustainability-focused business, this agent is in charge of advertising campaigns, social media presence, and public relations.With a strong emphasis on the company' s eco-friendly values, it develops targeted marketing strategies to reach a wider audience, creating a strong brand identity around sustainability.The agent also handles analytics, gauging the effectiveness of marketing efforts and adjusting tactics to optimize outreach and customer engagement."24 } 25 ], 26 "task_description": "I want to start a business that focuses on sustainable living.The business will include a podcast series on how to incorporate sustainability into daily life and crafting custom eco-friendly products for customers."27 }</p>
<p>Similarly, an example of a generated sub-task description with additional agent in JSON format is: 1 { 2 "additional_subtask": { 3 "task_description": "Implement advanced custom animations and interactive elements to enhance the visual appeal of the personal website, particularly for the graphic design portfolio section.This includes creating dynamic, engaging animations that showcase the artist's skills and bring the homepage to life, as well as ensuring cross-browser compatibility and responsiveness on various devices.",</p>
<p>4</p>
<p>"agent": { 5 "agent_name": "AnimationExpert",</p>
<p>6</p>
<p>"agent_type": "Thing Assistant",</p>
<p>7</p>
<p>"agent_description": "AnimationExpert is a highly specialized virtual assistant dedicated to creating sophisticated web animations and interactive experiences.It is equipped with state-of-the-art tools and knowledge of the latest animation libraries like GSAP, Three.js, and WebGL.This agent analyzes the existing style and content of the website to develop tailored, eye-catching animations that complement the graphical elements without compromising website performance.It ensures compatibility with all major browsers and devices and works seamlessly with responsive design principles to deliver a consistent experience across all user interfaces.""agent_name": "WebDesignerAssistant",</p>
<p>13</p>
<p>"agent_type": "Human Assistant",</p>
<p>14</p>
<p>"agent_description": "This agent specializes in web design and user experience.It assists in creating a visually appealing and intuitive homepage layout that effectively showcases the portfolio of graphic design work.It will help organize content in a cohesive manner, using best web design practices to emphasize the most compelling pieces.This assistant can also suggest and implement design elements that reflect personal style and artistic sensibility.""agent_name": "PhotographyShowcaseAssistant",</p>
<p>23</p>
<p>"agent_type": "Thing Assistant",</p>
<p>24</p>
<p>"agent_description": "This agent is tailored to enhance the presentation of photography work on the website.Equipped with image organizing and editing software integration capabilities, it can help sort and select the best photographs to feature.It will ensure that the images are displayed in high quality and that the loading speed is optimized for user convenience.This assistant will also provide options for interactive image galleries that enable visitors to view the work in detail."By generating a couple of diverse sets of tasks and agents, we create a comprehensive simulated environment for evaluating the regular team formation mechanism and the nested team formation mechanism.This environment enables us to assess the effectiveness of IoA in assembling appropriate teams to complete task requirements, addressing the limitations of existing benchmarks in providing suitable large-scale agent evaluation scenarios.</p>
<p>Figure 2 :
2
Figure 2: An example of nested team formation mechanism.The process is simplified for clarity.</p>
<p>Figure 3
3
Figure 3 illustrates the state transitions in the conversation flow.Each state corresponds to different phases of the collaboration process: • Discussion (s d ): Agents engage in general dialogue, exchange ideas, and clarify task requirements.• Synchronous task assignment (s s ): Tasks are assigned to specific agents, pausing the group chat until completion (Section 2.3.4).• Asynchronous task assignment (s a ): Tasks are assigned without interrupting the ongoing discussion (Section 2.3.4).• Pause &amp; trigger (s p ): The group chat is paused, waiting for the completion of specified asynchronous tasks.• Conclusion (s c ): Marks the end of the collaboration, prompting a final summary.Start Team FormationDiscussionSync Task Assignment</p>
<p>Figure 3 :
3
Figure 3: The state transition among different states.</p>
<p>t e x i t s h a 1 _ b a s e 6 4 = " x y F k 3B A 2 o 8 r + 3 2 z Z 6 o w Q r S 8 w J a A = " &gt; A A A C G H i c b V D L S g M x F M 3 U V 6 2 v q k s 3 w S p U k D p T n 8 u C G 5 c V 7 A M 6 Z c i k a R u a y Q z J H b E M 8 x l u / B U 3 L h R x2 5 1 / Y / p Y a O u B e z m c c y / J P X 4 k u A b b / r Y y S 8 s r q 2 v Z 9 d z G 5 t b 2 T n 5 3 r 6 7 D W F F W o 6 E I V d M n m g k u W Q 0 4 C N a M F C O B L 1 j D H 9 y O / c Y j U 5 q H 8 g G G E W s H p C d 5 l 1 M C R v L y Z y 6 w J w B I B I k l 7 b t e T 4 V x 5 H q 0</p>
<p>H 9 a 9 k / r x 5 V H 1 b L e o o 0 S 2 y Q 6 p E Y + c k j N y Q Z q k R T i 5 J 4 / k m b w 4 D 8 6 T 8 + q 8 f Y 3 O O E V m i / y A 8 / E J r S S k 8 A = = &lt; / l a t e x i t &gt; search client({Paper Writing, . . .}) t e x i t s h a 1 _ b a s e 6 4 = " N I</p>
<p>Figure 4 :
4
Figure 4: An example walkthrough of the major components of IoA.</p>
<p>Figure 5 :
5
Figure 5: Comparison of win rates on the open-ended instruction benchmark between IoA, Auto-GPT, and Open Interpreter.</p>
<p>Figure 6 :
6
Figure 6: An example of the repeated communication.</p>
<p>Figure 7 :
7
Figure 7: Fields in the IoA message protocol.</p>
<p>Figure 8 :
8
Figure 8: Example instructions from different categories in our open-ended instruction benchmark</p>
<dl>
<dt>Figure 9 :</dt>
<dt>9</dt>
<dt>Figure 9: The different environments in RocoBench.</dt>
<dd>
<p>"I want to create a personal website that showcases my portfolio of graphic design work, my fashion and style blog posts, and my photography.Please provide instructions on how to design the layout for my homepage that effectively incorporates all three aspects."28 }</p>
</dd>
</dl>
<p>Table 1 :
1
The performance on the validation set of GAIA benchmark.
ModelsAgent Type Level 1 Level 2 Level 3 OverallGPT-415.092.330.006.06GPT-4-Turbo20.755.810.009.70AutoGPT-4 (Significant Gravitas, 2023)13.210.003.854.85GPT-4 + Plugins (Mialon et al., 2023)30.309.700.0014.60FRIDAY (Wu et al., 2024b)45.2834.8811.5434.55AutoGen (Wu et al., 2023)54.7238.3711.5439.39IoA50.9440.7015.3840.00</p>
<p>Table 2 :
2
Average success rate and the number of steps on different tasks from RoCoBench.
ModelMetric Cabinet Sweep Sandwich Sort RopeCentral PlanSuccess0.901.000.960.70 0.50(oracle)#Step4.08.48.88.62.3RocoSuccess0.750.700.700.70 0.70Dialog#Step4.77.99.15.42.4IoASuccess #Step1.00 4.60.80 8.51.00 8.91.00 0.70 5.8 2.63.3 HETEROGENEOUS OBSERVATION AND ACTION SPACE: EMBODIED AGENT TASKS</p>
<p>Table 3 :
3
Results for RAG task.IoA, based on GPT-3.5, performs on par with or better than GPT-4 across all tasks.Best results (excluding GPT-4) are in bold, and second-best are underlined.Heterogeneous means agents have different evidence pools, while Homogeneous means all agents access all evidence pools.</p>
<p>Table 4 :
4
Performance of Team Formation Mechanisms.Regular denotes the initial team formation setting, and Nested denotes the nested team formation mechanism.
Top@1↑ Top@10↑ MR↓ MRR↑Regular41.4%64.9%27.450.1%Nested59.7%81.8%10.666.5%</p>
<p>Table 5 :
5
Cost analysis of standalone agents and IoA-integrated agents on the open-ended instruction benchmark.
SettingCost per TaskAutoGPT (Standalone)$0.39Open Interpreter (Standalone)$0.16AutoGPT (in IoA)$0.33Open Interpreter (in IoA)$0.13IoA Communication$0.53IoA Communication (Dedup.)$0.28IoA Overall$0.99IoA Overall (Dedup.)$0.74</p>
<p>Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. Cohen, Ruslan Salakhutdinov, and Christopher D. Manning.Hotpotqa: A dataset for diverse, explainable multi-hop question answering, 2018.Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R. Narasimhan, and Yuan Cao.React: Synergizing reasoning and acting in language models.In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023.OpenReview.net, 2023.URL https://openreview.net/pdf?id=WE_vluYUL-X.Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica.Judging llm-as-a-judge with mt-bench and chatbot arena, 2023b.
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, YonghaoZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez,and Ion Stoica. Judging llm-as-a-judge with mt-bench and chatbot arena. In Alice Oh,Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine (eds.),Advances in Neural Information Processing Systems 36: Annual Conference on Neural In-formation Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10-16, 2023, 2023a. URL http://papers.nips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html.HeaderAutonomous Team Formationsender: strgoal: strstate: enumteam_members: list[str]comm_id: strteam_up_depth: intmax_turns: intPause &amp; Triggertriggers: list[str]Task AssignmentDiscussion content: str type: enum next_speaker: list[str]task_id: str task_desc: str task_conclusion: str task_abstract: str
A IMPLEMENTATION DETAILS OF IOAIn this appendix, we provide a comprehensive overview of the implementation details for each module in the client and server layers of IoA.A.1 MESSAGE PROTOCOL</p>
<p>Please complete the function according to its comment.defminimumTime(grid:List[List[int]])-&gt;int:"""You are given a m x n matrix grid consisting of non-negative integers where grid[row][col] represents the minimum time required to be able to visit the cell (row, col), which means you can visit the cell (row, col) only when the time you visit it is greater than or equal to grid[row][col].</p>
<p>"agent_description": "This agent focuses on content creation and management.It supports in putting together the fashion and style blog posts by helping to curate topics, edit posts for clarity and brand consistency, and integrate them into the website.It ensures that the blog content is strategically placed for optimal engagement, incorporating SEO best practices to increase visibility and draw in more visitors interested in fashion and style ."
16 17}, {"agent_name": "ContentStrategistAssistant",18"agent_type": "Human Assistant",2021 22{
19</p>
<p>https://www.wikipedia.org/
https://www.linux.org/
If not specified, we use GPT-4-1106-preview model in our experiments.
https://github.com/pytube/pytube
https://python.langchain.com/v0.1/docs/integrations/tools/wikidata/
C SIMULATED ENVIRONMENT FOR TEAM FORMATION EVALUATION C.1 REGULAR TEAM FORMATION SIMULATED ENVIRONMENT CONSTRUCTIONTo construct a simulated environment for evaluating the regular ,team formation mechanism, we employ GPT-4-1106-preview to generate a diverse set of tasks and agents.The dataset construction process involved the following steps:1. Task Generation:• Using ChatGPT-4, we generate 399 distinct categories of theme keywords, covering various domains such as sports, lifestyle, and entertainment.• From these categories, we randomly select 25 themes and task GPT-4 with generating task descriptions related to at least four themes from the selected set, thus obtaining a task that require diverse agents with different capabilities.• Task descriptions are generated in JSON format using the GPT-4 API, ensuring a structured and consistent representation.2. Agent Generation:• After generating the tasks, for each task, we again prompt GPT-4 to construct at least two agents with varying capabilities for the given task, including the name of the agent, the type of the agent and the description of the agent.• The agent profile format is designed to align with the server-side agent registry, facilitating seamless integration and interaction within IoA.An example of a generated task description in JSON format is as follows:1 { 2 "task_id": "xxx",3"task_description": "Develop a mobile app that helps users plan and manage their personal finance, including budgeting, expense tracking, and investment suggestions."4 } Similarly, an example of an agent profile in JSON format is: 1 { 2 "agent_name": "FinanceGuru", 3 "agent_type": "Thing Assitant" 4 "agent_description": "FinanceGuru is a highly skilled agent specializing in personal finance management.C.2 NESTED TEAM FORMATION SIMULATED ENVIRONMENT CONSTRUCTIONIn a similarly way, in order to construct a simulated environment for evaluating the nested team formation mechanism, we also employ GPT-4-1106-preview to generate two diverse sets of tasks and agents.The dataset construction process involved the following steps:1. Sub-tasks Completed by Existing Agents:• Su-btask Generation:-Based on the dataset that we have constructed for regular team formation, we randomly select 300 sets as the original dataset.-For tasks in the original dataset, we prompt GPT-4 to construct a sub-task that can be completed by an existing agent, with the agent being selected by GPT-4.-Sub-task description are generated in JSON format using the GPT-4 API with the existing agent, ensuring a structured and consistent representation.Sub-tasks Completed by Additional Agent:• Sub-task and Agent Generation:-After generating the sub-tasks for exiting agent, we take the rest of sets as the another original dataset.-The difference for sub-task completed by existing agent is that we prompt  to construct a sub-task requiring a very specific expertise.-Meanwhile, we also prompt GPT-4 to construct an agent with distinct capabilities compared to the existing agents to complete the generated sub-task, including the name of the agent, the type of the agent and the description of the agent.-Sub-task description and additional agent are generated in JSON format using the GPT-4 API ensuring a structured and consistent representation.An example of a generated sub-task description with existing agent in JSON format is as follows:1 { 2 "additional_subtask": { 3 "task_description": "Develop a comprehensive marketing plan highlighting the business's commitment to sustainability, including strategies for podcast promotion, brand awareness, and customer engagement.",4"agent": { 5 "agent_name": "MarketingStrategist",6"agent_type": "Human Assistant",7"agent_description": "Critical to the success of the sustainability-focused business, this agent is in charge of advertising campaigns, social media presence, and public relations.With a strong emphasis on the company' s eco-friendly values, it develops targeted marketing strategies to reach a wider audience, creating a strong brand identity around sustainability.The agent also handles analytics, gauging the effectiveness of marketing efforts and adjusting tactics to optimize outreach and customer engagement.""agent_name": "SustainabilityEducator", 12 "agent_type": "Human Assistant", 13 "agent_description": "This agent is specialized in creating, curating, and disseminating information about sustainable living.It is responsible for researching various subjects related to sustainability, structuring podcast content, interviewing experts, and sharing practical tips on incorporating eco-friendly practices into daily life.The agent will also engage the audience through various channels, answer listener queries, and promote discussion on sustainability.""agent_name": "MarketingStrategist",22"agent_type": "Human Assistant",
. Sam Ade Marah I Abdin, Ammar Jacobs, Jyoti Ahmad Awan, Ahmed Aneja, Hany Awadallah, Nguyen Awadalla, Amit Bach, Arash Bahree, Harkirat S Bakhtiari, Alon Behl, Misha Benhaim, Johan Bilenko, Sébastien Bjorck, Martin Bubeck, Caio Cai, Teodoro César, Weizhu Mendes, Vishrav Chen, Parul Chaudhary, Allie Chopra, Gustavo Del Giorno, Matthew De Rosa, Ronen Dixon, Dan Eldan, Amit Iter, Abhishek Garg, Suriya Goswami, Emman Gunasekar, Junheng Haider, Russell J Hao, Jamie Hewett, Mojan Huynh, Xin Javaheripi, Piero Jin, Nikos Kauffmann, Dongwoo Karampatziakis, Mahoud Kim, Lev Khademi, James R Kurilenko, Yin Lee, Yuanzhi Tat Lee, Chen Li, Weishung Liang, Eric Liu, Zeqi Lin, Piyush Lin, Arindam Madan, Hardik Mitra, Anh Modi, Brandon Nguyen, Barun Norick, Daniel Patra, Thomas Perez-Becker, Reid Portet, Heyang Pryzant, Marko Qin, Corby Radmilac, Sambudha Rosset, Olatunji Roy, Olli Ruwase, Amin Saarikivi, Adil Saied, Michael Salim, Shital Santacroce, Ning Shah, Hiteshi Shang, Xia Sharma, Masahiro Song, Xin Tanaka, Rachel Wang, Guanhua Ward, Philipp Wang, Michael Witte, Can Wyatt, Jiahang Xu, Sonali Xu, Fan Yadav, Ziyi Yang, Donghan Yang, Chengruidong Yu, Cyril Zhang, Jianwen Zhang, Li Lyna Zhang, Yi Zhang, Yue Zhang, Yunan Zhang, Xiren Zhang, Zhou, 10.48550/arXiv.2404.14219Phi-3 technical report: A highly capable language model locally on your phone. CoRR, abs/2404.14219, 2024</p>
<p>Introducing the next generation of claude. Anthropic, 2024</p>
<p>How to do things with words. John Langshaw, Austin , 1975Oxford university press88</p>
<p>Software architecture in practice. SEI series in software engineering. Leonard J Bass, Paul C Clements, Rick Kazman, 1999Addison-Wesley-Longman</p>
<p>Chateval: Towards better llm-based evaluators through multi-agent debate. Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, Zhiyuan Liu, 10.48550/arXiv.2308.072012023</p>
<p>. Harrison Chase, Langchain, October 2022</p>
<p>Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors. Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu, Yi-Hsin Hung, Chen Qian, The Twelfth International Conference on Learning Representations. 2023</p>
<p>Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality. Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, Ion Stoica, Eric P Xing, March 2023</p>
<p>Improving factuality and reasoning in language models through multiagent debate. Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, Igor Mordatch, 10.48550/arXiv.2305.143252023</p>
<p>KQML as an agent communication language. Timothy W Finin, Richard Fritzson, Donald P Mckay, Robin Mcentire, 10.1145/191246.191322Proceedings of the Third International Conference on Information and Knowledge Management (CIKM'94). the Third International Conference on Information and Knowledge Management (CIKM'94)Gaithersburg, Maryland, USAACMNovember 29 -December 2, 1994. 1994</p>
<p>Constructing a multi-hop qa dataset for comprehensive evaluation of reasoning steps. Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara, Akiko Aizawa, 2020</p>
<p>Metagpt: Meta programming for multi-agent collaborative framework. Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka, Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, 10.48550/arXiv.2308.003522023</p>
<p>Minicpm: Unveiling the potential of small language models with scalable training strategies. Shengding Hu, Yuge Tu, Xu Han, Chaoqun He, Ganqu Cui, Xiang Long, Zhi Zheng, Yewei Fang, Yuxiang Huang, Weilin Zhao, Xinrong Zhang, Zhen Leng Thai, Kai Zhang, Chongyi Wang, Yuan Yao, Chenyang Zhao, Jie Zhou, Jie Cai, Zhongwu Zhai, Ning Ding, Chao Jia, Guoyang Zeng, Dahai Li, Zhiyuan Liu, Maosong Sun, 10.48550/arXiv.2404.063952024</p>
<p>Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. Mandar Joshi, Eunsol Choi, Daniel S Weld, Luke Zettlemoyer, 2017</p>
<p>Dense passage retrieval for open-domain question answering. Vladimir Karpukhin, Barlas Oguz, Sewon Min, S H Patrick, Ledell Lewis, Sergey Wu, Danqi Edunov, Wen-Tau Chen, Yih, 10.18653/v1/2020.emnlp-main.550Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. Bonnie Webber, Trevor Cohn, Yulan He, Yang Liu, the 2020 Conference on Empirical Methods in Natural Language ProcessingOnlineAssociation for Computational LinguisticsNovember 16-20, 2020. 20202020</p>
<p>Natural questions: A benchmark for question answering research. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur P Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M Dai, Jakob Uszkoreit, Quoc V Le, Slav Petrov, 2019Transactions of the Association for Computational Linguistics7</p>
<p>Agent communication languages: the current landscape. Yannis Labrou, Tim Finin, Yun Peng, 10.1109/5254.757631IEEE Intell. Syst. 1421999</p>
<p>Retrieval-augmented generation for knowledge-intensive nlp tasks. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen Tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela, 2021</p>
<p>CAMEL: communicative agents for "mind" exploration of large language model society. Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin, Bernard Ghanem, Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023. Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, Sergey Levine, NeurIPS; New Orleans, LA, USA2023. December 10 -16, 2023. 2023</p>
<p>Formal-llm: Integrating formal language and natural language for controllable llm-based agents. Zelong Li, Wenyue Hua, Hao Wang, He Zhu, Yongfeng Zhang, 10.48550/arXiv.2402.007982024</p>
<p>Encouraging divergent thinking in large language models through multiagent debate. Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, Shuming Shi, 10.48550/arXiv.2305.19118CoRR, abs/2305.19118, 2023</p>
<p>Smot: Think in state machine. Jia Liu, Jie Shuai, 10.48550/arXiv.2312.174452023</p>
<p>Roco: Dialectic multi-robot collaboration with large language models. Zhao Mandi, Shreeya Jain, Shuran Song, 10.48550/arXiv.2307.047382023</p>
<p>A survey on resource discovery mechanisms, peer-to-peer and service discovery frameworks. Elena Meshkova, Janne Riihijärvi, Marina Petrova, Petri Mähönen, 10.1016/j.comnet.2008.03.006Comput. Networks. 52112008</p>
<p>Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir Sanjay Kale, Juliette Love, Pouya Tafti, Léonard Hussenot, Aakanksha Chowdhery, Adam Roberts, Aditya Barua, Alex Botev, Alex Castro-Ros, Ambrose Slone, Amélie Héliou, Andrea Tacchetti, Anna Bulanova, Antonia Paterson, Beth Tsai, Bobak Shahriari, Charline Le Lan, Christopher A Choquette-Choo, Clément Crepy, Daniel Cer, Daphne Ippolito, David Reid, Elena Buchatskaya, Eric Ni, Eric Noland, Geng Yan, George Tucker, George-Cristian Muraru, Grigory Rozhdestvenskiy, Henryk Michalewski, Ian Tenney, Ivan Grishchenko, Jacob Austin, James Keeling, Jane Labanowski, Jean-Baptiste Lespiau, Jeff Stanway, Jenny Brennan, Jeremy Chen, Johan Ferret, Justin Chiu, 10.48550/arXiv.2403.08295Open models based on gemini research and technology. 2024</p>
<p>GAIA: a benchmark for general AI assistants. Grégoire Mialon, Clémentine Fourrier, Craig Swift, Thomas Wolf, Yann Lecun, Thomas Scialom, 10.48550/arXiv.2311.129832023</p>
<p>Webgpt: Browser-assisted question-answering with human feedback. Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, John Schulman, CoRR, abs/2112.093322021</p>
<p>Aws service registry for resilient mid-tier load balancing and failover. Netflix, Eureka, </p>
<p>Open Interpreter, Open Interpreter. 2023</p>
<p>10.48550/arXiv.2303.08774GPT-4 technical report. 2023OpenAI</p>
<p>OpenDevin: An Open Platform for AI Software Developers as Generalist Agents. Opendevin Team, ENTER THE DATE YOU ACCESSED THE PROJECT. 2024</p>
<p>Generative agents: Interactive simulacra of human behavior. Sung Joon, Joseph C Park, Carrie Jun O'brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, 10.1145/3586183.3606763Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology, UIST 2023. Sean Follmer, Jeff Han, Jürgen Steimle, Nathalie Henry Riche, the 36th Annual ACM Symposium on User Interface Software and Technology, UIST 2023San Francisco, CA, USAACM29 October 2023-1 November 202322023-2:22</p>
<p>Communicative agents for software development. Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, Maosong Sun, 10.48550/arXiv.2307.079242023a</p>
<p>Experiential co-learning of software-developing agents. Chen Qian, Yufan Dang, Jiahao Li, Wei Liu, Weize Chen, Cheng Yang, Zhiyuan Liu, Maosong Sun, 10.48550/arXiv.2312.170252023b</p>
<p>Toolllm: Facilitating large language models to master 16000+ real-world apis. Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, Maosong Sun, 10.48550/arXiv.2307.167892023</p>
<p>An anytime algorithm for optimal coalition structure generation. Talal Rahwan, D Sarvapali, Nicholas R Ramchurn, Andrea Jennings, Giovannucci, 10.1613/jair.2695J. Artif. Intell. Res. 342009</p>
<p>Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, Timothy P Lillicrap, Jean-Baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat, Julian Schrittwieser, Ioannis Antonoglou, Rohan Anil, Sebastian Borgeaud, Andrew M Dai, Katie Millican, Ethan Dyer, Mia Glaese, Thibault Sottiaux, Benjamin Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, James Molloy, Jilin Chen, Michael Isard, Paul Barham, Tom Hennigan, Ross Mcilroy, Melvin Johnson, Johan Schalkwyk, Eli Collins, Eliza Rutherford, Erica Moreira, Kareem Ayoub, Megha Goel, Clemens Meyer, Gregory Thornton, Zhen Yang, Henryk Michalewski, Zaheer Abbas, Nathan Schucher, Ankesh Anand, Richard Ives, James Keeling, Karel Lenc, Salem Haykal, Siamak Shakeri, Pranav Shyam, Aakanksha Chowdhery, Roman Ring, Stephen Spencer, Eren Sezener, 10.48550/arXiv.2403.055302024</p>
<p>The probabilistic relevance framework: BM25 and beyond. Stephen E Robertson, Hugo Zaragoza, 10.1561/1500000019Found. Trends Inf. Retr. 342009</p>
<p>Toolformer: Language models can teach themselves to use tools. Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom, Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems. Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, Sergey Levine, NeurIPS; New Orleans, LA, USA2023. 2023. December 10 -16, 2023. 2023</p>
<p>Speech Acts: An Essay in the Philosophy of Language. John R Searle, 1969Cambridge University Press</p>
<p>A classification of illocutionary acts1. John R Searle, Language in society. 511976</p>
<p>Hugginggpt: Solving AI tasks with chatgpt and its friends in hugging face. Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting Zhuang, Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023. Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, Sergey Levine, NeurIPS; New Orleans, LA, USA2023. December 10 -16, 2023. 2023</p>
<p>Reflexion: language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao, Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023. Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, Sergey Levine, NeurIPS; New Orleans, LA, USA2023. December 10 -16, 2023. 2023</p>
<p>Significant-Gravitas/AutoGPT. XAgent Team. Xagent: An autonomous agent for complex task solving. Significant Gravitas, Autogpt, 2023. 2023</p>
<p>Voyager: An open-ended embodied agent with large language models. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, Anima Anandkumar, 10.48550/arXiv.2305.162912023a</p>
<p>Apollo's oracle: Retrieval-augmented reasoning in multi-agent debates. Haotian Wang, Xiyuan Du, Weijiang Yu, Qianglong Chen, Kun Zhu, Zheng Chu, Lian Yan, Yi Guan, ArXiv, abs/2312.048542023b</p>
<p>MINT: evaluating llms in multi-turn interaction with tools and language feedback. Xingyao Wang, Zihan Wang, Jiateng Liu, Yangyi Chen, Lifan Yuan, Hao Peng, Heng Ji, 10.48550/arXiv.2309.106912023c</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou, The Eleventh International Conference on Learning Representations, ICLR 2023. Kigali, RwandaMay 1-5, 2023. 2023dOpenReview.net</p>
<p>Self-instruct: Aligning language models with self-generated instructions. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, Hannaneh Hajishirzi, 10.18653/v1/2023.acl-long.754Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. Anna Rogers, Jordan L Boyd-Graber, Naoaki Okazaki, the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational LinguisticsJuly 9-14, 2023. 2023e1ACL 2023</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H Chi, V Quoc, Denny Le, Zhou, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems. S Sanmi Koyejo, A Mohamed, Danielle Agarwal, K Belgrave, A Cho, Oh, NeurIPS; New Orleans, LA, USA2022. 2022. November 28 -December 9, 2022. 2022</p>
<p>Autogen: Enabling next-gen LLM applications via multi-agent conversation framework. Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, Chi Wang, 10.48550/arXiv.2308.081552023</p>
<p>Stateflow: Enhancing LLM task-solving through state-driven workflows. Yiran Wu, Tianwei Yue, Shaokun Zhang, Chi Wang, Qingyun Wu, 10.48550/arXiv.2403.113222024a</p>
<p>Os-copilot: Towards generalist computer agents with selfimprovement. Zhiyong Wu, Chengcheng Han, Zichen Ding, Zhenmin Weng, Zhoumianze Liu, Shunyu Yao, Tao Yu, Lingpeng Kong, 10.48550/arXiv.2402.074562024b</p>            </div>
        </div>

    </div>
</body>
</html>