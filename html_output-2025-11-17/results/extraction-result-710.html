<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-710 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-710</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-710</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-249926970</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2206.11131v1.pdf" target="_blank">Variational Causal Dynamics: Discovering Modular World Models from Interventions</a></p>
                <p><strong>Paper Abstract:</strong> Latent world models allow agents to reason about complex environments with high-dimensional observations. However, adapting to new environments and effectively leveraging previous knowledge remain signiﬁcant challenges. We present variational causal dynamics (VCD), a structured world model that exploits the invariance of causal mechanisms across environments to achieve fast and modular adaptation. By causally factorising a transition model, VCD is able to identify reusable components across different environments. This is achieved by combining causal discovery and variational inference to learn a latent representation and transition model jointly in an unsupervised manner. Speciﬁcally, we optimise the evidence lower bound jointly over a representation model and a transition model structured as a causal graphical model. In evaluations on simulated environments with state and image observations, we show that VCD is able to successfully identify causal variables, and to discover consistent causal structures across different environments. Moreover, given a small number of observations in a previously unseen, intervened environment, VCD is able to identify the sparse changes in the dynamics and to adapt efﬁciently. In doing so, VCD signiﬁcantly extends the capabilities of the current state-of-the-art in latent world models while also comparing favourably in terms of prediction accuracy.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e710.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e710.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VCD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Variational Causal Dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A latent world-model that jointly learns a representation and a causally factorised transition model by combining variational inference with differentiable causal discovery and sparsity regularisation to identify invariant mechanisms and sparse interventions across multiple environments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Variational Causal Dynamics (VCD)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>VCD is a latent state-space model whose transition probability is factorised across latent dimensions into independent one-dimensional conditional mechanisms (Independent Causal Mechanisms principle). It parameterises a probabilistic belief over a sparse causal adjacency matrix (Bernoulli entries with logits α) and per-environment intervention target masks (Bernoulli with logits β). The transition for variable i conditions only on its parents selected by a binary mask M_G (learned) and switches between a shared observational mechanism p^(0)_i and environment-specific interventional mechanism p^(k)_i according to R_I (learned). Training maximises an expected ELBO across environments plus sparsity penalties on expected number of edges and intervention targets; gradients through graph/intervention expectations are estimated using straight-through Gumbel-type sampling (Gumbel-Softmax / logistic trick) and reparameterisation for latent sampling. Separate small recurrent units per latent variable are used so each mechanism can model temporal context while preserving per-variable modularity. Adaptation to a new environment is performed by inferring the intervention mask R and refitting only the intervened mechanisms while reusing shared mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>2-D multi-body simulated environment (mixed-state and image experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>A controlled simulated multi-particle physics environment with four particles interacting via springs / electrostatic-like forces. Two observation modalities used: 'mixed-state' (affine-mixed ground-truth positions) and rendered RGB images (128x128x3). The environments include an undisturbed base environment plus multiple intervened environments (e.g., remove/strengthen springs, change masses, constrain particle axes). This is an interactive simulation in the sense that actions (external force on one particle) and interventions (environmental changes) are available, but VCD is trained from logged trajectories rather than performing active experiment selection.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Implicit handling via sparse causal factorisation and intervention modelling: (1) sparsity regularisation on graph edges and intervention targets (λ_G, λ_I) to discourage spurious edges; (2) independent mechanisms (per-latent conditional models) that prevent signal leakage across variables; (3) binary intervention masks that explain distribution shifts by switching to environment-specific mechanisms instead of changing many mechanisms globally, thereby attributing spurious correlations to localised interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious / non-generalising correlations arising from pooling data across environments (i.e. distribution shifts / noninvariant conditional mechanisms), measurement/mixing in observations (entangled observation maps), and irrelevant entangled latent dimensions (entanglement does not generalise across interventions).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Learns Bernoulli parameters β for intervention masks and α for graph edges via gradient-based optimisation of the expected ELBO across environments; detection of 'intervened' variables arises when describing an environment with environment-specific conditional p^(k)_i reduces ELBO (i.e. better explains data) while sparsity penalties keep number of interventions small. Gumbel/ logistic sampling (straight-through) is used to propagate gradients for discrete graph/intervention samples.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Non-intervened mechanisms reuse a shared observational conditional p^(0)_i; by default the model 'downweights' environment-specific explanations for variables that can be re-used, enforced by sparsity penalties on R and by the ELBO/KL coupling which favour parsimonious explanations—this effectively reduces influence of spurious, environment-specific correlations by not allocating environment-specific parameters unless supported by data.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>No explicit classical refutation test is used; model selection / refutation is effected via sparsity regularisation and likelihood (ELBO) comparison across models with/without edges or interventions: spurious edges/interventions are penalised (λ_G, λ_I), and the optimisation prefers minimal sets of mechanisms/interventions that explain multi-environment data, thereby implicitly refuting unnecessary causal links.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Qualitative and quantitative gains reported: VCD learns sparse causal graphs and causally meaningful latent axes, correctly identifies intervention targets in the mixed-state experiments, and substantially outperforms baselines (RSSM, MultiRSSM) in rollout error in the low-data adaptation regime. The paper reports VCD identified 42 edges (out of 288 possible) in mixed-state and 73 edges in the image experiment, and that it recovers all intervention targets in the mixed-state test; VCD can converge to a correct latent dimension encoding an intervened coordinate with as little as one trajectory.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baselines (RSSM with full parameter sharing and MultiRSSM with per-environment models) either capture averaged dynamics (RSSM) or overfit/no cross-environment reuse (MultiRSSM). They show higher rollout error and worse adaptation in low-data regimes; specific numeric metrics (e.g., SHD) are not reported for direct graph comparison except counts of discovered edges and qualitative correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Joint training of representation and a sparse causal transition model yields causally meaningful, axis-aligned latent representations and sparse graphs; modelling interventions explicitly (sparse mechanism shift) enables identification of intervened mechanisms and modular adaptation, giving large gains in data efficiency for adapting to new environments. Sparsity regularisation and per-mechanism modularity are central to suppressing spurious cross-environment correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Variational Causal Dynamics: Discovering Modular World Models from Interventions', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e710.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e710.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DCDI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Differentiable Causal Discovery with Interventional Data</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A differentiable, continuous optimisation approach for causal discovery that learns a probabilistic belief (Bernoulli parameters) over DAG adjacency and over unknown intervention targets by maximising expected data likelihood under sparsity penalties and using differentiable sampling (Gumbel-Softmax/logistic tricks) to propagate gradients through discrete graph structures.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Differentiable causal discovery from interventional data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Differentiable Causal Discovery with Interventional Data (DCDI)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>DCDI parameterises the adjacency matrix and intervention-target masks as independent Bernoulli random variables with logits α and β, and then optimises the expected log-likelihood of observed and interventional datasets under these discrete structures plus sparsity regularisation on expected edge/intervention counts. It uses continuous relaxations and straight-through style sampling (Gumbel-Softmax/logistic trick) to enable gradient-based optimisation over graphs and unknown interventions. Optionally enforces acyclicity constraints and parameterises conditionals with neural networks (score-based).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>General multi-environment / interventional datasets (applied within VCD to the simulated multi-body domain)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Originally general framework applicable to tabular/low-dimensional variables with observational and interventional datasets; in this paper it is adopted inside a latent-variable ELBO training loop where causal variables are latent and observation mappings are learned.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Designed to handle changes across environments due to interventions (i.e., noninvariant mechanisms) and to disambiguate which conditional mechanisms changed, but not explicitly designed for unrelated distractor variables; relies on sparsity regularisation to avoid spurious edges.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Infers intervention targets by optimising expected likelihood across environments and finding intervention masks R that explain inter-environment distribution differences, implemented via Bernoulli logits β and Gumbel/logistic sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Sparsity regularisation on expected number of edges and intervention targets penalises complex graphs and many interventions, thereby biasing the model away from explaining data via many spurious edges.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>No explicit refutation tests; uses parsimony (sparsity penalties) and likelihood to rule out unnecessary edges/interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Not reported in isolation within this paper; DCDI is used as a graph-learning backbone and shown to be effective when combined with VCD's latent modelling. Specific performance metrics for DCDI alone are not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>DCDI's continuous probabilistic graph parameterisation and differentiable sampling techniques integrate well into a latent-variable ELBO framework, enabling joint learning of representation and causal structure from interventional datasets; sparsity priors are critical to avoid spurious connectivity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Variational Causal Dynamics: Discovering Modular World Models from Interventions', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e710.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e710.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IRM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Invariant Risk Minimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of methods that aim to learn predictors whose optimality is invariant across multiple environments, thereby isolating causal features and avoiding predictors that exploit spurious, environment-specific correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Invariant risk minimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Invariant Risk Minimization (IRM) / invariant predictor methods</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>IRM formulates learning as seeking a data representation and classifier such that the optimal classifier on top of that representation is simultaneously optimal for all training environments; operationally it minimises empirical risk across environments together with a penalty encouraging invariance of classifier gradients. Variants and related invariant predictor methods learn stable features across environments and are used to identify and avoid using features that correspond to spurious correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>General multi-environment / domain shift benchmarks; not used in VCD experiments here</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Designed for multi-environment datasets where spurious correlations vary across domains; typically not interactive—uses provided environment labels and datasets rather than active interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Invariance principle: features that produce invariant optimal predictors across environments are preferred over features whose predictive power changes by environment, which downweights spurious environment-specific correlates.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Confounding induced spurious correlations across environments and selection bias that lead to non-invariant predictors.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Detects spurious features by testing stability/invariance of predictor performance or gradients across environments (penalty on environment-specific optimality violations).</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Penalises representations/predictors that rely on environment-specific features through an invariance regulariser, thus downweighting spurious signals in learned predictors.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as a related line of work exploiting invariance across environments to avoid spurious predictors; differs from VCD in that IRM focuses on discriminative invariance for prediction rather than learning a generative causal world model and explicit per-mechanism interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Variational Causal Dynamics: Discovering Modular World Models from Interventions', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e710.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e710.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ICP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Invariant Causal Prediction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A constraint-based approach which leverages invariance of conditional distributions across environments to identify causal parents by finding subsets of covariates whose conditional distribution of the target remains invariant across interventions/environments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal inference using invariant prediction: identification and confidence intervals</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Invariant Causal Prediction (ICP)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>ICP searches for subsets of covariates S such that the conditional distribution of the target given S is invariant across environments; under certain assumptions this identifies a set of causal parents. It often provides statistical tests and confidence intervals for parent inclusion by testing whether residuals are identically distributed across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>General multi-environment observational/interventional datasets; not instantiated in this paper's experiments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Operates on datasets with known environment labels (multiple domains); typically not an interactive experimental design method but usable when several environments / interventions are available.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>By selecting covariates whose conditionals are invariant, ICP aims to exclude variables whose predictive relationship is environment-specific (distractors).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Noninvariant predictors due to confounding, selection bias, or changing mechanisms across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Statistical tests for invariance of conditional distributions of the target given candidate parent sets across environments (e.g., tests on residuals).</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Provides hypothesis tests to reject candidate parent sets that violate invariance; thus can refute spurious proposed parents.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as part of the literature exploiting invariance across environments for robust causal discovery; ICP explicitly tests invariance to reject spurious predictors, but it requires access to observable candidate variables and is not directly applied in VCD which learns latent causal variables.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Variational Causal Dynamics: Discovering Modular World Models from Interventions', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e710.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e710.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SMS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sparse Mechanism Shift hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hypothesis that naturally occurring distribution shifts are typically sparse and localised changes in the causal generative process so that most causal mechanisms remain invariant across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Sparse Mechanism Shift (SMS) hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>SMS is not an algorithm but an inductive prior/hypothesis used to motivate modelling choices: that distributional changes across domains correspond to a small set of changed causal mechanisms, so learning should focus on models that allow sparse, localised mechanism changes.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Applied conceptually to multi-environment datasets including the multi-body simulation used in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>SMS frames the expectation about how environments differ (few mechanisms change), enabling modular adaptation strategies that only relearn a small subset of mechanisms when facing a new environment.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Provides an inductive bias to prefer models that attribute cross-environment differences to a few mechanisms rather than many spurious correlations; implemented in VCD via sparsity penalties and intervention masks.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Environment-specific noninvariant conditional mechanisms; explains why many correlations are stable and only a few change under interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Used as a core modelling assumption in VCD: by assuming sparse mechanism shifts, VCD can reuse most learned mechanisms across environments and only relearn those that changed, which yields sample-efficient adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Variational Causal Dynamics: Discovering Modular World Models from Interventions', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Differentiable causal discovery from interventional data <em>(Rating: 2)</em></li>
                <li>Invariant risk minimization <em>(Rating: 2)</em></li>
                <li>Causal inference using invariant prediction: identification and confidence intervals <em>(Rating: 2)</em></li>
                <li>Learning neural causal models from unknown interventions <em>(Rating: 1)</em></li>
                <li>Toward causal representation learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-710",
    "paper_id": "paper-249926970",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "VCD",
            "name_full": "Variational Causal Dynamics",
            "brief_description": "A latent world-model that jointly learns a representation and a causally factorised transition model by combining variational inference with differentiable causal discovery and sparsity regularisation to identify invariant mechanisms and sparse interventions across multiple environments.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Variational Causal Dynamics (VCD)",
            "method_description": "VCD is a latent state-space model whose transition probability is factorised across latent dimensions into independent one-dimensional conditional mechanisms (Independent Causal Mechanisms principle). It parameterises a probabilistic belief over a sparse causal adjacency matrix (Bernoulli entries with logits α) and per-environment intervention target masks (Bernoulli with logits β). The transition for variable i conditions only on its parents selected by a binary mask M_G (learned) and switches between a shared observational mechanism p^(0)_i and environment-specific interventional mechanism p^(k)_i according to R_I (learned). Training maximises an expected ELBO across environments plus sparsity penalties on expected number of edges and intervention targets; gradients through graph/intervention expectations are estimated using straight-through Gumbel-type sampling (Gumbel-Softmax / logistic trick) and reparameterisation for latent sampling. Separate small recurrent units per latent variable are used so each mechanism can model temporal context while preserving per-variable modularity. Adaptation to a new environment is performed by inferring the intervention mask R and refitting only the intervened mechanisms while reusing shared mechanisms.",
            "environment_name": "2-D multi-body simulated environment (mixed-state and image experiments)",
            "environment_description": "A controlled simulated multi-particle physics environment with four particles interacting via springs / electrostatic-like forces. Two observation modalities used: 'mixed-state' (affine-mixed ground-truth positions) and rendered RGB images (128x128x3). The environments include an undisturbed base environment plus multiple intervened environments (e.g., remove/strengthen springs, change masses, constrain particle axes). This is an interactive simulation in the sense that actions (external force on one particle) and interventions (environmental changes) are available, but VCD is trained from logged trajectories rather than performing active experiment selection.",
            "handles_distractors": true,
            "distractor_handling_technique": "Implicit handling via sparse causal factorisation and intervention modelling: (1) sparsity regularisation on graph edges and intervention targets (λ_G, λ_I) to discourage spurious edges; (2) independent mechanisms (per-latent conditional models) that prevent signal leakage across variables; (3) binary intervention masks that explain distribution shifts by switching to environment-specific mechanisms instead of changing many mechanisms globally, thereby attributing spurious correlations to localised interventions.",
            "spurious_signal_types": "Spurious / non-generalising correlations arising from pooling data across environments (i.e. distribution shifts / noninvariant conditional mechanisms), measurement/mixing in observations (entangled observation maps), and irrelevant entangled latent dimensions (entanglement does not generalise across interventions).",
            "detection_method": "Learns Bernoulli parameters β for intervention masks and α for graph edges via gradient-based optimisation of the expected ELBO across environments; detection of 'intervened' variables arises when describing an environment with environment-specific conditional p^(k)_i reduces ELBO (i.e. better explains data) while sparsity penalties keep number of interventions small. Gumbel/ logistic sampling (straight-through) is used to propagate gradients for discrete graph/intervention samples.",
            "downweighting_method": "Non-intervened mechanisms reuse a shared observational conditional p^(0)_i; by default the model 'downweights' environment-specific explanations for variables that can be re-used, enforced by sparsity penalties on R and by the ELBO/KL coupling which favour parsimonious explanations—this effectively reduces influence of spurious, environment-specific correlations by not allocating environment-specific parameters unless supported by data.",
            "refutation_method": "No explicit classical refutation test is used; model selection / refutation is effected via sparsity regularisation and likelihood (ELBO) comparison across models with/without edges or interventions: spurious edges/interventions are penalised (λ_G, λ_I), and the optimisation prefers minimal sets of mechanisms/interventions that explain multi-environment data, thereby implicitly refuting unnecessary causal links.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Qualitative and quantitative gains reported: VCD learns sparse causal graphs and causally meaningful latent axes, correctly identifies intervention targets in the mixed-state experiments, and substantially outperforms baselines (RSSM, MultiRSSM) in rollout error in the low-data adaptation regime. The paper reports VCD identified 42 edges (out of 288 possible) in mixed-state and 73 edges in the image experiment, and that it recovers all intervention targets in the mixed-state test; VCD can converge to a correct latent dimension encoding an intervened coordinate with as little as one trajectory.",
            "performance_without_robustness": "Baselines (RSSM with full parameter sharing and MultiRSSM with per-environment models) either capture averaged dynamics (RSSM) or overfit/no cross-environment reuse (MultiRSSM). They show higher rollout error and worse adaptation in low-data regimes; specific numeric metrics (e.g., SHD) are not reported for direct graph comparison except counts of discovered edges and qualitative correctness.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Joint training of representation and a sparse causal transition model yields causally meaningful, axis-aligned latent representations and sparse graphs; modelling interventions explicitly (sparse mechanism shift) enables identification of intervened mechanisms and modular adaptation, giving large gains in data efficiency for adapting to new environments. Sparsity regularisation and per-mechanism modularity are central to suppressing spurious cross-environment correlations.",
            "uuid": "e710.0",
            "source_info": {
                "paper_title": "Variational Causal Dynamics: Discovering Modular World Models from Interventions",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "DCDI",
            "name_full": "Differentiable Causal Discovery with Interventional Data",
            "brief_description": "A differentiable, continuous optimisation approach for causal discovery that learns a probabilistic belief (Bernoulli parameters) over DAG adjacency and over unknown intervention targets by maximising expected data likelihood under sparsity penalties and using differentiable sampling (Gumbel-Softmax/logistic tricks) to propagate gradients through discrete graph structures.",
            "citation_title": "Differentiable causal discovery from interventional data",
            "mention_or_use": "use",
            "method_name": "Differentiable Causal Discovery with Interventional Data (DCDI)",
            "method_description": "DCDI parameterises the adjacency matrix and intervention-target masks as independent Bernoulli random variables with logits α and β, and then optimises the expected log-likelihood of observed and interventional datasets under these discrete structures plus sparsity regularisation on expected edge/intervention counts. It uses continuous relaxations and straight-through style sampling (Gumbel-Softmax/logistic trick) to enable gradient-based optimisation over graphs and unknown interventions. Optionally enforces acyclicity constraints and parameterises conditionals with neural networks (score-based).",
            "environment_name": "General multi-environment / interventional datasets (applied within VCD to the simulated multi-body domain)",
            "environment_description": "Originally general framework applicable to tabular/low-dimensional variables with observational and interventional datasets; in this paper it is adopted inside a latent-variable ELBO training loop where causal variables are latent and observation mappings are learned.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Designed to handle changes across environments due to interventions (i.e., noninvariant mechanisms) and to disambiguate which conditional mechanisms changed, but not explicitly designed for unrelated distractor variables; relies on sparsity regularisation to avoid spurious edges.",
            "detection_method": "Infers intervention targets by optimising expected likelihood across environments and finding intervention masks R that explain inter-environment distribution differences, implemented via Bernoulli logits β and Gumbel/logistic sampling.",
            "downweighting_method": "Sparsity regularisation on expected number of edges and intervention targets penalises complex graphs and many interventions, thereby biasing the model away from explaining data via many spurious edges.",
            "refutation_method": "No explicit refutation tests; uses parsimony (sparsity penalties) and likelihood to rule out unnecessary edges/interventions.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Not reported in isolation within this paper; DCDI is used as a graph-learning backbone and shown to be effective when combined with VCD's latent modelling. Specific performance metrics for DCDI alone are not provided here.",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "DCDI's continuous probabilistic graph parameterisation and differentiable sampling techniques integrate well into a latent-variable ELBO framework, enabling joint learning of representation and causal structure from interventional datasets; sparsity priors are critical to avoid spurious connectivity.",
            "uuid": "e710.1",
            "source_info": {
                "paper_title": "Variational Causal Dynamics: Discovering Modular World Models from Interventions",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "IRM",
            "name_full": "Invariant Risk Minimization",
            "brief_description": "A class of methods that aim to learn predictors whose optimality is invariant across multiple environments, thereby isolating causal features and avoiding predictors that exploit spurious, environment-specific correlations.",
            "citation_title": "Invariant risk minimization",
            "mention_or_use": "mention",
            "method_name": "Invariant Risk Minimization (IRM) / invariant predictor methods",
            "method_description": "IRM formulates learning as seeking a data representation and classifier such that the optimal classifier on top of that representation is simultaneously optimal for all training environments; operationally it minimises empirical risk across environments together with a penalty encouraging invariance of classifier gradients. Variants and related invariant predictor methods learn stable features across environments and are used to identify and avoid using features that correspond to spurious correlations.",
            "environment_name": "General multi-environment / domain shift benchmarks; not used in VCD experiments here",
            "environment_description": "Designed for multi-environment datasets where spurious correlations vary across domains; typically not interactive—uses provided environment labels and datasets rather than active interventions.",
            "handles_distractors": null,
            "distractor_handling_technique": "Invariance principle: features that produce invariant optimal predictors across environments are preferred over features whose predictive power changes by environment, which downweights spurious environment-specific correlates.",
            "spurious_signal_types": "Confounding induced spurious correlations across environments and selection bias that lead to non-invariant predictors.",
            "detection_method": "Detects spurious features by testing stability/invariance of predictor performance or gradients across environments (penalty on environment-specific optimality violations).",
            "downweighting_method": "Penalises representations/predictors that rely on environment-specific features through an invariance regulariser, thus downweighting spurious signals in learned predictors.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Mentioned as a related line of work exploiting invariance across environments to avoid spurious predictors; differs from VCD in that IRM focuses on discriminative invariance for prediction rather than learning a generative causal world model and explicit per-mechanism interventions.",
            "uuid": "e710.2",
            "source_info": {
                "paper_title": "Variational Causal Dynamics: Discovering Modular World Models from Interventions",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "ICP",
            "name_full": "Invariant Causal Prediction",
            "brief_description": "A constraint-based approach which leverages invariance of conditional distributions across environments to identify causal parents by finding subsets of covariates whose conditional distribution of the target remains invariant across interventions/environments.",
            "citation_title": "Causal inference using invariant prediction: identification and confidence intervals",
            "mention_or_use": "mention",
            "method_name": "Invariant Causal Prediction (ICP)",
            "method_description": "ICP searches for subsets of covariates S such that the conditional distribution of the target given S is invariant across environments; under certain assumptions this identifies a set of causal parents. It often provides statistical tests and confidence intervals for parent inclusion by testing whether residuals are identically distributed across domains.",
            "environment_name": "General multi-environment observational/interventional datasets; not instantiated in this paper's experiments",
            "environment_description": "Operates on datasets with known environment labels (multiple domains); typically not an interactive experimental design method but usable when several environments / interventions are available.",
            "handles_distractors": null,
            "distractor_handling_technique": "By selecting covariates whose conditionals are invariant, ICP aims to exclude variables whose predictive relationship is environment-specific (distractors).",
            "spurious_signal_types": "Noninvariant predictors due to confounding, selection bias, or changing mechanisms across environments.",
            "detection_method": "Statistical tests for invariance of conditional distributions of the target given candidate parent sets across environments (e.g., tests on residuals).",
            "downweighting_method": null,
            "refutation_method": "Provides hypothesis tests to reject candidate parent sets that violate invariance; thus can refute spurious proposed parents.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Cited as part of the literature exploiting invariance across environments for robust causal discovery; ICP explicitly tests invariance to reject spurious predictors, but it requires access to observable candidate variables and is not directly applied in VCD which learns latent causal variables.",
            "uuid": "e710.3",
            "source_info": {
                "paper_title": "Variational Causal Dynamics: Discovering Modular World Models from Interventions",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "SMS",
            "name_full": "Sparse Mechanism Shift hypothesis",
            "brief_description": "A hypothesis that naturally occurring distribution shifts are typically sparse and localised changes in the causal generative process so that most causal mechanisms remain invariant across environments.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Sparse Mechanism Shift (SMS) hypothesis",
            "method_description": "SMS is not an algorithm but an inductive prior/hypothesis used to motivate modelling choices: that distributional changes across domains correspond to a small set of changed causal mechanisms, so learning should focus on models that allow sparse, localised mechanism changes.",
            "environment_name": "Applied conceptually to multi-environment datasets including the multi-body simulation used in this paper",
            "environment_description": "SMS frames the expectation about how environments differ (few mechanisms change), enabling modular adaptation strategies that only relearn a small subset of mechanisms when facing a new environment.",
            "handles_distractors": null,
            "distractor_handling_technique": "Provides an inductive bias to prefer models that attribute cross-environment differences to a few mechanisms rather than many spurious correlations; implemented in VCD via sparsity penalties and intervention masks.",
            "spurious_signal_types": "Environment-specific noninvariant conditional mechanisms; explains why many correlations are stable and only a few change under interventions.",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Used as a core modelling assumption in VCD: by assuming sparse mechanism shifts, VCD can reuse most learned mechanisms across environments and only relearn those that changed, which yields sample-efficient adaptation.",
            "uuid": "e710.4",
            "source_info": {
                "paper_title": "Variational Causal Dynamics: Discovering Modular World Models from Interventions",
                "publication_date_yy_mm": "2022-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Differentiable causal discovery from interventional data",
            "rating": 2,
            "sanitized_title": "differentiable_causal_discovery_from_interventional_data"
        },
        {
            "paper_title": "Invariant risk minimization",
            "rating": 2,
            "sanitized_title": "invariant_risk_minimization"
        },
        {
            "paper_title": "Causal inference using invariant prediction: identification and confidence intervals",
            "rating": 2,
            "sanitized_title": "causal_inference_using_invariant_prediction_identification_and_confidence_intervals"
        },
        {
            "paper_title": "Learning neural causal models from unknown interventions",
            "rating": 1,
            "sanitized_title": "learning_neural_causal_models_from_unknown_interventions"
        },
        {
            "paper_title": "Toward causal representation learning",
            "rating": 1,
            "sanitized_title": "toward_causal_representation_learning"
        }
    ],
    "cost": 0.0153005,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Variational Causal Dynamics: Discovering Modular World Models from Interventions
22 Jun 2022</p>
<p>Anson Lei 
Applied AI Lab University of Oxford
UK</p>
<p>Bernhard Schölkopf 
MPI for Intelligent Systems
TübingenGermany</p>
<p>Ingmar Posner ingmar@robots.ox.ac.uk 
Applied AI Lab University of Oxford
UK</p>
<p>Variational Causal Dynamics: Discovering Modular World Models from Interventions
22 Jun 202224FDE216D4F2B0DB32AF7A33C9C43F27arXiv:2206.11131v1[cs.LG]
Latent world models allow agents to reason about complex environments with high-dimensional observations.However, adapting to new environments and effectively leveraging previous knowledge remain significant challenges.We present variational causal dynamics (VCD), a structured world model that exploits the invariance of causal mechanisms across environments to achieve fast and modular adaptation.By causally factorising a transition model, VCD is able to identify reusable components across different environments.This is achieved by combining causal discovery and variational inference to learn a latent representation and transition model jointly in an unsupervised manner.Specifically, we optimise the evidence lower bound jointly over a representation model and a transition model structured as a causal graphical model.In evaluations on simulated environments with state and image observations, we show that VCD is able to successfully identify causal variables, and to discover consistent causal structures across different environments.Moreover, given a small number of observations in a previously unseen, intervened environment, VCD is able to identify the sparse changes in the dynamics and to adapt efficiently.In doing so, VCD significantly extends the capabilities of the current state-of-the-art in latent world models while also comparing favourably in terms of prediction accuracy.Preprint.Under review.</p>
<p>Introduction</p>
<p>The ability to adapt flexibly and efficiently to novel environments is one of the most distinctive and compelling features of the human mind.It has been suggested that humans do so by learning internal models which not only contain abstract representations of the world, but also encode generalisable, structural relationships within the environment [4].This latter aspect, it is conjectured, is what allows humans to adapt efficiently and selectively.Recent efforts have been made to mimic this kind of representation in machine learning.World models [e.g.12] aim to capture the dynamics of an environment by distilling past experience into a parametric predictive model.Advances in latent variable models have enabled the learning of world models in a compact latent space [12,30,14,8,35] from high-dimensional observations such as images.Whilst these models have enabled agents to act in complex environments via planning [e.g.14,26] or learning parametric policies [e.g.13,12], structurally adapting to changes in the environment remains a significant challenge.The consequence of this limitation is particularly pronounced when deploying learning agents to environments, where distribution shifts occur.As such, we argue that it is beneficial to Figure 1: Left: The general architecture of VCD.The dynamics model is trained using observation sequences from multiple environments by minimising the KL divergence between the predicted state distribution and the encoded posterior state distribution.Rollouts in the latent space can be performed by recursively applying the learnt transition model.Right: The structure of the causal transition model.Each dimension of the latent space is treated as a causal variable.Predictions are made using only the causal parents of each variable, according to a learnt causal graph.build structural world models that afford modular and efficient adaptation, and that causal modeling offers a tantalising prospect to discover such structure from observations.Causality plays a central role in understanding distribution changes, which can be modelled as causal interventions [25].The Sparse Mechanism Shift hypothesis [25,5] (SMS) states that naturally occurring shifts in the data distribution can be attributed to sparse and local changes in the causal generative process.This implies that many causal mechanisms remain invariant across domains [24,22,33].In this light, learning a causal model of the environment enables agents to reason about distribution shifts and to exploit the invariance of learnt causal mechanisms across different environments.Hence, we posit that world models with a causal structure can facilitate modular transfer of knowledge.To date, however, methods for causal discovery [27,21,23,7,17] require access to abstract causal variables to learn causal models from data.These are not typically available in the context of world model learning, where we wish to operate directly on high-dimensional observations.In order to benefit from the structure of causal models and the ability to represent high-dimensional observations, we propose Variational Causal Dynamics (VCD), which combines causal discovery with variational inference.Specifically, we train a latent state-space model with a structural transition model using variational inference and sparsity regularisation from causal discovery.By jointly training a representation and a transition model, VCD learns a causally factorised world model that can modularly adapt to different environments.The key intuition behind our approach is that, since sparse causal structures can only be discovered on abstract causal variables, training the representation and the causal discovery module in an end-to-end manner acts as an inductive bias that encourages causally meaningful representations.By leveraging the learnt causal structure, VCD is able to identify the sparse mechanism changes in the environment and re-learn only the intervened mechanisms.This enables fast and modular adaptation to changes in dynamics.</p>
<p>Related Work</p>
<p>Predictive models of the environment can be used to derive exploration- [26] or reward-driven [12,13,14] behaviours.In this paper, we focus on the learning of latent dynamics models.World models [12] train a representation encoder and a RNN-based transition model in a two-stage process.Other approaches [14,35,30] learn a generative model by jointly training the representation and the transition via variational inference.PlaNet [14] parameterises the transition model with RNNs.E2C [30,3] and SOLAR [35] use locally-linear transition models, arguing that including constraints in the dynamics model yields structured latent spaces that are suitable for control problems.Our proposed approach shares the general principle that latent representations can be shaped by structured transition mechanisms [1].However, to the best of our knowledge, VCD is the first approach that implements a causal transition model given high-dimensional inputs.</p>
<p>Causal discovery methods enable the learning of causal structure from data.Approaches can be categorised as constraint-based (e.g.[27]) and score-based (e.g.[15]).The reader is referred to [23] for a detailed review of causal discovery methods.Motivated by the fact that these methods require access to abstract causal variables, recent efforts have been made to reconcile machine learning, which has the ability to operate on low-level data, and causality [25].Our current work situates within this broader context of causal representation learning, and aims to identify causally meaningful representations via the discovery of causal transition dynamics.To this end, [20] proposes a similar framework to ours and provide a theoretical discussion around the identifiability of causal variables.Our approach differs in that we focus on the adaptation capabilities of causal models and show that the method is applicable to image observations.Another branch of related work leverages the invariance of causal mechanisms by learning invariant predictors across environments [28,24,22,34,2].This invariance has been studied in the context of state abstractions in MDPs [32], and invariant policies can be learnt via imitation learning from different environments [6].In contrast, our approach models the full generative process of the data across different environments rather than learning discriminative predictors.</p>
<p>Background</p>
<p>This section describes the prerequisite definitions and formulations for our proposed method.We highlight the strengths and weaknesses of latent state-space models, causal models and causal discovery methods, and motivate our approach that builds upon these to learn causal world models.</p>
<p>Latent state-space models In a complex environment with high-dimensional observations, such as images, learning a compact latent state space that captures the dynamics of the environment has been shown to be more computationally efficient than learning predictions directly in the observation space [14,8].Given a dataset of sequences {(o 0:T , a 0:T i )} N i=01 , with observations o t and actions a t at discrete timesteps t, a generative model of the observations can be defined using latent states z 0:T as
p(o 0:T , a 0:T ) = T t=0 p θ (o t |z t )p(a t |z t )p θ (z t |z t−1 , a t−1 )dz 0:T ,(1)
where p θ (o t |z t ) and p θ (z t |z t−1 , a t−1 ) are the observation model and the transition model respectively.</p>
<p>For simplicity, we do not learn the policy term p(a t |z t ) and omit it throughout this paper as it is constant with respect to the parameter θ.The variational evidence lower bound can be written as
ELBO(θ, φ) = T t=0 E q φ (z t |o t ) log(p θ (o t |z t )) − E q φ (z t−1 |o t−1 ) KL[q φ (z t |o t )||p θ (z t |z t−1 , a t−1 )] ,
(2) where q φ (z t |o t ) is a learnable approximate posterior of the observations.See Appendix A for the derivation.RSSM [14] employs a flexible transition model parameterised as a fully connected recurrent neural network, where the transition probability is split into a stochastic part and a deterministic recurrent part,
z t ∼ p θ (z t |h t ), h t = f θ (h t−1 , z t−1 , a t−1 ),(3)
where f (•) is instantiated as a GRU [9] and h t is the associated hidden state.Intuitively, this provides a path through which information can be passed on over multiple timesteps.</p>
<p>Despite their success, these models cannot reason about changes in the environment.Specifically, they are unable to structurally utilise prior knowledge learnt from different environments under distribution shift.To this end, we argue that imposing a causal structure on the transition model equips the learning agent with the ability to adapt to changes in a modular and efficient manner.</p>
<p>Causal graphical models A causal graphical model (CGM) [23] is defined as a set of random variables {X 1 , ..., X d }, their joint distribution P X , and a directed acyclic graph (DAG), G = (X, E), where each edge (i, j) ∈ E implies that X i is a direct cause of X j .The joint distribution admits a causal factorisation such that where P A i is the set of parents to the variable X i in the graph.Each of the conditional distributions can be considered as an independent causal mechanism.
p(x 1 , ..., x d ) = d i=0 p(x i |P A i ),(4)
In contrast to standard graphical models, CGMs support the notion of interventions, i.e., local changes in the causal distribution.Formally, an intervention on the variable X i is modelled as replacing the conditional distribution p(x i |P A i ) while leaving the other mechanisms unchanged.</p>
<p>Given the set of intervention targets I ⊂ X, the interventional distribution can be written as
p (x 1 , ..., x d ) = i ∈I p(x i |P A i ) i∈I p (x i |P A i ),(5)
where p (•|•) is the new conditional distribution corresponding to the intervention.The SMS hypothesis [25] posits that naturally occurring distribution shifts tend to correspond to sparse changes in a causal model when factorized as (4), i.e., changes of a few mechanisms only.Causal mechanisms thus tend to be invariant across environments [24,22,34].In this light, we argue that a causal world model can structurally leverage the invariance within distribution shifts as an inductive prior.In order to learn a causal model in the context of world models, we draw inspiration from recent advances in causal discovery which aim to learn causal structures from data.</p>
<p>Differentiable causal discovery We focus on methods that formulate causal discovery as a continuous optimisation problem [7,17,5] as these can be naturally incorporated into the variational inference framework.Furthermore, since the causal variables are learnt in our model, the causal discovery module is required to learn causal graphs from unknown intervention targets.In this work, we follow the formulation in Differentiable Causal Discovery with Interventional data [7] (DCDI), which optimises a continuously parameterised probabilistic belief over graph structures and intervention targets.See Appendix B for further detail.</p>
<p>In the context of learning world models from high-dimensional observations, the drawback of this approach, and of causal discovery methods in general, is that it requires access to semantically meaningful causal variables, much like classical AI required symbols in terms of which algorithms could be formulated.In the next section, we present a method to perform causal discovery and learn causally meaningful representations jointly.</p>
<p>Variational Causal Dynamics</p>
<p>Similar to causal discovery with interventional data, variational causal dynamics (VCD) learns from action-observation sequences from an undisturbed environment, (o 0:T (0) , a o:T (0) ), and K intervened environments, {(o 0:T (k) , a 0:T (k) )} K k=1 .Throughout this paper, we assume that 1) changes between the environments are due to 'soft' interventions where the structure of the causal graphs remains the same but individual parameters of the mechanisms change, 2) there are no instantaneous causal dependencies in each timestep, and 3) the observation function does not change across environments.</p>
<p>The general approach of VCD follows the latent state-space model framework (Fig. 2a), where a latent representation of the observations is jointly learnt with a transition model by maximising the ELBO.In contrast to existing approaches that parameterise the transition probability p(z t |z t−1 , a t−1 ) as a feedforward neural network (Fig. 2b), VCD learns a causal transition model by utilising inductive biases from causal discovery.Importantly, our approach is grounded in the hypothesis that causal structures can only be discovered on semantically meaningful causal representations of the system.We therefore argue that training a representation and a transition model jointly to optimise a causal discovery objective can lead to a latent representation that affords causal transition models and is therefore semantically meaningful. 2 Taking the view that changes in the dynamics can be attributed to sparse causal interventions, we posit that a causally factorised transition model facilitates modular adaptation to new environments by explicitly leveraging the invariance of causal mechanisms.We propose an algorithm for such adaptation in Section 4.4.</p>
<p>Causal transition model</p>
<p>In order to perform causal discovery on the transition dynamics, the transition model in VCD is designed to mimic the structure of a CGM (Eq.5).In the following paragraphs, we motivate and describe the three main architectural features of VCD that enable causal discovery: independent mechanisms, sparse causal dependencies and sparse interventions.Access to the causal graph G and the intervention targets for each environment I k is assumed throughout this subsection.We describe the method of learning these jointly with the model in Section 4.3.</p>
<p>Independent mechanisms</p>
<p>In contrast to a fully-connected transition model, the transition probability is factorised into individual conditional distribution as
p(z t |z t−1 , a t−1 ) = d i p i (z t i |z t−1 , a t−1 ), (6)
where d is the dimension of the latent space, to be set as a hyperparameter.z i denotes the ith dimension of the latent state, and each conditional distribution p i is a one-dimensional normal distribution with mean and variance given by separate neural networks.This factorisation and separation of parameters is motivated by the Independent Causal Mechanism principle, which states that the causal generative process of a system's variables is composed of autonomous modules that do not inform or influence each other [25].This explicit modularity of the model structure enables the notion of interventions, where individual conditional distributions are locally changed without affecting the other mechanisms.</p>
<p>Sparse causal dependencies Following the structure of a CGM, we condition each variable only on its causal parents according to the learnable causal graph G, rather than the full state.Given a graph G, we define the binary adjacency mask M G where the entry
M G ij is 1 if and only if [z t−1 , a t−1 ] i is a causal parent of z t j
. This is consistent with the intuition that, in physical systems, states interact with each other in a sparse manner [11], and actions tend to have a direct effect on only a subset of the states.Under this parameterisation, the causal transition probability can be written as
p(z t |z t−1 , a t−1 ) = d i p i (z t i |M G i [z t−1 , a t−1 ]),(7)
where denotes the element-wise product, [•, •] denotes the concatenation of vectors, and M G i is the binary mask that selects only the causal parents of z i under the graph G. [25], we assume that changes in distributions across the K intervened environments are due to sparse interventions in the ground truth causal generative process.In order to incorporate sparse interventions in VCD, given the set of learnt intervention targets I k for each environment, we define the binary intervention mask R I where the entry R I ki is 1 if and only if the variable z i is in the set of intervention targets in environment k.For each variable z i , R I ki acts as a switch between reusing a shared observational model and an environment-specific interventional model.The full interventional causal model of the transition probability in the environment k can be written as</p>
<p>Sparse interventions Following the SMS hypothesis
p k (z t |z t−1 , a t−1 ) = d i p (0) i (z t i |M G i [z t−1 , a t−1 ]) 1−R I ki p (k) i (z t i |M G i [z t−1 , a t−1 ]) R I ki ,(8)
where p (0) is the observational mechanism that is shared across all environments and p (k) is the intervened distribution specific to environment k.Intuitively, this model ensures that all environments reuse the same conditional distributions p obs unless it is deemed that a particular mechanism has been intervened on (i.e.R I ki = 1).This modular adaptation between environments facilitates structural transfer of knowledge between different environments.Note that the structure is that of a causal graphical model.The overall architecture of the VCD transition model is summarised in Fig. 2c.</p>
<p>Recurrent module</p>
<p>Similar to RSSM [14], we augment the model with a deterministic recurrent path to enable long-term predictions.To ensure that each conditional distribution only has access to the causal parents, in the same way that each conditional distribution is modelled by a separate network, each conditional distribution keeps a separate recurrent unit and a corresponding hidden activation:
z t i ∼ p i (z t i |h t i ), h t i = f i (h t−1 i , M G i [z t−1 i , a t−1 i ]),(9)
where f i is a recurrent module specific to the variable z i , instantiated as a GRU [9].</p>
<p>Training</p>
<p>The task of model training is to determine the model parameters θ, the approximate posterior parameters φ, as well as the causal graph G and the intervention targets I.These can be jointly trained in a way similar to DCDI.We parameterise the belief over the causal adjacency matrix M G as a random binary matrix.Each entry M G ij follows a Bernoulli distribution with success probability σ(α ij ), where α ij is a scalar parameter and σ(•) is the sigmoid function.Similarly, a random binary matrix R I is parameterised using the scalar variable β ki for each entry.Unlike DCDI, due to the existence of latent variables, we cannot directly maximise the data likelihood.Instead, we maximise the expected ELBO across all environments over causal graphs and intervention masks,
L(θ, φ, α, β) = k∈[0,1,...,K] E G,I ELBO(o 0:T (k) , a 0:T (k) ; θ, φ, G, I) − λ G |G| − λ I |I| ,(10)
where
ELBO(o 0:T (k) , a 0:T (k) ; θ, φ, G, I) = T t=0 E q φ (z t |o t ) p θ (o t |z t ) − E q φ (z t−1 |o t−1 ) KL[q φ (z t |o t )||p (k) θ (z t |z t−1 , a t−1 )] .(11) p (k)
θ (z t |z t−1 , a t−1 ) is further factorised as in Equation (8).The gradients through the outer expectation and the expectation term in ELBO are estimated using the straight-through Gumbel-max trick [16] and the reparameterisation trick [18] respectively.For further implementation details, derivation of the lower bound, and model architectures, see Appendices A and B.</p>
<p>Adaptation</p>
<p>Due to the modular nature of the transition model, VCD can naturally adapt to new, unseen environments by jointly inferring the intervention targets and the new model parameters for the intervened mechanisms.Specifically, the transition model in a new environment can be written as
p new (z t |z t−1 , a t−1 ) = i p (0) i (z t i |M G i [z t−1 , a t−1 ]) 1−R i p i (z t i |M G i [z t−1 , a t−1 ]) R i , (12)
where R is the intervention mask for the new environment and p i is the environment-specific distribution.The parameters of p (0)</p>
<p>i are carried over from the training environments, meaning that the model reuses trained mechanisms unless the variable is intervened on in the new environment.Under the SMS hypothesis, only a small subset of the mechanisms need to be adapted in a new environment.As such, by leveraging past experience, VCD can adapt more quickly to environment change.</p>
<p>One way to implement modular transfer is to train VCD on trajectories in the new environment while reusing the trained parameters for the causal graph and the mechanisms in the undisturbed environment.This can be done by identifying the set of intervention targets in the new environment I and learning the model parameters for the corresponding conditional distributions θ .These can be jointly trained in an analogous way to Eq. 10,
L adapt (θ , β ) = E G,I ELBO(o new 0:T , a new 0:T ; θ , φ, G, I ) − λ I |I | ,(13)
where β are the Bernoulli parameters for the distribution over intervention targets.Under this framework, VCD has the capability to identify the sparse mechanism changes in a new environment and learn the transition mechanisms only for the intervened variables.In Section 5, we show that VCD can identify sparse interventions from a small amount of data and is able to refit the world model with less data than baseline approaches.</p>
<p>Experiments</p>
<p>In this section, we demonstrate that VCD is able to learn from multiple environments with different dynamics by learning a causal world model that explicitly captures the changes between the environments as interventions.We evaluate, qualitatively and quantitatively, the learnt representations and causal structures and show that VCD is able to capture the dynamics of the scene using sparse dependencies between states, as well as identify sparse changes between the environments.Moreover, we illustrate that, in an unseen environment, VCD can leverage past experience to perform modular adaptation, resulting in significantly improved data efficiency over the baselines.Dataset We evaluate VCD on a simulated dataset of a 2-D multi-body system which contains four particles that affect each other via a spring or an electrostatic-like force.The configuration of the environment is shown in Fig. 3.The action a ∈ R 2 is an external force that applies to particle 4. The environment is designed such that there is an unambiguous ground-truth causal graph between the causal variables and well-defined changes in the dynamics.We consider changes such as strengthening or removing one of the springs, increasing or decreasing the mass of a particle, or constraining the position of a particle along the x or the y axis.Each of these changes can be considered as an intervention on one or more causal variables.See Appendix C for further details of the environment and the full list of interventions.We evaluate VCD in two experiments: Mixed-state, where the observation is given by applying an affine transformation to the ground-truth positions of the particles, and Image, where the observation is given by rendering the environment as a RGB image.</p>
<p>Baselines We compare the performance of VCD against RSSM [14], a state-of-the-art latent world model that served as inspiration for VCD.As RSSM does not support learning from multiple environments, we consider two adaptations of RSSM with different levels of knowledge transfer between environments: (1) RSSM, where one transition model is trained over all environments, i.e., maximum parameter sharing across environments; and (2) MultiRSSM, where individual transition models are trained on each environment, with shared encoders and decoders.This corresponds to the case where no knowledge about dynamics is transferred, i.e., each model is a local expert.We hypothesise that, compared to these two extremes of knowledge sharing, VCD is able to capture environment-specific behaviours whilst reusing invariant mechanisms via modular transfer.</p>
<p>Prediction performance VCD and the baselines are trained on a dataset composed of 2000 trajectories from each of the undisturbed environment and five intervened environments.The models are evaluated on trajectories from a validation set drawn from the training environments.Fig. 4 shows the rollout error for each of the models with state and image observations.Unlike VCD and MultiRSSM, RSSM can only capture the average dynamics of the environments due to parameter sharing.As such, it is not able to capture environment-specific behaviours.This is reflected in the prediction accuracy of the model.In the mixed-state experiment, VCD is able to identify changes between the environments and performs as well as MultiRSSM in terms of prediction error.A similar trend is shown in the image space, where VCD outperforms the baselines. 3See Appendix D for image rollout examples that demonstrate the difference in behaviour between RSSM and VCD.</p>
<p>Causal discovery One of the key hypotheses of this work is that jointly learning a representation and a transition model using causal discovery leads to causally meaningful representations.Here we examine the quality of the learnt latent space and the causal structure of the transition model.Fig. 5 shows the image reconstructions of points drawn from a straight line along dimension 6 of the latent space.Since both models are initialised with the same encoder, this provides a qualitative intuition as to how the causal discovery inductive bias shapes the latent space.Whilst this dimension of the latent space in RSSM is able to encode only the blue particle, VCD is able to learn an axisaligned coordinate (x coordinate) of the blue particle with respect to the environment.Note that the motion of bouncing off the boundaries is only separable in the x, y frame, implying that the dynamics in axis-aligned coordinates is sparser.We present a quantitative analysis of the learnt causal representation in the mixed-state environment in Appendix D. As desired, the learnt causal graphs in both the mixed-state and the image environment are found to be sparse.</p>
<p>Adaptation We provide empirical evidence that VCD can adapt to a new environment with less data compared to RSSM and MultiRSSM by reusing learnt mechanisms in a modular fashion.We collect datasets of different sizes in a previously unseen intervened environment where particle 1 is RSSM VCD along dimension 6  VCD is able to reuse most of the previously learnt mechanisms, as indicated by the sparsity in the learnt intervention targets.In the mixed-state, we verify that the learnt intervention target (dimension 8) corresponds to the ground-truth target (y 1 ), see Appendix D.</p>
<p>constrained horizontally.RSSM and MultiRSSM adapt to the new environment by optimizing the ELBO (Eq.2), with the difference that MultiRSSM instantiates a new transition model randomly and RSSM initialises the transition model using pre-trained parameters.Following Eq. 13, VCD performs adaptation by jointly estimating the intervention targets and the parameters of the intervened mechanisms.The models are evaluated on a validation set of trajectories in the new environment.Fig. 6 shows the rollout error of the models trained on datasets of varying size.Across all models, performance improves as the dataset grows.However, in contrast to RSSM and MultiRSSM, which overfits the dataset when the number of trajectories is small, VCD is able to predict significantly more accurately.This is because VCD estimates the intervention targets and reuses trained modules that remain invariant.Remarkably, in the mixed-state experiment, VCD is able to converge to a single latent dimension that encodes the y position of particle 1 with just one training trajectory.See Appendix E for more experiments with different interventions.</p>
<p>Conclusion</p>
<p>In this paper, we propose VCD, a predictive world model with a causal structure that is able to consume high-dimensional observations.This is achieved by jointly training a representation and a causally structured transition model using a modified causal discovery objective.In doing so, VCD is able to identify causally meaningful representations of the observations and discover sparse relationships in the dynamics of the system.By leveraging the invariance of causal mechanisms, VCD is able to adapt to new environments efficiently by identifying relevant mechanism changes and updating in a modular way, resulting in significantly improved data efficiency.One exciting avenue of future research is to explore the synergy between causal world models and object-centric generative models [31,10,29].</p>
<p>Societal Impact While the present work significantly advances the current state-of-the-art in world-modelling and causal representation learning, we expect its immediate impact outside of the machine learning community to be low as current methods can not yet deal effectively with real-world scenarios.</p>
<p>A Derivations</p>
<p>Using the approximate posterior q(z 0:T |o 0:T , a 0:T ) = t q(z t |o t ), the variational log lower bound for the latent state-space model (Eq.2) can be derived from importance weighting and Jensen's inequality:
log p(o 0:T , a 0:T ) = log T t=0 p(o t |z t )p(a t |z t )p(z t |z t−1 , a t−1 )dz 0:T (14) = log T 0 p(o t |z t )p(a t |z t ) t |z t−1 , a t−1 ) q(z t |o t ) q(z t |o t )dz 0:T (15) ≥E q(z t |o t ) log T o p(o t |z t )p(a t |z t ) p(z t |z t−1 , a t−1 ) q(z t |o t ) (16) = T 0 E q(z t |o t ) log p(o t |z t ) + log p(a t |z t ) + E q(z t−1 |o t−1 ) E q(z t |o t ) log p(z t |z t−1 , a t−1 ) − log p(z t |o t )(17)= T 0 E q(z t |o t ) log p(o t |z t ) + log p(a t |z t ) − E q(z t−1 |o t−1 ) KL q(z t |o t )||p(z t |z t−1 , a t−1 ) . (18)
Since the policy p(a t |z t ) is constant with respect to the model parameters, we omit this term and write the ELBO objective as
ELBO(θ, φ) = T t=0 E q φ (z t |o t ) log(p θ (o t |z t )) − E q φ (z t−1 |o t−1 ) KL[q φ (z t |o t )||p θ (z t |z t−1 , a t−1 )] , (19)
where θ is the model parameter and φ is the parameter for the approximate posterior.θ and φ are omitted henceforth to simplify notation.In VCD, the KL divergence term can be further decomposed by exploiting the structure of the transition model (Eq.8), and the assumption that variables within each timestep are independent:
KL q(z t |o t )||p (k) (z t |z t−1 , a t−1 ) (20) = − log p (k) (z t |z t−1 , a t−1 ) q(z t |o t ) q(z t |o t )dz t (21) = − d i=0 log p (0) i (z t i |M G i [z t−1 , a t−1 ]) 1−R I ki p (k) i (z t i |M G i [z t−1 , a t−1 ]) R I ki q(z t i |o t ) q(z t i |o t )dz t i (22) = − d 0 (1 − R I ki ) log p (0) i (z t i |M G i [z t−1 , a t−1 ] q(z t i |o t ) q(z t i |o t )dz t i + R I ki log p (k) i (z t i |M G i [z t−1 , a t−1 ]) q(z t i |o t ) q(z t i |o t )dz t i (23) = − d 0 (1 − R I ki )KL q(z t i |o t )||p (0) i (z t i |M G i [z t−1 , a t−1 ]) + R I ki KL q(z t i |o t )||p (k) i (z t i |M G i [z t−1 , a t−1 ]) . (24)
The KL terms can be computed analytically since the conditional distributions in the last expression are univariate Gaussian distributions.In training time, the gradients through the expectation terms in the ELBO is estimated by drawing a sample from the posterior distribution using the reparameterisation trick [18].</p>
<p>B Implementation Detail</p>
<p>B.1 DCDI and Graph Learning</p>
<p>This section covers the formulation of DCDI [7] and the graph learning method.These are subsequently used in the learning of VCD.</p>
<p>Given samples from an observed data distribution P (0) X and K intervened distributions P (k)</p>
<p>X , DCDI optimises a probabilistic belief over causal graphs G and intervention targets I. Specifically, these are encoded as random binary matrices, MG and RI, where M G ij = 1 implies that the edge (i, j) is in the causal graph, and R I ki = 1 implies that the variable xi is in the intervention targets in environment k.Each entry in M G follows an independent Bernoulli distribution, parameterised by matrix α where P (M G ij = 1) = σ(αij).R I ki is similarly parameterised by β.Under this parameterisation, causal discovery can be formulated as maximising the expected data log likelihood with sparsity regularisation,
L(θ, α, β) = E α,β K k=0 log[p (k) θ (x k 1 , ..., x k d ; G, I)] − λG|G| − λI |I| ,(25)
where p (k) is the data likelihood under causal graph G and intervention targets I in the kth environment, as factorised in eq.( 5).The conditional distributions are parameterised as feedforward neural networks with parameter θ; λG,I are hyperparameters to control sparsity.In the original DCDI framework, this is also subject to an acyclicity constraint.However, this is not neccessary in the context of our work as we assume there are no instantaneous causal effects (i.e., within a timestep).</p>
<p>The training objective for VCD can be viewed as a modified version of the DCDI objective, where the likelihood term is replaced with the ELBO (Eq.19),
L V CD (θ, φ, α, β) = E α,β K k=0 T t=0 ELBO(θ, φ; G, I) − λG|G| − λI |I| ,(26)
Note that the expected number of edges in G and I given α and β is simply the sum of the probability of each entry being one.Therefore, the training objective can be computed as:
L V CD (θ, φ, α, β) = E α,β K k=0 T t=0 ELBO(θ, φ; G, I) − λG ij σ(αij) − λI ki σ(β ki ).(27)
The gradients through the outer expectation can be estimated using the Gumbel-Softmax trick [16].To implement this, the ELBO term is evaluated with a sample of the causal graph using the following expression for each entry,
M G ij = I(σ(αij + Lij) &gt; 0.5) + σ(αij + Lij) − stop_gradient(σ(αij + Lij)),(28)
where I(•) is the indicator function, Lij is a sample from the logistic distribution, and stop_gradient is a function that does not change the value of the argument but sets the gradient to zero.Samples for the intervention targets are similarly acquired.Note that the sample is used throughout each trajectory, i.e. the same sample graph and intervention targets are used for all of T timesteps.</p>
<p>B.2 Model Architecture</p>
<p>Mixed-state In the mixed-state experiment, all conditional distributions (including encoders, decoders and transition models) are parameterised by feedforward MLPs with two hidden layers of 64 hidden units each.The recurrent modules are implemented as GRUs [9] with 64 hidden units.Distributions in the latent space are 16-dimensional diagonal Gaussian distributions with predicted mean and log variance.</p>
<p>Image In the image experiment, the encoders and decoders are parameterised as convolutional and deconvolu- tional networks from [12].In the RSSM models, the transition models are parameterised as feedforward MLPs with two hidden layers of 300 hidden units.The recurrent module is a GRU with 300 hidden units.In VCD, to compensate for the fact each dimension in the latent space has a separate model, the number of hidden units in the GRU and MLP are reduced to 32 to avoid over-parameterisation.We found that initialising the encoders and decoders by pretraining them as a variational autoencoder helped with training stability for both RSSM and VCD.</p>
<p>In both experiments, the training objective is maximised using the ADAM optimiser [19] with learning rate 10 −3 for mixed-state, and 10 −4 for images.In both environments, we clip the log variance to −3, with a batch size of two trajectories from each of six environments with T = 50.In VCD, the hyperparameters λG, λI are both set to 0.01.All models are trained on a single Nvidia Tesla V100 GPU.</p>
<p>C Experiment Detail</p>
<p>Interventions The ground truth states of the multi-body dynamics environment is the x and y coordinates of each particle.The full list of possible interventions on the environment is provided in Table 1.Note that the forces between particle 1, 3 and 4 are proportional to their masses.Hence intervening on the mass of particle 1 and 3 also affect the dynamics of particle 4. In the experiments, all models are trained in the undisturbed environment and intervened environments 1, 5, 11, 14, 17.Remove spring between 2 and 3 x 2 , y 2 , x 3 , y 3 3</p>
<p>Increase mass 1 In the mixed-state experiment, the observation function is a mixing matrix where each entry is drawn from a unit Gaussian distribution.In the image experiment, the observation is given by rendering the system to a 128 × 128 × 3 image.In both experiments, the models are trained on a training set of 2000 trajectories from each of the six environments and evaluated on a validation set of 400 unseen trajectories.</p>
<p>D Qualitative Exploration for Learnt Causal Structure D.1 Rollout prediction</p>
<p>Section 5 shows the rollout accuracy of the baselines and VCD.Here we demonstrate qualitatively that VCD is able to capture environment-specific behaviours that RSSM cannot learn due to maximal parameter sharing.Figure 7 shows sample rollouts in the image space from RSSM and VCD in intervened environment 11, i.e. the yellow particle is constrained horizontally and only moves vertically.The yellow particle in the VCD rollout stays along a vertical line whereas RSSM fails to capture this environment-specific constraint.</p>
<p>D.2 Representation quality</p>
<p>In this subsection, we explore the quality of the learnt latent space.The key hypothesis of our work is that training the representation jointly with the transition model to maximise a causal discovery objective serves as an inductive bias that helps to structure the latent space in a causally meaningful way.</p>
<p>Mixed-state Since the observation mixing function is linear and invertable in the mixed-state environment, we can directly access the level of disentanglement of the latent space with respect to the ground-truth state of the environment, i.e. the x and y coordinate of the particles.Fig. 8 shows the average magnitude of the entries of the Jacobian matrix between the ground-truth state and the learnt latent state.Each entry measures the changes in each ground-truth state variable when the latent representation is perturbed along each dimension.By using the discovery of causal transition models as an inductive bias, VCD is able to learn a disentangled representation where each ground-truth state is captured by only one latent dimension.In contrast, RSSM learns a representation that is not sparse.</p>
<p>Image The quality of the learnt representation is discussed in Section 5.Here we show reconstruction samples along all dimensions of the latent space in the RSSM and VCD representation.Note that since both encoders are initialised from the same pretrained VAE, the difference in the latent space arise because of the causal discovery objective in VCD.Fig. 12 shows the changes in the reconstruction when the RSSM representation is perturbed in each dimension of the latent space.Fig. 11 shows the same for VCD.As discussed in the main text, VCD learns a axis-aligned representation that affords a sparse causal graph.For example, dimension 1 and 3 captures the y and x coordinates of the green particle respectively.In contrast, RSSM learns a representation that is not axis-aligned.</p>
<p>D.3 Learnt causal graphs and intervention targets</p>
<p>In this subsection, we explore the quality of the learnt causal graph and intervention targets.Fig. 9 shows the learnt causal graphs for the mixed-state and image experiments.Fig. 10 shows the learnt intervention targets for each environment.The sparsity of the learnt graph and targets is summarised in  Mixed-state In the mixed-state experiments, each ground-truth state can be mapped to a latent dimension using the average magnitude Jacobian matrix (Fig. 8).We use this mapping to compare the learnt causal graph with the ground truth causal structure of the environment and report the number of correctly identified edges.Table 2 summarises the quality of the learnt graph.VCD is able to identify a majority of the correct causal dependencies and all of the intervention targets.Upon further inspection of the learnt causal graph, we find that all of the seven missed edges correspond to the 1/||δx|| 2 terms that scale the electrostatic-like forces.We hypothesise that the model cannot capture these dependencies as they are not as significant as the other forces.</p>
<p>Image In the image space, it is not trivial to obtain a way to map each of the ground-truth state to a latent dimension.Instead, we qualitatively explore the learnt causal relationships.Focusing on dimension 3, for example, which encodes the x coordinate of the green particle, the ground-truth causal parents of this variable is the x coordinates of the yellow and the blue particles.In the learnt causal graph, on column three, the learnt causal parents are dimensions 3, 6, 8, 14 and 15.The visualisation of the latent space (Fig. 11) suggests that dimensions 6 and 8 captures the x coordinates of the yellow and blue particles respectively, meaning that VCD has learnt the correct causal parents.</p>
<p>A similar analysis can be carried out on the intervention targets.Focusing on intervened environment 0, for example, the learnt intervention targets are dimension 1, 2, 3, 7, 8, 11, 13, 15.The ground-truth intervention ID is 1, i.e. the intervention targets are x, y coordinates of the yellow and green particles (see.table 1).By inspecting the VCD latent space (Fig. 11), dimensions 1 and 3 encodes the position of the green particle and dimensions 7, 8 and 11 encodes the position of the yellow particle.This shows that VCD is able to identify the changes in the environments.</p>
<p>In summary, while VCD identifies some false positive edges, it is able to capture the causal parents and the intervention targets in each environment.</p>
<p>E Further Experiments</p>
<p>This section provides extra adaptation experiment results similar to Fig. 6 in the main text, where the models adapt to intervention number 12 (see table 1).We present experiment results for adaptation to different types of interventions (intervention numbers 4, 9, 13).Fig 13,14 and 15 show the adaptation plots.The results exhibit a consistent pattern where VCD significantly outperforms the baselines in the low data regime by identifying sparse mechanism changes.</p>
<p>Figure 3 :
3
Figure 3: The configuration of the multi-body environment.The red and the blue lines represent an attractive and repulsive force respectively.</p>
<p>Figure 4 :
4
Figure 4: The rollout error measured on validation trajectories.The models receive observations on each timestep for the first half of each trajectory (shaded), after which the model is rolled out based on latent predictions.The reported error in the mixed-state environment (left) and the image environment (right) are squared error in the ground-truth state space and squared error in pixel values respectively.VCD outperforms the baselines in both modes of observation.</p>
<p>Figure 5 :
5
Figure 5: Reconstructed images from points sampled along dimension 6 of the latent space.Compared to the latent space learnt in RSSM, VCD is able to learn an axis-aligned representation where the blue particle moves horizontally.See Appendix D for more examples.</p>
<p>Figure 6 :
6
Figure 6: Rollout errors in the mixed-state and image experiments where the models are trained on datasets of varying sizes.The models receive observations for the first half of the trajectory (shaded), and perform latent space prediction for the rest.VCD significantly outperforms the other models with little data.The bar below each plot shows the learnt intervention targets in the new environment.VCD is able to reuse most of the previously learnt mechanisms, as indicated by the sparsity in the learnt intervention targets.In the mixed-state, we verify that the learnt intervention target (dimension 8) corresponds to the ground-truth target (y 1 ), see Appendix D.</p>
<p>x 1 , y 1 , x 4 x 3 Figure 7 :
11437
Figure 7: Sample rollouts from an intervened environment.VCD successfully captures the constraint on the yellow particle (vertical movement only) over a long time horizon.</p>
<p>Figure 8 :
8
Figure8: The average magnitude of the derivative of the ground-truth states x i w.r.t. the learnt latent states z j .VCD is able to learn a latent representation where each dimension captures information about one state only, i.e.only one state variable changes when we perturb the latent representation along one dimension.On the other hand, the RSSM latent space encodes state information in a more entangled manner, i.e. multiple ground-truth states are affected when the latent representation is perturbed in one dimension.</p>
<p>Figure 9 :Figure 10 :
910
Figure9: The learnt causal graphs for the mixed-state and image experiments, obtained by binarising the learnt edge probabilities such that a blue square at (i, j) implies σ(α ij ) &gt; 0.5, i.e. i is a causal parent of j.</p>
<p>Figure 11 :
11
Figure 11: Visualisation of the learnt latent space in VCD.18</p>
<p>Figure 12 :
12
Figure 12: Visualisation of the learnt latent space in RSSM.19</p>
<p>Figure 13 :
13
Figure 13: Adaptation results for intervention 4.</p>
<p>Figure 14 :
14
Figure 14: Adaptation results for intervention 9.</p>
<p>Figure 15 :
15
Figure 15: Adaptation results for intervention 13.</p>
<p>The causal transition model in VCD.Each individual variable has a separate conditional distribution p i .Each mechanism is conditioned on a subset of the previous state and action.The blue lines highlight the intervened mechanism which is specific to the environment k, as opposed to the mechanisms corresponding to the black lines, which are shared across environments.
TransitionModel(a) Latent state space model(b) Typical transition model(c) VCD transition modelFigure 2: (a) The structure of latent state space models in one timestep. Solid lines denote thegenerative process of the environment, dashed lines denote approximate posteriors, shaded nodesdenote observed variables, and the bi-directional arrow denotes the KL divergence in the ELBOterm. In this work, we propose a novel architecture for the transition model. (b) The structure oflatent transition models where the probability distribution is modelled as a fully connected neuralnetwork. (c)</p>
<p>Table 1 :
1
List of interventions ID InterventionIntervention targets 1 Remove spring between 1 and 2 x 1 , y 1 , x 2 , y 2 2</p>
<p>Table 2 :
2
Sparsity of learnt causal graphs and intervention targets.In the mixed-state experiments, we compare the learnt graph with the ground truth causal graph by mapping each latent dimension to a ground-truth state as shown in Fig.8.
Observation# of edges Correct Edges Missed Edges False PositivesMixed state causal graph42/2881978intervention targets 18/801005Imagecausal graph73/288---intervention targets 31/80---</p>
<p>Table 2 .
2
VCD has identified 42 and 73 causal edges in the mixed-state and image experiments respectively, out of 288 possible edges.Viewed in conjunction with the prediction performance results, this shows that VCD is able to learn a world model that is sparsely connected and affords modular parameter sharing without compromising on prediction accuracy.
causal parents0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 17 160 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 causal variables Mixed-statecausal parents6 7 8 9 10 11 15 14 13 12 5 4 3 2 1 0causal variables 0 2 4 6 8 10 12 14 Image
In the current work, we focus on environments without rewards. However, the proposed method can be readily extended to include reward prediction.
The reader is referred to[20] for a theoretical discussion of learning identifiable causal representations via causal transition models.
We note that in the image space, MultiRSSM does not perform well compared to RSSM and VCD. We hypothesise that this is due to the fact that the environment-specific transition models are only trained on data from one environment each, compared to RSSM which has access to data from all environments. VCD does not suffer from this due to modular parameter sharing.
AcknowledgementsThis research was supported by an EPSRC Programme Grant (EP/V000748/1).The authors would like to acknowledge the use of the University of Oxford Advanced Research Computing (ARC) facility in carrying out this work.http://dx.doi.org/10.5281/zenodo.22558.The authors thank Ceri Ngai, Jack Collins, Oiwi Parker Jones, Frederik Nolte and Jun Yamada for useful comments.
Properties from mechanisms: An equivariance perspective on identifiable representation learning. K Ahuja, J Hartford, Y Bengio, arXiv:2110.157962021arXiv preprint</p>
<p>M Arjovsky, L Bottou, I Gulrajani, D Lopez-Paz, arXiv:1907.02893Invariant risk minimization. 2019arXiv preprint</p>
<p>Robust locally-linear controllable embedding. E Banijamali, R Shu, H Bui, A Ghodsi, International Conference on Artificial Intelligence and Statistics. PMLR2018</p>
<p>What is a cognitive map? organizing knowledge for flexible behavior. T Behrens, T Muller, J Whittington, S Mark, A Baram, K Stachenfeld, Z Kurth-Nelson, 10.1016/j.neuron.2018.10.002.URLhttps://www.sciencedirect.com/science/article/pii/S0896627318308560Neuron. 0896-627310022018</p>
<p>A meta-transfer objective for learning to disentangle causal mechanisms. Y Bengio, T Deleu, N Rahaman, R Ke, S Lachapelle, O Bilaniuk, A Goyal, C Pal, arXiv:1901.109122019</p>
<p>Invariant causal imitation learning for generalizable policies. I Bica, D Jarrett, M Van Der Schaar, Advances in Neural Information Processing Systems. 342021</p>
<p>Differentiable causal discovery from interventional data. P Brouillard, S Lachapelle, A Lacoste, S Lacoste-Julien, A Drouin, Advances in Neural Information Processing Systems. H Larochelle, M Ranzato, R Hadsell, M F Balcan, H Lin, Curran Associates, Inc202033</p>
<p>Learning and querying fast generative models for reinforcement learning. L Buesing, T Weber, S Racanière, S M Ali Eslami, D Rezende, D Reichert, F Viola, F Besse, K Gregor, D Hassabis, D Wierstra, ArXiv, abs/1802.030062018</p>
<p>Learning phrase representations using rnn encoder-decoder for statistical machine translation. K Cho, B Van Merrienboer, C Gulcehre, F Bougares, H Schwenk, Y Bengio, Conference on Empirical Methods in Natural Language Processing. 2014. 2014</p>
<p>Genesis-v2: Inferring unordered object representations without iterative refinement. M Engelcke, O Parker Jones, I Posner, Advances in Neural Information Processing Systems. M Ranzato, A Beygelzimer, Y Dauphin, P S Liang, J Wortman Vaughan, Curran Associates, Inc202134</p>
<p>Recurrent independent mechanisms. A Goyal, A Lamb, J Hoffmann, S Sodhani, S Levine, Y Bengio, B Schölkopf, 9th International Conference on Learning Representations (ICLR). May 2021</p>
<p>Recurrent world models facilitate policy evolution. D Ha, J Schmidhuber, Advances in Neural Information Processing Systems 31. Curran Associates, Inc2018</p>
<p>D Hafner, T Lillicrap, J Ba, M Norouzi, arXiv:1912.01603Dream to control: Learning behaviors by latent imagination. 2019arXiv preprint</p>
<p>Learning latent dynamics for planning from pixels. D Hafner, T Lillicrap, T Fischer, T Villegas, D Ha, H Lee, J Davidson, Proceedings of the 36th International Conference on Machine Learning. the 36th International Conference on Machine Learning09-15 Jun 201997</p>
<p>Characterization and greedy learning of interventional Markov equivalence classes of directed acyclic graphs. A Hauser, P Bühlmann, Journal of Machine Learning Research. 132012</p>
<p>Categorical reparameterization with gumbel-softmax. E Jang, S Gu, B Poole, 5th International Conference on Learning Representations. Toulon, France2017. April 24-26, 2017. 2017Conference Track Proceedings</p>
<p>Learning neural causal models from unknown interventions. R Ke, O Bilaniuk, A Goyal, S Bauer, H Larochelle, B Schölkopf, M C Mozer, C Pal, Y Bengio, arXiv:1910.01075v22020</p>
<p>Auto-encoding variational bayes. D Kingma, M Welling, 2nd International Conference on Learning Representations, ICLR. 2014</p>
<p>P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980Adam: A method for stochastic optimization. 2014arXiv preprint</p>
<p>S Lachapelle, P López, Y Sharma, K Everett, R Le Priol, A Lacoste, S Lacoste-Julien, Disentanglement via mechanism sparsity regularization: A new principle for nonlinear ica. 2021</p>
<p>Causality: Models, Reasoning, and Inference. J Pearl, 2009Cambridge University PressNew York, NY2nd edition</p>
<p>Causal inference using invariant prediction: identification and confidence intervals. J Peters, P Bühlmann, N Meinshausen, Journal of the Royal Statistical Society, Series B: Statistical Methodology. 7852016with discussion</p>
<p>Elements of Causal Inference -Foundations and Learning Algorithms. J Peters, D Janzing, B Schölkopf, 2017MIT PressCambridge, MA, USA</p>
<p>On causal and anticausal learning. B Schölkopf, D Janzing, J Peters, E Sgouritsa, K Zhang, J Mooij, Proceedings of the 29th International Conference on Machine Learning (ICML). J Langford, J Pineau, the 29th International Conference on Machine Learning (ICML)New York, NY, USA2012</p>
<p>Toward causal representation learning. B Schölkopf, F Locatello, S Bauer, N R Ke, N Kalchbrenner, A Goyal, Y Bengio, 10.1109/JPROC.2021.3058954Proceedings of the IEEE -Advances in Machine Learning and Deep Neural Networks. the IEEE -Advances in Machine Learning and Deep Neural Networks2021109</p>
<p>Planning to explore via selfsupervised world models. R Sekar, O Rybkin, K Daniilidis, P Abbeel, D Hafner, D Pathak, ICML. 2020</p>
<p>Causation, Prediction, and Search. P Spirtes, C Glymour, R Scheines, 2000MIT PressCambridge, MA2nd edition</p>
<p>Causal discovery from changes. J Tian, J Pearl, Proceedings of the 17th Annual Conference on Uncertainty in Artificial Intelligence (UAI). the 17th Annual Conference on Uncertainty in Artificial Intelligence (UAI)2001</p>
<p>Towards causal generative scene models via competition of experts. J Von Kügelgen, I Ustyuzhaninov, P Gehler, M Bethge, B Schölkopf, arXiv:2004.129062020arXiv preprint</p>
<p>Embed to control: A locally linear latent dynamics model for control from raw images. M Watter, J Springenberg, J Boedecker, M Riedmiller, Advances in Neural Information Processing Systems. C Cortes, N Lawrence, D Lee, M Sugiyama, R Garnett, Curran Associates, Inc201528</p>
<p>Apex: Unsupervised, object-centric scene segmentation and tracking for robot manipulation. Y Wu, O Parker, M Jones, I Engelcke, Posner, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). 2021</p>
<p>Invariant causal prediction for block mdps. A Zhang, C Lyle, S Sodhani, A Filos, M Kwiatkowska, J Pineau, Y Gal, D Precup, International Conference on Machine Learning. PMLR2020</p>
<p>Multi-source domain adaptation: A causal view. K Zhang, M Gong, B Schölkopf, Proceedings of the 29th AAAI Conference on Artificial Intelligence. the 29th AAAI Conference on Artificial Intelligence2015</p>
<p>Causal discovery from nonstationary/heterogeneous data: Skeleton estimation and orientation determination. K Zhang, B Huang, J Zhang, C Glymour, B Schölkopf, Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI 2017). the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI 2017)2017</p>
<p>Solar: Deep structured representations for model-based reinforcement learning. M Zhang, S Vikram, L Smith, P Abbeel, M Johnson, S Levine, International Conference on Machine Learning. PMLR2019</p>            </div>
        </div>

    </div>
</body>
</html>