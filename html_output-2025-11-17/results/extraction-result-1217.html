<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1217 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1217</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1217</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-28.html">extraction-schema-28</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <p><strong>Paper ID:</strong> paper-227334937</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2012.03345v1.pdf" target="_blank">Neural Online Graph Exploration</a></p>
                <p><strong>Paper Abstract:</strong> Can we learn how to explore unknown spaces efficiently? To answer this question, we study the problem of Online Graph Exploration, the online version of the Traveling Salesperson Problem. We reformulate graph exploration as a reinforcement learning problem and apply Direct Future Prediction (Dosovitskiy and Koltun, 2016) to solve it. As the graph is discovered online, the corresponding Markov Decision Process entails a dynamic state space, namely the observable graph and a dynamic action space, namely the nodes forming the graph's frontier. To the best of our knowledge, this is the first attempt to solve online graph exploration in a data-driven way. We conduct experiments on six data sets of procedurally generated graphs and three real city road networks. We demonstrate that our agent can learn strategies superior to many well known graph traversal algorithms, confirming that exploration can be learned.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1217.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1217.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Barabasi</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Barabási–Albert (procedurally generated) graphs (barabasi dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Procedurally generated graphs used in experiments, drawn from a Barabási-like model (scale-free style) with varying sizes and connectivity (see Table 1 for |V|,|E| ranges).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>barabasi</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Synthetic procedurally generated graph class intended to produce heterogeneous degree distributions (scale-free-like); used as an exploration environment where the agent only observes local neighbors on visiting nodes.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Varied connectivity characteristic of Barabási-like graphs; see Table 1 for |V| (100–199) and |E| (384–780) ranges.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>|V| range: (100, 199); |E| range: (384, 780) (see Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>NOGE</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Neural Online Graph Exploration agent: GCN-based node embeddings, mean pooling for visited set, Direct Future Prediction (DFP) to predict future exploration-rate-conditioned returns, selects next frontier node by predicted future gain; dynamic action set equals frontier nodes.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>exploration rate u_T = |C_T| / |P_T| (visited nodes divided by total path length)</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>NOGE mean exploration rate = 0.7214 (std 0.0663) (Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Greedy nearest-neighbor (NN) often performs best on this class according to reported results</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>On the Barabasi dataset the paper reports that the simple greedy nearest-neighbor (NN) heuristic attained the highest exploration rate (NN = 0.8179), while NOGE achieved lower mean performance (0.7214). This indicates that in this topology (heterogeneous/scale-free connectivity) a local greedy policy performs very strongly and the learned long-horizon predictor did not surpass NN.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Performance varies by topology: NN dominates on Barabasi graphs while NOGE outperforms baselines on other topologies (e.g. grid, caveman).</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>For Barabasi-like graphs, local greedy selection (NN) suffices and outperforms the learned DFP policy in these experiments, implying that policies with very short horizon (memoryless, distance-greedy) can be near-optimal in some heterogeneous-degree networks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neural Online Graph Exploration', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1217.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1217.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Caveman</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Caveman (procedurally generated) graphs (caveman dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Procedurally generated 'caveman' graphs used as clustered/community-structured environments with varied node/edge counts (see Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>caveman</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Synthetic clustered graph class (many dense local cliques / community structure) used for online exploration experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Clustered / community structure with high intra-community connectivity and sparser inter-community links; see Table 1 for |V| (60–316 / 70–304) and large |E| ranges.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>|V| range: (60, 316) (train) and (70, 304) (test); |E| range: (870, 12324) (train) and (1190, 11400) (test) (Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>NOGE</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>GCN-based embeddings + DFP predictor that outputs future measurement deltas; selects frontier node maximizing weighted predicted future exploration-rate gains.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>exploration rate u_T = |C_T| / |P_T|</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>NOGE mean exploration rate = 0.9817 (std 0.0029) (Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>NOGE / learned long-horizon strategies (NOGE and NOGE-NN achieved top performance on caveman)</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>On caveman graphs (clustered topology) NOGE and especially NOGE-NN matched or slightly outperformed classical heuristics (NOGE-NN reached 0.9907). The paper reports that learning a predictive, longer-horizon policy is beneficial in this topology where exploration must balance moving between dense communities.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>NOGE outperforms baselines on caveman graphs, indicating that clustered topologies benefit from longer-horizon predictive policies.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Clustered/community topologies favor policies that can predict future gains over multiple steps (DFP-style) rather than purely greedy local choices.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neural Online Graph Exploration', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1217.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1217.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Grid</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Grid (procedurally generated) graphs (grid dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Procedurally generated 2D grid graphs used as exploration environments with moderate sizes (see Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>grid</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Synthetic 2D grid graphs (regular lattice topology) used to test exploration strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Regular lattice connectivity (grid); see Table 1 for |V| = 64–289 (train) and 72–240 (test), |E| ranges.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>|V| range (train): (64, 289); (test): (72, 240). |E| range (train): (112, 544); (test): (127, 449) (Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>NOGE</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>GCN embeddings + DFP predictor that selects frontier nodes by predicted future exploration-rate improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>exploration rate u_T = |C_T| / |P_T|</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>NOGE mean exploration rate = 0.8861 (std 0.0162) (Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Learned long-horizon (NOGE) policies outperformed greedy baselines on grids in these experiments</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>The paper reports that NOGE significantly outperforms classical heuristics on grid graphs (NOGE = 0.8861 > NN = 0.7670, DFS = 0.6272), indicating that regular low-dimensional topologies benefit strongly from learned predictive policies that account for future exploration costs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>NOGE performs particularly well on grid topologies compared to other datasets; grid structure benefits from long-horizon planning implemented via DFP.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>In regular lattice structures (grids) policies that predict and optimize multi-step exploration (DFP) yield better coverage per travel cost than one-step greedy methods.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neural Online Graph Exploration', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1217.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1217.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ladder</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ladder (procedurally generated) graphs (ladder dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Procedurally generated ladder graphs used as exploration environments with chain/ladder-like structure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>ladder</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Synthetic ladder graphs (two parallel chains connected by rungs) used to probe exploration behavior in elongated, quasi-linear topologies.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Sparse, quasi-linear ladder connectivity; see Table 1 for sizes: |V| ~ 200–400 and |E| ~ 298–595 (train)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>|V| range (train): (200, 398); (test): (220, 386). |E| range (train): (298, 595); (test): (328, 577) (Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>NOGE</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>GCN + DFP predictor; dynamic frontier action selection based on predicted future exploration-rate gains.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>exploration rate u_T = |C_T| / |P_T|</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>NOGE mean exploration rate = 0.6046 (std 0.1208) (Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Classical heuristics (DFS / NN) performed best on ladder graphs in reported experiments</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>On ladder graphs NN and DFS tied for best (≈0.753), while NOGE performed worse and with high variance, suggesting that certain elongated or near-linear topologies favor simpler traversal rules (e.g., following entry order or nearest frontier) over the learned DFP policy as instantiated.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>NOGE underperformed on ladder graphs compared to DFS/NN, highlighting sensitivity of learned policies to topology geometry.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Near-linear topologies appear to be well-served by stack-like (DFS) or local greedy policies; learned policies need to capture this structure to match classical methods.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neural Online Graph Exploration', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1217.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1217.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Maze</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Maze (procedurally generated) graphs (maze dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Procedurally generated maze graphs used to test exploration in labyrinthine topologies with corridors and possible dead-ends.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>maze</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Synthetic maze graphs (labyrinth-like environments) with corridor structures; used to evaluate exploration strategies in environments with constrained passages.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Sparse corridor-like connectivity typical of mazes; see Table 1 for |V| ~ 97–255 and |E| ~ 96–276.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>|V| range (train): (97, 251); (test): (97, 255). |E| range (train): (96, 262); (test): (96, 276) (Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>NOGE</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>GCN node embeddings, mean pooled visited summary, DFP predictor for future exploration-rate gains; selects frontier nodes maximizing weighted predicted future gains.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>exploration rate u_T = |C_T| / |P_T|</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>NOGE mean exploration rate = 0.4921 (std 0.0140) (Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Nearest-neighbor (NN) performed best in reported maze experiments; adding NN feature to NOGE (NOGE-NN) improved performance</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>In maze-like topologies NN outperformed vanilla NOGE (NN = 0.5723 > NOGE = 0.4921), but augmenting NOGE with an NN feature (NOGE-NN) brought performance close to NN (NOGE-NN = 0.5601). This suggests maze topologies benefit from local distance information combined with longer-horizon prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>NOGE performed worse on maze graphs than NN, but adding an NN indicator feature to NOGE reduced the gap.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Maze structures (with corridors and potential dead-ends) require policies that effectively combine local distance heuristics with some memory/prediction; pure long-horizon prediction without local nearest information underperformed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neural Online Graph Exploration', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1217.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1217.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tree</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tree (procedurally generated) graphs (tree dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Procedurally generated tree graphs used to evaluate exploration strategies on acyclic, hierarchical topologies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>tree</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Synthetic tree graphs (acyclic connected graphs) where backtracking is required to visit leaf nodes; used to test exploration algorithms' handling of dead-ends.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Acyclic (tree) structure; see Table 1 for wide |V| ranges (e.g., train |V|: 121–1365)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>|V| range (train): (121, 1365); (test): (364, 1093). |E| approximately |V|-1 (Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>NOGE</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>GCN + DFP predictor; learns to predict future exploration-rate gains and select frontier nodes accordingly. Also evaluated with an NN-indicator feature (NOGE-NN).</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>exploration rate u_T = |C_T| / |P_T|</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>NOGE mean exploration rate = 0.4403 (std 0.0272) (Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Depth-first search (DFS) is optimal on trees (provably traverses each edge twice), and DFS/NN achieved optimal performance (~0.5044 exploration rate in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>The paper explicitly notes that DFS explores trees optimally (each edge traversed twice, exploration rate ≈ 0.5). NOGE found this optimal strategy on trees in its tested variant (NOGE-NN matched DFS at ~0.5043). This highlights that in acyclic topologies the backtracking behavior (captured by DFS) is necessary and optimal.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Trees are a case where classical algorithm DFS is optimal; learned methods can emulate this when provided appropriate features (NOGE-NN matched DFS).</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Acyclic graphs (trees) require backtracking mechanisms; stack-like policies (DFS) are optimal. Learned policies that can represent or emulate backtracking (memory of visited path/order) can match DFS performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neural Online Graph Exploration', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1217.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1217.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MUC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Munich road network (MUC)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Real-world drivable road network for the city of Munich from OpenStreetMap, split into training and test components for exploration experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Munich (MUC) road network</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Real city road-network graph (drivable roads) from OpenStreetMap used to evaluate exploration on realistic large sparse networks.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Real-world road network connectivity (sparse), split into training/test components; see Table 2 for |V| and |E|.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>|V| (train): 8559; |E| (train): 12821. |V| (test): 5441; |E| (test): 7772 (Table 2)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>NOGE</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>GCN-based embedding network with DFP predictor; dynamic frontier actions; evaluated also in NOGE-NN variant that includes nearest-neighbor indicator feature.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>exploration rate u_T = |C_T| / |P_T|</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>NOGE mean exploration rate = 0.6458 (std 0.0441) (Table 4)</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Nearest-neighbor (NN) performed best on Munich; NOGE-NN approached NN performance</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>In the Munich road network NN achieved highest reported exploration rate (0.8314); NOGE underperformed but the NOGE-NN variant improved substantially (0.7814). This suggests that on realistic road networks, local nearest heuristics are highly effective and combining them with learned prediction helps but did not always surpass NN in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Across the three city networks, NN was consistently strong (often best), while learned methods (NOGE) performed variably and improved when augmented with NN features (NOGE-NN).</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Road-network topologies favor local nearest heuristics; learned policies need local-distance cues (nearest indicator) to match classical baselines on such sparse real-world graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neural Online Graph Exploration', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1217.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e1217.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OXF</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Oxford road network (OXF)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Real-world drivable road network for Oxford from OpenStreetMap, used for exploration evaluation after splitting into train/test.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Oxford (OXF) road network</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Real city road-network graph (drivable roads) used to evaluate exploration policies on a smaller real-world graph.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Real-world sparse road connectivity; see Table 2 for |V| and |E|.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>|V| (train): 2197; |E| (train): 2561. |V| (test): 1185; |E| (test): 1430 (Table 2)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>NOGE</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>GCN + DFP predictor; dynamic frontier action set; variant NOGE-NN includes nearest-neighbor indicator feature.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>exploration rate u_T = |C_T| / |P_T|</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>NOGE mean exploration rate = 0.4695 (std 0.0136) (Table 4)</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Nearest-neighbor (NN) performed best; NOGE-NN nearly matched NN</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>On Oxford NN achieved the best mean exploration rate (0.6422), while NOGE underperformed but the NOGE-NN variant closed the gap (0.6328). This again indicates local greedy heuristics perform strongly on road networks and that augmenting learned predictors with local nearest information helps.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>City networks show similar patterns: NN strong baseline, NOGE benefits from NN feature.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Real road graphs favor locally greedy policies; learned policies must incorporate local-distance signals to reach comparable efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neural Online Graph Exploration', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1217.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e1217.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SFO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>San Francisco road network (SFO)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Real-world drivable road network for San Francisco from OpenStreetMap, used as a large realistic exploration environment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>San Francisco (SFO) road network</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Large real city road-network graph used to test exploration strategies in realistic urban topologies.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Real urban road connectivity (sparse); see Table 2 for |V| and |E|.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>|V| (train): 5691; |E| (train): 9002. |V| (test): 3885; |E| (test): 6579 (Table 2)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>NOGE</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Graph-convolutional node embeddings, mean pooled context, DFP regression to predict future measurement deltas and select frontier nodes by weighted predictions; variant NOGE-NN includes an NN indicator channel.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>exploration rate u_T = |C_T| / |P_T|</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>NOGE mean exploration rate = 0.7541 (std 0.0679) (Table 4)</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Nearest-neighbor (NN) was best in reported SFO results (NN = 0.9017); NOGE-NN improved but did not surpass NN.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>On the San Francisco road network NN substantially outperformed vanilla NOGE; NOGE-NN improved toward NN but remained lower. This suggests dense urban road layouts strongly favor local nearest heuristics in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Across city road networks NN consistently performed best or near-best; augmenting learned policies with NN indicators improved performance but did not universally surpass NN.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Urban road topologies in these tests favor greedy nearest policies; learned policies need to integrate local-distance cues to match performance and may require architecture or feature changes to exceed them.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neural Online Graph Exploration', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Learning transferable graph exploration <em>(Rating: 2)</em></li>
                <li>A frontier-based approach for autonomous exploration <em>(Rating: 2)</em></li>
                <li>Exploring an unknown graph <em>(Rating: 2)</em></li>
                <li>Online graph exploration: New results on old and new algorithms <em>(Rating: 2)</em></li>
                <li>Constructing competitive tours from local information <em>(Rating: 1)</em></li>
                <li>Optimal constrained graph exploration <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1217",
    "paper_id": "paper-227334937",
    "extraction_schema_id": "extraction-schema-28",
    "extracted_data": [
        {
            "name_short": "Barabasi",
            "name_full": "Barabási–Albert (procedurally generated) graphs (barabasi dataset)",
            "brief_description": "Procedurally generated graphs used in experiments, drawn from a Barabási-like model (scale-free style) with varying sizes and connectivity (see Table 1 for |V|,|E| ranges).",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "barabasi",
            "environment_description": "Synthetic procedurally generated graph class intended to produce heterogeneous degree distributions (scale-free-like); used as an exploration environment where the agent only observes local neighbors on visiting nodes.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Varied connectivity characteristic of Barabási-like graphs; see Table 1 for |V| (100–199) and |E| (384–780) ranges.",
            "environment_size": "|V| range: (100, 199); |E| range: (384, 780) (see Table 1)",
            "agent_name": "NOGE",
            "agent_description": "Neural Online Graph Exploration agent: GCN-based node embeddings, mean pooling for visited set, Direct Future Prediction (DFP) to predict future exploration-rate-conditioned returns, selects next frontier node by predicted future gain; dynamic action set equals frontier nodes.",
            "exploration_efficiency_metric": "exploration rate u_T = |C_T| / |P_T| (visited nodes divided by total path length)",
            "exploration_efficiency_value": "NOGE mean exploration rate = 0.7214 (std 0.0663) (Table 3)",
            "success_rate": null,
            "optimal_policy_type": "Greedy nearest-neighbor (NN) often performs best on this class according to reported results",
            "topology_performance_relationship": "On the Barabasi dataset the paper reports that the simple greedy nearest-neighbor (NN) heuristic attained the highest exploration rate (NN = 0.8179), while NOGE achieved lower mean performance (0.7214). This indicates that in this topology (heterogeneous/scale-free connectivity) a local greedy policy performs very strongly and the learned long-horizon predictor did not surpass NN.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "Performance varies by topology: NN dominates on Barabasi graphs while NOGE outperforms baselines on other topologies (e.g. grid, caveman).",
            "policy_structure_findings": "For Barabasi-like graphs, local greedy selection (NN) suffices and outperforms the learned DFP policy in these experiments, implying that policies with very short horizon (memoryless, distance-greedy) can be near-optimal in some heterogeneous-degree networks.",
            "uuid": "e1217.0",
            "source_info": {
                "paper_title": "Neural Online Graph Exploration",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Caveman",
            "name_full": "Caveman (procedurally generated) graphs (caveman dataset)",
            "brief_description": "Procedurally generated 'caveman' graphs used as clustered/community-structured environments with varied node/edge counts (see Table 1).",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "caveman",
            "environment_description": "Synthetic clustered graph class (many dense local cliques / community structure) used for online exploration experiments.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Clustered / community structure with high intra-community connectivity and sparser inter-community links; see Table 1 for |V| (60–316 / 70–304) and large |E| ranges.",
            "environment_size": "|V| range: (60, 316) (train) and (70, 304) (test); |E| range: (870, 12324) (train) and (1190, 11400) (test) (Table 1)",
            "agent_name": "NOGE",
            "agent_description": "GCN-based embeddings + DFP predictor that outputs future measurement deltas; selects frontier node maximizing weighted predicted future exploration-rate gains.",
            "exploration_efficiency_metric": "exploration rate u_T = |C_T| / |P_T|",
            "exploration_efficiency_value": "NOGE mean exploration rate = 0.9817 (std 0.0029) (Table 3)",
            "success_rate": null,
            "optimal_policy_type": "NOGE / learned long-horizon strategies (NOGE and NOGE-NN achieved top performance on caveman)",
            "topology_performance_relationship": "On caveman graphs (clustered topology) NOGE and especially NOGE-NN matched or slightly outperformed classical heuristics (NOGE-NN reached 0.9907). The paper reports that learning a predictive, longer-horizon policy is beneficial in this topology where exploration must balance moving between dense communities.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "NOGE outperforms baselines on caveman graphs, indicating that clustered topologies benefit from longer-horizon predictive policies.",
            "policy_structure_findings": "Clustered/community topologies favor policies that can predict future gains over multiple steps (DFP-style) rather than purely greedy local choices.",
            "uuid": "e1217.1",
            "source_info": {
                "paper_title": "Neural Online Graph Exploration",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Grid",
            "name_full": "Grid (procedurally generated) graphs (grid dataset)",
            "brief_description": "Procedurally generated 2D grid graphs used as exploration environments with moderate sizes (see Table 1).",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "grid",
            "environment_description": "Synthetic 2D grid graphs (regular lattice topology) used to test exploration strategies.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Regular lattice connectivity (grid); see Table 1 for |V| = 64–289 (train) and 72–240 (test), |E| ranges.",
            "environment_size": "|V| range (train): (64, 289); (test): (72, 240). |E| range (train): (112, 544); (test): (127, 449) (Table 1)",
            "agent_name": "NOGE",
            "agent_description": "GCN embeddings + DFP predictor that selects frontier nodes by predicted future exploration-rate improvement.",
            "exploration_efficiency_metric": "exploration rate u_T = |C_T| / |P_T|",
            "exploration_efficiency_value": "NOGE mean exploration rate = 0.8861 (std 0.0162) (Table 3)",
            "success_rate": null,
            "optimal_policy_type": "Learned long-horizon (NOGE) policies outperformed greedy baselines on grids in these experiments",
            "topology_performance_relationship": "The paper reports that NOGE significantly outperforms classical heuristics on grid graphs (NOGE = 0.8861 &gt; NN = 0.7670, DFS = 0.6272), indicating that regular low-dimensional topologies benefit strongly from learned predictive policies that account for future exploration costs.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "NOGE performs particularly well on grid topologies compared to other datasets; grid structure benefits from long-horizon planning implemented via DFP.",
            "policy_structure_findings": "In regular lattice structures (grids) policies that predict and optimize multi-step exploration (DFP) yield better coverage per travel cost than one-step greedy methods.",
            "uuid": "e1217.2",
            "source_info": {
                "paper_title": "Neural Online Graph Exploration",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Ladder",
            "name_full": "Ladder (procedurally generated) graphs (ladder dataset)",
            "brief_description": "Procedurally generated ladder graphs used as exploration environments with chain/ladder-like structure.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "ladder",
            "environment_description": "Synthetic ladder graphs (two parallel chains connected by rungs) used to probe exploration behavior in elongated, quasi-linear topologies.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Sparse, quasi-linear ladder connectivity; see Table 1 for sizes: |V| ~ 200–400 and |E| ~ 298–595 (train)",
            "environment_size": "|V| range (train): (200, 398); (test): (220, 386). |E| range (train): (298, 595); (test): (328, 577) (Table 1)",
            "agent_name": "NOGE",
            "agent_description": "GCN + DFP predictor; dynamic frontier action selection based on predicted future exploration-rate gains.",
            "exploration_efficiency_metric": "exploration rate u_T = |C_T| / |P_T|",
            "exploration_efficiency_value": "NOGE mean exploration rate = 0.6046 (std 0.1208) (Table 3)",
            "success_rate": null,
            "optimal_policy_type": "Classical heuristics (DFS / NN) performed best on ladder graphs in reported experiments",
            "topology_performance_relationship": "On ladder graphs NN and DFS tied for best (≈0.753), while NOGE performed worse and with high variance, suggesting that certain elongated or near-linear topologies favor simpler traversal rules (e.g., following entry order or nearest frontier) over the learned DFP policy as instantiated.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "NOGE underperformed on ladder graphs compared to DFS/NN, highlighting sensitivity of learned policies to topology geometry.",
            "policy_structure_findings": "Near-linear topologies appear to be well-served by stack-like (DFS) or local greedy policies; learned policies need to capture this structure to match classical methods.",
            "uuid": "e1217.3",
            "source_info": {
                "paper_title": "Neural Online Graph Exploration",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Maze",
            "name_full": "Maze (procedurally generated) graphs (maze dataset)",
            "brief_description": "Procedurally generated maze graphs used to test exploration in labyrinthine topologies with corridors and possible dead-ends.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "maze",
            "environment_description": "Synthetic maze graphs (labyrinth-like environments) with corridor structures; used to evaluate exploration strategies in environments with constrained passages.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Sparse corridor-like connectivity typical of mazes; see Table 1 for |V| ~ 97–255 and |E| ~ 96–276.",
            "environment_size": "|V| range (train): (97, 251); (test): (97, 255). |E| range (train): (96, 262); (test): (96, 276) (Table 1)",
            "agent_name": "NOGE",
            "agent_description": "GCN node embeddings, mean pooled visited summary, DFP predictor for future exploration-rate gains; selects frontier nodes maximizing weighted predicted future gains.",
            "exploration_efficiency_metric": "exploration rate u_T = |C_T| / |P_T|",
            "exploration_efficiency_value": "NOGE mean exploration rate = 0.4921 (std 0.0140) (Table 3)",
            "success_rate": null,
            "optimal_policy_type": "Nearest-neighbor (NN) performed best in reported maze experiments; adding NN feature to NOGE (NOGE-NN) improved performance",
            "topology_performance_relationship": "In maze-like topologies NN outperformed vanilla NOGE (NN = 0.5723 &gt; NOGE = 0.4921), but augmenting NOGE with an NN feature (NOGE-NN) brought performance close to NN (NOGE-NN = 0.5601). This suggests maze topologies benefit from local distance information combined with longer-horizon prediction.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "NOGE performed worse on maze graphs than NN, but adding an NN indicator feature to NOGE reduced the gap.",
            "policy_structure_findings": "Maze structures (with corridors and potential dead-ends) require policies that effectively combine local distance heuristics with some memory/prediction; pure long-horizon prediction without local nearest information underperformed.",
            "uuid": "e1217.4",
            "source_info": {
                "paper_title": "Neural Online Graph Exploration",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Tree",
            "name_full": "Tree (procedurally generated) graphs (tree dataset)",
            "brief_description": "Procedurally generated tree graphs used to evaluate exploration strategies on acyclic, hierarchical topologies.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "tree",
            "environment_description": "Synthetic tree graphs (acyclic connected graphs) where backtracking is required to visit leaf nodes; used to test exploration algorithms' handling of dead-ends.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": true,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Acyclic (tree) structure; see Table 1 for wide |V| ranges (e.g., train |V|: 121–1365)",
            "environment_size": "|V| range (train): (121, 1365); (test): (364, 1093). |E| approximately |V|-1 (Table 1)",
            "agent_name": "NOGE",
            "agent_description": "GCN + DFP predictor; learns to predict future exploration-rate gains and select frontier nodes accordingly. Also evaluated with an NN-indicator feature (NOGE-NN).",
            "exploration_efficiency_metric": "exploration rate u_T = |C_T| / |P_T|",
            "exploration_efficiency_value": "NOGE mean exploration rate = 0.4403 (std 0.0272) (Table 3)",
            "success_rate": null,
            "optimal_policy_type": "Depth-first search (DFS) is optimal on trees (provably traverses each edge twice), and DFS/NN achieved optimal performance (~0.5044 exploration rate in experiments).",
            "topology_performance_relationship": "The paper explicitly notes that DFS explores trees optimally (each edge traversed twice, exploration rate ≈ 0.5). NOGE found this optimal strategy on trees in its tested variant (NOGE-NN matched DFS at ~0.5043). This highlights that in acyclic topologies the backtracking behavior (captured by DFS) is necessary and optimal.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "Trees are a case where classical algorithm DFS is optimal; learned methods can emulate this when provided appropriate features (NOGE-NN matched DFS).",
            "policy_structure_findings": "Acyclic graphs (trees) require backtracking mechanisms; stack-like policies (DFS) are optimal. Learned policies that can represent or emulate backtracking (memory of visited path/order) can match DFS performance.",
            "uuid": "e1217.5",
            "source_info": {
                "paper_title": "Neural Online Graph Exploration",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "MUC",
            "name_full": "Munich road network (MUC)",
            "brief_description": "Real-world drivable road network for the city of Munich from OpenStreetMap, split into training and test components for exploration experiments.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "Munich (MUC) road network",
            "environment_description": "Real city road-network graph (drivable roads) from OpenStreetMap used to evaluate exploration on realistic large sparse networks.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Real-world road network connectivity (sparse), split into training/test components; see Table 2 for |V| and |E|.",
            "environment_size": "|V| (train): 8559; |E| (train): 12821. |V| (test): 5441; |E| (test): 7772 (Table 2)",
            "agent_name": "NOGE",
            "agent_description": "GCN-based embedding network with DFP predictor; dynamic frontier actions; evaluated also in NOGE-NN variant that includes nearest-neighbor indicator feature.",
            "exploration_efficiency_metric": "exploration rate u_T = |C_T| / |P_T|",
            "exploration_efficiency_value": "NOGE mean exploration rate = 0.6458 (std 0.0441) (Table 4)",
            "success_rate": null,
            "optimal_policy_type": "Nearest-neighbor (NN) performed best on Munich; NOGE-NN approached NN performance",
            "topology_performance_relationship": "In the Munich road network NN achieved highest reported exploration rate (0.8314); NOGE underperformed but the NOGE-NN variant improved substantially (0.7814). This suggests that on realistic road networks, local nearest heuristics are highly effective and combining them with learned prediction helps but did not always surpass NN in these experiments.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "Across the three city networks, NN was consistently strong (often best), while learned methods (NOGE) performed variably and improved when augmented with NN features (NOGE-NN).",
            "policy_structure_findings": "Road-network topologies favor local nearest heuristics; learned policies need local-distance cues (nearest indicator) to match classical baselines on such sparse real-world graphs.",
            "uuid": "e1217.6",
            "source_info": {
                "paper_title": "Neural Online Graph Exploration",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "OXF",
            "name_full": "Oxford road network (OXF)",
            "brief_description": "Real-world drivable road network for Oxford from OpenStreetMap, used for exploration evaluation after splitting into train/test.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "Oxford (OXF) road network",
            "environment_description": "Real city road-network graph (drivable roads) used to evaluate exploration policies on a smaller real-world graph.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Real-world sparse road connectivity; see Table 2 for |V| and |E|.",
            "environment_size": "|V| (train): 2197; |E| (train): 2561. |V| (test): 1185; |E| (test): 1430 (Table 2)",
            "agent_name": "NOGE",
            "agent_description": "GCN + DFP predictor; dynamic frontier action set; variant NOGE-NN includes nearest-neighbor indicator feature.",
            "exploration_efficiency_metric": "exploration rate u_T = |C_T| / |P_T|",
            "exploration_efficiency_value": "NOGE mean exploration rate = 0.4695 (std 0.0136) (Table 4)",
            "success_rate": null,
            "optimal_policy_type": "Nearest-neighbor (NN) performed best; NOGE-NN nearly matched NN",
            "topology_performance_relationship": "On Oxford NN achieved the best mean exploration rate (0.6422), while NOGE underperformed but the NOGE-NN variant closed the gap (0.6328). This again indicates local greedy heuristics perform strongly on road networks and that augmenting learned predictors with local nearest information helps.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "City networks show similar patterns: NN strong baseline, NOGE benefits from NN feature.",
            "policy_structure_findings": "Real road graphs favor locally greedy policies; learned policies must incorporate local-distance signals to reach comparable efficiency.",
            "uuid": "e1217.7",
            "source_info": {
                "paper_title": "Neural Online Graph Exploration",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "SFO",
            "name_full": "San Francisco road network (SFO)",
            "brief_description": "Real-world drivable road network for San Francisco from OpenStreetMap, used as a large realistic exploration environment.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "San Francisco (SFO) road network",
            "environment_description": "Large real city road-network graph used to test exploration strategies in realistic urban topologies.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Real urban road connectivity (sparse); see Table 2 for |V| and |E|.",
            "environment_size": "|V| (train): 5691; |E| (train): 9002. |V| (test): 3885; |E| (test): 6579 (Table 2)",
            "agent_name": "NOGE",
            "agent_description": "Graph-convolutional node embeddings, mean pooled context, DFP regression to predict future measurement deltas and select frontier nodes by weighted predictions; variant NOGE-NN includes an NN indicator channel.",
            "exploration_efficiency_metric": "exploration rate u_T = |C_T| / |P_T|",
            "exploration_efficiency_value": "NOGE mean exploration rate = 0.7541 (std 0.0679) (Table 4)",
            "success_rate": null,
            "optimal_policy_type": "Nearest-neighbor (NN) was best in reported SFO results (NN = 0.9017); NOGE-NN improved but did not surpass NN.",
            "topology_performance_relationship": "On the San Francisco road network NN substantially outperformed vanilla NOGE; NOGE-NN improved toward NN but remained lower. This suggests dense urban road layouts strongly favor local nearest heuristics in these experiments.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "Across city road networks NN consistently performed best or near-best; augmenting learned policies with NN indicators improved performance but did not universally surpass NN.",
            "policy_structure_findings": "Urban road topologies in these tests favor greedy nearest policies; learned policies need to integrate local-distance cues to match performance and may require architecture or feature changes to exceed them.",
            "uuid": "e1217.8",
            "source_info": {
                "paper_title": "Neural Online Graph Exploration",
                "publication_date_yy_mm": "2020-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Learning transferable graph exploration",
            "rating": 2,
            "sanitized_title": "learning_transferable_graph_exploration"
        },
        {
            "paper_title": "A frontier-based approach for autonomous exploration",
            "rating": 2,
            "sanitized_title": "a_frontierbased_approach_for_autonomous_exploration"
        },
        {
            "paper_title": "Exploring an unknown graph",
            "rating": 2,
            "sanitized_title": "exploring_an_unknown_graph"
        },
        {
            "paper_title": "Online graph exploration: New results on old and new algorithms",
            "rating": 2,
            "sanitized_title": "online_graph_exploration_new_results_on_old_and_new_algorithms"
        },
        {
            "paper_title": "Constructing competitive tours from local information",
            "rating": 1,
            "sanitized_title": "constructing_competitive_tours_from_local_information"
        },
        {
            "paper_title": "Optimal constrained graph exploration",
            "rating": 1,
            "sanitized_title": "optimal_constrained_graph_exploration"
        }
    ],
    "cost": 0.01813175,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Neural Online Graph Exploration</p>
<p>Ioannis Chiotellis john.chiotellis@tum.decremers@tum.de 
Technical University of Munich Technical University of Munich</p>
<p>Daniel Cremers 
Technical University of Munich Technical University of Munich</p>
<p>Neural Online Graph Exploration</p>
<p>Can we learn how to explore unknown spaces efficiently? To answer this question, we study the problem of Online Graph Exploration, the online version of the Traveling Salesperson Problem. We reformulate graph exploration as a reinforcement learning problem and apply Direct Future Prediction (Dosovitskiy and Koltun, 2016) to solve it. As the graph is discovered online, the corresponding Markov Decision Process entails a dynamic state space, namely the observable graph and a dynamic action space, namely the nodes forming the graph's frontier. To the best of our knowledge, this is the first attempt to solve online graph exploration in a data-driven way. We conduct experiments on six data sets of procedurally generated graphs and three real city road networks. We demonstrate that our agent can learn strategies superior to many well known graph traversal algorithms, confirming that exploration can be learned.</p>
<p>INTRODUCTION</p>
<p>In online graph exploration, an agent is immersed in a completely unknown environment. Located at a node of an unknown graph, they can only see the node's immediate neighbors. The agent moves and discovers the graph as they go. Whenever they visit a new node, all incident edges are revealed, along with their weights and their end nodes. To visit a new node, the agent has to traverse a path of known edges in the discovered graph. For each of these edges, the agent pays their weight as a cost. The goal of the agent is to visit all nodes in the graph, while paying the minimum cost.</p>
<p>Preliminary work.</p>
<p>By removing any particular geometric constraints, a large number of problems can be reduced to online graph exploration, as it basically is search with partial information in a discrete space. We revisit online graph exploration for undirected unweighted connected graphs. This task can be directly associated with many major problems in robotics such as planning, navigation, tracking and mapping (Yamauchi, 1997). All these subfields have been thoroughly investigated and a large number of algorithms have been devised, both classical and recently also learning-based. While path planning and navigation algorithms consider the question "How can I get from A to B the fastest?", exploration algorithms consider a more abstract question: "Where should I go beginning from A in order to discover the world the fastest?". In other words, while path planning studies how to reach a given destination, exploration is concerned with which destination should be reached next, a problem more akin to dynamic planning. We argue that exploration is a fundamental sequential decision making problem and it is therefore worth investigating if algorithms can learn which destinations are worth reaching and when.</p>
<p>The best known exploration strategy remains a simple greedy method -the nearest neighbor algorithm (NN). However, as NN selects the nearest (in terms of shortest path distance) unexplored node, its decisions are optimal only when considering a horizon of a single decision step. Therefore, a reasonable question is whether there are algorithms that can consider a longer horizon and thus minimize the cumulative path length, which is the true objective of exploration.</p>
<p>We present a learning algorithm that does exactly this. Our contributions can be summarized as follows:</p>
<p>• reformulate online graph exploration as a reinforcement learning problem,</p>
<p>• propose a neural network that can handle the associated dynamic state and action space,</p>
<p>• show experimentally that the proposed approach solves graph exploration as fast or faster than many classical graph exploration algorithms.</p>
<p>arXiv:2012.03345v1 [cs.</p>
<p>LG] 6 Dec 2020</p>
<p>RELATED WORK</p>
<p>The problem of graph exploration has been studied by the graph theory community for decades. A large number of works has been conducted, studying the problem for specific classes of graphs (Miyazaki et al., 2009;Higashikawa et al., 2014), with multiple collaborative agents (Dereniowski et al., 2013) or for variations of the problem with additional information (Dobrev et al., 2012) or energy constraints (Duncan et al., 2006;Das et al., 2015). Successful exploration algorithms are often sophisticated variations of depth first search (DFS), where the algorithm has to decide when to diverge from DFS (Kalyanasundaram and Pruhs, 1994;Megow et al., 2012). A similar problem has been studied by Deng and Papadimitriou (1999) for unweighted directed graphs, where the agent has to traverse all edges instead of visiting all nodes. In this setting, the offline equivalent problem is known as the Chinese Postman Problem (CPP) (Guan, 1962) which is solvable in polynomial time. In contrast, the offline equivalent of Online Graph Exploration is the Traveling Salesperson Problem, an NP-hard problem.</p>
<p>Besides the large volume of research, for general graphs, the best known exploration algorithm remains a simple greedy method -the nearest neighbor algorithm (NN). The trajectories followed by NN are provably at most O(log n) 1 longer than the optimal ones (Rosenkrantz et al., 1977).</p>
<p>However, to the best of our knowledge, it has not been attempted to solve graph exploration in a data-driven way. In this work, we investigate whether, given a training set of graphs, a learning algorithm is able to find good exploration strategies that are competitive or even superior to traditional methods. Recently, there has been growing interest in applying learning to combinatorial optimization problems. In the work of Vinyals et al. (2015), three problems were studied and solved by learning to "point" to elements of a set with a neural network. Among these problems was the Traveling Salesperson Problem, which can be thought of as the offline equivalent to graph exploration. Vinyals et al. (2015) proposed a recurrent neural network (RNN) architecture, called Pointer Network, based on the attention mechanism introduced by Vaswani et al. (2017). However, using an RNN might introduce a bias due to the ordering of the elements in the input sequence. To alleviate this bias, several works have studied neural architectures that can preserve the permutation-invariance property of sets (Edwards and Storkey, 2016;Zaheer et al., 2017;Lee et al., 2018). Moreover, in recent years, Graph Neural Networks (GNNs) (Battaglia et al., 2018) have emerged.</p>
<p>1 where n is the number of nodes Figure 1: A graph exploration agent (red) keeps track of the nodes already visited (blue) and the frontier nodes that could be visited next (green). The frontier nodes form the boundary between known and unknown (white) space. The goal is to discover and visit all nodes as fast as possible.</p>
<p>These neural networks consider not just sets of nodes but also their pairwise connections or relationships as inputs and can learn how to solve problems such as node classification (Kipf and Welling, 2016) and link prediction (Zhang and Chen, 2018). Further, methods such as DeepWalk (Perozzi et al., 2014) and node2vec (Grover and Leskovec, 2016) have been used to learn node embeddings in an unsupervised way, borrowing ideas from natural language processing (Mikolov et al., 2013). These methods make an implicit assumption that nodes that co-appear in a random walk on the graph are more similar than nodes that don't. Nevertheless, it remains a challenge to learn node embeddings for dynamic graphs that are changing while an algorithm makes decisions about the graph's structure.</p>
<p>Close to our work is the work of Dai et al. (2019) which studies exploration on environments with graphstructured state-spaces, such as software testing. In contrast to (Dai et al., 2019), we study the original problem as defined by the graph theory community which prohibits the revisiting of past nodes. This allows us to study the problem in isolation, without the interference of other tasks such as visual feature learning and the perceptual aliasing problem.</p>
<p>FORMULATION</p>
<p>Graph Exploration Overview</p>
<p>An agent explores a connected unweighted graph G = (V, E). At time step t = 0, they start at an arbitrary node v 0 ∈ V and they can only observe an initial map G 0 = (V 0 , E 0 ) comprised of the neighbors and incident edges of v 0 . We assume the agent has a memory where it can store and integrate observations. Therefore, at any time step t, the agent observes a subgraph G t = (V t , E t ) with a subset of visited nodes C t and a subset of frontier nodes F t that are to be explored. Being at node v t ∈ C t , the agent has to choose a node v t+1 ∈ F t to visit next. Once a decision is made, the agent follows a path from v t to v t+1 of length l t+1 = d Gt (v t , v t+1 ). Note that this is a shortest path in G t but not necessarily in G 2 . The new node v t+1 gets removed from the frontier and becomes part of the set of visited nodes:
C t+1 ← C t ∪ {v t+1 }.
Finally, the agent observes the neighbors N (v t+1 ) of v t+1 and the frontier gets expanded by the subset of neighbors that have not been observed in the past:
F t+1 ← F t ∪ N (v t+1 ) \ C t+1 .(1)
The goal is to visit the nodes in such an order that the total path length is minimized. Notice that we use a different timescale than commonly used e.g. in navigation problems. In a single time step, the exploration agent can traverse a path of arbitrary length in the known graph G t . The differences between exploration algorithms lie in the way they choose the node v ∈ F t to visit next. For instance, DFS considers the order of entry in the frontier and chooses the most recently entered node. The nearest neighbor algorithm (NN) chooses the node closest to the current node v t ∈ C t :
v N N t+1 = arg min v∈Ft d(v t , v)(2)
However, since the NN selection rule is greedy, it might be suboptimal. Namely, an algorithm A could exist that takes into account the expected future path lengths and could therefore make better decisions:
v A t+1 = arg min v∈Ft E[d(v t , v) + ∞ i=t+1 d(v i , v i+1 )].(3)
This formulation is reminiscent of reinforcement learning (RL). In RL an agent in a state s t and following a policy π, chooses action a t = π(s t ) and receives an immediate reward r t+1 . The true objective of the agent is to maximize the cumulative reward:
a t = arg max a∈A E[r t+1 + ∞ i=t+1 γ i−t r i+1 |π, a],(4)
where γ ∈ [0, 1] is a discount factor that weighs distant future rewards less than imminent rewards. The expectation of cumulative rewards is also known as the action value Q π (s t , a t ). Notice that the NN algorithm can be exactly recovered for γ = 0.</p>
<p>Markov Decision Process</p>
<p>RL problems are formally described as Markov Decision Processes (MDPs). An MDP is defined as a 5-tuple (S, A, p, r, γ), namely a state space S, an action space A, a state transition probability function p : S ×A ×S → [0, 1], a reward function r : S ×A → R and a discount factor γ ∈ [0, 1]. A partially observable Markov decision process (POMDP) is a generalization of a MDP, where the agent cannot directly observe the state s t ∈ S but has partial information through observations o t ∈ O. An agent with a memory component can integrate partial observations to cumulative observations x t ∈ X . Notice that the observation space X is a subset of the state space S. Thus, we refer to the setting of Online Graph Exploration as a memory-augmented POMDP. In Figure 2, we illustrate this setting. In the following, we describe the components of this MDP.</p>
<p>State Space Let G be the set of all conceivable graphs, and let P G denote the set of all conceivable visit orderings P G for a graph G ∈ G. Then the state space S is defined as the set of all pairs (G, P G ) of graphs G ∈ G and associated visit orderings P G ∈ P G .</p>
<p>Observation Space At each time step, the environment reveals the neighborhood of the visited node. Therefore, the observation space is exactly the subset of graphs that are star graphs.</p>
<p>Action Space It is common in RL problems with discrete action spaces, for the agent to have access to a fixed set of actions A as in Eq. (4). Instead, in graph exploration, a new unique action set A t is induced from the state at each time step. This action set corresponds to the nodes that have been observed but not visited yet, namely the nodes in the frontier:
A t = F t .(5)
The general action space can be described by the power set of all nodes: A = 2 V . Note that the frontier can be derived from the known graph G t = (V t , E t ) and the path P t as F t = V t \ C t , where C t denotes the set of visited nodes found in the sequence P t .  Figure 2: The task of a graph exploring agent is to select the frontier node v t+1 ∈ F t to visit next. Once the node is visited, the environment reveals a new set of nodes ∆V t+1 and edges ∆E t+1 , expanding the agent's knowledge to the graph G t+1 = (V t+1 , E t+1 ). The distance traveled by the agent from v t to v t+1 is paid as a negative reward r t+1 . The agent acts upon an integrated observation x t+1 retrieved from its memory. The subset of nodes that have been discovered but are not yet visited are labeled as the frontier F t+1 .</p>
<p>Reward Function As defined in section 3.1, the rewards correspond to negative geodesic distances. Therefore, assuming unweighted graphs, all rewards are strictly negative:
r(s t , a t ) = −d(v t , v t+1 ) &lt; 0.(6)
State Transition Function Let v t+1 be the node to visit next. Then, if s t = (G, P t ) is the state described by the graph G and the path P t , the new state is described by the same graph G and the extended path P t+1 ← P t || v t+1 3 .</p>
<p>Memory Update Upon observing ∆V t+1 = N (v t+1 ), namely the neighbors of v t+1 , and ∆E t+1 = E(v t+1 ), the edges from v t+1 to N (v t+1 ), the agent's memory is updated as:
V t+1 ← V t ∪ ∆V t+1 (7) E t+1 ← E t ∪ ∆E t+1 (8) P t+1 ← P t || v t+1 (9) C t+1 ← C t ∪ {v t+1 } (10) F t+1 ← F t ∪ ∆V t+1 \ C t+1 .(11)</p>
<p>METHODOLOGY</p>
<p>Predicting the Future Path Lengths</p>
<p>Our premise is that a learning agent can perform better than traditional exploration algorithms, as long as they can predict the future distances to be traveled. Inspired by the framework introduced by Dosovitskiy and Koltun (2016), we use Direct Future Prediction (DFP) to learn a predictor of future path lengths. Confirming the authors' observations, we found that reducing policy learning to a supervised regression problem makes training faster and more stable. In 3 By || we denote concatenation of a sequence with a new element. particular, at time t, we aim to predict the vector (12) where m t is a low-dimensional measurement vector augmenting the agent's high-dimensional observation x t , and {τ j } M j=1 are temporal offsets. Following Dosovitskiy and Koltun (2016), we choose exponential offsets τ j = 2 j−1 . We could directly use a scalar measurement L t = t i=0 l i , namely the cumulative path length up to time t. However, there are several disadvantages with this choice. For unweighted graphs, we know that any one-step path length l t lies in the range [1, N max −1], where N max is the maximum number of nodes we are considering. Thus, directly predicting path lengths would limit our ability to generalize to graphs larger than our training graphs. Second, the distribution of path lengths naturally grows over time together with the observable graph's diameter. To avoid these problems, instead of minimizing path lengths, we maximize the agent's exploration rate u t = |Ct| Lt = t Lt which always lies in the [0, 1] interval and thus the entries of y always lie in [−1, 1]. At test time, we choose the node to visit next by simply taking the arg max:
y t = (m t+τ1 −m t , m t+τ2 −m t , . . . , m t+τ M −m t ),v t+1 = arg max v∈Ft g f θ (x t , m t , v),(13)
where f θ is our parameterized predictor network, x t = (V t , E t , X t ) is the observable graph with node features X t and g is a goal vector expressing how much we care about different future horizons. Another advantage of using DFP instead of RL is that, given information about the remaining time available, we can directly incorporate it in the goal vector, both at training and at test time without the need of retraining the network. In contrast to Dosovitskiy and Koltun (2016), we don't use g as an input to the network 4 , but only as a weighting of the predictions to obtain a policy. </p>
<p>Network Architecture</p>
<p>In Figure 3 we show our network architecture. We first obtain node embeddings Z F , Z C and z vt by passing the observable graph x t = (V t , E t , X t ) through a graph neural network (GNN). The embeddings correspond to the node subsets F t , C t and the current node v t . We use a standard graph convolutional network (GCN) (Kipf and Welling, 2016), but any graph neural network that produces node embeddings can be used. We then aggregate the node embeddings Z C of the visited set to obtain a subgraph embeddingz C . Even though more sophisticated pooling methods (e.g. attention (Veličković et al., 2017)) may be used, we use simple mean pooling.</p>
<p>We pass m t through a multi-layer Perceptron (MLP) to obtain a measurement embedding z m . The vectors z C , z vt and z m are concatenated to form a context vector z ctx . Each frontier node embedding z F (v) ∈ Z F is concatenated with z ctx , resulting in a set of stateaction encodings φ(x t , m t , v), one for each node v ∈ F t . Finally we pass these encodings through a rowwise feed-forward network (another MLP) to obtain a prediction vector f (x t , m t , v) for each node v ∈ F t . The state-action value Q(x t , m t , v, g) of each node in the frontier can be obtained by multiplying the associated prediction vector f (x t , m t , v) with the goal vector g.</p>
<p>Input Features</p>
<p>Solving online graph exploration as a learning problem depends critically on what the learning algorithm "sees" as input. The state s t consists of the known graph G t and the path P t . Therefore, we have to decide on the nodes and perhaps also edge input features of the graph G t . Second, we have to consider a representation of the path P t .</p>
<p>We used categorical node features indicating if a node belongs to the visited set C t , the frontier set F t or if it is the current node v t :
x(v i ) = (1(v i ∈ C t ), 1(v i ∈ F t ), 1(v i = v t )).(14)
Note that a categorical node feature space can incorporate many classical graph traversal algorithms (e.g. BFS, DFS and NN) as special cases by simply adding a binary channel that indicates the node that would be selected by the respective algorithm. Furthermore, this representation allows the learning algorithm to potentially learn a hyper-policy (Precup et al., 1998) by combining greedy algorithms in novel ways.</p>
<p>In preliminary experiments, we investigated ways to utilize the order of visit of the nodes, P t , by using positional encodings (Vaswani et al., 2017) as continuous node features. We found that these features degraded the agent's performance both when used on their own and when combined with the categorical features.</p>
<p>Training</p>
<p>In Algorithm 1 we describe our training procedure. In each episode, we randomly sample a graph from the training set and then randomly set one of its nodes as source. This virtually increases the training set size from the number of training graphs |G train | to the total number of nodes in all training graphs G∈Gtrain |V G |, where by V G we denote the vertices of graph G.</p>
<p>Algorithm 1 Training NOGE 1: Input: network f θ , training set of graphs G train , time limit T max , goal vector g, minibatch size B. 2: Output: trained network f θ . 3: Initialize θ randomly. 4: Initialize an experience replay buffer R. 5: while training do 6:</p>
<p>Sample a graph G = (V, E) ∼ G train .</p>
<p>7:</p>
<p>Sample a source node v 0 ∼ V .</p>
<p>8:</p>
<p>Explore G using f θ , g and -greedy policy for up to T max steps.</p>
<p>9:</p>
<p>Store G and the followed path P T in R.</p>
<p>10:</p>
<p>for update = 1, . . . , N updates do 11:</p>
<p>Sample a minibatch {G t , P t } from R.</p>
<p>12:</p>
<p>Reconstruct tuples {x t , m t , v t+1 , y t }.</p>
<p>13:</p>
<p>Train f θ with the minibatch using Adam to minimize the mean squared error:
L(θ) = 1 B B i=1 ||y t − f θ (x t , m t , v t+1 )|| 2 .
14: end for 15: end while</p>
<p>EXPERIMENTS</p>
<p>The complete set of hyperparameters used is reported in Appendix A and our full source code will be available at https://github.com/johny-c/noge.</p>
<p>Evaluation Protocol</p>
<p>We evaluate our algorithm -NOGE (Neural Online Graph Exploration) on data sets of generated and real networks. In addition to the basic version of our algorithm, we evaluate NOGE with an extra node feature, indicating the nearest neighbor, as described in section 4.3. We call this variant NOGE-NN. We use three well known graph exploration algorithms as baselines: Breadth First Search (BFS), Depth First Search (DFS) and Nearest Neighbor (NN). We note that these heuristics do not need any training. For completeness, we also report a random exploration baseline (RAN-DOM). We compare the algorithms in terms of the exploration rate u T , namely the number of visited nodes over the total path length at the end of episodes:
u T = |C T | |P T | = T T i=0 l i .(15)
For the test sets we fix a set of source nodes per graph, to compare all methods given the exact same initial conditions. The metrics reported are computed on the test sets after either all nodes have been explored or when a fixed number of T max = 500 exploration steps has been reached. For all experiments we report mean and standard deviation over 5 random seeds.</p>
<p>Procedurally Generated Graphs</p>
<p>We first examine six classes of procedurally generated graphs ( Figure 6). We used the networkx library (https://github.com/networkx/networkx) to generate a diverse (in terms of size and connectivity) set of graphs for each class. In Table 1 we report basic statistics describing the size and connectivity of the graphs. We split each data set in a training (80%) and test set (20%) of graphs. For some of these data sets, an optimal strategy is known. For instance, DFS explores trees optimally by traversing each edge two times -once to explore and once to backtrack. Thus its exploration rate is approximately 0.5. It is worthwhile examining if NOGE can find this optimal strategy.</p>
<p>In Figure 4 we show the test performance of NOGE over 25600 training steps. In Table 3 we report the final performance of the algorithms compared to the baselines. NOGE is able to outperform other methods on grids and the caveman data set and find the optimal strategy on trees. Somewhat surprisingly the NN feature seems to only help on the maze and tree data sets. Note that in ladder and tree, DFS's line is hidden as its performance matches that of NN.    Figure 4: Exploration rate over gradient steps for the six procedurally generated data sets.</p>
<p>City Road Networks</p>
<p>To examine its capabilities, we also evaluate NOGE, on three real road networks. We use openly available drivable road networks from OpenStreetMap (Haklay and Weber, 2008). We explore three cities with diverse networks: Munich (MUC), Oxford (OXF) and San Francisco (SFO), shown in Figure 7.</p>
<p>In Table 2, we show basic statistics for these data sets.</p>
<p>We constructed a training set and test set for each city by cutting each graph in two components and removing any edges connecting them. We aimed to split each graph such that approximately 60% of the nodes fall into the training component.</p>
<p>In Figure 5 we show the test performance of NOGE over 40000 training steps and in Table 4 we report the final performance. Nearest Neighbor performs clearly better in San Francisco and Munich. NOGE-NN is able to match and surpass DFS, as the second best method. In Oxford, NOGE-NN is within a standard deviation from the best performance by NN. In these graphs the NN feature clearly improves performance.</p>
<p>CONCLUSION</p>
<p>In this work, we presented NOGE, a learning-based algorithm for exploring graphs online. First, we formulated an appropriate memory-augmented Markov Decision Process. Second, we proposed a neural architecture that can handle the growing graph as input and the dynamic frontier as output. Third, we devised a node feature space that can represent greedy methods as options (Precup et al., 1998). Finally, we showed experimentally that NOGE is competitive to well known classical graph exploration algorithms in terms of the exploration rate of unseen graphs.  Figure 5: Exploration rate over gradient steps for the city road networks data sets. </p>
<p>Figure 3 :
3The proposed neural network architecture for online graph exploration.</p>
<p>Figure 6 :Figure 7 :
67Samples from the procedurally generated data sets used in the experiments of Section 5.2. The road city networks used for the experiments in Section 5.3.</p>
<p>Table 1 :
1Basic statistics of the procedurally generated data sets (tr: training set, te: test set).Dataset 
Size |V | min,max 
|E| min,max </p>
<p>barabasi(tr) 400 
(100, 199) 
(384, 780) 
barabasi(te) 100 
(100, 199) 
(384, 780) 
ladder(tr) 
80 
(200, 398) 
(298, 595) 
ladder(te) 
20 
(220, 386) 
(328, 577) 
tree(tr) 
4 
(121, 1365) 
(120, 1364) 
tree(te) 
2 
(364, 1093) 
(363, 1092) 
grid(tr) 
80 
(64, 289) 
(112, 544) 
grid(te) 
20 
(72, 240) 
(127, 449) 
caveman(tr) 120 
(60, 316) 
(870, 12324) 
caveman(te) 
30 
(70, 304) 
(1190, 11400) 
maze(tr) 
400 
(97, 251) 
(96, 262) 
maze(te) 
100 
(97, 255) 
(96, 276) </p>
<p>Table 2 :
2Basic statistics of the city road network data sets (tr: training set, te: test set).Dataset 
Size 
|V | min,max 
|E| min,max </p>
<p>MUC(tr) 
1 
(8559, 8559) (12821, 12821) 
MUC(te) 
1 
(5441, 5441) 
(7772, 7772) 
OXF(tr) 
1 
(2197, 2197) 
(2561, 2561) 
OXF(te) 
1 
(1185, 1185) 
(1430, 1430) 
SFO(tr) 
1 
(5691, 5691) 
(9002, 9002) 
SFO(te) 
1 
(3885, 3885) 
(6579, 6579) </p>
<p>Table 3 :
3Final exploration rate: Mean and standard deviation on the generated data sets.Dataset 
RANDOM 
BFS 
DFS 
NN 
NOGE 
NOGE-NN </p>
<p>barabasi 0.3695 (0.0006) 0.4695 (0.0013) 
0.5494 (0.0009) 0.8179(0.0014) 
0.7214 (0.0663) 
0.6970 (0.0497) 
caveman 0.5664 (0.0050) 0.9526 (0.0025) 
0.9778 (0.0006) 
0.9827 (0.0015) 
0.9817 (0.0029) 0.9907(0.0031) 
grid 
0.1461 (0.0037) 0.2264 (0.0039) 
0.6272 (0.0041) 
0.7670 (0.0028) 0.8861(0.0162) 0.8373(0.0536) 
ladder 
0.1531 (0.0226) 0.1691 (0.0341) 0.7519(0.0010) 0.7530(0.0009) 
0.6046 (0.1208) 0.6729(0.1114) 
maze 
0.0688 (0.0027) 0.0626 (0.0025) 
0.5266 (0.0050) 0.5723(0.0033) 
0.4921 (0.0140) 0.5601(0.0106) 
tree 
0.1242 (0.0011) 0.3397 (0.0002) 0.5044(0.0002) 0.5044(0.0003) 
0.4403 (0.0272) 0.5043(0.0004) </p>
<p>Table 4 :
4Final exploration rate: Mean and standard deviation on the city road networks data sets.Dataset 
RANDOM 
BFS 
DFS 
NN 
NOGE 
NOGE-NN </p>
<p>MUC 
0.0674 (0.0003) 0.1961 (0.0007) 0.7644 (0.0053) 0.8314(0.0091) 0.6458 (0.0441) 
0.7814 (0.0386) 
OXF 
0.0624 (0.0009) 0.1608 (0.0019) 0.6012 (0.0048) 0.6422(0.0037) 0.4695 (0.0136) 0.6328(0.0141) 
SFO 
0.0726 (0.0015) 0.2007 (0.0033) 0.8252 (0.0073) 0.9017(0.0064) 0.7541 (0.0679) 
0.8289 (0.0456) </p>
<p>In the rest of the paper, we omit Gt and use the shorter notation d(vt, vt+1) wherever possible.
We found that adding a goal module does not improve and some times even hurts performance.
A IMPLEMENTATION DETAILSA.1 HyperparametersInTable 5we show the hyperparameters used for the experiments on the procedurally generated data sets. The only differences in the experiments for the city road networks are the number of training steps which was set to 40000 and the hidden layer width of the neural network (see next subsection). We elaborate on hyperparameters, the usage of which may not be immediately clear:Node History It is common in deep reinforcement learning to replace the input observation x t with a stack of the last k observations [x t−k+1 , x t−k+2 , . . . , x t ], particularly when the observations are images. This gives the agent a sense of the environment dynamics. We found that using a stack of the last 2 feature vectors for each node also improves performance in graph exploration, as it gives a sense of direction.Feature Range As a preprocessing step, shifting input features to the [−0.5, 0.5] range speeds up learning.Target Normalization As a postprocessing step, target normalization also aids the learning process. We scaled targets y by the standard deviation of measurements collected during random exploration, as described byDosovitskiy and Koltun (2016).Evaluation Episodes For evaluation, we sampled 50 graphs from the test set and fixed one source node per graph. If the test set contained less than 50 graphs, we sampled 50 source nodes uniformly from all test graphs.ε-greedy Policy As described in our training algorithm, we used an ε-greedy policy to collect experiences, namely a random frontier node was selected to be visited with probability ε and a node was selected by the network's policy with probability 1 -ε. We linearly interpolated ε from 1 to 0.15 over the course of training. During testing, the greedy policy (ε = 0) was used.A.2 Network ArchitectureThe architecture of our network, used for the procedurally generated graphs, is shown inTable 6. The same architecture was used for the city road networks except that all layers -apart for input and output -are wider by a factor of two. The input dimension for the graph neural network (GNN) was 3 for NOGE and 4 for NOGE-NN. In all networks we use the ReLU nonlinearity after all layers except for the output layer of the row-wise feed-forward (rFF) network.A.3 Replay Buffer for GraphsTo use the replay buffer for training, we need to be able to sample graph observations G t from any time step in an episode. To do that, for each episode we store the discovered graph G T = (V T , E T ) at the end of the episode and two arrays: an array of node counts and an array of edge counts, indicating the size of the graph at each time step. To be able to reconstruct the frontier at an arbitrary time step t, we need to store two integers per node v: the time of discovery t dis (v) and the time of visit t dis (v). Then the frontier F t at any time step t is:
P W Battaglia, J B Hamrick, V Bapst, A Sanchez-Gonzalez, V Zambaldi, M Malinowski, A Tacchetti, D Raposo, A Santoro, R Faulkner, arXiv:1806.01261Relational inductive biases, deep learning, and graph networks. arXiv preprintBattaglia, P. W., Hamrick, J. B., Bapst, V., Sanchez- Gonzalez, A., Zambaldi, V., Malinowski, M., Tacchetti, A., Raposo, D., Santoro, A., Faulkner, R., et al. (2018). Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261.</p>
<p>Learning transferable graph exploration. H Dai, Y Li, C Wang, R Singh, P.-S Huang, P Kohli, Advances in Neural Information Processing Systems. Dai, H., Li, Y., Wang, C., Singh, R., Huang, P.-S., and Kohli, P. (2019). Learning transferable graph explo- ration. In Advances in Neural Information Processing Systems, pages 2518-2529.</p>
<p>Collaborative exploration by energy-constrained mobile robots. S Das, D Dereniowski, C Karousatou, International Colloquium on Structural Information and Communication Complexity. SpringerDas, S., Dereniowski, D., and Karousatou, C. (2015). Collaborative exploration by energy-constrained mobile robots. In International Colloquium on Structural Infor- mation and Communication Complexity, pages 357-369. Springer.</p>
<p>Exploring an unknown graph. X Deng, C H Papadimitriou, Journal of Graph Theory. 323Deng, X. and Papadimitriou, C. H. (1999). Exploring an unknown graph. Journal of Graph Theory, 32(3):265- 297.</p>
<p>Fast collaborative graph exploration. D Dereniowski, Y Disser, A Kosowski, D Pajkak, P Uznański, International Colloquium on Automata, Languages, and Programming. SpringerDereniowski, D., Disser, Y., Kosowski, A., Pajkak, D., and Uznański, P. (2013). Fast collaborative graph ex- ploration. In International Colloquium on Automata, Languages, and Programming, pages 520-532. Springer.</p>
<p>Online graph exploration with advice. S Dobrev, R Královič, E Markou, International Colloquium on Structural Information and Communication Complexity. SpringerDobrev, S., Královič, R., and Markou, E. (2012). Online graph exploration with advice. In International Col- loquium on Structural Information and Communication Complexity, pages 267-278. Springer.</p>
<p>Learning to act by predicting the future. A Dosovitskiy, V Koltun, arXiv:1611.01779arXiv preprintDosovitskiy, A. and Koltun, V. (2016). Learning to act by predicting the future. arXiv preprint arXiv:1611.01779.</p>
<p>Optimal constrained graph exploration. C A Duncan, S G Kobourov, V A Kumar, ACM Transactions on Algorithms (TALG). 23Duncan, C. A., Kobourov, S. G., and Kumar, V. A. (2006). Optimal constrained graph exploration. ACM Transac- tions on Algorithms (TALG), 2(3):380-402.</p>
<p>H Edwards, A Storkey, arXiv:1606.02185Towards a neural statistician. arXiv preprintEdwards, H. and Storkey, A. (2016). Towards a neural statistician. arXiv preprint arXiv:1606.02185.</p>
<p>node2vec: Scalable feature learning for networks. A Grover, J Leskovec, Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. the 22nd ACM SIGKDD international conference on Knowledge discovery and data miningGrover, A. and Leskovec, J. (2016). node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining, pages 855-864.</p>
<p>Graphic programming using odd or even points chinese mathematics. M G Guan, V ol. 12Guan, M. G. (1962). Graphic programming using odd or even points chinese mathematics. V ol, 1(2):73-2.</p>
<p>Openstreetmap: Usergenerated street maps. M Haklay, P Weber, IEEE Pervasive Computing. 74Haklay, M. and Weber, P. (2008). Openstreetmap: User- generated street maps. IEEE Pervasive Computing, 7(4):12-18.</p>
<p>Online graph exploration algorithms for cycles and trees by multiple searchers. Y Higashikawa, N Katoh, S Langerman, S Tanigawa, Journal of Combinatorial Optimization. 282Higashikawa, Y., Katoh, N., Langerman, S., and Tanigawa, S.-i. (2014). Online graph exploration algorithms for cy- cles and trees by multiple searchers. Journal of Combi- natorial Optimization, 28(2):480-495.</p>
<p>Constructing competitive tours from local information. B Kalyanasundaram, K R Pruhs, Theoretical Computer Science. 1301Kalyanasundaram, B. and Pruhs, K. R. (1994). Construct- ing competitive tours from local information. Theoretical Computer Science, 130(1):125-138.</p>
<p>Semi-supervised classification with graph convolutional networks. T N Kipf, M Welling, arXiv:1609.02907arXiv preprintKipf, T. N. and Welling, M. (2016). Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907.</p>
<p>Set transformer: A framework for attention-based permutation-invariant neural networks. J Lee, Y Lee, J Kim, A R Kosiorek, S Choi, Y W Teh, arXiv:1810.00825arXiv preprintLee, J., Lee, Y., Kim, J., Kosiorek, A. R., Choi, S., and Teh, Y. W. (2018). Set transformer: A framework for attention-based permutation-invariant neural networks. arXiv preprint arXiv:1810.00825.</p>
<p>Online graph exploration: New results on old and new algorithms. N Megow, K Mehlhorn, P Schweitzer, Theoretical Computer Science. 463Megow, N., Mehlhorn, K., and Schweitzer, P. (2012). On- line graph exploration: New results on old and new al- gorithms. Theoretical Computer Science, 463:62-72.</p>
<p>Distributed representations of words and phrases and their compositionality. T Mikolov, I Sutskever, K Chen, G S Corrado, J Dean, Advances in neural information processing systems. Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., and Dean, J. (2013). Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems, pages 3111-3119.</p>
<p>The online graph exploration problem on restricted graphs. S Miyazaki, N Morimoto, Y Okabe, IEICE transactions on information and systems. 929Miyazaki, S., Morimoto, N., and Okabe, Y. (2009). The online graph exploration problem on restricted graphs. IEICE transactions on information and systems, 92(9):1620-1627.</p>
<p>Deepwalk: Online learning of social representations. B Perozzi, R Al-Rfou, S Skiena, Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. the 20th ACM SIGKDD international conference on Knowledge discovery and data miningPerozzi, B., Al-Rfou, R., and Skiena, S. (2014). Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 701-710.</p>
<p>Theoretical results on reinforcement learning with temporally abstract options. D Precup, R S Sutton, S Singh, European conference on machine learning. SpringerPrecup, D., Sutton, R. S., and Singh, S. (1998). Theoret- ical results on reinforcement learning with temporally abstract options. In European conference on machine learning, pages 382-393. Springer.</p>
<p>An analysis of several heuristics for the traveling salesman problem. D J Rosenkrantz, R E Stearns, Lewis, P M Ii, SIAM journal on computing. 63Rosenkrantz, D. J., Stearns, R. E., and Lewis, II, P. M. (1977). An analysis of several heuristics for the trav- eling salesman problem. SIAM journal on computing, 6(3):563-581.</p>
<p>Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, Advances in neural information processing systems. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. (2017). Attention is all you need. In Advances in neural infor- mation processing systems, pages 5998-6008.</p>
<p>P Veličković, G Cucurull, A Casanova, A Romero, P Lio, Y Bengio, arXiv:1710.10903Graph attention networks. arXiv preprintVeličković, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., and Bengio, Y. (2017). Graph attention net- works. arXiv preprint arXiv:1710.10903.</p>
<p>Pointer networks. O Vinyals, M Fortunato, Jaitly , N , Advances in neural information processing systems. Vinyals, O., Fortunato, M., and Jaitly, N. (2015). Pointer networks. In Advances in neural information processing systems, pages 2692-2700.</p>
<p>A frontier-based approach for autonomous exploration. B Yamauchi, Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97.'Towards New Computational Principles for Robotics and Automation. 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97.'Towards New Computational Principles for Robotics and AutomationIEEEYamauchi, B. (1997). A frontier-based approach for au- tonomous exploration. In Proceedings 1997 IEEE In- ternational Symposium on Computational Intelligence in Robotics and Automation CIRA'97.'Towards New Computational Principles for Robotics and Automation', pages 146-151. IEEE.</p>
<p>Deep sets. M Zaheer, S Kottur, S Ravanbakhsh, B Poczos, R R Salakhutdinov, A J Smola, Advances in neural information processing systems. Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R. R., and Smola, A. J. (2017). Deep sets. In Advances in neural information processing sys- tems, pages 3391-3401.</p>
<p>Link prediction based on graph neural networks. M Zhang, Y Chen, Advances in Neural Information Processing Systems. Zhang, M. and Chen, Y. (2018). Link prediction based on graph neural networks. In Advances in Neural Informa- tion Processing Systems, pages 5165-5175.</p>            </div>
        </div>

    </div>
</body>
</html>