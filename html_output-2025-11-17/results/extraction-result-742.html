<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-742 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-742</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-742</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-88500825</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1902.10347v1.pdf" target="_blank">ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery</a></p>
                <p><strong>Paper Abstract:</strong> Determining the causal structure of a set of variables is critical for both scientific inquiry and decision-making. However, this is often challenging in practice due to limited interventional data. Given that randomized experiments are usually expensive to perform, we propose a general framework and theory based on optimal Bayesian experimental design to select experiments for targeted causal discovery. That is, we assume the experimenter is interested in learning some function of the unknown graph (e.g., all descendants of a target node) subject to design constraints such as limits on the number of samples and rounds of experimentation. While it is in general computationally intractable to select an optimal experimental design strategy, we provide a tractable implementation with provable guarantees on both approximation and optimization quality based on submodularity. We evaluate the efficacy of our proposed method on both synthetic and real datasets, thereby demonstrating that our method realizes considerable performance gains over baseline strategies such as random sampling.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e742.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e742.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ABCD-Strategy</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Active Budgeted Causal Design Strategy (ABCD-Strategy)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Bayesian experimental-design method for targeted causal-structure discovery under sample and batch budget constraints that selects batched interventions to maximize mutual information about a target function of the DAG and uses tractable approximations (DAG bootstrap, MLE parameters, importance reweighting) with greedy submodular optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>ABCD-Strategy</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Selects multiset(s) of interventions in each pre-specified batch by maximizing an approximation to the expected mutual information (reduction in entropy) about a target functional f(G) of the unknown DAG. The method approximates the posterior over DAGs via a candidate set (MCMC or DAG-bootstrap), uses MLE estimates of edge parameters θ for each sampled DAG (empirical-Bayes style) to avoid marginalizing θ, computes importance weights for hypothetical new interventional data as P(y | G_i, ξ, θ_Gi_MLE), and then greedily builds the multiset of interventions exploiting DR-submodularity to get a (1-1/e) approximation guarantee.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Batched interventional experiments on simulated DAGs and DREAM4 in-silico gene networks</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Batch-constrained experimental/interactive setting where the experimenter chooses interventions from a conservative family I* and collects N_b samples per batch over B batches; evaluated on synthetic DAGs (Erdös-Rényi, chain graphs) and the DREAM4 simulated gene-regulatory datasets (in-silico perturbation/knockdown data). The environment allows active selection of interventions but with budgeted batches and possibly limits on unique interventions per batch.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Implicit Bayesian refutation and reweighting: candidate DAGs (including those reflecting spurious edges) are downweighted via likelihood of newly observed interventional data (importance weights P(y | G_i, ξ, θ_Gi_MLE)), and targeted interventions are chosen to maximally reduce posterior entropy of the feature f(G), thereby empirically disconfirming spurious edges/models.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Confounding/spurious edges encoded as alternative DAGs in the posterior; finite-sample noise that can produce spurious conditional independencies or orientations; irrelevant/uninformative interventions (not directly named as 'distractors' but treated via posterior updates).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>No explicit separate detector; models that encode spurious signals are detected implicitly by having low likelihood on newly observed interventional data and so receive lower posterior weight in importance reweighting.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Importance-weight reweighting using MLE parameters: approximate importance weights ŝ_w_i = P(y | G_i, ξ, θ_Gi_MLE) are used to update the candidate-graph weights, effectively downweighting graphs/models inconsistent with new interventional observations (empirical Bayes posterior approximation).</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Targeted interventions chosen by mutual-information objective reduce posterior mass on DAGs containing spurious edges; repeated allocation (selecting same intervention multiple times) is allowed when that reduces entropy, enabling stronger refutation of spurious signals via more samples at informative interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Bayesian optimal experimental design using mutual information (expected reduction in entropy of f(G)) approximated by (1) sampling a candidate set of DAGs via DAG-bootstrap or MCMC, (2) computing likelihoods under MLE parameters, (3) importance-weighting hypothetical outcomes, and (4) greedily selecting interventions in the batch leveraging DR-submodularity for approximation guarantees.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Qualitative empirical results: ABCD substantially reduces posterior entropy compared to random and Chordal-Random baselines on synthetic DAGs (chain and Erdös-Rényi) and shows improved recovery of downstream-target functions on DREAM4 simulated gene networks; e.g., with 192 samples and 3 batches ABCD learns most graphs with high certainty in reported experiments. No detailed numeric precision/recall/SHD table for 'distractor-robust' variants specifically provided.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baseline random sampling and Chordal-Random show much smaller entropy reduction in the reported experiments; ABCD outperforms random and is comparable or better than BED (Ghassami et al., 2018) for the setups where comparison is possible. Exact numeric metrics (SHD, F1) versus a non-robust variant are not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mutual-information-driven batched experimental design with candidate-graph sampling and importance reweighting is a practical, consistent (for single-node interventions) approach that focuses statistical power on a target functional f(G); empirical-Bayes approximations (MLE θ) and importance-weight reweighting make computation tractable while still allowing the method to downweight models that explain away spurious correlations via interventional data. Greedy selection is justified by DR-submodularity, giving a (1-1/e) guarantee. The paper also demonstrates that some previously proposed utility functions (e.g., Ness et al. 2018) can be inconsistent and get stuck repeatedly selecting the same intervention, failing to refute spurious models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery', 'publication_date_yy_mm': '2019-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e742.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e742.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mutual-Information Utility (MI)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mutual-Information-based Expected Utility for Experimental Design</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A utility function defined as the expected reduction in entropy of a target functional f(G) after hypothetical interventional observations; selecting interventions that maximize expected mutual information leads to maximal expected decrease in uncertainty about the target.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Mutual-information utility</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Utility U_f_MI(ξ; D) = H(f | D) − E_{y∼P(y|D,ξ)} H(f | D, y, ξ); in practice approximated by sampling candidate DAGs and using importance reweighting to approximate the posterior after hypothetical data. In the infinite-sample per-intervention limit, this reduces to selecting interventions that minimize expected log I-MEC size (orient the most edges on average).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Batched interventional experimental setting (same as ABCD)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Used within the batched, budget-constrained intervention selection environment; supports adaptive selection across rounds and can select repeated interventions if adding more samples reduces entropy.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>When used within ABCD, MI drives selection of interventions that maximally reduce posterior uncertainty and thus helps disconfirm spurious edges by collecting targeted interventions that contradict models encoding spurious correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Selects interventions that maximize expected mutual information about the target functional; evaluated in batch-constrained setting.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mutual information is shown to be budgeted-batch consistent for single-node interventions and in the infinite-sample limit selects interventions that minimize expected log I-MEC sizes (paralleling graph-based rules using Meek propagation). It also naturally handles finite-sample allocation decisions (including selecting the same intervention multiple times).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery', 'publication_date_yy_mm': '2019-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e742.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e742.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Importance-weighted empirical-Bayes reweighting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Importance-weighted empirical-Bayes posterior approximation (using MLE θ and likelihood-based reweighting)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A tractable approximation to the posterior update that replaces marginalization over θ by using MLE parameter estimates for each candidate DAG and reweights candidate DAGs by the likelihood of hypothetical new interventional outcomes, enabling fast importance-sampling approximations to expected utilities.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Importance-weighted empirical-Bayes reweighting</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>For a sampled candidate DAG G_i with MLE parameters θ_{G_i}^{MLE}, compute ŝ_w_i = P(y | G_i, ξ, θ_{G_i}^{MLE}) and form an empirical-Bayes-style posterior P̃(G | D) ∝ P(D | G, θ_G^{MLE}) P(G). Use these importance weights when approximating H(f | D, y, ξ) and expected mutual information to avoid parameter integration and to cheaply update graph weights given hypothetical/intervened data.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Batch-interventional experimental design (same environments as ABCD experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Approximates posterior updates when hypothetical interventional data are simulated/considered during design; used on synthetic DAGs and DREAM4 simulated gene-expression datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Downweights candidate DAGs/models (including those encoding spurious edges) via likelihood of newly observed interventional data computed at MLE parameters; effectively reduces posterior support for spurious models that fail to explain interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious edges / alternative DAGs in posterior that are inconsistent with interventional outcomes; finite-sample noise in observational data that may have supported spurious orientations.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>No explicit separate detector; candidate graphs that represent spurious signals will produce low likelihoods for observed interventional outcomes and hence get low importance weights.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Direct likelihood-based downweighting (ŝ_w_i ∝ P(y | G_i, ξ, θ_Gi_MLE)).</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Interventions selected by the MI objective, combined with the importance-weighted reweighting, reduce the posterior mass on spurious DAGs by producing interventional outcomes contradictory to those DAGs' predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Used within the expected-utility computation: hypothetical outcomes y are simulated under each candidate DAG at its MLE parameters and used to compute importance weights for posterior updates; these are averaged to evaluate expected MI and guide greedy selection.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Reported to be effective in practice: enables computation of MI-based utility and empirical gains over random/Chordal-Random baselines; no explicit numeric metrics isolating the benefit of importance-weighting vs full marginalization were provided.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The empirical-Bayes / importance-weighted approximation makes mutual-information-based design tractable and preserves desirable properties (consistency for single-node interventions under the given approximations). It operationalizes downweighting of spurious DAGs without expensive marginalization over θ, justified asymptotically by Bernstein–von Mises concentration of θ around MLE.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery', 'publication_date_yy_mm': '2019-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e742.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e742.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DAG-bootstrap posterior approximation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Nonparametric DAG bootstrap (candidate set approximation of posterior over DAGs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach to approximate the posterior over DAGs by repeatedly resampling the dataset (with replacement), learning a DAG on each bootstrap dataset, and weighting the resulting candidate DAGs to form an approximate posterior used for expected-utility computation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Data analysis with Bayesian networks: A bootstrap approach</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>DAG-bootstrap (candidate set posterior approximation)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Generate T bootstrap datasets from D, learn a DAG on each (using a DAG learner that handles observational and interventional data) to produce a candidate set Ĝ_T; weight each G ∈ Ĝ_T by unnormalized posterior P(G) P(D | G) to approximate P(G | D) for downstream expected-utility calculations.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same batched experimental design environments (synthetic DAGs, DREAM4)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Used to provide a tractable candidate set of high-probability DAGs in place of enumerating the superexponential space of DAGs; candidate set is reused across hypothetical updates with importance-weight reweighting.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>When combined with MI-based selection and importance reweighting, bootstrap-sampled candidate DAGs that represent spurious models will acquire low posterior weight after informative interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Provides the candidate graph set on which hypothetical interventional outcomes are simulated for expected-utility evaluation in each batch.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>DAG-bootstrap is a practical alternative to MCMC for constructing a high-probability candidate set of DAGs for expected-utility computation; combined with MLE parameter estimates and importance reweighting it enables tractable mutual-information based design in the batched setting.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery', 'publication_date_yy_mm': '2019-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e742.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e742.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ness et al. (2018) utility</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Utility based on expected number of additionally oriented edges (Ness et al., 2018)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A previously proposed Bayesian experimental-design utility that scores interventions by expected number of additional edges that can be oriented given the observational MEC; shown in this paper to be, in general, not consistent in the budgeted batched setting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Bayesian active learning experimental design for inferring signaling networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Ness et al. (2018) edge-orientation utility</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Scores candidate interventions according to the expected increase in number of oriented edges in the interventional Markov equivalence classes relative to the observational MEC; designed for batched experimental design but focuses on orienting edges via Meek-rule propagation.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Batched experimental intervention design (as discussed in related work)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Proposed for active learning of signaling networks where experimental budget constraints make selecting informative interventions necessary; evaluated in prior work in batched setups.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Select interventions that orient the greatest expected number of edges in I-essential graphs (using Meek rules) given the known MEC.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>This utility can be inconsistent in budgeted batch settings: the paper gives a counterexample where the Ness et al. utility repeatedly selects the same intervention and thus fails to fully identify the target graph or refute spurious models. The ABCD paper argues that MI-based utilities avoid this failure mode and proves consistency for single-node interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery', 'publication_date_yy_mm': '2019-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>A Bayesian active learning experimental design for inferring signaling networks <em>(Rating: 2)</em></li>
                <li>Budgeted experiment design for causal structure learning <em>(Rating: 2)</em></li>
                <li>Two optimal strategies for active learning of causal models from interventional data <em>(Rating: 2)</em></li>
                <li>Reconstructing causal biological networks through active learning <em>(Rating: 2)</em></li>
                <li>Active learning for structure in Bayesian networks <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-742",
    "paper_id": "paper-88500825",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "ABCD-Strategy",
            "name_full": "Active Budgeted Causal Design Strategy (ABCD-Strategy)",
            "brief_description": "A Bayesian experimental-design method for targeted causal-structure discovery under sample and batch budget constraints that selects batched interventions to maximize mutual information about a target function of the DAG and uses tractable approximations (DAG bootstrap, MLE parameters, importance reweighting) with greedy submodular optimization.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "ABCD-Strategy",
            "method_description": "Selects multiset(s) of interventions in each pre-specified batch by maximizing an approximation to the expected mutual information (reduction in entropy) about a target functional f(G) of the unknown DAG. The method approximates the posterior over DAGs via a candidate set (MCMC or DAG-bootstrap), uses MLE estimates of edge parameters θ for each sampled DAG (empirical-Bayes style) to avoid marginalizing θ, computes importance weights for hypothetical new interventional data as P(y | G_i, ξ, θ_Gi_MLE), and then greedily builds the multiset of interventions exploiting DR-submodularity to get a (1-1/e) approximation guarantee.",
            "environment_name": "Batched interventional experiments on simulated DAGs and DREAM4 in-silico gene networks",
            "environment_description": "Batch-constrained experimental/interactive setting where the experimenter chooses interventions from a conservative family I* and collects N_b samples per batch over B batches; evaluated on synthetic DAGs (Erdös-Rényi, chain graphs) and the DREAM4 simulated gene-regulatory datasets (in-silico perturbation/knockdown data). The environment allows active selection of interventions but with budgeted batches and possibly limits on unique interventions per batch.",
            "handles_distractors": true,
            "distractor_handling_technique": "Implicit Bayesian refutation and reweighting: candidate DAGs (including those reflecting spurious edges) are downweighted via likelihood of newly observed interventional data (importance weights P(y | G_i, ξ, θ_Gi_MLE)), and targeted interventions are chosen to maximally reduce posterior entropy of the feature f(G), thereby empirically disconfirming spurious edges/models.",
            "spurious_signal_types": "Confounding/spurious edges encoded as alternative DAGs in the posterior; finite-sample noise that can produce spurious conditional independencies or orientations; irrelevant/uninformative interventions (not directly named as 'distractors' but treated via posterior updates).",
            "detection_method": "No explicit separate detector; models that encode spurious signals are detected implicitly by having low likelihood on newly observed interventional data and so receive lower posterior weight in importance reweighting.",
            "downweighting_method": "Importance-weight reweighting using MLE parameters: approximate importance weights ŝ_w_i = P(y | G_i, ξ, θ_Gi_MLE) are used to update the candidate-graph weights, effectively downweighting graphs/models inconsistent with new interventional observations (empirical Bayes posterior approximation).",
            "refutation_method": "Targeted interventions chosen by mutual-information objective reduce posterior mass on DAGs containing spurious edges; repeated allocation (selecting same intervention multiple times) is allowed when that reduces entropy, enabling stronger refutation of spurious signals via more samples at informative interventions.",
            "uses_active_learning": true,
            "inquiry_strategy": "Bayesian optimal experimental design using mutual information (expected reduction in entropy of f(G)) approximated by (1) sampling a candidate set of DAGs via DAG-bootstrap or MCMC, (2) computing likelihoods under MLE parameters, (3) importance-weighting hypothetical outcomes, and (4) greedily selecting interventions in the batch leveraging DR-submodularity for approximation guarantees.",
            "performance_with_robustness": "Qualitative empirical results: ABCD substantially reduces posterior entropy compared to random and Chordal-Random baselines on synthetic DAGs (chain and Erdös-Rényi) and shows improved recovery of downstream-target functions on DREAM4 simulated gene networks; e.g., with 192 samples and 3 batches ABCD learns most graphs with high certainty in reported experiments. No detailed numeric precision/recall/SHD table for 'distractor-robust' variants specifically provided.",
            "performance_without_robustness": "Baseline random sampling and Chordal-Random show much smaller entropy reduction in the reported experiments; ABCD outperforms random and is comparable or better than BED (Ghassami et al., 2018) for the setups where comparison is possible. Exact numeric metrics (SHD, F1) versus a non-robust variant are not provided.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Mutual-information-driven batched experimental design with candidate-graph sampling and importance reweighting is a practical, consistent (for single-node interventions) approach that focuses statistical power on a target functional f(G); empirical-Bayes approximations (MLE θ) and importance-weight reweighting make computation tractable while still allowing the method to downweight models that explain away spurious correlations via interventional data. Greedy selection is justified by DR-submodularity, giving a (1-1/e) guarantee. The paper also demonstrates that some previously proposed utility functions (e.g., Ness et al. 2018) can be inconsistent and get stuck repeatedly selecting the same intervention, failing to refute spurious models.",
            "uuid": "e742.0",
            "source_info": {
                "paper_title": "ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery",
                "publication_date_yy_mm": "2019-02"
            }
        },
        {
            "name_short": "Mutual-Information Utility (MI)",
            "name_full": "Mutual-Information-based Expected Utility for Experimental Design",
            "brief_description": "A utility function defined as the expected reduction in entropy of a target functional f(G) after hypothetical interventional observations; selecting interventions that maximize expected mutual information leads to maximal expected decrease in uncertainty about the target.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "Mutual-information utility",
            "method_description": "Utility U_f_MI(ξ; D) = H(f | D) − E_{y∼P(y|D,ξ)} H(f | D, y, ξ); in practice approximated by sampling candidate DAGs and using importance reweighting to approximate the posterior after hypothetical data. In the infinite-sample per-intervention limit, this reduces to selecting interventions that minimize expected log I-MEC size (orient the most edges on average).",
            "environment_name": "Batched interventional experimental setting (same as ABCD)",
            "environment_description": "Used within the batched, budget-constrained intervention selection environment; supports adaptive selection across rounds and can select repeated interventions if adding more samples reduces entropy.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": "When used within ABCD, MI drives selection of interventions that maximally reduce posterior uncertainty and thus helps disconfirm spurious edges by collecting targeted interventions that contradict models encoding spurious correlations.",
            "uses_active_learning": true,
            "inquiry_strategy": "Selects interventions that maximize expected mutual information about the target functional; evaluated in batch-constrained setting.",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Mutual information is shown to be budgeted-batch consistent for single-node interventions and in the infinite-sample limit selects interventions that minimize expected log I-MEC sizes (paralleling graph-based rules using Meek propagation). It also naturally handles finite-sample allocation decisions (including selecting the same intervention multiple times).",
            "uuid": "e742.1",
            "source_info": {
                "paper_title": "ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery",
                "publication_date_yy_mm": "2019-02"
            }
        },
        {
            "name_short": "Importance-weighted empirical-Bayes reweighting",
            "name_full": "Importance-weighted empirical-Bayes posterior approximation (using MLE θ and likelihood-based reweighting)",
            "brief_description": "A tractable approximation to the posterior update that replaces marginalization over θ by using MLE parameter estimates for each candidate DAG and reweights candidate DAGs by the likelihood of hypothetical new interventional outcomes, enabling fast importance-sampling approximations to expected utilities.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Importance-weighted empirical-Bayes reweighting",
            "method_description": "For a sampled candidate DAG G_i with MLE parameters θ_{G_i}^{MLE}, compute ŝ_w_i = P(y | G_i, ξ, θ_{G_i}^{MLE}) and form an empirical-Bayes-style posterior P̃(G | D) ∝ P(D | G, θ_G^{MLE}) P(G). Use these importance weights when approximating H(f | D, y, ξ) and expected mutual information to avoid parameter integration and to cheaply update graph weights given hypothetical/intervened data.",
            "environment_name": "Batch-interventional experimental design (same environments as ABCD experiments)",
            "environment_description": "Approximates posterior updates when hypothetical interventional data are simulated/considered during design; used on synthetic DAGs and DREAM4 simulated gene-expression datasets.",
            "handles_distractors": true,
            "distractor_handling_technique": "Downweights candidate DAGs/models (including those encoding spurious edges) via likelihood of newly observed interventional data computed at MLE parameters; effectively reduces posterior support for spurious models that fail to explain interventions.",
            "spurious_signal_types": "Spurious edges / alternative DAGs in posterior that are inconsistent with interventional outcomes; finite-sample noise in observational data that may have supported spurious orientations.",
            "detection_method": "No explicit separate detector; candidate graphs that represent spurious signals will produce low likelihoods for observed interventional outcomes and hence get low importance weights.",
            "downweighting_method": "Direct likelihood-based downweighting (ŝ_w_i ∝ P(y | G_i, ξ, θ_Gi_MLE)).",
            "refutation_method": "Interventions selected by the MI objective, combined with the importance-weighted reweighting, reduce the posterior mass on spurious DAGs by producing interventional outcomes contradictory to those DAGs' predictions.",
            "uses_active_learning": true,
            "inquiry_strategy": "Used within the expected-utility computation: hypothetical outcomes y are simulated under each candidate DAG at its MLE parameters and used to compute importance weights for posterior updates; these are averaged to evaluate expected MI and guide greedy selection.",
            "performance_with_robustness": "Reported to be effective in practice: enables computation of MI-based utility and empirical gains over random/Chordal-Random baselines; no explicit numeric metrics isolating the benefit of importance-weighting vs full marginalization were provided.",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "The empirical-Bayes / importance-weighted approximation makes mutual-information-based design tractable and preserves desirable properties (consistency for single-node interventions under the given approximations). It operationalizes downweighting of spurious DAGs without expensive marginalization over θ, justified asymptotically by Bernstein–von Mises concentration of θ around MLE.",
            "uuid": "e742.2",
            "source_info": {
                "paper_title": "ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery",
                "publication_date_yy_mm": "2019-02"
            }
        },
        {
            "name_short": "DAG-bootstrap posterior approximation",
            "name_full": "Nonparametric DAG bootstrap (candidate set approximation of posterior over DAGs)",
            "brief_description": "An approach to approximate the posterior over DAGs by repeatedly resampling the dataset (with replacement), learning a DAG on each bootstrap dataset, and weighting the resulting candidate DAGs to form an approximate posterior used for expected-utility computation.",
            "citation_title": "Data analysis with Bayesian networks: A bootstrap approach",
            "mention_or_use": "use",
            "method_name": "DAG-bootstrap (candidate set posterior approximation)",
            "method_description": "Generate T bootstrap datasets from D, learn a DAG on each (using a DAG learner that handles observational and interventional data) to produce a candidate set Ĝ_T; weight each G ∈ Ĝ_T by unnormalized posterior P(G) P(D | G) to approximate P(G | D) for downstream expected-utility calculations.",
            "environment_name": "Same batched experimental design environments (synthetic DAGs, DREAM4)",
            "environment_description": "Used to provide a tractable candidate set of high-probability DAGs in place of enumerating the superexponential space of DAGs; candidate set is reused across hypothetical updates with importance-weight reweighting.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": "When combined with MI-based selection and importance reweighting, bootstrap-sampled candidate DAGs that represent spurious models will acquire low posterior weight after informative interventions.",
            "uses_active_learning": true,
            "inquiry_strategy": "Provides the candidate graph set on which hypothetical interventional outcomes are simulated for expected-utility evaluation in each batch.",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "DAG-bootstrap is a practical alternative to MCMC for constructing a high-probability candidate set of DAGs for expected-utility computation; combined with MLE parameter estimates and importance reweighting it enables tractable mutual-information based design in the batched setting.",
            "uuid": "e742.3",
            "source_info": {
                "paper_title": "ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery",
                "publication_date_yy_mm": "2019-02"
            }
        },
        {
            "name_short": "Ness et al. (2018) utility",
            "name_full": "Utility based on expected number of additionally oriented edges (Ness et al., 2018)",
            "brief_description": "A previously proposed Bayesian experimental-design utility that scores interventions by expected number of additional edges that can be oriented given the observational MEC; shown in this paper to be, in general, not consistent in the budgeted batched setting.",
            "citation_title": "A Bayesian active learning experimental design for inferring signaling networks",
            "mention_or_use": "mention",
            "method_name": "Ness et al. (2018) edge-orientation utility",
            "method_description": "Scores candidate interventions according to the expected increase in number of oriented edges in the interventional Markov equivalence classes relative to the observational MEC; designed for batched experimental design but focuses on orienting edges via Meek-rule propagation.",
            "environment_name": "Batched experimental intervention design (as discussed in related work)",
            "environment_description": "Proposed for active learning of signaling networks where experimental budget constraints make selecting informative interventions necessary; evaluated in prior work in batched setups.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": true,
            "inquiry_strategy": "Select interventions that orient the greatest expected number of edges in I-essential graphs (using Meek rules) given the known MEC.",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "This utility can be inconsistent in budgeted batch settings: the paper gives a counterexample where the Ness et al. utility repeatedly selects the same intervention and thus fails to fully identify the target graph or refute spurious models. The ABCD paper argues that MI-based utilities avoid this failure mode and proves consistency for single-node interventions.",
            "uuid": "e742.4",
            "source_info": {
                "paper_title": "ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery",
                "publication_date_yy_mm": "2019-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "A Bayesian active learning experimental design for inferring signaling networks",
            "rating": 2,
            "sanitized_title": "a_bayesian_active_learning_experimental_design_for_inferring_signaling_networks"
        },
        {
            "paper_title": "Budgeted experiment design for causal structure learning",
            "rating": 2,
            "sanitized_title": "budgeted_experiment_design_for_causal_structure_learning"
        },
        {
            "paper_title": "Two optimal strategies for active learning of causal models from interventional data",
            "rating": 2,
            "sanitized_title": "two_optimal_strategies_for_active_learning_of_causal_models_from_interventional_data"
        },
        {
            "paper_title": "Reconstructing causal biological networks through active learning",
            "rating": 2,
            "sanitized_title": "reconstructing_causal_biological_networks_through_active_learning"
        },
        {
            "paper_title": "Active learning for structure in Bayesian networks",
            "rating": 1,
            "sanitized_title": "active_learning_for_structure_in_bayesian_networks"
        }
    ],
    "cost": 0.014513249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery</p>
<p>Raj Agrawal 
MIT MIT MIT MIT-IBM Watson AI Lab IBM Research NY MIT</p>
<p>Chandler Squires 
MIT MIT MIT MIT-IBM Watson AI Lab IBM Research NY MIT</p>
<p>Karren Yang 
MIT MIT MIT MIT-IBM Watson AI Lab IBM Research NY MIT</p>
<p>Karthikeyan Shanmugam 
MIT MIT MIT MIT-IBM Watson AI Lab IBM Research NY MIT</p>
<p>Caroline Uhler 
MIT MIT MIT MIT-IBM Watson AI Lab IBM Research NY MIT</p>
<p>ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery</p>
<p>Determining the causal structure of a set of variables is critical for both scientific inquiry and decision-making. However, this is often challenging in practice due to limited interventional data. Given that randomized experiments are usually expensive to perform, we propose a general framework and theory based on optimal Bayesian experimental design to select experiments for targeted causal discovery. That is, we assume the experimenter is interested in learning some function of the unknown graph (e.g., all descendants of a target node) subject to design constraints such as limits on the number of samples and rounds of experimentation. While it is in general computationally intractable to select an optimal experimental design strategy, we provide a tractable implementation with provable guarantees on both approximation and optimization quality based on submodularity. We evaluate the efficacy of our proposed method on both synthetic and real datasets, thereby demonstrating that our method realizes considerable performance gains over baseline strategies such as random sampling.</p>
<p>Introduction</p>
<p>Determining the causal structure of a set of variables is a fundamental task in causal inference, with widespread applications not only in artificial intelligence but also in scientific domains such as biology and economics (Friedman et al., 2000;Pearl, 2003;Robins et al., 2000;Spirtes et al., 2000). One of the most common ways of representing causal structure is through a directed acyclic graph (DAG), where a directed edge between two variables in the DAG represents a direct causal effect and a directed path indicates an indirect causal effect (Spirtes et al., 2000).</p>
<p>Causal structure learning is intrinsically hard, since a DAG is generally only identifiable up to its Markov equivalence class (MEC) (Verma and Pearl, 1991;Andersson et al., 1997). Identifiability can be improved by performing interventions (Hauser and Bühlmann, 2012;Yang et al., 2018), and several algorithms have been proposed for structure learning from a combination of observational and interventional data (Wang et al., 2017;Hauser and Bühlmann, 2012;Yang et al., 2018). Since experiments tend to be costly in practice, a natural question is how principled experimental design (i.e., selection of intervention targets) can be leveraged to maximize the performance of these algorithms under budget constraints.</p>
<p>Seminal works by Tong and Koller (2001) and Murphy (2001) showed that experimental design can improve structure recovery in causal DAG models. However, these methods assume a basic framework in which experiments are performed one sample at a time. In practice, experimenters often perform a batch of interventions and collect samples over multiple rounds of experiments; and they must also factor in budget and feasibility constraints, such as on the number of unique interventions that can be performed in a single experiment, the number of experimental rounds, and the total number of samples to be collected. In genomics, for instance, genome editing technologies have enabled the collection of batches of large-scale interventional gene expression data (Dixit et al., 2016). An imminent problem is understanding how to optimally select a batch of interventions and allocate samples across these interventions, over multiple experimental rounds in a computationally tractable manner.</p>
<p>Since the initial works by Tong and Koller (2001) and Murphy (2001), there have been a number of new experimental design methods under budget constraints (Hauser and Bühlmann, 2014;Ghassami et al., 2018;Ness et al., 2018). These methods suffer from two drawbacks: (1) poor computational scaling (cf.</p>
<p>Generalizing the frameworks in (Tong and Koller, 2001;Murphy, 2001;Cho et al., 2016;Hauser and Bühlmann, 2014;Ness et al., 2018), we assume the experimenter is interested in learning some function f (G) of the unknown graph G. Returning to gene regulation, one might set f (G) to indicate whether some gene X is downstream of some gene Y , i.e. if X is a descendant of Y in G. Using targeted experimental design, all statistical power is placed in learning the target function rather than being agnostic to recovering all features in the graph. In addition, we also explicitly take into account that only finitely many samples are allowed in each round, and work under various budget constraints such as a limit on the number of rounds of experimentation.</p>
<p>We start by reviewing causal DAGs in Section 2 and then propose an entropy-based score function that generalizes the one by Tong and Koller (2001) and Murphy (2001) in Section 3. Since optimizing this score function is in general computationally intractable, we propose our ABCD-Strategy consisting of approximations via weighted importance sampling and greedy optimization in Section 4. We also provide guarantees for this algorithm based on submodularity. Further, in contrast to earlier score functions, we show that our proposed score function is provably consistent. Finally, in Section 5 we demonstrate the empirical gains of the proposed method over random sampling on both synthetic and real datasets.</p>
<p>Preliminaries</p>
<p>Causal DAGs:</p>
<p>Let G = ([p], A) be a directed acyclic graph (DAG) with vertices [p] := {1, . . . , p} and directed edges A, where (i, j) ∈ A represents the arrow i → j. A linear causal model is specified by a DAG G and a corresponding set of edge weights θ ∈ R |A| . Each node i in G is associated with a random variable X i . Under the Markov Assumption, each variable X i is conditionally independent of its nondescendants given its parents, which implies that the joint distribution factors as Spirtes et al., 2000, Chapter 4). This factorization implies a set of conditional independence (CI) relations; the Markov equivalence class (MEC) of a DAG G consists of all DAGs that share the same CI relations (Lauritzen, 1996, Chapter 3). The essential graph Ess(G) is a partially oriented graph that uniquely represents the MEC of a DAG by placing directed arrows on edges consistent across the equivalence class and leaves the other edges undirected (Andersson et al., 1997).
p i=1 P X i | Pa G (X i ) , where Pa G (X i ) denotes the parents of node X i (</p>
<p>Learning with Interventions:</p>
<p>Let intervention I ⊆ [p] be a set of intervention targets. Intervening on I removes the incoming edges to the random variables X I := (X i ) i∈I in G and sets the joint distribution of X I to a new interventional distribution P I . The resulting mutilated graph is denoted by G I . A typical choice of P I is the product distribution i∈I f i (X i ), where each f i (X i ) is the probability density function for the intervention at X i . We denote by I * := {I 1 , · · · , I K } the set of all K ∈ N allowed interventions and by I ⊆ I * the subset of selected interventions. An intervention I = ∅ indicates observational data. We assume that I * is a conservative family of interventions, i.e., for any i ∈ [p], there exists some I j ∈ I * such that i / ∈ I j (Hauser and Bühlmann, 2012). Given a conservative family of targets I, two DAGs G 1 and G 2 are I-Markov equivalent if they are observationally Markov equivalent and for all I ∈ I, G I 1 and G I 2 have the same skeleta Bühlmann, 2012, 2015). The set of I-Markov equivalent DAGs can be represented by the I-essential graph Ess I (G), a partially directed graph with at least as many directed arrows as Ess(G) (Hauser and Bühlmann, 2012, Theorem 10).</p>
<p>Bayesian Inference over DAGs:</p>
<p>In various applications, the goal is to recover a function f (G) of the underlying causal DAG G given a mix of n independent observational and interventional samples D = {(X mi , I (m) ) : I (m) ∈ I * , m ∈ [n], i ∈ [p]}. For example, we might ask whether an undirected edge (i, j) is in A, or we might wish to discover which nodes are the parents of a node i. We can encode our prior structural knowledge about the underlying DAG through a prior P(G). The likelihood P(D | G) is obtained by marginalizing out θ:
P(D | G) = θ P(D, θ | G) dθ = θ P(D | θ, G)P(θ | G) dθ
and can be computed in closed-form for certain distributions (Geiger and Heckerman, 1999;Kuipers et al., 2014). Applying Bayes' Theorem yields the posterior distribution P(G | D) ∝ P(D | G)P(G), which describes the state of knowledge about G after observing the data D. Given the posterior, we can then compute E P(G|D) f (G), the posterior mean of some target function f (G). Note that when f is an indicator function, this quantity is a posterior probability.</p>
<p>Optimal Bayesian Experimental Design</p>
<p>Our goal is to learn some feature f (G) of the unknown graph through experimental design under budget constraints such as limited number of experimental rounds. In principle, this question can be answered using optimal Bayesian experimental design, namely by selecting the experiment that maximizes the expected value of some utility function U , where the expectation is with respect to hypothetical data generated according to our current beliefs (Chaloner and Verdinelli, 1995). Here, the expected utility function U is a function defined on multisets of I * :</p>
<p>Definition 3.1. The expected utility U f (ξ; D) of a multiset of interventions ξ ∈ Z I * for learning a function f (G) given currently collected data D is given by
U f (ξ; D) = E y∼P(y|D,ξ) U f (y, ξ; D) = E G,θ|D E y|G,θ,ξ U f (y, ξ; D), y ∈ R |ξ| ,(1)
where U f (y, ξ; D) ∈ R is a function measuring the utility of observing additional samples y from a proposed design ξ and |ξ| := I∈I * |# times I in ξ|. The optimal Bayesian design ξ * under a set of design constraints C is given by
ξ * ∈ arg max ξ∈Z I * ∩C U f (ξ; D).(2)
We denote samples collected from such an optimal strategy ξ * by D ξ * In Definition 3.1, y is distributed according to our current beliefs P(y | D, ξ) = E G,θ|D [P(y | G, θ, ξ)], a mixture distribution over (G, θ), and the utility function U f (y, ξ; D) is averaged over this distribution. There are many potential choices for U f (y, ξ; D), a popular one being mutual information. Tong and Koller (2001), Cho et al. (2016) and Murphy (2001) propose optimizing mutual information for the problem of recovering the full graph. More precisely, they consider the problem where f (G) = G in the active learning setting, where the experimenter can adaptively collect one sample at a time. We here extend their framework to general functions f (G) and the batched setting, where multiple samples are collected at once and the total number of batches is fixed by the experimenter. Hence, U f must be defined on multisets instead of elements of I * since multiple samples (i.e., interventions of the same type) may be collected in each batch. Note that the difficulty in solving Eq. (2) stems from the constraint set C, which renders this optimization problem combinatorial.</p>
<p>Recently, Ness et al. (2018) proposed a Bayesian experimental design method to work in the batched setting.</p>
<p>The authors proposed a utility function based on the expected number of additional edges that could be oriented by performing a particular intervention given the observational MEC. This function is similar to the one proposed by Hauser and Bühlmann (2014) and Ghassami et al. (2018), in which interventions are chosen that fully identify the causal network given the MEC. Unfortunately, the algorithm in Ness et al. (2018) has factorial dependence on the size of the batch; in addition, we prove in Appendix A.3 that their proposed utility function is, in general, not consistent; see Definition 3.3 for a definition of consistency.</p>
<p>We therefore follow the approach taken by Tong and Koller (2001) and Murphy (2001) and consider the utility function U f (y, ξ; D) to be given by mutual information. Maximizing the mutual information is equivalent to picking the set of interventions that leads to the greatest expected decrease in entropy of f (G). The mutual information utility function is given by
U f M.I. (y, ξ; D) := H(f | D) − H(f | D, y = y, ξ), (3) where the entropy H(f | D) equals e:f (G)=e −P(f (G) = e | D) log P(f (G) = e | D)
,
and P(f (G) = e | D) = E P(G|D) 1(f (G) = e), P(G | D) ∝ θ P(D | G, θ)P(θ | G)P(G).
To better understand the behavior of U f M.I. , we prove the following proposition, which highlights the behavior of U f M.I. in the limit of infinite samples per intervention; this is the setting studied by Hauser and Bühlmann (2014) and Ghassami et al. (2018).</p>
<p>Proposition 3.2. Suppose that the Markov equivalence class G of G * is known and the goal is to identify the underlying true DAG G * . Furthermore, assume a uniform prior over G, infinite samples per intervention I ∈ I, and at most K unique interventions per batch as in Ghassami et al. (2018). Then, U M.I. selects the interventions
I M.I. ∈ arg min |I|≤K 1 |G| G∈G log 2 |Ess I (G)| where |Ess I (G)| := |{G ∈ G : G ∈ Ess I (G)}|.
This result (proof in Appendix) shows that in the limiting case, mutual information selects interventions that lead to the finest expected log I-MEC sizes. This limiting behavior of mutual information parallels what graph-based score functions do, such as the ones considered by Hauser and Bühlmann (2014), Ghassami et al. (2018) and Ness et al. (2018), that invoke the</p>
<p>Meek Rules (Verma and Pearl, 1992) to select interventions that orient the most number of edges in the I-essential graphs (in expectation).</p>
<p>A score function based on mutual information is particularly appealing since it not only has desirable properties in the infinite sample setting, but also does not require the MEC to be known, naturally handling the case of finite sample sizes. In particular, a score function based solely on Meek rules will not pick the same intervention twice by definition, since repeating the same intervention does not improve identifiability. As a result, adapting graph-based score functions in the finite sample regime requires first constructing an intervention set and then allocating samples instead of jointly picking and allocating samples. Mutual information, on the other hand, can pick the same intervention twice; for example if a particular intervention is very informative, selecting it twice and allocating more samples to it might lead to a greater expected decrease in entropy than a new intervention.</p>
<p>Budget Constraints</p>
<p>So far we have not specified the constraint set C in Eq. (2). To this end, we assume that the experimenter has a total of N samples to allocate across B batches. While one could try to optimize the partition of N samples across batches, in this work we study the simpler case where each batch b, 1 ≤ b ≤ B, receives a pre-specified amount of samples N b with b N b = N . For simplifying notation we assume throughout that
N b = N B .
We leave the study of adaptive batch sizes N b for future work. The constraint set then equals,
C N,b := {ξ ∈ Z I * : |ξ| = N b },(4)
where the subscripts on C emphasize the dependence on N and b. Then, the optimal design in batch b is obtained by solving the following combinatorial optimization problem:
ξ * b ∈ arg max ξ∈Z I * ∩C N,b U (ξ; D b−1 ),(5)
where
D b−1 := [D ξ * 1 , · · · , D ξ * b−1 ]
is all the data collected at the start of batch b and U (ξ; D b−1 ) could, for example, be the mutual information defined in Eq. (3). Notice that while a particular form of U (ξ; D b−1 ) is provided in Definition 3.1, U (ξ; D b−1 ) need not necessarily be a Bayesian utility function to fit within the framework of Eq. (5).</p>
<p>We now define a natural notion of consistency for any experimental design method that can be cast as an optimization routine in the form of Eq. (5). Since the consistency of a utility function should not depend on a specific constraint set such as C N,b , Definition 3.3 assumes the constraint set is arbitrary and set by the practitioner.
Definition 3.3. Suppose f (G) is identifiable in Ess I * (G * ), where G * is the true unknown DAG. Let C N,b , 1 ≤ b ≤ B denote the constraints in batch b. A utility function U (ξ) is budgeted batch consistent for learning a target feature f (G) if P (f (G) | D B ) µ * a.s. − −−− → 1(f (G) = f (G * )), as N, B → ∞, where µ * is the law determined by the true unknown causal DAG (G * , θ * ) Theorem 3.4. U f M.I. is budgeted batch consistent for single-node interventions, i.e., when I * = {{1}, · · · , {p}}.
Remark 1. While Theorem 3.4 may not be surprising (proof in the Appendix), we found that various utility functions that seem natural and have been proposed in earlier work are not consistent in the budgeted setting. In particular, in Appendix A.3 we show that the utility function proposed by Ness et al. (2018) is not consistent for single-node interventions. The main issue is that there are DAGs and constraint sets for which the same interventions keep getting selected, instead of selecting new interventions to fully identify f (G).</p>
<p>Tractable Algorithm</p>
<p>While Section 3 provides a general framework for targeted experimental design, there are several computational challenges that we have not yet addressed. The first challenge is computing U f M.I. (ξ; D). This objective function requires summing over an exponential number of DAGs and marginalizing out the edge weights θ. In this section, we discuss how to approximate U f M.I. (ξ; D) by sampling graphs (either through MCMC or the DAG-bootstrap Friedman et al. (1999)) and using the maximum likelihood estimator of θ for each graph. Taken together, these approximations not only allow the mutual information score to be computed tractably but also lead to desirable optimization properties. In particular, we prove in Theorem 4.1 that our approximate utility function is submodular. This property enables optimizing the approximate objective in a sequential greedy fashion with provable guarantees on optimization quality.</p>
<p>Expectation over (G, θ)</p>
<p>A serious problem from a computational perspective is the expectation over (G, θ) in Definition 3.1. Since the number of DAGs grows superexponentially with p, enumerating all possible DAGs is intractable. Instead, in each batch b, we propose to sample T graphs according to the posterior P(G | D b−1 ). This can be done using a variety of different Markov chain Monte-Carlo (MCMC) samplers; see for example Heckerman et al. (1997); Ellis and Wong (2008); Friedman and Koller (2003); Niinimaki et al. (2016); Kuipers and Moffa (2017); Madigan and York (1995); Grzegorczyk and Husmeier (2008); Agrawal et al. (2018). An alternative that is often faster but still achieves good performance, is approximating the posterior via a highprobability candidate set of T DAGsĜ T (Heckerman et al., 1997;Friedman et al., 1999). While there are many ways to build up this set, a popular approach is through the nonparametric DAG bootstrap (Friedman et al., 1999). The main idea is to subsample the data (with replacement) T times and fit a DAG learning algorithm to each of the generated datasets to construct G T . Each G ∈Ĝ T can then be weighted according to the ratio of unnormalized posterior probabilities,
w G,D := P(G)P(D | G) G∈Ĝ T P(G)P(D | G)(6)
to form an approximate posteriorP(G) := w G,D 1(G ∈ G T ). The DAG learning algorithm used for this purpose must be able to handle a mix of observational and interventional data. Two recent methods that have been developed for this purpose are given in Hauser and Bühlmann (2012) </p>
<p>Instead of carrying out the expensive expectation over θ | G, D in Eq. (7), we use the MLE of θ for each sampled G. This approximation is justified by the Bernstein-von Mises Theorem, which implies that
P(θ | G, D) → N (θ G MLE , 1 n I(θ G ) −1 ), θ G MLE := arg max θ P(D | G, θ).(8)
Here, n is the number of datapoints in D, and I(θ G ) is the Fisher information matrix of the parameter θ G , which is the asymptotic limit of the maximum likelihood estimatorθ G MLE (Van der Vaart, 2000, Chapter 10). Therefore, the posterior distribution θ | D, G concentrates aroundθ G MLE at the standard O(1/ √ n) statistical rate. Hence, for moderate n (e.g., when a moderate amount of observational data is provided at the start of the experimental design), Eq. (8) implies
E G|D E θ|G,D E y|G,θ,ξ U f M.I. (y, ξ; D) ≈ E G|D E y|G,θ G MLE ,ξ U f M.I. (y, ξ; D) .(9)
In Hauser and Bühlmann (2015, Section 6.1), the authors provide a closed-form expression forθ G MLE when y | G, θ is multivariate Gaussian. In this case,θ G MLE is a simple function of the sample covariance matrix.</p>
<p>Approximating Mutual Information</p>
<p>While in the previous subsection we showed how to approximate the expectations in Eq. (9), computing U f M.I. (y, ξ) even for a fixed y is intractable since we must sum over all possible DAGs. Recall from Eq. (3) that the mutual information utility function is
U f M.I. (y, ξ; D) = H(f | D) − H(f | D, y = y, ξ).(10)
Note that H(f | D) is a constant and does not matter in the optimization over ξ. More care is required for computing the second term in Eq. (10), since the posterior of G changes as a result of observing y, the realizations of the interventions specified by ξ. We therefore cannot immediately use the samples inĜ T to approximate this term. To overcome this problem, we propose to use weighted importance sampling and approximate H(f | D, y, ξ) by a weighted average of DAGs inĜ T . We define the importance sample weights for DAG G i , 1 ≤ i ≤ T , by
w i := P(D, y | G i , ξ) P(D | G i ) .(11)
In general, w i is not equal to P(y | G, ξ) since D and y are dependent without conditioning on θ. While P(D, y | G, ξ) can be computed in closed-form if the prior on θ | G belongs to one of the families described in Geiger and Heckerman (1999), the dependence on previous samples in the importance weights makes greedily building up the intervention set ξ expensive.</p>
<p>In particular, since Eq. (11) does not factorize, the importance weights must be recomputed with every new additional intervention, which again requires an integration over all parameters. Motivated by the approximation in Section 4, where the parameters of each sampled G ∈Ĝ T are not marginalized out, we instead propose using the importance sample weightŝ
w i := P(D, y | G i ,θ Gi MLE , ξ) P(D | G i ,θ Gi MLE ) = P(y | G i , ξ,θ Gi MLE );(12)
w i has the natural interpretation of re-weighting each DAG by the likelihood of the newly observed data y.</p>
<p>Recall from Eq. (3), that U f M.I. (y, ξ; D) is based on weighting each DAG according to its posterior probability P(G | D) ∝ θ P(D | G, θ)P(θ | G)P(G). Using the importance sample weightsŵ i translates into approximating the mutual information against a different posterior distribution in Eq. (3), namelỹ
P(G | D) ∝ P(D | G,θ G MLE )P(G),(13)
which is a specific instance of an empirical Bayes approximation. In what follows, we denote the mutual information score based on the posterior in Eq. (13) byŨ f M.I. (y, ξ; D).</p>
<p>Greedy Optimization</p>
<p>The cardinality constraint |ξ| = N b makes our optimization problem a difficult integer program. In the following, we show how to overcome this final computational hurdle using a generalized notion of submodularity for multisets (Soma and Yoshida, 2016). In particular, we prove that greedily selecting interventions provides a (1 − 1 e ) guarantee on optimization quality.</p>
<p>Algorithm 2 GreedyDesign</p>
<p>Input: Utility function U , number of samples N b , intervention family I * Output: Multiset of interventions ξ 1: ξ ← ∅ 2: for s = 1 : N b do 3: 
I * ∈ arg max I∈I * U (ξ ∪ I) 4: ξ ← ξ ∪ I * return ξv * b = max ξ∈Z I * ∩C N,b E G|D b−1 E y|G,θ G MLE ,ξŨ f M.I. (y, ξ; D) andṽ b = GreedyDesign(Ũ f M.I. , N b , I * ), the output of Algorithm 2 in batch b, satisfiesṽ b ≥ (1 − 1 e )v * b , where C N,b is defined as in Eq. (4).
Remark. We conjecture that Theorem 4.1 holds for arbitrary functions f , but we currently only have a proof (see Appendix) for the case when f (G) = G.</p>
<p>We conclude this section by summarizing the developed Active Budgeted Causal Design Strategy (ABCD-Strategy) in Algorithm 3 and then summarizing all the proposed approximations.</p>
<p>Algorithm 3 ABCD-Strategy</p>
<p>Input: Target 
U f M.I. (y tm , ξ; D) := H 1 (f | D) − H 2 (f | D), P 1 (G | D) := w G,D 1(G ∈Ĝ T ), P 2 (G | D, y, ξ) := w G,D P(y | G, ξ,θ G MLE ) T t=1 w Gt,D P(y | G t , ξ,θ Gt MLE ) ,(14)
where M is the number of synthetic datasets generated, H 1 and H 2 are the entropies induced byP 1 and P 2 respectively, and w G,D is defined in Eq. (6). Note thatÛ f M.I. is based on the importance sample weights given in Eq. (12). We begin by considering a simple case to demonstrate the behavior of our ABCD-strategy under easily interpretable conditions. Consider the chain graph on 2m − 1 nodes,
1 → 2 → . . . → m → . . . → p = 2m − 1.(15)
The corresponding essential graph is completely undirected, and the MEC has 2m − 1 members, one with each node as the source. Assume that sufficient observational data is available to identify the MEC, and we are interested in fully identifying the DAG. Then, our ABCD-strategy selects interventions in order to minimize the expected entropy of the posterior over this MEC. Given a limit of one intervention per batch but infinite samples per batch, Proposition 3.2 implies the expected entropy after intervening at node i or 2m − i,
1 ≤ i ≤ m, is 1 2m − 1 j<i log(i − 2) + j>i log(m − (i + 2)) ,
which is minimized by choosing the midpoint i = m. Analogously, we see that the updated {∅, {m}}-MEC is of the same form, so in the second batch, the optimal intervention will be halfway through the remaining nodes. This process of bisection is illustrated in Figure 1 and matches the behavior of our algorithm even in the finite-sample regime as described next. Figure 2 illustrates the performance of our ABCDstrategy on fifty 11-node chain graphs with random edge weights sampled from [−1, −.25] ∪ [.25, 1]. For comparison, we consider a random intervention strategy that uniformly distributes the samples in each batch to k interventions picked uniformly at random, where k is the maximum number of unique interventions allowed per batch. Whereas the medianperforming random strategy barely reduces the entropy, the ABCD-strategy reduces the entropy significantly in all runs. When all k interventions are  picked for the same batch, so that ABCD receives no feedback, the median-performing run of active learning still reduces the entropy as much as the bestperforming runs of the random strategy.</p>
<p>Having demonstrated the behavior of ABCD for a simple case, we now analyze the performance of our method on more general DAGs. The skeleton of each graph is sampled from an Erdös-Rényi model with density ρ = 0.25. The edges of these graphs are directed by sampling a permutation of the nodes uniformly at random and orienting the edges accordingly. To avoid long runtimes when enumerating the MEC, we disposed of graphs with more than 100 members in their MEC. 1 When the MEC is known, we may define a variant of the random strategy, Chordal-Random, which only intervenes on nodes that are in chordal components of the essential graph, i.e., nodes adjacent to at least one undirected edge. Since the Meek rules can only propagate by intervening within chordal components, Chordal-Random is a more fair baseline strategy for comparison than simple random sampling. Figure 3a demonstrates the improvement in selecting interventions using the ABCD-strategy as compared to Chordal-Random when the number of unique interventions per batch is bounded by one. The entropy reduction for an interventional data set D ξ is defined as
H(G)−H(G|D ξ ) H(G)
, and it is used as a metric so that MECs of different sizes are comparable. Since the number of total possible unique interventions is kB, an increase in the number of batches also increases the variability of the interventions, reflected in the increase of en-  tropy reduction with batch size. Already with only 192 samples and 3 total batches, our ABCD-strategy is able to learn most graphs with complete certainty. The comparable performance of the Budgeted Experiment Design (BED) strategy (Ghassami et al., 2018) suggests that for the given experimental setup, the interventions that orient the most edges correspond well to those that most reduce entropy as we discussed in Proposition 3.2. Figure 3b shows that the performance of the ABCD-strategy remains strong even when the MEC of the graph is not known. Specifically, up to 3 additional MECs were generated by randomly flipping non-covered edges that did not create cycles, and again only graphs for which the union of these MECs had cardinality less than 100 were kept. Note that we are not able to compare with BED since BED requires that the MEC is known.</p>
<p>DREAM4 Synthetic Dataset. Finally, we applied our experimental design strategy to gene expression data from the DREAM4 10-node in-silico network reconstruction challenge (Schaffter et al., 2011). These data are generated from stochastic differential equations and simulate microarray data of gene regulatory networks. We constructed an observational dataset from the wild-type, multifactorial perturbation, and time 0 time-series samples (16 samples in total), and similarly, interventional datasets from the knockdown and knockout samples (2 samples each).</p>
<p>Previous work on experimental design applied to bi- ological datasets (Cho et al., 2016) has focused on learning the entire network. In practice, practitioners may be specifically interested in performing experiments to elucidate a functional of the network, such as the pathway or local network surrounding a gene of interest. To emulate this setting, we applied our ABCDstrategy towards learning the downstream genes of select genes from the true network (Figure 4, top). Despite high variations in learning due to the small size of the dataset, we observed an improvement over the random strategy for several central genes (Fig. 4, bottom; Fig. 6). These results illustrate the promise of applying targeted experimental design for applications to genomics.</p>
<p>Concluding Remarks</p>
<p>We proposed Active Budgeted Causal Design Strategy (ABCD-Strategy), an experimental method based on optimal Bayesian experimental design with provable guarantees on approximation quality. Empirically, we demonstrated that ABCD yields considerable boosts over random sampling for both targeted and full causal structure discovery. Such experimental design strategies are particularly relevant for applications to genomics, where the number of possible experiments is huge due to the possibility of intervening on combinations of genes. </p>
<p>A Proofs</p>
<p>A.1 Proof of Proposition 3.2</p>
<p>Given infinite samples per intervention I ∈ I, G * is recovered up to its I-Markov equivalence class. Hence, the resulting entropy after placing an infinite number of samples at each intervention is equal to log 2 |Ess I (G)| when the true DAG is G. Since the true DAG is unknown, this entropy must be averaged over our prior distribution on G, which is uniform. Hence, the entropy after observing an infinite number of samples per intervention in I equals 1 |G| G∈G log 2 |Ess I (G)|. Minimizing this entropy over all possible interventions sets of size at most K completes the proof.</p>
<p>A.2 Proof of Theorem 3.4</p>
<p>Let
I ∞ := {I ∈ I * : ∞ b=1 |Ĩ ∈ ξ b :Ĩ = I| = ∞ µ * a.s.},
where ξ b denotes the interventions selected at batch b by U f M.I . Since I * is finite, I ∞ is non-empty. When |I ∞ | &gt; 1, I ∞ is a conservative family of targets since I * is a family of single-node interventions. Hence, we identify the I ∞ -MEC of G * in the limit of an infinite number of batches and samples (Hauser and Bühlmann, 2012). Assume |I ∞ | &gt; 1. If f (G) is identifiable in Ess I ∞ (G * ), then
P (f (G) | D B ) µ * a.s. − −−− → 1(f (G) = f (G * )).
Hence, it suffices to show that the interventions U f</p>
<p>M.I</p>
<p>selects infinitely often identifies f (G) in the limiting interventional essential graph Ess I ∞ (G * ). Suppose towards a contradiction that f (G) were not fully identifiable in Ess I ∞ (G * ). By definition of almost sure convergence, there exists some b * &lt; ∞ such that anỹ I ∈ I * \ I ∞ is never selected again after batch b * with probability one since I * is finite. Maximizing U f M.I. is equivalent to minimizing the conditional entropy,
H b ξ (f | Y ξ ) := E y∼P(y|D b ,ξ) H(f | D b , Y = y). (16) If b &gt; b * , then arg min ξ∈Z I * ∩C b H b ξ (f | Y ξ ) = arg min ξ∈Z I ∞ ∩C b H b ξ (f | Y ξ ) (17)
since any batch b after b * never selects an intervention inĨ ∈ I * \ I ∞ . Since f is not identifiable in Since I * consists of all single-node interventions, I * can identify f (G) (Hauser and Bühlmann, 2012). Hence, there must be someĨ ∈ I * \ I ∞ and &gt; 0 such that lim
Ess I ∞ (G * ), that implies lim b→∞ H b ξ∞ (f | Y ξ∞ ) → L &gt; 0.b→∞ H b ξ∞∪Ĩ∞ (f ) &lt; L − ,(18)
whereĨ ∞ denotes selectingĨ infinitely many times. But Eq. (18) implies that there must exist some batch b &gt; b * such that the conditional entropy of the designξ = {Ĩ} is uniformly smaller than the conditional entropy of any ξ ∈ Z I ∞ . But this is a contradiction because thenĨ would be selected again after some batch b &gt; b * and Eq. (17) would no longer hold.</p>
<p>For |I ∞ | = 1, we no longer have a conservative family of targets. However, a nearly identical argument works by noting that, in the limit, we learn the observational equivalence class of the I ∞ mutilated graph of G * .</p>
<p>A.3 Consistency Counterexample</p>
<p>Suppose we know the Markov equivalence class of G * and the goal is to fully recover G * . Suppose C b = {ξ : ξ 0 = K}, where · 0 counts the number of unique interventions in ξ. Since there is no constraint on the number of samples, only on the number of unique interventions, we may allocate an infinite number of samples per intervention within each batch. This constraint is equivalent to the one examined in Ghassami et al. (2018). The scores in both Ness et al. (2018) and Ghassami et al. (2018) </p>
<p>where A(Ess I (G)) equals the additional number of edges oriented relative to the observational Markov equivalence class. Suppose G * equals the graph in Fig. 5 and that K = 1 unique interventions are allowed within each batch. Assume that I * = {{1}, · · · , {4}} and that we start with a uniform prior over G.</p>
<p>Then, since all arrows are undirected in the observational Markov equivalence class, symmetry implies U ({j}; ∅) = U ({j}; ∅) for all i, j ∈ 1, · · · , 4. Without any loss of generality suppose intervention one is selected in batch one. We show that every subsequent batch will select intervention {1}. If only {1} were selected, U (I; D) would not be consistent since the {∅, {1}}-MEC(G * ) contains two graphs, as shown at the bottom of Fig. 5. After batch one, the posterior is supported on these two graphs since an infinite number of samples are allocated to the intervention at node one.</p>
<p>The utility function in Eq. (19) scores interventions relative to the observational equivalence class, which causes the consistency issue. In particular, the posterior in batch two is only supported on the two DAGs given in the bottom box of Fig. 5. The score of {1} equals 5 in batch two while the scores of interventions {2}, {3}, {4} equal 4, 3, 4, respectively. Hence, in batch two, intervention {1} will be selected again, but the posterior will remain the same since the {∅, {1}} interventional Markov equivalence class of G * is already known.</p>
<p>An easy way to fix Eq. (19) (for this given counterexample) would be to only select interventions not selected in previous batches. This modification would fix the issue with the counterexample, namely prevent intervention one from being selecting infinitely often. However, when one can only allocate a finite number of samples per batch, this modification would not lead to a consistent estimator. In particular, if a certain intervention is done in some batch, and that intervention must be conducted in order to identify f , then only placing finitely many samples to that intervention in that batch and never placing any more samples in subsequent batches will not lead to a consistent method.</p>
<p>A 
f (x + χ e ) − f (x) ≥ f (y + χ e ) − f (y), x, y ∈ Z E (20)
where e ∈ E and χ e is the ith unit vector.</p>
<p>Lemma A.2.Ũ f M.I. (ξ; D) is DR-submodular.</p>
<p>Proof. f (G) = G so we omit f inŨ f M.I. to simplify notation. Since the sum of submodular functions is submodular, it suffices to show </p>
<p>is DR-submodular, where I is the mutual information.</p>
<p>Consider an A ⊆ B ∈ Z I * . Take any C ∈ I * . Since entropy decreases with more conditioning,
H(Y C | Y A ) − H(Y C | (G,θ G MLE )) ≥ H(Y C | Y B ) − H(Y C | (G,θ G MLE )).(22)
By conditional independence,
H(Y C | (G,θ G MLE )) = H(Y C | (G,θ G MLE ), Y A ) = H(Y C | (G,θ G MLE ), Y B ).(23)
Hence, Eq. (22) may be rewritten as,
I((G,θ G MLE ), Y C | Y A ) = H(Y C | Y A ) − H(Y C | (G,θ G MLE ), Y A ) ≥ H(Y C | Y B ) − H(Y C | (G,θ G MLE ), Y B ) = I((G,θ G MLE ), Y C | Y B ).(24)
Eq. (24) implies
I((G,θ G MLE ), Y A + Y C ) − I((G,θ G MLE ), Y A ) ≥ I((G,θ G MLE ), Y B + Y C ) − I((G,θ G MLE ), Y B )(25)
as desired.</p>
<p>The proof of Theorem 4.1 then follows directly from Lemma A.2 and Soma et al. (2014, Theorem 2.4).</p>
<p>A.5 Proof of Proposition 4.2</p>
<p>For each graph G ∈ G T , compute the associated edge weightsθ G MLE . Computing eachθ G MLE takes O(pκ 3 ) time using the formula given in Hauser and Bühlmann (2012, pg. 17). Since there are T DAGs, the total time to compute the MLE estimates of the edge weights of each DAG is O(T pκ 3 ). Sampling from a multivariate Gaussian with bounded indegree with known adjacency matrix takes O(pκ) time.Û f M.I. requires a total of |I * |M N b T 2 samples. Hence, the total computation time of sampling all the y mt in Eq. (14) is O(|I * |M N b κpT 2 ). EvaluatingÛ f M.I. takes O(M T 2 ) time using these samples, which is of lower computational complexity than computingÛ f M.I. . Hence, the total runtime is O(pκ 3 + |I * |M N b κpT 2 ).</p>
<p>A.6 Constraint on the Number of Unique Interventions</p>
<p>If we are only allowed to allocate at most K unique interventions per batch, we modify Algorithm 3 by allocating N b K samples per intervention in Algorithm 2. Once an intervention is selected, that intervention is removed from I * and another one is greedily selected from the remaining set. With this strategy, Algorithm 2 will terminate after K iterations. Hence, there will be at most K unique interventions as desired.</p>
<p>A.7 DREAM4 Supplementary Figures</p>
<p>We applied our targeted experimental design strategy towards learning the downstream pathways of select genes from a 10-node network from the DREAM4 challenge. We observed a modest improvement over the random strategy for some central genes in the network (Fig. 6, top). However, the results are subject to high variations (Fig. 6, bottom), which we surmise to be due to the small size of the observational dataset. Nevertheless, these preliminary results illustrate the promise of applying targeted experimental design to real, large-scale biological datasets.</p>
<p>and Wang et al. (2017). We summarize constructing an approximate posterior via the DAG bootstrap in Algorithm 1. Algorithm 1 DAGBootSample Input: N datapoints D N , number of samples T Output: T bootstrap DAG samplesĜ T 1:Ĝ T ← ∅ 2: for s = 1 : T do 3:D N ← N datapoints sampled (with replacement) from D N 4: G s ← DAGLearner(D N ) e.g. (Wang et al., 2017; Hauser and Bühlmann, 2012) 5:Ĝ T ←Ĝ T ∪ G s returnĜ T GivenĜ T , which can be constructed from Algorithm 1 or sampled from a Markov chain, we next discuss how to compute the expectation over θ. Recall that U f M.I. (ξ; D) is given by E G|D E y|G,ξ U f M.I. (y, ξ; D) = E G|D E θ|G,D E y|G,θ,ξ U f M.I. (y, ξ; D) .</p>
<p>Theorem 4 . 1 .
41Suppose f (G) = G i.e. the goal is to recover the full graph as in Tong and Koller (2001); Cho et al. (2016); Murphy (2001); Ness et al. (2018). Then the difference between the global optimum</p>
<p>functional f , interventional data collected D b−1 , observational data D obs , number of batch samples N b , intervention family I * , number of DAGs T , number of datasets M Output: Multiset of interventions ξ 1: ξ ← ∅ 2: G T ←DAGBootSample([D obs , D b−1 ], T ) 3: ComputeÛ f M.I. via Eq. (14) 4: return GreedyDesign(Û f M.I. , N b , I * ) In terms of approximations, Eq. (9) implies E G,θ|D E y|G,θ,ξŨ f M.I. (y, ξ; D) ≈ E G,|D E y|G,θ G MLE ,ξŨ M.I. (y, I. (y tm , ξ; D), where</p>
<p>Proposition 4 . 2 .
42The total runtime of Algorithm 2 with input utility functionÛ f M.I. is O(pT κ 3 + |I * |M T 2 N b κp), where κ is the maximum indegree of a graph inĜ T . See Appendix A.5 for the proof of Proposition 4.2.</p>
<p>Figure 1 :
1Illustration of active learning on a chain graph, beginning with a known MEC on a simulated dataset with p = 15 nodes. The brown circles indicate the interventions selected in each batch.</p>
<p>Figure 2 :
2Box plots for 50 runs of the random strategy versus our ABCD-strategy on the graph inFigure 5with p = 11 and n = 30 samples. The horizontal line indicates the entropy of the prior distribution, i.e. uniform over the MEC. Note that k = ∞ corresponds to the case with no constraints on the number of unique interventions.</p>
<p>Figure 3 :
3Performance of intervention strategies for batch sizes b as a function of the total number of samples, computed from 50 Erdös-Rényi DAGs with density ρ = 0.25.</p>
<p>Figure 4 :
4Top: DREAM4 ground truth 10-node network. Bottom: Performance of intervention strategies on predicting the descendants of gene 0.</p>
<p>Figure 5 :
5Each box represents the members of the interventional Markov equivalence classes. For G * given in the bottom left box, the observational Markov equivalence class has no edges oriented. The top box represents the essential graph of the observational Markov equivalence class. The interventional Markov equivalence class for an intervention at node one consists of two DAGs given in the bottom box.</p>
<p>select interventions by maximizing the expected number of oriented edges in the interventional Markov equivalence classes. In particular, the utility function in Ness et al.</p>
<p>E
y|G,θ G MLE ,ξŨ M.I. (y, ξ; D) = H(G) − H(G | Y ξ ) = I((G,θ G MLE ), Y ξ )</p>
<p>T .
TSchaffter, D. Marbach, and D. Floreano.GeneNetWeaver: in silico benchmark generation 
and performance profiling of network inference 
methods. Bioinformatics, 27:2263-2270, 2011. </p>
<p>T. Soma and Y. Yoshida. Maximizing monotone 
submodular functions over the integer lattice. In 
International Conference on Integer Programming 
and Combinatorial Optimization, pages 325-336. 
Springer, 2016. </p>
<p>T. Soma, 
N. Kakimura, 
K. Inaba, 
and 
K. Kawarabayashi. 
Optimal budget alloca-
tion: Theoretical guarantee and efficient algorithm. 
In International Conference on International 
Conference on Machine Learning, 2014. </p>
<p>P. Spirtes, C. Glymour, and R. Scheines. Causation, 
Prediction, and Search. MIT press, 2nd edition, 
2000. </p>
<p>S. Tong and D. Koller. Active learning for structure 
in Bayesian networks. In International Joint Con-
ference on Artificial Intelligence, 2001. </p>
<p>A. W. Van der Vaart. Asymptotic statistics, volume 3. 
Cambridge university press, 2000. </p>
<p>T. S. Verma and J. Pearl. Equivalence and synthesis 
of causal models. In Uncertainty in Artificial Intel-
ligence, volume 6, page 255, 1991. </p>
<p>T. S. Verma and J. Pearl. An algorithm for deciding 
if a set of observed independencies has a causal ex-
planation. In Uncertainty in Artificial Intelligence, 
1992. </p>
<p>Y. Wang, L. Solus, K. Yang, and C. Uhler. 
Permutation-based causal inference algorithms with 
interventions. In Advances in Neural Information 
Processing Systems, pages 5824-5833, 2017. </p>
<p>K. D. Yang, A. Katcoff, and C. Uhler. Characteriz-
ing and learning equivalence classes of causal DAGs 
under interventions. In International Conference on 
Machine Learning, 2018. </p>
<p>.4 Proof of Theorem 4.1 Definition A.1. (Soma and Yoshida, 2016) Let E be a finite set. A function f : Z E → R is diminishing returns submodular (DR-submodular) if for x ≤ y
From a sample of 10,000 graphs, only 54 had MEC size greater than 100. Based on the results byGillispie and Perlman (2001), we expect the MECs to be typically small.
Acknowledgements R. Agrawal was partially supported by IBM. K.D. Yang was supported by an NSF graduate fellowship Agrawal, Squires, Yang, Shanmugam, Uhler    and ONR (N00014-18-1-2765). C. Uhler was partially supported by NSF (DMS-1651995), ONR (N00014-17-1-2147 and N00014-18-1-2765), IBM, and a Sloan Fellowship.
Minimal I-MAP MCMC for scalable structure discovery in causal DAG models. R Agrawal, T Broderick, C Uhler, International Conference on Machine Learning. R. Agrawal, T. Broderick, and C. Uhler. Minimal I-MAP MCMC for scalable structure discovery in causal DAG models. In International Conference on Machine Learning, 2018.</p>
<p>A characterization of Markov equivalence classes for acyclic digraphs. S A Andersson, D Madigan, M D Perlman, Annals of Statistics. 252S. A. Andersson, D. Madigan, and M. D. Perlman. A characterization of Markov equivalence classes for acyclic digraphs. Annals of Statistics, 25(2):505- 541, 1997.</p>
<p>Bayesian experimental design: A review. K Chaloner, I Verdinelli, Statistical Science. 10K. Chaloner and I. Verdinelli. Bayesian experimental design: A review. Statistical Science, 10:273-304, 1995.</p>
<p>Reconstructing causal biological networks through active learning. H Cho, B Berger, J Peng, PLoS ONE. H. Cho, B. Berger, and J. Peng. Reconstructing causal biological networks through active learning. PLoS ONE, 2016.</p>
<p>Perturbseq: dissecting molecular circuits with scalable single-cell RNA profiling of pooled genetic screens. A Dixit, O Parnas, B Li, J Chen, C Fulco, L Jerby-Arnon, N Marjanovic, D Dionne, T Burks, R Raychowdhury, B Adamson, T Norman, E Lander, J Weissman, N Friedman, A Regev, Cell. A. Dixit, O. Parnas, B. Li, J. Chen, C. Fulco, L. Jerby- Arnon, N. Marjanovic, D. Dionne, T. Burks, R. Ray- chowdhury, B. Adamson, T. Norman, E. Lander, J. Weissman, N. Friedman, and A. Regev. Perturb- seq: dissecting molecular circuits with scalable single-cell RNA profiling of pooled genetic screens. Cell, pages 1853-1866, 2016.</p>
<p>Learning causal Bayesian network structures from experimental data. B Ellis, W H Wong, Journal of the American Statistical Association. 103B. Ellis and W. H. Wong. Learning causal Bayesian network structures from experimental data. Journal of the American Statistical Association, 103:778- 789, 2008.</p>
<p>Being Bayesian about network structure. A Bayesian approach to structure discovery in Bayesian networks. N Friedman, D Koller, Machine Learning. 50N. Friedman and D. Koller. Being Bayesian about network structure. A Bayesian approach to structure discovery in Bayesian networks. Machine Learning, 50:95-125, 2003.</p>
<p>Data analysis with Bayesian networks: A bootstrap approach. N Friedman, M Goldszmidt, A J Wyner, Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence. the Fifteenth Conference on Uncertainty in Artificial IntelligenceN. Friedman, M. Goldszmidt, and A. J. Wyner. Data analysis with Bayesian networks: A bootstrap ap- proach. In Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence, 1999.</p>
<p>Using Bayesian networks to analyze expression data. N Friedman, M Linial, I Nachman, D Pe&apos;er, Journal of Computational Biology. 73-4N. Friedman, M. Linial, I. Nachman, and D. Pe'er. Using Bayesian networks to analyze expression data. Journal of Computational Biology, 7(3-4):601-620, 2000.</p>
<p>Parameter priors for directed acyclic graphical models and the characterization of several probability distributions. D Geiger, D Heckerman, Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence. the Fifteenth Conference on Uncertainty in Artificial IntelligenceD. Geiger and D. Heckerman. Parameter priors for di- rected acyclic graphical models and the characteri- zation of several probability distributions. In Pro- ceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence, 1999.</p>
<p>Budgeted experiment design for causal structure learning. A Ghassami, S Salehkaleybar, N Kiyavash, E Bareinboim, International Conference on Machine Learning. A. Ghassami, S. Salehkaleybar, N. Kiyavash, and E. Bareinboim. Budgeted experiment design for causal structure learning. In International Confer- ence on Machine Learning, 2018.</p>
<p>Enumerating Markov equivalence classes of acyclic digraph models. S B Gillispie, M D Perlman, Proceedings of the 17th Conference in Uncertainty in Artificial Intelligence. the 17th Conference in Uncertainty in Artificial IntelligenceS. B. Gillispie and M. D. Perlman. Enumerating Markov equivalence classes of acyclic digraph mod- els. In Proceedings of the 17th Conference in Uncer- tainty in Artificial Intelligence, 2001.</p>
<p>Improving the structure MCMC sampler for Bayesian networks by introducing a new edge reversal move. M Grzegorczyk, D Husmeier, Machine Learning. 71M. Grzegorczyk and D. Husmeier. Improving the structure MCMC sampler for Bayesian networks by introducing a new edge reversal move. Machine Learning, 71:265-305, 2008.</p>
<p>Characterization and greedy learning of interventional Markov equivalence classes of directed acyclic graphs. A Hauser, P Bühlmann, Journal of Machine Learning Research. 131A. Hauser and P. Bühlmann. Characterization and greedy learning of interventional Markov equiva- lence classes of directed acyclic graphs. Journal of Machine Learning Research, 13(1):2409-2464, 2012.</p>
<p>Two optimal strategies for active learning of causal models from interventional data. A Hauser, P Bühlmann, International Journal of Approximate Reasoning. 55A. Hauser and P. Bühlmann. Two optimal strategies for active learning of causal models from interven- tional data. International Journal of Approximate Reasoning, 55:926-939, 2014.</p>
<p>Jointly interventional and observational data: estimation of interventional Markov equivalence classes of directed acyclic graphs. A Hauser, P Bühlmann, Journal of the Royal Statistical Society Series B. 771A. Hauser and P. Bühlmann. Jointly interventional and observational data: estimation of interven- tional Markov equivalence classes of directed acyclic graphs. Journal of the Royal Statistical Society Se- ries B, 77(1):291-318, 2015.</p>
<p>A Bayesian approach to causal discovery. D Heckerman, C Meek, G Cooper, Microsoft ResearchTechnical reportD. Heckerman, C. Meek, and G. Cooper. A Bayesian approach to causal discovery. Technical report, Mi- crosoft Research, 1997.</p>
<p>Partition MCMC for inference on acyclic digraphs. J Kuipers, G Moffa, Journal of the American Statistical Association. 112J. Kuipers and G. Moffa. Partition MCMC for infer- ence on acyclic digraphs. Journal of the American Statistical Association, 112:282-299, 2017.</p>
<p>Addendum on the scoring of Gaussian directed acyclic graphical models. J Kuipers, G Moffa, D Heckerman, The Annals of Statistics. 42J. Kuipers, G. Moffa, and D. Heckerman. Addendum on the scoring of Gaussian directed acyclic graphi- cal models. The Annals of Statistics, 42:1689-1691, 2014.</p>
<p>S Lauritzen, Graphical Models. Oxford University PressS. Lauritzen. Graphical Models. Oxford University Press, 1996.</p>
<p>Bayesian graphical models for discrete data. D Madigan, J York, International Statistical Review. 63D. Madigan and J. York. Bayesian graphical models for discrete data. International Statistical Review, 63:215-232, 1995.</p>
<p>Active learning of causal Bayes net structure. K Murphy, Technical reportK. Murphy. Active learning of causal Bayes net struc- ture. Technical report, 2001.</p>
<p>A Bayesian active learning experimental design for inferring signaling networks. R O Ness, K Sachs, P Mallick, O Vitek, Journal of Computational Biology. 257R. O. Ness, K. Sachs, P. Mallick, and O. Vitek. A Bayesian active learning experimental design for in- ferring signaling networks. Journal of Computa- tional Biology, 25(7):709-725, 2018.</p>
<p>Structure discovery in Bayesian networks by sampling partial orders. T Niinimaki, P Parviainen, M Koivisto, Journal of Machine Learning Research. 17T. Niinimaki, P. Parviainen, and M. Koivisto. Struc- ture discovery in Bayesian networks by sampling partial orders. Journal of Machine Learning Re- search, 17:2002-2048, 2016.</p>
<p>Causality: Models, reasoning, and inference. J Pearl, Econometric Theory. 1946J. Pearl. Causality: Models, reasoning, and inference. Econometric Theory, 19(675-685):46, 2003.</p>
<p>Marginal structural models and causal inference in epidemiology. M Robins, M A Hernan, B Brumback, M. Robins, M. A. Hernan, and B. Brumback. Marginal structural models and causal inference in epidemiology, 2000.</p>            </div>
        </div>

    </div>
</body>
</html>