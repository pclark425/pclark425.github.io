<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2573 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2573</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2573</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-65.html">extraction-schema-65</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-ed56e11c9c454bed81ec1396196998b9ca9f5a6c</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/ed56e11c9c454bed81ec1396196998b9ca9f5a6c" target="_blank">AgentFL: Scaling LLM-based Fault Localization to Project-Level Context</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This paper presents AgentFL, a multi-agent system based on ChatGPT for automated fault localization, which outperforms the other LLM-based approaches and exhibits complementarity to the state-of-the-art learning-based techniques.</p>
                <p><strong>Paper Abstract:</strong> Fault Localization (FL) is an essential step during the debugging process. With the strong capabilities of code comprehension, the recent Large Language Models (LLMs) have demonstrated promising performance in diagnosing bugs in the code. Nevertheless, due to LLMs' limited performance in handling long contexts, existing LLM-based fault localization remains on localizing bugs within a small code scope (i.e., a method or a class), which struggles to diagnose bugs for a large code scope (i.e., an entire software system). To address the limitation, this paper presents AgentFL, a multi-agent system based on ChatGPT for automated fault localization. By simulating the behavior of a human developer, AgentFL models the FL task as a three-step process, which involves comprehension, navigation, and confirmation. Within each step, AgentFL hires agents with diversified expertise, each of which utilizes different tools to handle specific tasks. Particularly, we adopt a series of auxiliary strategies such as Test Behavior Tracking, Document-Guided Search, and Multi-Round Dialogue to overcome the challenges in each step. The evaluation on the widely used Defects4J-V1.2.0 benchmark shows that AgentFL can localize 157 out of 395 bugs within Top-1, which outperforms the other LLM-based approaches and exhibits complementarity to the state-of-the-art learning-based techniques. Additionally, we confirm the indispensability of the components in AgentFL with the ablation study and demonstrate the usability of AgentFL through a user study. Finally, the cost analysis shows that AgentFL spends an average of only 0.074 dollars and 97 seconds for a single bug.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2573.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2573.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AGENTFL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AGENTFL: Scaling LLM-based Fault Localization to Project-Level Context</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent LLM-based system (implemented on ChatGPT) that decomposes project-level fault localization into a three-step SOP (Fault Comprehension, Codebase Navigation, Fault Confirmation) and leverages specialized agents plus program-analysis tools to locate buggy methods and produce human-readable rationales.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AGENTFL</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>AGENTFL is a centralized, SOP-driven multi-agent pipeline for project-level fault localization. It orchestrates LLM-driven agents (with ChatGPT as the LLM engine) together with external program-analysis tools. The system decomposes the overall task into three sequential phases (Fault Comprehension → Codebase Navigation → Fault Confirmation). A Prompt Generator, Result Parser, and a shared State Storage act as central orchestration/memory components: tools write structured results (e.g., Extracted Classes) to State Storage, the Prompt Generator uses stored material to build task-specific prompts, agents respond in natural language which the Result Parser converts to structured data for subsequent steps. External components include lightweight dynamic instrumentation (Method Call Traces), static analysis (via tree-sitter), and custom tools for Test/Source Code Analysis. Outputs are ranked/suspected methods and natural-language rationales.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>4</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Four specialized LLM-driven agents: (1) Test Code Reviewer — analyzes test methods and test utility code to summarize test behavior and gather covered classes/methods; (2) Software Test Engineer — examines test failure information, lists possible causes, and validates suspicious methods (used for Test Failure Analysis and Method Review/confirmation); (3) Software Architect — focuses on software architecture and locating problematic areas/classes (used in class/method search tasks); (4) Source Code Reviewer — generates / enhances method/class documentation and analyzes call relationships to produce clearer method summaries (Method Doc Enhancement).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Problem understanding (Fault Comprehension), exploration/navigation of large code bases (Codebase Navigation), execution/validation (running tests and Fault Confirmation), and human-interpretable explanation generation (rationale). In other words: comprehension, implementation-level exploration/execution, and evaluation/validation.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Centralized, sequential pipeline following a predefined SOP. A central Prompt Generator/State Storage/Result Parser coordinates agents: tools/agents write to State Storage and subsequent agents read from it; agents are invoked per SOP step in sequence with well-defined task templates. Multi-step chain-of-thought style coordination (intermediate 'Possible Causes' are produced and consumed by downstream agents).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural-language prompts and responses to/from LLM-driven agents augmented by structured artifacts: markdown tables for class lists, fixed prompt templates per task, and structured data in State Storage (tool outputs like Extracted Classes). Agents call external tools (Program Analysis) which return structured outputs (e.g., JSON-like Extracted Classes) that are included in prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Iterative refinement and multi-round dialogue: (1) agents produce intermediate artifacts (e.g., 'Possible Causes', enhanced method docs) stored centrally and consumed downstream; (2) Method Review uses Multi-Round Dialogue where the Software Test Engineer inspects one candidate method per round and returns TRUE/FALSE with reason; (3) retrospective Get-Top-1 task aggregates per-class/method reviews. These loops provide feedback that refines search and confirmation.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Phase-driven / on-demand: agents exchange information at phase transitions (after each SOP step) and during iterative confirmation (on-demand per suspicious method via multi-round dialogues).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Software engineering — automated fault localization / debugging at project (method) level.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Top-N localization counts on Defects4J-V1.2.0 and V2.0.0: On Defects4J-V1.2.0 (395 bugs) AGENTFL: Top-1 = 157, Top-3 = 183, Top-5 = 187. On Defects4J-V2.0.0 (226 bugs) AGENTFL: Top-1 = 78, Top-3 = 98, Top-5 = 103. Runtime & cost: average runtime ≈ 97 seconds per bug; average monetary cost ≈ $0.074 per bug (model price used: $0.003 per 1k tokens).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to LLM-based baselines adapted to project-level (ChatGPT_{Ochiai}, LLMAO_{Ochiai}): AGENTFL outperforms both on Top-1 (AGENTFL Top-1=157 vs ChatGPT_{Ochiai}=121, LLMAO_{Ochiai}=129). Compared to statistic-based approaches (Ochiai, FLUCCS, DeepFL_{cov}, GRACE): AGENTFL (157 Top-1) outperforms Ochiai and FLUCCS on many projects but underperforms the top learning/graph approaches (e.g., GRACE Top-1=192 overall); AGENTFL is complementary (has unique correct localizations).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Coordination enables: (1) improved Top-1 localization compared to single-LM prompting baselines (+36 vs ChatGPT_{Ochiai}, +28 vs LLMAO_{Ochiai}); (2) generation of human-readable rationales that improved developer task completion in a user study (participants localized more bugs with AGENTFL suggestions); (3) cost- and time-efficient project-level localization (avg $0.074, 97s). Quantified contributions from coordinated components shown via ablation (see below).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Limitations reported: (1) ranking is weaker than learning-based rankers — AGENTFL is designed as a validation/inspection workflow rather than producing fine-grained suspiciousness scores, hurting Top-3/Top-5; (2) struggles on projects with very large coverage (e.g., Closure) where many classes/methods are covered and LLM focus degrades; (3) LLM context-length and decreased reliability on long contexts (necessitating decomposition); (4) potential hallucination and reliance on quality of available documentation; (5) small number of suspicious methods returned (often <3) can reduce recall in Top-N metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Three ablations reported: (a) remove TestBehaviorAnalysis → Top-1 drops from 157 to 148; (b) remove TestFailureAnalysis → Top-1 drops from 157 to 125 (largest drop); (c) remove MethodDocEnhancement → Top-1 drops from 157 to 133. These quantify the contribution of coordination components and intermediate artifacts ('Possible Causes', enhanced docs, test behavior).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Practical configuration choices reported: use gpt-3.5-turbo-16k as LLM engine; retain only Top-50 covered classes by method-level coverage to reduce search space (preserves buggy class in >98% cases); token limits: test output log ≤ 200 tokens, class/method documentation ≤ 100 tokens; keep ≤ 5 failed test cases per test class; use the three-step SOP and four agent specializations described above. The paper highlights the importance of the Test Failure Analysis and Method Doc Enhancement tasks as key components.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentFL: Scaling LLM-based Fault Localization to Project-Level Context', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2573.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2573.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatDev</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatDev: Communicative agents for software development</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent framework for software development that supports communicative LLM-driven agents, standardized workflows (SOP), and agent roles; used as the implementation foundation for AGENTFL.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Communicative agents for software development</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ChatDev</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A state-of-the-art multi-agent framework enabling multiple communicative agents for software development tasks. The framework provides primitives for agent roles, message passing, and workflow coordination; AGENTFL is implemented on top of ChatDev in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Supports a variety of role-based agents commonly used in software development workflows (e.g., product managers, engineers); exact specializations depend on instantiation.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Software design and development workflows (task decomposition, implementation, and coordination); in AGENTFL it is used to implement debugging/localization pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Predefined streamlined workflows / SOPs (centralized workflow engine in the framework that sequences agents and standardizes intermediate artifacts).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural-language messages among agents mediated by the framework, plus structured artifacts (documents, code) as intermediate outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Supports memory and tool usage for agents; agents can produce structured intermediate artifacts used by other agents (implicit iterative refinement supported).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Configurable by workflow; typically at phase boundaries and on-demand within tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Software engineering / automated software development (framework-oriented).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not reported in this paper (framework used as implementation substrate).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Not compared; used as the underlying multi-agent framework for AGENTFL implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Enables modular agent instantiation and SOP-based orchestration which AGENTFL leverages for task decomposition and agent specialization.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not specifically evaluated in this paper; general concerns include need for well-defined SOPs and the risk of propagation of LLM hallucinations across agents.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>None reported specifically for ChatDev in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>The paper follows ChatDev's approach of structured SOP and task-specific system instructions; no additional optimal configurations for ChatDev are prescribed beyond those used to implement AGENTFL.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentFL: Scaling LLM-based Fault Localization to Project-Level Context', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2573.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2573.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MetaGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MetaGPT: Meta programming for multi-agent collaborative framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced multi-agent system that applies SOP-style workflows and role-based agents (e.g., product managers, engineers) to automate software development tasks; cited as inspiration for SOP and agent design.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>MetaGPT: Meta programming for multi-agent collaborative framework</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MetaGPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Mentioned as an example of multi-agent systems that follow predefined SOP/workflows where agents with specific roles collaborate to produce structured intermediate outputs (documents, code). The paper cites MetaGPT as an example that uses role-based agents in a coordinated workflow for software engineering.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Typical role examples (as described in the paper): product managers, engineers, etc.; designed for software development pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Software development workflow (planning, implementation, documentation); used as inspiration for SOP-based coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Predefined, streamlined workflow (SOP) that sequences role-based agents; the paper references MetaGPT's SOP idea but does not detail its internals.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Not specified in detail here — referenced as using structured intermediate outputs (documents, code) and standardized formats.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>SOP-driven artifact handoff and standardized intermediate outputs ensure robustness; specific feedback loops not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Workflow-driven (at task boundaries as per SOP).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Automated software development / programming automation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not provided in this paper (only referenced).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Not applicable in this paper (referenced).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Provides task decomposition and robust coordination via SOP; cited as motivating AGENTFL's SOP decomposition.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>None reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentFL: Scaling LLM-based Fault Localization to Project-Level Context', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2573.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2573.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AutoGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AutoGPT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source autonomous-agent system that chains LLM calls to pursue user-specified goals; mentioned as a broad example of LLM-driven autonomous agents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autogpt</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AutoGPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited as an example of LLM-driven agents that attempt to autonomously carry out missions by chaining tasks and using tools; referenced in the context of multi-agent/autonomous agent examples.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable / autonomous single-agent orchestration (as typically deployed)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>General autonomous 'mission' agent(s) that plan, call tools, and iterate; paper does not detail role breakdown.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>General autonomous task execution and planning; not specifically scientific research in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Autonomous goal-driven task chaining (not described in detail here).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Primarily natural-language prompts and tool API calls; specifics not described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Iterative planning and execution loops internal to the AutoGPT pattern; not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Continuous/iterative as tasks progress in AutoGPT architecture (paper only cites AutoGPT).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General autonomous tasks / multi-step missions (cited as an example).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Not applicable in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Demonstrates autonomous chaining of LLM calls and tool use; cited as an example of agent autonomy.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not discussed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>None reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentFL: Scaling LLM-based Fault Localization to Project-Level Context', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2573.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2573.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BabyAGI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BabyAGI</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A lightweight project/repo (cited) that demonstrates an agentic loop for task decomposition and iterative execution using LLMs; referenced as another example of agentic systems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Babyagi</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BabyAGI</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Mentioned as an example of simple agent pipelines that perform arbitrary missions by repeatedly generating tasks, executing them, and storing results; referenced in the related-work context of LLM-driven agents.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (often implemented as one agent orchestrating tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Task-generation, task-execution, and memory maintenance roles as typical in BabyAGI patterns; paper does not provide specifics.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>General iterative execution/automation, not specified as scientific research here.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Task queue and iterative loop; not detailed in the present paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural language prompts and simple memory storage; specifics not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Task re-prioritization based on results in the agent loop; not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Iterative per-task loop; paper only references BabyAGI generally.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General automation / autonomous agents.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Not applicable in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Illustrative of simple agentic loops; used as contextual reference.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not discussed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>None reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentFL: Scaling LLM-based Fault Localization to Project-Level Context', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2573.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2573.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Agents (open-source framework)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Agents: An open-source framework for autonomous language agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source framework that provides primitives for constructing autonomous language agents with memory, tool use, and inter-agent coordination; cited in related work as underpinning agent features (memory management, tool usage).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Agents: An open-source framework for autonomous language agents</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Agents framework (Zhou et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced as a general open-source framework that offers building blocks for autonomous language agents (memory, tools, workflows). The paper cites it in the context of capabilities that multi-agent systems can leverage (memory management, tool usage, multi-agent communication).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Framework-agnostic — supports arbitrary role specializations depending on instantiation.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Tool-supported execution/interaction phases for autonomous agents; not specifically tailored to scientific research in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Framework-provided orchestration primitives (not detailed in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Framework-level message passing and persistent memory; specifics not elaborated in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Supports memory-based iterative refinement and tool-invocation feedback; paper only references these general capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Configurable by framework workflows; not specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General autonomous language-agent tasks; mentioned for background.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Not applicable in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Provides core capabilities (memory, tools) that support coordinated multi-agent behavior; cited as motivation.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not discussed here.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>None reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentFL: Scaling LLM-based Fault Localization to Project-Level Context', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2573.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2573.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CAMEL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CAMEL: Communicative agents for 'mind' exploration of large language model society</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced multi-agent research work that focuses on communication protocols among agents (cited as an example of multi-agent communication research).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Camel: Communicative agents for "mind" exploration of large language model society</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CAMEL</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Mentioned as a representative study of communicative multi-agent systems which explores agent-to-agent communication patterns and emergent behaviors in LLM societies; cited in related work on multi-agent communication.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable / research-dependent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Research-focused agent roles to explore communication/coordination behaviors; not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Study of agent communication and emergent behaviors; not directly applied to scientific research tasks in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Inter-agent communicative protocols studied in CAMEL (paper references conceptually).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Agent-to-agent natural-language communication (studied in CAMEL); paper only references CAMEL conceptually.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Peer communication/negotiation in agent society (conceptual reference).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Varies by study; not specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Multi-agent communication research; referenced as related work.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Not applicable here.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Provides background on communicative agent design; cited as related work.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>None reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentFL: Scaling LLM-based Fault Localization to Project-Level Context', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2573.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2573.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gorilla</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gorilla: Large language model connected with massive APIs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced system that connects LLMs to many APIs/tools to extend capabilities; cited in context of tool-augmented agents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Gorilla: Large language model connected with massive apis</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Gorilla</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced as an example of augmenting LLM-driven agents with rich tool/ API access to improve capabilities. The paper cites Gorilla in the context of tool usage mechanisms for agents.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable / framework-level</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Tool-using agent archetypes; specifics not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Tool-augmented execution and information retrieval phases; cited as a tool-usage example.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Not described here — referenced for tool integration.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>LLM-to-API/tool calls; specifics not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Tool outputs fed back into agent prompts; conceptual reference only.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>On-demand tool invocation; not specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General LLM tool-augmentation; referenced in background.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Not applicable in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Illustrates the value of augmenting agents with tool access; used as contextual background.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not discussed here.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>None reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentFL: Scaling LLM-based Fault Localization to Project-Level Context', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>MetaGPT: Meta programming for multi-agent collaborative framework <em>(Rating: 2)</em></li>
                <li>Communicative agents for software development <em>(Rating: 2)</em></li>
                <li>Autogpt <em>(Rating: 2)</em></li>
                <li>Babyagi <em>(Rating: 1)</em></li>
                <li>Agents: An open-source framework for autonomous language agents <em>(Rating: 2)</em></li>
                <li>Camel: Communicative agents for "mind" exploration of large language model society <em>(Rating: 2)</em></li>
                <li>Gorilla: Large language model connected with massive apis <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2573",
    "paper_id": "paper-ed56e11c9c454bed81ec1396196998b9ca9f5a6c",
    "extraction_schema_id": "extraction-schema-65",
    "extracted_data": [
        {
            "name_short": "AGENTFL",
            "name_full": "AGENTFL: Scaling LLM-based Fault Localization to Project-Level Context",
            "brief_description": "A multi-agent LLM-based system (implemented on ChatGPT) that decomposes project-level fault localization into a three-step SOP (Fault Comprehension, Codebase Navigation, Fault Confirmation) and leverages specialized agents plus program-analysis tools to locate buggy methods and produce human-readable rationales.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "AGENTFL",
            "system_description": "AGENTFL is a centralized, SOP-driven multi-agent pipeline for project-level fault localization. It orchestrates LLM-driven agents (with ChatGPT as the LLM engine) together with external program-analysis tools. The system decomposes the overall task into three sequential phases (Fault Comprehension → Codebase Navigation → Fault Confirmation). A Prompt Generator, Result Parser, and a shared State Storage act as central orchestration/memory components: tools write structured results (e.g., Extracted Classes) to State Storage, the Prompt Generator uses stored material to build task-specific prompts, agents respond in natural language which the Result Parser converts to structured data for subsequent steps. External components include lightweight dynamic instrumentation (Method Call Traces), static analysis (via tree-sitter), and custom tools for Test/Source Code Analysis. Outputs are ranked/suspected methods and natural-language rationales.",
            "number_of_agents": "4",
            "agent_specializations": "Four specialized LLM-driven agents: (1) Test Code Reviewer — analyzes test methods and test utility code to summarize test behavior and gather covered classes/methods; (2) Software Test Engineer — examines test failure information, lists possible causes, and validates suspicious methods (used for Test Failure Analysis and Method Review/confirmation); (3) Software Architect — focuses on software architecture and locating problematic areas/classes (used in class/method search tasks); (4) Source Code Reviewer — generates / enhances method/class documentation and analyzes call relationships to produce clearer method summaries (Method Doc Enhancement).",
            "research_phases_covered": "Problem understanding (Fault Comprehension), exploration/navigation of large code bases (Codebase Navigation), execution/validation (running tests and Fault Confirmation), and human-interpretable explanation generation (rationale). In other words: comprehension, implementation-level exploration/execution, and evaluation/validation.",
            "coordination_mechanism": "Centralized, sequential pipeline following a predefined SOP. A central Prompt Generator/State Storage/Result Parser coordinates agents: tools/agents write to State Storage and subsequent agents read from it; agents are invoked per SOP step in sequence with well-defined task templates. Multi-step chain-of-thought style coordination (intermediate 'Possible Causes' are produced and consumed by downstream agents).",
            "communication_protocol": "Natural-language prompts and responses to/from LLM-driven agents augmented by structured artifacts: markdown tables for class lists, fixed prompt templates per task, and structured data in State Storage (tool outputs like Extracted Classes). Agents call external tools (Program Analysis) which return structured outputs (e.g., JSON-like Extracted Classes) that are included in prompts.",
            "feedback_mechanism": "Iterative refinement and multi-round dialogue: (1) agents produce intermediate artifacts (e.g., 'Possible Causes', enhanced method docs) stored centrally and consumed downstream; (2) Method Review uses Multi-Round Dialogue where the Software Test Engineer inspects one candidate method per round and returns TRUE/FALSE with reason; (3) retrospective Get-Top-1 task aggregates per-class/method reviews. These loops provide feedback that refines search and confirmation.",
            "communication_frequency": "Phase-driven / on-demand: agents exchange information at phase transitions (after each SOP step) and during iterative confirmation (on-demand per suspicious method via multi-round dialogues).",
            "task_domain": "Software engineering — automated fault localization / debugging at project (method) level.",
            "performance_metrics": "Top-N localization counts on Defects4J-V1.2.0 and V2.0.0: On Defects4J-V1.2.0 (395 bugs) AGENTFL: Top-1 = 157, Top-3 = 183, Top-5 = 187. On Defects4J-V2.0.0 (226 bugs) AGENTFL: Top-1 = 78, Top-3 = 98, Top-5 = 103. Runtime & cost: average runtime ≈ 97 seconds per bug; average monetary cost ≈ $0.074 per bug (model price used: $0.003 per 1k tokens).",
            "baseline_comparison": "Compared to LLM-based baselines adapted to project-level (ChatGPT_{Ochiai}, LLMAO_{Ochiai}): AGENTFL outperforms both on Top-1 (AGENTFL Top-1=157 vs ChatGPT_{Ochiai}=121, LLMAO_{Ochiai}=129). Compared to statistic-based approaches (Ochiai, FLUCCS, DeepFL_{cov}, GRACE): AGENTFL (157 Top-1) outperforms Ochiai and FLUCCS on many projects but underperforms the top learning/graph approaches (e.g., GRACE Top-1=192 overall); AGENTFL is complementary (has unique correct localizations).",
            "coordination_benefits": "Coordination enables: (1) improved Top-1 localization compared to single-LM prompting baselines (+36 vs ChatGPT_{Ochiai}, +28 vs LLMAO_{Ochiai}); (2) generation of human-readable rationales that improved developer task completion in a user study (participants localized more bugs with AGENTFL suggestions); (3) cost- and time-efficient project-level localization (avg $0.074, 97s). Quantified contributions from coordinated components shown via ablation (see below).",
            "coordination_challenges": "Limitations reported: (1) ranking is weaker than learning-based rankers — AGENTFL is designed as a validation/inspection workflow rather than producing fine-grained suspiciousness scores, hurting Top-3/Top-5; (2) struggles on projects with very large coverage (e.g., Closure) where many classes/methods are covered and LLM focus degrades; (3) LLM context-length and decreased reliability on long contexts (necessitating decomposition); (4) potential hallucination and reliance on quality of available documentation; (5) small number of suspicious methods returned (often &lt;3) can reduce recall in Top-N metrics.",
            "ablation_studies": "Three ablations reported: (a) remove TestBehaviorAnalysis → Top-1 drops from 157 to 148; (b) remove TestFailureAnalysis → Top-1 drops from 157 to 125 (largest drop); (c) remove MethodDocEnhancement → Top-1 drops from 157 to 133. These quantify the contribution of coordination components and intermediate artifacts ('Possible Causes', enhanced docs, test behavior).",
            "optimal_configurations": "Practical configuration choices reported: use gpt-3.5-turbo-16k as LLM engine; retain only Top-50 covered classes by method-level coverage to reduce search space (preserves buggy class in &gt;98% cases); token limits: test output log ≤ 200 tokens, class/method documentation ≤ 100 tokens; keep ≤ 5 failed test cases per test class; use the three-step SOP and four agent specializations described above. The paper highlights the importance of the Test Failure Analysis and Method Doc Enhancement tasks as key components.",
            "uuid": "e2573.0",
            "source_info": {
                "paper_title": "AgentFL: Scaling LLM-based Fault Localization to Project-Level Context",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "ChatDev",
            "name_full": "ChatDev: Communicative agents for software development",
            "brief_description": "A multi-agent framework for software development that supports communicative LLM-driven agents, standardized workflows (SOP), and agent roles; used as the implementation foundation for AGENTFL.",
            "citation_title": "Communicative agents for software development",
            "mention_or_use": "use",
            "system_name": "ChatDev",
            "system_description": "A state-of-the-art multi-agent framework enabling multiple communicative agents for software development tasks. The framework provides primitives for agent roles, message passing, and workflow coordination; AGENTFL is implemented on top of ChatDev in this paper.",
            "number_of_agents": "variable",
            "agent_specializations": "Supports a variety of role-based agents commonly used in software development workflows (e.g., product managers, engineers); exact specializations depend on instantiation.",
            "research_phases_covered": "Software design and development workflows (task decomposition, implementation, and coordination); in AGENTFL it is used to implement debugging/localization pipeline.",
            "coordination_mechanism": "Predefined streamlined workflows / SOPs (centralized workflow engine in the framework that sequences agents and standardizes intermediate artifacts).",
            "communication_protocol": "Natural-language messages among agents mediated by the framework, plus structured artifacts (documents, code) as intermediate outputs.",
            "feedback_mechanism": "Supports memory and tool usage for agents; agents can produce structured intermediate artifacts used by other agents (implicit iterative refinement supported).",
            "communication_frequency": "Configurable by workflow; typically at phase boundaries and on-demand within tasks.",
            "task_domain": "Software engineering / automated software development (framework-oriented).",
            "performance_metrics": "Not reported in this paper (framework used as implementation substrate).",
            "baseline_comparison": "Not compared; used as the underlying multi-agent framework for AGENTFL implementation.",
            "coordination_benefits": "Enables modular agent instantiation and SOP-based orchestration which AGENTFL leverages for task decomposition and agent specialization.",
            "coordination_challenges": "Not specifically evaluated in this paper; general concerns include need for well-defined SOPs and the risk of propagation of LLM hallucinations across agents.",
            "ablation_studies": "None reported specifically for ChatDev in this paper.",
            "optimal_configurations": "The paper follows ChatDev's approach of structured SOP and task-specific system instructions; no additional optimal configurations for ChatDev are prescribed beyond those used to implement AGENTFL.",
            "uuid": "e2573.1",
            "source_info": {
                "paper_title": "AgentFL: Scaling LLM-based Fault Localization to Project-Level Context",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "MetaGPT",
            "name_full": "MetaGPT: Meta programming for multi-agent collaborative framework",
            "brief_description": "A referenced multi-agent system that applies SOP-style workflows and role-based agents (e.g., product managers, engineers) to automate software development tasks; cited as inspiration for SOP and agent design.",
            "citation_title": "MetaGPT: Meta programming for multi-agent collaborative framework",
            "mention_or_use": "mention",
            "system_name": "MetaGPT",
            "system_description": "Mentioned as an example of multi-agent systems that follow predefined SOP/workflows where agents with specific roles collaborate to produce structured intermediate outputs (documents, code). The paper cites MetaGPT as an example that uses role-based agents in a coordinated workflow for software engineering.",
            "number_of_agents": "variable",
            "agent_specializations": "Typical role examples (as described in the paper): product managers, engineers, etc.; designed for software development pipelines.",
            "research_phases_covered": "Software development workflow (planning, implementation, documentation); used as inspiration for SOP-based coordination.",
            "coordination_mechanism": "Predefined, streamlined workflow (SOP) that sequences role-based agents; the paper references MetaGPT's SOP idea but does not detail its internals.",
            "communication_protocol": "Not specified in detail here — referenced as using structured intermediate outputs (documents, code) and standardized formats.",
            "feedback_mechanism": "SOP-driven artifact handoff and standardized intermediate outputs ensure robustness; specific feedback loops not detailed in this paper.",
            "communication_frequency": "Workflow-driven (at task boundaries as per SOP).",
            "task_domain": "Automated software development / programming automation.",
            "performance_metrics": "Not provided in this paper (only referenced).",
            "baseline_comparison": "Not applicable in this paper (referenced).",
            "coordination_benefits": "Provides task decomposition and robust coordination via SOP; cited as motivating AGENTFL's SOP decomposition.",
            "coordination_challenges": "Not detailed in this paper.",
            "ablation_studies": "None reported here.",
            "optimal_configurations": "Not specified in this paper.",
            "uuid": "e2573.2",
            "source_info": {
                "paper_title": "AgentFL: Scaling LLM-based Fault Localization to Project-Level Context",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "AutoGPT",
            "name_full": "AutoGPT",
            "brief_description": "An open-source autonomous-agent system that chains LLM calls to pursue user-specified goals; mentioned as a broad example of LLM-driven autonomous agents.",
            "citation_title": "Autogpt",
            "mention_or_use": "mention",
            "system_name": "AutoGPT",
            "system_description": "Cited as an example of LLM-driven agents that attempt to autonomously carry out missions by chaining tasks and using tools; referenced in the context of multi-agent/autonomous agent examples.",
            "number_of_agents": "variable / autonomous single-agent orchestration (as typically deployed)",
            "agent_specializations": "General autonomous 'mission' agent(s) that plan, call tools, and iterate; paper does not detail role breakdown.",
            "research_phases_covered": "General autonomous task execution and planning; not specifically scientific research in this paper.",
            "coordination_mechanism": "Autonomous goal-driven task chaining (not described in detail here).",
            "communication_protocol": "Primarily natural-language prompts and tool API calls; specifics not described in this paper.",
            "feedback_mechanism": "Iterative planning and execution loops internal to the AutoGPT pattern; not detailed in this paper.",
            "communication_frequency": "Continuous/iterative as tasks progress in AutoGPT architecture (paper only cites AutoGPT).",
            "task_domain": "General autonomous tasks / multi-step missions (cited as an example).",
            "performance_metrics": "Not provided in this paper.",
            "baseline_comparison": "Not applicable in this paper.",
            "coordination_benefits": "Demonstrates autonomous chaining of LLM calls and tool use; cited as an example of agent autonomy.",
            "coordination_challenges": "Not discussed in this paper.",
            "ablation_studies": "None reported here.",
            "optimal_configurations": "Not specified in this paper.",
            "uuid": "e2573.3",
            "source_info": {
                "paper_title": "AgentFL: Scaling LLM-based Fault Localization to Project-Level Context",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "BabyAGI",
            "name_full": "BabyAGI",
            "brief_description": "A lightweight project/repo (cited) that demonstrates an agentic loop for task decomposition and iterative execution using LLMs; referenced as another example of agentic systems.",
            "citation_title": "Babyagi",
            "mention_or_use": "mention",
            "system_name": "BabyAGI",
            "system_description": "Mentioned as an example of simple agent pipelines that perform arbitrary missions by repeatedly generating tasks, executing them, and storing results; referenced in the related-work context of LLM-driven agents.",
            "number_of_agents": "variable (often implemented as one agent orchestrating tasks)",
            "agent_specializations": "Task-generation, task-execution, and memory maintenance roles as typical in BabyAGI patterns; paper does not provide specifics.",
            "research_phases_covered": "General iterative execution/automation, not specified as scientific research here.",
            "coordination_mechanism": "Task queue and iterative loop; not detailed in the present paper.",
            "communication_protocol": "Natural language prompts and simple memory storage; specifics not provided here.",
            "feedback_mechanism": "Task re-prioritization based on results in the agent loop; not detailed in this paper.",
            "communication_frequency": "Iterative per-task loop; paper only references BabyAGI generally.",
            "task_domain": "General automation / autonomous agents.",
            "performance_metrics": "Not provided here.",
            "baseline_comparison": "Not applicable in this paper.",
            "coordination_benefits": "Illustrative of simple agentic loops; used as contextual reference.",
            "coordination_challenges": "Not discussed in this paper.",
            "ablation_studies": "None reported here.",
            "optimal_configurations": "Not provided here.",
            "uuid": "e2573.4",
            "source_info": {
                "paper_title": "AgentFL: Scaling LLM-based Fault Localization to Project-Level Context",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Agents (open-source framework)",
            "name_full": "Agents: An open-source framework for autonomous language agents",
            "brief_description": "An open-source framework that provides primitives for constructing autonomous language agents with memory, tool use, and inter-agent coordination; cited in related work as underpinning agent features (memory management, tool usage).",
            "citation_title": "Agents: An open-source framework for autonomous language agents",
            "mention_or_use": "mention",
            "system_name": "Agents framework (Zhou et al.)",
            "system_description": "Referenced as a general open-source framework that offers building blocks for autonomous language agents (memory, tools, workflows). The paper cites it in the context of capabilities that multi-agent systems can leverage (memory management, tool usage, multi-agent communication).",
            "number_of_agents": "variable",
            "agent_specializations": "Framework-agnostic — supports arbitrary role specializations depending on instantiation.",
            "research_phases_covered": "Tool-supported execution/interaction phases for autonomous agents; not specifically tailored to scientific research in this paper.",
            "coordination_mechanism": "Framework-provided orchestration primitives (not detailed in this paper).",
            "communication_protocol": "Framework-level message passing and persistent memory; specifics not elaborated in this paper.",
            "feedback_mechanism": "Supports memory-based iterative refinement and tool-invocation feedback; paper only references these general capabilities.",
            "communication_frequency": "Configurable by framework workflows; not specified here.",
            "task_domain": "General autonomous language-agent tasks; mentioned for background.",
            "performance_metrics": "Not provided in this paper.",
            "baseline_comparison": "Not applicable in this paper.",
            "coordination_benefits": "Provides core capabilities (memory, tools) that support coordinated multi-agent behavior; cited as motivation.",
            "coordination_challenges": "Not discussed here.",
            "ablation_studies": "None reported here.",
            "optimal_configurations": "Not specified in this paper.",
            "uuid": "e2573.5",
            "source_info": {
                "paper_title": "AgentFL: Scaling LLM-based Fault Localization to Project-Level Context",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "CAMEL",
            "name_full": "CAMEL: Communicative agents for 'mind' exploration of large language model society",
            "brief_description": "A referenced multi-agent research work that focuses on communication protocols among agents (cited as an example of multi-agent communication research).",
            "citation_title": "Camel: Communicative agents for \"mind\" exploration of large language model society",
            "mention_or_use": "mention",
            "system_name": "CAMEL",
            "system_description": "Mentioned as a representative study of communicative multi-agent systems which explores agent-to-agent communication patterns and emergent behaviors in LLM societies; cited in related work on multi-agent communication.",
            "number_of_agents": "variable / research-dependent",
            "agent_specializations": "Research-focused agent roles to explore communication/coordination behaviors; not detailed here.",
            "research_phases_covered": "Study of agent communication and emergent behaviors; not directly applied to scientific research tasks in this paper.",
            "coordination_mechanism": "Inter-agent communicative protocols studied in CAMEL (paper references conceptually).",
            "communication_protocol": "Agent-to-agent natural-language communication (studied in CAMEL); paper only references CAMEL conceptually.",
            "feedback_mechanism": "Peer communication/negotiation in agent society (conceptual reference).",
            "communication_frequency": "Varies by study; not specified here.",
            "task_domain": "Multi-agent communication research; referenced as related work.",
            "performance_metrics": "Not provided in this paper.",
            "baseline_comparison": "Not applicable here.",
            "coordination_benefits": "Provides background on communicative agent design; cited as related work.",
            "coordination_challenges": "Not detailed in this paper.",
            "ablation_studies": "None reported here.",
            "optimal_configurations": "Not specified in this paper.",
            "uuid": "e2573.6",
            "source_info": {
                "paper_title": "AgentFL: Scaling LLM-based Fault Localization to Project-Level Context",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Gorilla",
            "name_full": "Gorilla: Large language model connected with massive APIs",
            "brief_description": "A referenced system that connects LLMs to many APIs/tools to extend capabilities; cited in context of tool-augmented agents.",
            "citation_title": "Gorilla: Large language model connected with massive apis",
            "mention_or_use": "mention",
            "system_name": "Gorilla",
            "system_description": "Referenced as an example of augmenting LLM-driven agents with rich tool/ API access to improve capabilities. The paper cites Gorilla in the context of tool usage mechanisms for agents.",
            "number_of_agents": "variable / framework-level",
            "agent_specializations": "Tool-using agent archetypes; specifics not provided in this paper.",
            "research_phases_covered": "Tool-augmented execution and information retrieval phases; cited as a tool-usage example.",
            "coordination_mechanism": "Not described here — referenced for tool integration.",
            "communication_protocol": "LLM-to-API/tool calls; specifics not detailed in this paper.",
            "feedback_mechanism": "Tool outputs fed back into agent prompts; conceptual reference only.",
            "communication_frequency": "On-demand tool invocation; not specified here.",
            "task_domain": "General LLM tool-augmentation; referenced in background.",
            "performance_metrics": "Not provided here.",
            "baseline_comparison": "Not applicable in this paper.",
            "coordination_benefits": "Illustrates the value of augmenting agents with tool access; used as contextual background.",
            "coordination_challenges": "Not discussed here.",
            "ablation_studies": "None reported here.",
            "optimal_configurations": "Not provided in this paper.",
            "uuid": "e2573.7",
            "source_info": {
                "paper_title": "AgentFL: Scaling LLM-based Fault Localization to Project-Level Context",
                "publication_date_yy_mm": "2024-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "MetaGPT: Meta programming for multi-agent collaborative framework",
            "rating": 2
        },
        {
            "paper_title": "Communicative agents for software development",
            "rating": 2
        },
        {
            "paper_title": "Autogpt",
            "rating": 2
        },
        {
            "paper_title": "Babyagi",
            "rating": 1
        },
        {
            "paper_title": "Agents: An open-source framework for autonomous language agents",
            "rating": 2
        },
        {
            "paper_title": "Camel: Communicative agents for \"mind\" exploration of large language model society",
            "rating": 2
        },
        {
            "paper_title": "Gorilla: Large language model connected with massive apis",
            "rating": 1
        }
    ],
    "cost": 0.020873000000000003,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>AGENTFL: Scaling LLM-based Fault Localization to Project-Level Context</h1>
<p>Yihao Qin<em>, Shangwen Wang</em>, Yiling Lou ${ }^{\dagger}$, Jinhao Dong ${ }^{\ddagger}$, Kaixin Wang ${ }^{\dagger}$, Xiaoling Li<em>, Xiaoguang Mao</em>, *National University of Defense Technology, China, {yihaoqin, wangshangwen13, lixiaoling, xgmao}@nudt.edu.cn<br>${ }^{\dagger}$ Fudan University, China, {yilinglou@, kxwang23@m.}fudan.edu.cn<br>${ }^{\ddagger}$ Peking University, China, dongjinhao@stu.pku.edu.cn</p>
<h4>Abstract</h4>
<p>Fault Localization (FL) is an essential step during the debugging process. With the strong capabilities of code comprehension, the recent Large Language Models (LLMs) have demonstrated promising performance in diagnosing bugs in the code. Nevertheless, due to LLMs' limited performance in handling long contexts, existing LLM-based fault localization remains on localizing bugs within a small code scope (i.e., a method or a class), which struggles to diagnose bugs for a large code scope (i.e., an entire software system). To address the limitation, this paper presents AGENTFL, a multi-agent system based on ChatGPT for automated fault localization. By simulating the behavior of a human developer, AGENTFL models the FL task as a three-step process, which involves comprehension, navigation, and confirmation. Within each step, AGENTFL hires agents with diversified expertise, each of which utilizes different tools to handle specific tasks. Particularly, we adopt a series of auxiliary strategies such as Test Behavior Tracking, Document-Guided Search, and Multi-Round Dialogue to overcome the challenges in each step. The evaluation on the widely used Defects4J-V1.2.0 benchmark shows that AGENTFL can localize 157 out of 395 bugs within Top-1, which outperforms the other LLM-based approaches and exhibits complementarity to the state-of-the-art learning-based techniques. Additionally, we confirm the indispensability of the components in AGENTFL with the ablation study and demonstrate the usability of AGENTFL through a user study. Finally, the cost analysis shows that AGENTFL spends an average of only 0.074 dollars and 97 seconds for a single bug.</p>
<p>Index Terms-Large Language Model, Fault Localization</p>
<h2>I. INTRODUCTION</h2>
<p>Fault Localization (FL) is an important but time-consuming phase in the software debugging process. In particular, developers can spend nearly half of the debugging time to understand and localize the bug before they fix the buggy code locations [1]. To release developers from the laborious FL tasks, various techniques have been proposed to automatically localize buggy program entities (e.g., classes, methods, or statements), among which the spectrum-based fault localization (SBFL) [2], [3], [4], [5], [6] and learning-based fault localization (LBFL) [7], [8], [9], [10] have been extensively studied and perform progressive effectiveness. As one of the most famous FL techniques, SBFL statistically analyzes</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>the coverage information and prioritizes the program entities covered by more failed tests and fewer passed tests. To better utilize the coverage information, LBFL techniques such as GRACE [11] represent coverage with a graph structure and leverage GNN models to learn useful features. Several state-of-the-art techniques have also suggested incorporating auxiliary information, such as code complexity and code history, and leveraging the combined features of such information with machine/deep learning models [8], [10].</p>
<p>The recent advance of Large Language Models (LLMs) has shed new light on fault localization. Having been trained on massive code and textual data, LLMs exhibit a strong capability in code comprehension [12], [13], [14], including detecting and localizing bugs in the code [15]. Existing LLM-based fault localization mainly remains on the preliminary application of LLMs via basic prompting or fine-tuning. In particular, Wu et al. [15] prompt ChatGPT with simple instructions (e.g., "Please analyze the following code snippet for potential bugs...") and test failure information to localize bugs in the given method; LLMAO [16] fine-tunes LLMs with adapters on the fault localization dataset (i.e., the tuning input are 128 consecutive code lines while the output are the buggy line labels). Although showing promising effectiveness, existing techniques can only address a simplified fault localization scenario, i.e., localizing the buggy statements in the given buggy method. The potential of LLMs under the project-level fault localization, i.e., localizing the buggy methods from an entire project, has not been thoroughly studied, possibly due to the following technical challenges. First, the codebase of a real-world project often contains millions of tokens, which are far beyond the maximum input length of existing LLMs (e.g., the input lengths of the GPT-3.5 series models vary from 4,096 to 16,385 tokens). Therefore, it is often infeasible and unacceptably resource-consuming to directly query LLMs with the entire project for fault localization. Second, existing LLMs exhibit deteriorating performance as the length of input context increases and have a tendency to overlook critical information within the long inputs [17]. Therefore, simply feeding LLMs with as much code as possible might not be an optimal way to leverage the superior capabilities of the model.</p>
<p>To scale up LLM-based fault localization to the project-level contexts, in this work, we propose to decompose the local-</p>
<p>ization process into multiple phases and selectively enhance LLMs with different debugging information during each phase. We are inspired by the debugging process of human developers, who often take various actions such as analyzing the fault (comprehending an error trace or a core dump), browsing the codebase (following each computational step in the execution of the failing test), and examining the code (building mental representation by reading and understanding the code) [1], [18]. Specifically, by decomposing the localization process into several steps and achieving FL through the collaboration of multiple LLM-driven agents (i.e., intelligent entities that can perceive the environment, make decisions, and perform actions), the advantages we expect are twofold. On the one hand, this multi-step approach allows more controllable model inputs, which avoids excessively long contexts by merely providing essential information for the LLMs in each step. On the other hand, the capabilities of LLMs are further exploited since each agent focuses on processing specific tasks with their customized expertise.</p>
<p>Based on the above intuition, we propose a novel LLMbased FL system, AGENTFL, which incorporates multiple LLM-driven agents to localize bugs for an entire project. To mitigate the inherent limitations of LLMs in handling largescale codebases, AGENTFL decomposes the project-level fault localization into three stages, including Fault Comprehension, Codebase Navigation, and Fault Confirmation, where each stage is driven by multiple specialized agents. (1) The fault comprehension stage leverages LLMs to analyze the potential causes of the exposed fault, which would serve as the essential guidelines for the following two stages. Different from existing LLM-based FL techniques that only provide LLMs with the error message and the failed test code, AGENTFL incorporates a novel Test Behavior Tracking approach to collect the complete test execution behaviors (i.e., the test utility code) via lightweight program instrumentation. (2) The codebase navigation stage then leverages LLMs to identify suspicious methods in a gradual refinement way, which first narrows down the faulty code space by finding out the suspicious classes and then selects related methods from these classes. To achieve this, AGENTFL incorporates a novel Document-Guided Search approach, which utilizes both existing documents and LLM-enhanced documents to identify classes and methods related to the potential error causes. (3) The fault confirmation stage lastly leverages LLM to revisit all the suspicious methods (identified in the previous stage) and decide the most suspicious one as the final result. In this stage, AGENTFL incorporates a novel Multi-Round Dialogue approach, which iteratively asks LLM to review each suspicious method with its detailed information.</p>
<p>We evaluate AGENTFL on the Defects4J-V1.2.0 [19] benchmark which includes 395 real-world bugs from 6 Java projects. To compare with the existing LLM-based FL techniques, we empower them to achieve project-level localization with Ochiai [20]. The results show that AGENTFL can localize 157 bugs within Top-1, which significantly outperforms the LLMbased baselines ChatGPT_{Ochiai} [15] and LLMAO_{Ochiai} [16]. AGENTFL also shows complementarity with existing learningbased techniques such as DeepFL [10] and GRACE [11]. We further validate the importance of different components in AGENTFL with an ablation study. In addition, through a user study, we show the usability of AGENTFL in practice with its ability to provide both suspicious methods and rationale. Finally, the cost analysis reveals that AGENTFL requires only an average of 0.074 dollars and 97 seconds to localize a fault.</p>
<p>The main contributions of this paper are:</p>
<ul>
<li>We propose to decompose the project-level fault localization into three stages, i.e., comprehension, navigation, and confirmation. Such a process adheres to the developers’ debugging practice and holds the potential for effectively managing the inputs of the LLMs.</li>
<li>We present AGENTFL, a three-stage FL technique empowered by multiple LLM-driven agents, capable of automatically localizing faults within the entire software.</li>
<li>We extensively evaluate AGENTFL on both Defects4JV1.2.0 and Defects4J-V2.0.0. AGENTFL outperforms the other LLM-based approaches and shows complementarity with existing LBFL techniques on both datasets. Additionally, we conduct the user study and cost analysis to demonstrate the usability of AGENTFL.</li>
</ul>
<h2>II. BACKGROUND \&amp; RELATED WORK</h2>
<h2>A. Statistic-Based Fault Localization</h2>
<p>Spectrum-based and learning-based fault localization are mainstream FL technologies that achieve prominent performance on the Defects4J [19] benchmark. Given the buggy program and a set of tests including both passed and failed instances, the spectrum-based fault localization (SBFL) localizes suspicious program entities through the hypothesis that the fault location should be covered by more failed tests than passed ones. To achieve this, SBFL first collects coverage information for each program element $e$ by recording the number of passed tests $T_{p}(e)$ and failed tests $T_{f}(e)$ that cover $e$, then designs different formula such as Ochiai [20], DStar [21] and Jaccard [22] to calculate the suspiciousness scores for ranking all the elements. As an example, Ochiai computes the suspiciousness of an element $e$ as $T_{f}(e) /\left(\left(T_{f}(e)+T_{p}(e)\right) T_{f}\right)^{1 / 2}$, where $T_{f}$ is the number of all failed tests.</p>
<p>To use coverage more exhaustively and combine extra valuable information such as code history, learning-based fault localization (LBFL) is also extensively studied. FLUCCS [8] boosts SBFL with code and change metrics. DeepFL [10] learns to combine four dimensions of knowledge from SBFL, mutation-based FL, code complexity, and text similarity through RNN [23] and MLP [24]. GRACE [11] integrates coverage with fine-grained code structures by a GNN [25] model. Other well-known LBFL techniques include CNNFL [9], TraPT [26], CombineFL [27], and GNet4FL [28], etc.</p>
<p>Based on the high dependence of SBFL and LBFL on coverage information and code features, we consider them both as statistic-based fault localization (STBFL) to distinguish them from the approaches based on the LLMs.</p>
<h2>B. LLM-Based Fault Localization</h2>
<p>With the emergence of the Large Language Model (LLM), LLMs such as ChatGPT [29], Phind [30], CodeGen [31], and StarCoder [32] have shown remarkable power on aligning semantics between natural languages (NL) and programming languages (PL). In the ChatGPT-4 launch event, OpenAI prompted the model to localize and fix errors by providing program code and error log, which unveiled the potential and applicability of ChatGPT-4 in fault localization.</p>
<p>However, due to the well-known context limitation issue as well as the decreasing performance on longer input contexts [15], [17], existing LLM-based FL techniques primarily concentrate on localizing buggy lines within a code snippet, while neglecting the identification of bugs in an entire software project. Given a context of 128 code lines, LLMAO [16] trains lightweight bidirectional adapters on top of LLMs to produce a suspiciousness score for each line. Wu et al. [15] prompts ChatGPT with code and error logs, and instructs the model to identify the buggy lines. To assist developers from another perspective, in this paper, we endow the LLMs with the ability to automatically identify bugs in the entire software.</p>
<h2>C. LLM-driven agents \&amp; SOP</h2>
<p>Supported by the existing studies about human debugging behaviors [1], [18], we regard fault localization as a complex task, which is difficult to get desired results with only one LLM inference. Therefore, we inherited the design principles of LLM-driven agents and standard operating procedure (SOP) during the construction of AGENTFL.</p>
<p>LLM-driven agents are designed to solve complex tasks specified in natural language autonomously. Equipped with mechanisms including memory management [33], tool usage [34], and multi-agent communication [35], LLM-driven agents have been proposed to conduct various tasks such as social behavior simulation [36], website tasks [37], and interactive writing [33]. There are also LLM-driven agents such as AutoGPT [38] and BabyAGI [39] that aim at conducting arbitrary missions with user instructions. More recently, multiagent systems such as MetaGPT [40] and ChatDev [41] have started to move towards automated software development.</p>
<p>SOP is a concept from the real-world engineering domain, for LLM-driven agents, SOP is a symbolic plan to make the agents more controllable [40], [42]. For example, in MetaGPT, employed agents (e.g., product managers and engineers) work together by following a predefined and streamlined workflow, where all intermediate outputs (e.g., the document and code) are structured and standardized. SOP plays a vital role in task decomposition and effective coordination, which ensures the robustness of the multi-agent system.</p>
<h2>III. APPROACH</h2>
<p>AGENTFL is a multi-agent fault localization system that localizes buggy methods for the given project in three steps. We first introduce an overview of AGENTFL and then explain the detailed steps respectively.</p>
<h2>A. Overview</h2>
<p>The overall workflow of AGENTFL is shown in Figure 1. In particular, AGENTFL consists of three steps; in each step, AGENTFL is supposed to tackle different tasks; to specialize the LLMs to solve different tasks, four different agents are constructed by enhancing the LLMs with domain knowledge and external components.</p>
<p>Inputs \&amp; Outputs. The inputs of AGENTFL include the codebase of the entire project, the failed test methods (i.e., the failed test cases), and the error message of the triggered fault. As it is common for one fault to trigger multiple failed test methods (e.g., 22 test methods fail in the bug Chart-26 in Defects4J) and it is less efficient to diagnose each failed test method separately, AGENTFL focuses on one failed test class (i.e., the aggregation of the failed test methods in the same class) in each run, and the total number of runs is the number of failed test classes. The outputs of AGENTFL include the buggy location and the corresponding explanations, which consist of the following three parts: (i) the Top-1 Suspicious Method along with its reason for being buggy, (ii) the suspicious Class, and (iii) other Suspicious Methods in the class along with their reasons for being buggy.</p>
<p>Steps \&amp; Tasks. By mimicking the human debugging strategies [1], [18], AGENTFL models the fault localization process as an SOP which comprises three steps, including (i) understanding the cause of the fault (Fault Comprehension), (ii) browsing the relevant program elements (Codebase Navigation), and (iii) validating the buggy location (Fault Confirmation). In each step, AGENTFL tackles different tasks (identified by - in Figure 1), e.g., the first step of fault comprehension involves the (1) Test Behavior Analysis task and the (2) Test Failure Analysis task.</p>
<p>Agents. To specialize the LLMs to solve different tasks, AGENTFL incorporates four different LLM-driven agents (i.e., Test Code Reviewer, Source Code Reviewer, Software Architect, and Software Test Engineer), which enhance LLMs with task-specific knowledge and external capabilities (e.g., program analysis component). In particular, the Test Code Reviewer agent (used in Task 1) is designed for reviewing the test code and summarizing the test behavior; the Source Code Reviewer agent (used in Task 4) is designed for writing highquality code comments; the Software Architect agent (used in Tasks 3\&amp;5) is designed for software architecture and adept at finding areas of the program that may be problematic; the Software Test Engineer agent (used in Tasks 2\&amp;6\&amp;7) is designed for all the tasks associated with analyzing and validating the test failures. Each LLM-driven agent is customized by prompting LLMs with specific system instructions and enabling LLMs to use external components. In particular, the specific system instruction is typically provided at the start of the interaction to serve as the initial context or instruction for the LLMs. Due to space constraints, we present the system instruction of the Software Test Engineer agent below:</p>
<p>You are a Software Test Engineer. We share a common interest in collaborating to successfully locate the buggy code that causes the test class to fail. Your main responsibilities include examining the information of the failed tests to analyze the possible causes of the test failures, and determining the method that needs to be fixed. To locate the bug, you must write a response that appropriately solves the requested instruction based on your expertise.</p>
<p>Components. The LLMs alone fall short in limited context length and unstable performance of hallucination [43]. Therefore, AGENTFL incorporates multiple components to enhance LLM-driven agents with memorization, reasoning, and tool usage capabilities. In other words, with the LLM as the brain of each agent, the other components provide LLMs with external capabilities of better utilizing debugging contexts. In particular, the Program Analysis component is driven by lightweight Instrumentation and Static Analysis, which equips the agents with the tools (Test/Source Code Analysis) to perceive the test execution process; the components of Result Parser, State Storage, and Prompt Generator enable a loop to drive the pipeline operations of multiple tasks. Specifically, the Prompt Generator collects material from the State Storage and generates the prompt according to a template predefined for each task. After the agent returns the response, the Result Parser transforms the result into formatted data and sends it to the State Storage, where the result will be utilized in the downstream steps. Moreover, the data in State Storage can also come from the Program Analysis component when the agent calls a tool.</p>
<h2>B. Fault Comprehension</h2>
<p>Aim. To guide the whole localization process, AGENTFL starts with the Fault Comprehension step to better understand the cause of the fault before starting to find it. Our intuition is that compared to direct reasoning, the "understandingreasoning" manner bridges the test failure information and the buggy source code with intermediate thought, which is more akin to the human mindset. Specifically, the Fault Comprehension step consists of two tasks. Provided with the test code, the (1) Test Behavior Analysis task prompts the LLM to describe in detail the behavior of the failed test cases. In the (2) Test Failure Analysis task, the test behavior we obtained before together with other test failure information (including error stack trace, test code, and test output) encourages the LLM to list the possible causes of the fault. As the intermediate thought, the possible causes will inform the subsequent navigation step.</p>
<p>Challenge. Although the attendance of test code (i.e., the test method executed during each unit test) has been proved helpful in LLM-based FL [15], we observe that the LLMs may still suffer from the limited information in the test method. Figure 2 shows an example derived from bug Closure-19 in Defects4J-V1.2.0 [19], in this case, the test testNoThisInference failed when a test utility method inFunction() is called at line 4. However, since the developers kept all the detailed test logic in test utility methods that are called by the test method, the LLMs may find it difficult to comprehend the complete test behavior through
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1: Overview of AGENTFL.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2: Example from Closure-19.
only the test method. In particular, test utility methods are very prevalent in practice, e.g., each test method calls 4.93 other test utility methods on average in the Defect4J-V1.2.0 benchmark. Therefore, the information in the utility methods can be potentially helpful for comprehensively comprehending the test failure.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3: The process of the Program Analysis.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4: An example of method document enhancement.
Strategy. To track the complete test execution behavior from the test utility methods, we adopt the Test Behavior Tracking strategy which equips the LLMs with the capability of program analysis. Specifically, the Test Code Reviewer agent in task (1) utilizes the Test Code Analysis tool to fill the prompt with the Test Utility Code before it is asked to summarize the test behavior. The more detailed process of Test Code Analysis in the Program Analysis component is demonstrated in Figure 3. Firstly, the tool applies lightweight Instrumentation for each failed test case to record the Method Call Trace during test code execution, and parses the trace to register the Covered Classes, each Class comprised of the full class name (e.g., com.google.jscomp.TypeInferenceTest) and a signature list (e.g., init (int, String) int) of the covered test utility methods in that class. Secondly, a Class Intersection operation is conducted to keep the common classes and methods that are covered by all failed test cases, we refer to the output as Common Classes. Finally, the Static Analysis further augments the classes and methods with the document, name, and code from the codebase. As the output of the tool, Extracted Classes contains information about both the covered test class and the covered test utility methods, which is then reserved in the State Storage and used to construct the Test</p>
<p>Utility Code of the prompt in Test Behavior Analysis task.</p>
<h2>C. Codebase Navigation</h2>
<p>Aim. Provided with the comprehension of the possible causes in the last step, the Codebase Navigation step intends to identify all related methods from the entire codebase. Our intuition is that given the test failure information and the possible causes generated from task (2, ChatGPT can gradually browse the entire codebase from global to local and identify the program entities that may be responsible for the test failure. Specifically, we start with two tasks for the Codebase Navigation step. The (1) Search Suspicious Class task intends to localize the most suspicious class among all covered classes during a test execution process. After that, the (2) Find Related Methods task aims to filter out all the methods that may relate to the bug within the suspicious class. To depict the role of methods in a class, the information about the suspicious class is also included in the prompt.</p>
<p>Challenge. Nevertheless, the above design still faces three challenges: (1) Due to the possible invalidity or weakness of LLMs under long contexts [17], a strategy should be taken for leading the model to concentrate on critical information during the browsing process; (2) An excessive number of covered classes can still result in LLM distraction and context length issues, for example, the failed integration test testSingletonGetter1 of bug Closure-36 covers hundreds of methods in 208 classes; (3) The ChatGPT model struggles to identify related methods directly with the existing documents due to the absence of some method comments and the "function nested" problem. The upper side of Figure 4 shows an example of the original method comments in bug Closure-1. In the first row, the absence of the comment of method isRemovableVar(Var) prevents ChatGPT from better understanding its functionality. In the second row, although the comment of process (Node, Node) says it "removes all unused variables", this method accomplishes the functionality by calling other methods. We refer to this inconsistency of comment and function of a method as the "function nested" problem, which could mislead the LLMs to focus on irrelevant methods.</p>
<p>Strategy. To alleviate the aforementioned challenges, we adopt a series of heuristic strategies: (1) Considering that the LLMs can associate the function of a class/method with the function that may cause the bug through the proximity of natural language description, we adopt a Document-Guided Search strategy to first search for suspicious classes and then find the related methods. Specifically, in task (2, we extract the covered classes by source code analysis (Figure 3), and prompt ChatGPT to select a single class from a markdown format table built with names and documentation of the covered classes. After localizing the suspicious class, the (1) task filters out all the methods that may relate to the bug according to the names and comments of the covered methods. (2) To address the issue of an excessive number of covered classes, we draw inspiration from an observation in test coverage. Specifically, we have observed that the fixing</p>
<p>behavior tends to occur more frequently in classes that exhibit higher method-level coverage (for further details, please refer to Section IV-D). Based on this insight, we effectively mitigate the problem by selectively reducing the number of covered classes while ensuring that the performance remains unaffected, which is achieved by retaining only the Top-N classes that possess relatively high method-level coverage. (3) For the documentation inconsistency, our insight is that as the LLMs have demonstrated powerful capabilities in code summarization [12], [44], the Source Code Reviewer agent can be hired to fix the problematic documentation. Therefore, we further design the (1) Method Doc Enhancement task to handle the above problem. Before finding related methods, the source code and the original comments of all covered methods in the suspicious class are listed in the prompt, the agent is then required to analyze the method call relationship to generate a new comment for each method. The enhanced documentation can be seen from the bottom side of Figure 4. In the first row, the task fills in the missing comment. In the second row, the task declares the callee method process() to alleviate the "function nested" problem, which provides more accurate information for the upcoming Find Related Methods task.</p>
<h2>D. Fault Confirmation</h2>
<p>Aim. In the previous steps, AGENTFL has only utilized the documentation and coverage information to search for the related methods in the codebase, which may not be enough to validate the exact fault location. Therefore, we design the Fault Confirmation step to aggregate all useful information and make a final decision on which method is buggy. Specifically, we build the (1) Method Review task, where the Software Test Engineer agent examines the source code of the related methods and integrates all useful information to recognize the buggy methods.</p>
<p>Challenge. In order to review all related methods, a straightforward approach is to fill all the source codes in a single request and require the model to select the most suspicious method. Nevertheless, we found in practice that as the volume of code in the context increases, it is more difficult for the model to focus on the fault location, resulting in a significant performance decrease. Therefore, a strategy should be taken to validate all of the suspicious methods while also ensuring the model's accuracy.</p>
<p>Strategy. To address the above problem, we adopt a MultiRound Dialogue strategy in task (1), enabling the model to analyze one related method at a time. The prompt template of the Method Review task is illustrated below:</p>
<p>One or more tests in the test class [TEST CLASS] failed: Failed tests: [FAILED TESTS]
The method [METHOD NAME] may be problematic. Detailed information is listed below: [TEST INFOS]
Possible Causes: [POSSIBLE CAUSES],
Class of the Suspicious Method: [CLASS NAME]
Documentation of the Class: [CLASS DOC]
Suspicious Method Full Name: [METHOD NAME]
Suspicious Method Comment: [METHOD DOC]
Suspicious Method Code: [METHOD CODE]
As a Software Test Engineer, please carefully examine the code of the method [METHOD NAME] and determine if this method is the buggy location. You can return TRUE with the reason or only FALSE.</p>
<p>After the task (1), multiple methods can be regarded as suspicious. Compared to spectrum-based and learning-based FL, AGENTFL does not generate suspicious values for ranking the suspicious methods. For usability and evaluation purposes, we further design a (2) Get Top-1 Method task in the last, where the Software Test Engineer agent retrospectively analyzes the buggy methods in all failed test classes to determine the most probable fault location. In particular, if there is only one buggy method, the task takes it directly as the top-1 method.</p>
<h2>IV. EXPERIMENT DESIGN</h2>
<h2>A. Research Questions</h2>
<p>To assess the effectiveness of AGENTFL, we propose to answer the following research questions:</p>
<ul>
<li>RQ1: What is the performance of AGENTFL in methodlevel fault localization? This RQ aims to build a new effectiveness baseline for LLM-based method-level fault localization.</li>
<li>RQ2: How does our design choices affect the performance of AGENTFL? This RQ could help measure the contribution of different components in AGENTFL, and thus inspire future studies.</li>
<li>RQ3: Can AGENTFL help developers in practice? This RQ conducts a user study to help understand how useful AGENTFL could be in practice.</li>
</ul>
<h2>B. Benchmark</h2>
<p>In line with most existing fault localization work, we include the two versions of the widely-used benchmarks Defects4J [19] (i.e., Defects4J-V1.2.0 and Defects4J-V2.0.0) for evaluation. In particular, Defects4J-V1.2.0 consists of 395 bugs from 6 real-world Java projects (as shown in Table I), on which we compare AGENTFL against all the studied baselines. In addition, Defects4J-V2.0.0 consists of additional 226 bugs from extra 9 Java projects, on which we further evaluate the generalization capability of studied techniques in the crossproject prediction setting in line with GRACE [11].</p>
<h2>C. Baselines</h2>
<p>LLM-based Baselines. We include two existing LLMbased FL techniques (i.e., LLMAO [16] and Wu et al. [15]) as baselines. However, both techniques are only originally</p>
<p>applied for fault localization within a small context, i.e., LLMAO [16] trains lightweight adapters on top of CodeGen [31] to produce a suspicious score of each line within the given 128 code lines, and Wu et al. [15] require ChatGPT to analyze the buggy line in a method with well-crafted prompts. Therefore, to adapt these techniques to project-level fault localization (i.e., localizing the buggy method from the whole code base), we construct two variants of them (i.e., LLMAO_{Ochiai} and ChatGPT_{Ochiai}), which first leverage the state-of-the-art SBFL technique Ochiai [20] to reduce the context size and then apply these techniques for fault localization. In particular, for ChatGPT_{Ochiai}, we apply a minimal change to the approach of Wu et al. by retaining their prompt format except that the command is changed from finding buggy lines to judging the correctness of the method, and ChatGPT is prompted to validate the top 20 suspicious methods localized by Ochiai. For LLMAO_{Ochiai}, given the top 20 suspicious methods localized by Ochiai, we first use LLMAO to predict a suspicious value for each line in a method, then each method is re-ranked according to the value of its most suspicious line.</p>
<p>Statistic-based Baselines. We include the SBFL technique Ochiai [20], FLUCCS [8] based on machine learning, DeepFL [10] based on deep learning, and GRACE [11] based on graph neural network. For a fair comparison, we follow GRACE [11] to exclude mutation-related features in DeepFL and keep the features related to source code and coverage, the modified version is named DeepFL_{cov}.</p>
<h3>IV-D Implementation</h3>
<p>We implement AGENTFL in Python based on the state-of-the-art multi-agent framework ChatDev [41], we use the gpt-3.5-turbo-16k-0613 model of the ChatGPT family as the engine of AGENTFL. For dynamic program analysis, we implement a lightweight JVM agent by the java.lang.instrument [45] package, and modify the framework of Defects4J to support dynamic program instrumentation. To keep the program analysis focused on test/source code, we allow the tool to instrument the Java bytecode files in the specified folder. For static program analysis, we use tree-sitter [46] for code parsing and program element extraction.</p>
<p>We set the following alterable parameters to regulate the behavior of AGENTFL. Among test information, the maximum token length of the test output log is 200. The token length of class and method documentation is limited to 100. To deal with the rare circumstances of overwhelming test cases, we keep no more than 5 failed test cases for each test class, which barely impairs the performance of AGENTFL in practice.</p>
<p>For covered class reduction (introduced in Section III-C), we investigate the method-level coverage rank of the class changed by developers among all covered classes. Specifically, the method-level coverage rate of class $c$ is calculated with $r_{c}=\left(\sum_{i=1}^{N}\mathbb{I}<em i="i">{y</em>}}\right)/N$, where $\mathbb{I<em i="i">{y</em>$ is covered. Based on the results shown in Figure 5, we retain classes that fall in the top-50 method-level coverage rates, which ensures the buggy class is preserved in over 98% of the cases.}}$ is an function to indicate whether method $y_{i</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 5: Method level coverage rank. For each bug, the green bar is the average coverage rank of all changed classes, and the orange bar is the amount of all covered classes. We show 2 out of 6 projects in Defects4J-V1.2.0 due to space limit.</p>
<p>TABLE I: Information of Defects4J-V1.2.0 benchmark.</p>
<table>
<thead>
<tr>
<th>ID</th>
<th>Name</th>
<th>#Bug</th>
<th>LOC(k)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Chart</td>
<td>JFreeChart</td>
<td>26</td>
<td>96</td>
</tr>
<tr>
<td>Lang</td>
<td>Apache commons-lang</td>
<td>65</td>
<td>22</td>
</tr>
<tr>
<td>Math</td>
<td>Apache commons-math</td>
<td>106</td>
<td>85</td>
</tr>
<tr>
<td>Time</td>
<td>Joda-Time</td>
<td>27</td>
<td>28</td>
</tr>
<tr>
<td>Mockito</td>
<td>Mockito framework</td>
<td>38</td>
<td>23</td>
</tr>
<tr>
<td>Closure</td>
<td>Google Closure compiler</td>
<td>133</td>
<td>90</td>
</tr>
</tbody>
</table>
<h3>IV-E Metrics</h3>
<p>Following prior studies [8], [10], [11], [28], we assess the effectiveness of AGENTFL based on the Top-N (N=1,3,5) metric. Top-N computes the number of bugs that have at least one buggy element localized within the first N positions in the ranked list. It is easy to calculate the Top-1 value with the design of Get Top-1 Method task in AGENTFL. However, since the ChatGPT model is a master at judging true or false rather than calculating suspicious values, it is non-trivial to get Top-3 and Top-5. To alleviate the problem, we compromise by keeping a list of all the methods that AGENTFL considers suspicious in chronological order and calculating Top-N with the rank of the buggy methods in the list.</p>
<h2>V Evaluation</h2>
<h3>V-A RQ1: Localization Performance</h3>
<p>Compared to LLM-based baselines. We first compare AGENTFL with ChatGPT_{Ochiai} and LLMAO_{Ochiai} that both use LLMs to drive fault localization, the results are shown in Table II. Overall, AGENTFL achieves reasonable performance: it can localize 157 out of 395 bugs within Top-1, 28 more than LLMAO_{Ochiai} and 36 more than ChatGPT_{Ochiai}. When considering the Top-1 metric on the individual project, we observe that AGENTFL significantly outperforms the other two techniques on nearly every project except Closure, where LLMAO_{Ochiai} localizes 18 more methods within Top-1. In terms of Top-3 and Top-5 metrics, we found that although AGENTFL outperforms ChatGPT_{Ochiai}, it failed to localize more bugs than LLMAO_{Ochiai}.</p>
<p>The above results can be explained by the different mechanisms of LLMAO_{Ochiai} and AGENTFL. The LLMAO_{Ochiai} predicts a suspicious value for each method that has been pre-localized by Ochiai, which is more talented at ranking tasks.</p>
<p>TABLE II: Comparision with LLM-based baselines on Defects4J-V1.2.0.</p>
<table>
<thead>
<tr>
<th>Project</th>
<th># Bugs</th>
<th>Techniques</th>
<th>Top1</th>
<th>Top3</th>
<th>Top5</th>
</tr>
</thead>
<tbody>
<tr>
<td>Chart</td>
<td>26</td>
<td>ChatGPT_{Ochiai}</td>
<td>11</td>
<td>15</td>
<td>15</td>
</tr>
<tr>
<td></td>
<td></td>
<td>LLMAO_{Ochiai}</td>
<td>11</td>
<td>15</td>
<td>19</td>
</tr>
<tr>
<td></td>
<td></td>
<td>AGENTFL</td>
<td>16</td>
<td>18</td>
<td>19</td>
</tr>
<tr>
<td>Lang</td>
<td>65</td>
<td>ChatGPT_{Ochiai}</td>
<td>29</td>
<td>35</td>
<td>36</td>
</tr>
<tr>
<td></td>
<td></td>
<td>LLMAO_{Ochiai}</td>
<td>31</td>
<td>49</td>
<td>54</td>
</tr>
<tr>
<td></td>
<td></td>
<td>AGENTFL</td>
<td>44</td>
<td>45</td>
<td>45</td>
</tr>
<tr>
<td>Math</td>
<td>106</td>
<td>ChatGPT_{Ochiai}</td>
<td>38</td>
<td>55</td>
<td>55</td>
</tr>
<tr>
<td></td>
<td></td>
<td>LLMAO_{Ochiai}</td>
<td>30</td>
<td>59</td>
<td>70</td>
</tr>
<tr>
<td></td>
<td></td>
<td>AGENTFL</td>
<td>49</td>
<td>60</td>
<td>61</td>
</tr>
<tr>
<td>Time</td>
<td>27</td>
<td>ChatGPT_{Ochiai}</td>
<td>9</td>
<td>11</td>
<td>12</td>
</tr>
<tr>
<td></td>
<td></td>
<td>LLMAO_{Ochiai}</td>
<td>7</td>
<td>13</td>
<td>14</td>
</tr>
<tr>
<td></td>
<td></td>
<td>AGENTFL</td>
<td>11</td>
<td>13</td>
<td>13</td>
</tr>
<tr>
<td>Mockito</td>
<td>38</td>
<td>ChatGPT_{Ochiai}</td>
<td>12</td>
<td>16</td>
<td>16</td>
</tr>
<tr>
<td></td>
<td></td>
<td>LLMAO_{Ochiai}</td>
<td>8</td>
<td>19</td>
<td>26</td>
</tr>
<tr>
<td></td>
<td></td>
<td>AGENTFL</td>
<td>13</td>
<td>14</td>
<td>14</td>
</tr>
<tr>
<td>Closure</td>
<td>133</td>
<td>ChatGPT_{Ochiai}</td>
<td>22</td>
<td>36</td>
<td>38</td>
</tr>
<tr>
<td></td>
<td></td>
<td>LLMAO_{Ochiai}</td>
<td>42</td>
<td>57</td>
<td>70</td>
</tr>
<tr>
<td></td>
<td></td>
<td>AGENTFL</td>
<td>24</td>
<td>33</td>
<td>35</td>
</tr>
<tr>
<td>Overall</td>
<td>395</td>
<td>ChatGPT_{Ochiai}</td>
<td>121</td>
<td>168</td>
<td>172</td>
</tr>
<tr>
<td></td>
<td></td>
<td>LLMAO_{Ochiai}</td>
<td>129</td>
<td>212</td>
<td>253</td>
</tr>
<tr>
<td></td>
<td></td>
<td>AGENTFL</td>
<td>157</td>
<td>183</td>
<td>187</td>
</tr>
</tbody>
</table>
<p>than the ChatGPT model. However, since AGENTFL behaves more like a human by browsing the entire codebase without any auxiliary localization results, the limited search space and the ranking issue [47] of the LLMs hinder it from achieving better performance in Top-3 and Top-5 metrics.</p>
<p>Compared to statistic-based baselines. To investigate how AGENTFL performs against the statistic-based techniques, we select four techniques based on different methodologies: FLUCCS [8] (machine learning), DeepFL_{cov} [10] (multilayer perception), GRACE [11] (graph neural network), and Ochiai [20] (suspicious formula). From Table III, we observe that as a first attempt to use the LLMs for method-level fault localization, AGENTFL is not yet able to surpass existing approaches entirely. Overall, AGENTFL localizes 157 of 395 bugs within Top-1, 77 more than Ochiai, 3 less than FLUCCS, 19 less than DeepFL_{cov}, and 35 less than GRACE.</p>
<p>However, when focusing on the results of individual projects, we find that AGENTFL has achieved competitive performance in all software projects except Closure. To explain this, we scrutinized every bug that AGENTFL failed to localize while other approaches were able to make it. We attribute the prominent weak effectiveness of AGENTFL on Closure to three aspects: (1) Some bugs in Closure possess very similar characteristics. For instance, bugs Closure-18 and Closure-31 have failed test cases with similar purposes (testDependencySorting and testDependencySortingWhitespaceMode), and even the same buggy method parseInputs(). In these cases, the learning-based techniques learn much richer in-project knowledge than AGENTFL as they perform within-project prediction with the leave-one-out training strategy. AGENTFL, however, needs to localize a bug from scratch based on more generalized knowledge from ChatGPT. (2) The tests in Closure tend to cover more program elements. For example, the average number of classes covered by the bugs in Closure is 107.7, which is extremely larger than those in Lang (2.3) and Chart (27.5). In this case, it is more difficult for AGENTFL to recognize the suspicious class at once among a large number of covered classes. (3) Since AGENTFL is designed to validate rather than rank the methods, the number of suspicious methods in the result of AGENTFL is relatively small. Among all 395 bugs, there are 319 (374) cases where the number of suspicious methods in the result is less than 3 (5). Consequently, the increase in the number of bugs localized by AGENTFL becomes progressively smaller from Top-1 to Top-3 (157 to 183) and then Top-3 to Top-5 (183 to 187).</p>
<p>The last row of Table III presents the result without project Closure, AGENTFL reaches a similar level as GRACE in terms of Top-1 and outperforms the other three techniques on each project by localizing 67 more bugs than Ochiai, 15 more than FLUCCS, 21 more than DeepFL_{cov} and only 12 less than GRACE. For cross-project evaluation, we follow Lou et al. [11] to evaluate AGENTFL against other statistic-based approaches on 226 extra bugs in Defects4J-V2.0.0, the result in Table IV shows that AGENTFL significantly outperforms most of the other approaches by localizing 35 more bugs within Top-1 than DeepFL_{cov}, 21 more than FLUCCS, and 46 more than Ochiai. AGENTFL gains comparable performance to GRACE with only 7 fewer bugs localized in the top.</p>
<p>We also investigated the overlaps among the bugs localized within Top-1 by different approaches on the Defects4J-V1.2.0 benchmark, and the results are shown in Figure 6. The figure illustrates the complementarity of AGENTFL with existing approaches on localizing different bugs. Specifically, 34 bugs can be uniquely localized within Top-1 by AGENTFL while the numbers for DeepFL_{cov} and GRACE are 36 and 27 respectively.</p>
<p>Answer to RQ1: AGENTFL can effectively localize the bugs in Defects4J, which outperforms the other LLM-based approaches and shows complementarity with existing statistic-based techniques in terms of the Top-1 metric.</p>
<h3>V-B RQ2: Ablation Study</h3>
<p>For this research question, we aim to investigate the contributions of different design choices to AGENTFL. To this end, we separately remove the Test Behavior Analysis task, Test Failure Analysis task, and Method Doc Enhancement task from AGENTFL, and retain the other tasks that need to maintain the proper functionality of the system. Note that after removing the Test Failure Analysis task, the Test Behavior Analysis task</p>
<p>TABLE III: Comparision with statistic-based baselines on Defects4J-V1.2.0.</p>
<table>
<thead>
<tr>
<th>Project</th>
<th># Bugs</th>
<th>AGENTFL</th>
<th></th>
<th></th>
<th>GRACE</th>
<th></th>
<th></th>
<th>DeepFL ${ }_{\text {coco }}$</th>
<th></th>
<th></th>
<th>FLUCCS</th>
<th></th>
<th></th>
<th>Ochiai</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td>Top1</td>
<td>Top3</td>
<td>Top5</td>
<td>Top1</td>
<td>Top3</td>
<td>Top5</td>
<td>Top1</td>
<td>Top3</td>
<td>Top5</td>
<td>Top1</td>
<td>Top3</td>
<td>Top5</td>
<td>Top1</td>
<td>Top3</td>
<td>Top5</td>
</tr>
<tr>
<td>Chart</td>
<td>26</td>
<td>16</td>
<td>18</td>
<td>19</td>
<td>14</td>
<td>20</td>
<td>22</td>
<td>12</td>
<td>18</td>
<td>21</td>
<td>15</td>
<td>19</td>
<td>16</td>
<td>8</td>
<td>14</td>
<td>15</td>
</tr>
<tr>
<td>Lang</td>
<td>65</td>
<td>44</td>
<td>45</td>
<td>45</td>
<td>42</td>
<td>54</td>
<td>57</td>
<td>43</td>
<td>53</td>
<td>56</td>
<td>40</td>
<td>53</td>
<td>55</td>
<td>24</td>
<td>44</td>
<td>50</td>
</tr>
<tr>
<td>Math</td>
<td>106</td>
<td>49</td>
<td>60</td>
<td>61</td>
<td>61</td>
<td>78</td>
<td>89</td>
<td>39</td>
<td>68</td>
<td>80</td>
<td>48</td>
<td>77</td>
<td>83</td>
<td>23</td>
<td>52</td>
<td>62</td>
</tr>
<tr>
<td>Time</td>
<td>27</td>
<td>11</td>
<td>13</td>
<td>13</td>
<td>11</td>
<td>14</td>
<td>19</td>
<td>9</td>
<td>16</td>
<td>18</td>
<td>8</td>
<td>15</td>
<td>18</td>
<td>6</td>
<td>11</td>
<td>13</td>
</tr>
<tr>
<td>Mockito</td>
<td>38</td>
<td>13</td>
<td>14</td>
<td>14</td>
<td>17</td>
<td>24</td>
<td>26</td>
<td>9</td>
<td>15</td>
<td>21</td>
<td>7</td>
<td>18</td>
<td>22</td>
<td>7</td>
<td>14</td>
<td>18</td>
</tr>
<tr>
<td>Closure</td>
<td>133</td>
<td>24</td>
<td>33</td>
<td>35</td>
<td>47</td>
<td>70</td>
<td>81</td>
<td>64</td>
<td>86</td>
<td>97</td>
<td>42</td>
<td>66</td>
<td>77</td>
<td>14</td>
<td>30</td>
<td>38</td>
</tr>
<tr>
<td>Overall</td>
<td>395</td>
<td>157</td>
<td>183</td>
<td>187</td>
<td>192</td>
<td>260</td>
<td>294</td>
<td>176</td>
<td>256</td>
<td>293</td>
<td>160</td>
<td>249</td>
<td>271</td>
<td>80</td>
<td>165</td>
<td>196</td>
</tr>
<tr>
<td>w/o Closure</td>
<td>262</td>
<td>133</td>
<td>150</td>
<td>152</td>
<td>145</td>
<td>190</td>
<td>213</td>
<td>112</td>
<td>170</td>
<td>196</td>
<td>118</td>
<td>183</td>
<td>194</td>
<td>66</td>
<td>135</td>
<td>158</td>
</tr>
</tbody>
</table>
<p>TABLE IV: Results on Defects4J-V2.0.0.</p>
<table>
<thead>
<tr>
<th>Project</th>
<th># Bugs</th>
<th>Techniques</th>
<th>Top1</th>
<th>Top3</th>
<th>Top5</th>
</tr>
</thead>
<tbody>
<tr>
<td>Overall</td>
<td>226</td>
<td>Ochiai</td>
<td>32</td>
<td>74</td>
<td>93</td>
</tr>
<tr>
<td></td>
<td></td>
<td>FLUCCS</td>
<td>57</td>
<td>97</td>
<td>119</td>
</tr>
<tr>
<td></td>
<td></td>
<td>DeepFL ${ }_{\text {coco }}$</td>
<td>43</td>
<td>89</td>
<td>112</td>
</tr>
<tr>
<td></td>
<td></td>
<td>GRACE</td>
<td>85</td>
<td>119</td>
<td>140</td>
</tr>
<tr>
<td></td>
<td></td>
<td>AGENTFL</td>
<td>78</td>
<td>98</td>
<td>103</td>
</tr>
</tbody>
</table>
<p>is also muted, since the results of the former task participate in the construction of the latter task's prompt.</p>
<p>The performances of the variants of AGENTFL are shown in Table V. We notice that when the Test Failure Analysis task is discarded, the efficacy of AGENTFL decreases sharply, with the number of bugs localized within Top-1 decreasing from 157 to 125 . This indicates that it is a finer choice to offer ChatGPT time to think about the root causes of the test failure and take the analysis result as intermediate data to guide the subsequent localization process. This pattern is more in line with the debugging behavior of developers and shares the idea of chain-of-thought [48]. Similarly, when the Method Doc Enhancement task is removed, the Top-1 result drops significantly from 157 to 133 . While this phenomenon emphasizes the importance of higher quality documentation for AGENTFL to more accurately localize the buggy methods, it also calls on the developers to write better documentation during production, as the human wisdom preserved in documents can conversely support the development and maintenance of software.</p>
<p>Surprisingly, when we abandon the Test Behavior Analysis task, the performance of AGENTFL declines marginally from 157 to 148 on the Top-1 metric. To deeply understand the reasons for this phenomenon, we analyze the characteristics of utility methods corresponding to failed test cases. We find that although each test method calls 4.93 other utility methods on average, these utility methods are generally shared by multiple test methods to handle common operations such as test initialization. This means that the code of the test method may already carry most of the information needed by the ChatGPT to understand the behavior of the test. Nonetheless, the fact of performance gain still emphasizes the potential of other sources of information than just the test code.</p>
<p>Answer to RQ2: The Test Behavior Analysis, Test Failure Analysis, and Method Doc Enhancement tasks are useful to underpin the effectiveness of AGENTFL. The contribution of Test Behavior Analysis appears to be relatively small.</p>
<p>TABLE V: Result of ablation study.</p>
<table>
<thead>
<tr>
<th>Project</th>
<th># Bugs</th>
<th>Techniques</th>
<th>Top1</th>
<th>Top3</th>
<th>Top5</th>
</tr>
</thead>
<tbody>
<tr>
<td>Overall</td>
<td>395</td>
<td>w/o TestBehaviorAnalysis</td>
<td>148</td>
<td>174</td>
<td>175</td>
</tr>
<tr>
<td></td>
<td></td>
<td>w/o TestFailureAnalysis</td>
<td>125</td>
<td>148</td>
<td>152</td>
</tr>
<tr>
<td></td>
<td></td>
<td>w/o MethodDocEnhancement</td>
<td>133</td>
<td>156</td>
<td>160</td>
</tr>
<tr>
<td></td>
<td></td>
<td>AGENTFL</td>
<td>157</td>
<td>183</td>
<td>187</td>
</tr>
</tbody>
</table>
<p>C. RQ3: User study</p>
<p>In this RQ, we intend to evaluate to what extent can AGENTFL help developers localize bugs in practice. Kochhar et al. [49] found that $85 \%$ of the practitioners strongly agreed that the ability to provide rationale is important, with one of the respondents stating "because to make a decision about bug fixing I want to exactly know why the automated tool 'thinks' that the code has a bug". Therefore, merely relying on the Top-N metric may not be enough to reflect the usability of AGENTFL, since it not only lists the suspicious methods but also provides the user with additional natural language interpretations. To investigate the usability of AGENTFL, we re-evaluate AGENTFL through the following user study: (1) Participant Selection. We recruited five Ph.D. students each of whom has more than five years of programming experience and does not know about the Defects4J benchmark before; (2) Data Preparation. By excluding 98 out of 395 bugs where AGENTFL did not find any suspicious methods, we constructed 297 bug-suggestion pairs. The suggestion for each bug contains the top-3 suspicious methods and the corresponding rationales generated by AGENTFL; (3) Localization Procedure. We ask each participant to localize the buggy method from the codebase with the test failure information (including failed tests, error stack traces, and test outputs) and the suggestions provided by AGENTFL. The participants are allowed to use web searches if they are not familiar with any program logic. Given that the previous study shows that a practitioner usually takes about 11 minutes to localize a bug with an FL tool [50], we set the time limit to 15 minutes, providing the users with sufficient time to finish the task; (4) Results Collection. Finally, for each bug-suggestion pair, we regard AGENTFL as helpful if the user successfully localizes the buggy method within the specified time.</p>
<p>The result of our user study is shown in Figure 7, from which we observe that with the help of AGENTFL, developers can consistently localize more bugs in all the projects compared with the vanilla AGENTFL. Two most significant breakthroughs occur in projects Math and Closure, where the numbers of localized bugs in terms of the Top-1 (Top-3) results are improved by 19 (8) and 29 (20), respectively. To understand why participants achieved better localization results, we</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 7: Evaluation results of RQ3.
further investigate the cases where AGENTFL failed to suggest the buggy method at the top position. The statistics show that in more than $80 \%$ of the cases, the number of incorrect predictions (i.e., non-buggy methods that are ranked before buggy methods) produced by AGENTFL does not exceed 3, thus bringing less distraction to the users. Such results indicate that the explanations produced by AGENTFL could provide additional fault-related information for the developers and help them better finish the fault localization task, demonstrating the potential usability of AGENTFL in practice.</p>
<p>To help further understand the usability of AGENTFL in practice, we demonstrate two cases in Figure 8. In the first case, AGENTFL successfully understands the root cause of the bug Lang-42 (i.e., "did not escape the high unicode character correctly"). However, although the method escapeHtml has been mentioned in the bug report, the developer eventually modified its callee method escape (i.e., the method called by escapeHtml to handle with more specific character escaping logic) to fix the bug. Similarly, in the second case, AGENTFL still failed to localize the buggy method, but it correctly interpreted the root cause of the bug Closure-1 and suggested the users to investigate the method interpretAssigns, which is exactly the caller of the buggy method. As shown in the figure, the incorrect removal of unused variables happens in the method removeUnreferencedFunctionArgs, making it the buggy location. For both cases, AGENTFL provides reasonable explanations despite its prediction (i.e., the caller methods of the buggy methods) is not exactly precise, which allows the user to "find the error location with a little extra work" (one participant left such a comment).</p>
<p>Answer to RQ3: AGENTFL exhibits relatively high usability in practice with its few incorrect predictions and the provision of rationale.</p>
<h2>VI. DISCUSSION</h2>
<h2>A. Cost Analysis</h2>
<p>We assessed the performance of AGENTFL on the oftenconcerned issues of prices and time consumption. The results are demonstrated in Figure 9, where each sample is marked with an orange dot. For runtime, we record the seconds required for AGENTFL to completely deal with each bug, including test runs, program analysis, and ChatGPT inference. For cost, we calculate how many dollars AGENTFL needs to localize each bug by multiplying the total number of consumed
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Fig. 8: Two use cases for bug Lang-42 and Closure-1.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Fig. 9: Cost analysis results.
tokens with the model price ( 0.003 dollar per thousand tokens). We observe that AGENTFL offers affordable cost in terms of time and money, which only takes an average of 0.074 dollars and 97 seconds to localize a fault. In over $95 \%$ cases, the cost per bug would not exceed 0.2 dollars and 200 seconds. Such a low expense is expected to mitigate the expensive costs that developers spend on FL.</p>
<h2>B. Threats to Validity</h2>
<p>Internal. The main internal threat comes from the data leakage problem. As the training data of the gpt-3.5-turbo$16 k$-0613 model is up to Sep 2021 while Defects4J-V1.2.0 is released in Feb 2018, the fault localization dataset may have been used for model training. We mitigate this threat by making sure that the input to ChatGPT does not include any content related to the project name, human-written bug report, or bug ID. Moreover, the poor performance of the default ChatGPT (i.e., the baseline ChatGPT ${ }_{\text {Ochini }}$ ) also indicates that ChatGPT has not simply memorized the answer, while the significant improvement of AGENTFL (compared to the default ChatGPT) shows the effectiveness of our approach.</p>
<p>External. The main external threat to validity comes from our evaluation benchmark. The results obtained by AGENTFL may not generalize to other benchmarks. To address this, we evaluate AGENTFL not only on the Defects4J-V1.2.0 benchmark but also on Defects4J-V2.0.0 to demonstrate the generalizability.</p>
<h2>VII. CONCLUSION</h2>
<p>In this paper, we introduce AGENTFL, a multi-agent system based on ChatGPT for automated LLM-based FL. Inspired by the human debugging actions, AGENTFL breaks the localization process into three steps (Fault Comprehension, Codebase Navigation, and Fault Confirmation), and hires several agents in each step to handle specific tasks. The evaluation results on the Defects4J-V1.2.0 benchmark show that AGENTFL outperforms other LLM-based approaches and can be used complementarily to the existing learning-based techniques. A user study also demonstrates the potential of AGENTFL in helping developers localize real-world software bugs. Finally, the cost analysis shows that AGENTFL takes only an average of 0.074 dollars and 97 seconds to localize 157 out of 395 bugs within Top-1.</p>
<h2>REFERENCES</h2>
<p>[1] A. Alaboudi and T. D. LaToza, "An exploratory study of debugging episodes," arXiv:2105.02162 [cs.SE], 2021.
[2] R. Abreu, P. Zoeteweij, and A. J. van Gemund, "Spectrum-based multiple fault localization," in 2009 IEEE/ACM International Conference on Automated Software Engineering, 2009, pp. 88-99.
[3] M. Raselimo and B. Fischer, "Spectrum-based fault localization for context-free grammars," in Proceedings of the 12th ACM SIGPLAN International Conference on Software Language Engineering, ser. SLE 2019. New York, NY, USA: Association for Computing Machinery, 2019, p. 15-28.
[4] S. Reis, R. Abreu, and M. D'Amorim, "Demystifying the combination of dynamic slicing and spectrum-based fault localization," in Proceedings of the 28th International Joint Conference on Artificial Intelligence, ser. IICAI'19. AAAI Press, 2019, p. 4760-4766.
[5] W. E. Wong, V. Debroy, R. Gao, and Y. Li, "The dstar method for effective software fault localization," IEEE Transactions on Reliability, vol. 63, no. 1, pp. 290-308, 2014.
[6] L. Zhang, M. Kim, and S. Khurshid, "Localizing failure-inducing program edits based on spectrum information," in 2011 27th IEEE International Conference on Software Maintenance (ICSM), 2011, pp. $23-32$.
[7] W. Zheng, D. Hu, and J. Wang, "Fault Localization Analysis Based on Deep Neural Network," Mathematical Problems in Engineering, vol. 2016, pp. 1-11, April 2016.
[8] J. Sohn and S. Yoo, "Fluccs: Using code and change metrics to improve fault localization," in Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis, ser. ISSTA 2017. New York, NY, USA: Association for Computing Machinery, 2017, p. 273-283.
[9] Z. Zhang, Y. Lei, X. Mao, and P. Li, "Cnn-fl: An effective approach for localizing faults using convolutional neural networks," in 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, 2019, pp. 445-455.
[10] X. Li, W. Li, Y. Zhang, and L. Zhang, "Deepfl: Integrating multiple fault diagnosis dimensions for deep fault localization," in Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, 2019, pp. 169-180.
[11] Y. Lou, Q. Zhu, J. Dong, X. Li, Z. Sun, D. Hao, L. Zhang, and L. Zhang, "Boosting coverage-based fault localization via graph-based representation learning," in Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ser. ESEC/FSE 2021. New York, NY, USA: Association for Computing Machinery, 2021, p. 664-676.
[12] X. Pu, M. Gao, and X. Wan, "Summarization is (almost) dead," arXiv:2309.09558 [cs.CL], 2023.
[13] J. Li, S. Tworkowski, Y. Wu, and R. Mooney, "Explaining competitivelevel programming solutions using llms," in The 61st Annual Meeting Of The Association For Computational Linguistics, 2023.
[14] Z. Yuan, J. Liu, Q. Zi, M. Liu, X. Peng, and Y. Lou, "Evaluating instruction-tuned large language models on code comprehension and generation," arXiv preprint arXiv:2308.01240, 2023.
[15] Y. Wu, Z. Li, J. M. Zhang, M. Papadakis, M. Harman, and Y. Liu, "Large language models in fault localisation," arXiv:2308.15276 [cs.SE], 2023.
[16] A. H. Yang, R. Martins, C. L. Goues, and V. J. Hellendoorn, "Large language models for test-free fault localization," in 2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE). Los Alamitos, CA, USA: IEEE Computer Society, Apr 2024, pp. 154-165.
[17] N. F. Liu, K. Lin, J. Hewitt, A. Paranjape, M. Bevilacqua, F. Petroni, and P. Liang, "Lost in the Middle: How Language Models Use Long Contexts," Transactions of the Association for Computational Linguistics, vol. 12, pp. 157-173, 022024.
[18] M. Böhme, E. O. Soremekun, S. Chattopadhyay, E. Ugherughe, and A. Zeller, "Where is the bug and how is it fixed? an experiment with practitioners," in Proceedings of the 11th Joint Meeting on Foundations of Software Engineering. ACM, 2017, pp. 117-128.
[19] R. Just, D. Jalali, and M. D. Ernst, "Defects4J: A database of existing faults to enable controlled testing studies for java programs," in Proceedings of the 23rd International Symposium on Software Testing and Analysis. ACM, 2014, pp. 437-440.
[20] R. Abreu, P. Zoeteweij, and A. J. Van Gemund, "An evaluation of similarity coefficients for software fault localization," in 2006 12th Pacific Rim International Symposium on Dependable Computing (PRDC'06), 2006, pp. 39-46.
[21] W. E. Wong, V. Debroy, R. Gao, and Y. Li, "The dstar method for effective software fault localization," IEEE Transactions on Reliability, vol. 63, no. 1, pp. 290-308, 2013.
[22] R. Abreu, P. Zoeteweij, and A. J. Van Gemund, "On the accuracy of spectrum-based fault localization," in Testing: Academic and Industrial Conference Practice and Research Techniques-MUTATION. IEEE, 2007, pp. 89-98.
[23] M. Tomáš, K. Martin, B. Lukáš, C. Jan, and K. Sanjeev, "Recurrent neural network based language model," Interspeech 2010, p. 1045, 09 2010.
[24] M.-C. Popescu, V. E. Balas, L. Perescu-Popescu, and N. Mastorakis, "Multilayer perceptron and neural networks," WSEAS Trans. Cir. and Sys., vol. 8, no. 7, p. 579-588, jul 2009.
[25] Y. Li, R. Zemel, M. Brockschmidt, and D. Tarlow, "Gated graph sequence neural networks," in Proceedings of ICLR'16, April 2016.
[26] X. Li and L. Zhang, "Transforming programs and tests in tandem for fault localization," Proc. ACM Program. Lang., vol. 1, no. OOPSLA, oct 2017.
[27] D. Zou, J. Liang, Y. Xiong, M. D. Ernst, and L. Zhang, "An empirical study of fault localization families and their combinations," IEEE Transactions on Software Engineering, vol. 47, no. 2, pp. 332-347, 2021.
[28] J. Qian, X. Ju, and X. Chen, "Gnet4fl: Effective fault localization via graph convolutional neural network," Automated Software Engg., vol. 30, no. 2, apr 2023.
[29] "Openai," https://openai.com/, 2024.
[30] "Phind," https://www.phind.com/, 2024.
[31] E. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang, Y. Zhou, S. Savarese, and C. Xiong, "Codegen: An open large language model for code with multi-turn program synthesis," in The Eleventh International Conference on Learning Representations, 2023.
[32] R. Li, L. B. allal, Y. Zi, N. Muennighoff, D. Kocetkov, C. Mou, M. Marone, C. Akiki, J. LI, J. Chim, Q. Liu, E. Zheltonozhskii, T. Y. Zhuo, T. Wang, O. Dehaene, J. Lamy-Poirier, J. Monteiro, N. Gontier, M.-H. Yee, L. K. Umapathi, J. Zhu, B. Lipkin, M. Oblokulov, Z. Wang, R. Murthy, J. T. Stillerman, S. S. Patel, D. Abulkhanov, M. Zocca, M. Dey, Z. Zhang, U. Bhattacharyya, W. Yu, S. Luccioni, P. Villegas, F. Zhdanov, T. Lee, N. Timor, J. Ding, C. S. Schlesinger, H. Schoelkopf, J. Ebert, T. Dao, M. Mishra, A. Gu, C. J. Anderson, B. Dolan-Gavitt, D. Contractor, S. Reddy, D. Fried, D. Bahdanau, Y. Jernite, C. M. Ferrandis, S. Hughes, T. Wolf, A. Guha, L. V. Werra, and H. de Vries, "Starcoder: may the source be with you!" Transactions on Machine Learning Research, 2023, reproducibility Certification.
[33] W. Zhou, Y. E. Jiang, P. Cui, T. Wang, Z. Xiao, Y. Hou, R. Cotterell, and M. Sachan, "Recurrentgpt: Interactive generation of (arbitrarily) long text," arXiv:2305.13304 [cs.CL], 2023.
[34] S. G. Patil, T. Zhang, X. Wang, and J. E. Gonzalez, "Gorilla: Large language model connected with massive apis," arXiv:2305.15334 [cs.CL], 2023.
[35] G. Li, H. Hammoud, H. Itani, D. Khizbullin, and B. Ghanem, "Camel: Communicative agents for "mind" exploration of large language model society," in Advances in Neural Information Processing Systems, A. Oh,</p>
<p>T. Neumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds., vol. 36. Curran Associates, Inc., 2023, pp. 51991-52008.
[36] J. S. Park, J. O’Brien, C. J. Cai, M. R. Morris, P. Liang, and M. S. Bernstein, "Generative agents: Interactive simulacra of human behavior," in Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology, ser. UIST '23. New York, NY, USA: Association for Computing Machinery, 2023.
[37] I. Gur, H. Furuta, A. V. Huang, M. Safdari, Y. Matsuo, D. Eck, and A. Faust, "A real-world webagent with planning, long context understanding, and program synthesis," in The Twelfth International Conference on Learning Representations, 2024.
[38] "Autogpt," https://github.com/Significant-Gravitas/AutoGPT, 2024.
[39] "Babyagi," https://github.com/yoheinakajima/babyagi, 2024.
[40] S. Hong, M. Zhuge, J. Chen, X. Zheng, Y. Cheng, J. Wang, C. Zhang, Z. Wang, S. K. S. Yau, Z. Lin, L. Zhou, C. Ran, L. Xiao, C. Wu, and J. Schmidhuber, "MetaGPT: Meta programming for multi-agent collaborative framework," in The Twelfth International Conference on Learning Representations, 2024.
[41] C. Qian, X. Cong, W. Liu, C. Yang, W. Chen, Y. Su, Y. Dang, J. Li, J. Xu, D. Li, Z. Liu, and M. Sun, "Communicative agents for software development," arXiv:2307.07924 [cs.SE], 2023.
[42] W. Zhou, Y. E. Jiang, L. Li, J. Wu, T. Wang, S. Qiu, J. Zhang, J. Chen, R. Wu, S. Wang, S. Zhu, J. Chen, W. Zhang, X. Tang, N. Zhang, H. Chen, P. Cui, and M. Sachan, "Agents: An open-source framework for autonomous language agents," arXiv:2309.07870 [cs.CL], 2023.
[43] Y. Zhang, Y. Li, L. Cui, D. Cai, L. Liu, T. Fu, X. Huang, E. Zhao, Y. Zhang, Y. Chen et al., "Siren's song in the ai ocean: a survey
on hallucination in large language models," arXiv:2309.01219 [cs.CL], 2023.
[44] K. Yang, X. Mao, S. Wang, T. Zhang, B. Lin, Y. Wang, Y. Qin, Z. Zhang, and X. Mao, "Enhancing code intelligence tasks with chatgpt," arXiv:2312.15202 [cs.SE], 2023.
[45] "java.lang.instrument," https://docs.oracle.com/javase/8/docs/api/java/ lang/instrument/package-summary.html, 2024.
[46] "tree-sitter," https://tree-sitter.github.io/tree-sitter/, 2024.
[47] Z. Qin, R. Jagerman, K. Hui, H. Zhuang, J. Wu, J. Shen, T. Liu, J. Liu, D. Metzler, X. Wang, and M. Bendersky, "Large language models are effective text rankers with pairwise ranking prompting," arXiv:2306.17563 [cs.IR], 2023.
[48] J. Wei, X. Wang, D. Schuurmans, M. Bosma, b. ichter, F. Xia, E. Chi, Q. V. Le, and D. Zhou, "Chain-of-thought prompting elicits reasoning in large language models," in Advances in Neural Information Processing Systems, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, Eds., vol. 35. Curran Associates, Inc., 2022, pp. 24824-24837.
[49] P. S. Kochhar, X. Xia, D. Lo, and S. Li, "Practitioners' expectations on automated fault localization," in Proceedings of the 25th International Symposium on Software Testing and Analysis, ser. ISSTA 2016. New York, NY, USA: Association for Computing Machinery, 2016, p. $165-176$.
[50] X. Xia, L. Bao, D. Lo, and S. Li, "'automated debugging considered harmful' considered harmful: A user study revisiting the usefulness of spectra-based fault localization techniques with professionals using real bugs from large systems," in 2016 IEEE International Conference on Software Maintenance and Evolution (ICSME), 2016, pp. 267-278.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<ul>
<li>Our work has been accepted by Transactions on Software Engineering (TSE) in 2025. For the latest version, please refer to "SOAPFL: A Standard Operating Procedure for LLM-based Method-Level Fault Localization".</li>
</ul>
<p><a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>