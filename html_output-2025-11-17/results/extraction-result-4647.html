<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4647 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4647</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4647</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-103.html">extraction-schema-103</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <p><strong>Paper ID:</strong> paper-267499950</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2402.03578v2.pdf" target="_blank">LLM Multi-Agent Systems: Challenges and Open Problems</a></p>
                <p><strong>Paper Abstract:</strong> This paper explores multi-agent systems and identify challenges that remain inadequately addressed. By leveraging the diverse capabilities and roles of individual agents, multi-agent systems can tackle complex tasks through agent collaboration. We discuss optimizing task allocation, fostering robust reasoning through iterative debates, managing complex and layered context information, and enhancing memory management to support the intricate interactions within multi-agent systems. We also explore potential applications of multi-agent systems in blockchain systems to shed light on their future development and application in real-world distributed systems.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4647.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4647.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval-Augmented Generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A paradigm that augments LLM inference with an external retrieval step (vector store) to ground responses in retrieved documents, improving factuality and knowledge access for knowledge-intensive tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Retrieval-augmented generation for knowledgeintensive nlp tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>RAG (Retrieval-Augmented Generation)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An LLM pipeline that issues a retrieval query to an external vector database and conditions generation on retrieved passages to ground answers; used broadly as a mechanism to extend model knowledge beyond weights.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external data storage / vector database (retrieval-augmented)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Stores documents or past interactions as vector embeddings in a datastore; at query time relevant vectors are retrieved and concatenated/used as context for the LLM to produce grounded outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>knowledge-intensive question answering / grounding</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks that require up-to-date or factual knowledge beyond the model's parametric memory; retrieval supplies relevant external text to support generation.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Paper cites retrieval-augmented methods as an external-memory approach for grounding LLMs but does not report numerical comparisons within this survey; RAG is described as enabling more informative and accurate responses by leveraging external stores.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>No numeric evaluation reported here; general limitations noted in literature include retrieval errors, stale or irrelevant documents, latency, and integration complexity in multi-agent workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>External vector stores are a primary mechanism to provide long-term memory and grounding for agents; in multi-agent settings they can serve as shared consensus or long-term memory to align agents' outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM Multi-Agent Systems: Challenges and Open Problems', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4647.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4647.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative Agents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system of LLM-driven agents that simulate human-like behavior by maintaining and using episodic memories of observed events to guide future actions and interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Generative Agents (Park et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Multi-agent simulation where each agent records experiences (events, observations) and retrieves relevant episodic memory to decide actions and dialogue in a simulated environment.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic memory (event memory), long-term memory (external storage)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Agents log events and observations into an episodic memory store and retrieve contextually similar events to inform behavior and dialogue; memories serve as persistent records across sessions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>interactive simulation / behavior modeling</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Simulated social interactions and environment-driven behaviors where agents must recall past events to maintain coherent personalities and relationships over time.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Survey notes generative agents as an example where episodic memory improves contextual relevance and consistency of agent behavior; no quantitative ablation provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Challenges include selecting relevant episodic memories, memory scaling as events accumulate, privacy of stored experiences, and ensuring integrity when memories are shared between agents.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Episodic memory is critical in multi-agent simulations for coherence across time; multi-agent systems require strategies for selective recall and memory maintenance to remain tractable and secure.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM Multi-Agent Systems: Challenges and Open Problems', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4647.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4647.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mot</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Memory-of-Thought (MoT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mechanism that records internal reasoning traces or 'thoughts' so the model can revisit and improve its chain-of-thoughts across sessions, enabling self-improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mot: Memory-of-thought enables chatgpt to self-improve.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Memory-of-Thought (MoT)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An approach that stores intermediate reasoning traces or 'thoughts' produced by an LLM (e.g., ChatGPT) so future reasoning can reuse or refine prior internal chains of thought.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic / reasoning trace memory (scratchpad-like long-term storage)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Persists internal intermediate reasoning outputs (scratchpads) across interactions so that subsequent sessions can retrieve and refine previous chains of thought to improve solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>self-improvement of reasoning / multi-step problem solving</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks where internal intermediate reasoning steps are useful to revisit and refine, enabling the model to iteratively improve answer quality over multiple interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Mentioned as an example of leveraging stored reasoning traces to enable self-improvement; this survey does not report quantitative gains or ablations itself.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Issues include how to index and retrieve relevant past reasoning traces, preventing propagation of erroneous reasoning, and storage/selection policies as traces accumulate.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Persisting internal reasoning (scratchpads) across sessions can enable iterative self-improvement, but requires careful retrieval and validation mechanisms to avoid reinforcing mistakes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM Multi-Agent Systems: Challenges and Open Problems', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4647.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4647.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Long-term Memory (Wang et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Augmenting language models with long-term memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced work that augments LLMs with mechanisms for storing and retrieving long-term memories to improve consistency and personalization over extended interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Augmenting language models with long-term memory.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LLM + Long-term Memory (Wang et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Systems that integrate explicit long-term memory modules (often external vector stores) to persist user-specific or session-specific information enabling personalization and consistency.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>long-term memory (external vector DB / persistent store)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Long-lived persistent storage of past interactions or user facts in an external database with retrieval mechanisms that surface relevant memories during later interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>personalization / long-context interactions</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks requiring retention of user preferences, session history, or other persistent facts across multiple sessions to maintain coherent personalization and long-horizon reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Survey cites long-term memory augmentation as important for enabling persistent personalization and improving inferences, but does not provide numerical comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Challenges include privacy and access control for agent-specific sensitive memories, redundancy across agents, and maintaining consistency of shared memories in multi-agent contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Long-term memory stores are necessary for persistent personalization in agents; in multi-agent systems designers must solve access control, deduplication, and consensus issues for shared memories.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM Multi-Agent Systems: Challenges and Open Problems', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4647.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4647.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prompt-Guided Retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prompt-guided retrieval augmentation for non-knowledgeintensive tasks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach that uses prompt-guided retrieval strategies to augment LLMs for tasks that are not strictly knowledge-intensive by retrieving contextually useful snippets to guide generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Promptguided retrieval augmentation for non-knowledgeintensive tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Prompt-Guided Retrieval Augmentation (Guo et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Technique that uses prompts to shape retrieval from external stores so retrieved context better matches the LLM's needs for non-knowledge-intensive generation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external retrieval / vector database with prompt-guided retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Uses a retrieval stage guided by crafted prompts to fetch context from an external store which is then provided to the LLM to improve relevance on generation tasks not dominated by world knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>non-knowledge-intensive generation / retrieval-augmented generation</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Generation tasks where retrieval can nonetheless improve output quality (e.g., stylistic or contextual grounding) though they are not purely fact-based QA.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Described as an example of retrieval augmentation beyond classic knowledge-intensive tasks; no quantitative comparisons are given in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Selecting retrieval prompts and ensuring retrieved context helps rather than distracts; integration into multi-agent pipelines where multiple agents may query shared stores.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Retrieval-augmentation can benefit a broader range of tasks if retrieval is guided to produce context that is directly useful for the LLM's generation objective.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM Multi-Agent Systems: Challenges and Open Problems', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4647.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4647.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CGMI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Configurable General Multi-Agent Interaction framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent interaction framework that employs shared resources such as a skill library (consensus memory) to align agent capabilities and coordinate tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Configurable general multi-agent interaction framework.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>CGMI (Jinxin et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A general multi-agent interaction framework that configures agents with roles and shared artifacts (e.g., skill libraries) to facilitate coordinated multi-agent behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>consensus memory / shared skill library</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Implements a shared memory or skill library that all agents can consult to access common knowledge, capabilities, or standardized procedures for task alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>multi-agent coordination / collaborative tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks requiring agents to coordinate actions and share domain-specific knowledge or skills to complete subtasks coherently within a multi-agent workflow.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Survey highlights consensus memory (e.g., skill libraries) as useful for aligning agents but does not include ablation or numerical comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Maintaining integrity and access control of shared consensus memory, managing overlapping or redundant data, and ensuring updates to shared memory do not introduce inconsistencies.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Consensus/shared memory is crucial for alignment in multi-agent systems; robust access control and maintenance strategies are required to prevent corruption and leakage of sensitive agent-specific data.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM Multi-Agent Systems: Challenges and Open Problems', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Retrieval-augmented generation for knowledgeintensive nlp tasks. <em>(Rating: 2)</em></li>
                <li>Generative agents: Interactive simulacra of human behavior. <em>(Rating: 2)</em></li>
                <li>Mot: Memory-of-thought enables chatgpt to self-improve. <em>(Rating: 2)</em></li>
                <li>Augmenting language models with long-term memory. <em>(Rating: 2)</em></li>
                <li>Promptguided retrieval augmentation for non-knowledgeintensive tasks. <em>(Rating: 2)</em></li>
                <li>Configurable general multi-agent interaction framework. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4647",
    "paper_id": "paper-267499950",
    "extraction_schema_id": "extraction-schema-103",
    "extracted_data": [
        {
            "name_short": "RAG",
            "name_full": "Retrieval-Augmented Generation",
            "brief_description": "A paradigm that augments LLM inference with an external retrieval step (vector store) to ground responses in retrieved documents, improving factuality and knowledge access for knowledge-intensive tasks.",
            "citation_title": "Retrieval-augmented generation for knowledgeintensive nlp tasks.",
            "mention_or_use": "mention",
            "agent_name": "RAG (Retrieval-Augmented Generation)",
            "agent_description": "An LLM pipeline that issues a retrieval query to an external vector database and conditions generation on retrieved passages to ground answers; used broadly as a mechanism to extend model knowledge beyond weights.",
            "memory_type": "external data storage / vector database (retrieval-augmented)",
            "memory_description": "Stores documents or past interactions as vector embeddings in a datastore; at query time relevant vectors are retrieved and concatenated/used as context for the LLM to produce grounded outputs.",
            "task_name": "knowledge-intensive question answering / grounding",
            "task_description": "Tasks that require up-to-date or factual knowledge beyond the model's parametric memory; retrieval supplies relevant external text to support generation.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "Paper cites retrieval-augmented methods as an external-memory approach for grounding LLMs but does not report numerical comparisons within this survey; RAG is described as enabling more informative and accurate responses by leveraging external stores.",
            "limitations_or_challenges": "No numeric evaluation reported here; general limitations noted in literature include retrieval errors, stale or irrelevant documents, latency, and integration complexity in multi-agent workflows.",
            "key_insights": "External vector stores are a primary mechanism to provide long-term memory and grounding for agents; in multi-agent settings they can serve as shared consensus or long-term memory to align agents' outputs.",
            "uuid": "e4647.0",
            "source_info": {
                "paper_title": "LLM Multi-Agent Systems: Challenges and Open Problems",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Generative Agents",
            "name_full": "Generative agents: Interactive simulacra of human behavior",
            "brief_description": "A system of LLM-driven agents that simulate human-like behavior by maintaining and using episodic memories of observed events to guide future actions and interactions.",
            "citation_title": "Generative agents: Interactive simulacra of human behavior.",
            "mention_or_use": "mention",
            "agent_name": "Generative Agents (Park et al., 2023)",
            "agent_description": "Multi-agent simulation where each agent records experiences (events, observations) and retrieves relevant episodic memory to decide actions and dialogue in a simulated environment.",
            "memory_type": "episodic memory (event memory), long-term memory (external storage)",
            "memory_description": "Agents log events and observations into an episodic memory store and retrieve contextually similar events to inform behavior and dialogue; memories serve as persistent records across sessions.",
            "task_name": "interactive simulation / behavior modeling",
            "task_description": "Simulated social interactions and environment-driven behaviors where agents must recall past events to maintain coherent personalities and relationships over time.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "Survey notes generative agents as an example where episodic memory improves contextual relevance and consistency of agent behavior; no quantitative ablation provided in this paper.",
            "limitations_or_challenges": "Challenges include selecting relevant episodic memories, memory scaling as events accumulate, privacy of stored experiences, and ensuring integrity when memories are shared between agents.",
            "key_insights": "Episodic memory is critical in multi-agent simulations for coherence across time; multi-agent systems require strategies for selective recall and memory maintenance to remain tractable and secure.",
            "uuid": "e4647.1",
            "source_info": {
                "paper_title": "LLM Multi-Agent Systems: Challenges and Open Problems",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Mot",
            "name_full": "Memory-of-Thought (MoT)",
            "brief_description": "A mechanism that records internal reasoning traces or 'thoughts' so the model can revisit and improve its chain-of-thoughts across sessions, enabling self-improvement.",
            "citation_title": "Mot: Memory-of-thought enables chatgpt to self-improve.",
            "mention_or_use": "mention",
            "agent_name": "Memory-of-Thought (MoT)",
            "agent_description": "An approach that stores intermediate reasoning traces or 'thoughts' produced by an LLM (e.g., ChatGPT) so future reasoning can reuse or refine prior internal chains of thought.",
            "memory_type": "episodic / reasoning trace memory (scratchpad-like long-term storage)",
            "memory_description": "Persists internal intermediate reasoning outputs (scratchpads) across interactions so that subsequent sessions can retrieve and refine previous chains of thought to improve solutions.",
            "task_name": "self-improvement of reasoning / multi-step problem solving",
            "task_description": "Tasks where internal intermediate reasoning steps are useful to revisit and refine, enabling the model to iteratively improve answer quality over multiple interactions.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "Mentioned as an example of leveraging stored reasoning traces to enable self-improvement; this survey does not report quantitative gains or ablations itself.",
            "limitations_or_challenges": "Issues include how to index and retrieve relevant past reasoning traces, preventing propagation of erroneous reasoning, and storage/selection policies as traces accumulate.",
            "key_insights": "Persisting internal reasoning (scratchpads) across sessions can enable iterative self-improvement, but requires careful retrieval and validation mechanisms to avoid reinforcing mistakes.",
            "uuid": "e4647.2",
            "source_info": {
                "paper_title": "LLM Multi-Agent Systems: Challenges and Open Problems",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Long-term Memory (Wang et al.)",
            "name_full": "Augmenting language models with long-term memory",
            "brief_description": "A referenced work that augments LLMs with mechanisms for storing and retrieving long-term memories to improve consistency and personalization over extended interactions.",
            "citation_title": "Augmenting language models with long-term memory.",
            "mention_or_use": "mention",
            "agent_name": "LLM + Long-term Memory (Wang et al., 2023)",
            "agent_description": "Systems that integrate explicit long-term memory modules (often external vector stores) to persist user-specific or session-specific information enabling personalization and consistency.",
            "memory_type": "long-term memory (external vector DB / persistent store)",
            "memory_description": "Long-lived persistent storage of past interactions or user facts in an external database with retrieval mechanisms that surface relevant memories during later interactions.",
            "task_name": "personalization / long-context interactions",
            "task_description": "Tasks requiring retention of user preferences, session history, or other persistent facts across multiple sessions to maintain coherent personalization and long-horizon reasoning.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "Survey cites long-term memory augmentation as important for enabling persistent personalization and improving inferences, but does not provide numerical comparisons.",
            "limitations_or_challenges": "Challenges include privacy and access control for agent-specific sensitive memories, redundancy across agents, and maintaining consistency of shared memories in multi-agent contexts.",
            "key_insights": "Long-term memory stores are necessary for persistent personalization in agents; in multi-agent systems designers must solve access control, deduplication, and consensus issues for shared memories.",
            "uuid": "e4647.3",
            "source_info": {
                "paper_title": "LLM Multi-Agent Systems: Challenges and Open Problems",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Prompt-Guided Retrieval",
            "name_full": "Prompt-guided retrieval augmentation for non-knowledgeintensive tasks",
            "brief_description": "An approach that uses prompt-guided retrieval strategies to augment LLMs for tasks that are not strictly knowledge-intensive by retrieving contextually useful snippets to guide generation.",
            "citation_title": "Promptguided retrieval augmentation for non-knowledgeintensive tasks.",
            "mention_or_use": "mention",
            "agent_name": "Prompt-Guided Retrieval Augmentation (Guo et al., 2023)",
            "agent_description": "Technique that uses prompts to shape retrieval from external stores so retrieved context better matches the LLM's needs for non-knowledge-intensive generation tasks.",
            "memory_type": "external retrieval / vector database with prompt-guided retrieval",
            "memory_description": "Uses a retrieval stage guided by crafted prompts to fetch context from an external store which is then provided to the LLM to improve relevance on generation tasks not dominated by world knowledge.",
            "task_name": "non-knowledge-intensive generation / retrieval-augmented generation",
            "task_description": "Generation tasks where retrieval can nonetheless improve output quality (e.g., stylistic or contextual grounding) though they are not purely fact-based QA.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "Described as an example of retrieval augmentation beyond classic knowledge-intensive tasks; no quantitative comparisons are given in this survey.",
            "limitations_or_challenges": "Selecting retrieval prompts and ensuring retrieved context helps rather than distracts; integration into multi-agent pipelines where multiple agents may query shared stores.",
            "key_insights": "Retrieval-augmentation can benefit a broader range of tasks if retrieval is guided to produce context that is directly useful for the LLM's generation objective.",
            "uuid": "e4647.4",
            "source_info": {
                "paper_title": "LLM Multi-Agent Systems: Challenges and Open Problems",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "CGMI",
            "name_full": "Configurable General Multi-Agent Interaction framework",
            "brief_description": "A multi-agent interaction framework that employs shared resources such as a skill library (consensus memory) to align agent capabilities and coordinate tasks.",
            "citation_title": "Configurable general multi-agent interaction framework.",
            "mention_or_use": "mention",
            "agent_name": "CGMI (Jinxin et al., 2023)",
            "agent_description": "A general multi-agent interaction framework that configures agents with roles and shared artifacts (e.g., skill libraries) to facilitate coordinated multi-agent behavior.",
            "memory_type": "consensus memory / shared skill library",
            "memory_description": "Implements a shared memory or skill library that all agents can consult to access common knowledge, capabilities, or standardized procedures for task alignment.",
            "task_name": "multi-agent coordination / collaborative tasks",
            "task_description": "Tasks requiring agents to coordinate actions and share domain-specific knowledge or skills to complete subtasks coherently within a multi-agent workflow.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "Survey highlights consensus memory (e.g., skill libraries) as useful for aligning agents but does not include ablation or numerical comparisons.",
            "limitations_or_challenges": "Maintaining integrity and access control of shared consensus memory, managing overlapping or redundant data, and ensuring updates to shared memory do not introduce inconsistencies.",
            "key_insights": "Consensus/shared memory is crucial for alignment in multi-agent systems; robust access control and maintenance strategies are required to prevent corruption and leakage of sensitive agent-specific data.",
            "uuid": "e4647.5",
            "source_info": {
                "paper_title": "LLM Multi-Agent Systems: Challenges and Open Problems",
                "publication_date_yy_mm": "2024-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Retrieval-augmented generation for knowledgeintensive nlp tasks.",
            "rating": 2,
            "sanitized_title": "retrievalaugmented_generation_for_knowledgeintensive_nlp_tasks"
        },
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior.",
            "rating": 2,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        },
        {
            "paper_title": "Mot: Memory-of-thought enables chatgpt to self-improve.",
            "rating": 2,
            "sanitized_title": "mot_memoryofthought_enables_chatgpt_to_selfimprove"
        },
        {
            "paper_title": "Augmenting language models with long-term memory.",
            "rating": 2,
            "sanitized_title": "augmenting_language_models_with_longterm_memory"
        },
        {
            "paper_title": "Promptguided retrieval augmentation for non-knowledgeintensive tasks.",
            "rating": 2,
            "sanitized_title": "promptguided_retrieval_augmentation_for_nonknowledgeintensive_tasks"
        },
        {
            "paper_title": "Configurable general multi-agent interaction framework.",
            "rating": 2,
            "sanitized_title": "configurable_general_multiagent_interaction_framework"
        }
    ],
    "cost": 0.0102285,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LLM Multi-Agent Systems: Challenges and Open Problems
12 May 2025</p>
<p>Shanshan Han 
Qifan Zhang 
Yuhang Yao 
Weizhao Jin 
Zhaozhuo Xu 
LLM Multi-Agent Systems: Challenges and Open Problems
12 May 20251EF720C3A98962BEA24A15FE7E3E02EDarXiv:2402.03578v2[cs.MA]
This paper explores multi-agent systems and identify challenges that remain inadequately addressed.By leveraging the diverse capabilities and roles of individual agents, multi-agent systems can tackle complex tasks through agent collaboration.We discuss optimizing task allocation, fostering robust reasoning through iterative debates, managing complex and layered context information, and enhancing memory management to support the intricate interactions within multiagent systems.We also explore potential applications of multi-agent systems in blockchain systems to shed light on their future development and application in real-world distributed systems.</p>
<p>Introduction</p>
<p>Multi-agent systems enhance the capabilities of single LLM agents by leveraging collaborations among agents and their specialized abilities (Talebirad &amp; Nadiri, 2023;Zhang et al., 2023a;Park et al., 2023;Li et al., 2023;Jinxin et al., 2023).It utilizing collaboration and coordination among agents to execute tasks that are beyond the capability of any individual agent.In multi-agent systems, each agent is equipped with distinctive capabilities and roles, collaborating towards the fulfillment of some common objectives.Such collaboration, characterized by activities such as debate and reflection, has proven particularly effective for tasks requiring deep thought and innovation.Recent works include simulating interactive environments (Park et al., 2023;Jinxin et al., 2023), roleplaying (Li et al., 2023), reasoning (Du et al., 2023;Liang et al., 2023), demonstrating the huge potential of multi-agent systems in handling complex real-world scenarios.</p>
<p>While existing works have demonstrated the impressive capabilities of multi-agent systems, the potential for advanced multi-agent systems far exceeds the progress made to date.</p>
<p>A large number of existing works focus on devising planning strategies within a single agent by breaking down the tasks into smaller, more manageable tasks (Chen et al., 2022;Ziqi &amp; Lu, 2023;Yao et al., 2023;Long, 2023;Besta et al., 2023;Wang et al., 2022b).Yet, multi-agent systems involve agents of various specializations and more complex interactions and layered context information, which poses challenges to the designing of the work flow as well as the whole system.Also, existing literature pays limited attention to memory storage, while memory plays a critical role in collaborations between agents.It enables agents to access to some common sense, aligning context with their tasks, and further, learn from past work flows and adapt their strategies accordingly.</p>
<p>To date, multiple significant challenges that differentiate multi-agent systems and single-agent systems remain inadequately addressed.We summarize them as follows.</p>
<p> Optimizing task allocation to leverage agents' unique skills and specializations.</p>
<p> Fostering robust reasoning through iterative debates or discussions among a subset of agents to enhance intermediate results.</p>
<p> Managing complex and layered context information, such as context for overall tasks, single agents, and some common knowledge between agents, while ensuring alignment to the general objective.</p>
<p> Managing various types of memory that serve for different objectives in coherent to the interactions in multiagent systems</p>
<p>This paper explores multi-agent systems, offering a survey of the existing works while shedding light on the challenges and open problems in it.We study major components in multi-agent systems, including planning and memory storage, and address unique challenges posed by multiagent systems, compared with single-agent systems.We also explore potential application of multi-agent systems in blockchain systems from two perspectives, including 1) utilizing multi-agent systems as tools, and 2) assigning an agent to each blockchain node to make it represent the user, such that the agent can can complete some tasks on behalf of the user in the blockchain network.</p>
<p>Overview</p>
<p>Structure of Multi-agent Systems</p>
<p>The structure of multi-agent systems can be categorized into various types, based on the each agent's functionality and their interactions.</p>
<p>Equi-Level Structure.LLM agents in an equi-level system operate at the same hierarchical level, where each agent has its role and strategy, but neither holds a hierarchical advantage over the other, e.g., DMAS (Chen et al., 2023); see Figure 1(a).The agents in such systems can have same, neutral, or opposing objectives.Agents with same goals collaborate towards a common goal without a centralized leadership.The emphasis is on collective decision-making and shared responsibilities (Li et al., 2019).With opposing objectives, the agents negotiate or debate to convince the others or achieve some final solutions (Terekhov et al., 2023;Du et al., 2023;Liang et al., 2023;Chan et al., 2023).</p>
<p>Hierarchical Structure.Hierarchical structures (Gronauer &amp; Diepold, 2022;Ahilan &amp; Dayan, 2019) 2006) fall into this category (Harris et al., 2023).This type of game is distinguished by this leadership-followership dynamic and the sequential nature of decision-making.Agents make decisions in a sequential order, where the leader player first generate an output (e.g., instructions) then the follower players take an action based on the leader's instruction.</p>
<p>Nested Structure.Nested structures, or hybrid structures, constitute sub-structures of equi-level structures and/or hierarchical structures in a same multi-agent system (Chan et al., 2023); see Figure 1(c).The "big picture" of the system can be either equi-level or hierarchical, however, as some agents have to handle complex tasks, they break down the tasks into small ones and construct a sub-system, either equi-level or hierarchical, and "invite" several agents to help with those tasks.In such systems, the interplay between different levels of hierarchy and peer-to-peer interaction contributes to complexity.Also, the interaction among those different structures can lead to intricate dynamics, where strategies and responses become complicated due to the presence of various influencing factors, including external elements like context or environment.</p>
<p>Dynamic Structure.Dynamic structures mean that the states of the multi-agent system, e.g., the role of agents, their relations, and the number of agents in the multi-agent system, may change (Talebirad &amp; Nadiri, 2023) over time.</p>
<p>As an example, (Talebirad &amp; Nadiri, 2023) enables addition and removal of agents to make the system to suit the tasks at hand.A multi-agent system may also be contextually adaptive, with the interaction patterns inside the system being modified based on internal system states or external factors, such as contexts.Agents in such systems can dynamically reconfigure their roles and relationships in response to changing conditions.</p>
<p>Overview of Challenges in Multi-Agent Systems</p>
<p>This paper surveys various components of multi-agent systems and discusses the challenges compared with singleagent systems.We discuss planning, memory management, as well as potential applications of multi-agent systems on distributed systems, e.g., blockchain systems.</p>
<p>Planning.In a single-agent system, planning involves the LLM agent breaking down large tasks into a sequence of small, manageable tasks to achieve specific goals efficiently while enhancing interpretability, controllability, and flexibility (Li et al., 2024;Zhang et al., 2023b;Nye et al., 2021;Wei et al., 2022).The agent can also learn to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), or connect LLMs with websites, software, and tools (Patil et al., 2023;Zhou et al., 2023;Cai et al., 2023) to help reasoning and improve performance.While agents in a multi-agent system have same capabilities with single-agent systems, they encounter challenges inherited from the work flow in multiagent systems.In 3, we discuss partitioning work flow and allocating the sub-tasks to agents; we name this process as "global planning"; see 3.1.We then discuss task decomposition in each single-agent.Different from planning in a single-agent systems, agents in multi-agent systems must deal with more sophisticated contexts to reach alignment inside the multi-agent system, and further, achieve consistency towards the overall objective; see 3.2.</p>
<p>Memory management.Memory management in singleagent systems include short-term memory during a conversation, long-term memory that store historical conversations, and, if any, external data storage that serves as a complementary information source for inferences, e.g., RAG (Lewis et al., 2020).Memory management in multi-agent systems must handle complex context data and sophisticated interaction and history information, thus requires advanced design for memories.We classify the memories involved in multiagent systems in 4.1 and then discuss potential challenges posed by the sophisticated structure of memory in 4.2.</p>
<p>Application.We discuss applications of multi-agent systems in blockchain, a distributed system that involves sophisticated design of layers and applications.Basically, multiagent systems can serve as a tool due to its ability to handle sophisticated tasks in blockchain; see 5.1.Blockchain can also be integrated with multi-agent systems due to their distributed nature, where an intelligent agent can be allocated to an blockchain node to perform sophisticated actions, such as negotiations, on behalf of the agent; see 5.2.</p>
<p>Planning</p>
<p>Planning in multi-agent systems involves understanding the overall tasks and design work flow among agents based on their roles and specializations, (i.e., global planning) and breaking down the tasks for each agent into small manageable tasks (i.e., local planning).Such process must account for functionalities of the agents, dynamic interactions among the agents, as well as a more complex context compared with single-agent systems.This complexity introduces unique challenges and opportunities in the multi-agent systems.</p>
<p>Global Planning</p>
<p>Global planning refers to understanding the overall task and split the task into smaller ones and coordinate the subtasks to the agents.It requires careful consideration of task decomposition and agent coordination.Below we discuss the unique challenges in global planning in multi-agent systems.</p>
<p>Designing effective work flow based on the agents' specializations.Partitioning responsibilities and designing effective work flows for agents is crucial for ensuring that the tasks for each agent are executable while meaningful and directly contributes to the overall objective in systems.</p>
<p>The biggest challenge lies in the following perspectives: 1) the partition of work flow should maximize the utilization of each agent's unique capabilities, i.e., each agent can handle a part of the task that matches its capabilities and expertise; 2) each agent's tasks must align with the overall goal; and 3) the design must understand and consider the context for the overall tasks as well as each agent.This requires a deep understanding of the task at hand and the specific strengths and limitations of each agent in the system.</p>
<p>Introducing loops for a subset of agents to enhance intermediate results.Multi-agent systems can be integrated with loops inside one or multiple subsets of agents to improve the quality of the intermediate results, or, local optimal answers.In such loops, agents debate or discuss to achieve an optimal results that are accepted by the agents in the loop.The iterative process can refine the intermediate results, leading to a deeper exploration of the task.</p>
<p>The agents in the loop can adjust their reasoning process and plans during the loop, thus have better capabilities in handling uncertainties of the task.</p>
<p>Game Theory.Game theory provides a well-structured framework for understanding strategic interactions in multiagent systems, particularly for systems that involve complex interactions among agents such as debates or discussions.A crucial concept in game theory is equilibrium, e.g., Nash Equilibrium (Kreps, 1989) and Stackelberg Equilibrium (Von Stackelberg, 2010;Conitzer &amp; Sandholm, 2006), that describes a state where, given the strategies of others, no agent benefits from unilaterally changing their strategy.Game theory has been applied in multi-agent systems, especially Stackelberg equilibrium (Gerstgrasser &amp; Parkes, 2023;Harris et al., 2023), as the structure of Stackelberg equilibrium contains is a leader agent and multiple follower agents, and such hierarchical architectures are wildely considered in multi-agent systems.(Gerstgrasser &amp; Parkes, 2023) designs a general multi-agent framework to identify Stackelberg Equilibrium in Markov games, and (Harris et al., 2023) extend the Stackelberg model to allow agents to consider external context information, such as traffic and weather, etc.However, some problems are still challenging in multi-agent systems, such as defining an appropriate payoff structure for both the collective strategy and individual agents based on the context of the overall tasks, and efficiently achieving equilibrium states.These unresolved issues highlight the ongoing need for refinement in the application of game theory to complex multi-agent scenarios.</p>
<p>Single-Agent Task Decomposition</p>
<p>Task decomposition in a single agent involves generating a series of intermediate reasoning steps to complete a task or arrive at an answer.This process can be represented as transforming direct input-output (input  output) mappings into the input  rational  output mappings (Wei et al., 2022;Zhang et al., 2023b).Task composition can be of different formats, as follows.</p>
<p>i) Chain of Thoughts (CoT) (Wei et al., 2022) that transforms big tasks into step-by-step manageable tasks to represent interpretation of the agents' reasoning (or thinking) process.</p>
<p>ii) Multiple CoTs (Wang et al., 2022a) that explores multiple independent CoT reasoning paths and return the one with the best output.</p>
<p>iii) Program-of-Thoughts (PoT) (Chen et al., 2022) that uses language models to generate text and programming language statements, and finally an answer.</p>
<p>iv) Table-of-Thoughts (Tab-CoT) (Ziqi &amp; Lu, 2023) that utilize a tabular-format for reasoning, enabling the complex reasoning process to be explicitly modelled in a highly structured manner.</p>
<p>v) Tree-of-Thoughts (ToT) (Yao et al., 2023;Long, 2023) that extends CoT by formulating a tree structure to explore multiple reasoning possibilities at each step.It enables generating new thoughts based on a given arbitrary thought and possibly backtracking from it.</p>
<p>vi) Graph-of-Thoughts-Rationale (GoT-Rationale) (Besta et al., 2023) that explores an arbitrary graph to enable aggregating arbitrary thoughts into a new one and enhancing the thoughts using loops.</p>
<p>vii) Rationale-Augmented Ensembles (Wang et al., 2022b) that automatically aggregate across diverse rationales to overcome the brittleness of performance to sub-optimal rationales.</p>
<p>In multi-agent systems, task decomposition for a single agent becomes more intricate.Each agent must understand layered and sophisticated context, including 1) the overall tasks, 2) the specific context of the agent's individual tasks, and 3) the contextual information provided by other agents in the multi-agent system.Moreover, the agents must align these complex, multi-dimensional contexts into their decomposed tasks to ensure coherent and effective functioning within the overall task.We summarize the challenges for single agent planning as follows.</p>
<p>Aligning Overall Context.Alignment of goals among different agents is crucial in multi-agent systems.Each LLM agent must have a clear understanding of its role and how it fits into the overall task, such that the agents can perform their functions effectively.Beyond individual roles, agents need to recognize how their tasks fit into the bigger picture, such that their outputs can harmonize with the outputs of other agents, and, further, ensuring all efforts are directed towards the common goal.</p>
<p>Aligning Context Between Agents.Agents in multiagent systems process tasks collectively, and each agent must understand and integrate the contextual information provided by other agents within the system to ensure that the information provided by other agents is fully utilized.</p>
<p>Aligning Context for Decomposed Tasks.When tasks of each agents are broken down into smaller, more manageable sub-tasks, aligning the complex context in multi-agent systems becomes challenging.Each agent's decomposed task must fit their individual tasks and the overall goal while integrating with contexts of other agents.Agents must adapt and update their understanding of the task in response to context provided by other agents, and further, plan the decomposed tasks accordingly.</p>
<p>Consistency in Objectives.</p>
<p>In multi-agent systems, consistency in objectives is maintained across various levels, i.e., from overall goals down to individual agent tasks and their decomposed tasks.Each agent must understand and effectively utilize the layered contexts while ensuring its task and the decomposed sub-tasks to remain aligned with the overall goals.(Harris et al., 2023) extends the Stackelberg model (Von Stackelberg, 2010;Conitzer &amp; Sandholm, 2006) to enable agents to incorporate external context information, such as context (or insights) provided by other agents.However, aligning the complex context with the decomposed tasks during reasoning remains unresolved.</p>
<p>Agent Memory and Information Retrieval</p>
<p>The memory in single-LLM agent systems refers to the agent's ability to record, manage, and utilize data, such as past historical queries and some external data sources, to help inference and enhance decision-making and reasoning (Yao et al., 2023;Park et al., 2023;Li &amp; Qiu, 2023;Wang et al., 2023;Guo et al., 2023).While the memory in a single-LLM agent system primarily focuses on internal data management and utilization, a multi-agent system requires agents to work collaboratively to complete some tasks, necessitating the individual memory capabilities of each agent as well as a sophisticated mechanism for sharing, integrating, and managing information across agents, thus poses challenges to memory and information retrieval.</p>
<p>Classifications of Memory in Multi-agent Systems</p>
<p>Based on the work flow of a multi-agent system, we categorize memory in multi-agent system as follows.</p>
<p> Short-term memory: This is the immediate, transient memory used by a Large Language Model (LLM) during a conversation or interaction, e.g., working memory in (Jinxin et al., 2023).It is ephemeral, existing only for the duration of the ongoing interaction and does not persist once the conversation ends.</p>
<p> Long-term Memory: This type of memory stores historical queries and responses, essentially chat histories from earlier sessions, to support inferences for future interactions.Typically, this memory is stored in external data storage, such as a vector database, to facilitate recall of past interactions. External data storage: This is an emerging area in LLM research where models are integrated with external data storage like vector databases, such that the agents can access additional knowledge from these databases, enhancing their ability to ground and enrich their responses (Lewis et al., 2020).This allows the LLM to produce responses that are more informative, accurate, and highly relevant to the specific context of the query. Episodic Memory: This type of memory encompasses a collection of interactions within multi-agent systems.</p>
<p>It plays a crucial role when agents are confronted with new tasks or queries.By referencing past interactions that have contextual similarities to the current query, agents can significantly enhance the relevance and accuracy of their responses.Episodic Memory allows for a more informed approach to reasoning and problemsolving, enabling a more adaptive and intelligent response mechanism, thus serves as a valuable asset in the multi-agent system,  Consensus Memory: In a multi-agent system where agents work on a task collaboratively, consensus memory acts as a unified source of shared information, such as common sense, some domain-specific knowledge, etc, e.g., skill library in (Jinxin et al., 2023).Agents utilize consensus memory to align their understanding and strategies with the tasks, thus enhancing an effective and cohesive collaboration among agents.</p>
<p>While both single-agent and multi-agent systems handle short-term memory and long-term memory, multi-agent systems introduce additional complexities due to the need for inter-agent communication, information sharing, and adaptive memory management.</p>
<p>Challenges in Multi-agent Memory Management</p>
<p>Managing memory in multi-agent systems is fraught with challenges and open problems, especially in the realms of safety, security, and privacy.We outline these as follows:</p>
<p>Hierarchical Memory Storage: In a multi-agent system, different agents often have varied functionalities and access needs.Some agents may have to query their sensitive data, but they don't want such data to be accessed by other parties.</p>
<p>While ensuring the consensus memory to be accessible to all clients, implementing robust access control mechanisms is crucial to ensure sensitive information of an agent is not accessible to all agents.Additionally, as the agents in a sys-tem collaborative on one task, and their functionalities share same contexts, their external data storage and memories may overlap.If the data and functionalities of these agents are not sensitive, adopting an unified data storage can effectively manage redundancy among the data, and furthermore, ensure consistency across the multi-agent system, leading to more efficient and precise maintenance of memory.</p>
<p>Maintenance of Consensus Memory: As consensus memory is obtained by all agents when collaborating on a task, ensuring the integrity of shared knowledge is critical to ensure the correct execution of the tasks in the multi-agent systems.Any tampering or unauthorized modification of consensus memory can lead to systemic failures of the execution.Thus, a rigorous access control is important to mitigate risks of data breaches.</p>
<p>Communication and information exchange: Ensuring effective communication and information exchange between agents is essential in multi-agent systems.Each agent may hold critical pieces of information, and seamless integration of these is vital for the overall system performance.</p>
<p>Management of Episodic Memory.Leveraging past interactions within the multi-agent system to enhance responses to new queries is challenging in multi-agent systems.Determining how to effectively recall and utilize contextually relevant past interactions among agents for current problemsolving scenarios is important.</p>
<p>These challenges underscore the need for continuous research and development in the field of multi-agent systems, focusing on creating robust, secure, and efficient memory management methodologies.</p>
<p>Applications in Blockchain</p>
<p>Multi-agent systems offer significant advantages to blockchain systems by augmenting their capabilities and efficiency.Essentially, these multi-agent systems serve as sophisticated tools for various tasks on blockchain and Web3 systems.Also, blockchain nodes can be viewed as agents with specific roles and capabilities (Ankile et al., 2023).</p>
<p>Given that both Blockchain systems and multi-agent systems are inherently distributed, the blockchain networks can be integrated with multi-agent systems seamlessly.By assigning a dedicated agent to each blockchain node, it's possible to enhance data analyzing and processing while bolstering security and privacy in the chain.</p>
<p>Multi-Agent Systems As a Tool</p>
<p>To cast a brick to attract jade, we give some potential directions that multi-agents systems can act as tools to benefit blockchain systems.Fraud Detection.Fraud detection is one of the most important task in financial monitoring.As an example, (Ankile et al., 2023) studies fraud detection through the perspective of an external observer who detects price manipulation by analyzing the transaction sequences or the price movements of a specific asset.Multi-agent systems can benefit fraud detection in blockchain as well.Agents can be deployed with different roles, such as monitoring transactions for fraudulent activities and analyzing user behaviors.Each agent could also focus on different behavior patterns to improve the accuracy and efficiency of the fraud detection process.</p>
<p>Blockchain Nodes as Agents</p>
<p>( Ankile et al., 2023) identifies blockchain nodes as agents, and studies fraud detection in the chain from the perspective an external observer.However, as powerful LLM agents with analyzing and reasoning capabilities, there are much that the agents can do, especially when combined with game theory and enable the agents to negotiate and debate.Below we provide some perspectives.</p>
<p>Smart Contract Management and Optimization.Smart contracts are programs that execute the terms of a contract between a buyer and a seller in a blockchain system.The codes are fixed, and are self-executed when predetermined conditions are met.Multi-agent systems can automate and optimize the execution of smart contracts with more flexible terms and even dynamic external information from users.</p>
<p>Agents can negotiate contract terms on behalf of their users, manage contract execution, and even optimize gas fees (in the context of Ethereum (Wood et al., 2014).The agents can analyze context information , such as past actions and predefined criteria, and utilize the information with flexibility.Such negotiations can also utilize game theory, such as Stackelberg Equilibrium (Von Stackelberg, 2010;Conitzer &amp; Sandholm, 2006) when there is a leader negotiator and Nash Equilibrium (Kreps, 1989) when no leader exists.</p>
<p>Conclusion</p>
<p>The exploration of multi-agent systems in this paper underscores their significant potential in advancing the capabilities of LLM agents beyond the confines of single-agent paradigms.By leveraging the specialized abilities and collaborative dynamics among agents, multi-agent systems can tackle complex tasks with enhanced efficiency and innovation.Our study has illuminated challenges that need to be addressed to harness the power of multi-agent systems better, including optimizing task planning, managing complex context information, and improving memory management.Furthermore, the potential applications of multi-agent systems in blockchain technologies reveal new avenues for development, which suggests a promising future for these systems in distributed computing environments.</p>
<p>Figure 1 .
1
Figure 1.Structures of multi-agent systems.</p>
<p>Smart Contract Analysis.Smart contracts are programs stored on a blockchain that run when predetermined conditions are met.Multi-agents work together to analyze and audit smart contracts.The agents can have different specializations, such as identifying security vulnerabilities, legal compliance, and optimizing contract efficiency.Their collaborative analysis can provide a more comprehensive review than a single agent could achieve alone.
Consensus Mechanism Enhancement. Consensus mech-anisms like Proof of Work (PoW) (Gervais et al., 2016) orProof of Stake (PoS) (Saleh, 2021) are critical for validatingtransactions and maintaining network integrity. Multi-agentsystems can collaborate to monitor network activities, an-alyze transaction patterns, and identify potential securitythreats. By working together, these agents can proposeenhancements to the consensus mechanism, making theblockchain more secure and efficient.
University of California, Irvine, CA, USA
Carnegie Mellon University, Pittsburgh, PA, USA
University of Southern California, Los Angeles, CA,
USA 4 Stevens Institute of Technology, Hoboken, NJ, USA. Correspondence to: Shanshan Han <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#115;&#104;&#97;&#110;&#115;&#104;&#97;&#110;&#46;&#104;&#97;&#110;&#64;&#117;&#99;&#105;&#46;&#101;&#100;&#117;">&#115;&#104;&#97;&#110;&#115;&#104;&#97;&#110;&#46;&#104;&#97;&#110;&#64;&#117;&#99;&#105;&#46;&#101;&#100;&#117;</a>.</p>
<p>Feudal multi-agent hierarchies for cooperative reinforcement learning. S Ahilan, P Dayan, arXiv:1901.084922019arXiv preprint</p>
<p>I see you! robust measurement of adversarial behavior. L Ankile, M X Ferreira, D Parkes, Multi-Agent Security Workshop@ NeurIPS'23. 2023</p>
<p>Graph of thoughts: Solving elaborate problems with large language models. M Besta, N Blach, A Kubicek, R Gerstenberger, L Gianinazzi, J Gajda, T Lehmann, M Podstawski, H Niewiadomski, P Nyczyk, arXiv:2308.096872023arXiv preprint</p>
<p>T Cai, X Wang, T Ma, X Chen, D Zhou, arXiv:2305.17126Large language models as tool makers. 2023arXiv preprint</p>
<p>C.-M Chan, W Chen, Y Su, J Yu, W Xue, S Zhang, J Fu, Z Liu, arXiv:2308.07201Towards better llm-based evaluators through multi-agent debate. 2023arXiv preprint</p>
<p>Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. W Chen, X Ma, X Wang, W W Cohen, arXiv:2211.125882022arXiv preprint</p>
<p>Scalable multi-robot collaboration with large language models: Centralized or decentralized systems?. Y Chen, J Arkin, Y Zhang, N Roy, Fan , C , arXiv:2309.159432023arXiv preprint</p>
<p>Computing the optimal strategy to commit to. V Conitzer, T Sandholm, Proceedings of the 7th ACM conference on Electronic commerce. the 7th ACM conference on Electronic commerce2006</p>
<p>Improving factuality and reasoning in language models through multiagent debate. Y Du, S Li, A Torralba, J B Tenenbaum, I Mordatch, arXiv:2305.143252023arXiv preprint</p>
<p>Oracles &amp; followers: Stackelberg equilibria in deep multi-agent reinforcement learning. M Gerstgrasser, D C Parkes, International Conference on Machine Learning. PMLR2023</p>
<p>On the security and performance of proof of work blockchains. A Gervais, G O Karame, K Wst, V Glykantzis, H Ritzdorf, S Capkun, Proceedings of the 2016 ACM SIGSAC conference on computer and communications security. the 2016 ACM SIGSAC conference on computer and communications security2016</p>
<p>Multi-agent deep reinforcement learning: a survey. S Gronauer, K Diepold, Artificial Intelligence Review. 2022</p>
<p>Promptguided retrieval augmentation for non-knowledgeintensive tasks. Z Guo, S Cheng, Y Wang, P Li, Y Liu, arXiv:2305.176532023arXiv preprint</p>
<p>Stackelberg games with side information. K Harris, S Wu, M F Balcan, Multi-Agent Security Workshop@ NeurIPS'23. 2023</p>
<p>S Jinxin, Z Jiabao, W Yilei, W Xingjiao, L Jiawen, H Liang, Cgmi, arXiv:2308.12503Configurable general multi-agent interaction framework. 2023arXiv preprint</p>
<p>Nash equilibrium. D M Kreps, Game Theory. Springer1989</p>
<p>Retrieval-augmented generation for knowledgeintensive nlp tasks. P Lewis, E Perez, A Piktus, F Petroni, V Karpukhin, N Goyal, H Kttler, M Lewis, W.-T Yih, T Rocktschel, Advances in Neural Information Processing Systems. 202033</p>
<p>G Li, H A A K Hammoud, H Itani, D Khizbullin, B Ghanem, Camel, arXiv:2303.17760Communicative agents for" mind" exploration of large scale language model society. 2023arXiv preprint</p>
<p>Mot: Memory-of-thought enables chatgpt to self-improve. X Li, X Qiu, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language Processing2023</p>
<p>Multi-agent discussion mechanism for natural language generation. X Li, M Sun, P Li, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence201933</p>
<p>Y Li, H Wen, W Wang, X Li, Y Yuan, G Liu, J Liu, W Xu, X Wang, Y Sun, arXiv:2401.05459Personal llm agents: Insights and survey about the capability, efficiency and security. 2024arXiv preprint</p>
<p>Encouraging divergent thinking in large language models through multi-agent debate. T Liang, Z He, W Jiao, X Wang, Y Wang, R Wang, Y Yang, Z Tu, S Shi, arXiv:2305.191182023arXiv preprint</p>
<p>Large language model guided tree-of-thought. J Long, arXiv:2305.082912023arXiv preprint</p>
<p>Show your work: Scratchpads for intermediate computation with language models. M Nye, A J Andreassen, G Gur-Ari, H Michalewski, J Austin, D Bieber, D Dohan, A Lewkowycz, M Bosma, D Luan, arXiv:2112.001142021arXiv preprint</p>
<p>Generative agents: Interactive simulacra of human behavior. J S Park, J O'brien, C J Cai, M R Morris, P Liang, M S Bernstein, Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. the 36th Annual ACM Symposium on User Interface Software and Technology2023</p>
<p>S G Patil, T Zhang, X Wang, J E Gonzalez, Gorilla, arXiv:2305.15334Large language model connected with massive apis. 2023arXiv preprint</p>
<p>Blockchain without waste: Proof-of-stake. The Review of financial studies. F Saleh, 202134</p>
<p>Multi-agent collaboration: Harnessing the power of intelligent llm agents. Y Talebirad, A Nadiri, arXiv:2306.033142023arXiv preprint</p>
<p>Second-order jailbreaks: Generative agents successfully manipulate through an intermediary. M Terekhov, R Graux, E Neville, D Rosset, G Kolly, Multi-Agent Security Workshop@ NeurIPS'23. 2023</p>
<p>Market structure and equilibrium. Von Stackelberg, H , 2010Springer Science &amp; Business Media</p>
<p>W Wang, L Dong, H Cheng, X Liu, X Yan, J Gao, F Wei, arXiv:2306.07174Augmenting language models with long-term memory. 2023arXiv preprint</p>
<p>Self-consistency improves chain of thought reasoning in language models. X Wang, J Wei, D Schuurmans, Q Le, E Chi, S Narang, A Chowdhery, D Zhou, arXiv:2203.111712022aarXiv preprint</p>
<p>X Wang, J Wei, D Schuurmans, Q Le, E Chi, D Zhou, arXiv:2207.00747Rationale-augmented ensembles in language models. 2022barXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, F Xia, E Chi, Q V Le, D Zhou, Advances in Neural Information Processing Systems. 202235</p>
<p>Ethereum: A secure decentralised generalised transaction ledger. Ethereum project yellow paper. G Wood, 2014. 2014151</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. S Yao, D Yu, J Zhao, I Shafran, T L Griffiths, Y Cao, K Narasimhan, arXiv:2305.106012023arXiv preprint</p>
<p>Exploring collaboration mechanisms for llm agents: A social psychology view. J Zhang, X Xu, S Deng, 2023a</p>
<p>Igniting language intelligence: The hitchhiker's guide from chainof-thought reasoning to language agents. Z Zhang, Y Yao, A Zhang, X Tang, X Ma, Z He, Y Wang, M Gerstein, R Wang, G Liu, arXiv:2311.117972023barXiv preprint</p>
<p>S Zhou, F F Xu, H Zhu, X Zhou, R Lo, A Sridhar, X Cheng, Y Bisk, D Fried, U Alon, arXiv:2307.13854A realistic web environment for building autonomous agents. 2023arXiv preprint</p>
<p>Tab-CoT: Zero-shot tabular chain of thought. J Ziqi, W Lu, doi: 10.18653Findings of the Association for Computational Linguistics: ACL 2023. A Rogers, J Boyd-Graber, N Okazaki, Toronto, CanadaAssociation for Computational LinguisticsJuly 2023</p>
<p>URL. </p>            </div>
        </div>

    </div>
</body>
</html>