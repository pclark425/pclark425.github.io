<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1995 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1995</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1995</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-46.html">extraction-schema-46</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <p><strong>Paper ID:</strong> paper-281496289</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2509.18180v3.pdf" target="_blank">Large Language Models in Operations Research: Methods, Applications, and Challenges</a></p>
                <p><strong>Paper Abstract:</strong> Operations research (OR) is a core methodology that supports complex system decision-making, with broad applications in transportation, supply chain management, and production scheduling. However, traditional approaches that rely on expert-driven modeling and manual parameter tuning often struggle with large-scale, dynamic, and multi-constraint problems, limiting scalability and real-time applicability. Large language models (LLMs), with capabilities in semantic understanding, structured generation, and reasoning control, offer new opportunities to overcome these challenges. They can translate natural language problem descriptions into mathematical models or executable code, generate heuristics, evolve algorithms, and directly solve optimization tasks. This shifts the paradigm from human-driven processes to intelligent human-AI collaboration. This paper systematically reviews progress in applying LLMs to OR, categorizing existing methods into three pathways: automatic modeling, auxiliary optimization, and direct solving. It also examines evaluation benchmarks and domain-specific applications, and highlights key challenges, including unstable semantic-to-structure mapping, fragmented research, limited generalization and interpretability, insufficient evaluation systems, and barriers to industrial deployment. Finally, it outlines potential research directions. Overall, LLMs demonstrate strong potential to reshape the OR paradigm by enhancing interpretability, adaptability, and scalability, paving the way for next-generation intelligent optimization systems.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1995.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1995.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LMEA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-as-Evolutionary-Operator (LMEA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Frameworks that use LLMs as zero-shot evolutionary operators (parent selection, crossover, mutation) invoked via natural-language prompts to produce candidate offspring; reported to reduce operator design burden and adapt across instance types.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LMEA (LLM-as-evolutionary-operator)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based (zero-shot operator)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Uses prompt templates to ask an LLM to produce offspring, candidate parents, or mutation suggestions directly in natural language or as pseudocode; may include temperature-adaptive sampling to balance exploration/exploitation. Operators are not trained specifically for the operator task in zero-shot variants; some works augment with structured prompts or light fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>TSP instances and other combinatorial optimization benchmarks (multiple TSP instances mentioned in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Traditional genetic operators (hand-designed crossover/mutation/selection), standard evolutionary algorithms (e.g., NSGA-II, MOEA/D), and classical heuristics</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Survey reports qualitative improvement: 'superior performance over traditional methods on multiple TSP instances' (no numeric metrics provided in this survey)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Survey indicates generalization across multiple TSP instances but does not provide quantified OOD results; claims of strong generalization are qualitative.</td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td>Not discussed specifically for LMEA zero-shot operators in the survey; limitations of LLM generalization and instability are noted elsewhere in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>Survey notes LLM invocation is costly relative to classical operators; mitigation strategies (temperature/linear operators, conditional invocation) are described but no quantitative cost figures are given.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td>Survey describes zero-shot use of general pre-trained LLMs; no explicit controlled comparison with domain-specific fine-tuned models for LMEA in the surveyed text.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>Some LMEA-style works include iterative refinement across generations (LLM suggestions evaluated and better prompts retained), but the survey does not report systematic online fine-tuning; adaptation generally via prompt- and population-level feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>High invocation cost; variable stability; occasional degeneration to less-useful or repetitive offspring; sensitivity to prompt design and sampling temperature.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>LLM zero-shot operators can produce qualitatively different and sometimes superior offspring that speed convergence on some combinatorial problems (e.g., TSP); however, they incur higher computational cost and are sensitive to prompt/sampling settings, motivating hybrid or cost-aware invocation strategies.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1995.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1995.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AEL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Algorithm Evolution using Large Language models (AEL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Framework treating the algorithm itself as an object for LLM generation: LLMs generate, rewrite, and refine algorithmic components (heuristics/local-search functions), enabling iterative self-improvement of algorithms across evolutionary rounds.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Algorithm evolution using large language model</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AEL (Algorithm Evolution with LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based (learned/generative operator for algorithm code)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Structured prompts condition the LLM on task description and structural embeddings to generate executable algorithmic code or pseudocode; the generated code is executed, evaluated, and used to prompt the model for further refinements (generate-evaluate-refine loop). May use supervised fine-tuning or structured prompt templates to improve consistency.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Guided local search and complex TSP tasks (survey reports applications to TSP and other combinatorial problems)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Manually designed guiding functions, traditional metaheuristics and hand-designed local search heuristics</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Survey states LLM-generated guiding functions 'outperform manually designed schemes' on complex TSP tasks (qualitative; no numeric metrics given in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td>Survey mentions generation of executable code as a goal and use of validation/self-debugging loops, but no aggregate validity rates reported.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Claims of strong generalization on complex TSP tasks are made qualitatively; no detailed OOD evaluation numbers provided by the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td>Not specifically reported in survey for AEL; general caution that LLMs can be biased towards training patterns is noted elsewhere.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>Generating and executing code is more expensive than simple hand-coded operators; survey does not provide quantitative CPU/latency/memory comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td>Survey describes both prompt-only generation and variants that use instruction-tuning or supervised fine-tuning, but does not give a head-to-head numeric comparison within AEL.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td>The framework implicitly expands the hypothesis space (space of possible heuristics) by using LLM generation; survey notes this enables discovery of novel guiding functions but does not characterize coverage quantitatively.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>Yes — iterative generate-evaluate-refine across rounds; improvements are retained via selection, giving a form of adaptation that improves algorithm components over time.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Instability of generated code (bugs), occasional semantic mismatch between prompt and generated function, variable performance across instances, and computational overhead.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Treating algorithms as generative artifacts allows discovery of novel heuristics that can outperform hand-designed functions on some tasks, but the approach trades increased search/compute cost and requires validation/repair loops to ensure executable, reliable operators.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1995.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1995.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM+NSGA-II / llmPC-NSGA-II</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-augmented NSGA-II (llmPC-NSGA-II)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Hybrid approach embedding LLM-generated individuals or heuristic functions into NSGA-II evolutionary framework to improve convergence and diversity in multi-objective optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>llmPC-NSGA-II (LLM-augmented NSGA-II)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>hybrid (LLM-based operators + traditional genetic operators)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Structured prompts generate full offspring populations or mutation/crossover suggestions which are then integrated into NSGA-II population with standard non-dominated sorting and crowding distance update rules. LLM acts as an auxiliary generator while NSGA-II provides selection pressure.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Portfolio multi-objective optimization on real financial data and standard benchmark functions (as reported in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Standard NSGA-II, other specialized optimizers and heuristic baselines</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Survey reports strong convergence and diversity when LLM-generated offspring are integrated; described as outperforming traditional heuristics in the cited experiments (qualitative, no numeric values in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td>Diversity measured qualitatively via non-dominated set diversity and crowding distance mechanisms; no numeric diversity metrics reported in survey</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>Hybrid approach increases per-generation cost due to LLM invocations; survey notes trade-offs and suggests selective invocation strategies (e.g., only on stagnation) to reduce cost.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td>Survey mentions LoRA and fine-tuning used in other contexts (job shop scheduling) but does not specify if llmPC used domain-specific models.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>Yes — LLM outputs used within NSGA-II loop and can be refined across generations; some reported methods use reflection/self-improvement to adapt operators.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>High cost at scale, sensitivity to prompt quality, potential to reduce diversity if LLM outputs converge to similar heuristics without explicit diversity mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>LLM-generated offspring can complement traditional genetic operators by injecting novel search directions and improving multi-objective convergence/diversity, but cost-aware integration and mechanisms to preserve diversity are essential.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1995.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1995.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cost-aware invocation (stagnation-triggering)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Low-cost adaptive invocation of LLM (stagnation-based trigger)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Approach where LLM is invoked selectively (e.g., only when evolutionary progress stagnates) to reduce computational cost while retaining generative benefits.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Stagnation-triggered LLM invocation (low-cost adaptive MOEA)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>hybrid (conditional LLM-based + traditional operators)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>LLM is used as an auxiliary generator only under certain conditions (e.g., stagnation detection). Traditional genetic operators run normally; when progress stalls, the system prompts an LLM to propose diverse candidate solutions to escape local optima.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Multi-objective optimization (NSGA-II context) and TSP variants (survey mentions MOEA contexts)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Fully LLM-invoking evolutionary runs; pure traditional EA without LLM assistance</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Survey notes improved solution quality under limited computational resources compared to calling LLM every generation; no numeric metrics provided.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>Qualitatively described as 'low-cost' because LLM calls are rare; no quantitative CPU/time/cost numbers provided in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>Adaptation via conditional invocation policy and potential prompt/template evolution; limited online learning reported.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>If trigger thresholds are mis-set, improvements may be missed or cost savings lost; effectiveness depends on reliable stagnation detection.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Selective invocation preserves most of LLM benefits for escaping local optima while greatly reducing computational expense, suggesting a practical trade-off between operator novelty and cost.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1995.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1995.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HeurAgenix</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HeurAgenix: Multi-Agent LLM-Based Adaptive Heuristic Evolution and Selection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Multi-agent system where separate LLM agents generate heuristics, evaluate them, and select/coordinate strategies; extends LLM role from single generator to multi-role collaborator in heuristic evolution.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>HeurAgenix: A Multi-Agent LLM-Based Paradigm for Adaptive Heuristic Evolution and Selection in Combinatorial Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>HeurAgenix</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>hybrid / multi-agent LLM-based (learned operators + evaluator/selection agents)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Separate agent roles include generation (produce heuristics), evolution (mutate/combine heuristics), evaluation (assess solutions), and selection (choose strategies). LLMs are used in generation and reflection roles; traditional evolutionary selection mechanisms (e.g., tournament or non-dominated sorting) coordinate populations.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Combinatorial optimization tasks (survey-level description; specific benchmarks not enumerated here)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Single-agent LLM generator approaches, traditional heuristics and specialized optimizers</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Reported improvements in adaptive heuristic evolution and selection versus single-agent or purely hand-designed heuristics (qualitative summary only in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>Multi-agent orchestration increases orchestration overhead and total LLM calls; survey notes benefits in quality may justify higher cost but gives no numeric cost comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td>System increases diversity of generated heuristics by role specialization; no quantitative coverage given.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>Yes — agents provide reflection and selection leading to continuous adaptation of heuristics across iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Complex coordination overhead, risk of collapse to similar heuristics without explicit diversity mechanisms, sensitivity to agent prompt designs.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Multi-agent decomposition leverages LLM strengths (generation + reasoning) while providing internal checks (evaluation/selection), improving heuristic discovery and robustness compared to monolithic LLM operators; orchestration cost and diversity preservation are central design concerns.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1995.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1995.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BRKGA+LLM (Sartori)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structure-aware BRKGA decoder augmented with LLM-generated probabilistic signals</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Integration where LLM extracts node/instance features and emits probabilistic signals that bias a biased-random-key genetic algorithm (BRKGA) decoder for structure-aware metaheuristic search.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BRKGA+LLM (Structure-aware metaheuristic)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>hybrid (LLM-guided probability signals + traditional BRKGA decoder)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>LLM analyzes problem instance/context in natural language and outputs node-level features or probabilistic guidance that are injected as biases into BRKGA decoding, thereby making the random-key GA structure-aware. LLM thus influences offspring generation indirectly via decoder biasing rather than replacing genetic operators.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Graph-structured combinatorial optimization problems (survey references BRKGA applications and structure-aware metaheuristics)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Standard BRKGA without LLM guidance and other hand-tuned metaheuristics</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Survey reports improvements in structure-aware search and solution quality versus non-LLM BRKGA in cited works (qualitative; no numeric metrics shown in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>LLM produces guidance signals (lighter than full offspring generation) — lower cost than full LLM operator but higher than pure BRKGA; no numeric cost data provided.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>Guidance can be updated or re-generated across generations; the decoder remains traditional GA, so adaptation is indirect via bias adjustments.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>If LLM guidance is noisy or misaligned, decoder bias can hurt search; dependency on prompt design and instance feature extraction accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Indirect injection of learned, instance-aware guidance into traditional decoders can capture instance structure and improve search without the cost of replacing core genetic operators; this suggests beneficial hybridization patterns where learned components provide high-level bias while cheap traditional operators run the main loop.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Algorithm evolution using large language model <em>(Rating: 2)</em></li>
                <li>Llm4ad: A platform for algorithm design with large language model <em>(Rating: 2)</em></li>
                <li>HeurAgenix: A Multi-Agent LLM-Based Paradigm for Adaptive Heuristic Evolution and Selection in Combinatorial Optimization <em>(Rating: 2)</em></li>
                <li>ARS: Automatic Routing Solver with Large Language Models <em>(Rating: 2)</em></li>
                <li>Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations <em>(Rating: 1)</em></li>
                <li>Large language models as evolutionary optimizers <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1995",
    "paper_id": "paper-281496289",
    "extraction_schema_id": "extraction-schema-46",
    "extracted_data": [
        {
            "name_short": "LMEA",
            "name_full": "LLM-as-Evolutionary-Operator (LMEA)",
            "brief_description": "Frameworks that use LLMs as zero-shot evolutionary operators (parent selection, crossover, mutation) invoked via natural-language prompts to produce candidate offspring; reported to reduce operator design burden and adapt across instance types.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "LMEA (LLM-as-evolutionary-operator)",
            "operator_type": "LLM-based (zero-shot operator)",
            "operator_description": "Uses prompt templates to ask an LLM to produce offspring, candidate parents, or mutation suggestions directly in natural language or as pseudocode; may include temperature-adaptive sampling to balance exploration/exploitation. Operators are not trained specifically for the operator task in zero-shot variants; some works augment with structured prompts or light fine-tuning.",
            "training_data_description": null,
            "domain_or_benchmark": "TSP instances and other combinatorial optimization benchmarks (multiple TSP instances mentioned in survey)",
            "comparison_baseline": "Traditional genetic operators (hand-designed crossover/mutation/selection), standard evolutionary algorithms (e.g., NSGA-II, MOEA/D), and classical heuristics",
            "performance_learned_operator": "Survey reports qualitative improvement: 'superior performance over traditional methods on multiple TSP instances' (no numeric metrics provided in this survey)",
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": "Survey indicates generalization across multiple TSP instances but does not provide quantified OOD results; claims of strong generalization are qualitative.",
            "training_bias_evidence": "Not discussed specifically for LMEA zero-shot operators in the survey; limitations of LLM generalization and instability are noted elsewhere in the paper.",
            "computational_cost_comparison": "Survey notes LLM invocation is costly relative to classical operators; mitigation strategies (temperature/linear operators, conditional invocation) are described but no quantitative cost figures are given.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": "Survey describes zero-shot use of general pre-trained LLMs; no explicit controlled comparison with domain-specific fine-tuned models for LMEA in the surveyed text.",
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": "Some LMEA-style works include iterative refinement across generations (LLM suggestions evaluated and better prompts retained), but the survey does not report systematic online fine-tuning; adaptation generally via prompt- and population-level feedback.",
            "failure_modes": "High invocation cost; variable stability; occasional degeneration to less-useful or repetitive offspring; sensitivity to prompt design and sampling temperature.",
            "key_findings_for_theory": "LLM zero-shot operators can produce qualitatively different and sometimes superior offspring that speed convergence on some combinatorial problems (e.g., TSP); however, they incur higher computational cost and are sensitive to prompt/sampling settings, motivating hybrid or cost-aware invocation strategies.",
            "uuid": "e1995.0"
        },
        {
            "name_short": "AEL",
            "name_full": "Algorithm Evolution using Large Language models (AEL)",
            "brief_description": "Framework treating the algorithm itself as an object for LLM generation: LLMs generate, rewrite, and refine algorithmic components (heuristics/local-search functions), enabling iterative self-improvement of algorithms across evolutionary rounds.",
            "citation_title": "Algorithm evolution using large language model",
            "mention_or_use": "mention",
            "system_name": "AEL (Algorithm Evolution with LLM)",
            "operator_type": "LLM-based (learned/generative operator for algorithm code)",
            "operator_description": "Structured prompts condition the LLM on task description and structural embeddings to generate executable algorithmic code or pseudocode; the generated code is executed, evaluated, and used to prompt the model for further refinements (generate-evaluate-refine loop). May use supervised fine-tuning or structured prompt templates to improve consistency.",
            "training_data_description": null,
            "domain_or_benchmark": "Guided local search and complex TSP tasks (survey reports applications to TSP and other combinatorial problems)",
            "comparison_baseline": "Manually designed guiding functions, traditional metaheuristics and hand-designed local search heuristics",
            "performance_learned_operator": "Survey states LLM-generated guiding functions 'outperform manually designed schemes' on complex TSP tasks (qualitative; no numeric metrics given in survey)",
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": "Survey mentions generation of executable code as a goal and use of validation/self-debugging loops, but no aggregate validity rates reported.",
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": "Claims of strong generalization on complex TSP tasks are made qualitatively; no detailed OOD evaluation numbers provided by the survey.",
            "training_bias_evidence": "Not specifically reported in survey for AEL; general caution that LLMs can be biased towards training patterns is noted elsewhere.",
            "computational_cost_comparison": "Generating and executing code is more expensive than simple hand-coded operators; survey does not provide quantitative CPU/latency/memory comparisons.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": "Survey describes both prompt-only generation and variants that use instruction-tuning or supervised fine-tuning, but does not give a head-to-head numeric comparison within AEL.",
            "ablation_study_results": null,
            "hypothesis_space_characterization": "The framework implicitly expands the hypothesis space (space of possible heuristics) by using LLM generation; survey notes this enables discovery of novel guiding functions but does not characterize coverage quantitatively.",
            "adaptation_during_evolution": "Yes — iterative generate-evaluate-refine across rounds; improvements are retained via selection, giving a form of adaptation that improves algorithm components over time.",
            "failure_modes": "Instability of generated code (bugs), occasional semantic mismatch between prompt and generated function, variable performance across instances, and computational overhead.",
            "key_findings_for_theory": "Treating algorithms as generative artifacts allows discovery of novel heuristics that can outperform hand-designed functions on some tasks, but the approach trades increased search/compute cost and requires validation/repair loops to ensure executable, reliable operators.",
            "uuid": "e1995.1"
        },
        {
            "name_short": "LLM+NSGA-II / llmPC-NSGA-II",
            "name_full": "LLM-augmented NSGA-II (llmPC-NSGA-II)",
            "brief_description": "Hybrid approach embedding LLM-generated individuals or heuristic functions into NSGA-II evolutionary framework to improve convergence and diversity in multi-objective optimization.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "llmPC-NSGA-II (LLM-augmented NSGA-II)",
            "operator_type": "hybrid (LLM-based operators + traditional genetic operators)",
            "operator_description": "Structured prompts generate full offspring populations or mutation/crossover suggestions which are then integrated into NSGA-II population with standard non-dominated sorting and crowding distance update rules. LLM acts as an auxiliary generator while NSGA-II provides selection pressure.",
            "training_data_description": null,
            "domain_or_benchmark": "Portfolio multi-objective optimization on real financial data and standard benchmark functions (as reported in survey)",
            "comparison_baseline": "Standard NSGA-II, other specialized optimizers and heuristic baselines",
            "performance_learned_operator": "Survey reports strong convergence and diversity when LLM-generated offspring are integrated; described as outperforming traditional heuristics in the cited experiments (qualitative, no numeric values in survey)",
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": "Diversity measured qualitatively via non-dominated set diversity and crowding distance mechanisms; no numeric diversity metrics reported in survey",
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": "Hybrid approach increases per-generation cost due to LLM invocations; survey notes trade-offs and suggests selective invocation strategies (e.g., only on stagnation) to reduce cost.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": "Survey mentions LoRA and fine-tuning used in other contexts (job shop scheduling) but does not specify if llmPC used domain-specific models.",
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": "Yes — LLM outputs used within NSGA-II loop and can be refined across generations; some reported methods use reflection/self-improvement to adapt operators.",
            "failure_modes": "High cost at scale, sensitivity to prompt quality, potential to reduce diversity if LLM outputs converge to similar heuristics without explicit diversity mechanisms.",
            "key_findings_for_theory": "LLM-generated offspring can complement traditional genetic operators by injecting novel search directions and improving multi-objective convergence/diversity, but cost-aware integration and mechanisms to preserve diversity are essential.",
            "uuid": "e1995.2"
        },
        {
            "name_short": "Cost-aware invocation (stagnation-triggering)",
            "name_full": "Low-cost adaptive invocation of LLM (stagnation-based trigger)",
            "brief_description": "Approach where LLM is invoked selectively (e.g., only when evolutionary progress stagnates) to reduce computational cost while retaining generative benefits.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Stagnation-triggered LLM invocation (low-cost adaptive MOEA)",
            "operator_type": "hybrid (conditional LLM-based + traditional operators)",
            "operator_description": "LLM is used as an auxiliary generator only under certain conditions (e.g., stagnation detection). Traditional genetic operators run normally; when progress stalls, the system prompts an LLM to propose diverse candidate solutions to escape local optima.",
            "training_data_description": null,
            "domain_or_benchmark": "Multi-objective optimization (NSGA-II context) and TSP variants (survey mentions MOEA contexts)",
            "comparison_baseline": "Fully LLM-invoking evolutionary runs; pure traditional EA without LLM assistance",
            "performance_learned_operator": "Survey notes improved solution quality under limited computational resources compared to calling LLM every generation; no numeric metrics provided.",
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": "Qualitatively described as 'low-cost' because LLM calls are rare; no quantitative CPU/time/cost numbers provided in the survey.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": "Adaptation via conditional invocation policy and potential prompt/template evolution; limited online learning reported.",
            "failure_modes": "If trigger thresholds are mis-set, improvements may be missed or cost savings lost; effectiveness depends on reliable stagnation detection.",
            "key_findings_for_theory": "Selective invocation preserves most of LLM benefits for escaping local optima while greatly reducing computational expense, suggesting a practical trade-off between operator novelty and cost.",
            "uuid": "e1995.3"
        },
        {
            "name_short": "HeurAgenix",
            "name_full": "HeurAgenix: Multi-Agent LLM-Based Adaptive Heuristic Evolution and Selection",
            "brief_description": "Multi-agent system where separate LLM agents generate heuristics, evaluate them, and select/coordinate strategies; extends LLM role from single generator to multi-role collaborator in heuristic evolution.",
            "citation_title": "HeurAgenix: A Multi-Agent LLM-Based Paradigm for Adaptive Heuristic Evolution and Selection in Combinatorial Optimization",
            "mention_or_use": "mention",
            "system_name": "HeurAgenix",
            "operator_type": "hybrid / multi-agent LLM-based (learned operators + evaluator/selection agents)",
            "operator_description": "Separate agent roles include generation (produce heuristics), evolution (mutate/combine heuristics), evaluation (assess solutions), and selection (choose strategies). LLMs are used in generation and reflection roles; traditional evolutionary selection mechanisms (e.g., tournament or non-dominated sorting) coordinate populations.",
            "training_data_description": null,
            "domain_or_benchmark": "Combinatorial optimization tasks (survey-level description; specific benchmarks not enumerated here)",
            "comparison_baseline": "Single-agent LLM generator approaches, traditional heuristics and specialized optimizers",
            "performance_learned_operator": "Reported improvements in adaptive heuristic evolution and selection versus single-agent or purely hand-designed heuristics (qualitative summary only in survey).",
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": "Multi-agent orchestration increases orchestration overhead and total LLM calls; survey notes benefits in quality may justify higher cost but gives no numeric cost comparison.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": "System increases diversity of generated heuristics by role specialization; no quantitative coverage given.",
            "adaptation_during_evolution": "Yes — agents provide reflection and selection leading to continuous adaptation of heuristics across iterations.",
            "failure_modes": "Complex coordination overhead, risk of collapse to similar heuristics without explicit diversity mechanisms, sensitivity to agent prompt designs.",
            "key_findings_for_theory": "Multi-agent decomposition leverages LLM strengths (generation + reasoning) while providing internal checks (evaluation/selection), improving heuristic discovery and robustness compared to monolithic LLM operators; orchestration cost and diversity preservation are central design concerns.",
            "uuid": "e1995.4"
        },
        {
            "name_short": "BRKGA+LLM (Sartori)",
            "name_full": "Structure-aware BRKGA decoder augmented with LLM-generated probabilistic signals",
            "brief_description": "Integration where LLM extracts node/instance features and emits probabilistic signals that bias a biased-random-key genetic algorithm (BRKGA) decoder for structure-aware metaheuristic search.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "BRKGA+LLM (Structure-aware metaheuristic)",
            "operator_type": "hybrid (LLM-guided probability signals + traditional BRKGA decoder)",
            "operator_description": "LLM analyzes problem instance/context in natural language and outputs node-level features or probabilistic guidance that are injected as biases into BRKGA decoding, thereby making the random-key GA structure-aware. LLM thus influences offspring generation indirectly via decoder biasing rather than replacing genetic operators.",
            "training_data_description": null,
            "domain_or_benchmark": "Graph-structured combinatorial optimization problems (survey references BRKGA applications and structure-aware metaheuristics)",
            "comparison_baseline": "Standard BRKGA without LLM guidance and other hand-tuned metaheuristics",
            "performance_learned_operator": "Survey reports improvements in structure-aware search and solution quality versus non-LLM BRKGA in cited works (qualitative; no numeric metrics shown in survey)",
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": "LLM produces guidance signals (lighter than full offspring generation) — lower cost than full LLM operator but higher than pure BRKGA; no numeric cost data provided.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": "Guidance can be updated or re-generated across generations; the decoder remains traditional GA, so adaptation is indirect via bias adjustments.",
            "failure_modes": "If LLM guidance is noisy or misaligned, decoder bias can hurt search; dependency on prompt design and instance feature extraction accuracy.",
            "key_findings_for_theory": "Indirect injection of learned, instance-aware guidance into traditional decoders can capture instance structure and improve search without the cost of replacing core genetic operators; this suggests beneficial hybridization patterns where learned components provide high-level bias while cheap traditional operators run the main loop.",
            "uuid": "e1995.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Algorithm evolution using large language model",
            "rating": 2
        },
        {
            "paper_title": "Llm4ad: A platform for algorithm design with large language model",
            "rating": 2
        },
        {
            "paper_title": "HeurAgenix: A Multi-Agent LLM-Based Paradigm for Adaptive Heuristic Evolution and Selection in Combinatorial Optimization",
            "rating": 2
        },
        {
            "paper_title": "ARS: Automatic Routing Solver with Large Language Models",
            "rating": 2
        },
        {
            "paper_title": "Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations",
            "rating": 1
        },
        {
            "paper_title": "Large language models as evolutionary optimizers",
            "rating": 1
        }
    ],
    "cost": 0.016434999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large Language Models in Operations Research: Methods, Applications, and Challenges
14 Oct 2025</p>
<p>Yang Wang 
University of Chinese Academy of Sciences
BeijingChina</p>
<p>Kai Li 
Institute of Automation
Chinese Academy of Sciences
BeijingChina</p>
<p>School of Artificial Intelligence
University of Chinese Academy of Sciences
BeijingChina</p>
<p>Large Language Models in Operations Research: Methods, Applications, and Challenges
14 Oct 20250A24FBC730726240AC3871D3B35605EDarXiv:2509.18180v3[cs.AI]This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.Automatic ModelingAuxiliary OptimizationIntelligent Optimization SystemsLarge Language ModelsOperations Research
Operations research (OR) is a core methodology that supports complex system decisionmaking, with broad applications in transportation, supply chain management, and production scheduling.However, traditional approaches that rely on expertdriven modeling and manual parameter tuning often struggle with large-scale, dynamic, and multiconstraint problems, limiting scalability and real-time applicability.Large language models (LLMs), with capabilities in semantic understanding, structured generation, and reasoning control, offers new opportunities to overcome these challenges.It can translate natural language problem descriptions into mathematical models or executable code, generate heuristics, evolve algorithms, and directly solve optimization tasks.This shifts the paradigm from human-driven processes to intelligent human-AI collaboration.This paper systematically reviews progress in applying LLMs to OR, categorizing existing methods into three pathways: automatic modeling, auxiliary optimization, and direct solving.It also examines evaluation benchmarks and domain-specific applications, and highlights key challenges, including unstable semantic-to-structure mapping, fragmented research, limited generalization and interpretability, insufficient evaluation systems, and barriers to industrial deployment.Finally, it outlines potential research directions.Overall, LLMs demonstrate strong potential to reshape the OR paradigm by enhancing interpretability, adaptability, and scalability, paving the way for next-generation intelligent optimization systems.</p>
<p>A S a core methodology for decision-making in com- plex systems, OR has been widely applied in domains such as transportation, supply chain management, and production scheduling.However, with the rapid growth of data, increasing environmental dynamism, and rising demand customization, the traditional optimization paradigm-reliant on expert-based modeling and manual parameter tuning-has increasingly shown its limitations.The exponential expansion of problem scale, the growing complexity of constraint structures, and stringent realtime requirements pose formidable challenges to existing Emails: yangw77718@gmail.com,kai.li@ia.ac.cn methods, significantly hindering their applicability and adoption in complex scenarios [1], [2], [3].</p>
<p>Against this backdrop, the emergence of LLM offers a new opportunity to transform the paradigms of OR.Leveraging capabilities in semantic understanding, structured generation, and reasoning control, LLM has the potential to reshape the optimization process.Its value is primarily reflected in two aspects: First, at the modeling level, LLM can automatically translate natural language problem descriptions into formal mathematical models or executable code, thereby achieving a direct mapping from requirements to models [4], [5].Second, at the solving level, LLM can serve as a generator of heuristic strategies and collaborate with traditional optimization algorithms to build a closed-loop perception-reasoning-feedback framework, thereby improving both efficiency and solution quality [6], [7], [8].</p>
<p>Although recent studies have made progress, most explorations remain confined to local breakthroughs on specific tasks, and a unified methodological framework has yet to emerge.When addressing complex logical reasoning, LLM still exhibits instability and uncertainty in results.The limited interpretability of its reasoning process further challenges the reliability of practical applications.Hence, a systematic review is needed to clarify the research landscape, unify methodological paradigms, and outline future development directions.As shown in Fig. 1, the literature classification map visually illustrates the distribution of research pathways and representative works.Specifically, this paper systematically introduces research on LLMdriven OR from three perspectives:</p>
<p>• Methodological Paradigm Summary: reviewing existing work by classifying it into modeling and solving paradigms, and summarizing core technologies and implementation paths.• Domain Application Analysis: presenting case studies of LLM in typical scenarios such as supply chain optimization and urban management.• Frontier Trends Outlook: identifying key bottlenecks in current research and outlining potential breakthroughs and future directions.</p>
<p>Existing surveys on LLMs for optimization provide valuable but fragmented perspectives.Da Ros et al. [1]  emphasize methodological advances within combinatorial optimization, whereas cross-paradigm and applicationoriented perspectives remain underexplored.Liu et al. [2] highlight algorithm design, viewing LLMs mainly as generators rather than covering the full workflow.Xiao et al. [9] review the modeling stack-data, inference, and evaluation-yet give little attention to auxiliary optimization and solving.Zhang et al. [10] connect modeling and solving within evolutionary optimization but do not extend beyond this paradigm.In contrast, our review unifies automatic modeling, auxiliary optimization, and direct solving into a coherent framework, while also extending the analysis to domain problems and sector-specific applications, thereby offering a more comprehensive perspective on LLM-driven OR.The goal is to provide a systematic methodological review and structured insights, thereby promoting the deep integration of LLM with OR and supporting the development of next-generation intelligent decision-making systems.</p>
<p>II. Introduction to Basic Principles</p>
<p>A. Operations Research (OR)</p>
<p>OR is a systematic decision science centered on mathematical methods, aiming to obtain optimal or nearoptimal solutions to objective functions under multiple constraints [11], [12].By means of formal modeling, complex real-world decision problems are abstracted into mathematical representations of objectives and constraints, providing the theoretical foundation and tools for systematic analysis and exact solving.The scope of OR covers diverse problem types, including linear programming, integer programming, and combinatorial optimization [13], [14].These models effectively capture structural characteristics and sources of uncertainty, thereby establishing the methodological basis for modeling and solving complex systems.With its rigorous mathematical framework and broad applicability, OR has been widely adopted in critical domains such as transportation, supply chain management, and production scheduling [15], [16].However, as problem sizes expand and constraint structures become increasingly complex, traditional methods reveal clear limitations, including over-reliance on expert experience, insufficient modeling flexibility, and prohibitive computational costs for NP-hard problems.These challenges open the door for the introduction of LLM, which shows breakthrough potential in natural language-driven modeling, heuristic strategy generation, and the solving of complex problems.</p>
<p>B. Foundation of Competence of LLM</p>
<p>Pre-trained on large-scale corpora, LLM acquires semantic understanding, knowledge association, and generative reasoning [17], [18].Its relevance to OR lies in mapping natural language inputs into structured elements, algorithmic steps, or approximate solutions.Two core applications emerge: modeling, where LLM transforms unstructured descriptions into variables, objectives, and constraints to generate mathematical models or executable code [4], [5], [19]; and solving, where reasoning decomposition and chain-of-thought (CoT) support local search, heuristic generation, and tool invocation [20], [21].Moreover, LLM enables task generalization and interactive correction by suggesting parameters, producing heuristic operators, or reorganizing solving logic within optimization frameworks [6], [7], [22].When modeling fails or solving degrades, it establishes a generate-validate-repair closed loop through multi-turn prompts, rewriting, or tool calls [23], enhancing stability and controllability with selfdebugging [21] and self-feedback [24].These capabilities underpin the application of LLM in OR, particularly along two key pathways-automatic modeling and assisted solving-reviewed in the next section.</p>
<p>III. LLM-based Methods for Operations Research</p>
<p>A. Automatic Modeling</p>
<p>In recent years, automatic modeling has emerged as a core research direction for LLMs in OR.Ramamonjison et al. [4] first proposed a systematic modeling framework for translating natural language into optimization models, laying the research foundation for this field.Subsequently, Fan et al. [5] reviewed the multi-stage pathway for integrating artificial intelligence and OR, explicitly highlighting the unique potential of LLMs in the modeling phase.Huang et al. [19] further introduced the MAMO benchmark and proposed a "model generation + numerical validation" evaluation method, which for the first time established modeling capability as an independent research objective.As a result, automatic modeling has been increasingly recognized as a critical bridge between natural language and formal models [22].</p>
<p>To clarify the process, this paper summarizes automatic modeling into five sequential steps forming a closed loop from natural language to model execution, as illustrated in Fig. 2. The process begins with problem comprehension, where optimization objectives and resource constraints are parsed, followed by element identification to extract decision variables, constraint types, and objective functions.These elements are then organized through structure generation into a standard mathematical model, which is further transformed into solver-executable code.Finally, verification and feedback are performed by running the code in a solver and iteratively correcting errors based on the results.This section systematically reviews three representative research paradigms: (1) the pathway via prompting, (2) the collaborative pathway combining prompt and model fine-tuning, and (3) the external knowledge-guided mechanism.It also summarizes related evaluation benchmarks to compare their performance and applicability.[25], [26], [27] Multi-stage + Visualization + Reflection-retry prompts</p>
<p>NL4OPT + ComplexOR</p>
<p>Chain-of-Experts [28] Multi-agent chain + Expert prompts + Backward reflection</p>
<p>LPWP + ComplexOR</p>
<p>OptLLM [29] Three-stage dialogue + Interactive feedback NL4OPT + Optimize tasks NL2OR [30] DSL generation + Structural validation 30 OR inst.</p>
<p>Autoformulator [31] Multi-stage + Composite prompts + Structural search NL4OPT + IndustryOR + MAMO + ComplexOR MA-GTS [32] Multi-agent + Hierarchical modules + Semantic decomposition</p>
<p>G-REAL</p>
<p>OR-LLM-Agent [33] Prompt modeling + Code validation + Self-repair chain + Validation chain 83 real OR</p>
<p>1) LLM-based Automatic Modeling Paradigm via prompting:</p>
<p>The prompt-driven approach has become a significant direction for automated optimization modeling due to its lightweight design and ease of implementation.This class of methods guides the LLM to generate core components such as variables, objective functions, and constraints through prompting.Representative studies are summarized in Table I.</p>
<p>In this pathway, the OptiMUS series of work by Ah-madiTeshnizi et al. has built the most representative prompt-driven modeling process.The initial version [25] progressively converted natural language into a solvable optimization model, covering structure generation, code generation, execution validation, and feedback correction, and developed the accompanying NLP4LP dataset to support evaluation.Subsequent research [26] introduced a connection graph mechanism to record dependencies between variables, constraints, and parameters, thereby extracting context to prompt input and adapt to complex modeling scenarios.The latest version [27] further integrates a structure detection agent and a structure pool, combined with error correction mechanisms such as prompt retries and self-correction.It also supports calling solver subroutines in advanced optimization systems and provides an interactive modeling and visualization platform, thereby greatly improving the structural perception and engineering potential of the system.</p>
<p>Within prompting-based modeling, verification has become a central theme, though different works emphasize it from distinct angles.Xiao et al. [28] strengthen controllability through the Chain-of-Experts framework, where role-specific agents handle terminology parsing, model construction, code generation, and verification, supported by a two-stage reasoning mechanism of forward construction and backward reflection.Zhang et al. [29] highlight interactive refinement, employing a three-stage workflow of parsing, structural transformation, and result generation that integrates user feedback to lower the entry barrier for non-experts.Building on structured prompts, Li et al. [30] enhance structural correctness by introducing grammar correction, variable-consistency checks, and JSON Schema validation, with automatic restarts when errors occur.Astorga et al. [31] pursue systematic exploration, combining hierarchical decomposition and Monte Carlo Tree Search (MCTS) with structured templates and a candidate generation-pruning-ranking procedure to ensure both consistency and diversity.</p>
<p>Prompting has also been applied in specific scenarios.Yuan et al. [32] proposed the MA-GTS framework for graph-structured tasks, where multi-agent collaboration supports hierarchical modeling through semantic parsing, knowledge integration, and algorithmic solving, progressively reconstructing graph structures from text and invoking optimization algorithms adaptively.Zhang et al. [33] introduced the OR-LLM-Agent framework, which emphasizes reasoning-driven closed-loop modeling by using structured prompts to transform natural language into linear programming models, automatically generating executable code and performing repair and validation within a sandbox environment.</p>
<p>In summary, prompting has developed across multiple dimensions, encompassing both single-prompt guidance and multi-agent collaboration, incorporating interactive parsing and structured verification mechanisms, and spanning a wide range of scenarios from general tasks to domain-specific applications.These studies not only validate the effectiveness of prompting in automatic modeling but also highlight its potential in structural perception, task decomposition, and interactive generation.</p>
<p>2) LLM-based Automatic Modeling Mechanism Driven by Prompt-Fine-tuning Synergy: In research on automatic modeling using LLM, the synergistic mechanism of prompting and model fine-tuning has gradually emerged as a core developmental path.By combining input optimization with parameter updating, this mechanism alleviates the instability and limited generalization of single-prompt guidance in complex tasks, while further improving the model's accuracy and robustness in variable recognition,</p>
<p>Study</p>
<p>Prompt Mechanism FT Amarasinghe [35] Fixed structured prompts SFT Li [36] Template-based prompts SFT Ma [37] Structured prompts + Rewrite CL + InstrSFT Wu [38] Structured prompts + Validation chain LoRA + Alpaca + COPT Jiang [39] Structured prompts + Multi-rule aug.</p>
<p>MI-SFT + KTO</p>
<p>Lu [40] Structured prompts + Self-correction LoRA</p>
<p>Li [41] Structure-enhanced NL prompts SFT + DPO constraint parsing, and structured representation [34].A summary of representative studies is provided in Table II.</p>
<p>In workflow and module design, researchers have explored decomposing complex tasks through structured prompts and staged fine-tuning.Amarasinghe et al. [35] proposed the AI Copilot framework, which uses supervised fine-tuning to transform natural language into modeling code and applies prompt engineering with nine submodules to overcome token limitations, ensuring completeness and executability.Li et al. [36] introduced a three-stage framework involving variable identification, constraint classification, and supplementary generation, which significantly improves the precision of variable extraction and constraint construction.Ma et al. [37] developed the LLaMoCo framework, incorporating code-tocode instruction tuning and a large-scale instruction set for diverse optimization tasks, while enhancing semantic alignment and constraint comprehension through unified structural prompts and diversified rewriting strategies.By integrating contrastive learning with instruction tuning in a two-stage process, LLaMoCo achieves stronger semantic understanding and generalization in code generation.</p>
<p>In the area of data generation and consistency verification, Wu et al. [38] proposed the Evo-Step-Instruct framework, which introduces dual strategies of complexity evolution and scope evolution to guide the model in generating diverse, high-quality data.A step-by-step verification mechanism is further employed to ensure consistency among descriptions, variables, and constraints, thereby effectively preventing error propagation.This method demonstrates strong stability and accuracy on complex benchmark tasks, underscoring the critical role of data quality in the effectiveness of synergistic mechanisms.</p>
<p>Meanwhile, modeling standardization and robustness enhancement have emerged as another important direction.Jiang et al. [39] proposed the LLMOPT framework, which defines a unified five-element modeling structure consisting of sets, parameters, variables, objectives, and constraints.By combining diverse samples generated through prompt templates with expert-annotated data, the framework employs supervised fine-tuning, model alignment, and self-correction mechanisms to significantly improve modeling reliability and solution stability in complex tasks.In contrast, Lu et al. [40] introduced the OptMATH framework, which emphasizes the construction of high-quality triplet datasets encompassing natural language, mathematical expressions, and solver code, while adjusting task difficulty through a feedback mechanism.</p>
<p>In the domain of structure-guided optimization algorithm generation, Li et al. [41] proposed the STR-CMP framework, which integrates language modeling with graph structure learning.By extracting structural features through a constraint-variable bipartite graph, the framework generates solver-oriented algorithmic code conditioned jointly on natural language and structural embeddings.Leveraging supervised fine-tuning, preference optimization, and the generative-evolutionary capabilities of LLM, it iteratively optimizes performance across multiple rounds.Methodologically, it shares similarities with MA-GTS [32] in structural extraction and multi-module collaboration, while following the structure-guided code generation paradigm introduced by AEL [42].</p>
<p>In summary, the synergy between prompting and finetuning demonstrates multi-dimensional advantages across workflow design, data generation, modeling standardization, and structure-guided algorithm generation.At the methodological level, it advances the systematic mapping from natural language to structured models, while at the practical level, it provides a solid foundation for scalability and industrial deployment.This synergistic mechanism lays the groundwork for extending automatic modeling to more complex tasks and cross-domain applications in the future.</p>
<p>3) LLM-based Automatic Modeling Mechanism Guided by External Knowledge:</p>
<p>In complex modeling tasks, external knowledge guidance provides LLM with new avenues for enhancement.Jiang et al. [43] proposed the DRoC framework, which decomposes vehicle routing problems into constraint subtasks and injects precise external knowledge through semantic retrieval and document filtering.Moreover, the Bootstrap mechanism in DRoC further validates the feasibility of dynamically expanding external knowledge bases.Extending this direction, Peng et al. [44] focused on privacy-preserving and local deployment scenarios, proposing a domain knowledge-enhanced automatic modeling framework for constructing MILPs in multi-robot task allocation and scheduling problems.By guiding variable and constraint generation through knowledge bases, and combining prompt-based guidance with supervised fine-tuning, their method enables automatic generation of solver code, demonstrating strong stability and generative capability in representative scheduling tasks.</p>
<p>External knowledge guidance substantially enhances LLM's modeling capacity for complex constraints and scheduling, improving accuracy and robustness while enabling dynamic expansion and scenario adaptation, thus supporting the development of more generalizable automatic modeling frameworks.</p>
<p>4) Benchmarks for Evaluating LLM-based Automatic</p>
<p>Modeling: As the evaluation system for automatic modeling continues to mature, researchers have proposed more targeted benchmarks and frameworks from various perspectives, including industry coverage, dataset scale, structural equivalence, cross-task unification, and constraint programming adaptation.These efforts not only address the limitations of existing evaluation tools in terms of applicability and breadth but also drive the systematic assessment of automatic modeling capabilities across multiple dimensions.</p>
<p>In terms of industry adaptation and large-scale sample requirements, Huang et al. [45] proposed the OR-INSTRUCT framework and constructed the IndustryOR benchmark, which encompasses 1,556 natural language modeling problems across 16 industries, yielding a training set of 32,481 samples.The ORLM series models outperformed GPT-4 on the NL4OPT, MAMO, and IndustryOR tasks, demonstrating near-expert, human-level modeling capabilities under the Pass@8 setting.To address the limitations of small models in language understanding, Yang et al. [46] introduced the OptiBench and ReSocratic frameworks, constructing the ReSocratic-29K dataset.Through a reverse-generation strategy, they back-translated natural language problems and programs from structured modeling examples, significantly boosting the performance of the LLaMA series on MILP tasks.Recognizing the limited scope and insufficient domain coverage of existing benchmarks, Wang et al. [47] further extended OptiBench by proposing an evaluation tool comprising 816 problems across more than 80 domains, thereby strengthening crosstask and cross-domain coverage.</p>
<p>In structural equivalence, Zhai et al. [48] introduced EquivaFormulation on the NLP4LP dataset and developed the EquivaMap framework, which uses LLM to generate variable mappings and automatically assess semantic equivalence of modeling results.This addresses the limitations of traditional accuracy metrics and WL tests in complex scenarios.For cross-task evaluation, Singirikonda et al. [49] created the TEXT2ZINC dataset, standardizing on MiniZinc and covering 110 problems across 11 domains, including both optimization and satisfiability tasks.Results show that CoT reasoning and compositional modeling outperform basic prompting in generation accuracy, offering a robust benchmark for cross-paradigm evaluation.</p>
<p>In the direction of constraint programming, Michailidis et al. [50] proposed CP-Bench, which covers 101 combinatorial optimization problems and 241 types of constraints.The study systematically compared three modeling frameworks-MiniZinc, CPMpy, and OR-Tools-and introduced enhancement strategies including prompt design, in-context examples, repeated sampling, and selfverification.The results show that Python-based frameworks are more suitable for LLM-driven modeling, and that repeated sampling combined with self-verification can significantly improve solution accuracy.</p>
<p>In summary, these benchmarks and frameworks have ex- panded the evaluation dimensions of automatic modeling in terms of industry adaptation, dataset scale, structural validation, and cross-task assessment, thereby significantly advancing the systematic development of evaluation systems.Nevertheless, their limitations remain evident: task coverage is still largely confined to typical problems such as MILP and VRP, making it insufficient to capture complex constraints and heterogeneous modeling scenarios; evaluation metrics are overly centered on structural equivalence and accuracy, lacking systematic measures of efficiency, interpretability, and robustness; and some datasets rely on manual or synthetic generation, resulting in a substantial gap from real-world industrial requirements.Future research must therefore focus on developing more representative and practical benchmarks to support the evaluation of LLM's modeling capabilities in diverse and realistic settings.</p>
<p>B. LLM-assisted Optimization</p>
<p>In recent years, LLM-assisted optimization has gradually become an important research direction in the field of OR.Its core objective is to enhance the practicality and controllability of models in solving optimization problems through structural design and capability coordination [22].Figure 3 illustrates the two primary approaches to LLMassisted optimization.</p>
<p>This section systematically reviews two representative research directions: (1) LLM-enabled hybrid mechanisms for integrating multiple optimization algorithms, and (2) LLM-dominated optimization solving.It also summarizes and analyzes the related evaluation benchmarks to comprehensively present the performance and limitations of such methods in optimization tasks.</p>
<p>1) LLM-enabled Hybrid Mechanisms for Integrating Multiple Optimization Algorithms:</p>
<p>In recent years, LLM has demonstrated unique advantages in reasoning control and strategy generation, opening new avenues for their integration with diverse optimization algorithms.Existing studies show that LLM can contribute not only to operator design and search guidance but also to strategy adjustment and structural optimization.Huang et al. [51], through an analysis of structural mapping between LLM and evolutionary algorithms, revealed their synergistic potential in operator generation and search control; Cai et Liu [60] Zero-shot operator + Temperature adaptation + Natural language Liu [42], [61], [62] Structured prompt modeling + Multi-round evolutionary optimization</p>
<p>Liu &amp; Li [63] Constraint-aware heuristic construction for VRP Romera-Paredes [64] LLM program generation with evaluator, maintain search diversity Chen [65] QUTC design, UIQ-based parent selection Ye [66] Short-and long-term reflection for evolution Sun [67] Module replacement + Candidate evaluation</p>
<p>Zhong [68] Multi-module prompt-based heuristic generation Yang [69], [70] Multi-agent strategy evolution and selection Huang [71] Reflection + Scheduling rule evolution Dat [72] Role prompts + Flash reflection + Harmony</p>
<p>Huang [73] Reasoning path generation + Modular strategies Ling [74] "Explore" + "Modify" strategy Ali [75] Human preference-based selection Bömer [76] Semantic structure + Context-driven generation</p>
<p>Wu [77] Key component extraction + Performance prediction Thach [78] Language reduction + Parallel evolution Shi [79] Dual-loop mechanism Duan [80] Instance generator + Solver co-evolution al. [7] further proposed leveraging LLM as a component for structural guidance and strategy adjustment, effectively enhancing the automation and adaptability of the optimization process.Against this backdrop, this paper further reviews three representative fusion pathways: (1) heuristic structure evolution and strategy optimization;</p>
<p>(2) collaborative mechanisms in multi-objective evolution; and (3) capability transfer in cross-paradigm integration.LLM has demonstrated broad potential in its integration with evolutionary algorithms.Existing studies have examined diverse embedding methods and collaborative pathways, encompassing heuristic structure generation, strategy regulation, and the optimization of evolutionary mechanisms [52], [53], while emphasizing LLM's critical role in search guidance and strategy automation [54], [55].This direction has further extended to the joint evolution of objective functions and control modules [56], [57], revealing the behavioral patterns and performance evolution of LLM in heuristic strategy development [58], [59].Overall, this approach has established a systematic framework, with the core mechanisms of related studies summarized in Table III.</p>
<p>On direct embedding strategies, Liu et al. [60] proposed the LMEA framework, which employs LLMs as zero-shot operators for parent selection, crossover, and mutation.This approach significantly reduces the complexity of operator design and domain adaptation.Candidate solutions are generated through natural language prompts, while a temperature-adaptive mechanism balances exploration and exploitation, yielding superior performance over tra-ditional methods on multiple TSP instances.</p>
<p>Building on this idea, Liu et al. [42] introduced the AEL framework, which regards the optimization algorithm itself as the target.By using structured prompts, LLMs generate, rewrite, and refine algorithms, enabling iterative self-improvement across evolutionary rounds.Further extensions [61] applied AEL to guided local search, where LLMs automatically produce key guiding functions that outperform manually designed schemes, demonstrating strong generalization on complex TSP tasks.</p>
<p>Continuing along this trajectory, the authors developed the LLM4AD platform [62].It leverages structured prompts and search mechanisms to generate standardized, executable algorithmic code, supported by a unified evaluation pipeline that forms a complete closed loop.In domain-specific applications, Li et al. [63] proposed the ARS framework, which uses prompt engineering to construct constraint-aware heuristics for vehicle routing problems.The framework is supported by the RoutBench benchmark, which covers 1,000 VRP variants and six realworld constraints, and achieves end-to-end optimization by performing constraint selection, detection, and scoring function generation without fine-tuning.</p>
<p>On algorithm generation and evolutionary mechanisms, Romera-Paredes et al. [64] proposed the FunSearch framework, which employs LLM as a core generator to iteratively produce, evaluate, and retain high-quality solutions within the function space, while maintaining search diversity through a distributed architecture.Building on this, Chen et al. [65] introduced the QUBE framework, which incorporates a unified uncertainty-based indicator to guide parent selection and population resetting, thereby achieving a dynamic balance between structural exploration and local exploitation.Ye et al. [66] proposed the ReEvo framework, embedding a dual-layer language reflection mechanism into the heuristic evolutionary loop.After generating heuristic code, the model can suggest improvements and guide subsequent searches, enabling strategies to progressively converge toward superior solution spaces.</p>
<p>On solver module optimization, Sun et al. [67] proposed the AutoSAT framework, which decomposes CDCL solvers into modular components and leverages LLM to generate candidate functions to replace specific modules.High-quality alternatives are retained through performance evaluation, thereby progressively enhancing solver performance.On structured prompting strategies, Zhong et al. [68] introduced the CRISPE prompting strategy, composed of five submodules, to guide LLM in generating heuristic pseudocode.Based on this, they developed the metaheuristic algorithm ZSO, which demonstrated strong performance and convergence stability across CEC2014, CEC2022, and several engineering optimization problems.</p>
<p>Within multi-agent collaboration, Yang et al. [69] proposed the HeurAgenix framework, which constructs a heuristic optimization system composed of four agents-generation, evolution, evaluation, and selection-thereby extending the role of LLM from a single generator to a multi-role collaborator.Further research [70] introduced a two-stage hyper-heuristic framework that integrates solution trajectories with preference mechanisms to iteratively refine heuristic strategies, even surpassing traditional specialized optimizers.</p>
<p>For dynamic scheduling and diversity maintenance, Huang et al. [71] proposed the SeEvo framework, which treats LLM-generated scheduling rules as individuals in the population and employs both individual and collective reflection mechanisms for continuous optimization, outperforming traditional methods in dynamic scheduling tasks.Dat et al. [72] introduced the HSEvo framework, which leverages role-playing prompts to generate diverse heuristic individuals and integrates Harmony Search for local refinement, effectively enhancing adaptability while maintaining diversity.</p>
<p>In graph optimization and complex planning scenarios, Huang et al. [73] proposed the GraphThought framework, which leverages reasoning-path generation and template synthesis mechanisms to advance structural recognition and LLM-based strategy integration in graph optimization tasks.Ling et al. [74] introduced the AutoHD framework, which employs LLM to generate diverse heuristic functions and continuously evolve them, thereby improving solution quality and reasoning efficiency in complex planning tasks.</p>
<p>In the field of preference modeling and task adaptability, Ali et al. [75] proposed the PAIR framework, which incorporates human-like preference mechanisms and leverages structured prompts to perform high-quality individual pairing and crossover and mutation, thereby equipping LLM with selection and regulation capabilities in heuristic evolution.Bömer et al. [76] introduced the CEoH framework, which integrates task context with structured prompts to generate heuristic algorithms that are more targeted and adaptive.Wu et al. [77] proposed the Hercules framework, which introduces performance prediction and confidence control mechanisms to achieve a coordinated trade-off between quality and efficiency during heuristic generation and evaluation.</p>
<p>In problem reformulation and meta-optimization exploration, Thach et al. [78] proposed the RedAHD framework, which employs language-based simplification to automatically generate surrogate problems and conducts multisource evolution across multiple spaces, thereby extending the boundaries of heuristic discovery.Shi et al. [79] introduced the MoH framework, which adopts a bi-level optimization process: in the outer loop, LLM generates candidate optimizers, while in the inner loop, the optimizers generate heuristics.This approach overcomes the limitations of fixed optimizer structures and demonstrates strong generalization ability in multi-task environments.Duan et al. [80] proposed the EALG framework, which establishes an adversarial co-evolutionary system in which LLM generates problem instances and heuristic solvers separately.Driven by adversarial objectives, both evolve jointly, enhancing problem difficulty and strategy adaptability.</p>
<p>In summary, LLM in heuristic structure evolution and strategy optimization has progressed from a single gen-</p>
<p>Study Key Idea Phase I: Offspring Generation and Search Collaboration</p>
<p>Liu [81] Prompted offspring + Linear operator to reduce cost while preserving generalization</p>
<p>Wang [82] Embed LLM as search operator in CCMO + Co-evolve with classic genetic operators Liu [83] Low-cost adaptive MOEA with auxiliary evaluation + Stagnation detection + NSGA-II Phase II: Evolutionary Mechanism Construction Huang [84] LLM-generated executable mutation operators + Performance feedback</p>
<p>Yao [85] Evolve non-dominated heuristic sets with dominance + Code diversity + Guided parents + Population update Forniés-Tabuenca [86] NSGA-II guided parents + Clustering-based reflection for heuristic evolution Phase III: Unified System Framework Qian [87] Unified framework + Homogeneous crossover + Heterogeneous co-evolution + Upgrades Task-specific Applications Li [88] Portfolio MO with NSGA-II + Non-dominated sorting + Crowding distance validation erator to a full-process collaborator, advancing heuristic design from experience-driven patterns toward adaptive evolution.Building upon this foundation, research has further extended into multi-objective evolutionary optimization, where the collaborative role of LLM evolves from offspring generation to the construction of systematic frameworks, as outlined in Table IV.</p>
<p>Early studies primarily explored the auxiliary role of LLM in offspring generation and search operators.Liu et al. [81] were the first to introduce LLM into multiobjective evolutionary optimization, where the MOEA/D-LLM framework employed prompt engineering to generate offspring individuals and designed linear operators to reduce invocation costs while maintaining strong generalization performance.Wang et al. [82] embedded LLM as a novel search operator within the CCMO framework, guiding the generation of partial offspring solutions and co-evolving with traditional genetic operators, thereby accelerating convergence and improving solution quality.Subsequently, Liu et al. [83] proposed a low-cost adaptive mechanism that invokes LLM to generate candidate solutions only when evolutionary stagnation occurs, and integrates them with NSGA-II operators, thereby improving solution quality under limited computational resources.</p>
<p>With the growing generative capabilities of LLM, its role has gradually expanded to the construction of evolutionary operators and heuristic structures.Huang et al. [84] proposed an automatic operator generation framework that guides LLM to produce executable mutation operators from structured task descriptions and iteratively refines them based on performance feedback, thereby enhancing algorithm adaptability and structural flexibility.Yao et al. [85] introduced the MEoH framework, which employs a combined strategy of dominance and structural diversity to guide parent selection and population updating, automatically evolving a structurally diverse set of non-dominated heuristics.Forniés-Tabuenca et al. [86] developed the REMoH framework, which represents individuals using LLM-generated heuristic functions and incorporates NSGA-II's non-dominated sorting and crowding-distance mechanisms, while embedding a clustering-based reflection process to improve solution diversity and robustness.</p>
<p>Building on mechanism exploration, research has further advanced toward systematic integration.Qian et al. [87] proposed the MLHH framework, which unifies the evolution of heuristic structures through three steps: homogeneous crossover evolution, heterogeneous co-evolution, and architecture function upgrading.The framework executes a "generate-standardize-evaluate-select" loop iteratively, enabling the continuous optimization of highquality multi-objective solution strategies.This stage of work highlights the shift in LLM's role in multi-objective evolution from supporting localized operations to orchestrating holistic system-level coordination.</p>
<p>For real-world tasks, Li et al. [88] embedded LLM into the NSGA-II framework and proposed the llmPC-NSGA-II method for multi-objective portfolio optimization.This approach generates complete offspring populations through structured prompts and updates them using non-dominated sorting and crowding distance mechanisms.Experimental results on real financial data and standard benchmark functions demonstrate strong convergence and diversity, validating the application potential of LLM in practical OR problems.</p>
<p>Overall, the collaborative mechanisms of LLM in multiobjective optimization follow a clear trajectory from initial offspring generation to unified frameworks and real-world applications, positioning LLM as a transformative force in this domain.Moving beyond the scope of multi-objective problems, recent studies have begun to emphasize crossparadigm integration, where LLM's language understanding, structural generation, and reasoning abilities are combined with classical operators, reinforcement learning, and neuro-symbolic systems to enhance transferability and global optimization capacity.To systematically present the progress of cross-paradigm integration, Table V summarizes representative studies and their primary technical pathways.</p>
<p>Some studies have focused on coupling LLM with classical optimization operators, embedding it into traditional algorithms such as large neighborhood search (LNS) and simulated annealing to enhance search efficiency and structural adaptability.Sartori et al. proposed an LLM-based heuristic redesign approach in two studies: on the one hand, structured prompts were used to extract node features and generate probabilistic signals, which were embedded into a BRKGA decoder to achieve structure-aware metaheuristic search [89]; on the other hand, the contextual understanding capabilities of LLM were incorporated into CMSA to reconstruct heuristic functions, generating variants with age bias and entropy regularization, thereby improving structural diversity and solution quality [90].Similarly, Ye et al. [91] designed a bi-level evolutionary LNS, where the inner layer leverages LLM to generate</p>
<p>Study Key Idea Fusion with Classical Optimization</p>
<p>Sartori [89] Prompted node features + Probabilistic BRKGA decoder + Structure-aware metaheuristics Sartori [90] Heuristic context + Policy redesign + Preference correction-penalty</p>
<p>Ye [91] Bi-level evolution + NL/Code heuristics + Memory-guided evolution</p>
<p>Wang [92] SA with heuristic reconstruction and temperature adaptation Fusion with Reinforcement Learning Ma [93] Heuristic pool + RL policy selection + Feedback-driven improvement Surina [94] Program sampling + DPO-LLM optimization + Preference construction</p>
<p>Huang [95] Prompted structure + GRPO-RL optimization + Collapse-restart evolution Fusion with neuro-symbolic systems Jiang [96] Semantic encoding + RL-trained generator + Instance understanding</p>
<p>Tran [97] LLM attention bias + POMO/LEHD integration + Lightweight fine-tuning</p>
<p>Search Trajectory Control and Reasoning</p>
<p>Deng [98] Spatial prompting + Q-learning correction + Reverse curriculum learning</p>
<p>Zheng [99] Heuristic actions + Dual-call mechanism + Thought-aligned search</p>
<p>Wang [100] MCTS framework + Trajectory evaluation + State-action-reward chain heuristic strategies, while the outer layer evolves prompt templates to enhance diversity.The framework also introduces differential memory and adaptive perturbation mechanisms to balance search efficiency and convergence control.Meanwhile, Wang et al. [92] integrated LLM into simulated annealing, employing three-stage prompts to guide new solution generation and combining them with a temperature control mechanism to enhance the ability to escape local optima.Beyond traditional operators, some studies have explored the integration of LLM with RL to support strategy optimization and adaptive evolution.Ma et al. [93] proposed the AutoDH framework, which constructs a pool of heuristic functions and employs an RL agent to select the optimal function based on solution states, thereby enabling subpath optimization and feedback-driven improvement.Surina et al. [94] introduced the Evo-Tune framework, which samples high-quality candidate construction prompts during program search to guide LLM-generated programs.After performance verification, these candidates form a preference dataset used to update the language model through direct preference optimization, gradually biasing it toward generating higher-quality structures.Building on this, Huang et al. [95] proposed the CALM framework, which incorporates prompt diversification and collapse-restart mechanisms, combined with generalized reinforcement preference optimization, to continuously enhance structural generation capabilities, thereby improving stability and robustness in complex tasks.</p>
<p>At a higher level of exploration, researchers have sought to integrate LLM into neuro-symbolic systems to unify semantic representation and structural constraints.Jiang et al. [96] proposed combining LLM with Transformers to map problem instances into a unified semantic space, and employing RL to train the generator, thereby improving solution quality and diversity.Tran et al. [97] developed a neural optimizer framework in which LLM automatically generates structure-aware attention biases to guide node selection.This mechanism was integrated into multiobjective optimization and lightweight enhanced heuristic decoders, achieving cross-scale generalization under lightweight fine-tuning conditions.</p>
<p>In addition, some studies have focused on search trajectory control and reasoning mechanisms.Deng et al. [98] proposed the S2RCQL model for path planning tasks, which transforms spatial prompts into entity relationships to guide LLM in constructing path representations, and integrates Q-learning with reverse curriculum learning to reduce learning difficulty, thereby improving reasoning stability and generalization.Zheng et al. [99] introduced the MCTS-AHD framework, where LLM generates heuristic functions and semantic descriptions within MCTS, and a two-stage invocation aligns function code with conceptual descriptions to enhance semantic consistency and interpretability.In contrast, Wang et al. [100] proposed the PoH framework, which employs MCTS as the dominant component while invoking LLM at the trajectory and key-node levels for evaluation and refinement, forming a "state-action-reward" closed-loop decision process that further improves global search performance.</p>
<p>Overall, cross-paradigm integration has opened new directions for the application of LLM in optimization algorithms.From coupling with traditional operators, to deep collaboration with RL, and further to extensions into neuro-symbolic systems and reasoning mechanisms, the transfer and coordination of LLM capabilities is gradually forming a systematic pathway.</p>
<p>2) LLM-dominated Optimization Solving: In the evolution of LLM-assisted OR, research that directly leverages model generation to solve optimization problems has gradually become a frontier direction.These approaches no longer rely on traditional mathematical modeling or heuristic algorithms.Instead, they employ natural language or multimodal prompts to guide LLM in generatively addressing diverse optimization tasks [101].To systematically review their development trajectory and application characteristics, this paper classifies related studies into two categories: single-modal generative optimization methods and multimodal structure-aware methods, which will be further analyzed through representative works in the following sections.</p>
<p>Single-modal generative optimization methods leverage natural language or structured text prompts to directly guide LLM in producing optimization solutions, thereby eliminating the dependence on gradient information and explicit modeling processes.These methods demonstrate advantages such as generality, interactive flexibility, and</p>
<p>Study Key Mechanism Phase I: Direct Solving by LLM</p>
<p>Yang [102] NL prompting + Meta-prompt iteration Phase II: Fusion-driven Techniques Guo [103] CoT + Historical prompts + Interactive optimization Liu [104] State prediction + Utility modeling + Preference ranking Huang [105] NL-to-Python + Self-debugging and verification Masoud [106] Prompt-driven + Multi-sampling + Self-ensemble Iklassov [107] Meta-prompt + Multi-trajectory + Recursive subtask optimization Zhong [108] Self-evolving prompt + Accuracy loop Zhang [109] SFT + RLF + RAG Jiang [110] Structural prompt + Multi-round opt.+ Knowledge integration Phase III: Exploring LLM's Solving Capacity Abgaryan [111] Constraint-aware output + Dynamic control ease of transfer.Related studies have undergone an evolutionary process from direct solving to technique-enhanced approaches, and further to unified solving of complex constraints.Their core mechanisms and application tasks are summarized in Table VI.</p>
<p>Early studies primarily focused on direct solving, aiming to validate the black-box optimization capability of LLM under a "zero-modeling" setting.A representative example is the OPRO method proposed by Yang et al. [102], which requires neither gradients nor heuristic operators but relies solely on natural language descriptions and historical solution feedback to construct meta-prompts that guide iterative solution generation by the LLM.In both continuous and combinatorial optimization tasks, OPRO demonstrated the potential for autonomous exploration of the solution space and achieved measurable improvements in accuracy in language reasoning tasks, indicating that LLM can perform basic optimization without external tool support.However, the limited performance of such methods in complex structures and multi-round tasks has driven research toward the incorporation of enhancement mechanisms.</p>
<p>Subsequent studies have progressively enhanced the solving capabilities of LLM in a gradual manner.Early improvements focused on reasoning support and trajectory interpretability, such as combining CoT reasoning with iterative prompting to accumulate the dialogue history as a traceable "optimization memory," thereby enabling the transition from "one-shot generation" to "interactive convergence" under a unified evaluation framework [103].On the other hand, researchers have investigated decisionmaking in uncertain environments.By incorporating state prediction, utility modeling, and preference ranking, LLM can simulate the process of expected utility maximization and adaptively balance gains and risks across multiple rounds of feedback, demonstrating greater robustness in real-world domains such as agriculture and finance [104].In addition, the work of Huang et al. [105] achieved end-to-end closed-loop solving by transforming natural language descriptions into executable code and integrating selfdebugging and self-verification mechanisms in the feedback loop to ensure the feasibility and stability of generated solutions.In vehicle routing problem experiments, this method demonstrated that even without manual modeling or traditional heuristic support, LLM possesses strong zero-shot optimization capabilities.</p>
<p>Beyond closed-loop design, studies have also sought to improve solution diversity and stability.Masoud et al. [106] proposed a self-ensemble strategy that mitigates local convergence through multi-round sampling and selection, enabling cross-scale generalization in tasks such as the TSP.Other work explored trajectory generation and recursive decomposition, where meta-prompts produce multiple strategies that are decomposed into subtasks and recursively optimized, extending solution scope and diversity across combinatorial, scheduling, and symbolic reasoning tasks [107].Zhong et al. [108] further introduced a self-evolving prompt mechanism driven by accuracy feedback, in which iterative "generate-evaluate-update" cycles refine prompt design, sustaining stable performance in high-dimensional structural search and supporting crossscale generalization.</p>
<p>With research progress, structured input scenarios have attracted growing attention.Zhang et al. [109] built a large-scale graph-task-code dataset and introduced a twostage training process with retrieval-augmented mechanisms, enabling LLM to map natural language graph tasks to executable code and achieve cross-task generalization.Jiang et al. [110] addressed the structural matrix ordering problem using prompts based on network topology, node descriptions, and semantic context to guide LLM in generating node sequences without gradients or operators, while applying multi-round iterative optimization to accelerate convergence and improve solution quality.These advances highlight the ability of single-modal generative approaches to handle higher-dimensional structural problems.</p>
<p>Researchers have increasingly focused on unified solving under complex constraints.Abgaryan et al. [111] proposed the ACCORD framework, which embeds constraint control into the output format to ensure satisfaction during decoding.Combined with task identification and LoRA routing, ACCORD enables unified solving across multiple NP-hard problem classes.This work highlights the potential of LLM in tackling optimization tasks with complex constraints and diverse problem types, offering a new perspective for general-purpose language-based optimizers.</p>
<p>In summary, single-modal methods have advanced from direct generation to reasoning-and feedback-enhanced solving, but remain limited in capturing complex structures and multi-source information.To address this gap, multimodal structure-aware approaches integrate visual and linguistic inputs to improve spatial perception and structural consistency, showing particular promise for tasks such as path planning and scheduling.The following section extends this discussion to other pathways, highlighting how external knowledge and hybrid mechanisms further enhance the modeling and solving capabilities of LLM in OR.</p>
<p>In structure-aware multimodal approaches, Huang et al. [112] proposed the MLLM-V framework, which integrates text and image prompts for solving the capacitated vehicle routing problem, simulating human cognitive processes through heuristic extraction, solution generation, and feedback refinement.This demonstrates the value of visual information in enhancing the quality and generalization of generative optimization.Building on this line, Elhenawy et al. [113] introduced a multimodal reasoning framework that combines image inputs with natural language prompts, enabling LLM to intuitively solve the traveling salesman problem (TSP) and progressively refine path structures through adaptive mechanisms, thereby highlighting the potential of multimodal inputs.Furthermore, Elhenawy et al. [114] proposed a purely visiondriven framework with both three-stage and dual-agent collaborative architectures, capable of generating solutions for TSP and multiple TSP without relying on coordinates or distance matrices, underscoring the promise of visual perception in complex structural optimization.</p>
<p>Overall, multimodal structure-aware approaches enhance LLM-based optimization by integrating visual and linguistic inputs, thereby improving structural understanding, stability, and generalization.Compared with single-modal methods, they offer complementary mechanisms that drive the evolution of optimization, and are expected to extend to broader inputs such as tabular and sensor data for more versatile systems.</p>
<p>3) Benchmarks for Evaluating LLM-assisted Optimization: To systematically evaluate the role of LLM in solving optimization problems, researchers have proposed a series of evaluation benchmarks.Unlike traditional tests that primarily assess modeling outcomes, these benchmarks place greater emphasis on reasoning and decision-making capabilities within complex optimization processes, covering a wide range of tasks such as graph-structured reasoning, path planning, task generation, optimization interpretation, and strategy improvement.</p>
<p>For graph reasoning, Wang et al. [115] proposed the NLGraph benchmark, which contains 29,370 problems spanning eight categories of graph reasoning tasks, providing an important tool for solving graph problems in natural language settings.For path planning in spatiotemporal reasoning, Aghzal et al. [116] constructed the PPNL benchmark, which simulates grid-world path planning scenarios to systematically evaluate model performance across varying prompt strategies and task complexities.Focusing on plan reasoning in asynchronous multi-step tasks, Lin et al. [117] introduced the AsyncHow benchmark, which includes 1,600 high-quality instances across multiple common domains such as education, diet, health, and household activities.</p>
<p>In graph computation tasks, Tang et al. [118] proposed the GraphArena benchmark, which employs a three-stage evaluation process consisting of path extraction, feasibility verification, and optimality checking.It covers four classes of polynomial-time tasks and six classes of NPcomplete problems.This benchmark not only provides detailed distinctions between correct, suboptimal, hallucinatory, and missing outputs but also enhances the interpretability and diagnostic capability of the reasoning process.The authors further explored four enhancement strategies-CoT prompting, instruction fine-tuning, code generation, and reasoning augmentation-examining their applicability limits and potential utility in complex graph problems.</p>
<p>For the systematic evaluation of reasoning capabilities in OR, Mostajabdaveh et al. [119] proposed the ORQA benchmark, which consists of 1,513 multiple-choice questions spanning 20 application domains in OR.To analyze the importance of interpretability in optimization processes, Zhang et al. [120] constructed the first industrialscale dataset for explainable optimization, covering 30 problem types and 300 queries, and introduced the EOR framework.This framework incorporates the concept of "decision information" and combines what-if analysis with graph-structured modeling.Through the collaboration of three agent modules-Commander, Writer, and Safeguard-it generates dual outputs of code modification explanations and result variation explanations, offering a new pathway to enhance the interpretability of LLM in optimization tasks.</p>
<p>For evaluating algorithm generation and end-to-end task execution in combinatorial optimization, Sun et al. [121] proposed CO-Bench, which encompasses 36 realworld problem classes, including bin packing, cutting, location, path planning, and tree-structure optimization.</p>
<p>The benchmark provides natural language descriptions, data-loading functions, and evaluation functions, forming a complete workflow spanning data reading, algorithm design, and performance evaluation.Building on this, Feng et al. [122] developed the FrontierCO benchmark, which systematically evaluates an LLM solver across eight combinatorial optimization tasks.Results indicate that the LLM solver is generally more robust and exhibits stronger generalization capability compared to neural approaches, and in certain tasks, it rivals or even surpasses state-ofthe-art heuristic methods.However, its performance fluctuates significantly across tasks, revealing shortcomings in algorithm selection and integration scheduling.</p>
<p>To validate the intelligence of LLM in heuristic design, Chen et al. [123] proposed the HeuriGym framework, which employs an iterative mechanism of "prompt generation-code execution-error feedback-multi-round refinement."The framework establishes a benchmark covering nine real-world tasks and introduces the Quality-Yield Index as a core metric, comprehensively evaluating the reasoning ability of the intelligent agent through success rate and relative solution quality.Focusing on long-term goaldriven structural optimization, Imajuku et al. [124] developed ALE-Bench, constructed on the AtCoder Heuristic Contest, encompassing NP-hard problems such as path planning and production scheduling.It is equipped with scorers, visualization tools, and expert evaluation systems to assess LLM's optimization ability under both singleround and multi-round iterations.</p>
<p>For large-scale search spaces, Li et al. [125] proposed OPT-BENCH, which covers 20 real-world machine learning tasks and 10 classical NP-hard combinatorial optimization problems.Accompanying it, the OPT-Agent framework simulates the human problem-solving process of "draft-optimize-debug," supporting the entire pipeline from initial solution generation to stepwise refinement based on feedback, thereby forming a fully automated workflow that integrates task definitions, datasets, metrics, and validation scripts.</p>
<p>Overall, existing benchmarks provide essential tools for evaluating LLM in optimization, supporting their transition from modeling assistants to intelligent collaborators.Yet they remain limited in task diversity, evaluation dimensions, and realism, with most focusing on static combinatorial problems and narrow metrics.Future work should expand coverage to dynamic, multimodal, and cross-domain scenarios, while establishing unified, integrated benchmarks that capture efficiency, stability, and interpretability in real-world settings.</p>
<p>IV. Domain Problems</p>
<p>With increasingly complex real-world application scenarios, the demand for optimization methods continues to grow, further exposing the limitations of traditional OR regarding modeling complexity, interactivity, and interpretability.The introduction of LLM offers new perspectives for addressing these challenges, not only enhancing problem analysis and knowledge representation but also demonstrating potential advantages in interactive processes and result presentation [126].Therefore, this section, together with the methodological pathways, systematically discusses the practical applications and future trends of LLM in typical scenarios.</p>
<p>A. Supply Chain</p>
<p>In supply chain optimization, LLM enhances interpretability by bridging natural language with solver execution.OptiGuide [127], which integrates GPT-4 with an optimizer, exemplifies the prompt-driven modeling pathway: it translates user requirements into optimization expressions, forms a closed feedback loop, and achieves over 90% accuracy in Microsoft Azure practice.Complementing such applications, a theoretical framework [128] systematically mapped LLM functions across supply chain stages, highlighting roles in supplier evaluation, forecasting, routing, and sustainability.Together, these studies demonstrate how LLM extends automatic modeling toward structured decision support and foreshadow external knowledge-guided mechanisms in OR.</p>
<p>B. Urban Planning</p>
<p>As urban systems continue to evolve, governance processes face increasingly complex challenges.While traditional OR methods possess strong theoretical rigor, their practical application in smart cities characterized by multi-source data and high-frequency responsiveness remains challenging.By combining reasoning and language understanding capabilities, LLM offers a novel pathway for complex decision-making in urban contexts.The City-LEO framework [129] integrates LLM reasoning with endto-end optimization, interpreting users' natural language requirements and leveraging historical data to generate relevant objective functions and reduce problem scale.At the same time, by combining random forests with mixedinteger programming, the framework enables interpretable mappings from features to decisions, producing solutions with higher computational efficiency and greater transparency.Experimental results show that the framework outperforms traditional methods in computational efficiency, global suboptimality control, and local satisfaction improvement, highlighting the synergistic effect of LLM and traditional optimization algorithms under a hybrid paradigm.</p>
<p>C. Food Science</p>
<p>In the domain of sustainable food management, traditional OR approaches are increasingly constrained by modeling complexity, high expertise requirements, and limited interpretability.Recent researcher [130] have proposed a framework that integrates the knowledge of LLM with human preference modeling capabilities, coupled with combinatorial optimization techniques, to construct a complete workflow that transforms natural language inputs into optimized decision-making outputs.Experimental evaluations demonstrate that this framework can substantially reduce greenhouse gas emissions while preserving overall user satisfaction, thereby underscoring the fusion of prompt-driven pathways with structural mapping mechanisms as a promising direction for intelligent optimization.</p>
<p>D. Job Shop Scheduling</p>
<p>The Job Shop Scheduling Problem (JSSP) is one of the most challenging tasks in OR, having long attracted attention due to its strong constraints and combinatorial complexity.In recent years, researchers have explored incorporating LLM into JSSP solution frameworks.One line of work constructed a large-scale dataset comprising 120,000 randomly generated natural language descriptions and feasible solutions, and employed LoRA to fine-tune the Phi-3-Mini model while introducing sampling strategies to enhance scheduling performance [131].Subsequently, the authors introduced the Starjob dataset, extended the approach to the LLaMA model, and completed single-GPU training via Rank-Stabilized LoRA.On the Tai and DMU benchmarks, their method significantly outperformed traditional heuristic and neural network baselines [132].Collectively, these explorations highlight the potential of integrating model fine-tuning mechanisms with structured task prompting, providing new ideas for intelligent solving of complex scheduling problems.</p>
<p>E. Communication and Networking</p>
<p>In mobile edge computing optimization, researchers have undertaken diverse explorations across related tasks.For server allocation, researchers have proposed a natural language interaction framework that leverages multiround prompting and feedback to guide LLM in generating user-server assignment schemes that satisfy constraints while minimizing latency [133].In the task of wireless access point deployment, the LMCO framework employs structured prompts to generate deployment schemes and incorporates ray-tracing evaluation and propagation knowledge to accelerate convergence [134].For critical node identification, the problem has been reformulated as a score-function generation task, leading to the design of an LLM-driven evolutionary optimization framework for automatically identifying the most important nodes in communication networks [135].At the system level, further studies have explored the potential of LLM in resource scheduling, prompt design, and heuristic strategy generation, embedding them into multiple optimization paradigms and thereby extending its application boundaries in intelligent communication systems [136].</p>
<p>V. Conclusion and Outlook</p>
<p>With the continuous advancement of LLM in natural language understanding, structural generation, and reasoning control, its role in OR is shifting from exploratory studies to paradigm reconstruction and system integration.This paper reviewed three core research pathways-automatic modeling, assisted optimization, and direct solving.LLM has demonstrated capabilities in translating natural language into structured models, generating heuristics and strategies for complex optimization tasks, and enabling end-to-end problem solving.Despite these advances, key challenges remain: unstable semantic-structure mapping; fragmented research outcomes without a unified framework; limited generalization and interpretability; insufficient evaluation tools and benchmarks; and high computational cost for large-scale deployment.Addressing these issues requires progress in robust representation and closed-loop mechanisms, standardization of task abstractions and workflows, integration of symbolic reasoning and causal analysis, development of multidimensional benchmarks, and exploration of lightweight deployment strategies.Overall, research on LLM-enabled OR is entering a stage of systematic development.By advancing methodological innovation, enhancing interpretability, and establishing comprehensive evaluation systems, LLM is expected to drive the construction of next-generation intelligent optimization systems.</p>
<p>Fig. 1 .
1
Fig. 1.Literature classification map of LLM-driven OR research pathways and representative works.</p>
<p>Fig. 2 .
2
Fig. 2. Closed-loop framework of automatic modeling from natural language input to model execution.</p>
<p>Fig. 3 .
3
Fig. 3. Two primary approaches to LLM-assisted optimization.</p>
<p>TABLE I
I
Representative Studies on Prompt-based LLM Automatic Modeling
FrameworkKey Modeling TraitsBenchmarksOptiMUS</p>
<p>TABLE III Representative
III
Studies on LLM-driven Heuristic Structure Evolution and Strategy Optimization
StudyCore Mechanism</p>
<p>TABLE V
V
Representative Studies on LLM Capability Transfer and Synergy in Cross-paradigm Fusion</p>
<p>Large Language Models for Combinatorial Optimization: A Systematic Review. F Da Ros, M Soprano, Di Gaspero, L , arXiv:2507.036372025arXiv preprint</p>
<p>A systematic survey on large language models for algorithm design. F Liu, Y Yao, P Guo, arXiv:2410.147162024arXiv preprint</p>
<p>Learning combinatorial optimization algorithms over graphs. E Khalil, H Dai, Y Zhang, Advances in neural information processing systems. 201730</p>
<p>Nl4opt competition: Formulating optimization problems based on their natural language descriptions[C]. NeurIPS 2022 competition track. R Ramamonjison, T Yu, R Li, PMLR. 2023</p>
<p>Artificial intelligence for operations research: Revolutionizing the operations research process. Z Fan, B Ghaddar, X Wang, arXiv:2401.032442024arXiv preprint</p>
<p>Combinatorial Optimization for All: Using LLMs to Aid Non-Experts in Improving Optimization Algorithms. C Sartori, C Blum, C , arXiv:2503.109682025arXiv preprint</p>
<p>Exploring the improvement of evolutionary computation via large language models[C]. Proceedings of the Genetic and Evolutionary Computation Conference Companion. J Cai, J Xu, J Li, 2024</p>
<p>Llm-planner: Few-shot grounded planning for embodied agents with large language models. C H Song, J Wu, C Washington, Proceedings of the IEEE/CVF international conference on computer vision. the IEEE/CVF international conference on computer vision2023</p>
<p>Z Xiao, J Xie, L Xu, S Guan, J Zhu, X Han, . . Zhang, D , arXiv:2508.10047A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions. 2025arXiv preprint</p>
<p>A Systematic Survey on Large Language Models for Evolutionary Optimization: From Modeling to Solving. Y Zhang, R Cheng, G Yi, K C Tan, arXiv:2509.082692025arXiv preprint</p>
<p>Introduction to operations research. A Kaufmann, R Faure, H C Sneyd, 1968</p>
<p>Operations research: applications and algorithms. E Zieyel, 1988</p>
<p>. D Bertsimas, J Tsitsiklis, Introduction to linear optimization[M</p>
<p>M A Belmont, Athena scientific. 1997</p>
<p>Integer and combinatorial optimization. L A Wolsey, G L Nemhauser, </p>
<p>C Papadimitriou, H Steiglitz, K , Combinatorial optimization: algorithms and complexity. </p>
<p>Multi-objective optimization using evolutionary algorithms. K Deb, 2001John Wiley &amp; Sons</p>
<p>Language models are fewshot learners. T Brown, B Mann, N Ryder, Advances in neural information processing systems. 202033</p>
<p>Gpt-4 technical. J Achiam, S Adler, S Agarwal, arXiv:2303.087742023arXiv preprint</p>
<p>Llms for mathematical modeling: Towards bridging the gap between natural and mathematical languages. X Huang, Q Shen, Y Hu, arXiv:2405.131442024arXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, 202235Advances in neural information processing systems</p>
<p>Self-consistency improves chain of thought reasoning in language models. X Wang, J Wei, D Schuurmans, arXiv:2203.111712022arXiv preprint</p>
<p>Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design. Z Li, L Li, S Lin, arXiv:2505.169792025arXiv preprint</p>
<p>Promptrobust: Towards evaluating the robustness of large language models on adversarial. K Zhu, J Wang, J Zhou, Proceedings of the 1st ACM workshop on large AI systems and models with privacy and safety analysis. the 1st ACM workshop on large AI systems and models with privacy and safety analysis2023</p>
<p>Self-refine: Iterative refinement with self-feedback. A Madaan, N Tandon, P Gupta, Advances in Neural Information Processing Systems. 202336</p>
<p>Optimization modeling using mip solvers and large language models. A Ahmaditeshnizi, W Gao, Udell M Optimus, arXiv:2310.061162023arXiv preprint</p>
<p>Optimus: Scalable optimization modeling with (mi) lp solvers and large language models. A Ahmaditeshnizi, W Gao, M Udell, arXiv:2402.101722024arXiv preprint</p>
<p>OptiMUS-0.3: Using large language models to model and solve optimization problems at scale. A Ahmaditeshnizi, W Gao, H Brunborg, arXiv:2407.196332024arXiv preprint</p>
<p>Chain-of-experts: When llms meet complex operations research problems. Z Xiao, D Zhang, Y Wu, The twelfth international conference on learning representations. 2023</p>
<p>Solving general naturallanguage-description optimization problems with large language models. J Zhang, W Wang, S Guo, arXiv:2407.079242024arXiv preprint</p>
<p>Abstract Operations Research Modeling Using Natural Language Inputs. J Li, R Wickman, S Bhatnagar, </p>
<p>Information. 202516128</p>
<p>Autoformulation of mathematical optimization models using llms. N Astorga, T Liu, Y Xiao, arXiv:2411.016792024arXiv preprint</p>
<p>MA-GTS: A Multi-Agent Framework for Solving Complex Graph Problems in Real-World Applications. Z Yuan, M Liu, H Wang, arXiv:2502.185402025arXiv preprint</p>
<p>Or-llm-agent: Automating modeling and solving of operations research optimization problem with reasoning large language model. B Zhang, P Luo, arXiv:2503.100092025arXiv preprint</p>
<p>From large language models and optimization to decision optimization copilot: A research manifesto. S Wasserkrug, L Boussioux, D Hertog, arXiv:2402.162692024arXiv preprint</p>
<p>Language Models for Business Optimisation with a Real World Case Study in Production Scheduling. P Amarasinghe, T Nguyen, S Sun, Y Alahakoon, D , 2023</p>
<p>Synthesizing mixed-integer linear programming models from natural language descriptions. Q Li, L Zhang, V , </p>
<p>Llamoco: Instruction tuning of large language models for optimization code generation. Z Ma, H Guo, J Chen, </p>
<p>Evo-Step: Evolutionary Generation and Stepwise Validation for Optimizing LLMs in OR. Y Wu, Y Zhang, Y Wu, </p>
<p>LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch. C Jiang, X Shu, H Qian, </p>
<p>Optmath: A scalable bidirectional data synthesis framework for optimization modeling. H Lu, Z Xie, Y Wu, arXiv:2502.111022025arXiv preprint</p>
<p>STRCMP: Integrating Graph Structural Priors with Language Models for Combinatorial Optimization. X Li, J Yang, J Wang, arXiv:2506.110572025arXiv preprint</p>
<p>Algorithm evolution using large language model. F Liu, X Tong, M Yuan, arXiv:2311.152492023arXiv preprint</p>
<p>DRoC: Elevating large language models for complex vehicle routing via decomposed retrieval of constraints. X Jiang, Y Wu, C Zhang, 13th international Conference on Learning Representations, ICLR 2025. OpenReview. net. 2025</p>
<p>Automatic milp model construction for multi-robot task allocation and scheduling based on large language models. M Peng, Z Chen, J Yang, arXiv:2503.138132025arXiv preprint</p>
<p>Orlm: A customizable framework in training large models for automated optimization modeling. C Huang, Z Tang, S Hu, </p>
<p>. Operations Research. 2025</p>
<p>Optibench meets resocratic: Measure and improve llms for optimization modeling. Z Yang, Y Wang, Y Huang, arXiv:2407.098872024arXiv preprint</p>
<p>OptiBench: benchmarking large language models in optimization modeling with equivalencedetection evaluation. Z Wang, Z Zhu, Y Han, 2024</p>
<p>Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations. H Zhai, C Lawless, E Vitercik, arXiv:2502.147602025arXiv preprint</p>
<p>Text2Zinc: A Cross-Domain Dataset for Modeling Optimization and Satisfaction Problems in MiniZinc. A Singirikonda, S Kadioglu, K Uppuluri, arXiv:2503.106422025arXiv preprint</p>
<p>CP-Bench: Evaluating Large Language Models for Constraint Modelling. K Michailidis, D Tsouros, T Guns, arXiv:2506.060522025arXiv preprint</p>
<p>When large language model meets optimization. S Huang, K Yang, S Qi, Swarm and Evolutionary Computation. 901016632024</p>
<p>Understanding the importance of evolutionary search in automated heuristic design with large language. R Zhang, F Liu, X Lin, International Conference on Parallel Problem Solving from Nature. Cham; Nature SwitzerlandSpringer2024</p>
<p>Evolution through large models[M]//Handbook of evolutionary machine learning. Singapore. J Lehman, J Gordon, S Jain, Springer Nature2023Singapore</p>
<p>Deep insights into automated optimization with large language models and evolutionary algorithms. H Yu, J Liu, arXiv:2410.208482024arXiv preprint</p>
<p>When large language models meet evolutionary algorithms: Potential enhancements and challenges. C Wang, J Zhao, L Jiao, </p>
<p>. Research. 86462025</p>
<p>Evolve cost-aware acquisition functions using large language models. Y Yao, F Liu, J Cheng, International Conference on Parallel Problem Solving from Nature. ChamSpringer Nature Switzerland2024</p>
<p>Evolutionary computation in the era of large language model: Survey and roadmap. X Wu, S Wu, J Wu, IEEE Transactions on Evolutionary Computation. 2024</p>
<p>Code evolution graphs: Understanding large language model driven design of algorithms. N Van Stein, V Kononova, A Kotthoff, L , Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation Conference2025</p>
<p>Fitness Landscape of Large Language Model-Assisted Automated Algorithm Search. F Liu, Q Zhang, X Tong, arXiv:2504.196362025arXiv preprint</p>
<p>Large language models as evolutionary optimizers[C]. 2024 IEEE Congress on Evolutionary Computation (CEC). S Liu, C Chen, X Qu, IEEE2024</p>
<p>An example of evolutionary computation + large language model beating human: Design of efficient guided local search. F Liu, X Tong, M Yuan, </p>
<p>. Corr, 2024</p>
<p>Llm4ad: A platform for algorithm design with large language model. F Liu, R Zhang, Z Xie, arXiv:2412.172872024arXiv preprint</p>
<p>ARS: Automatic Routing Solver with Large Language Models. K Li, F Liu, Z Wang, arXiv:2502.153592025arXiv preprint</p>
<p>Mathematical discoveries from program search with large language models. B Romera-Paredes, M Barekatain, A Novikov, </p>
<p>. Nature. 62579952024</p>
<p>Qube: Enhancing automatic heuristic design via quality-uncertainty balanced evolution. Z Chen, Z Zhou, Y Lu, </p>
<p>Large language models as hyper-heuristics with reflective evolution. H Ye, J Wang, Z Cao, Advances in neural information processing systems. 202437</p>
<p>Autosat: Automatically optimize sat solvers via large language models. Y Sun, F Ye, X Zhang, arXiv:2402.107052024arXiv preprint</p>
<p>Leveraging large language model to generate a novel metaheuristic algorithm with CRISPE framework. R Zhong, Y Xu, C Zhang, </p>
<p>Cluster Computing. 202427</p>
<p>HeurAgenix: A Multi-Agent LLM-Based Paradigm for Adaptive Heuristic Evolution and Selection in Combinatorial Optimization. X Yang, L Song, Y Zhang, </p>
<p>Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges. X Yang, L Zhang, H Qian, arXiv:2506.151962025arXiv preprint</p>
<p>Automatic programming via large language models with population self-evolution for dynamic job shop scheduling problem. J Huang, X Li, L Gao, arXiv:2410.226572024arXiv preprint</p>
<p>Elevating automatic heuristic design with diversity-driven harmony search and genetic algorithm using llms. P V T Dat, L Doan, H Binh, T Hsevo, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2025</p>
<p>GraphThought: Graph Combinatorial Optimization with Thought Generation. Z Huang, L Guo, W Li, arXiv:2502.116072025arXiv preprint</p>
<p>Complex LLM planning via automated heuristics discovery. H Ling, S Parashar, S Khurana, arXiv:2502.192952025arXiv preprint</p>
<p>PAIR: A Novel Large Language Model-Guided Selection Strategy for Evolutionary Algorithms. S Ali, M Ashraf, S Hegazy, arXiv:2503.032392025arXiv preprint</p>
<p>Leveraging large language models to develop heuristics for emerging optimization problems. T Bömer, N Koltermann, M Disselnmeyer, arXiv:2503.033502025arXiv preprint</p>
<p>Efficient heuristics generation for solving combinatorial optimization problems using large language models. X Wu, D Wang, C Wu, Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V. the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V2</p>
<p>RedAHD: Reduction-Based End-to-End Automatic Heuristic Design with Large Language Models. N Thach, A Riahifar, N Huynh, arXiv:2505.202422025arXiv preprint</p>
<p>Generalizable Heuristic Generation Through Large Language Models with Meta-Optimization. Y Shi, J Zhou, W Song, arXiv:2505.208812025arXiv preprint</p>
<p>EALG: Evolutionary Adversarial Generation of Language Model-Guided Generators for Combinatorial Optimization. R Duan, Y Liu, X Dong, arXiv:2506.025942025arXiv preprint</p>
<p>Large language model for multiobjective evolutionary optimization[C]. International Conference on Evolutionary Multi-Criterion Optimization. F Liu, X Lin, S Yao, Springer Nature2025Singapore; Singapore</p>
<p>Large language model-aided evolutionary search for constrained multiobjective optimization. Z Wang, S Liu, J Chen, International Conference on Intelligent Computing. Singapore; SingaporeSpringer Nature2024</p>
<p>Large language model aided multiobjective evolutionary algorithm: a low-cost adaptive approach. W Liu, L Chen, Z Tang, arXiv:2410.023012024arXiv preprint</p>
<p>Autonomous multi-objective optimization using large language model. Y Huang, S Wu, W Zhang, IEEE Transactions on Evolutionary Computation. 2025</p>
<p>Multi-objective evolution of heuristic using large language model. S Yao, F Liu, X Lin, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2025</p>
<p>REMoH: A Reflective Evolution of Multi-objective Heuristics approach via Large Language Models. D Forniés-Tabuenca, A Uribe, U Otamendi, arXiv:2506.077592025arXiv preprint</p>
<p>Unifying All Species: LLM-based Hyper-Heuristics for Multi-objective Optimization. H Qian, S Dong, H Yu, </p>
<p>Generative Evolution Attacks Portfolio Selection[C]. 2024 IEEE Congress on Evolutionary Computation (CEC). C Li, Z Han, J Jiang, IEEE2024</p>
<p>Rodríguez Corominas G, Metaheuristics and Large Language Models Join Forces: Toward an Integrated Optimization Approach. C Sartori, C Blum, C Bistaffa, F , IEEE Access. 132025</p>
<p>Improving existing optimization algorithms with llms. C Sartori, C Blum, C , arXiv:2502.082982025arXiv preprint</p>
<p>Large Language Model-driven Large Neighborhood Search for Large-Scale MILP Problems. H Ye, H Xu, A Yan, </p>
<p>Forty-second International Conference on Machine Learning. 2025</p>
<p>Large Language Model Implemented Simulated Annealing Algorithm for Traveling Salesman Problem. D Wang, Z Zhang, Y Teng, 2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC). IEEE2024</p>
<p>Automatic Algorithm Design Assisted by LLMs for Solving Vehicle Routing Problems. L Ma, X Hao, R Yang, 2024 IEEE 17th International Conference on Signal Processing. IEEE2024</p>
<p>Algorithm discovery with llms: Evolutionary search meets reinforcement learning. A Surina, A Mansouri, L Quaedvlieg, arXiv:2504.051082025arXiv preprint</p>
<p>Calm: Co-evolution of algorithms and language model for automatic heuristic design. Z Huang, W Wu, K Wu, arXiv:2505.122852025arXiv preprint</p>
<p>Bridging Large Language Models and Optimization: A Unified Framework for Text-attributed Combinatorial Optimization. X Jiang, Y Wu, Y Wang, arXiv:2408.122142024arXiv preprint</p>
<p>Large language models powered neural solvers for generalized vehicle routing problems. C D Tran, Q Nguyen-Tri, H T T Binh, Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation. </p>
<p>Can LLM be a good path planner based on prompt engineering? mitigating the hallucination for path. H Deng, H Zhang, J Ou, International Conference on Intelligent Computing. Singapore; SingaporeSpringer Nature2025</p>
<p>Monte carlo tree search for comprehensive exploration in llm-based automatic heuristic design. Z Zheng, Z Xie, Z Wang, arXiv:2501.086032025arXiv preprint</p>
<p>Planning of Heuristics: Strategic Planning on Large Language Models with Monte Carlo Tree Search for Automating Heuristic Optimization. H Wang, X Zhang, C Mu, arXiv:2502.114222025arXiv preprint</p>
<p>Using large language models for hyperparameter optimization. M Zhang, R Desai, N Bae, J , arXiv:2312.045282023arXiv preprint</p>
<p>Large language models as optimizers. C Yang, X Wang, Y Lu, The Twelfth International Conference on Learning Representations. 2023</p>
<p>Towards optimizing with large language models. P F Guo, Y H Chen, Y D Tsai, arXiv:2310.052042023arXiv preprint</p>
<p>Decision making under uncertainty with large language models. O Liu, D Fu, D Yogatama, arXiv:2402.023922024arXiv preprint</p>
<p>Large Language Models Solve Robot Routing. Z Huang, G Shi, G S Sukhatme, Can, arXiv:2403.107952024arXiv preprint</p>
<p>Exploring combinatorial problem solving with large language models: A case study on the travelling salesman problem using gpt-3.5 turbo. M Masoud, A Abdelhay, M Elhenawy, arXiv:2405.019972024arXiv preprint</p>
<p>Self-guiding exploration for combinatorial problems. Z Iklassov, Y Du, F Akimov, Advances in Neural Information Processing Systems. 202437</p>
<p>Large language model assisted adversarial robustness neural architecture search. R Zhong, Y Cao, J Yu, 2024 6th International Conference on Data-driven Optimization of Complex Systems (DOCS). IEEE2024</p>
<p>Improving large language model for generalized graph problem solving. Q Zhang, X Hong, J Tang, arXiv:2410.190842024arXiv preprint</p>
<p>Large language models for combinatorial optimization of design structure matrix. S Jiang, M Xie, J Luo, arXiv:2411.125712024arXiv preprint</p>
<p>ACCORD: Autoregressive Constraint-satisfying Generation for COmbinatorial Optimization with Routing and Dynamic attention. H Abgaryan, T Cazenave, A Harutyunyan, arXiv:2506.110522025arXiv preprint</p>
<p>How multimodal integration boost the performance of llm for optimization: Case study on capacitated vehicle routing problems. Y Huang, W Zhang, L Feng, 2025 IEEE Symposium for Multidisciplinary Computational Intelligence Incubators (MCII). IEEE</p>
<p>Eyeballing combinatorial problems: A case study of using multimodal large language models to solve traveling salesman problems. M Elhenawy, A Abdelhay, T I Alhadidi, </p>
<p>International Conference on Intelligent Systems, Blockchain, and Communication Technologies. ChamSpringer Nature Switzerland2024</p>
<p>Visual reasoning and multi-agent approach in multimodal large language models (mllms): Solving tsp and mtsp combinatorial challenges. M Elhenawy, A Abutahoun, T I Alhadidi, arXiv:2407.000922024arXiv preprint</p>
<p>Can language models solve graph problems in natural language. H Wang, S Feng, T He, Advances in Neural Information Processing Systems. 202336</p>
<p>Can large language models be good path planners? a benchmark and investigation on spatialtemporal reasoning. M Aghzal, E Plaku, Z Yao, arXiv:2310.032492023arXiv preprint</p>
<p>Graph-enhanced large language models in asynchronous plan reasoning. F Lin, La Malfa, E Hofmann, V , arXiv:2402.028052024arXiv preprint</p>
<p>Grapharena: Evaluating and exploring large language models on graph computation. J Tang, Q Zhang, Y Li, </p>
<p>Evaluating LLM Reasoning in the Operations Research Domain with ORQA. M Mostajabdaveh, T T L Yu, S C B Dash, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2025</p>
<p>Decision information meets large language models: The future of explainable operations research. Y Zhang, Q Kang, W Y Yu, arXiv:2502.099942025arXiv preprint</p>
<p>Co-bench: Benchmarking language model agents in algorithm search for combinatorial optimization. W Sun, S Feng, S Li, arXiv:2504.043102025arXiv preprint</p>
<p>A Comprehensive Evaluation of Contemporary ML-Based Solvers for Combinatorial Optimization. S Feng, W Sun, S Li, arXiv:2505.169522025arXiv preprint</p>
<p>HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization. H Chen, Y Wang, Y Cai, arXiv:2506.079722025arXiv preprint</p>
<p>ALE-Bench: A Benchmark for Long-Horizon Objective-Driven Algorithm Engineering. Y Imajuku, K Horie, Y Iwata, </p>
<p>OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems. X Li, J Chen, X Fang, </p>
<p>Leveraging large language models for solving rare mip challenges. T Wang, W Y Yu, R She, arXiv:2409.044642024arXiv preprint</p>
<p>Large language models for supply chain optimization. B Li, K Mellou, B Zhang, arXiv:2307.038752023arXiv preprint</p>
<p>ChatGPT in supply chain management-a research model. A Maryniak, K Pogorzelec-Glaser, </p>
<p>. Zeszyty Naukowe, Politechniki Śląskiej, Organizacja i Zarządzanie. 2032024</p>
<p>City-LEO: Toward transparent city management using LLM with end-to-end optimization. Z Jiao, M Sha, H Zhang, </p>
<p>What can large language models do for sustainable food. T Thomas, A Yee, A Mayne, arXiv:2503.047342025arXiv preprint</p>
<p>Llms can schedule. H Abgaryan, A Harutyunyan, T Cazenave, arXiv:2408.069932024arXiv preprint</p>
<p>Dataset for llm-driven job shop scheduling. H Abgaryan, T Cazenave, Harutyunyan A Starjob, arXiv:2503.018772025arXiv preprint</p>
<p>Task Offloading with Large Language Models in Mobile Edge Computing. Y Song, W Lee, S H Lee, 2024 15th International Conference on Information and Communication Technology Convergence (ICTC). IEEE2024</p>
<p>Large language modelbased wireless network design. K Qiu, S Bakirtzis, I Wassell, 2024IEEE Wireless Communications Letters</p>
<p>Identify critical nodes in complex network with large language models. J Mao, D Zou, L Sheng, arXiv:2403.039622024arXiv preprint</p>
<p>Large language model (llm) for telecommunications: A comprehensive survey on principles, key techniques, and opportunities. H Zhou, C Hu, Y Yuan, 2024IEEE Communications Surveys &amp; Tutorials</p>            </div>
        </div>

    </div>
</body>
</html>