<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2804 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2804</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2804</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-71.html">extraction-schema-71</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-274822836</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2412.14085v1.pdf" target="_blank">Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report</a></p>
                <p><strong>Paper Abstract:</strong> Video games are a natural and synergistic application domain for artificial intelligence (AI) systems, offering both the potential to enhance player experience and immersion, as well as providing valuable benchmarks and virtual environments to advance AI technologies in general. This report presents a high-level overview of five promising research pathways for applying state-of-the-art AI methods, particularly deep learning, to digital gaming within the context of the current research landscape. The objective of this work is to outline a curated, non-exhaustive list of encouraging research directions at the intersection of AI and video games that may serve to inspire more rigorous and comprehensive research efforts in the future. We discuss (i) investigating large language models as core engines for game agent modelling, (ii) using neural cellular automata for procedural game content generation, (iii) accelerating computationally expensive in-game simulations via deep surrogate modelling, (iv) leveraging self-supervised learning to obtain useful video game state embeddings, and (v) training generative models of interactive worlds using unlabelled video data. We also briefly address current technical challenges associated with the integration of advanced deep learning systems into video game development, and indicate key areas where further progress is likely to be beneficial.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2804.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2804.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative Agents (Park et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system of LLM-driven virtual agents that maintain persistent text-based memory streams of perceptions, plans and reflections; agents consult and update these memories to produce adaptive, socially-coordinated behaviours in a simulated 2D village.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Generative agents (Park et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Each agent uses an LLM as its core thinker that (1) receives textualized current perceptions of the environment, (2) has access to a persistent text-based memory stream containing prior perceptions, generated action plans, and higher-order reflections, and (3) outputs new reflections and adapted action plans; an action module translates textual plans into executable in-env behaviors. The LLM both reads from and appends to the agent's memory stream during decision/reflection cycles, enabling ongoing behavior adaptation and social coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>text-based memory stream (stores past perceptions, action plans, reflections; resembles episodic + reflective memory)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td>Persistent per-agent chronological text stream: memories are stored as textual entries containing perceptions, planned actions and synthesized reflections; the LLM processes current textual perceptions together with selected content from this stream to produce new reflections and action plans, and appends newly generated items back into the stream.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td>Continuously updated: new perceptions, generated action plans and synthesized higher-order reflections are appended to the memory stream as the agent perceives and plans.</td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td>Simulated 2D village with 25 distinct agents having personalities and professions; environment emphasised social interaction, dialogues, coordination and information spreading rather than formal game objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Qualitative emergent results reported: agents exhibited complex self-organising social behaviours (natural dialogues, coordinated actions, information propagation, dynamic updating of social-relationship memories). No quantitative metrics reported in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>Persistent text-based memories enable richer, adaptive and socially-coordinated behaviours; memory streams holding perceptions, plans and reflections are central to emergent social dynamics and plausible long-term behaviour in the simulated society.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2804.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2804.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hu et al. cognitive architecture</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>A survey on large language model-based game agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conceptual LLM-centered cognitive architecture for general game agents describing modular components (perception, memory, role-playing, thinking, action, learning) where an LLM functions as the thinking core and communicates with a memory module storing textual memories.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A survey on large language model-based game agents</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LLM-based cognitive architecture (Hu et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A conceptual multi-module architecture in which: (a) perception converts game states (pixels, features, embeddings) into textual descriptions, (b) a memory module stores past textual perceptions and other memory items (fixed character info, goals, LLM-generated knowledge/reflections), (c) an LLM-based thinking module receives current perceptions plus retrieved textual memories and outputs textual action plans and new memory items, (d) an action module translates textual plans into low-level game actions, and (e) a learning module updates components via RL or finetuning; optionally a goal module manages objectives in text form.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>textual memory module (stores past textual perceptions, fixed character info, LLM-generated knowledge/reflections, goals)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td>High-level conceptual memory module that stores textual memory items (both predetermined and generated). The thinking (LLM) component queries relevant textual memories alongside current perceptions to produce action plans and new memory items which are then stored back into memory. No implementation-level details given in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td>Described conceptually as continuously updated by outputs of the thinking module and by perception; specific update policies not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>Conceptual claim: integrating an explicit memory module with an LLM core is a promising design to enable agents to use past perceptions, role information and generated reflections to produce coherent plans and sustained behavior across time; no empirical evaluations are provided in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2804.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2804.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>STARLING (citation)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>STARLING: Self-supervised training of text-based reinforcement learning agent with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced work described as a method for self-supervised training of text-based RL agents that leverage large language models; cited in the review but not described in detail here.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>STARLING: Self-supervised training of text-based reinforcement learning agent with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>STARLING</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Not described in detail in this review; indicated by title to be a method for training text-based RL agents using LLMs and self-supervised techniques. The review does not summarise architecture, memory use, or experimental specifics for STARLING.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Generative agents: Interactive simulacra of human behavior <em>(Rating: 2)</em></li>
                <li>A survey on large language model-based game agents <em>(Rating: 2)</em></li>
                <li>STARLING: Self-supervised training of text-based reinforcement learning agent with large language models <em>(Rating: 2)</em></li>
                <li>Voyager: An open-ended embodied agent with large language models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2804",
    "paper_id": "paper-274822836",
    "extraction_schema_id": "extraction-schema-71",
    "extracted_data": [
        {
            "name_short": "Generative Agents (Park et al.)",
            "name_full": "Generative agents: Interactive simulacra of human behavior",
            "brief_description": "A system of LLM-driven virtual agents that maintain persistent text-based memory streams of perceptions, plans and reflections; agents consult and update these memories to produce adaptive, socially-coordinated behaviours in a simulated 2D village.",
            "citation_title": "Generative agents: Interactive simulacra of human behavior",
            "mention_or_use": "mention",
            "agent_name": "Generative agents (Park et al.)",
            "agent_description": "Each agent uses an LLM as its core thinker that (1) receives textualized current perceptions of the environment, (2) has access to a persistent text-based memory stream containing prior perceptions, generated action plans, and higher-order reflections, and (3) outputs new reflections and adapted action plans; an action module translates textual plans into executable in-env behaviors. The LLM both reads from and appends to the agent's memory stream during decision/reflection cycles, enabling ongoing behavior adaptation and social coordination.",
            "base_llm": null,
            "uses_memory": true,
            "memory_type": "text-based memory stream (stores past perceptions, action plans, reflections; resembles episodic + reflective memory)",
            "memory_architecture": "Persistent per-agent chronological text stream: memories are stored as textual entries containing perceptions, planned actions and synthesized reflections; the LLM processes current textual perceptions together with selected content from this stream to produce new reflections and action plans, and appends newly generated items back into the stream.",
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": "Continuously updated: new perceptions, generated action plans and synthesized higher-order reflections are appended to the memory stream as the agent perceives and plans.",
            "text_game_benchmark": null,
            "game_characteristics": "Simulated 2D village with 25 distinct agents having personalities and professions; environment emphasised social interaction, dialogues, coordination and information spreading rather than formal game objectives.",
            "performance_with_memory": "Qualitative emergent results reported: agents exhibited complex self-organising social behaviours (natural dialogues, coordinated actions, information propagation, dynamic updating of social-relationship memories). No quantitative metrics reported in this review.",
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "Persistent text-based memories enable richer, adaptive and socially-coordinated behaviours; memory streams holding perceptions, plans and reflections are central to emergent social dynamics and plausible long-term behaviour in the simulated society.",
            "uuid": "e2804.0",
            "source_info": {
                "paper_title": "Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Hu et al. cognitive architecture",
            "name_full": "A survey on large language model-based game agents",
            "brief_description": "Conceptual LLM-centered cognitive architecture for general game agents describing modular components (perception, memory, role-playing, thinking, action, learning) where an LLM functions as the thinking core and communicates with a memory module storing textual memories.",
            "citation_title": "A survey on large language model-based game agents",
            "mention_or_use": "mention",
            "agent_name": "LLM-based cognitive architecture (Hu et al.)",
            "agent_description": "A conceptual multi-module architecture in which: (a) perception converts game states (pixels, features, embeddings) into textual descriptions, (b) a memory module stores past textual perceptions and other memory items (fixed character info, goals, LLM-generated knowledge/reflections), (c) an LLM-based thinking module receives current perceptions plus retrieved textual memories and outputs textual action plans and new memory items, (d) an action module translates textual plans into low-level game actions, and (e) a learning module updates components via RL or finetuning; optionally a goal module manages objectives in text form.",
            "base_llm": null,
            "uses_memory": true,
            "memory_type": "textual memory module (stores past textual perceptions, fixed character info, LLM-generated knowledge/reflections, goals)",
            "memory_architecture": "High-level conceptual memory module that stores textual memory items (both predetermined and generated). The thinking (LLM) component queries relevant textual memories alongside current perceptions to produce action plans and new memory items which are then stored back into memory. No implementation-level details given in this review.",
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": "Described conceptually as continuously updated by outputs of the thinking module and by perception; specific update policies not provided.",
            "text_game_benchmark": null,
            "game_characteristics": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "Conceptual claim: integrating an explicit memory module with an LLM core is a promising design to enable agents to use past perceptions, role information and generated reflections to produce coherent plans and sustained behavior across time; no empirical evaluations are provided in this review.",
            "uuid": "e2804.1",
            "source_info": {
                "paper_title": "Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "STARLING (citation)",
            "name_full": "STARLING: Self-supervised training of text-based reinforcement learning agent with large language models",
            "brief_description": "A referenced work described as a method for self-supervised training of text-based RL agents that leverage large language models; cited in the review but not described in detail here.",
            "citation_title": "STARLING: Self-supervised training of text-based reinforcement learning agent with large language models",
            "mention_or_use": "mention",
            "agent_name": "STARLING",
            "agent_description": "Not described in detail in this review; indicated by title to be a method for training text-based RL agents using LLMs and self-supervised techniques. The review does not summarise architecture, memory use, or experimental specifics for STARLING.",
            "base_llm": null,
            "uses_memory": null,
            "memory_type": null,
            "memory_architecture": null,
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": null,
            "text_game_benchmark": null,
            "game_characteristics": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": null,
            "uuid": "e2804.2",
            "source_info": {
                "paper_title": "Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report",
                "publication_date_yy_mm": "2024-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior",
            "rating": 2,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        },
        {
            "paper_title": "A survey on large language model-based game agents",
            "rating": 2,
            "sanitized_title": "a_survey_on_large_language_modelbased_game_agents"
        },
        {
            "paper_title": "STARLING: Self-supervised training of text-based reinforcement learning agent with large language models",
            "rating": 2,
            "sanitized_title": "starling_selfsupervised_training_of_textbased_reinforcement_learning_agent_with_large_language_models"
        },
        {
            "paper_title": "Voyager: An open-ended embodied agent with large language models",
            "rating": 1,
            "sanitized_title": "voyager_an_openended_embodied_agent_with_large_language_models"
        }
    ],
    "cost": 0.012088499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report
18 Dec 2024</p>
<p>Markus Dablander 
Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report
18 Dec 202475BBDD3EC93E0E7D7120A5F7D3E73D21arXiv:2412.14085v1[cs.LG]
Video games are a natural and synergistic application domain for artificial intelligence (AI) systems, offering both the potential to enhance player experience and immersion, as well as providing valuable benchmarks and virtual environments to advance AI technologies in general.This report presents a high-level overview of five promising research pathways for applying state-of-the-art AI methods, particularly deep learning, to digital gaming within the context of the current research landscape.The objective of this work is to outline a curated, non-exhaustive list of encouraging research directions at the intersection of AI and video games that may serve to inspire more rigorous and comprehensive research efforts in the future.We discuss (i) investigating large language models as core engines for game agent modelling, (ii) using neural cellular automata for procedural game content generation, (iii) accelerating computationally expensive in-game simulations via deep surrogate modelling, (iv) leveraging self-supervised learning to obtain useful video game state embeddings, and (v) training generative models of interactive worlds using unlabelled video data.We also briefly address current technical challenges associated with the integration of advanced deep learning systems into video game development, and indicate key areas where further progress is likely to be beneficial.</p>
<p>Introduction</p>
<p>In the last decade, the rise of advanced neural network architectures has led to a series of dramatic breakthroughs in the fields of machine learning and artificial intelligence (AI).The GPU-accelerated training of large, carefully designed deep learning models has enabled researchers to tackle previously intractable challenges in diverse areas such as computer vision [1,2,3,4,5], natural language processing [6,7,8,9], artificial content generation [10,11,12,13], and computational chemistry [14,15,16,17,18].One exceptionally promising and natural application area for modern deep learning, which will be explored in this report, is digital gaming.</p>
<p>The focus of AI research on games already has a long and important history.In particular, the study of classical board games such as Chess, Checkers, and Go has been formative and instrumental for the AI field as a whole [19,20].The highly structured nature of many games allows for the emergence of great complexity and strategic depth from simple rules that can easily be expressed in a computational framework; consequently, games have long been considered ideal testing grounds for the reasoning and planning capabilities of AI agents.A significant milestone was reached in 2016, when the first AI system achieved superhuman performance in the game of Go [21], which, at that time, represented the last major, popular board game in which human experts still outperformed computers.</p>
<p>Particularly since then, digital games have increasingly been recognised as one of the next great frontiers of AI research.In recent years, considerable progress has been made towards developing AI agents capable of mastering real-time strategy video games, such as StarCraft II [22], and multiplayer online battle arena video games, such as Dota 2 [23], both of which pose a far greater challenge to AI systems than classical board games.Simultaneously, the construction of general AI models that can learn to play multiple, qualitatively distinct arcade video games has emerged as an active field of research [24,25,26], and work in this area may serve as a stepping stone towards the development of more general AI systems in other domains.Importantly, it is not merely the case that video games have the potential to enrich contemporary AI research; the converse is true as well.The relationship between AI research and digital gaming is mutual and synergistic [19,20,27], with video games providing valuable benchmarks, test-beds and virtual environments for novel AI systems, while novel AI systems, in turn, provide a wealth of opportunities for video game developers to enhance their creative products.Partly due to the rapid progress of recent AI technologies, in particular deep learning, many of these opportunities are still underutilised and have yet to be explored.This report aims to give a concise, preliminary overview of a selection of five potential research avenues for the application of state-of-the-art AI techniques to digital gaming.While our emphasis will mainly be on research directions where contemporary AI methods can enhance digital gaming, the reciprocal connection between AI and video games makes it conceivable that investigating these topics could also drive new insights and advancements in AI itself.The objective of this exploratory report is not to provide a comprehensive set of mature research proposals, or to present novel original research findings.Instead, the focus is on offering a speculative collection of high-level ideas that may serve to inspire more rigorous and focused research efforts in the future.The selected areas are not in any way exhaustive, but rather represent a curated and necessarily subjective collection of ideas deemed particularly intriguing during our examination of the current research landscape.</p>
<p>The foundational book from Yannakakis and Togelius [20], which served as one of the most valuable references for this work, outlines three core applications of AI to video gaming:</p>
<p>• AI for game playing and agent modelling, which includes simulating the role of a human player [22,23], or controlling other game agents in the broadest sense, such as non-player characters (NPC) [28,29], or hidden agents governing aspects of the game environment [30].</p>
<p>• AI for procedural content generation [31], which includes the algorithmic creation of game levels, music, textures, art, dialogues, items, characters, or any other digital content.</p>
<p>• AI for player modelling [32], which includes the modelling of human player characteristics, such as player type, predicted in-game behaviour, or emotional state, based on measured gameplay and player data.</p>
<p>All of these three areas are reflected in the research avenues discussed below, with a greater emphasis on the first two.</p>
<p>Large Language Models for Game Agent Modelling</p>
<p>Large language models (LLMs) such as OpenAI's GPT-4 [33], Google's Llama 3 [34], and Anthropic's Claude 3 [35] have recently risen to enormous prominence due to their advanced capabilities to maintain realistic conversational arcs and generate flexible solutions to a wide range of language-related tasks.Current state-of-the-art LLMs are based almost exclusively on variants of the transformer architecture, introduced in the seminal work of Vaswani et al. [7] in 2017.Transformer networks rely on the concept of self-attention, a deep learning mechanism designed to effectively capture long-range dependencies and contextual information in sequential data.The core training process for many LLMs is self-supervised and autoregressive, meaning that the LLM is trained to generate text by probabilistically predicting the next word (or subword token) in a text based on the preceding words.LLMs regularly contain billions of trainable parameters and are frequently trained on vast corpora of unlabelled textual data collected from publicly available sources such as books and websites [36].</p>
<p>At the moment, LLMs are attracting significant attention within the video game AI research community for their potential applicability to a diverse array of gaming-related tasks [37,38].For example, LLMs have recently been explored for the algorithmic creation of new video game levels in Super Mario Bros [39], the autonomous playing of Minecraft through the generation of code for a suitable game API [40], the systematic extraction of player sentiment from written game reviews [41], and the automatic generation of dynamic audio commentary for League of Legends gameplay [42].Covering all promising use cases of LLMs in digital gaming would be beyond the scope of this exploratory report.However, we briefly highlight one possible research direction we consider to be particularly interesting, namely the use of LLMs for game agent modelling.</p>
<p>Game agent modelling includes the development and control of NPCs such as teammates, enemies, sidekick companions, merchants, bystanders, and other virtual characters in the broadest sense.Perhaps one of the most evident and fruitful applications of LLMs in this context would be to equip NPC agents with the ability to have natural and unscripted conversations with each other and with human players.First investigations in this area have already begun [43,44,45]; further advancements in integrating LLMs as NPC dialogue systems may be able to markedly enhance the realism of virtual characters, leading to substantially deeper and more immersive video game experiences.</p>
<p>However, the overall potential of LLMs for agent modelling may exceed the already appealing area of dynamic dialogue generation.In 2024, Hu et al. [46] gave a conceptual description of an entire cognitive architecture for general game agents that embeds an LLM as the core thinking component within a network of other submodules covering perception, memory, role-playing, action, and learning.Drawing closely from the work of Hu et al., one might envision an LLM-based cognitive architecture broadly working as follows: the perception module translates current game states into textual descriptions; the thinking module, powered by an LLM, receives outputs from the perception module and relevant text-based memories retrieved from the memory module to output textual action plans; these plans are translated by the action module into executable low-level in-game actions; the LLM-based thinking process is additionally biased with character information by the role-playing module; and continuously updated with techniques such as reinforcement learning or supervised finetuning by the learning module.One may also consider introducing a separate goal module that manages the objectives of the agent in a text-based manner and interacts with the other modules.</p>
<p>While each of the above modules could easily warrant its own extensive research programme, first successful attempts to design game agents via the integration of LLMs into broader cognitive architectures have already been made.Most notably, Park et al. [44] created an interactive artificial society consisting of a virtual 2D village with 25 distinct LLM-based game agents with different personalities and professions.Each agent maintains a text-based memory stream that contains a comprehensive list of the agent's perceptions, along with generated action plans and synthesised higher-order reflections.An LLM interacts with the agent's memory stream and current perceptions to generate new reflections and adapt action plans.This approach leads to an impressively complex and convincing set of self-organising emergent social behaviours: agents lead natural dialogues, coordinate actions, spread information, and dynamically update social relationship memories.A simple, schematic overview of an LLM-based cognitive architecture, heavily inspired by the works of Park et al. [44] and Hu et al. [46], is depicted in Figure 1.</p>
<p>Further efforts, such as those by Park et al., to integrate LLMs into a broader network of cognitive modules could not only contribute to the development of more immersive video game characters and Figure 1: Simple, high-level overview of a conceivable LLM-based cognitive architecture for a video game agent, strongly influenced by the works of Park et al. [44] and Hu et al. [46].The perception module translates game environment features (pixels, statistical features, vectorial embeddings, etc.) extracted from the game state into textual descriptions.The memory module stores past textual perceptions, as well as other memory items that are either predetermined (fixed character information, basic goals, etc.) or generated by the thinking module (novel knowledge, reflections, goals, procedural skills, etc.).The thinking module, based on a large language model (LLM), processes current textual perceptions and relevant textual memory items retrieved from the memory module, and outputs textual action plans and new memory items.The textual action plans are converted by the action module into low-level sequences of in-game behaviours that are executed to change the game state.</p>
<p>more human-like virtual agents for playtesting, but also advance research on the disputed question of how suitable LLMs truly are as core engines for artificial general intelligence [47,48].</p>
<p>Neural Cellular Automata for Procedural Content Generation</p>
<p>Cellular automata (CA) [49,50] are a family of extensively investigated and diverse mathematical models represented by grids of cells, whose states evolve in discrete time.At each time point t, each cell has a state represented by a number (or a vector of numbers), and its state at time t + 1 is determined by its own state and the states of its neighboring cells at time t, according to a local transition function that defines how the states evolve.</p>
<p>A simple and iconic example of CA that many readers may be familiar with is given by Conway's Game of Life [51], which takes place on an infinite 2D orthogonal grid of square cells, each of which can only be in one of two possible states, dead or alive.Given some initial configuration, cell states start to evolve based on a simple transition function that only takes into account how many dead or alive neighbours a cell has at a given time.In spite of its extreme simplicity, Conway's Game of Life exhibits an impressive set of complex self-organising behaviours. 1A have already been used in video games with considerable success, for instance to grow infinite cave levels for the game Cave Crawler [52], automatically generate playable mazes for maze running games [53], model granular media like sand or soil [54], or simulate erosion in virtual environments [55].CA are highly computationally efficient models that can be used to generate intricate virtual content.At the same time, CA are conceptually simple, intuitive to understand and easy to implement.However, the constructive, emergent nature of CA also makes them difficult to control [20].In general, given a local transition function, it is very difficult to predict which pattern will arise over time from a specific initial grid state; even extremely similar initial states may quickly diverge in a chaotic manner, leading to entirely different outcomes [56].Similarly, identifying a local transition function that over time maps a given initial state to a desired pattern is a nontrivial technical problem.These properties limit the utility of CA as procedural content generators for video games by making it challenging to impose essential constraints on generated content.Such constraints may ).An NCA is a cellular automaton whose local transition function is parametrised by a neural network.Mordvintsev et al. [59] showed how an NCA can be trained with gradient-based methods to organically grow an arbitrary, predefined target pattern from a single initial cell.The NCA can also learn to automatically converge back to its intended target pattern when disturbed in a manner that resembles self-regeneration.</p>
<p>include guaranteed solvability for a game level, or a particular shape, connectivity and aesthetic style for a game object.</p>
<p>Recently, neural cellular automata (NCA) [57,58] have been increasingly investigated as a significant way to address some of these shortcomings and allow for substantially greater control over the dynamical processes governing CA.An NCA is a CA whose local transition function is parametrised by a trainable neural network.One of the key contributions in the field of NCA was made by Mordvintsev et al. [59] in 2020, who demonstrated how an NCA parametrised by a convolutional neural network can be effectively trained in a differentiable end-to-end manner via gradient-based methods to iteratively generate any predefined target image from a single cell (see Figure 2 for an illustration of this idea).They moreover showed how NCA can be trained to exhibit self-regeneration, or, in the language of dynamical systems theory, how the target image can be turned into an attractor.A self-regenerating NCA automatically converges back to its intended target pattern when perturbed. 2he seminal work of Mordvintsev et al. [59] has implications stretching into diverse areas, including morphogenesis, embryonic development, regenerative medicine, self-organisation, and swarm robotics.In addition, first attempts have already been made to apply NCA in video game research [60,61,62,63,64,65]: Earle et al. [60] successfully trained NCA to generate levels for 2D tile-based games while taking into account validity and diversity constraints; Sudhakaran et al. [63] used NCA in the virtual world of Minecraft for the targeted morphogenetic growth of complex 3D objects such as castles and trees; and Pajouheshgar et al. [64] employed NCA for the virtual synthesis of desired textures on 3D meshes.</p>
<p>These early studies highlight the potential of NCA as a novel deep-learning-based tool for procedural content generation in virtual environments [66].However, many promising research directions remain to be investigated.Additional work could further explore the capabilities of NCA to be trained via custom loss functions designed to promote specific design constraints for video game content generation.Future studies could also more deeply investigate NCA for the creation of realistic textures for digital objects in a computationally efficient manner, or for accurately simulating organic and regenerative processes, such as the growth of natural ecosystems, aging characters, material degradation, or wound healing.Beyond content generation, it may also be interesting to investigate NCA as efficiently trainable swarm intelligence models to induce emergent behaviours in groups of locally connected NPCs.</p>
<p>Deep Surrogate Modelling to Accelerate Computationally Expensive In-Game Simulations</p>
<p>In their seminal study, Gilmer et al. [14] not only introduced message-passing as a unifying framework for graph neural network architectures; in addition to this salient contribution, they also showed that a graph neural network can learn to efficiently predict quantum-chemical properties of small molecules using the QM9 data set [67] for training.The QM9 data set consists of around 134k chemical compounds; each compound comes with a set of numerical labels that represent approximations of relevant quantum-chemical properties.For each compound, each numerical label is the result of a quantum-mechanical simulation based on what is known as density functional theory [68].Density functional theory simulations, while highly useful for elucidating the electronic structure of a molecule, are associated with prohibitive computational costs; for example, generating all the labels in the QM9 data set for a single molecule with nine heavy atoms on a single core of a Xeon E5-2660 processor with 2.2 GHz and commonly used software may take around one hour [14].In contrast, the graph neural network from Gilmer et al., which was trained on the QM9 data set in a supervised manner, can estimate the outcome of density functional theory simulations for a novel molecule in a fraction of a second.This corresponds to a speed-up of five orders of magnitude, making it computationally feasible to rapidly predict quantum-chemical properties for large molecular libraries.
f : X → R n
that is of interest for a practical application.For instance, f could represent an expensive numerical computer simulation.In our earlier example from Gilmer et al., the domain X would be a set of molecular graphs, and f would represent a density functional theory simulation that maps molecular graphs to numerical quantum-chemical properties expressed as vectors in R n .Initially, a (sometimes considerable) computational effort is made to create a data set
D = {(x 1 , f (x 1 )), ..., (x m , f (x m ))} ⊆ X × R n ,
which is then used to train the parameters θ of a suitable deep learning architecture
Φ θ : X → R n
in a supervised manner.After training, the deep network Φ θ can be used as a surrogate for f , approximating the value of f (x) with Φ θ (x) for novel x outside the training set D. Furthermore, Φ θ can also be optimised instead of f when looking for maximisers or minimisers of f .While Φ θ may be less accurate than the original simulation function f , it can be orders of magnitude faster to evaluate.</p>
<p>Deep surrogate modelling is particularly useful in situations requiring computationally expensive and repetitive simulations [70].Video games regularly involve a plethora of such simulations, spanning diverse areas like gameplay balancing, difficulty tuning, fluid and particle dynamics, Newtonian mechanics, pathfinding, environmental systems, realistic lighting, sound propagation, game state prediction, and procedural content generation.As such, digital gaming may be well-suited for the application of deep surrogate models to accelerate gameplay, reduce loading times and optimise the game development process.Despite these encouraging possibilities, the number of studies exploring deep surrogate models for video games appears to be relatively limited [73,74,75,76,77,78,79].However, early work in this field has already shown some success.For example, Bhatt et al. [74] trained a deep surrogate model on simulated data to predict the behaviour of a game agent in novel environments, applying the model to accelerate the algorithmic generation of new environments that lead to diverse agent behaviours.Overall, the utility of deep surrogate modelling for digital gaming may still be underexplored, offering notable opportunities for future research.</p>
<p>Self-Supervised Video Game State Representation Learning</p>
<p>Being able to represent the abstract state of a video game in terms of a meaningful numerical vector is a key element in a large variety of modern AI applications for digital gaming [20].In this context, a high-quality vectorial representation technique should be able to condense the essential features of a video game state into an informative embedding that can be effectively used for downstream AI tasks.Such tasks may, for example, include using a game state embedding as a model of perception for an autonomous game agent [26,80], predicting the emotional state of a player from gameplay video streams [81], predicting future game states from current ones [82], dynamically adapting game music depending on the state of a game [83], or algorithmically translating game states into natural language descriptions [44].</p>
<p>A powerful deep learning paradigm for vectorial data representation that has emerged in recent years is self-supervised learning [84], which offers a collection of strategies to learn rich, general-purpose embeddings solely from the internal structure of unlabelled input data.While supervised deep learning is based on the extraction of task-specific features from labelled data sets, self-supervised learning does not rely on data annotation by human subjects, and instead allows one to find flexible feature representations in a task-agnostic manner.Labelled data is frequently scarce and hard to obtain; self-supervised learning methods do not suffer from comparable limits, as they can take advantage of vast corpora of unlabelled data sets, such as curated libraries of images and text extracted from the internet.Representations learned via self-supervised training can be employed in a variety of ways, including clustering [85] and anomaly detection [86].Importantly, they can also be finetuned on downstream supervised tasks [87], an approach that regularly leads to substantial boosts in performance compared to purely supervised techniques.</p>
<p>While self-supervised learning has become a significant area of research in domains like natural language processing and computer vision [88], comparable work in digital gaming is still relatively sparse.A literature search for studies that use concepts from self-supervised learning in digital gaming revealed only 12 instances [80,89,90,91,92,93,94,95,96,97,98,99].In a notable article, Anand et al. [80] introduced a systematic benchmark to evaluate self-supervised learning methods for video game states via the prediction of essential internal game variables in Atari 2600 games from learned representations.They employed this benchmark to demonstrate the effectiveness of a mutual-information-based representation learning strategy.In a related study, Trivedi et al. [89] showed that three popular self-supervised learning strategies applied to video game pixels alone can be used to derive game state embeddings that are predictive of key internal game variables, such as enemy positions on the screen in a first-person shooter, or game world coordinates of football players and the ball in a football simulator.</p>
<p>Representing video game states via state-of-the-art self-supervised learning may be an impactful area for future research.One particularly interesting approach could be to further investigate joint-Figure 4: Schematic overview of a prototypical joint-embedding predictive architecture (JEPA) [100] for self-supervised learning.The variables x and y could, for instance, represent images of game pixels at times t and t + δ, the encoders Φ θ and Ψ γ could be convolutional neural networks that map the images to embeddings v x , v y , the latent variable z could symbolise the action taken by the player at time t, and P η could be a multilayer perceptron whose output P η (v x , z) aims to approximate v y .</p>
<p>embedding predictive architectures (JEPAs) [100,101] for this purpose.JEPAs constitute a novel self-supervised learning framework with attractive technical properties that has recently demonstrated encouraging results in the image domain [102].Let
Ψ γ : Y → R m , Φ θ : X → R n ,
be two trainable deep learning encoders that map given data entities in the sets X and Y (which could, for example, be collections of images or graphs) to vectors.In essence, a JEPA aims to learn useful representations by training to predict the embedding
v y := Ψ γ (y) ∈ R m
of an input entity y ∈ Y from the embedding
v x := Φ θ (x) ∈ R n
of a somehow related input entity x ∈ X, with the help of a latent variable
z ∈ Z ⊆ R l
that can be used to add additional information about y not contained in x.The prediction of v y from v x and z is done via a trainable predictor
P η : R n × Z → R m
whose aim is to minimise a scalar error function such as
E(P η (v x , z), v y ) := ||P η (v x , z) − v y || 2 ∈ R ≥0 .
A schematic visualisation of this architecture is depicted in Figure 4.</p>
<p>Since the prediction of y from x and z occurs implicitly in abstract representation space, unimportant details of x and y can be eliminated by the encoders Ψ γ and Φ θ prior to prediction.This architecture also allows for multiple values of y to be compatible with a single value of x, due to potential invariance properties of the encoder Ψ γ and the ability to change the output of P η by varying the latent variable z.</p>
<p>In the context of video games, x and y could, for example, represent game pixels on the player screen at times t and t + δ, the encoders Φ θ and Ψ γ could be convolutional neural networks that map the pixels to vectorial embeddings v x , v y , the latent variable z could symbolise the action taken by the player at time t, and P η could be a multilayer perceptron whose output P η (v x , z) aims to approximate v y .In other words, P η could be trained to predict the abstract future game state from the abstract current game state given the player action, a task that may encourage Φ θ and Ψ γ to simultaneously learn meaningful abstract game state embeddings.The BYOL method [103], which shares some similarities with the JEPA approach, has already been successfully tested for pixel-based game state representation learning in the previously mentioned study by Trivedi et al. [89].For a more detailed technical description of JEPAs, including important training considerations to prevent such architectures from collapsing into producing only constant representations, we refer the reader to the original article by LeCun [100].</p>
<p>Learning Generative Models of Interactive Worlds from Unlabelled Videos</p>
<p>In early 2024, Google DeepMind introduced Genie [104], an 11-billion parameter generative world model trained in a self-supervised manner on a large-scale library of publicly available gameplay videos of 2D platformer games.Genie can automatically generate an infinite variety of novel and action-controllable 2D platformer gaming worlds. 3Each unique world is created using only a single image as an initial seed.</p>
<p>The neural architecture of Genie consists of three major components, all of which rely on the use of computationally efficient spatiotemporal transformer models [7,105]: a video tokeniser, a latent action model, and a dynamics model.The video tokeniser is implemented via a VQ-VAE [106] that is trained to translate video game frames into discrete vectorial tokens, and vice versa.The latent action model is trained to infer plausible actions between consecutive pairs of frames.It too is based on a VQ-VAE architecture that naturally allows for limiting the number of possible actions to a small, fixed-size set of discrete vectorial action embeddings.Most notably, the latent action model is trained in an entirely self-supervised way, without the need for human-annotated action labels.The dynamics model [107] is trained autoregressively to predict future tokenised frames from past and current tokenised frames and inferred action embeddings.As a result, the dynamics model is encouraged to learn the consequences of actions on the temporal evolution of the video game world.</p>
<p>Once trained, the Genie system can be operated in the following way:</p>
<p>1.A user first prompts Genie with an image x 1 vaguely resembling a scene from a platformer game.This image serves as the initial game frame.The starting image x 1 could for instance be a screenshot from an actual game, an imagined sketch drawn by a human, or an artificial image created via a text-to-image generator [108] from a natural language description.2. The image x 1 is compressed into a discrete vectorial token z 1 using the video tokeniser.3. The player can then input an initial action which is translated into a discrete vectorial action embedding a 1 by a component of the latent action model.4. The dynamics model uses its acquired world knowledge [109] to predict the next tokenised frame z 2 based on action a 1 and state z 1 .5. The compressed vectorial token z 2 is decoded into the next video game frame x 2 by the video tokeniser.The image frame x 2 is displayed to the user.6.The last three steps are iteratively repeated to give rise to an interactive sequence of image frames (x 1 , x 2 , x 3 , ...)</p>
<p>that constitute a playable platformer game.For example, after the initial iteration, the user specifies another action a 2 , the dynamics model uses (z 1 , z 2 ) and (a 1 , a 2 ) to predict z 3 , and z 3 is subsequently decoded into the next visible frame x 3 .</p>
<p>This process is visualised in Figure 5.</p>
<p>One of the limitations of Genie outlined in the original article [104] is its low frame rate, reported to be around one frame per second.Genie may also sometimes hallucinate unrealistic future scenarios, or fail to maintain the stability and consistency of a generated world over time.Despite these Figure 5: Schematic diagram illustrating the inference process of the trained Genie model [104] to generate a playable platformer game from a given image prompt x 1 (images not generated by actual Genie system, used for illustrative purposes only).The video tokeniser and the latent action model respectively translate the prompt image x 1 and the initial player action input into embeddings z 1 and a 1 , which are subsequently used by the dynamics model to predict the next tokenised frame z 2 .The compressed representation z 2 is then converted by the video tokeniser into a visible game frame x 2 .This process is iteratively repeated using previously generated image tokens and recorded input actions to give rise to a sequence of interactive game frames (x 1 , x 2 , x 3 , ...).</p>
<p>shortcomings, Genie's architecture represents a strong proof of concept for the possibility of learning generative models of interactive worlds from gameplay video data alone.The fact that Genie is able to effectively infer an operable latent action space entirely without human-annotated action labels is particularly noteworthy.</p>
<p>Note that this article is written only a few days after Google DeepMind's public announcement of Genie 2 [110].Due to the early stage of this research, a comprehensive technical description of this novel model via an associated research paper is currently lacking.It has been stated, however, that Genie 2 is an autoregressive latent diffusion model [12].It appears that Genie 2 extends the domain of Genie to the substantially more challenging task of generating complex, interactive 3D game worlds 4 instead of simple 2D platformer games.Genie 2 is reported to exhibit a set of emergent capabilities related to physics, object interactions, character animation and game agents, and to be able to maintain a consistent 3D world for up to a minute.</p>
<p>The potential implications of interactive-world generators like Genie and Genie 2 for general AI research as well as digital gaming are noteworthy.In the future, considerably more mature versions of such systems could conceivably become useful for a wide array of tasks, including training and testing general adaptive agents in maximally diverse virtual environments [111], simulating an infinite stream of realistic training scenarios for robotic systems like autonomous vehicles [112], accelerating video game development via rapid prototyping, allowing non-experts to easily create their own action-controllable video game snippets, procedurally extending existing video games and virtual worlds [66,113], automatically personalising video game content based on a model of player behaviour or characteristics [32], and simulating virtual environments for human training purposes in fields like medicine [114] and aviation [115].</p>
<p>Future impactful work in this area could for example focus on maintaining the consistency and stability of generated environments over extended periods of time, the prevention of hallucinations [116,117], the inclusion of audio signals, the generation of game mechanics for less explored genres like bird'seye strategy games, the identification and mitigation of computational bottlenecks [118] to accelerate low frame rates, and the development of even more capable dynamics and latent action models [119].</p>
<p>In addition, it may be interesting to investigate to what extent combinations of current LLMs with text-to-image models [120,121,122] could enable the generation of interactive worlds.One of the main concerns of game developers is the feasibility of training, running and gathering data for advanced deep learning architectures [123,124].The large amount of computation time and expensive hardware required to train state-of-the-art models such as LLMs or interactive-world generators represent an important bottleneck, especially for small and moderately-sized studios.Furthermore, if a model does not generalise effectively to new scenarios, it may have to be discarded or retrained.In supervised settings, it may be intractable to obtain sufficient amounts of humanannotated training data.If supervised data relates to in-game behaviour or player analytics, this may also potentially raise concerns regarding privacy ethics.In addition, running large trained models in real-time during gameplay could decelerate frame rate and responsiveness to unacceptably low levels.</p>
<p>Further hurdles for game developers arise in connection to the black-box nature of deep learning systems [125,126], which refers to the difficulty in understanding how such models make predictions and arrive at decisions.Neural networks consist of inscrutable compositions of large matrices and nonlinear functions, which makes their outputs and working mechanisms notoriously hard to interpret from a human perspective.In particular, this makes it challenging to definitively predict the behaviour of deep networks in novel edge cases [127], to guarantee their consistency, and to debug them in case they produce undesired outcomes.This opacity creates a variety of obstacles for applications in digital gaming: for instance, NPCs controlled by neural networks may exhibit unexpected and inexplicable behaviours that contradict the intended narrative or essential game mechanics; complex debugging procedures may significantly extend game development time; and it may be unclear how to hard-code necessary playability constraints into deep-learning-based procedural game level generators.</p>
<p>In order to reduce justified hesitancy amongst game developers to integrate novel deep learning technologies into their products, concerns like the ones outlined in this section must be addressed.Notably, a variety of currently active research areas could lead to the mitigation of some of the mentioned problems: Advances in self-supervised learning [84,87] and simulation of synthetic training data [128] could improve generalisation and reduce the need for labelled data sets in video game applications.More powerful model distillation [129] or network pruning techniques [130], possibly based on the exploitation of so-called super weights recently discovered in LLMs [131], may reduce the computational costs associated with deep networks.Additionally, large deep learning architectures could potentially be run on distributed cloud computing systems during gameplay to offload the computational burden from local machines.Research on AI explainability [132] and the adversarial robustness of neural networks [133] could make deep learning models more predictable, consistent, and debuggable.And quality-diversity optimisation methods [134,135] represent a growing family of algorithms that can be combined with deep learning to generate content that respects certain constraints while being diverse in nature.</p>
<p>Conclusions</p>
<p>In this work, we illuminated five promising research pathways for the application of state-of-the-art AI techniques to digital gaming: LLMs for game agent modelling, neural cellular automata for procedural content generation, deep surrogate modelling to accelerate expensive in-game simulations, self-supervised game state representation learning, and the use of unlabelled video data to train generative models of interactive worlds.The primary objective of this report is to provide a high-level overview of these areas within the current research landscape, with the aim of sparking intellectual curiosity for more targeted and in-depth research efforts in these or related fields in the future.</p>
<p>Video games are one of the most natural and important research frontiers in the search for general artificial intelligence systems, as they offer an almost limitless abundance of distinct cognitive tasks and simulated environments to challenge virtual agents.Further work in the areas discussed in this report could not only lead to novel technologies that enhance the quality and immersiveness of digital gaming experiences; it could also drive scientific developments in the search for more useful and capable AI models overall.For instance, research on LLM-based video game agents could lead to progress on the debated question to what extent purely language-based systems are in fact suitable as models for general intelligence [47,48]; and advanced generative models of interactive worlds could supply AI agents with a potentially infinite stream of complex virtual training and testing environments [104,111].</p>
<p>While we regard the research directions described in this work to hold considerable potential, it is important to note current challenges that may still limit the practical utility of deep learning in digital gaming.Issues remain around topics such as interpretability, predictability, consistency, debuggability, data requirements, generalisation, reusability, the setting of model constraints, as well as financial and computational efficiency.Systematic efforts to address these technical obstacles, alongside experimentation with novel research ideas like those outlined in this report, should be a high priority to accelerate future progress in both AI and video game research.</p>
<p>Figure 2 :
2
Figure2: Conceptual diagram of how a neural cellular automaton (NCA), once trained, could iteratively generate the target image of a tree (image not generated by actual NCA, used for illustrative purposes only).An NCA is a cellular automaton whose local transition function is parametrised by a neural network.Mordvintsev et al.[59] showed how an NCA can be trained with gradient-based methods to organically grow an arbitrary, predefined target pattern from a single initial cell.The NCA can also learn to automatically converge back to its intended target pattern when disturbed in a manner that resembles self-regeneration.</p>
<p>Figure 3 :
3
Figure 3: Illustration of the elementary idea behind deep surrogate modelling: A computationally expensive function f is repeatedly evaluated to generate a training data set D, which is then used to train a deep network Φ θ .After training, Φ θ acts as a computationally fast approximation of f .The work of Gilmer et al. represents a prime example of what can be referred to as deep surrogate modelling[69,70,71,72].A high-level illustration of the key idea behind deep surrogate modelling is given in Figure3.In one of its most elementary forms, deep surrogate modelling is a technique used to speed up the evaluation of a computationally expensive function</p>
<p>While modern AI techniques, in particular deep learning, hold significant promise to enhance the future of video gaming experiences, serious technical challenges remain.As in other application areas of neural networks, these challenges frequently revolve around computational efficiency and speed, interpretability and predictability, the setting of model constraints, data requirements, model generalisation abilities, privacy considerations, and financial costs.Other, more game-specific issues centre around the complexities of integrating deep learning systems into traditional game development workflows, development time, managing player expectations with regards to AI, maintaining narrative control of video game stories, ensuring model consistency, and preserving debugging options.
7 Current Technical Challenges for Deep Learning in Digital Gaming: ACritical View
Video illustration of Conway's Game of Life
Interactive animations of self-regenerating NCA by Mordvintsev et al.[59] 
Video illustrations of Genie's[104] capabilities
Video illustrations of Genie 2's capabilities
Homepage | X
Acknowledgments and Disclosure of FundingThis exploratory report was commissioned and funded by Beam Foundation 5 as part of their emerging initiative to investigate the future of artificial intelligence in digital gaming.
ImageNet classification with deep convolutional neural networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, Advances in Neural Information Processing Systems. 252012</p>
<p>Very deep convolutional networks for large-scale image recognition. Karen Simonyan, Andrew Zisserman, arXiv:1409.15562014arXiv preprint</p>
<p>Visualizing and understanding convolutional networks. Matthew D Zeiler, Rob Fergus, Proceedings of the European Conference on Computer Vision. the European Conference on Computer Vision2014</p>
<p>Going deeper with convolutions. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2015</p>
<p>Deep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2016</p>
<p>Google's neural machine translation system: Bridging the gap between human and machine translation. Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, arXiv:1609.081442016arXiv preprint</p>
<p>Attention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin, Advances in Neural Information Processing Systems. 201730</p>
<p>Language models are few-shot learners. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, arXiv:2005.141652020arXiv preprint</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, Journal of Machine Learning Research. 211402020</p>
<p>. P Diederik, Max Kingma, Welling, arXiv:1312.61142013Auto-encoding variational Bayes. arXiv preprint</p>
<p>Generative adversarial nets. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, Advances in Neural Information Processing Systems. 201427</p>
<p>High-resolution image synthesis with latent diffusion models. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022</p>
<p>Denoising diffusion probabilistic models. Jonathan Ho, Ajay Jain, Pieter Abbeel, Advances in Neural Information Processing Systems. 202033</p>
<p>Neural message passing for quantum chemistry. Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, George E Dahl, International Conference on Machine Learning. 201770</p>
<p>Automatic chemical design using a datadriven continuous representation of molecules. Rafael Gómez-Bombarelli, Jennifer N Wei, David Duvenaud, José Miguel Hernández-Lobato, Benjamín Sánchez-Lengeling, Dennis Sheberla, Jorge Aguilera-Iparraguirre, Timothy D Hirzel, Ryan P Adams, Alán Aspuru-Guzik, ACS Central Science. 422018</p>
<p>Convolutional networks on graphs for learning molecular fingerprints. David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alán Aspuru-Guzik, Ryan P Adams, Advances in Neural Information Processing Systems. 282015</p>
<p>Keyulu Xu, Weihua Hu, Leskovec , Stefanie Jegelka, arXiv:1810.00826How powerful are graph neural networks?. 2018arXiv preprint</p>
<p>Highly accurate protein structure prediction with AlphaFold. John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek, Anna Potapenko, Nature. 59678732021</p>
<p>Games for artificial intelligence research: A review and perspectives. Chengpeng Hu, Yunlong Zhao, Ziqi Wang, Haocheng Du, Jialin Liu, IEEE Transactions on Artificial Intelligence. 2024</p>
<p>Artificial intelligence and games. Georgios N Yannakakis, Julian Togelius, 2018Springer</p>
<p>Mastering the game of Go with deep neural networks and tree search. David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den, Julian Driessche, Ioannis Schrittwieser, Veda Antonoglou, Marc Panneershelvam, Lanctot, Nature. 52975872016</p>
<p>Grandmaster level in StarCraft II using multi-agent reinforcement learning. Oriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung, David H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, Nature. 57577822019</p>
<p>Dota 2 with large scale deep reinforcement learning. Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemysław Dębiak, Christy Dennison, David Farhi, Quirin Fischer, Shariq Hashme, Chris Hesse, arXiv:1912.066802019arXiv preprint</p>
<p>Multi-game decision transformers. Kuang-Huei Lee, Ofir Nachum, Sherry Mengjiao, Lisa Yang, Daniel Lee, Sergio Freeman, Ian Guadarrama, Winnie Fischer, Eric Xu, Henryk Jang, Michalewski, Advances in Neural Information Processing Systems. 202235</p>
<p>Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo, Alexander Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay, arXiv:2205.06175Jost Tobias Springenberg, et al. A generalist agent. 2022arXiv preprint</p>
<p>Human-level control through deep reinforcement learning. Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, Nature. 51875402015</p>
<p>Bobby D Risto Miikkulainen, Ryan Bryant, Igor V Cornelius, Kenneth O Karpov, Chern Stanley, Yong Han, Computational intelligence in games. Computational Intelligence: Principles and Practice. 2006</p>
<p>Three states and a plan: The AI of FEAR. Jeff Orkin, Game Developers Conference. 2006. 2006</p>
<p>Davide Aversa, Stavros Vassos, arXiv:1307.3195Action-based character AI in video-games with CogBots architecture: A preliminary report. 2013arXiv preprint</p>
<p>Michael Booth, The AI systems of Left 4 Dead. Artificial Intelligence and Interactive Digital Entertainment Conference at Stanford. 2009</p>
<p>Procedural content generation in games. Noor Shaker, Julian Togelius, Mark J Nelson, 2016Springer</p>
<p>Player modeling. N Georgios, Pieter Yannakakis, Daniele Spronck, Elisabeth Loiacono, André, 2013Dagstuhl Publishing</p>
<p>Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, arXiv:2303.08774Shyamal Anadkat, et al. GPT-4 technical report. 2023arXiv preprint</p>
<p>The Llama 3 herd of models. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, arXiv:2407.217832024arXiv preprint</p>
<p>Maxim Enis, Mark Hopkins, arXiv:2404.13813From LLM to NMT: Advancing low-resource machine translation with Claude. 2024arXiv preprint</p>
<p>A survey of LLM datasets: From autoregressive model to AI chatbot. Fei Du, Xin-Jian Ma, Jing-Ru Yang, Yi Liu, Chao-Ran, Xue-Bin Luo, Hai-Ou Wang, Xiang Jiang, Jing, Journal of Computer Science and Technology. 3932024</p>
<p>Roberto Gallotta, Graham Todd, Marvin Zammit, Sam Earle, Antonios Liapis, Julian Togelius, Georgios N Yannakakis, arXiv:2402.18659Large language models and games: A survey and roadmap. 2024arXiv preprint</p>
<p>Large language models and video games: A preliminary scoping review. Penny Sweetser, Proceedings of the 6th ACM Conference on Conversational User Interfaces. the 6th ACM Conference on Conversational User Interfaces2024</p>
<p>MarioGPT: Open-ended text2level generation through large language models. Shyam Sudhakaran, Miguel González-Duque, Matthias Freiberger, Claire Glanois, Elias Najarro, Sebastian Risi, Advances in Neural Information Processing Systems. 202436</p>
<p>Voyager: An open-ended embodied agent with large language models. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, Anima Anandkumar, arXiv:2305.162912023arXiv preprint</p>
<p>Leveraging the OPT large language model for sentiment analysis of game reviews. Markos Viggiato, Cor-Paul Bezemer, IEEE Transactions on Games. 2023</p>
<p>Towards automated video game commentary using generative AI. Noah Ranella, Markus Eger, EXAG@ AIIDE. 2023</p>
<p>Chatter generation through language models. Matthias Müller-Brockhausen, Giulio Barbero, Mike Preuss, IEEE Conference on Games. 2023</p>
<p>Generative agents: Interactive simulacra of human behavior. Sung Joon, Park, O' Joseph, Carrie Jun Brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. the 36th Annual ACM Symposium on User Interface Software and Technology2023</p>
<p>What if Red can talk? Dynamic dialogue generation using large language models. Navapat Nananukul, Wichayaporn Wongkamjan, arXiv:2407.203822024arXiv preprint</p>
<p>Sihao Hu, Tiansheng Huang, Fatih Ilhan, Selim Tekin, Gaowen Liu, Ramana Kompella, Ling Liu, arXiv:2404.02039A survey on large language model-based game agents. 2024arXiv preprint</p>
<p>Ben Goertzel, arXiv:2309.10371Generative AI vs. AGI: The cognitive strengths and weaknesses of modern LLMs. 2023arXiv preprint</p>
<p>Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, arXiv:2303.12712Sparks of artificial general intelligence: Early experiments with GPT-4. 2023arXiv preprint</p>
<p>Theory of self-reproducing automata. John Von, Neumann , Arthur Walter Burks, 1966University of Illinois PressUrbana</p>
<p>A brief history of cellular automata. Palash Sarkar, ACM Computing Surveys. 3212000</p>
<p>Mathematical games. Martin Gardner, Scientific American. 22261970</p>
<p>Cellular automata for realtime generation of infinite cave levels. Lawrence Johnson, Georgios N Yannakakis, Julian Togelius, Proceedings of the Workshop on Procedural Content Generation in Games. the Workshop on Procedural Content Generation in Games2010</p>
<p>Procedural maze level generation with evolutionary cellular automata. Chad Adams, Sushil Louis, IEEE Symposium Series on Computational Intelligence. 2017</p>
<p>Probabilistic cellular automata for granular media in video games. Jonathan Devlin, Micah D Schuster, The Computer Games Journal. 1012021</p>
<p>Realtime procedural terrain generation. Jacob Olsen, 2004</p>
<p>Sensitive dependence on initial conditions for cellular automata. Jesús Urıas, Raúl Rechtman, Agustın Enciso, Chaos: An Interdisciplinary Journal of Nonlinear Science. 741997</p>
<p>Learning cellular automaton dynamics with neural networks. N Wulff, J A Hertz, Advances in Neural Information Processing Systems. 51992</p>
<p>Ca-NEAT: Evolved compositional pattern producing networks for cellular automata morphogenesis and replication. Stefano Nichele, Mathias Berild Ose, Sebastian Risi, Gunnar Tufte, IEEE Transactions on Cognitive and Developmental Systems. 1032017</p>
<p>Growing neural cellular automata. Distill. Alexander Mordvintsev, Ettore Randazzo, Eyvind Niklasson, Michael Levin, 10.23915/distill.000232020</p>
<p>Illuminating diverse neural cellular automata for level generation. Sam Earle, Justin Snider, Matthew C Fontaine, Stefanos Nikolaidis, Julian Togelius, Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation Conference2022</p>
<p>µNCA: Texture generation with ultra-compact neural cellular automata. Alexander Mordvintsev, Eyvind Niklasson, arXiv:2111.135452021arXiv preprint</p>
<p>DyNCA: Real-time dynamic texture synthesis using neural cellular automata. Ehsan Pajouheshgar, Yitao Xu, Tong Zhang, Sabine Süsstrunk, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2023</p>
<p>Growing 3D artefacts and functional machines with neural cellular automata. Shyam Sudhakaran, Djordje Grbic, Siyan Li, Adam Katona, Elias Najarro, Claire Glanois, Sebastian Risi, Artificial Life Conference Proceedings. 3311082021</p>
<p>Mesh neural cellular automata. Ehsan Pajouheshgar, Yitao Xu, Alexander Mordvintsev, Eyvind Niklasson, Tong Zhang, Sabine Süsstrunk, ACM Transactions on Graphics. 4342024</p>
<p>Automata quest: NCAs as a video game life mechanic. Hiroki Sato, Tanner Lund, Takahide Yoshida, Atsushi Masumori, arXiv:2309.143642023arXiv preprint</p>
<p>Deep learning for procedural content generation. Jialin Liu, Sam Snodgrass, Ahmed Khalifa, Sebastian Risi, Georgios N Yannakakis, Julian Togelius, Neural Computing and Applications. 3312021</p>
<p>Quantum chemistry structures and properties of 134 kilo molecules. Raghunathan Ramakrishnan, O Pavlo, Matthias Dral, O Rupp, Von Anatole, Lilienfeld, Scientific Data. 112014</p>
<p>Density-functional thermochemistry. I. The effect of the exchange-only gradient correction. Axel D Becke, The Journal of Chemical Physics. 9631992</p>
<p>Surrogate models for uncertainty quantification: An overview. Bruno Sudret, Stefano Marelli, Joe Wiart, 11th European Conference on Antennas and Propagation. 2017</p>
<p>Physicsconstrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data. Yinhao Zhu, Nicholas Zabaras, Phaedon-Stelios Koutsourelakis, Paris Perdikaris, Journal of Computational Physics. 3942019</p>
<p>A deep-learning-based surrogate model for data assimilation in dynamic subsurface flow problems. Meng Tang, Yimin Liu, Louis J Durlofsky, Journal of Computational Physics. 4131094562020</p>
<p>Surrogate modeling of advanced computer simulations using deep Gaussian processes. I Majdi, Tomasz Radaideh, Kozlowski, Reliability Engineering &amp; System Safety. 1951067312020</p>
<p>A multifaceted surrogate model for search-based procedural content generation. Daniel Karavolos, Antonios Liapis, Georgios N Yannakakis, IEEE Transactions on Games. 1312019</p>
<p>Deep surrogate assisted generation of environments. Varun Bhatt, Bryon Tjanaka, Matthew Fontaine, Stefanos Nikolaidis, Advances in Neural Information Processing Systems. 202235</p>
<p>Pairing character classes in a deathmatch shooter game via a deep-learning surrogate model. Daniel Karavolos, Antonios Liapis, Georgios N Yannakakis, Proceedings of the 13th International Conference on the Foundations of Digital Games. the 13th International Conference on the Foundations of Digital Games2018</p>
<p>Using a surrogate model of gameplay for automated level design. Daniel Karavolos, Antonios Liapis, Georgios N Yannakakis, IEEE Conference on Computational Intelligence and Games. 2018</p>
<p>Deep surrogate assisted map-elites for automated hearthstone deckbuilding. Yulun Zhang, Matthew C Fontaine, Amy K Hoover, Stefanos Nikolaidis, Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation Conference2022</p>
<p>SuSketch: Surrogate models of gameplay as a design assistant. Panagiotis Migkotzidis, Antonios Liapis, IEEE Transactions on Games. 1422021</p>
<p>Learning the patterns of balance in a multi-player shooter game. Daniel Karavolos, Antonios Liapis, Georgios N Yannakakis, Proceedings of the 12th International Conference on the Foundations of Digital Games. the 12th International Conference on the Foundations of Digital Games2017</p>
<p>Unsupervised state representation learning in Atari. Ankesh Anand, Evan Racah, Sherjil Ozair, Yoshua Bengio, Marc-Alexandre Côté, R Devon Hjelm, Advances in Neural Information Processing Systems. 201932</p>
<p>Konstantinos Makantasis, Antonios Liapis, Georgios N Yannakakis, From pixels to affect: A study on games and player experience. 8th International Conference on Affective Computing and Intelligent Interaction. 2019</p>
<p>Actionconditional video prediction using deep networks in atari games. Junhyuk Oh, Xiaoxiao Guo, Honglak Lee, Richard L Lewis, Satinder Singh, Advances in Neural Information Processing Systems. 201528</p>
<p>Generative music in video games: State of the art, challenges, and prospects. Cale Plut, Philippe Pasquier, 2020Entertainment Computing33100337</p>
<p>Self-supervised learning: Generative or contrastive. Xiao Liu, Fanjin Zhang, Zhenyu Hou, Li Mian, Zhaoyu Wang, Jing Zhang, Jie Tang, IEEE Transactions on Knowledge and Data Engineering. 3512021</p>
<p>Selfsupervised learning of face representations for video face clustering. Vivek Sharma, Makarand Tapaswi, M Saquib Sarfraz, Rainer Stiefelhagen, 14th IEEE International Conference on Automatic Face &amp; Gesture Recognition. 2019</p>
<p>Self-supervised learning for anomaly detection with dynamic local augmentation. Seungdong Yoa, Seungjun Lee, Chiyoon Kim, Hyunwoo J Kim, IEEE Access. 92021</p>
<p>Hinton. Big self-supervised models are strong semi-supervised learners. Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, Geoffrey E , Advances in Neural Information Processing Systems. 202033</p>
<p>A survey on contrastive self-supervised learning. Ashish Jaiswal, Ramesh Ashwin, Mohammad Zaki Babu, Debapriya Zadeh, Fillia Banerjee, Makedon, 20209Technologies</p>
<p>Learning task-independent game state representations from unlabeled images. Chintan Trivedi, Konstantinos Makantasis, Antonios Liapis, Georgios N Yannakakis, IEEE Conference on Games. 2022</p>
<p>Chintan Trivedi, Konstantinos Makantasis, Antonios Liapis, Georgios N Yannakakis, arXiv:2307.11141Towards general game representations: Decomposing games pixels into content and style. 2023arXiv preprint</p>
<p>Contrastive learning of generalized game representations. Chintan Trivedi, Antonios Liapis, Georgios N Yannakakis, IEEE Conference on Games. 2021</p>
<p>Self-supervised contrastive learning for predicting game strategies. Jae Young, Insung Lee, Uk Baek, Jaehoon Jo, Jinsoo Kim, Keewon Bae, Seoung Bum Jeong, Kim, Proceedings of SAI Intelligent Systems Conference. SAI Intelligent Systems Conference2022</p>
<p>Comparing learning methodologies for self-supervised audio-visual representation learning. Hacene Terbouche, Liam Schoneveld, Oisin Benson, Alice Othmani, IEEE Access. 102022</p>
<p>Nemanja Rašajski, Chintan Trivedi, arXiv:2402.01335Konstantinos Makantasis, Antonios Liapis, and Georgios N. Yannakakis. BehAVE: Behaviour alignment of video game encodings. 2024arXiv preprint</p>
<p>Game state learning via game scene augmentation. Chintan Trivedi, Konstantinos Makantasis, Antonios Liapis, Georgios N Yannakakis, Proceedings of the 17th International Conference on the Foundations of Digital Games. the 17th International Conference on the Foundations of Digital Games2022</p>
<p>Creating multimodal interactive agents with imitation and self-supervised learning. Deepmind Interactive, Agents Team, Josh Abramson, Arun Ahuja, Arthur Brussee, Federico Carnevale, Mary Cassin, Felix Fischer, Petko Georgiev, Alex Goldin, Mansi Gupta, arXiv:2112.037632021arXiv preprint</p>
<p>STARLING: Self-supervised training of text-based reinforcement learning agent with large language models. Shreyas Basavatia, Keerthiram Murugesan, Shivam Ratnakar, arXiv:2406.058722024arXiv preprint</p>
<p>Nazanin Yousefzadeh, Khameneh , Matthew Guzdial, arXiv:2010.01685Entity embedding as game representation. 2020arXiv preprint</p>
<p>CURL: Contrastive unsupervised representations for reinforcement learning. Michael Laskin, Aravind Srinivas, Pieter Abbeel, International Conference on Machine Learning. 2020</p>
<p>A path towards autonomous machine intelligence version 0. Yann Lecun, Open Review. 912022</p>
<p>Introduction to latent variable energy-based models: A path toward autonomous machine intelligence. Anna Dawid, Yann Lecun, Journal of Statistical Mechanics: Theory and Experiment. 2024101040112024</p>
<p>Self-supervised learning from images with a jointembedding predictive architecture. Mahmoud Assran, Quentin Duval, Ishan Misra, Piotr Bojanowski, Pascal Vincent, Michael Rabbat, Yann Lecun, Nicolas Ballas, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2023</p>
<p>Bootstrap your own latent -a new approach to self-supervised learning. Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, Advances in Neural Information Processing Systems. 202033</p>
<p>Jake Bruce, Michael D Dennis, Ashley Edwards, Jack Parker-Holder, Yuge Shi, Edward Hughes, Matthew Lai, Aditi Mavalankar, Richie Steigerwald, Chris Apps, Generative interactive environments. International Conference on Machine Learning. 2024</p>
<p>Mingxing Xu, Wenrui Dai, Chunmiao Liu, Xing Gao, Weiyao Lin, Guo-Jun Qi, Hongkai Xiong, arXiv:2001.02908Spatial-temporal transformer networks for traffic flow forecasting. 2020arXiv preprint</p>
<p>Neural discrete representation learning. Aaron Van Den, Oriol Oord, Koray Vinyals, Kavukcuoglu, Advances in Neural Information Processing Systems. 201730</p>
<p>Maskgit: Masked generative image transformer. Huiwen Chang, Han Zhang, Lu Jiang, Ce Liu, William T Freeman, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022</p>
<p>Photorealistic text-to-image diffusion models with deep language understanding. Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, Advances in Neural Information Processing Systems. 202235</p>
<p>. David Ha, Jürgen Schmidhuber, arXiv:1803.101222018World models. arXiv preprint</p>
<p>Google Deepmind, Genie 2: A large-scale foundation world model. </p>
<p>Scaling instructable agents across many simulated worlds. Maria Abi Raad, Arun Ahuja, Catarina Barros, Frederic Besse, Andrew Bolt, Adrian Bolton, Bethanie Brownfield, Gavin Buttimore, Max Cant, Sarah Chakera, arXiv:2404.101792024arXiv preprint</p>
<p>A survey on simulators for testing self-driving cars. Prabhjot Kaur, Samira Taghavi, Zhaofeng Tian, Weisong Shi, Fourth International Conference on Connected and Autonomous Driving. 2021</p>
<p>Super Mario as a string: Platformer level generation via LSTMs, author=Summerville, Adam and Mateas. arXiv:1603.00930year=2016Michaeljournal=arXiv preprint</p>
<p>Virtual reality for medical training: The state-ofthe-art. Greg S Ruthenbeck, Karen J Reynolds, Journal of Simulation. 912015</p>
<p>Flight simulation: Virtual environments in aviation. Alfred T Lee, 2017Routledge</p>
<p>Augmenting LLMs with knowledge: A survey on hallucination prevention. Konstantinos Andriopoulos, Johan Pouwelse, arXiv:2309.164592023arXiv preprint</p>
<p>The troubling emergence of hallucination in large language models-an extensive definition, quantification, and prescriptive remediations. Swagata Vipula Rawte, Agnibh Chakraborty, Anubhav Pathak, S M Sarkar, Aman Tonmoy, Amit P Chadha, Amitava Sheth, Das, arXiv:2310.049882023arXiv preprint</p>
<p>Efficient deep learning: A survey on making deep learning models smaller, faster, and better. Gaurav Menghani, ACM Computing Surveys. 55122023</p>
<p>Latent action pretraining from videos. Seonghyeon Ye, Joel Jang, Byeongguk Jeon, Sejune Joo, Jianwei Yang, Baolin Peng, Ajay Mandlekar, Reuben Tan, Yu-Wei Chao, Bill Yuchen Lin, arXiv:2410.117582024arXiv preprint</p>
<p>LLM4GEN: Leveraging semantic representation of LLMs for text-to-image generation. Mushui Liu, Yuhang Ma, Yang Zhen, Jun Dan, Yunlong Yu, Zeng Zhao, Zhipeng Hu, Bai Liu, Changjie Fan, arXiv:2407.007372024arXiv preprint</p>
<p>LayoutLLM-T2I: Eliciting layout guidance from LLM for text-to-image generation. Leigang Qu, Shengqiong Wu, Hao Fei, Liqiang Nie, Tat-Seng Chua, Proceedings of the 31st ACM International Conference on Multimedia. the 31st ACM International Conference on Multimedia2023</p>
<p>LLM-grounded diffusion: Enhancing prompt understanding of text-to-image diffusion models with large language models. Long Lian, Boyi Li, Adam Yala, Trevor Darrell, arXiv:2305.136552023arXiv preprint</p>
<p>Deep learning for video game playing. Niels Justesen, Philip Bontrager, Julian Togelius, Sebastian Risi, IEEE Transactions on Games. 1212019</p>
<p>Data management challenges for deep learning. Aiswarya Munappy, Jan Bosch, Helena Holmström Olsson, Anders Arpteg, Björn Brinne, 45th Euromicro Conference on Software Engineering and Advanced Applications. 2019</p>
<p>Understanding intermediate layers using linear classifier probes. Guillaume Alain, Yoshua Bengio, arXiv:1610.016442016arXiv preprint</p>
<p>Opening the black box of deep neural networks via information. Ravid Shwartz, -Ziv , Naftali Tishby, arXiv:1703.008102017arXiv preprint</p>
<p>Misbehaviour prediction for autonomous driving systems. Andrea Stocco, Michael Weiss, Marco Calzana, Paolo Tonella, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering. the ACM/IEEE 42nd International Conference on Software Engineering2020</p>
<p>Synthetic data for deep learning. I Sergey, Nikolenko, 2021Springer174</p>
<p>Geoffrey Hinton, Oriol Vinyals, Jeff Dean, arXiv:1503.02531Distilling the knowledge in a neural network. 2015arXiv preprint</p>
<p>What is the state of neural network pruning?. Davis Blalock, Jose , Javier Gonzalez Ortiz, Jonathan Frankle, John Guttag, Proceedings of Machine Learning and Systems. Machine Learning and Systems20202</p>
<p>Mengxia Yu, De Wang, Qi Shan, Alvin Wan, arXiv:2411.07191The super weight in large language models. 2024arXiv preprint</p>
<p>Arun Das, Paul Rad, arXiv:2006.11371Opportunities and challenges in explainable artificial intelligence (XAI): A survey. 2020arXiv preprint</p>
<p>Opportunities and challenges in deep learning adversarial robustness: A survey. Henrique Samuel, Peyman Silva, Najafirad, arXiv:2007.007532020arXiv preprint</p>
<p>Procedural content generation through quality diversity. Daniele Gravina, Ahmed Khalifa, Antonios Liapis, Julian Togelius, Yannakakis, N Georgios, IEEE Conference on Games. 2019</p>
<p>Differentiable quality diversity. Matthew Fontaine, Stefanos Nikolaidis, Advances in Neural Information Processing Systems. 202134</p>            </div>
        </div>

    </div>
</body>
</html>