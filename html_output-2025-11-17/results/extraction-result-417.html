<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-417 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-417</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-417</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-263789994</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1610.08602v2.pdf" target="_blank">A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications</a></p>
                <p><strong>Paper Abstract:</strong> In this paper we present a broad overview of the last 40 years of research on cognitive architectures. Although the number of existing architectures is nearing several hundred, most of the existing surveys do not reflect this growth and focus on a handful of well-established architectures. Thus, in this survey we wanted to shift the focus towards a more inclusive and high-level overview of the research on cognitive architectures. Our final set of 85 architectures includes 49 that are still actively developed, and borrow from a diverse set of disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we discuss only the core cognitive abilities, such as perception, attention mechanisms, action selection, memory, learning and reasoning. In order to assess the breadth of practical applications of cognitive architectures we gathered information on over 900 practical projects implemented using the cognitive architectures in our list. We use various visualization techniques to highlight overall trends in the development of the field. In addition to summarizing the current state-of-the-art in the cognitive architecture research, this survey describes a variety of methods and ideas that have been tried and their relative success in modeling human cognitive abilities, as well as which aspects of cognitive behavior need more research with respect to their mechanistic counterparts and thus can further inform how cognitive science might progress.</p>
                <p><strong>Cost:</strong> 0.034</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e417.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e417.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ACT-R</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adaptive Control of Thought—Rational (ACT-R)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cognitive architecture combining symbolic production rules and declarative chunks with subsymbolic mechanisms (activation values, spreading activation and stochastic selection) to model human cognition; explicitly self-identifies as hybrid in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ACT-R</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>ACT-R is presented as a hybrid cognitive architecture whose symbolic layer consists of production rules and declarative chunks (symbolic atoms manipulated syntactically) while a subsymbolic layer supplies activation values, spreading activation and probabilistic/stochastic selection to bias retrieval and production firing; used to model human-like reasoning, memory and attention.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Symbolic production-rule system and declarative memory of chunks (localist symbols/relations used for syntactic inference and planning).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Subsymbolic activation mechanisms, spreading activation, stochastic selection processes and reinforcement-learning-like adjustments to production utility (procedural tuning); numeric activation values mediate retrieval and selection.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Tight hybridization where subsymbolic activations modulate symbolic retrieval and rule selection (activation-driven retrieval and utility-guided production firing); symbolic structures remain explicit while numeric activations provide soft competition and decay.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Human-like memory phenomena (limited-capacity working memory, decay, priming effects), graded retrieval and probabilistic reasoning emergent from interaction of symbolic rules with subsymbolic activations; more robust retrieval under uncertainty than pure symbolic rules.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Used across many cognitive modeling tasks in the survey (reasoning, memory tasks, attentional blink, Tower of Hanoi models), i.e., psychological experiment replication and embodied HRI tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Survey reports ACT-R models generalize to multiple human experimental paradigms due to subsymbolic biasing enabling graded behavior under partial knowledge; explicit claims about out-of-distribution or compositional generalization are not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High interpretability from the symbolic layer (rules and chunks) which can be inspected and used to generate explanations, while subsymbolic activations provide quantitative rationale for selection.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Scaling long-term declarative memory and detailed perceptual processing; the survey notes perception and large-scale memory as challenges; specific numeric limitations are not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Complementary strengths: symbolic explicit representations for reasoning and procedural control, subsymbolic activations for graded retrieval and learning — division of labor between transparent symbolic rules and continuous modulatory processes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications', 'publication_date_yy_mm': '2016-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e417.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e417.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CLARION</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CLARION (Connectionist Learning with Adaptive Rule Induction ONline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid architecture that explicitly separates implicit (subsymbolic) and explicit (symbolic) knowledge into two interacting subsystems, enabling modeling of both automatic and declarative behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CLARION</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CLARION implements a two-level hybrid where implicit knowledge is captured by distributed subsymbolic structures (neural-network-like) and explicit knowledge by symbolic rules/chunks; the two interact (implicit guides behavior and is made explicit via rule-extraction mechanisms).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Explicit symbolic component: transparent symbolic rules/representations (chunks) that capture consciously accessible knowledge and can be used for reasoning and explanation.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Implicit/subsymbolic component: distributed numerical representations (neural-network style) encoding procedural/skill knowledge and associative mappings.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Bi-level integration: explicit (symbolic) and implicit (subsymbolic) stores communicate bidirectionally — implicit generates behavior and can be promoted to explicit rules (rule extraction); explicit knowledge can initialize or bias implicit learning.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Ability to model interplay between fast automatic skills and slower explicit reasoning (e.g., proceduralization, skill transfer), accounts for priming and both implicit and explicit learning phenomena not captured by either component alone.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Psychological modeling tasks including priming, lexical decision tasks, and skill learning scenarios (survey cites CLARION models for lexical priming and skill phenomena).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Hybrid enables transfer of learned implicit patterns into explicit rules for reuse; survey states CLARION can explain a range of psychological phenomena, but no quantitative OOD/generalization metrics are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Explicit symbolic layer affords interpretability and explicit explanations; implicit layer remains distributed and less interpretable but contributes adaptability.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Survey notes general difficulty quantifying large-scale memory and scaling; CLARION specific limitations (e.g., utility problem, rule explosion) are not numerically characterized in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Division-of-labor theory: explicit/implicit separation mirrors conscious vs. unconscious knowledge, enabling complementary coverage of reasoning and automatic skill execution.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications', 'publication_date_yy_mm': '2016-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e417.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e417.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DUAL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DUAL cognitive architecture</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A fully hybrid multi-agent architecture composed of numerous micro-agents, each with co-located symbolic and subsymbolic representations, enabling micro-level integration and emergent cognitive behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DUAL</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>DUAL consists of many interacting hybrid micro-agents; each micro-agent pairs a symbolic representation with a subsymbolic substrate, and cognition emerges from their high-degree interconnection and competition/cooperation.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Local symbolic representations within micro-agents (concepts/atoms used for inference and symbolic chaining).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Subsymbolic substrates per micro-agent (activation levels, attractor dynamics) supporting graded activation, priming and associative processing.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Micro-level hybridization: symbolic and subsymbolic representations are co-located within agents and interact locally; global cognition emerges from networked agent interactions (competition, spreading activation, binding).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Analogical reasoning, priming and creative analogical search behaviors that emerge from micro-agent dynamics and cross-agent interactions; allows modelling of graded priming and creative problem-solving effects.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Used to model analogical reasoning and priming phenomena in cognitive experiments (survey references analogical reasoning micro-domain examples).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Micro-agent coupling yields flexible, context-sensitive generalization and dynamic recombination of knowledge; the survey describes capability qualitatively but provides no quantitative generalization metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Symbolic micro-components provide local interpretability, but global emergent behavior can be less transparent due to many interacting agents.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Complexity of analyzing emergent global behavior and engineering interfaces; survey notes difficulty in clearly identifying hybridization in many works and scaling concerns generally.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Emergence via many interacting hybrid micro-agents: cognitive functions arise from local symbolic/subsymbolic interaction rather than from a centralized separation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications', 'publication_date_yy_mm': '2016-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e417.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e417.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CogPrime</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CogPrime (Novamente / OpenCog family)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A fully integrated hybrid architecture that combines symbolic concept representations and rules with subsymbolic mechanisms (activation, spreading activation, stochastic processes, reinforcement learning) aiming toward AGI.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CogPrime</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CogPrime is described as conceptually closer to emergent systems but fully hybrid: it integrates symbolic knowledge structures and rule-based processing with subsymbolic processes like spreading activation, stochastic selection and learning, supporting broad AGI-oriented goals.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Explicit symbolic concept networks/knowledge graphs and rule-based inference (symbolic knowledge representations for reasoning and planning).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Subsymbolic mechanisms including spreading activation, stochastic selection, reinforcement-learning components, and connectionist modules for perception/learning.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Fully integrated hybridization where symbolic knowledge (concept graphs/rules) and subsymbolic processes interact via activation spreading, probabilistic selection and learning loops; symbolic structures receive probabilistic weights and are influenced by subsymbolic signals.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Flexible behavior across perception, planning and learning; capacity to combine probabilistic/reactive decisions with explicit reasoning to handle sparse knowledge and continuous learning scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Applied across diverse practical applications in survey (virtual agents, learning tasks, reasoning); often used as an AGI testbed rather than a single benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Designed to leverage symbolic structure for compositional generalization while subsymbolic learning handles perception and noisy data; survey gives conceptual claims but no quantitative cross-distribution metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Symbolic graph and rule components provide interpretable structure and potential explanations, while stochastic/subsymbolic elements reduce transparency for some behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Survey highlights that many AGI-scale hybrid systems face scaling, reproducibility and engineering-detail gaps; CogPrime's concrete performance figures are not reported in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Hybrid AGI principle: integrate symbolic reasoning for compositionality and explanation with subsymbolic learning for perception and adaptivity; cognitive synergy between modules.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications', 'publication_date_yy_mm': '2016-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e417.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e417.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CAPS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CAPS (Cognitive Architecture for Perception and Symbolism)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid cognitive architecture combining symbolic reasoning with subsymbolic activation mechanisms to model perception, memory and reasoning in a unified framework.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CAPS</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CAPS is listed among fully integrated architectures combining explicit symbolic representations with subsymbolic processes (activation, graded retrieval) to support memory, reasoning and perceptual tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Symbolic representations and production-like rules for reasoning and planning (explicit symbolic structures).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Activation-based subsymbolic processes and neural-style dynamics that influence retrieval and decision-making.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Symbolic processing modulated by subsymbolic activation dynamics (spreading activation and graded retrieval) providing a hybrid control loop.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Models of limited-capacity working memory, activation-driven retrieval and graded attention effects; bridges symbolic planning with graded perceptual selection.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Psychological tasks and cognitive modeling including working memory and syntax parsing scenarios (survey references CAPS uses).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Enables behavior that is robust to incomplete knowledge via activation-modulated retrieval; no quantitative generalization claims in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Symbolic layer offers interpretable rules and traces; subsymbolic activations provide quantitative modulation but reduce full transparency.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Survey does not provide numeric performance; general limitations echo survey-wide scaling and perceptual modeling gaps.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Complementary strengths: symbolic control plus subsymbolic modulation to capture graded human-like cognitive effects.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications', 'publication_date_yy_mm': '2016-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e417.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e417.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GMU-BICA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GMU-BICA (George Mason University - Biologically Inspired Cognitive Architecture)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A fully integrated hybrid architecture developed under the BICA program combining symbolic knowledge and subsymbolic learning/activation mechanisms toward biologically-inspired cognition.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GMU-BICA</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GMU-BICA is a hybrid, biologically-inspired architecture that integrates symbolic representations and reasoning with subsymbolic processes (activation, learning) and multiple interacting modules to approximate cognitive functionality.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Symbolic knowledge structures and rule-like representations for high-level reasoning and planning.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Subsymbolic modules (activation/spreading, learning algorithms) for perception, pattern association and graded control.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Fully integrated multi-module hybridization with symbolic knowledge interacting with subsymbolic learning and activation processes; modules exchange information and biases between representations.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Aims to produce biologically plausible behaviors combining rule-based decisions with learned perceptual mappings and graded attention, enabling richer cognitive-functional repertoire than pure-symbolic systems.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Used as part of BICA program demonstration tasks (survey groups it with fully integrated hybrids) but specific benchmark metrics are not given.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Intended to improve robustness and adaptability by combining symbolic generalization with subsymbolic perceptual learning; survey provides conceptual claims only.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Symbolic components permit explanation; integrated subsymbolic portions reduce full-system interpretability but contribute adaptive capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>No quantitative performance reported; survey highlights general engineering and scaling difficulties for biologically-inspired hybrids.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Biologically-inspired complementary integration: use symbolic representations for abstract cognition while subsymbolic modules encode biologically plausible learning and perception.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications', 'publication_date_yy_mm': '2016-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e417.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e417.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sigma</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sigma cognitive architecture</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid architecture that blends symbolic representations with probabilistic/subsymbolic computation in a graphical framework, aiming to integrate reasoning, learning and perception.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Sigma</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Sigma is described as a fully integrated hybrid that conceptually leans toward emergent systems by sharing properties with neural networks, but explicitly integrates symbolic concepts/rules with probabilistic/subsymbolic mechanisms in a graphical architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Symbolic concepts and rule-like structures; knowledge represented in forms that support combinatorial and logical reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Probabilistic/subsymbolic computations (graphical models / trellis graphs / message-passing) and stochastic selection; can implement reinforcement learning and probabilistic inference.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Graphical-factor style integration where symbolic relations are embedded in probabilistic graphical structures and probabilistic message-passing / inference interacts with symbolic reasoning; symbolic and probabilistic modules exchange beliefs via factorization.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Supports flexible reasoning (including theory-of-mind modeling via trellis graphs), probabilistic decision-making and integration of planning with uncertainty handling not available in pure symbolic or pure neural systems alone.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Survey cites Sigma used for modeling two-player games and two mechanisms for theory-of-mind (e.g., Prisoner's Dilemma); employed for probabilistic reasoning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Sigma's probabilistic integration is intended to handle uncertain and sparse knowledge better than pure symbolic systems; survey reports conceptual capabilities but no numeric generalization benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Graphical structure supports traceable probabilistic inference and symbolic reasoning steps enabling some interpretability; low-level probabilistic messages can be less intuitive.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Survey does not provide numeric evaluation; general limitations include engineering complexity and lack of large-scale evaluation reported in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Combines symbolic logic and probabilistic graphical modeling to leverage strengths of both: explicit structure/compositionality with uncertainty-tolerant inference.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications', 'publication_date_yy_mm': '2016-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e417.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e417.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ADAPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ADAPT (Architecture using Soar + Perception Modules)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid architecture that composes an existing symbolic cognitive architecture (Soar) with separate sub-symbolic sensor and perception modules to leverage strengths of each.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ADAPT (Soar + perception modules)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>ADAPT uses Soar as the symbolic controller for deliberative tasks while delegating sensor processing and 3D world modeling to separate sub-symbolic modules; integration is via designed interfaces so Soar issues control and receives processed percepts.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Soar symbolic control: production rules, goal/plan management and symbolic knowledge for decision-making.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Subsymbolic sensor-processing modules (vision/3D modeling pipelines, perception algorithms possibly neural or engineered), pre-processing raw sensor data into symbolic assertions.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular, coarse-grained integration: dedicated interfaces map processed subsymbolic percepts into symbolic facts for Soar; Soar supplies control commands to perception modules — a pipeline/co-processing approach.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables robust real-world perception-driven behavior by combining mature symbolic planning/control with engineered or learned perceptual processing, yielding capabilities (e.g., embodied navigation) not present in Soar alone.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Robotics tasks: ADAPT used in embodied robot scenarios (navigation and manipulation) as noted in the survey; no numeric benchmarks provided.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Modular design allows leveraging perceptual generalization from sub-symbolic modules while preserving symbolic planning generality; survey gives qualitative assessment only.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Symbolic Soar controller remains interpretable; perceptual modules are black-boxes whose outputs are symbolicized, so end-to-end transparency depends on module instrumentation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Requires engineering effort to design interfaces and translations between modules; survey mentions cost of building interfaces and limited discussion of end-to-end training.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Functional modularity: assign perception to sub-symbolic modules and control/reasoning to symbolic systems, connecting via engineered interfaces to exploit each side's strengths.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications', 'publication_date_yy_mm': '2016-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e417.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e417.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SAL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SAL (Symbolic-Subsymbolic ALliance) - ACT-R + Leabra example</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid system combining ACT-R symbolic control with Leabra neural models, where ACT-R guides learning of Leabra neural models to integrate symbolic guidance with biologically-inspired learning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SAL (ACT-R + Leabra integration)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>SAL exemplifies a hybrid that pairs ACT-R's symbolic control and cognitive modeling with Leabra's biologically-plausible neural networks; ACT-R provides guidance and structure for training Leabra perceptual/behavioral models.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>ACT-R symbolic production rules and declarative chunks for task guidance, planning and high-level control.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Leabra neural models (biologically inspired connectionist networks) for perceptual and lower-level processing and learning.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Cross-architecture training: ACT-R guides or constraints learning of Leabra models (symbolic top-down supervision to train subsymbolic networks), a co-processing/teacher-student style integration.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Combines symbolic reasoning/planning with biologically plausible neural learning to produce perceptually grounded, neurally plausible behaviors informed by symbolic task structure; supports learning in neural models that align with symbolic expectations.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Learning tasks where ACT-R instructs Leabra models (survey references SAL as an example of combining architectures), but no quantitative benchmark numbers provided in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Symbolic guidance can improve sample-efficiency and structure of neural learning; survey describes conceptually but provides no quantitative OOD generalization measures.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Symbolic ACT-R layer is interpretable and provides explicit rationale; learned neural components are less interpretable though constrained by symbolic guidance.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Needs careful engineering to coordinate learning signals and representations across architectures; survey does not list numeric failure modes.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Teacher-student / guided-learning hybridization: explicit symbolic structures scaffold and shape subsymbolic learning to attain both interpretability and neural plausibility.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications', 'publication_date_yy_mm': '2016-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e417.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e417.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SiMA / ARS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SiMA (formerly ARS) / ARS-SiMA</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-level hybridization where neural networks construct 'neurosymbols' from sensors/actuators (connectionist logic systems) and a top symbolic processing layer operates on those neurosymbols.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SiMA (ARS)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>SiMA hybridizes on multiple levels: bottom-up neural networks transform sensory inputs into structured neurosymbols (connectionist logic systems) and a top-level symbolic processor reasons over these neurosymbols, creating an integrated perception-reasoning stack.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Top-layer symbolic processing system operating on neurosymbols (explicit symbols used for higher-level inference and planning).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Lower-level neural networks / connectionist modules that build neurosymbols from raw sensors and actuators; connectionist logic systems produce structured representations.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Hierarchical multi-level integration: subsymbolic neural modules produce intermediate symbol-like representations (neurosymbols) which are consumed by a symbolic reasoning layer (symbolic subprocessing).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables symbol grounding: raw sensory data is converted into structured symbolic-like units enabling symbolic reasoning grounded in perception; improves robustness to noisy sensors while retaining symbolic compositionality.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Perception-to-reasoning robotic and cognitive tasks where sensor data must be converted into symbolic representations for planning; survey gives conceptual description without numeric benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Hierarchical grounding supports better transfer from perception to symbolic reasoning relative to purely symbolic systems lacking grounding; quantitative generalization claims are not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Top symbolic layer interpretable; neurosymbols provide an intermediate level that can be inspected; lower-level networks may remain opaque.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Engineering cost of building reliable neurosymbol extraction and alignment to symbolic vocabularies; survey notes that many hybridization strategies are underdocumented.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Grounding principle: build symbol-like constructs from learned subsymbolic structures, then leverage symbolic reasoning — a hierarchical hybridization strategy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications', 'publication_date_yy_mm': '2016-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Desiderata for cognitive architectures <em>(Rating: 2)</em></li>
                <li>Hybrid Connectionist-Symbolic Modules <em>(Rating: 2)</em></li>
                <li>The DUAL Cognitive Architecture: A Hybrid Multi-Agent Approach <em>(Rating: 2)</em></li>
                <li>A Standard Model for the Mind: Toward a Common Computational Framework across Artificial Intelligence <em>(Rating: 2)</em></li>
                <li>Integrating top-down expectations with bottom-up perceptual processing in a hybrid neural-symbolic architecture <em>(Rating: 2)</em></li>
                <li>Integrating deep learning based perception with probabilistic logic via frequent pattern mining <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-417",
    "paper_id": "paper-263789994",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "ACT-R",
            "name_full": "Adaptive Control of Thought—Rational (ACT-R)",
            "brief_description": "A cognitive architecture combining symbolic production rules and declarative chunks with subsymbolic mechanisms (activation values, spreading activation and stochastic selection) to model human cognition; explicitly self-identifies as hybrid in the survey.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "ACT-R",
            "system_description": "ACT-R is presented as a hybrid cognitive architecture whose symbolic layer consists of production rules and declarative chunks (symbolic atoms manipulated syntactically) while a subsymbolic layer supplies activation values, spreading activation and probabilistic/stochastic selection to bias retrieval and production firing; used to model human-like reasoning, memory and attention.",
            "declarative_component": "Symbolic production-rule system and declarative memory of chunks (localist symbols/relations used for syntactic inference and planning).",
            "imperative_component": "Subsymbolic activation mechanisms, spreading activation, stochastic selection processes and reinforcement-learning-like adjustments to production utility (procedural tuning); numeric activation values mediate retrieval and selection.",
            "integration_method": "Tight hybridization where subsymbolic activations modulate symbolic retrieval and rule selection (activation-driven retrieval and utility-guided production firing); symbolic structures remain explicit while numeric activations provide soft competition and decay.",
            "emergent_properties": "Human-like memory phenomena (limited-capacity working memory, decay, priming effects), graded retrieval and probabilistic reasoning emergent from interaction of symbolic rules with subsymbolic activations; more robust retrieval under uncertainty than pure symbolic rules.",
            "task_or_benchmark": "Used across many cognitive modeling tasks in the survey (reasoning, memory tasks, attentional blink, Tower of Hanoi models), i.e., psychological experiment replication and embodied HRI tasks.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Survey reports ACT-R models generalize to multiple human experimental paradigms due to subsymbolic biasing enabling graded behavior under partial knowledge; explicit claims about out-of-distribution or compositional generalization are not provided.",
            "interpretability_properties": "High interpretability from the symbolic layer (rules and chunks) which can be inspected and used to generate explanations, while subsymbolic activations provide quantitative rationale for selection.",
            "limitations_or_failures": "Scaling long-term declarative memory and detailed perceptual processing; the survey notes perception and large-scale memory as challenges; specific numeric limitations are not reported.",
            "theoretical_framework": "Complementary strengths: symbolic explicit representations for reasoning and procedural control, subsymbolic activations for graded retrieval and learning — division of labor between transparent symbolic rules and continuous modulatory processes.",
            "uuid": "e417.0",
            "source_info": {
                "paper_title": "A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications",
                "publication_date_yy_mm": "2016-10"
            }
        },
        {
            "name_short": "CLARION",
            "name_full": "CLARION (Connectionist Learning with Adaptive Rule Induction ONline)",
            "brief_description": "A hybrid architecture that explicitly separates implicit (subsymbolic) and explicit (symbolic) knowledge into two interacting subsystems, enabling modeling of both automatic and declarative behaviors.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "CLARION",
            "system_description": "CLARION implements a two-level hybrid where implicit knowledge is captured by distributed subsymbolic structures (neural-network-like) and explicit knowledge by symbolic rules/chunks; the two interact (implicit guides behavior and is made explicit via rule-extraction mechanisms).",
            "declarative_component": "Explicit symbolic component: transparent symbolic rules/representations (chunks) that capture consciously accessible knowledge and can be used for reasoning and explanation.",
            "imperative_component": "Implicit/subsymbolic component: distributed numerical representations (neural-network style) encoding procedural/skill knowledge and associative mappings.",
            "integration_method": "Bi-level integration: explicit (symbolic) and implicit (subsymbolic) stores communicate bidirectionally — implicit generates behavior and can be promoted to explicit rules (rule extraction); explicit knowledge can initialize or bias implicit learning.",
            "emergent_properties": "Ability to model interplay between fast automatic skills and slower explicit reasoning (e.g., proceduralization, skill transfer), accounts for priming and both implicit and explicit learning phenomena not captured by either component alone.",
            "task_or_benchmark": "Psychological modeling tasks including priming, lexical decision tasks, and skill learning scenarios (survey cites CLARION models for lexical priming and skill phenomena).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Hybrid enables transfer of learned implicit patterns into explicit rules for reuse; survey states CLARION can explain a range of psychological phenomena, but no quantitative OOD/generalization metrics are provided.",
            "interpretability_properties": "Explicit symbolic layer affords interpretability and explicit explanations; implicit layer remains distributed and less interpretable but contributes adaptability.",
            "limitations_or_failures": "Survey notes general difficulty quantifying large-scale memory and scaling; CLARION specific limitations (e.g., utility problem, rule explosion) are not numerically characterized in the survey.",
            "theoretical_framework": "Division-of-labor theory: explicit/implicit separation mirrors conscious vs. unconscious knowledge, enabling complementary coverage of reasoning and automatic skill execution.",
            "uuid": "e417.1",
            "source_info": {
                "paper_title": "A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications",
                "publication_date_yy_mm": "2016-10"
            }
        },
        {
            "name_short": "DUAL",
            "name_full": "DUAL cognitive architecture",
            "brief_description": "A fully hybrid multi-agent architecture composed of numerous micro-agents, each with co-located symbolic and subsymbolic representations, enabling micro-level integration and emergent cognitive behavior.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "DUAL",
            "system_description": "DUAL consists of many interacting hybrid micro-agents; each micro-agent pairs a symbolic representation with a subsymbolic substrate, and cognition emerges from their high-degree interconnection and competition/cooperation.",
            "declarative_component": "Local symbolic representations within micro-agents (concepts/atoms used for inference and symbolic chaining).",
            "imperative_component": "Subsymbolic substrates per micro-agent (activation levels, attractor dynamics) supporting graded activation, priming and associative processing.",
            "integration_method": "Micro-level hybridization: symbolic and subsymbolic representations are co-located within agents and interact locally; global cognition emerges from networked agent interactions (competition, spreading activation, binding).",
            "emergent_properties": "Analogical reasoning, priming and creative analogical search behaviors that emerge from micro-agent dynamics and cross-agent interactions; allows modelling of graded priming and creative problem-solving effects.",
            "task_or_benchmark": "Used to model analogical reasoning and priming phenomena in cognitive experiments (survey references analogical reasoning micro-domain examples).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Micro-agent coupling yields flexible, context-sensitive generalization and dynamic recombination of knowledge; the survey describes capability qualitatively but provides no quantitative generalization metrics.",
            "interpretability_properties": "Symbolic micro-components provide local interpretability, but global emergent behavior can be less transparent due to many interacting agents.",
            "limitations_or_failures": "Complexity of analyzing emergent global behavior and engineering interfaces; survey notes difficulty in clearly identifying hybridization in many works and scaling concerns generally.",
            "theoretical_framework": "Emergence via many interacting hybrid micro-agents: cognitive functions arise from local symbolic/subsymbolic interaction rather than from a centralized separation.",
            "uuid": "e417.2",
            "source_info": {
                "paper_title": "A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications",
                "publication_date_yy_mm": "2016-10"
            }
        },
        {
            "name_short": "CogPrime",
            "name_full": "CogPrime (Novamente / OpenCog family)",
            "brief_description": "A fully integrated hybrid architecture that combines symbolic concept representations and rules with subsymbolic mechanisms (activation, spreading activation, stochastic processes, reinforcement learning) aiming toward AGI.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "CogPrime",
            "system_description": "CogPrime is described as conceptually closer to emergent systems but fully hybrid: it integrates symbolic knowledge structures and rule-based processing with subsymbolic processes like spreading activation, stochastic selection and learning, supporting broad AGI-oriented goals.",
            "declarative_component": "Explicit symbolic concept networks/knowledge graphs and rule-based inference (symbolic knowledge representations for reasoning and planning).",
            "imperative_component": "Subsymbolic mechanisms including spreading activation, stochastic selection, reinforcement-learning components, and connectionist modules for perception/learning.",
            "integration_method": "Fully integrated hybridization where symbolic knowledge (concept graphs/rules) and subsymbolic processes interact via activation spreading, probabilistic selection and learning loops; symbolic structures receive probabilistic weights and are influenced by subsymbolic signals.",
            "emergent_properties": "Flexible behavior across perception, planning and learning; capacity to combine probabilistic/reactive decisions with explicit reasoning to handle sparse knowledge and continuous learning scenarios.",
            "task_or_benchmark": "Applied across diverse practical applications in survey (virtual agents, learning tasks, reasoning); often used as an AGI testbed rather than a single benchmark.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Designed to leverage symbolic structure for compositional generalization while subsymbolic learning handles perception and noisy data; survey gives conceptual claims but no quantitative cross-distribution metrics.",
            "interpretability_properties": "Symbolic graph and rule components provide interpretable structure and potential explanations, while stochastic/subsymbolic elements reduce transparency for some behaviors.",
            "limitations_or_failures": "Survey highlights that many AGI-scale hybrid systems face scaling, reproducibility and engineering-detail gaps; CogPrime's concrete performance figures are not reported in the survey.",
            "theoretical_framework": "Hybrid AGI principle: integrate symbolic reasoning for compositionality and explanation with subsymbolic learning for perception and adaptivity; cognitive synergy between modules.",
            "uuid": "e417.3",
            "source_info": {
                "paper_title": "A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications",
                "publication_date_yy_mm": "2016-10"
            }
        },
        {
            "name_short": "CAPS",
            "name_full": "CAPS (Cognitive Architecture for Perception and Symbolism)",
            "brief_description": "A hybrid cognitive architecture combining symbolic reasoning with subsymbolic activation mechanisms to model perception, memory and reasoning in a unified framework.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "CAPS",
            "system_description": "CAPS is listed among fully integrated architectures combining explicit symbolic representations with subsymbolic processes (activation, graded retrieval) to support memory, reasoning and perceptual tasks.",
            "declarative_component": "Symbolic representations and production-like rules for reasoning and planning (explicit symbolic structures).",
            "imperative_component": "Activation-based subsymbolic processes and neural-style dynamics that influence retrieval and decision-making.",
            "integration_method": "Symbolic processing modulated by subsymbolic activation dynamics (spreading activation and graded retrieval) providing a hybrid control loop.",
            "emergent_properties": "Models of limited-capacity working memory, activation-driven retrieval and graded attention effects; bridges symbolic planning with graded perceptual selection.",
            "task_or_benchmark": "Psychological tasks and cognitive modeling including working memory and syntax parsing scenarios (survey references CAPS uses).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Enables behavior that is robust to incomplete knowledge via activation-modulated retrieval; no quantitative generalization claims in survey.",
            "interpretability_properties": "Symbolic layer offers interpretable rules and traces; subsymbolic activations provide quantitative modulation but reduce full transparency.",
            "limitations_or_failures": "Survey does not provide numeric performance; general limitations echo survey-wide scaling and perceptual modeling gaps.",
            "theoretical_framework": "Complementary strengths: symbolic control plus subsymbolic modulation to capture graded human-like cognitive effects.",
            "uuid": "e417.4",
            "source_info": {
                "paper_title": "A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications",
                "publication_date_yy_mm": "2016-10"
            }
        },
        {
            "name_short": "GMU-BICA",
            "name_full": "GMU-BICA (George Mason University - Biologically Inspired Cognitive Architecture)",
            "brief_description": "A fully integrated hybrid architecture developed under the BICA program combining symbolic knowledge and subsymbolic learning/activation mechanisms toward biologically-inspired cognition.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "GMU-BICA",
            "system_description": "GMU-BICA is a hybrid, biologically-inspired architecture that integrates symbolic representations and reasoning with subsymbolic processes (activation, learning) and multiple interacting modules to approximate cognitive functionality.",
            "declarative_component": "Symbolic knowledge structures and rule-like representations for high-level reasoning and planning.",
            "imperative_component": "Subsymbolic modules (activation/spreading, learning algorithms) for perception, pattern association and graded control.",
            "integration_method": "Fully integrated multi-module hybridization with symbolic knowledge interacting with subsymbolic learning and activation processes; modules exchange information and biases between representations.",
            "emergent_properties": "Aims to produce biologically plausible behaviors combining rule-based decisions with learned perceptual mappings and graded attention, enabling richer cognitive-functional repertoire than pure-symbolic systems.",
            "task_or_benchmark": "Used as part of BICA program demonstration tasks (survey groups it with fully integrated hybrids) but specific benchmark metrics are not given.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Intended to improve robustness and adaptability by combining symbolic generalization with subsymbolic perceptual learning; survey provides conceptual claims only.",
            "interpretability_properties": "Symbolic components permit explanation; integrated subsymbolic portions reduce full-system interpretability but contribute adaptive capabilities.",
            "limitations_or_failures": "No quantitative performance reported; survey highlights general engineering and scaling difficulties for biologically-inspired hybrids.",
            "theoretical_framework": "Biologically-inspired complementary integration: use symbolic representations for abstract cognition while subsymbolic modules encode biologically plausible learning and perception.",
            "uuid": "e417.5",
            "source_info": {
                "paper_title": "A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications",
                "publication_date_yy_mm": "2016-10"
            }
        },
        {
            "name_short": "Sigma",
            "name_full": "Sigma cognitive architecture",
            "brief_description": "A hybrid architecture that blends symbolic representations with probabilistic/subsymbolic computation in a graphical framework, aiming to integrate reasoning, learning and perception.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Sigma",
            "system_description": "Sigma is described as a fully integrated hybrid that conceptually leans toward emergent systems by sharing properties with neural networks, but explicitly integrates symbolic concepts/rules with probabilistic/subsymbolic mechanisms in a graphical architecture.",
            "declarative_component": "Symbolic concepts and rule-like structures; knowledge represented in forms that support combinatorial and logical reasoning.",
            "imperative_component": "Probabilistic/subsymbolic computations (graphical models / trellis graphs / message-passing) and stochastic selection; can implement reinforcement learning and probabilistic inference.",
            "integration_method": "Graphical-factor style integration where symbolic relations are embedded in probabilistic graphical structures and probabilistic message-passing / inference interacts with symbolic reasoning; symbolic and probabilistic modules exchange beliefs via factorization.",
            "emergent_properties": "Supports flexible reasoning (including theory-of-mind modeling via trellis graphs), probabilistic decision-making and integration of planning with uncertainty handling not available in pure symbolic or pure neural systems alone.",
            "task_or_benchmark": "Survey cites Sigma used for modeling two-player games and two mechanisms for theory-of-mind (e.g., Prisoner's Dilemma); employed for probabilistic reasoning tasks.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Sigma's probabilistic integration is intended to handle uncertain and sparse knowledge better than pure symbolic systems; survey reports conceptual capabilities but no numeric generalization benchmarks.",
            "interpretability_properties": "Graphical structure supports traceable probabilistic inference and symbolic reasoning steps enabling some interpretability; low-level probabilistic messages can be less intuitive.",
            "limitations_or_failures": "Survey does not provide numeric evaluation; general limitations include engineering complexity and lack of large-scale evaluation reported in the survey.",
            "theoretical_framework": "Combines symbolic logic and probabilistic graphical modeling to leverage strengths of both: explicit structure/compositionality with uncertainty-tolerant inference.",
            "uuid": "e417.6",
            "source_info": {
                "paper_title": "A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications",
                "publication_date_yy_mm": "2016-10"
            }
        },
        {
            "name_short": "ADAPT",
            "name_full": "ADAPT (Architecture using Soar + Perception Modules)",
            "brief_description": "A hybrid architecture that composes an existing symbolic cognitive architecture (Soar) with separate sub-symbolic sensor and perception modules to leverage strengths of each.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "ADAPT (Soar + perception modules)",
            "system_description": "ADAPT uses Soar as the symbolic controller for deliberative tasks while delegating sensor processing and 3D world modeling to separate sub-symbolic modules; integration is via designed interfaces so Soar issues control and receives processed percepts.",
            "declarative_component": "Soar symbolic control: production rules, goal/plan management and symbolic knowledge for decision-making.",
            "imperative_component": "Subsymbolic sensor-processing modules (vision/3D modeling pipelines, perception algorithms possibly neural or engineered), pre-processing raw sensor data into symbolic assertions.",
            "integration_method": "Modular, coarse-grained integration: dedicated interfaces map processed subsymbolic percepts into symbolic facts for Soar; Soar supplies control commands to perception modules — a pipeline/co-processing approach.",
            "emergent_properties": "Enables robust real-world perception-driven behavior by combining mature symbolic planning/control with engineered or learned perceptual processing, yielding capabilities (e.g., embodied navigation) not present in Soar alone.",
            "task_or_benchmark": "Robotics tasks: ADAPT used in embodied robot scenarios (navigation and manipulation) as noted in the survey; no numeric benchmarks provided.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Modular design allows leveraging perceptual generalization from sub-symbolic modules while preserving symbolic planning generality; survey gives qualitative assessment only.",
            "interpretability_properties": "Symbolic Soar controller remains interpretable; perceptual modules are black-boxes whose outputs are symbolicized, so end-to-end transparency depends on module instrumentation.",
            "limitations_or_failures": "Requires engineering effort to design interfaces and translations between modules; survey mentions cost of building interfaces and limited discussion of end-to-end training.",
            "theoretical_framework": "Functional modularity: assign perception to sub-symbolic modules and control/reasoning to symbolic systems, connecting via engineered interfaces to exploit each side's strengths.",
            "uuid": "e417.7",
            "source_info": {
                "paper_title": "A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications",
                "publication_date_yy_mm": "2016-10"
            }
        },
        {
            "name_short": "SAL",
            "name_full": "SAL (Symbolic-Subsymbolic ALliance) - ACT-R + Leabra example",
            "brief_description": "A hybrid system combining ACT-R symbolic control with Leabra neural models, where ACT-R guides learning of Leabra neural models to integrate symbolic guidance with biologically-inspired learning.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "SAL (ACT-R + Leabra integration)",
            "system_description": "SAL exemplifies a hybrid that pairs ACT-R's symbolic control and cognitive modeling with Leabra's biologically-plausible neural networks; ACT-R provides guidance and structure for training Leabra perceptual/behavioral models.",
            "declarative_component": "ACT-R symbolic production rules and declarative chunks for task guidance, planning and high-level control.",
            "imperative_component": "Leabra neural models (biologically inspired connectionist networks) for perceptual and lower-level processing and learning.",
            "integration_method": "Cross-architecture training: ACT-R guides or constraints learning of Leabra models (symbolic top-down supervision to train subsymbolic networks), a co-processing/teacher-student style integration.",
            "emergent_properties": "Combines symbolic reasoning/planning with biologically plausible neural learning to produce perceptually grounded, neurally plausible behaviors informed by symbolic task structure; supports learning in neural models that align with symbolic expectations.",
            "task_or_benchmark": "Learning tasks where ACT-R instructs Leabra models (survey references SAL as an example of combining architectures), but no quantitative benchmark numbers provided in survey.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Symbolic guidance can improve sample-efficiency and structure of neural learning; survey describes conceptually but provides no quantitative OOD generalization measures.",
            "interpretability_properties": "Symbolic ACT-R layer is interpretable and provides explicit rationale; learned neural components are less interpretable though constrained by symbolic guidance.",
            "limitations_or_failures": "Needs careful engineering to coordinate learning signals and representations across architectures; survey does not list numeric failure modes.",
            "theoretical_framework": "Teacher-student / guided-learning hybridization: explicit symbolic structures scaffold and shape subsymbolic learning to attain both interpretability and neural plausibility.",
            "uuid": "e417.8",
            "source_info": {
                "paper_title": "A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications",
                "publication_date_yy_mm": "2016-10"
            }
        },
        {
            "name_short": "SiMA / ARS",
            "name_full": "SiMA (formerly ARS) / ARS-SiMA",
            "brief_description": "A multi-level hybridization where neural networks construct 'neurosymbols' from sensors/actuators (connectionist logic systems) and a top symbolic processing layer operates on those neurosymbols.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "SiMA (ARS)",
            "system_description": "SiMA hybridizes on multiple levels: bottom-up neural networks transform sensory inputs into structured neurosymbols (connectionist logic systems) and a top-level symbolic processor reasons over these neurosymbols, creating an integrated perception-reasoning stack.",
            "declarative_component": "Top-layer symbolic processing system operating on neurosymbols (explicit symbols used for higher-level inference and planning).",
            "imperative_component": "Lower-level neural networks / connectionist modules that build neurosymbols from raw sensors and actuators; connectionist logic systems produce structured representations.",
            "integration_method": "Hierarchical multi-level integration: subsymbolic neural modules produce intermediate symbol-like representations (neurosymbols) which are consumed by a symbolic reasoning layer (symbolic subprocessing).",
            "emergent_properties": "Enables symbol grounding: raw sensory data is converted into structured symbolic-like units enabling symbolic reasoning grounded in perception; improves robustness to noisy sensors while retaining symbolic compositionality.",
            "task_or_benchmark": "Perception-to-reasoning robotic and cognitive tasks where sensor data must be converted into symbolic representations for planning; survey gives conceptual description without numeric benchmarks.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Hierarchical grounding supports better transfer from perception to symbolic reasoning relative to purely symbolic systems lacking grounding; quantitative generalization claims are not provided.",
            "interpretability_properties": "Top symbolic layer interpretable; neurosymbols provide an intermediate level that can be inspected; lower-level networks may remain opaque.",
            "limitations_or_failures": "Engineering cost of building reliable neurosymbol extraction and alignment to symbolic vocabularies; survey notes that many hybridization strategies are underdocumented.",
            "theoretical_framework": "Grounding principle: build symbol-like constructs from learned subsymbolic structures, then leverage symbolic reasoning — a hierarchical hybridization strategy.",
            "uuid": "e417.9",
            "source_info": {
                "paper_title": "A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications",
                "publication_date_yy_mm": "2016-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Desiderata for cognitive architectures",
            "rating": 2,
            "sanitized_title": "desiderata_for_cognitive_architectures"
        },
        {
            "paper_title": "Hybrid Connectionist-Symbolic Modules",
            "rating": 2,
            "sanitized_title": "hybrid_connectionistsymbolic_modules"
        },
        {
            "paper_title": "The DUAL Cognitive Architecture: A Hybrid Multi-Agent Approach",
            "rating": 2,
            "sanitized_title": "the_dual_cognitive_architecture_a_hybrid_multiagent_approach"
        },
        {
            "paper_title": "A Standard Model for the Mind: Toward a Common Computational Framework across Artificial Intelligence",
            "rating": 2,
            "sanitized_title": "a_standard_model_for_the_mind_toward_a_common_computational_framework_across_artificial_intelligence"
        },
        {
            "paper_title": "Integrating top-down expectations with bottom-up perceptual processing in a hybrid neural-symbolic architecture",
            "rating": 2,
            "sanitized_title": "integrating_topdown_expectations_with_bottomup_perceptual_processing_in_a_hybrid_neuralsymbolic_architecture"
        },
        {
            "paper_title": "Integrating deep learning based perception with probabilistic logic via frequent pattern mining",
            "rating": 1,
            "sanitized_title": "integrating_deep_learning_based_perception_with_probabilistic_logic_via_frequent_pattern_mining"
        }
    ],
    "cost": 0.03441575,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>40 Years of Cognitive Architectures Core Cognitive Abilities and Practical Applications
8 Sep 2017</p>
<p>Iuliia Kotseruba 
John K Tsotsos 
40 Years of Cognitive Architectures Core Cognitive Abilities and Practical Applications
8 Sep 2017Survey · Cognitive architectures · Perception · Attention · Cognitive abilities · Practical applications
In this paper we present a broad overview of the last 40 years of research on cognitive architectures. Although the number of existing architectures is nearing several hundred, most of the existing surveys do not reflect this growth and focus on a handful of well-established architectures. Thus, in this survey we wanted to shift the focus towards a more inclusive and high-level overview of the research on cognitive architectures. Our final set of 85 architectures includes 49 that are still actively developed, and borrow from a diverse set of disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we discuss only the core cognitive abilities, such as perception, attention mechanisms, action selection, memory, learning and reasoning. In order to assess the breadth of practical applications of cognitive architectures we gathered information on over 900 practical projects implemented using the cognitive architectures in our list.We use various visualization techniques to highlight overall trends in the development of the field. In addition to summarizing the current state-of-the-art in the cognitive architecture research, this survey describes a variety of methods and ideas that have been tried and their relative success in modeling human cognitive abilities, as well as which aspects of cognitive behavior need more research with respect to their mechanistic counterparts and thus can further inform how cognitive science might progress.</p>
<p>Introduction</p>
<p>The goal of this paper is to provide a broad overview of the last 40 years of research in cognitive architectures with an emphasis on the core capabilities of perception, attention mechanisms, action selection, learning, memory, reasoning and their practical applications. Although the field of cognitive architectures has been steadily expanding, most of the surveys published in the past 10 years do not reflect this growth and feature essentially the same set of a dozen most established architectures. The latest large-scale study was conducted by Samsonovich in 2010 [389] in an attempt to catalog the implemented cognitive architectures. His survey contains descriptions of 26 cognitive architectures submitted by their respective authors. The same information is also presented online in a Comparative Table of Cognitive Architectures 1 . In addition to surveys, there are multiple on-line sources listing cognitive architectures, but they rarely go beyond a short description and a link to the project site or a software repository.</p>
<p>Since there is no exhaustive list of cognitive architectures, their exact number is unknown, but it is estimated to be around three hundred, out of which at least one-third of the projects are currently active. To form the initial list for our study we combined the architectures mentioned in surveys (published within the last 10 years) and several large on-line catalogs. We also included more recent projects not yet mentioned in the survey literature. Figure 1 shows a visualization of 195 cognitive architectures featured in 17 sources (surveys, on-line catalogs and Google Scholar). It is apparent from this diagram that a small group of architectures such as ACT-R, Soar, CLARION, ICARUS, EPIC, LIDA and a few others are present in most sources, while all other projects are only briefly mentioned in on-line catalogs. While the theoretical and practical contributions of the major architectures are undeniable, they represent only a part of the research in the field. Thus, in this review the focus is shifted away from the deep study of the major architectures or discussing what could be the best approach to modeling cognition, which has been done elsewhere. For example, in a recent paper by Laird et al. [258] ACT-R, Soar and Sigma are compared based on their structural organization and approaches to modelling core cognitive abilities. Further, a new Standard Model of the Mind is proposed as a reference model born out of consensus between the three architectures. Our goal, on the other hand, is to present a broad, inclusive, judgment-neutral snapshot of the past 40 years of development with the goal of informing the future cognitive architecture research by presenting the diversity of ideas that have been tried and their relative success.</p>
<p>To make this survey manageable we reduced the original list of architectures to 85 items by considering only implemented architectures with at least one practical application and several peer-reviewed publications. Even though we do not explicitly include some of the philosophical architectures such as CogAff [423], Society of Mind [312], Global Workspace Theory (GWT) [27] and Pandemonium theory [412], we examine cognitive architectures heavily influenced by these theories (e.g. LIDA, ARCADIA, CERA-CRANIUM, ASMO, COGNET and Copycat/Metacat, also see discussion in section 5). We also exclude large-scale brain modeling projects, which are low-level and do not easily map onto the breadth of cognitive capabilities modeled by other types of cognitive architectures. Further, many of the brain models do not have practical applications, and thus do not fit the parameters of the present survey. Figure 2 shows all architectures featured in this survey with their approximate timelines recovered from the publications. Of these projects 49 are currently active 2 .</p>
<p>As we mentioned earlier, the first step towards creating an inclusive and organized catalog of implemented cognitive architectures was made by Samsonovich [389]. His work contained extended descriptions of 26 projects with the following information: short overview, a schematic diagram of major elements, common components and features (memory types, attention, consciousness, etc.), learning and cognitive development, cognitive modeling and applications, scalability and limitations. A survey of this kind brings together researchers from several disjoint communities and helps to establish a mapping between the different approaches and terminology they use. However, the descriptive or tabular format does not allow easy comparisons be-   tween architectures. Since our sample of architectures is large, we experimented with alternative visualization strategies.</p>
<p>In the following sections, we will provide an overview of the definitions of cognition and approaches to categorizing cognitive architectures. As one of our contributions, we map cognitive architectures according to their perception modality, implemented mechanisms of attention, memory organization, types of learning, action selection and practical applications.</p>
<p>In the process of preparing this paper, we examined the literature widely and this activity led to a 2500 item bibliography of relevant publications. We provide this bibliography, with short summary descriptions for each paper as a supplementary material. In addition, interactive versions of all diagrams in this paper are available on-line 3 and allow one to explore the data and view relevant references.</p>
<p>2 What are Cognitive Architectures?</p>
<p>Cognitive architectures are a part of research in general AI, which began in the 1950s with the goal of creating programs that could reason about problems across different domains, develop insights, adapt to new situations and reflect on themselves. Similarly, the ultimate goal of research in cognitive architectures is to achieve human-level artificial intelligence. As such, they attempt to provide evidence that particular mechanisms succeed in producing intelligent behavior and thus can further contribute to cognitive science. Moreover, the body of work represented by the cognitive architectures, and this review, documents what methods or strategies have been tried previously (and thus what has not), how they have been used, and what level of success has been achieved or lessons learned, all important elements that help guide future research efforts. For AI and engineering, documentation of past mechanistic work has obvious import. But this is just as important for cognitive science, since most experimental work eventually attempts to connect to explanations of how observed human behavior may be generated and the body of cognitive architectures provides a very rich source of viable ideas and mechanisms.</p>
<p>According to Russel and Norvig [383] artificial intelligence may be realized in four different ways: systems that think like humans, systems that think rationally, systems that act like humans, and systems that act rationally. The existing cognitive architectures have explored all four possibilities. For instance, human-like thought is pursued by the architectures stemming from cognitive modeling. In this case, the errors made by an intelligent system should match the errors typically made by people in similar situations. This is in contrast to rationally thinking systems which are required to produce consistent and correct conclusions for arbitrary tasks. A similar distinction is made for machines that act like humans or act rationally. Machines in either of these groups are not expected to think like humans, only their actions or behavior is taken into account.</p>
<p>However, with no clear definition and general theory of cognition, each architecture was based on a different set of premises and assumptions, making comparison and evaluation difficult. Several papers were published to resolve the uncertainties, the most prominent being Sun's desiderata for cognitive architectures [435] and Newell's functional criteria (first published in [324] and [325], and later restated by Anderson and Lebiere in [16]). Newell's criteria include flexible behavior, real-time operation, rationality, large knowledge base, learning, development, linguistic abilities, self-awareness and brain realization. Sun's desiderata are broader and include ecological, cognitive and bio-evolutionary realism, adaptation, modularity, routineness and synergistic interaction. Besides defining these criteria and applying them to a range of cognitive architectures, Sun also pointed out the lack of clearly defined cognitive assumptions and methodological approaches, Since the explicit beginning and ending dates are known only for a few projects, we recovered the timeline based on the dates of the publications and activity on the project web page or on-line repository. Colors correspond to different types of architectures: symbolic (green), emergent (red) and hybrid (blue). According to this data there was a particular interest in symbolic architectures since mid-1980s until early 1990s, however after 2000s most of the newly developed architectures are hybrid. Emergent architectures, many of which are biologically-inspired, are distributed fairly evenly in the timeline, but remain a relatively small group. which hinder progress in studying intelligence. He also noted an uncertainty regarding essential dichotomies (implicit/explicit, procedural/declarative, etc.), modularity of cognition and structure of memory. However, a quick look at the existing cognitive architectures reveals persisting disagreements in terms of their research goals, structure, operation and application.</p>
<p>Instead of looking for a particular definition of intelligence, it may be more practical to define it as a set of competencies and behaviors demonstrated by the system. While no comprehensive list of capabilities required for intelligence exists, several broad areas have been identified that may serve as guidance for ongoing work in the cognitive architecture domain. For example, Adams et al. [1] suggest areas such as perception, memory, attention, actuation, social interaction, planning, motivation, emotion, etc. These are further split into subareas. Arguably, some of these categories may seem more important than the others and historically attracted more attention (further discussed in section 10.2).</p>
<p>Implementing even a reduced set of abilities in a single architecture is a substantial undertaking. Unsurprisingly, Artificial General Intelligence (AGI) is currently pursued by only a handful of architectures, among which are Soar, ACT-R, NARS [498], LIDA [134], and several recent projects, such as SiMA (formerly ARS) [400], Sigma [362] and CogPrime [172]. Others focus on a particular aspect of cognition, e.g. attention (AR-CADIA [69], STAR [468]), emotion (CELTS [135]), perception of symmetry (Cognitive Symmetry Engine [193]) or problem solving (FORR [123], PRODIGY [123]). There are also narrowly specialized architectures designed for particular applications, such as ARDIS [298] for visual inspection of surfaces or MusiCog [305] for music comprehension and generation.</p>
<p>The criteria for being defined as a cognitive architecture are also rarely addressed. Most of the surveys broadly define cognitive architectures as a blueprint for intelligence, or more specifically, a proposal about the mental representations and computational procedures that operate on these representations enabling a range of intelligent behaviors ( [117], [270], [451], [361], [79]). There is generally no need to justify the inclusion of the established cognitive architectures such as Soar, ACT-R, EPIC, LIDA, ICARUS and a few others. However, when it comes to less common or new projects, reasons for considering them are less clear. As an example, AKIRA, a framework that explicitly does not self-identify as a cognitive architecture [353], is featured in some surveys anyway [454]. Similarly, a knowledge base Cyc [148], which does not make any claims about general intelligence is presented as an AGI architecture in [170].</p>
<p>Laird in [261] discusses how cognitive architectures differ from other software systems. While all of them have memory storage, control components, data representation, and input/output devices, the former provide only a fixed model for general computation. Cognitive architectures, on the other hand, must change through development and efficiently use knowledge to perform new tasks. Furthermore, he suggests toolkits and frameworks for building intelligent agents (e.g. GOMS, BDI, etc.) cannot themselves be considered cognitive architectures. However, Pogamut, a framework for building intelligent agents, is included in [389].</p>
<p>An important point to keep in mind while reading this survey is that cognitive architectures should be distinguished from the models or agents that implement them. For instance, ACT-R, Soar, HTM and many other architectures are used as the basis for multiple software agents that demonstrate only a subset of capabilities declared in theory. On the other hand, some agents may implement extra features that are not available in the cognitive architecture. A good example is the perceptual system of Rosie [240], one of the agents implemented in Soar, whereas Soar itself does not include a real perceptual system for physical sensors as part of the architecture. Unfortunately, in many cases the level of detail presented in the publications does not allow one to judge whether a particular capability is present in all agents related to the architecture or is added for a concrete application. Therefore, to avoid confusion, we do not make this distinction and list all capabilities demonstrated by the architecture.</p>
<p>Recently, claims have been made that deep learning is capable of solving AI by Google (DeepMind 4 ). Likewise, Facebook AI Research (FAIR 5 ) and other companies are actively working in the same direction. However, the question is where does this work stand with respect to cognitive architectures? Overall, the DeepMind research addresses a number of important issues in AI, such as natural language understanding, perceptual processing, general learning, and strategies for evaluating artificial intelligence. Although particular models already demonstrate cognitive abilities in limited domains, at this point they do not represent a unified model of intelligence.</p>
<p>Differently from DeepMind, Mikolov et al. from Facebook research team explicitly discuss their work in a broader context of developing intelligent machines [308]. Their main argument is that AI is too complex to be built all at once and instead its general characteristics should be defined first. Two such characteristics of intelligence are defined, namely, communication and learning, and a concrete roadmap are proposed for developing them incrementally.</p>
<p>Currently, there are no publications about developing such a system, but overall the research topics pursued by FAIR align with their proposal for AI and also the business interests of the company. Common topics include visual processing, especially segmentation and object detection, data mining, natural language processing, human-computer interaction and network security. Since the current deep learning techniques are mainly applied to solving practical problems and do not represent a unified framework we do not include them in this review. However, given their prevalence in other areas of AI, deep learning methods will likely play some role in the cognitive architectures of the future.</p>
<p>To ensure both inclusiveness and consistency, cognitive architectures in this survey are selected based on the following criteria: self-evaluation as cognitive, robotic or agent architecture, existing implementation (not necessarily open-source), and mechanisms for perception, attention, action selection, memory and learning. Note that some architectures went through significant structural and conceptual changes throughout their development. In cases like this we use the most recent variant of the architecture for the analysis. Furthermore, we considered the architectures with at least several peer-reviewed papers and practical applications beyond simple illustrative examples. For some of the most recent architectures still under development, some of these conditions were relaxed.</p>
<p>Taxonomies of Cognitive Architectures</p>
<p>Many papers published within the last decade address the problem of evaluation rather than categorization of cognitive architectures. As mentioned earlier, Newells criteria ( [324], [325], [16]) and Sun's desiderata [435] belong in this category. Furthermore, surveys of cognitive architectures propose various capabilities, properties and evaluation criteria, which include recognition, decision making, perception, prediction, planning, acting, communication, learning, goal setting, adaptability, generality, autonomy, problem solving, real-time operation, meta-learning, etc. ([486], [270], [454], [25]).</p>
<p>While these criteria could be used for classification, many of them are too fine-grained to be applied to a generic architecture. A more general grouping of architectures is based on the type of representation and information processing they implement. Three major paradigms are currently recognized: symbolic (also referred to as cognitivist), emergent (connectionist) and hybrid. Which of these representations, if any, correctly reflects the human cognitive processes, remains an open question and has been debated for the last thirty years ( [437], [231] Fig. 3 A taxonomy of cognitive architectures based on the representation and processing. The order of the architectures within each group is alphabetical and does not correspond to the proportion of symbolic vs sub-symbolic elements (i.e. the spatial proximity of ACT-R and iCub to nodes representing symbolic and emergent architectures respectively does not imply that ACT-R is closer to symbolic paradigm and iCub is conceptually related to emergent architectures).</p>
<p>Symbolic systems represent concepts using symbols that can be manipulated using a predefined instruction set. Such instructions can be implemented as if-then rules applied to the symbols representing the facts known about the world (e.g. ACT-R, Soar and other production rule architectures). Because it is a natural and intuitive representation of knowledge, symbolic manipulation remains very common. Although by design, symbolic systems excel at planning and reasoning, they are less able to able to deal with the flexibility and robustness that are required for dealing with a changing environment and for perceptual processing.</p>
<p>The emergent approach resolves the adaptability and learning issues by building massively parallel models, analogous to neural networks, where information flow is represented by a propagation of signals from the input nodes. However, the resulting system also loses its transparency, since knowledge is no longer a set of symbolic entities and instead is distributed throughout the network. For these reasons, logical inference in a traditional sense becomes problematic (although not impossible) in emergent architectures.</p>
<p>Naturally, each paradigm has its strengths and weaknesses. For example, any symbolic architecture requires a lot of work to create an initial knowledge base, but once it is done the architecture is fully functional. On the other hand, emergent architectures are easier to design, but they must be trained in order to produce useful behavior. Furthermore, their existing knowledge may deteriorate with the subsequent learning of new behaviors.</p>
<p>As neither paradigm is capable of addressing all major aspects of cognition, hybrid architectures attempt to combine elements of both symbolic and emergent approaches. Such systems are the most common in our selection of architectures (and, likely, overall). In general, there are no restrictions on how the hybridization is done and many possibilities have been explored. Multiple taxonomies of the hybridization types have been proposed ( [434], [196], [509], [510], [118]). In addition to representation, one can consider whether the system is single or multi-module, heterogeneous or homogeneous, take into account the granularity of hybridization (coarse-grained or fine-grained), the coupling between the symbolic and sub-symbolic components, and types of memory and learning. In addition, not all the hybrid architectures explicitly address what is referred to as symbolic and sub-symbolic elements and reasons for combining them. Only a few architectures, namely ACT-R, CLARION, DUAL, CogPrime, CAPS, GMU-BICA and Sigma, view this integration as essential and discuss it extensively. However, we found that symbolic and sub-symbolic parts cannot be identified for all reviewed architectures due to lack of such fine-grained detail in many publications, thus we focus on representation and processing. Figure 3 shows the architectures grouped according to the new taxonomy. The top level of the hierarchy is represented by the symbolic, emergent and hybrid approaches. The definitions of these terms in the literature are vague, which often leads to the inconsistent assignment of architectures to either group. There seems to be no agreement even regarding the most known architectures, Soar and ACT-R. Although both combine symbolic and sub-symbolic elements, ACT-R explicitly self-identifies as hybrid, while Soar does not [262]. The surveys are inconsistent as well, for instance, both Soar and ACT-R are called cognitivist in [486] and [167], while [25] lists them as hybrid.</p>
<p>To avoid inconsistent grouping, we did not rely on self-assigned labels and applied the same definition to all the reviewed architectures. We assume that explicit symbols are atoms of symbolic representation and can be combined to form meaningful expressions. Such symbols are used for inference or syntactical parsing. Sub-symbolic representations are generally associated with the metaphor of a neuron. A typical example of such representation is the neural network, where knowledge is encoded as a numerical pattern distributed among many simple neuron-like objects. Weights associated with units affect processing and are acquired by learning. For our classification, we assume that anything that is not an explicit symbol and processing other than syntactic manipulation is sub-symbolic (e.g. numeric data, pixels, probabilities, spreading activations, reinforcement learning, etc.). Hybrid representation combines any number of elements from both representations.</p>
<p>Given these definitions, we assigned labels to all the architectures and visualized them as shown in Figure 3. We distinguish between two groups in the emergent category: neuronal models, which implement models of biological neurons, and connectionist logic systems, which are closer to artificial neural networks. Within the hybrid architectures we separate symbolic sub-processing as a type of hybridization where a symbolic architecture is combined with a self-contained module performing sub-symbolic computation, e.g. for processing sensory data. Other types of functional hybrids also exist, for example, co-processing, metaprocessing and chain-processing, however, these are harder to identify based on the limited data available in the publications and are not included. The fully integrated category combines all other types of hybrids.</p>
<p>The architectures in the symbolic sub-processing group include at least one sub-symbolic module for sensory processing, while the rest of the knowledge and processing is symbolic. For example, 3T, ATLANTIS, RCS, DIARC, CARACaS and CoSy are robotic architectures, where a symbolic planning module determines the behavior of the system and one or more modules are used to process visual and audio sensory data using techniques like neural networks, optical flow calculation, etc. Similarly, ARDIS and STAR combine symbolic knowledge base and case-based symbolic reasoning with image processing algorithms.</p>
<p>The fully integrated architectures use a variety of approaches for combining different representations. ACT-R, Soar, CAPS, Copycat/Metacat, CHREST, CHARISMA, CELTS, CoJACK, CLARION, REM, NARS and Xapagy combine symbolic concepts and rules with sub-symbolic elements such as activation values, spreading activation, stochastic selection process, reinforcement learning, etc. On the other hand, DUAL consists of a large number of highly interconnected hybrid agents, each of which has a symbolic and sub-symbolic representation, implementing integration at a micro-level. In the case of SiMA hybridization is done on multiple levels: neural networks are used to build neurosymbols from sensors and actuators (connec-tionist logic systems) and the top layer is a symbol processing system (symbolic subprocessing). For the rest of the architectures, it is hard to clearly define hybridization strategy. For instance, many architectures are implemented as a set of interconnected competing and cooperating modules, where individual modules are not restricted to a particular representation (Kismet, LIDA, MACSi, ISAC, iCub, GMU-BICA, CORTEX, ASMO, CELTS, PolyScheme, FORR).</p>
<p>Another hybridization strategy is to combine two different architectures with complementary features. Even though additional effort is required to build interfaces for communication between them, this approach allows to take advantage of the strengths of each architecture. As, for example, it is done in ADAPT, which uses Soar for control, whereas separate modules are responsible for modeling a 3D world from sensor information and for visual processing [47]. Another example, SAL, comprises ACT-R and Leabra architectures [219]. Here ACT-R is used to guide learning of Leabra models.</p>
<p>Compared to hybrids, emergent architectures form a more uniform group. As mentioned before, the main difference between neuronal modeling and connectionist logic systems is in their biological plausibility. All systems in the first group implement particular neuron models and aim to accurately reproduce the low-level brain processes. The systems in the second group are based on artificial neural networks. Despite being heavily influenced by neuroscience and the ability to closely model certain elements of human cognition, the biological plausibility of these models is not claimed by their authors.</p>
<p>In conclusion, as can be seen in Figure 3, hybrid architectures are the most numerous and diverse group, showing the tendency to grow even more, thus confirming a prediction made almost a decade ago [117]. Hybrid architectures form a continuum between emergent and symbolic systems depending on the proportions and roles played by symbolic and sub-symbolic components. Although quantitative analysis of this space is not feasible, it is possible to crudely subdivide it. For instance, some architectures such as CogPrime and Sigma are conceptually closer to emergent systems as they share many properties with the neural networks. On the other hand, REM, CHREST, and RALPH, as well as the architectures implementing symbolic subprocessing, e.g. 3T and ATLANTIS, are very much within the cognitivist paradigm. These architectures are primarily symbolic but may utilize probabilistic reasoning and learning mechanisms.</p>
<p>Perception</p>
<p>Regardless of its design and purpose, an intelligent system cannot exist in isolation and requires an input to produce any behavior. Although historically the major cognitive architectures focused on higher-level reasoning, it is evident that perception and action play an important role in human cognition [14].</p>
<p>Perception can be defined as a process that transforms raw input into the system's internal representation for carrying out cognitive tasks. Depending on the origin and properties of the incoming data, multiple sensory modalities are distinguished. For instance, five most common ones are vision, hearing, smell, touch and taste. Other human senses include proprioception, thermoception, nocioception, sense of time, etc. Naturally, cognitive architectures implement some of these as well as other modalities that do not have a correlate among human senses such as symbolic input (using a keyboard or graphical user interface (GUI)) and various sensors such as LiDAR, laser, IR, etc.</p>
<p>Depending on its cognitive capabilities, an intelligent system can take various amounts and types of data as perceptual input. Thus, this section will investigate the diversity of the data inputs used in cognitive architectures, what information is extracted from these sources and how it is applied. The visualization in Figure 4 addresses the first part of the question by mapping the cognitive architectures to the sensory modalities they implement: vision (V), hearing (A), touch (T), smell (S), proprioception (P) as well as the  data input (D) and other sensors (O) 6 . Note that the data presented in the diagram is aggregated from many publications and most architectures do not demonstrate all listed sensory modalities in a single model.
p t i o n R o b o C o g I C A R U S F O R R C S E C O R T E X S A S E S oa r CE RA -C RA NIU M AIS MACSi Kis me t iC ub C o S y A S M O A P E X C A R A C a S A R T A T L A N T I S N o v
Several observations can be made from the visualization in Figure 4. For example, vision is the most commonly implemented sense, however, more than half of the architectures use simulation for visual input instead of the physical camera. It is also very common in symbolic architectures to use direct data input as the only source of information. Modalities such as touch and proprioception are mainly used in the physically embodied architectures. On the other hand, the sense of smell is relatively unexplored as only three architectures implement it (GLAIR [417], DAC [303] and PRS [443]). Overall, hybrid and emergent architectures (located mainly in the right half of the diagram) implement several different sensory modalities, while symbolic architectures (concentrated in the left half of the diagram) more often rely on the simulated vision or data input. However, much of the incoming sensory data is not usable in the raw form (except, maybe, for symbolic input) and requires further processing. Below we discuss various approaches to the problem of efficient and adequate perceptual processing in cognitive architectures.</p>
<p>Vision</p>
<p>For a long time, vision was viewed as the dominating sensory modality based on the available experimental evidence [360]. While recent works suggest a more balanced view of human sensory experience [432], cognitive architectures research remains fairly vision-centric, as it is the most studied and the most represented sensory modality. Even though in robotics various non-visual sensors and proprioception (e.g. odometry and bumpers) are used for solving visual tasks such as navigation, obstacle avoidance and search, visual input accounts for more than half of all implemented input modalities.</p>
<p>According to Marr [294] visual processing is composed of three different stages: early, intermediate and late. Early vision is data-driven and involves parallel processing of the visual scene and extracts simple elements, such as color, luminance, shape, motion, etc. Intermediate vision groups elements into regions, which are then further processed in the late stage to recognize objects and assign meaning to them using available knowledge. Although not mentioned by Marr, visual attention mechanisms, emotion and reward systems also influence all stages of visual processing [467]. Thus, perception and cognition are tightly interconnected starting throughout all levels of processing.</p>
<p>We base our analysis of visual processing in the cognitive architectures on image understanding stages described in [466]. These stages include: 1) detection and grouping of intensity-location-time values (results in edges, regions, flow vectors); 2) further grouping of edges, regions, etc. (produces surfaces, volumes, boundaries, depth information); 3) identification of objects and their motions; 4) building object-centered representations for entities; 5) assigning labels to objects based on the task; 6) inference of spatiotemporal relationships among entities 7 . Here only stage 1 represents early vision, and all subsequent stages require additional task or world knowledge. Already at stage 2, grouping of features may be facilitated by the viewpoint information and knowledge of the specific objects being viewed. Finally, the later stages involve spatial reasoning and operate on high-level representations abstracted from the results of early and intermediate processing.</p>
<p>Note that in computer vision research many of these image understanding stages are implemented implicitly with deep learning methods. Given the success of deep learning in many applications it is surprising to see that very few cognitive architectures employ them. Some applications of deep learning to simple vision tasks can be found in CogPrime [171], LIDA [288], SPA [430] and BECCA [373].</p>
<p>Diagrams in Figure 5 show stages of processing implemented for real and simulated vision. We assume that the real vision systems only receive pixel-level input with no additional information (e.g. camera parameters,    The stages are ordered from early to late processing: 1) features, 2) proto-objects, 3) objects, 4) object models, 5) object labels, 6) spatial relations. Different shades of blue are used to indicate processes that belong to early, intermediate and late vision. The architectures with real and simulated vision are shown in left and right columns respectively. The order within each column is alphabetical. In some architectures some type of visual process is implemented, however, the publications do not provide a sufficient amount of technical detail for our analysis ("No details" list). Architectures in the "Not implemented" list do not implement vision explicitly, although some may use other sensors (e.g. sonars and bumpers) for visual tasks such as recognition and navigation.
3T 4D-RCS ACT-R ADAPT ARCADIA ARDIS ART ATLANTIS BBD BECCA CARACaS CERA-CRANIUM CORTEX CSE CoSy DAC DIARC DSO DUAL ISAC Kismet LIDA Leabra MACSi MDB PolyScheme RoboCog SAL SASE SPA STAR Soar Subsumption iCub f
locations and features of objects, etc.). The images should be produced by a physical camera, but the architecture does not need to be connected to a physical sensor (i.e. if the input is a dataset of images or previously recorded video, it is still considered real vision). The simulated vision systems generally omit early and intermediate vision and receive input in the form that is suitable for the later stages of visual processing (e.g. symbolic descriptions for shape and color, object labels, coordinates, etc.). Technically, any architecture that does not have native support for real vision or other perceptual modalities, may be extended with an interface that connects it to sensors and pre-processes raw data into a more suitable format (e.g. Soar [319] and ACT-R [461]).</p>
<p>The illustration in Figure 5 shows what image interpretation stages are implemented, but it does not reflect the complexity and extent of such processing as there are no quantitative criteria for evaluation. In the remainder of this section we will provide brief descriptions of the visual processing in various architectures.</p>
<p>Real vision</p>
<p>The majority of the architectures implementing all stages of visual processing are physically embodied and include robot control, biologically inspired and biomimetic architectures. The architectures in the first group (3T, ATLANTIS and CARACaS) operate in realistic unstructured environments and approach vision as an engineering problem. Early vision (step 1) usually involves edge detection and disparity estimation. These features are then grouped (step 2) into blobs with similar features (color, depth, etc.), which are resolved into candidate objects with centroid coordinates (step 3). Object models are learned off-line using machine learning techniques (step 4) and can be used to categorize candidate objects (step 5). For example, in RCS architecture the scene is reconstructed from stereo images and features of the traversable ground are learned from LiDAR data and color histograms [201]. Similarly, the ATLANTIS robot architecture constructs a height map from stereo images and uses it to identify obstacles [310]. The CARACaS architecture also computes a map for hazard avoidance from stereo images and range sensors. The locations and types of obstacles are placed on the map relative to the robot itself. Its spatial reasoning (step 6) is limited to determining the distance to the obstacles or target locations for navigation [211].</p>
<p>Biologically inspired architectures also make use of computer vision algorithms and follow similar processing steps. For instance, neural networks for object detection (RCS [2], DIARC [402], Kismet [65]), SIFT features for object recognition (DIARC [401]), SURF features, AdaBoost learning and a mixture of Gaussians for hand detection and tracking (iCub [92]), Kinect and LBP features in conjunction with SVM classifier to find people and determine their age and gender (RoboCog and CORTEX [300], [376]).</p>
<p>In these architectures vision is more intertwined with memory and control systems and some steps in visual processing are explicitly related to the human visual system. One such example is saliency, which models the ability to prioritize visual stimuli based on their features or relevance to the task. As such, saliency is used to find regions of interest in the scene (Kismet [57], ARCADIA [69], DIARC [403], iCub [275], STAR [248]). Similarly, ego-sphere, a structure found in some robotic architectures, models functions of the hippocampus in the integration of sensory information with action. Essentially, ego-sphere forms a virtual dome surrounding the robot, onto which salient objects and events are mapped. Various implementations of this concept are included in RCS [4], ISAC [227], iCub [487] and MACSi [217].</p>
<p>The architectures in the third subgroup pursue biologically plausible vision. One of the most elaborate examples is the Leabra vision system called LVis [343] based on the anatomy of the ventral pathway of the brain. It models the primary visual cortex (V1), extrastriate areas (V2, V4) and the inferotemporal (IT) cortex. Computation in these areas roughly corresponds to early and intermediate processing steps on the diagram. LVis possesses other features of the human visual system, such as larger receptive fields of neurons in higher levels of the hierarchy, reciprocal connections between the layers and recurrent inhibitory dynamics that limit activity levels across layers [519]. The visual systems of Darwin VIII (BBD) [413], SPA (Spaun) [122] and ART [177] are also modeled on the primate ventral visual pathway.</p>
<p>The SASE architecture does not replicate the human visual system as closely. Instead, it uses a hierarchical neural network with localized connections, where each neuron gets input from a restricted region in the previous layer. The sizes of receptive fields within one layer are the same and increase at higher levels [526]. This system was tested on a SAIL robot in an indoor navigation scenario [507]. A similar approach to vision is implemented in MDB [119], BECCA [374] and DAC [303].</p>
<p>Note that although emergent systems do not explicitly assign labels to objects, they are capable of forming representations of spatial relations between the objects in the scene and use these representations for visual tasks like navigation (BBD [145], BECCA [374], DAC [303], MDB [119], SASE [504]).</p>
<p>Simulated vision</p>
<p>As evident from the diagram in Figure 5, most of the simulations support only the late stages of visual processing. Despite their varying visual complexity, different simulations usually provide the same kinds of data about the environment: objects, their properties (color, shape, label, etc.), locations and properties of the agent itself, spatial relations between objects and environmental factors (e.g. weather and wind direction). Sometimes, the scene is represented as polygons with color and 3D coordinates of corners, which have to be further processed to identify objects (Novamente [191]). Otherwise, the visual realism of 3D simulations is mostly for aesthetics and sensory information is available directly in symbolic form (e.g. CoJACK [130], Pogamut [49]).</p>
<p>As mentioned earlier, the diagram in Figure 5 does not reflect the differences in the complexity of the environments or capabilities of the individual architectures. However, there is a lot of variation in terms of size and realism among environments for the embodied cognitive architectures. For example, a planetary rover controlled by ATLANTIS performs cross-country navigation in an outdoor rocky terrain [304], salesman robot Gualzru (CORTEX [376]) moves around a large room full of people and iCub (MACsi [216]) recognizes and picks up various toys from a table. On the other hand, simple environments with no clutter or obstacles are also used in the cognitive architectures research (BECCA [374], MDB [42]). In addition, color-coding objects is a common way of simplifying visual processing. For instance, ADAPT tracks a red ball rolling on the table [47] and DAC orients itself towards targets marked with different colors [289].</p>
<p>Furthermore, most reviewed visual systems can recognize only a handful of different object categories. In our selection, only Leabra is able to distinguish dozens of object categories [519]. The quality of visual processing is greatly improved with the spread of available software toolkits such as OpenCV, Cloud Point Library or Kinect API. But not as much progress has been made within systems that try to model general purpose and biologically plausible visual systems. Currently, their applications are limited to controlled environments.</p>
<p>Audition</p>
<p>Audition is a fairly common modality in the cognitive architectures as sound or voice commands are typically used to guide an intelligent system or to communicate with it. Since the auditory modality is purely functional, many architectures resort to using available speech-to-text software rather than develop models of the audition. Among the few architectures modeling auditory perception are ART, ACT-R, SPA and EPIC.</p>
<p>For example, ARTWORD and ARTSTREAM were used to study phonemic integration [179] and source segregation (cocktail party problem) [178] respectively. A model of music interpretation was developed with ACT-R [91].</p>
<p>Using dedicated software for speech processing and communication helps to achieve a high degree of complexity and realism. For example, in robotics applications it allows a salesman robot to have scripted interaction with people in a crowded room (CORTEX [376]) or dialog about the objects in the scene in a subset of English (CoSy [280]). A more advanced application involves using speech recognition for the task of ordering books from the public library by phone (FORR [128]). Other systems using off-the-shelf speech processing software include the PolyScheme [460] and ISAC [350].</p>
<p>In our sample of architectures, most effort is directed at natural language processing, i.e. linguistic and semantic information carried by the speech (further discussed in section 10.2), and much less attention is paid to the emotional content, (e.g. loudness, speech rate, and intonation). Some attempts in this direction are made in social robotics. For example, the social robot Kismet does not understand what is being said to it but can determine approval, prohibition or soothing based on the prosodic contours of the speech [60]. The Ymir architecture also has a prosody analyzer combined with a grammar-based speech recognizer that can understand a limited vocabulary of 100 words [456]. Even the sound itself can be used as a cue, for example, the BBD robots can orient themselves toward the source of a loud sound [413].</p>
<p>Symbolic input</p>
<p>The symbolic input category in Figure 4 combines several input methods which do not fall under physical sensors or simulations. These include input in the form of text commands and data, and via GUI. Text input is typical for the architectures performing planning and logical inference tasks (e.g. NARS [498], OSCAR [357], MAX [254], Homer [484]). Text commands are usually written in terms of primitive predicates used in the architecture, so no additional parsing is required.</p>
<p>Although many architectures have tools for visualization of results and the intermediate stages of computation, interactive GUIs are less common. They are mainly used in the human performance research to simplify input of the expert knowledge and to allow multiple runs of the software with different parameters (IMPRINT [314], MAMID [209], OMAR [108], R-CAST [158]).</p>
<p>The data input can be in text or any other format (e.g. binary or floating point arrays) and is primarily used for the categorization and classification applications (e.g. HTM [273], CSE [193], ART [86]).</p>
<p>Other modalities and multi-modal perception</p>
<p>Other sensory modalities such as touch, smell and proprioception are trivially implemented with a variety of sensors (physical and simulated). For instance, many robotic platforms are equipped with touch-sensitive bumpers for an emergency stop in case of hitting an obstacle (e.g. RCS [6], AIS [188], CERA-CRANIUM [19], DIARC [464]). Similarly, proprioception, i.e. sensing of the relative positions of the body parts and effort being exerted, can be either simulated or provided by force sensors (3T [143], iCub [348], MDB [44], Subsumption [74]), joint feedback (SASE [203], RCS [55]), accelerometers (Kismet [61], 3T [517]), etc.</p>
<p>Some architectures address multi-modal perception in limited domains: in the iCub architecture egosphere has different saliency channels for auditory and visual events [380] and Ymir simultaneously processes features from gaze, gestures, head movement and speech to decide when to take a turn during the dialogue [457].</p>
<p>Attention</p>
<p>Perceptual attention plays an important role in human cognition, as it mediates the selection of relevant and filters out irrelevant information from the incoming sensory data. However, it would be wrong to think of attention as a monolithic structure that makes a decision about what to process next. Rather, the opposite may be true. There is ample evidence in favor of attention as set of mechanisms affecting both perceptual and cognitive processes [470]. Currently, visual attention remains the most studied form of attention, as there are no comprehensive frameworks for other sensory modalities. Since only a few architectures have rudimentary mechanisms for modulating auditory data (OMAR [111], iCub [380], EPIC [238] and MIDAS [174]), this section will be dedicated to the visual attention.</p>
<p>For the following analysis, we use the taxonomy of attentional mechanisms proposed by Tsotsos [467]. Elements of attention are grouped into three classes of information reduction mechanisms: selection (choose one from many), restriction (choose some from many) and suppression (suppress some from many). Selection mechanisms include gaze and viewpoint selection, world model (selection of objects/events to focus on) and time/region/features/objects/events of interest. Restriction mechanisms serve to prune the search space by priming (preparing the visual system for input based on task demands), endogenous motivations (domain knowledge), exogenous cues (external stimuli), exogenous task (restrict attention to objects relevant for the task), and visual field (limited field of view). Suppression mechanisms consist of feature/spatial surround inhibition (temporary suppression of the features around the object while attending), task irrelevant stimuli suppression, negative priming, and location/object inhibition of return (a bias against returning attention to previous attended location or stimuli). Finally, branch-and-bound mechanisms combine elements of suppression, selection and restriction. For more detailed explanations of the attentional mechanisms and review of the relevant psychological and neuroscience literature refer to [467].</p>
<p>The diagram in Figure 6 shows a summary of the implemented visual attention elements in the cognitive architectures. Here we only consider the architectures with implemented real or simulated vision and omit projects for which not enough technical details are provided (same as in the previous section). It is evident that most of the implemented mechanisms of attention belong to the selection and restriction group.</p>
<p>Only a handful of architectures implements suppression mechanisms. For instance, suppression of task irrelevant visual information is done in only three architectures: in BECCA irrelevant features are suppressed through the WTA mechanisms [372], in DSO background features are suppressed to speed up processing [520], in MACSi depth is used to ignore regions that are not reachable by the robot [285] and in ARCADIA non-central regions of the visual field are inhibited at each cycle since the cue always appears in the center [69]. Another suppression mechanism is inhibition of return (IOR), which prevents the visual system from attending to the same salient stimuli. In ACT-R activation values and distance are used to ignore objects for consecutive WHERE requests [335]. In ART, iCub and STAR an additional map is used to keep records of the attended locations. The temporal nature of inhibition can be modeled with a time decay function, as it is done in iCub [380]. ARCADIA mentions covert inhibition mechanism, however, the implementation details are not provided [69].</p>
<p>Selection mechanisms are more commonly found in the cognitive architectures. For example, a world model by default is a part of any visual system. Viewpoint/gaze selection is a necessary component of active vision systems. Gaze control allows to focus on a region in the environment and viewpoint selection allows to get more information about the region/object by changing the distance to it or by viewing it from different angles. The physically embodied architectures automatically support viewpoint selection because a camera installed on a robot can be moved around the environment. Eye movements are usually simulated, but it is also possible to implement them on a humanoid robot (iCub, Kismet). Other mechanisms in this group include selection of various features/objects of interest. The selection of visual data to attend can be data-driven (bottom-up) or task-driven (top-down). The bottom-up attentional mechanisms identify salient regions whose visual features are distinct from the surrounding image features, usually along a combination of dimensions, such as color channels, edges, motion, etc. Some architectures resort to the classical visual saliency algorithms, such as Guided Search [516] used in ACT-R [335] and Kismet [64], the Itti-Koch-Niebur model [215] used by ARCADIA [69], iCub [380] and DAC [302] or AIM [76] used in STAR [248]. Other approaches include filtering (DSO [520]), finding unusual motion patterns (MACsi [217]) or discrepancies between observed and expected data (RCS [9]).
3T 4D-RCS ACT-R ADAPT ARCADIA ARDIS ART ATLANTIS BBD BECCA CARACaS CERA-CRANIUM CORTEX CSE CoSy DAC DIARC DSO DUAL ISAC Kismet LIDA Leabra MACSi MDB PolyScheme RoboCog SAL SASE SPA STAR Soar Subsumption iCub f
Top-down selection can be applied to further limit the sensory data provided by the bottom-up processing. For example, in visual search, knowing desired features of the object (e.g., the color red) can narrow down the options provided by the data-driven figure-ground segmentation. Many architectures resort to this mechanism to improve search efficiency (ACT-R [387], APEX [155], ARCADIA [45], CERA-CRANIUM [19], CHARISMA [94], DAC [302]). Another option is to use a hard-coded or learned heuristics. For example, CHREST looks at typical positions on a chess board [266] and MIDAS replicates common eye scan patterns of pilots [174]. The limitation of the current top-down approaches is that they can direct vision for only a limited set of predefined visual tasks, however, ongoing research in STAR attempts to address this problem ( [470], [467]).</p>
<p>Restriction mechanisms allow to further reduce the complexity of vision by limiting the search space to certain features (priming), events (exogenous cues), space (visual field), objects (exogenous task) and knowledge (endogenous motivations). Exogenous task and endogenous motivations are implemented in all the architectures by default as domain knowledge and task instructions. In addition to that, attention can be modulated by internal signals such as motivation, emotions, which are discussed in the next section on action selection.</p>
<p>A limited visual field is a feature of any physically embodied system since most cameras do not have a 360-degree field of view. This feature is also present in some simulated vision systems. An ability to react to the sudden events (exogenous cues), such as fast movement or bright color, is common in social robotics applications (e.g. ISAC [228], Kismet [62]). On the other hand, priming allows to bias the visual system towards particular types of stimuli via task instruction. For example, by assigning more weight to skincolored features during the saliency computation to improve human detection (Kismet [57]) or by utilizing the knowledge of the probable location of some objects to spatially bias detection (STAR [248]). Neural mechanisms of top-down priming are studied in ART models [85].</p>
<p>Overall, visual attention is largely overlooked in cognitive architectures research with the exception of the biologically plausible visual models (e.g. ART) and the architectures that specifically focus on vision research (ARCADIA, STAR 8 ). This is surprising because strong theoretical arguments as to its importance in dealing with the computational complexity of visual processing have been known for decades [465]. Often the attention mechanisms found in the cognitive architectures are side-effects of other design decisions. For example, task constraints, world model and domain knowledge are necessary for the functioning of other aspects of intelligent system and are implemented by default. Limited visual field and viewpoint changes often result from physical embodiment. Otherwise, region of interest selection and visual reaction to exogenous cues are the two most common mechanisms explicitly included for optimizing visual processing.</p>
<p>In the cognitive and psychological literature, attention is also used as a broad term for the allocation of limited resources [378]. For instance, in the Global Workspace Theory (GWT) [27] attentional mechanisms are central to perception, cognition and action. According to GWT, the nervous system is organized as multiple specialized processes running in parallel. Coalitions of these processes compete for attention in the global workspace and the contents of the winning coalition are broadcast to all other processes. For instance, the LIDA architecture is an implementation of GWT 9 [153]. Other architectures influenced by the GWT include ARCADIA [69] and CERA-CRANIUM [20].</p>
<p>Along the same lines, cognition is simulated as a set of autonomous independent processes in ASMO (inspired by Society of Mind [312]). Here an attention value for each process is either assigned directly or learned from experience. Attention values vary dynamically and affect action selection and resource allocation [330]. A similar idea is implemented in COGNET [525], DUAL [242] and Copycat/Metacat [316] in which multiple processes also compete for attention. Other computational mechanisms, such as queue (PolyScheme [256]), Hopfield nets (CogPrime [214]) and modulators (MicroPsi [33]) have been used to implement a focus of attention. In MLECOG, in addition to saccades that operate on visual data, mental saccades allow to switch between the most activated memory neurons [428].</p>
<p>Action selection</p>
<p>Informally speaking, action selection determines at any point in time "what to do next". At the highest level, action selection can be split into the what part involving the decision making and the how part related to motor control [344]. However, this distinction is not always explicitly made in the literature, where action selection may refer to goal, task or motor command. For example, in the MIDAS architecture action selection involves both the selection of the next goal to pursue and of actions that implement it [471]. Similarly, in MIDCA the next action is normally selected from a planned sequence if one exists. In addition to this, a different mechanism is responsible for the adoption of the new goals based on dynamically determined priorities [346]. In COGNET and DIARC, selection of a task/goal triggers an execution of the associated procedural knowledge ( [523], [68]). In DSO, the selector module chooses between available actions or decisions to reach current goals and sub-goals [326]. Since the treatment of action selection in various cognitive architectures is inconsistent, in the following discussion the action selection mechanisms may apply both to decision-making and motor actions.</p>
<p>The diagram in Figure 7 illustrates all implemented action selection mechanisms organized by the type of the corresponding architecture (symbolic, hybrid and emergent). We distinguish between two major approaches to action selection: planning and dynamic action selection. Planning refers to the traditional AI algorithms for determining a sequence of steps to reach a certain goal or to solve a problem. In dynamic action selection, one best action is chosen among the alternatives based on the knowledge available at the time. For this category, we consider the type of selection (winner-take-all (WTA), probabilistic, predefined) and criteria for selection (relevance, utility, emotion). The default choice is always the best action based on the defined criteria (e.g. action with the highest activation value). Reactive actions are executed bypassing action selection. Finally, learning can also affect action selection but will be discussed in section 8. Note that these action selection mechanisms are not mutually exclusive and most of the architectures have more than one. And even though few architectures implement the same set of action selection mechanisms (as can be seen in the Figure 7), the whole space of valid combinations is likely much larger. Below we discuss approaches to action selection and what cognitive processes they correspond to in more detail.</p>
<p>Predictably, planning is more common in the symbolic architectures, but can also be found in some hybrid and even emergent (MicroPsi [33]) architectures. In particular, task decomposition, where the goal is recursively decomposed into subgoals, is a very common form of planning (e.g. Soar [106], Teton [478], PRODIGY [142]). Other types of planning are also used: temporal (Homer [485]), continual (CoSy [184]), hierarchical task network (PRS [113]), generative (REM [321]), search-based (Theo [318]), hill-climbing (MicroPsi [33]), etc.</p>
<p>Very few systems in our selection rely on classical planning alone, namely OSCAR, used for logical inference, and IMPRINT, which employs task decomposition for modeling human performance. Otherwise,    planning is usually augmented with more dynamic action selection mechanisms to improve adaptability to the changing environment.</p>
<p>On the other end of the spectrum are reactive actions. These are executed immediately, suspending any ongoing activity and bypassing reasoning, similar to reflex actions in humans as automatic responses to stimuli. As demonstrated by the Subsumption architecture, combining multiple reactive actions can give rise to complex behaviors [74], however, purely reactive systems are rare and reactive actions are used only under certain conditions. For example, they are used to protect the robot from the collision (ATLANTIS [159], 3T [54]) or to automatically respond to unexpected stimuli, such as fast moving objects or loud sounds (ISAC [227], Kismet [63], iCub [380]).</p>
<p>Alternatively, dynamic action selection offers the most flexibility and can be used to model many phenomena typical for human and animal behavior. Winner-take-all is a selection process in neuronal networks where the strongest set of inputs is amplified, while the output from others is inhibited. It is believed to be a part of cortical processes and is often used in the computational models of the brain to make a selection from a set of decisions depending on the input. WTA and its variants are common in the emergent architectures such as HTM [80], ART [87], SPA [121], Leabra [340], DAC [488], Darwinian Neurodynamics [140] and Shruti [502]. Similar mechanisms are also used to find the most appropriate action in the architectures, where behavior emerges as a result of cooperation and competition of multiple processes running in parallel (e.g. Copycat/Metacat [295], CELTS [133], LIDA [152]).</p>
<p>Predefined order of action selection may serve different purposes. For example, in the Subsumption architecture robot behavior is represented by a hierarchy of sub-behaviors, where higher-level behaviors override (subsume) the output of lower-level behaviors [74]. In FORR, decision-making component considers options from advisors in the order of increasing expertise to achieve robust and human-like learning [127]. In Ymir priority is given to processes within the reactive layer first, followed by the content layer and then by process control layer. Here the purpose is to provide a smooth real-time behavior generation. Each layer has a different upper bound on the perception-action time, thus reactive modules provide automatic feedback to the user (changing facial expressions, automatic utterances) while deliberative modules are generating more complex behaviors [455].</p>
<p>The remaining action selection mechanisms include finite-state machines (FSM), which are frequently used to represent sequences of motor actions (ATLANTIS [159], CARACaS [211], Subsumption [74]) and even to encode the entire behavior of the system (ARDIS [299], STAR [248]). Next action can also be chosen probabilistically (iCub [487], CSE [193], CogPrime [166], Sigma [474], Darwinian Neurodynamics [140], ERE [230], Novamente [169]).</p>
<p>There are several criteria that can be taken into account when selecting the next action: relevance, utility and affect (which includes motivations, affective states, emotions, moods, drives, etc.). Relevance reflects how well the action corresponds to the current situation. This mainly applies to systems with symbolic reasoning and involves checking pre-and/or post-conditions of the rule before applying it (MAX [255], Disciple [449], EPIC [234], GLAIR [416], PRODIGY [483], MIDAS [471], R-CAST [137], Disciple [449], Companions [197], Ymir [455], Pogamut [71], Soar [262], ACT-R [274]).</p>
<p>Utility of the action is a measure of its expected contribution to achieving the current goal (CERA-CRANIUM [20], CHARISMA [94], DIARC [68], MACSi [217], MAMID [205], NARS [499], Novamente [169]). Some architectures also perform a "dry run" of candidate actions and observe their effect to determine their utility (MLECOG [428], RoboCog [38]). Utility can also take into account the performance of the action in the past and improve the behavior in the future via reinforcement learning (ASMO [329], BECCA [370], CLARION [442], PRODIGY [82], CSE [193], CoJACK [130], DiPRA [352], Disciple [449], DSO [326], FORR [127], ICARUS [414], ISAC [227], MDB [41], MicroPsi [30], Soar [262]). Other machine learning techniques are also used to associate goals with successful behaviors in the past (MIDCA [346], SASE [503], CogPrime [166]).</p>
<p>Finally, internal factors do not determine the next behavior directly, but rather bias the selection. In humans, internal factors such as emotions, drives, moods and personality traits are known to have an effect on perception, action, learning and cognition. For example, it has been shown that fear reduces attentional capacity, biases attention toward threat detection and can lead to irrational choices ( [206], [130]). Emotional evaluations produce faster decisions (although less accurate) than longer and more complex cognitive evaluations [225]. There is also evidence that positive and negative emotions encode likelihood of positive and negative future events thus affecting memory [50]. Given the impact of emotion on human decision making and other cognitive abilities it is important to model emotion and affect in cognitive architectures, especially in the areas of human-computer interaction, social robotics and virtual agents. Not surprisingly, this is where most of the effort has been spent so far.</p>
<p>One of the most complex and functional motivational systems based on a plethora of psychological research is implemented on the social robot Kismet [58]. The robots behavior is organized around satiating three basic drives: to engage people, to engage toys, and to rest. These drives have a cyclical and homeostatic nature and, together with external events, contribute to the long-term affective state (or "mood" of the robot) and its expression as anger, disgust, fear, joy, sorrow and surprise via facial gestures, stance or changes in the tone of its voice. Although most of the emotional mechanisms are carefully engineered and hand-tuned, Kismet demonstrates probably the widest repertoire of emotional behaviors of all the cognitive architectures we reviewed.</p>
<p>Other cognitive architectures implement internal factors on a smaller scale. For example, in ASMO only three relatively simple drives (liking color red, praise and happiness of the user and the robot) are modeled. Their purpose is to bias the action selection by modifying the weights of the corresponding modules [329]. In CoJACK morale and fear are used to modify the plan selection. As a result, plans that confront a threat have higher utility when morale is high, but lower utility when fear is high [130]. DIARC introduces two values for positive and negative affect related to how close the system is to satisfying a goal [405]. In CHARISMA preservation drives (avoid harm and starvation) combined with curiosity and desire for self-improvement guide behavior generation [95]. In MACSi curiosity drives exploration towards areas where the agent learns the fastest [327]. Other examples include CELTS, where emotional tags are used to improve learning in an HCI scenario [133], and CERA-CRANIUM, where emotions of curiosity, fear, anger, joy, sadness [23] are used to increase the believability of the video game character [22].</p>
<p>Furthermore, multiple models of the effect of emotions on human behavior were developed. Examples include models of stress affecting decision-making (MAMID [208]), emotions of joy/sadness affecting blackjack strategy (CHREST [407]), model of coping with bullying at school (CLARION [513]), analogical reasoning in the state of anxiety (DUAL [141]), effect of arousal on memory (ACT-R [93]), etc. In addition, the largest attempt at implementing a theory of appraisal led to the creation of Soar-Emote, a model based on the ideas of [292] It should be noted that the models described above represent an externalist approach to synthetic emotions, where external and internal stimuli of an agent give rise to observable behavioral consequences [31]. MicroPsi and CogPrime, both implementing Dörners Psi theory [115], model emotions as emergent phenomena, not as parameters or modules represented at the architectural level. This is accomplished through the use of modulators, i.e. parameters that characterize how the emotion affects the process of perception, cognition and action selection [32].</p>
<p>The authors of the DIARC and ICARUS architectures argue that moral judgment should also be part of the decision-making process. For example, an assistive robot taking care of an ill person may need to give her a painkiller in a situation when the doctor is not available and cannot provide a prescription. In this case, the robot will have to choose between relieving the suffering of its master and breaking the law (DIARC [404]). Limited applications of moral reasoning were modeled in ICARUS in a "Robin Hood" scenario where an agent could recognize rich and poor people and acted to redistribute the wealth [213].</p>
<p>Memory</p>
<p>Memory is an essential part of any systems-level cognitive model, regardless of whether the model is being used for studying the human mind or for solving engineering problems. Thus, nearly all the architectures featured in this review have memory systems that store intermediate results of computations, enabling learning and adaptation to the changing environment. However, despite their functional similarity, the particular implementations of memory systems differ significantly and depend on the research goals and conceptual limitations, such as biological plausibility and engineering factors (e.g. programming language, software architecture, use of frameworks, etc.). In the cognitive architecture literature, memory is described in terms of its duration (short-and long-term) and type (procedural, declarative, semantic, etc.), although it is not necessarily implemented as separate knowledge stores.</p>
<p>The multi-store memory model is influenced by the Atkinson-Shiffrin model (1968) [26], later modified by Baddeley [36]. This view of memory is dominant in psychology, but its utility for engineering is questioned by some because it does not provide a functional description of various memory mechanisms [349]. Nevertheless, most architectures do distinguish between various memory types, although the naming conventions differ depending on the conceptual background. For instance, the architectures designed for planning and problem solving have short-and long-term memory storage systems but do not use terminology from the cognitive psychology. The long-term knowledge in planners is usually referred to as a knowledge base for facts and problem-solving rules, which correspond to semantic and procedural long-term memory (e.g. Disciple [444], MACsi [217], PRS [163], ARDIS [299], ATLANTIS [159], IMPRINT [67]). Some architectures also save previously implemented tasks and solved problems, imitating episodic memory (REM [322], PRODIGY [481]). The short-term storage in planners is usually represented by a current world model or the contents of the goal stack. Figure 8 shows a visualization of various types of memory implemented by the architectures. Here we follow the convention of distinguishing between the long-term and short-term storage. Long-term storage is further subdivided into semantic, procedural and episodic types, which store factual knowledge, information on what actions should be taken under certain conditions respectively and episodes from the personal experience of the system respectively. Short-term storage is split into sensory and working memory following [99]. Sensory or perceptual memory is a very short-term buffer that stores several recent percepts. Working memory is a temporary storage for percepts that also contains other items related to the current task and is frequently associated with the current focus of attention.</p>
<p>Sensory memory</p>
<p>The purpose of sensory memory is to cache the incoming sensory data and preprocess it before transferring it to other memory structures. For example, iconic memory assists in solving continuity and maintenance problems, i.e. identifying separate instances of the objects as being the same and retaining impression of the object when unattended (ARCADIA [69]). Similarly, echoic memory allows an acoustic stimulus to persist long enough for perceptual binding and feature extraction, such as pitch extraction and grouping (MusiCog [305]   LIDA [28]) for visual data and longer for audio data (MusiCog [305]), although the time limit is not always specified. Other architectures implementing this memory type include Soar [514], Sigma [377], ACT-R [335], CHARISMA [96], ICARUS [268] and Pogamut [71].</p>
<p>Working memory</p>
<p>Working memory can be defined as a mechanism for temporary storage of information related to the current task. It is critical for cognitive capacities such as attention, reasoning and learning, thus every cognitive architecture in our list implements it in some form. Particular realizations of working memory differ mainly in what information is being stored, how it is represented, accessed and maintained. Furthermore, some cognitive architectures contribute to ongoing research about the processes involved in encoding, manipulation and maintenance of information in the human working memory and its relationship to other processes in the human brain. Despite the importance of working memory for human cognition, relatively few publications provide sufficient detail about its internal organization and connections to other modules. Often it is summarized in a few words, e.g. "current world state" or "data from the sensors". Based on these statements we infer that in many architectures working memory or an equivalent structure serves as a cache for the current world model, the state of the system and/or current goals. Although there are no apparent limitations on the capacity of the working memory, new goals or new sensory data usually overwrite the existing content. This simplified account of working memory can be found in many symbolic architectures (3T [53], ATLANTIS [159], Homer [484], IMPRINT [67], MIDCA [101], PRODIGY [482], R-CAST [521], RALPH [336], REM [321], Theo [318], Disciple [448], OSCAR [356], ARS/SiMA [399], CoJACK [369], ERE [66], MAX [254], Companions [147], RCS [5]) as well as hybrids (CSE [193], MusiCog [305], MicroPsi [29], Pogamut [71]). More cognitively plausible models of working memory use an activation mechanism. Some of the earliest models of activation of the working memory contents were implemented in ACT-R. As before, the working memory holds the most relevant knowledge, which is retrieved from the long-term memory as determined by bias. This bias is referred to as activation and consists of base-level activation (which may decrease or increase) with every access and may also include the spreading activation from neighboring elements. The higher the activation of the element, the more likely it is to enter the working memory and directly affect the behavior of the system [12]. This applies to the graph-based knowledge representation where nodes refer to concepts and weights assigned to edges correspond to the associations between the concepts (Soar [259], CAPS [392], ADAPT [48], DUAL [243], Sigma [362], CELTS [133], NARS [496], Novamente [168], MAMID [207]). Naturally, activation can be used in neural network representation as well (Shruti [502], CogPrime [214], Recommendation Architecture [100], SASE [506], Darwinian Neurodynamics [140]). Activation mechanisms contribute to modeling many properties of working memory, such as limited capacity, temporal decay, rapid updating as the circumstances change, connection to other memory components and decision-making. Another common paradigm, the blackboard architecture, represents memory as a shared repository of goals, problems and partial results which can be accessed and modified by the modules running in parallel (AIS [186], CERA-CRANIUM [21], CoSy [421], FORR [124], Ymir [456], LIDA [152], ARCADIA [45], Copycat/Metacat [297], CHARISMA [96], PolyScheme [90], PRS [161]). The solution to the problem is obtained by continuously updating the shared short-term storage with information from specialized heterogeneous modules analogous to a group of people completing a jigsaw puzzle. Although not directly biologically plausible, this paradigm works well in situations where many disparate sources of information must be combined to solve a complex real-time task. Finally, neuronal models of the working memory based on the biology of the prefrontal cortex are realized within SPA [431], ART [177] and Leabra [339]. They demonstrate a range of phenomena (validated on human data) such as adaptive switching between rapid updating of the memory and maintaining previously stored information [338] and reduced accuracy with time (e.g. in a list memory task) [431]. In several robotics architectures all incoming sensory data is mapped to a sphere around the robot forming a sensory ego-sphere (iCub [380], ISAC [227], MACSi [217]). Although functionally similar to the mammalian hippocampus, a sensory ego-sphere is not biologically plausible [350]. However, it enables spatiotemporal integration of multiple sensory modalities and provides representation for the current location and the orientation of the robot within the environment. Along the same lines, Kismet and RoboCog [35] use a map built on the camera reference frame to maintain information about recently perceived regions of interest.</p>
<p>Since, by definition, working memory is a relatively small temporary storage, for biological realism, its capacity should be limited. However, there is no agreed upon way of how this should be done. For instance, in GLAIR the contents of the working memory are discarded when the agent switches to a new problem [416]. A more common approach is to gradually remove items from the memory based on their recency or relevance in the changing context. The CELTS architecture implements this principle by assigning an activation level to percepts that is proportional to the emotional valence of a perceived situation. This activation level changes over time and as soon as it falls below a set threshold, the percept is discarded [133]. The Novamente Cognitive Engine has a similar mechanism, where atoms stay in memory as long as they build links to other memory elements and increase their utility [168]. It is still unclear if under these conditions the size of working memory can grow substantially without any additional restrictions.</p>
<p>To prevent unlimited growth, a hard limit can be defined for the number of items in memory, for example, 3-6 objects in ARCADIA [45], 4 chunks in CHREST [282] or up to 20 items in MDB [43]. Then as the new information arrives, the oldest or the most irrelevant items would be deleted to avoid overflow. Items can also be discarded if they have not been used for some time. The exact amount of time can vary from 4-9 seconds (EPIC [233]) to 5 sec (MIDAS [202], CERA-CRANIUM [21]) to tens of seconds (LIDA [151]). In the Recommendation Architecture, a different approach is taken so that the limit of 3-4 items in working memory emerges naturally from the structure of the memory system, and not the external parameter setting [100].</p>
<p>Long-term memory</p>
<p>Long-term memory (LTM) preserves a large amount of information for a very long time. Typically, it is divided into the procedural memory of implicit knowledge (e.g. motor skills and routine behaviors) and declarative memory, which contains (explicit) knowledge. The latter is further subdivided into semantic (factual) and episodic (autobiographical) memory.</p>
<p>The dichotomies between the explicit/implicit and the declarative/procedural long-term memories are usually merged. One of the few exceptions is CLARION, where procedural and declarative memories are separate and both subdivided into an implicit and explicit component. This distinction is preserved on the level of knowledge representation: implicit knowledge is captured by distributed sub-symbolic structures like neural networks, while explicit knowledge has a transparent symbolic representation [436].</p>
<p>Long-term memory is a storage for innate knowledge that enables operation of the system, therefore almost all architectures implement procedural and/or semantic memory. The procedural memory contains knowledge about how to get things done in the task domain. In symbolic production systems, procedural knowledge is represented by a set of if-then rules preprogrammed or learned for a particular domain (3T [144], 4CAPS [480], ACT-R [274], ARDIS [299], EPIC [235], SAL [194], Soar [279], APEX [154]). Other variations include sensory-motor schemas (ADAPT [48]), task schemas (ATLANTIS [159]) and behavioral scripts (FORR [125]). In emergent systems, procedural memory may contain sequences of state-action pairs (BECCA [374]) or ANNs representing perceptual-motor associations (MDB [386]).</p>
<p>Semantic memory stores facts about the objects and relationships between them. In the architectures that support symbolic reasoning, semantic knowledge is typically implemented as a network-like ontology, where nodes correspond to concepts and links represent relationships between them (Casimir [410], Disciple [52], MIDAS [98], Soar [279], CHREST [281]). In emergent architectures factual knowledge is represented as patterns of activity within the network (BBD [251], SHRUTI [419], HTM [272], ART [83]).</p>
<p>Episodic memory stores specific instances of past experience. These can later be reused if a similar situation arises (MAX [255], OMAR [110], iCub [487], Ymir [456]). However, these experiences can also be exploited for learning new semantic or procedural knowledge. For example, CLARION saves action-oriented experiences as "input, output, result" and uses them to bias future behavior [438]. Similarly, BECCA stores sequences of state-action pairs to make predictions and guide the selection of system actions [374], and MLECOG gradually builds 3D scene representation from perceived situations [218]. MAMID [204] saves the past experience together with the specific affective connotations (positive or negative), which affect the likelihood of selecting similar actions in the future. Other examples include R-CAST [39], Soar [333], Novamente [278] and Theo [317].</p>
<p>Global memory</p>
<p>Despite the evidence for the distinct memory systems, some architectures do not have separate representations for different kinds of knowledge or short-vs long-term memory, and instead, use a unified structure to store all information in the system. For example, CORTEX and RoboCog use an integrated, dynamic multi-graph object which can represent both sensory data and high-level symbols describing the state of the robot and the environment ( [376], [77]). Similarly, AIS implements a global memory, which combines a knowledge database, intermediate reasoning results and the cognitive state of the system [189]. DiPRA uses Fuzzy Cognitive Maps to represent goals and plans [354]. NARS represents all empirical knowledge, regardless of whether it is declarative, episodic or procedural, as formal sentences in Narcese [500]. Similarly, in some emergent architectures, such as SASE [506] and ART [83], the role of neurons as working or long-term memory is dynamic and depends on whether the neuron is firing.</p>
<p>Overall, research on memory in the cognitive architectures mainly concerns its structure, representation and retrieval. Relatively little attention has been paid to the challenges associated with maintaining a largescale memory store since both the domains and the time spans of the intelligent agents are typically limited. In comparison, early estimates of the capacity of the human long-term memory are within 1.5 gigabits or on the order of 100K concepts [265], while more recent findings suggest that human brain capacity may be orders of magnitude higher [40]. However, scaling nave implementations even to the lowest estimated size of human memory likely will not be possible despite the increase in available computational power. Thus alternative solutions include tapping into existing methods for large-scale data management and improving the retrieval algorithms. Both avenues have been explored, the former by Soar and ACT-R, which used PostgreSQL relational database to load concepts and relations from WordNet ( [107], [116]), and the latter by the Companions architecture [146]. Alternatively, SPA supports a biologically plausible model of associative memory capable of representing over 100K concepts in WordNet using a network of spiking neurons [102].</p>
<p>Learning</p>
<p>Learning is the capability of a system to improve its performance over time. Ultimately, any kind of learning is based on experience. For example, a system may be able to infer facts and behaviors from the observed events or from results of its own actions. The type of learning and its realization depend on many factors, such as design paradigm (e.g. biological, psychological), application scenario, data structures and the algorithms used for implementing the architecture, etc. However, we will not attempt to analyze all these aspects given the diversity and number of the cognitive architectures surveyed. Besides, not all of these pieces of information can be easily found in the publications. Thus, a more general summary is preferable, where types of learning are defined following taxonomy by Squire ( [427]). Learning is divided into declarative or explicit knowledge acquisition and non-declarative, which includes perceptual, procedural, associative and non-associative types of learning. Figure 9 shows a visualization of the these types of learning for all cognitive architectures.</p>
<p>Perceptual learning</p>
<p>Although many systems use pre-learned components for processing perceptual data, such as object and face detectors or classifiers, we do not consider these here. Perceptual learning applies to the architectures that actively change the way sensory information is handled or how patterns are learned on-line. This kind of learning is frequently performed to obtain implicit knowledge about the environment, such as spatial maps (RCS [408], AIS [188], MicroPsi [34]), clustering visual features (HTM [247], BECCA [371], Leabra [343]) or finding associations between percepts. The latter can be used within the same sensory modality as in the case of the agent controlled by Novamente engine, which selects a picture of the object it wants to get from a teacher [165]. Learning can also occur between different modalities, for instance, the robot based on the SASE architecture learns the association between spoken command and action [507] and Darwin VII (BBD) learns to associate taste value of the blocks with their visual properties [120].</p>
<p>Declarative learning</p>
<p>Declarative knowledge is a collection of facts about the world and various relationships defined between them. In many production systems such as ACT-R and others, which implement chunking mechanisms (SAL [219], CHREST [407], CLARION [439]), new declarative knowledge is learned when a new chunk is added to declarative memory (e.g. when a goal is completed). Similar acquisition of knowledge has also been demonstrated in systems with distributed representations. For example, in DSO knowledge can be directly input by human experts or learned as contextual information extracted from labeled training data [326]. New symbolic knowledge can also be acquired by applying logical inference rules to already known facts (GMU-BICA [390], Disciple [51], Casimir [410], NARS [497]). In many biologically inspired systems learning new concepts usually takes the form of learning the correspondence between the visual features of the object and its name (iCub [112], Leabra [343], MACsi [217], Novamente [165], CoSy [184], DIARC [522]).</p>
<p>Procedural learning</p>
<p>Procedural learning refers to learning skills, which happens gradually through repetition until the skill becomes automatic. The simplest way of doing so is by accumulating examples of successfully solved problems to be reused later (e.g. AIS [188], R-CAST [137], RoboCog [291]     traversed path could be saved and used again to go between the same locations later (AIS [188]). Obviously, this type of learning is very limited and further processing of accumulated experience is needed to improve efficiency and flexibility. Explanation-based learning (EBL) [313] is a common technique for learning from experience found in many architectures with symbolic representation for procedural knowledge (PRODIGY [129], Teton [476], Theo [476], Disciple [51], MAX [255], Soar [263], Companions [156], ADAPT [46], ERE [230], REM [321], CELTS [132], RCS [3]). In short, it allows generalization of the explanation of a single observed instance into a general rule. However, EBL does not extend the problem domain, but rather makes solving problems more efficient in similar situations. A known drawback of this technique is that it can result in too many rules (also known as the "utility problem"), which may slow down the inference. To avoid the explosion in the model knowledge, various heuristics can be applied, e.g. adding constraints on events that a rule can contain (CELTS [132]) or eliminating low-use chunks (Soar [232]). Although EBL is not biologically inspired, it has been shown that in some cases human learning may exhibit EBL-like behavior [479].</p>
<p>Symbolic procedural knowledge can also be obtained by inductive inference (Theo [317], NARS [422]), learning by analogy (Disciple [447], NARS [422]), behavior debugging (MAX [255]), probabilistic reasoning (CARACaS [210]), correlation and abduction (RCS [3]) and explicit rule extraction (CLARION [440]).</p>
<p>Associative learning</p>
<p>Associative learning is a broad term for decision-making processes influenced by reward and punishment. In behavioral psychology, it is studied within two major paradigms: classical (Pavlovian) and instrumental (operant) conditioning. Reinforcement learning (RL) and its variants, such as temporal difference learning, Q-learning, Hebbian learning, etc., are commonly used in computational models of associative learning. Furthermore, there is substantial evidence that error-based learning is fundamental for decision-making and motor skill acquisition ( [200], [328], [411]).</p>
<p>The simplicity and efficiency of reinforcement learning make it one of the most common techniques with nearly half of all the cognitive architectures using it to implement associative learning. The advantage of RL is that it does not depend on the representation and can be used in the symbolic, emergent or hybrid architectures. One of the main uses of this technique is developing adaptive behavior. In systems with symbolic components it can be accomplished by changing the importance of actions and beliefs based on their success/failure (e.g. RCS [8], NARS [422], REM [321], RALPH [337], CHREST [407], FORR [173], ACT-R [81], CoJACK [368]).</p>
<p>In the hybrid and emergent systems, reinforcement learning can establish associations between states and actions. One application is sensorimotor reconstruction. The associations are often established in two stages: a "motor babbling" stage, during which the system performs random actions to accumulate data, followed by the learning stage where a model is built using the accrued experiences (ISAC [227], BECCA [374], iCub [307], DiPRA [352], CSE [192]). Associative learning can be applied when analytical solutions are hard to obtain as in case of soft-arm control (ISAC [227]) or when smooth and natural looking behavior is desired (e.g. Segway platform control using BBD [250]).</p>
<p>Non-associative learning</p>
<p>Non-associative learning, as the name suggests, does not require associations to link stimuli and responses together. Habituation and sensitization are commonly identified as two types of non-associative learning.</p>
<p>Habituation describes gradual reduction in the strength of response to repeated stimuli. The opposite process occurs during sensitization, i.e. repeated exposure to stimuli causes increased response. Because of their simplicity these types of learning are considered a prerequisite for other forms of learning. For instance, habituation filters out irrelevant stimuli and helps to focus on important stimuli [364], especially in the situations when positive or negative rewards are absent [503].</p>
<p>Most of the work to date in this area has been dedicated to the habituation in the context of social robotics and humancomputer interaction to achieve adaptive and realistic behavior. For instance, the ASMO architecture enables the robot to ignore irrelevant (but salient) stimuli. During the tracking task, the robot may be easily distracted by fast motion in the background. Habituation learning (implemented as a boost value attached to motion module) allows it to focus on the stimuli relevant for the task [331]. In Kismet [64] and iCub [380] habituation (realized as a dedicated habituation map) causes the robot to look at nonpreferred or novel stimuli. In LIDA and Pogamut habituation is employed to reduce the emotional response to repeated stimuli in human-robot interaction [149] and virtual agent [160] scenarios respectively. MusiCog includes habituation effects to introduce novelty in music generation by aggressively suppressing the salience of elements in working memory that stayed there for a long time [305].</p>
<p>In comparison, little attention has been paid to sensitization. In ASMO, in addition to habituation, sensitization learning allows the social robot to focus on the motion near the tracked object even though it may be slow and not salient [331]. The SASE architecture also describes both mechanisms of non-associative learning [203].</p>
<p>Priming</p>
<p>Priming occurs when prior exposure to stimulus affects its subsequent identification and classification. Numerous experiments demonstrated the existence of priming effects with respect to various stimuli, perceptual, semantic, auditory, etc., as well as behavioral priming [195]. In section 4.1 we mentioned some examples of priming in vision -spatial (STAR [248]) and feature priming (Kismet [57], ART [176]), which allow for more efficient processing of stimuli by biasing the visual system.</p>
<p>Priming in cognitive architectures has been investigated both within applications and theoretically. For example, in HTM priming is used in the context of analyzing streams of data such as spoken language. Priming is essentially a prediction of what is more likely to happen next and may resolve ambiguities based on those expectations [185]. Experiments with CoSy show that priming speech recognition results in a statistically significant improvement compared to a baseline system [280]. Other instances of priming were shown in improving perceptual categorization (ARS/SiMA [398]), skill transfer (SASE [527]), problem solving (DUAL [244]) and question answering (Shruti [418]).</p>
<p>Several models of priming validated by human data were developed in lexical domain and problem solving. For instance, the CLARION model of positive and negative priming in lexical decision tasks models the fact that human participants are faster at identifying sequences of related concepts (e.g. the word "butter" preceded by the word "bread") [190]. Leabra captures effects of priming for the production of the English past-tense inflection [342]. Finally, Darwinian Neurodynamics confirms priming in problem solving by showing that people who were primed for a more efficient solution perform better in solving puzzles [140].</p>
<p>Priming is well studied in psychology and neuroscience [508] and two major theoretical frameworks for modeling priming are found in cognitive architectures: spreading activation (ACT-R [453], Recommendation Architecture [100], Shruti [418], CELTS [131], LIDA [150], ARS/SiMA [398], DUAL [351], NARS [495]) and attractor networks (CLARION [190], Darwinian Neurodynamics [140]. ). The current consensus in the literature is that spreading activation has greater explanation power, but attractor networks are considered more biologically plausible [276]. In this case, it seems that the choice of the particular paradigm may also be influenced by the representation. For instance, spreading activation is found in the localist architectures, where units correspond to concepts. When a concept is invoked, a corresponding unit is activated, the activation is spread to adjacent related units, which facilitates their further use. Alternatively, in attractor networks, a concept is represented by a pattern involving multiple units. Depending on the correlation (relatedness) between the patterns, activating one leads to increase in activation of others. An alternative explanation of priming is offered by SPA based on the parallel constraint satisfaction [409].</p>
<p>We also identified 22 architectures (mostly symbolic and hybrid) that do not implement any learning. In some areas of research, learning is not even necessary, for example, in human performance modeling, where accurate replication of human performance data is required instead (e.g. APEX, EPIC, IMPRINT, MAMID, MIDAS, etc.). Some of the newer architectures are still in the early development stage and may add learning in the future (e.g. ARCADIA, SiMA, Sigma).</p>
<p>Reasoning</p>
<p>Reasoning, originally a major research topic in philosophy and epistemology, in the past decades has become one of the focal points in psychology and cognitive sciences as well. As an ability to logically and systematically process knowledge, reasoning can affect or structure virtually any form of human activity. As a result, aside from the classic triad of logical inference (deduction, induction and abduction), other kinds of reasoning are now being considered, such as heuristic, defeasible, analogical, narrative, moral, etc.</p>
<p>Predictably, all cognitive architectures are concerned with practical reasoning, whose end goal is to find the next best action and perform it, as opposed to the theoretical reasoning that aims at establishing or evaluating beliefs. There is also a third option, exemplified by the Subsumption architecture, which views reasoning about actions as an unnecessary step [72] and instead pursues physically grounded action [74]. Granted, one could still argue that significant amount of reasoning and planning is required from a designer to construct a grounded system with non-trivial capabilities. Otherwise, in the context of cognitive architectures, reasoning is primarily mentioned with regards to planning, decision-making and learning, as well as perception, language understanding and problem-solving.</p>
<p>One of the main challenges a human, and consequently any human-level intelligence, faces regularly is acting based on insufficient knowledge or "making rational decisions against a background of pervasive ignorance" [358]. In addition to the sparse domain knowledge, there are limitations in terms of available internal resources, such as information processing capacity. Furthermore, external constraints, such as realtime execution, may also be introduced by the task. It should be noted that even in the absence of these restrictions, reasoning is by no means trivial. Consider, for instance, complex machinery used by Copycat and Metacat to model analogical reasoning in a micro-domain of character strings [199].</p>
<p>So far, the most consolidated effort has been spent on overcoming the insufficient knowledge and/or resources problem in continuously changing environments. In fact, this is the goal of general-purpose reasoning systems such as Procedural Reasoning System (PRS), Non-Axiomatic Reasoning System (NARS), OSCAR and Rational Agent with Limited-Performance Hardware (RALPH). PRS is one of the earliest instances of the BDI (belief-desire-intention) model. In each reasoning cycle, it selects a plan matching the current beliefs, adds it to the intention stack and executes it. If new goals are generated during the execution, new intentions are created [162]. NARS approaches the issue of insufficient knowledge and resources by iteratively reevaluating existing evidence and adjusting its solutions accordingly. This is possible with Non-Axiomatic Logic, which associates truth values with each statement thus allowing to express the agents confidence in the belief, a feature not available in PRS [181]. RALPH tackles complex goal-driven behavior in complex domain using decision-theoretic approach. Thus computation is synonymous with action and action with the highest utility value (based on its expected effect) is always selected [382]. The OSCAR architecture explores defeasible reasoning, i.e. reasoning which is rationally compelling but not deductively valid [246]. This is a more accurate representation of everyday reasoning, where knowledge is sparse, tasks are complex and there are no certain criteria for measuring success.</p>
<p>All the architectures mentioned above aim at creating rational agents with human-level intelligence but they do not necessarily try to model human reasoning processes. This is the goal of architectures such as ACT-R, Soar, DUAL and CLARION. In particular, Human Reasoning Module implemented in ACT-R works under the assumption that human reasoning is probabilistic and inductive (although deductive reasoning may still occur in the context of some tasks). This is demonstrated by combining a deterministic rule-based inference mechanism with long-term declarative memory with properties similar to human memory, i.e. incomplete and inconsistent knowledge. Together, the uncertainty inherent in the knowledge and production rules enable human-like reasoning behavior, which has been confirmed experimentally [334]. Similarly, symbolic and subsymbolic mechanisms in CLARION [190] and DUAL [245] architectures are used to model and explain various psychological phenomena associated with deductive, inductive, analogical and heuristic reasoning.</p>
<p>As discussed in section 3, the question of whether the higher human cognition is inherently symbolic or not is still unresolved. The symbolic and hybrid architectures considered so far, view reasoning mainly as a symbolic manipulation. Given that in emergent architectures the information is represented by the weights between individual units, what kind of reasoning, if any, can they support? It appears, based on the cognitive architecture literature, the many of the emergent architectures, e.g. ART, HTM, DAC, BBD, BECCA, simply do not address reasoning, although they certainly exhibit complex intelligent behavior. On the other hand, since it is possible to establish a correspondence between the neural networks and logical reasoning systems [301], then it should also be possible to simulate symbolic reasoning via neural mechanisms. And indeed, several architectures demonstrate symbolic reasoning and planning (SASE, SHRUTI, MicroPsi). To date, one of the most successful implementation of symbolic reasoning (and other low-and high-level cognitive phenomena) in the neural architecture is represented by SPA [366]. Architectures like this also raise interesting questions whether it makes sense to try and segregate symbolic parts of cognition from sub-symbolic. As most existing cognitive architectures represent a continuum from purely symbolic to connectionist, the same may be true for the human cognition as well.</p>
<p>Practical applications</p>
<p>The cognitive architectures reviewed in this paper are mainly used as research tools and very few are developed outside of academia. However, it is still appropriate to talk about their practical applications, since useful behavior in various domains is an end goal of all cognitive architectures. Specifically, we are seeking answers to the following questions: what cognitive abilities have been demonstrated by the cognitive architectures and what particular practical tasks have they been applied to?</p>
<p>After a thorough search through the publications, we identified more than 900 projects implemented using 85 cognitive architectures. Our findings are summarized in Figure 10. It shows the cognitive abilities associated with the demonstrated applications, the total number of applications for each architecture (represented by the length of the bars) and what application categories they belong to (the types of categories and the corresponding number of applications in each category are shown by the color and length of the bar segments respectively).  </p>
<p>Competency areas</p>
<p>In order to determine the scope of research in cognitive architectures with respect to modeling various human cognitive abilities, we used the list of human competencies proposed by Adams et al. [1]. Furthermore, this list overlaps with cognitive abilities that have been identified for the purposes of evaluation of cognitive architectures (mentioned in the beginning of section 3), and adds several new areas such as social interaction, emotion, building/creation, quantitative skills and modeling self/other. In the following analysis, we depart from the work in [1] in two aspects. First, these competency areas are meant for evaluating AI and it is expected that each area will have a set of associated scenarios. Since we cannot conduct experiments needed for such evaluation, we instead decide which of these competency areas are represented in existing practical applications based on the published papers. Second, the authors of [1] define subareas for each of the competency areas (e.g. tactical, strategic, physical and social planning). Although we will discuss some of these subareas below, they are not shown in the diagram in Figure 10. Moreover, since perception, memory, attention, learning, reasoning, planning and emotion were already covered in the previous sections, they will not be considered here to avoid repetition. Actuation, communication and social interaction will be discussed in the following subsections on practical applications in robotics and human-robot interaction. Below we briefly examine the remaining competency areas: modeling self/other, building/creation and quantitative skills.</p>
<p>Modeling self/other implies many high-level cognitive abilities such as metacognition, awareness of others, "theory of mind", etc. Since the focus of this survey is on the core cognitive abilities, these phenomena are not covered in the main text. In the context of cognitive architectures, we will consider only metacognition and theory of mind.</p>
<p>Metacognition, intuitively defined as "thinking about thinking", introspectively monitors internal processes and reasons about them, which may lead to changes in one's behavior in the future. This self-watching ability is essential for noticing, explaining and correcting erroneous decisions. Although many architectures provide theoretical accounts of metacognition, its application has been demonstrated only in few limited domains. For instance, Metacat applies metacognition to analogical reasoning in a micro-domain of strings of characters (e.g. if abc → abd; mrrjjj → ?). Self-watching allows the system to remember past solutions, compare different answers and justify its decisions [296]. Similarly, in RALPH metareasoning is defined as the ability to recall and reevaluate past solutions based on their utility, and in addition make decisions on when and how much to plan depending on the situation and the past experience [385] (the same functions are delegated to so called meta-level Knowledge Areas in PRS [162]). This leads to more efficient problem solving in playing games such as Othello [384], better control of the simulated vehicle [337] and real-time adaptability to continuously changing environment [162]. In GMU-BICA metacognition is related to the Necker cube illusion as caused by the continuous revision of the beliefs of the agent [388]. Internal error monitoring, i.e. the comparison between the actual and expected perceptual inputs lets the SAL architecture to determine success or failure of its actions in a simple task, such as stacking blocks, and apply it to learning better actions in the future [489]. Rudimentary metacognitive mechanisms are also implemented in some robotic architectures, such as ASMO [332] and DIARC [401].</p>
<p>In the psychological literature, a Theory of mind (ToM) is seen as an important skill required for social cognition. ToM refers to being able to acknowledge and understand mental states of other people, use the judgment of their mental state to predict their behavior and inform one's own decision making. Very few architectures support this ability. Most recently, Sigma demonstrated two distinct mechanisms for ToM using as an example several single-stage simultaneous-move games, in particular, the well-known Prisoner's dilemma. The first mechanism is automatic as it involves probabilistic reasoning over the trellis graph and the second is combinatorial search across the problem space [363].</p>
<p>PolyScheme applies ToM to perspective taking in the human-robot interaction scenario. The robot and human in this scenario are together in a room with two traffic cones and multiple occluding elements. The human gives a command to move towards a cone, without specifying which one. If only one cone is visible to a human, the robot can model the scene from the human's perspective and use this information to disambiguate the command [460]. Another example is reasoning about beliefs in a false belief task. In this scenario, two agents A and B observe a cookie placed in a jar. After B leaves, the cookie is moved to another jar. When B comes back, A is able to reason that B still believes that cookie is still in the first jar [396].</p>
<p>ACT-R was used to build several models of false belief and second-order false belief task (answering questions of the kind "Where does Ayla think Murat will look for chocolate?") which are typically used to assess whether children have a theory of mind ( [463], [24]). However, particularly interesting is the recent developmental model of ToM based on ACT-R, which was subsequently implemented on a mobile robot. Several scenarios were set up to show how ToM ability can improve the quality of interaction between the robot and a human. For instance, in a patrol scenario both the robot and human receive a task of patrolling the south area of the building, but as they start, the instructions are changed and instead direct them to head west. When the human starts walking in the south direction, the robot infers that she might have forgotten about the new task and reminds her [462].</p>
<p>Building/creation competency area involves skills such as physical construction and forming new concepts. The latter roughly corresponds to learning declarative knowledge which has been covered in section 8. Most of the practical applications involve inference of new knowledge from given facts. For instance, an early SCA-Soar model for symbolic concept acquisition can learn rules for category prediction [309] and apply them in the context of a simplified air traffic control task to determine which planes should be accepted for landing [518]. Similarly, Disciple extends its knowledge in various domains from incomplete theory through inference and communication with human expert [450].</p>
<p>Demonstrated skills in physical construction presently are limited to toy problems, such as stacking blocks in a defined work area using a robotic arm (Soar [264]) or in a simulated environment (SAL [489]).</p>
<p>Quantitative skills, i.e. the ability to use or manipulate numeric information, are underrepresented in the cognitive architectures. Few implemented examples include counting moving and stationary objects in a simulated environment (GLAIR [393]), computing a sum of two values (SPA [122]), identifying and counting the number of surrounding faces in a room (DIARC [406]) and finger counting (iCub [112]).</p>
<p>Counting tasks are also used to evaluate other cognitive abilities in psychological experiments, e.g. memory (counting tasks investigated by ACT-R [347] and CLARION [442]) and cognitive arithmetic model for addition and subtraction (Soar [501]). Besides these, we came across several models of multi-column subtraction used to investigate hierarchical problem representation and solving (Teton [477], ICARUS [269] and Soar [379]).</p>
<p>Application categories</p>
<p>We identified ten major categories of applications, namely human performance modeling (HPM), games and puzzles, robotics, psychological experiments, natural language processing (NLP), human-robot and humancomputer interaction (HRI/HCI), computer vision, categorization and clustering, virtual agents and miscellaneous, which included projects not related to any major group but not numerous enough to be separated into a group of their own. Such grouping of projects emphasizes the application aspect of each project, although the goal of the researchers may have been different.</p>
<p>Note that some applications are associated with more than one category. For example, Soar has been used to play board games with a robotic arm [241], which is relevant to both robotics and games and puzzles. Similarly, the ACT-R model of Tower of Hanoi evaluated against the human fMRI data [13] belongs to games and puzzles and to psychological experiments.</p>
<p>Psychological Experiments</p>
<p>The psychological experiments category is the largest, comprising of more than 1/3rd of all applications. These include replications of numerous psychophysiological, fMRI and EEG experiments in order to demonstrate that cognitive architectures can adequately model human data or give reasonable explanations for existing psychological phenomena. If the data produced by the simulation matches the human data in some or most aspects, it is taken as an indication that a given cognitive architecture can to some extent imitate human cognitive processes.</p>
<p>Most of the experiments in our list investigate psychological phenomena related to memory, perception, attention and decision making. However, there is very little repetition among the specific studies that were replicated by the cognitive architectures. Notably, a Tower of Hanoi (and its derivative, Tower of London) is the only task reproduced by a handful of architectures (although not on the same human data). The task itself requires to move a stack of disks from one rod to another and is frequently used in psychology to study problem solving and skill learning. Similarly, in various cognitive architectures ToH/ToL tasks are used to evaluate the strategy acquisition (Soar [381], Teton [476], CAPS [223], CLARION [441], ICARUS [271], ACT-R [15]).</p>
<p>Given the importance of memory for even the most basic tasks, many phenomena related to different types of memory were also examined. To name a few, the following experiments were conducted: test of the effect of working memory capacity on the syntax parsing (CAPS [222]), N-back task testing spatial working memory (ACT-R [249]), reproduction of the Morris water maze test on a mobile robot to study the formation of episodic and spatial memory (BBD [252]), effect of priming on the speed of memory retrieval (CHREST [267]), effect of anxiety on recall (DUAL [141]), etc.</p>
<p>Attention has been explored both relative to perception and for general resource allocation. For example, models have been built to explain the well-known phenomena of inattentional blindness (ARCADIA [70]) and attentional blink (LIDA [286]). In addition, various dual task experiments were replicated to study and model the sources of attention limitation which reduces human ability to perform multiple tasks simultaneously. For example, CAPS proposes a functional account of attention allocation based on a dual-task experiment involving simultaneous sentence comprehension and mental rotation citeJust2001, ACT-R models effects of sleep loss on sustained attention performance, which requires tracking a known location on the monitor and a reaction task [180]. Similar experiments have been repeated using EPIC ( [237], [234]).</p>
<p>Multiple experiments relating perception, attention, memory and learning have been simulated using the CHREST architecture in the context of playing chess. These include investigations of gaze patterns of novice and expert players [266], effects of ageing on chess playing related to the reduced capacity of the working memory and decreased perceptual abilities [425] and effects of expertise, presentation time and working memory capacity on the ability to memorize random chess positions [164].</p>
<p>Robotics</p>
<p>Nearly a quarter of all applications of cognitive architectures are related to robotics. Much effort has been spent on navigation and obstacle avoidance, which are useful on their own and are necessary for more complex behaviors. In particular, navigation in unstructured environments was implemented on an autonomous vehicle (RCS [97] ATLANTIS [159]), mobile robot (Subsumption [73], CoSy [345]) and unmanned marine vehicle (CARACaS [212]).</p>
<p>The fetch and carry tasks used to be very popular in the early days of robotics research as an effective demonstration of robot abilities. Some well-known examples include a trash collecting mobile robot (3T [143]) and a soda can collecting robot (Subsumption [75]). Through a combination of simple vision techniques, such as edge detection and template matching, and sensors for navigation, these robots were able to find the objects of interest in unknown environments.</p>
<p>More recent cognitive architectures solve search and object manipulation tasks separately. Typically, experiments involving visual search are done in very controlled environments and preference is given to objects with bright colors or recognizable shapes to minimize visual processing, for example, a red ball (SASE [507]) or a soda can (ISAC [226]). Sometimes markers, such as printed barcodes attached to the object, are used to simplify recognition (Soar [311]). It is important to note that visual search in these cases is usually a part of a more involved task, such as learning by instruction. When visual search and localization is the end goal, the environments are more realistic (e.g. the robot controlled by CoSy finds a book on a cluttered shelf using a combination of sensors and SIFT features [283]).</p>
<p>Object manipulation involves arm control to reach and grasp an object. While reaching is a relatively easy problem and many architectures implement some form of arm control, gripping is more challenging even in a simulated environment. The complexity of grasping depends on many factors including the type of gripper and the properties of the object. One workaround is to experiment with grasping on soft objects, such as plush toys (ISAC [228]). More recent work involves objects with different grasping types (objects with handles located on the top or on a side) demonstrated on a robot controlled by DIARC citeWilson2016. Another example is iCub adapting its grasp to cans of different sizes, boxes and a ruler [395].</p>
<p>A few architectures implement multiple skills for complex scenarios such as a robotic salesman (CORTEX [376], RoboCog [375]), tutoring (DAC [490]), medical assessment (LIDA [287], RoboCog [37]), etc. Industrial applications are represented by a single architecture -RCS, which has been used for teleoperated robotic crane operation [284], bridge construction [56], autonomous cleaning and deburring workstation [323], and the automated stamp distribution center for the US Postal Service [7].</p>
<p>The biologically motivated architectures focus on the developmental aspect of physical skills and sensorimotor reconstruction. For example, a childlike iCub robot platform explores acquisition of skills for locomotion, grasping and manipulation [4], robots Dav and SAIL learn vision-guided navigation (SASE [507]) and ISAC learns grasping affordances [473].</p>
<p>Human Performance Modeling (HPM)</p>
<p>Human performance modeling is an area of research concerned with building quantitative models of human performance in a specific task environment. The need for such models comes from engineering domains where the space of design possibilities is too large so that empirical assessment is infeasible or too costly.</p>
<p>This type of modeling has been used extensively for military applications, for example, workload analysis of Apache helicopter crew [10], modeling the impact of communication tasks on the battlefield awareness [315], decision making in the AAW domain [524], etc. Common civil applications include models of air traffic control task citeSeamster1993), aircraft taxi errors [511], 911 dispatch operator [183], etc.</p>
<p>Overall, HPM is dominated by a handful of specialized architectures, including OMAR, APEX, COGNET, MIDAS and IMPRINT. In addition, Soar was used to implement a pilot model for large-scale distributed military simulations (TacAir-Soar [257], [220]).</p>
<p>Human-Robot and Human/Computer Interaction (HRI/HCI)</p>
<p>HRI is a multidisciplinary field studying various aspects of communication between people and robots. Many of these interactions are being studied in the context of social, assistive or developmental robotics. Depending on the level of autonomy demonstrated by the robot, interactions extend from direct control (teleoperation) to full autonomy of the robot enabling peer-to-peer collaboration. Although none of the systems presented in this survey are yet capable of full autonomy, they allow for some level of supervisory control ranging from single vowels signifying direction of movement for a robot (SASE [505]) to natural language instruction (Soar [263], HOMER [484], iCub [459]). It is usually assumed that a command is of particular form and uses a limited vocabulary.</p>
<p>Some architectures also target non-verbal aspects of HRI, for example, natural turn-taking in a dialogue (Ymir [457], Kismet [59]), changing facial expression (Kismet [61]) or turning towards the caregiver (MACsi [18]).</p>
<p>An important practical application which also involves HCI is in building decision support systems, i.e. intelligent assistants which can learn from and cooperate with experts to solve problems in complex domains. One such domain is intelligence analysis, which requires mining large amounts of textual information, proposing a hypothesis in search of evidence and reevaluating hypotheses in view of new evidence (Disciple [446]). Other examples include time-and resource-constrained domains such as emergency response planning (Disciple [445], NARS [422]), medical diagnosis (OSCAR [359]), military operations in urban areas (R-CAST [138]) and air traffic control (OMAR [109]).</p>
<p>Natural Language Processing (NLP)</p>
<p>Natural language processing (NLP) is a broad multi-disciplinary area which studies understanding of written or spoken language. In the context of cognitive architectures, many aspects of NLP have been considered, from low-level auditory perception, syntactic parsing and semantics to conversation in limited domains.</p>
<p>As have been noted in the section on perception, there are only a few models of low-level auditory perception. For instance, models based on Adaptive Resonance Theory (ART), namely ARTPHONE [176], ARTSTREAM [175], ARTWORD [179] and others, have been used to model perceptual processes involved in speech categorization, auditory streaming, source segregation (also known as the "cocktail party problem") and phonemic integration.</p>
<p>Otherwise, most research in NLP is related to investigating aspects of the syntactic and semantic processing of textual data. Some examples include anaphora resolution (Polyscheme [256], NARS [239], DIARC [512]), learning English passive voice (NARS [239]), models of syntactic and semantic parsing (SPA [429], CAPS [222]) and word sense disambiguation (SemSoar and WordNet [221]).</p>
<p>One of the early models for real-time natural language processing, NL-Soar, combined syntactic knowledge and semantics of simple instructions for the immediate reasoning and tasks in blocks world [277]. A more recent model (currently used in Soar) is capable of understanding commands, questions, syntax and semantics in English and Spanish [279]. A complete model of human reading which simulated gaze patterns, sequential and chronometric characteristics of human readers, semantic and syntactic analysis of sentences, recall and forgetting was built using CAPS architecture [452].</p>
<p>More commonly, off-the-shelf software is used for speech recognition and parsing, which helps to achieve a high degree of complexity and realism. For instance, a salesman robot (CORTEX [78]) can understand and answer questions about itself using a Microsoft Kinect Speech SDK. The Playmate system based on CoSy uses dedicated software for speech processing [280] and can have a meaningful conversation in a subset of English about colors and shapes of objects on the table. The FORR architecture uses speech recognition for the task of ordering books from the public library by phone. The architecture, in this case, increases the robustness of the automated speech recognition system based on an Olympus/RavenClaw pipeline (CMU) [128].</p>
<p>In general, most existing NLP systems are limited both in their domain of application and in terms of the syntactic structures they can understand. Recent architectures, such as DIARC, aim at supporting more naturally sounding requests like Can you bring me something to cut a tomato?, however, they are still in the early stages of development [394].</p>
<p>Categorization and clustering</p>
<p>Categorization, classification, pattern recognition and clustering are common ways of extracting general information from large datasets. In the context of cognitive architectures, these methods are useful for processing noisy sensory data. Applications in this group are almost entirely implemented by the emergent architectures, such as ART and HTM, which are used as sophisticated neural networks. The ART networks, in particular, have been applied to classification problems in a wide range of domains: movie recommendations (Netflix dataset [84]), medical diagnosis (Pima-Indian diabetes dataset [229]), fault diagnostics (pneumatic system analysis [105]), vowel recognition (Peterson and Barney dataset [11]), odor identification [114], etc. The HTM architecture is geared more towards the analysis of time series data, such as predicting IT failures 10 , monitoring stocks 11 , predicting taxi passenger demand [104] and recognition of cell phone usage type (email, call, etc.) based on the pressed key pattern [306].</p>
<p>A few other examples from the non-emergent architectures include gesture recognition from tracking suits (Ymir [89]), diagnosis of the failures in a telecommunications network (PRS [365]) and document categorization based on the information about authors and citations (CogPrime [182]).</p>
<p>Computer vision</p>
<p>The emergent cognitive architectures are also widely applied to solving typical computer vision problems. However, these are mainly standalone examples, such as hand-written character recognition (HTM [458], [433]), image classification benchmarks (HTM [528], [290]), view-invariant letter recognition (ART [139]), texture classification benchmarks (ART [494]), invariant object recognition (Leabra [341]), etc.</p>
<p>The computer vision applications that are part of more involved tasks, such as navigation in robotics, are discussed in the relevant sections.</p>
<p>Games and puzzles</p>
<p>Playing games remained an active area of research in cognitive architectures for decades. Some of the earliest models for playing tic-tac-toe and Eight Puzzle as a demo of reasoning and learning abilities were created in the 1980s (Soar [260]). The goal is typically not to mastering the game but rather to use it as a step towards solving similar but more complex problems. For example, Liar's Dice, a multi-player game of chance, is used to assess the feasibility of reinforcement learning in large domains (Soar [106]). Similarly, playing Backgammon was used to model cognitively plausible learning in (ACT-R [391]) and tic-tac-toe to demonstrate ability to learn from instruction (Companions [198]). Multiple two-player board games with conceptual overlap like tic-tac-toe, the Eight Puzzle and the Five Puzzle can also be used as an effective demonstration of knowledge transfer (e.g. Soar [241], FORR [126]).</p>
<p>Compared to the classic board games used in AI research since its inception, video games provide a much more varied and challenging domain. Like board games, most video games require certain cognitive skills from a player, thus allowing the researchers to break down the problem of solving general intelligence into smaller chunks and work on them separately. However, the graphics, complexity and response times of the recent video games are getting better and better, hence many games can already be used as sensible approximations of the real world environments. In addition to that, the simulated intelligent entity is much cheaper to develop and less prone to damage than the one embodied in a physical robot. A combination of these factors makes video games a very valuable tool for modeling human cognition.</p>
<p>The only drawback of using video games for research is that embedding a cognitive architecture within it requires software engineering work. Naturally, games with open source engines and readily available middleware are preferred. One such example is the Unreal Tournament 2004 (UT2004) game, for which the Pogamut architecture [224] serves as a middleware, making it easier to create intelligent virtual characters. Although Pogamut itself implements many cognitive functions, it is also used with modifications by other groups to implement artificial entities for UT2004 ( [320], [424], [103], [493], [475]). Other video games used in cognitive architectures research are Freeciv (REM [472]), Atari Frogger II (Soar [515]), Infinite Mario (Soar [420]), browser games (STAR [248]) and custom made games (Soar [293]). It should be noted that aside from the playing efficiency and achieved scores the intelligent agents are also evaluated based on their believability (e.g. 2K BotPrize Contest 12 ).</p>
<p>Virtual agents</p>
<p>Although related to human performance modeling, the category of virtual agents is broader. While HPM requires models which can closely model human behavior in precisely defined conditions, the goals of creating virtual agents are more varied. Simulations and virtual reality are frequently used as an alternative to the physical embodiment. For instance, in the military domain, simulations model behavior of soldiers in dangerous situations without risking their lives. Some examples include modeling agents in a suicide bomber scenario (CoJACK [130]), peacekeeping mission training (MAMID [204]), command and control in complex and urban terrain (R-CAST [136]) and tank battle simulation (CoJACK [369]).</p>
<p>Simulations are also common for modeling behaviors of intelligent agents in the civil applications. One of the advantages of virtual environments is that they can provide information about the state of the agent at any point in time. This is useful for studying the effect of emotions on actions, for example, in the social interaction context (ARS/SiMA [397]), or in learning scenarios, such as playing fetch with a virtual dog (Novamente [191]).</p>
<p>Intelligent characters with engaging personalities can also enhance user experience and increase their level of engagement in video games and virtual reality applications. One of the examples is virtual reality drama "Human Trials" which lets human actors to participate in an immersive performance together with multiple synthetic characters controlled by the GLAIR architecture ( [415], [17]). A similar project called Virtual Theater allowed users to interact with virtual characters on the screen to improvise new stories in real time. The story unfolds as users periodically select among directional options appearing on the screen (AIS [187]).</p>
<p>Discussion</p>
<p>The main contribution of this survey is in gathering and summarizing information on a large number of cognitive architectures from various backgrounds (computer science, cognitive psychology, philosophy and neuroscience). In particular, we discussed common approaches to modeling important elements of human cognition, such as perception, attention, action selection, learning, memory and reasoning. In our analysis, we also point out what approaches are more successful in modeling human cognitive processes or exhibiting useful behavior. In order to evaluate practical aspects of cognitive architectures we categorize their existing practical applications into several broad categories. Furthermore, we map these practical applications to a number of competency areas required for human-level intelligence to assess the current progress in that direction. This map may also serve as an approximate indication of what major areas of human cognition have received more attention than others. Thus, there are two main outcomes of this review. First, we present a broad and inclusive snapshot of the progress made in the cognitive architectures research in the past four decades. Second, by documenting the wide variety of tested mechanisms that may help in developing explanations and models for observed human behavior, we inform future research in cognitive science and in the component disciplines that feed it.</p>
<p>Historically, psychology and computer science were an inspiration for the first cognitive and agent architectures. Despite the differences in theory and terminology they tackled the same issues of action selection, adaptive behavior, efficient data processing and storage. For example, methods for action selection widely used in robotics and classic AI, ranging from priority queue to reinforcement learning [355], are also found in many cognitive architectures. More biologically plausible models were developed in parallel but became widely recognized as a viable alternative only relatively recently. It has been argued that their support for inference and general reasoning is inadequate for modeling all aspects of human cognition, although some of the latest neuronal models demonstrate that it is far from being proven. Overall, hybrid models combining both symbolic and sub-symbolic approaches show the most promise and will likely continue to be popular in the future. Another rising paradigm is represented by machine learning methods, such as deep learning, which have found enormous practical success in limited domains. Currently, they are mainly concerned with perception although there have been attempts at implementing more general inference and memory mechanisms with deep learning techniques.</p>
<p>Although we covered a wide range of cognitive abilities and phenomena represented in the cognitive architectures, our list is by no means exhaustive. But none of the systems we reviewed is close to covering all of identified human cognitive abilities (a comprehensive survey by Carroll [88] lists nearly 3000 of them). Much effort has been dedicated to studying higher level abilities such as reasoning, learning and action selection. Decades of work in these areas, both in traditional AI research and cognitive architectures, led to creation of multiple algorithms and data structures. Furthermore, various combinations of these approaches have been theoretically and practically validated in different architectures. As our analysis shows, the treatment of perception, and vision in particular, is rather superficial in comparison, both in terms of modeling perceptual processes and demonstrated abilities. Almost half of the architectures we reviewed do not implement any vision and the remaining systems vary greatly in quality of visual perception. In a sense, there is a tradeoff between biological realism and the actual abilities of the system. While many robotic architectures are capable of analyzing realistic scenes, they approach this problem from engineering perspective. On the other hand, biologically plausible visual systems are for the most part limited to recognizing simple shapes and colors.</p>
<p>As we mentioned in the introduction, only a handful of architectures have a goal of achieving AGI. Our data on practical applications also confirms this by showing that many architectures are narrowly focused on one or two particular areas. However, even for architectures with broader range of applications, it is likely that it is not the same model capable of performing all these tasks, but rather multiple models built with the same theoretical and/or software base. Examples of being able to switch between various tasks are sparse and are usually explicitly declared as such, like in the case of SPA architecture capable of performing eight unrelated tasks [122]. In this survey, visualizations of cognitive abilities and various mechanisms involved demonstrate aggregated statistics and do not imply that there exists a single model that encapsulates them all.</p>
<p>Another serious obstacle on the way to achieving human-level intelligence is an issue of scale. As we discussed in section 7, maintaining a knowledge base, comparable in size to what an average adult may have, is far from trivial. It has been shown that simple scaling up of existing algorithms introduces additional challenges, such as the need for more efficient data processing and storage. These problems are addressed only by a handful of architectures, even though solving them is crucial for further development of theoretical and applied AI.</p>
<p>Related to the problem of scale is range of abilities and realism of the scenarios. With respect to these criteria, there is a significant gap between the general research in robotics and computer vision and research in these areas within the cognitive architectures domain. It is especially apparent that biologically inspired models cannot demonstrate the same range and efficiency in practical applications compared to the less theoretically restricted systems based on heuristics and engineering. Biological systems are mostly limited to controlled domains and many of their demonstrated results are proof-of-concept. Some exceptions exist, for example Grok -a commercial application for IT analytics based on the biologically inspired HTM architecture or the Neural Information Retrieval System implemented as a hierarchy of ART networks for storing 2D and 3D parts designs built for Boeing company [426].</p>
<p>We also found that within publications in the area, more importance is given to the cognitive, psychological or philosophical aspects, while the actual implementation details are often incomplete or missing. We believe that in an applied field such as cognitive architectures, the engineering side is as important as the theoretical. Besides, given that only 1/3 of the architectures makes their code available, reproducibility of much of the research is uncertain. To a lesser extent this applies to architectures such as BBD, SASE, Kismet, Ymir, Subsumption and a few others that are physically embodied and highly depend on a particular robotic platform. However, the majority of architectures we reviewed have a substantial software component, releasing which could be of benefit to the community. Furthermore, open-source development offers numerous advantages. For instance, cognitive architectures, such as ART, ACT-R, Soar, HTM and Pogamut, attract a large community of researchers and are frequently cited in the publications outside the main developing group.</p>
<p>In conclusion, our hope is that this work will serve as an overview and a guide to the vast field of cognitive architecture research as we strived to objectively and quantitatively assess the state-of-the-art in modeling human cognition. Since we visualized multiple architectures side-by-side, it is natural to compare them, however any conclusions should be taken with caveats. For instance, existence of multiple practical applications is not necessarily a proof of the suitability of a particular architecture for modeling human intelligence. Since most of the architectures are based on certain theories of intelligence and often cite multiple works in psychology and neuroscience to validate their claims and performance, more sophisticated tools for assessing them are clearly needed.</p>
<p>Fig. 1
1A diagram showing cognitive architectures found in literature surveys and source highlighted with blue and orange colors respectively. The sorting order in the diagram is determined by the total number of references in the surveys and on-line sources for each architecture. Titles of the architectures covered in this survey are shown in red. All visualizations in this paper are made using D3.js library (https://d3js.org) and interactive versions of the figures are available on the project website. The color palettes are generated using ColorBrewer (http://colorbrewer2.org).</p>
<p>Fig. 2
2A timeline of 85 cognitive architectures featured in this survey. Each line corresponds to a single architecture. The architectures are sorted by the starting date, so that the earliest architectures are plotted at the bottom of the figure.</p>
<p>Fig. 4
4A diagram showing sensory modalities of cognitive architectures. Radial segments correspond to cognitive architectures and each track corresponds to a modality. Modalities are ordered based on their importance (calculated as a number of architectures that implement this modality): vision (V), symbolic input (D), proprioception (P), other sensors (O), audition (A), touch (T) and smell (S). Modalities plotted closer to the center of the diagram are more common. The following coloring convention was used for the individual segments: white (the modality not implemented), yellow (the modality is simulated), orange (sensory modality demonstrated both in real and simulated domains) and red (physical sensors used). Architectures are ordered based on how many different sensory modalities they implement and to what extent.</p>
<p>Fig. 5
5A diagram showing the stages of real and simulated visual processing implemented by the cognitive architectures.</p>
<p>Fig. 6
6A diagram showing visual attention mechanisms implemented in cognitive architectures for suppressing, selecting and restricting visual information. Architectures are ordered alphabetically. As in section 4.1, architectures in the left and right columns implement real and simulated vision respectively. Architectures not implementing vision or missing technical details are not shown. Suppression, selection and restriction mechanisms in the diagram are shown in shades of blue, yellow-red and green respectively.</p>
<p>Fig. 7
7A diagram of mechanisms involved in action selection for architectures. The visualization is organized in three columns grouping the symbolic, hybrid and emergent architectures. Learning is included for illustrative purposes and is discussed in the next section. Note that in this diagram (as well as in the diagrams for the sections 7 and 8) the sorting order emphasizes clusters of architectures with similar action selection mechanisms (or memory and learning approaches respectively). Since the discussion follows the order in which different mechanisms are shown in the diagram, it can help to identify groups of architectures focusing on a particular mechanism which correspond to clusters within each column. A version of the diagram with an alphabetical ordering of the architectures is also available on the project website.</p>
<p>Fig. 8
8A diagram showing types of memory implemented in the cognitive architectures. The symbolic, hybrid and emergent architectures are shown in separate columns. The architectures where memory system is unified, i.e. no distinction is made between short-, long-term and other types of memory, are labeled as "global". A version of the diagram with an alphabetical ordering of the architectures is also available on the project website.</p>
<p>Fig. 9
9A diagram summarizing types of learning implemented in the cognitive architectures. Symbolic, hybrid and emergent architectures are grouped and presented in different columns. The architectures are arranged according to the similarity between the implemented learning types. A version of the diagram with an alphabetical ordering of the architectures is also available on the project website.</p>
<p>.10 A diagram showing practical applications of the cognitive architectures and corresponding competency areas defined in[1]. The plot is split into two columns for better readability. Within each column the table shows the implemented competency areas (indicated by gray colored cells). The stacked bar plots show the practical applications: the length of the bar represents the total number of the practical applications found in the publications and colored segments within each bar represent different categories (see legend) and their relative importance (calculated as a proportion of the total number of applications implementing these categories). The architectures are sorted by the total number of their practical applications. For a complete list of all projects with short descriptions and citations refer to the interactive version of this diagram on the project website.</p>
<p>).HYBRID </p>
<p>symbolic 
sub-processing </p>
<p>3T 
ARDIS 
ATLANTIS 
CARACaS 
CoSy 
DIARC 
Pogamut 
RCS 
RoboCog 
STAR </p>
<p>fully integrated </p>
<p>ACT-R 
ADAPT 
ARCADIA 
ARS/SiMA 
ASMO 
CAPS 
CELTS 
CERA-CRANIUM 
CHARISMA 
CHREST 
CLARION 
CORTEX 
CSE 
Casimir 
CoJACK 
CogPrime 
Copycat/Metacat 
DSO 
DUAL 
DiPRA 
FORR 
GMU-BICA 
ISAC 
Kismet 
LIDA 
MACSi 
MIDCA 
MLECOG 
NARS 
Novamente 
PolyScheme 
RALPH 
REM 
SAL 
Sigma 
Soar 
Xapagy 
Ymir 
iCub </p>
<p>SYMBOLIC </p>
<p>AIS 
APEX 
COGNET 
Companions 
Disciple 
EPIC 
ERE 
GLAIR 
Homer 
ICARUS 
IMPRINT 
MAMID 
MAX 
MIDAS 
MusiCog 
OMAR 
OSCAR 
PRODIGY 
PRS 
R-CAST 
Teton 
Theo </p>
<p>EMERGENT </p>
<p>neuronal 
modeling </p>
<p>ART 
BBD 
DAC 
Darwinian </p>
<p>Neurodynamics </p>
<p>HTM 
Leabra 
Recommendation </p>
<p>connectionist 
logic systems </p>
<p>BECCA 
MDB 
SASE 
Shruti 
Subsumption 
SPA 
MicroPsi </p>
<p>). The decay rate for items in sensory memory is believed to be tens of milliseconds (EPIC[236],ICARUS 
EPIC 
MusiCog 
APEX 
GLAIR 
Homer 
MAMID 
OMAR 
PRODIGY 
R-CAST 
AIS 
COGNET 
Disciple 
ERE 
MAX 
MIDAS 
OSCAR 
PRS 
Teton 
Theo 
Companions 
IMPRINT </p>
<p>s e n s o r y 
W 
M s e m 
a n t i c 
p r o c e d u r a l 
e p i s o d i c 
g l o b a l </p>
<p>a) symbolic </p>
<p>ACT-R 
CHARISMA 
LIDA 
Sigma 
Soar 
Pogamut 
ARCADIA 
ASMO 
CogPrime 
NARS 
CELTS 
CLARION 
Copycat/Metacat 
DUAL 
GMU-BICA 
ISAC 
MIDCA 
MLECOG 
Novamente 
REM 
Ymir 
CORTEX 
DiPRA 
RALPH 
RoboCog 
3T 
ADAPT 
ARS/SiMA 
ATLANTIS 
CAPS 
CERA-CRANIUM 
CHREST 
CoJACK 
CoSy 
DIARC 
DSO 
FORR 
MACSi 
PolyScheme 
RCS 
SAL 
Xapagy 
Casimir 
iCub 
CARACaS 
CSE 
Kismet 
STAR 
ARDIS </p>
<p>). For instance, in a navigation task, aDisciple 
MusiCog 
GLAIR 
AIS 
Companions 
ERE 
ICARUS 
MAX 
PRODIGY 
R-CAST 
Teton 
Theo 
APEX 
COGNET 
EPIC 
Homer 
IMPRINT 
MAMID 
MIDAS 
OMAR 
OSCAR 
PRS </p>
<p>http://bicasociety.org/cogarch/architectures.htm 2 Since the exact dates for the start (and end) of the development are not specified for the majority of architectures, we use instead the first and the latest publication. If an architecture has an associated website or an online repository, we consider the project currently active, given that there was any activity (site update/code commit) within the last year. Similarly, we consider the project under the active development if there was at least one publication within the last year (2016).
http://jtl.lassonde.yorku.ca/project/cognitive_architectures_survey/
https://deepmind.com/ 5 https://research.facebook.com/ai/
The taste modality is omitted as it is only featured in a single architecture, Brain-Based Devices (BBD), where it is simulated by measuring the conductivity of the object[253].
The last stage forming consistent internal descriptions -from[466] is omitted. In cognitive architectures, such representations would be distributed among various reasoning and memory modules, making proper evaluation infeasible.
Note that biologically plausible models of vision, such as Selective Tuning[469], extensions to HMAX ([491],[492],[367]) and others[157], support many of the listed attention mechanisms. However, embedding these models in the cognitive architecture is non-trivial. For instance, STAR represents ongoing work on integrating general purpose vision, as represented by the Selective Tuning model, with other higher-order cognitive processes.9 In GWT focus of attention is associated with consciousness, however, this topic is beyond the scope of this survey.
grokstream.com 11 numenta.com/htm-for-stocks
http://botprize.org</p>
<p>Mapping the Landscape of Human-Level Artificial General Intelligence. Sam Adams, Itmar Arel, Joscha Bach, Robert Coop, Rod Furlan, Ben Goertzel, J Hall, Alexei Samsonovich, Matthias Scheutz, Matthew Schlesinger, Stuart C Shapiro, John Sowa, AI Mag. 331Sam Adams, Itmar Arel, Joscha Bach, Robert Coop, Rod Furlan, Ben Goertzel, J. Storrs Hall, Alexei Samsonovich, Matthias Scheutz, Matthew Schlesinger, Stuart C. Shapiro, and John Sowa. Mapping the Landscape of Human-Level Artificial General Intelligence. AI Mag., 33(1):25-42, 2012.</p>
<p>Intelligent control and tactical behavior development: A long term NIST partnership with the army. J Albus, A Barbera, In 1st Jt. Emerg. Prep. Response/Robotic Remote Syst. Top. Meet. J. Albus and A. Barbera. Intelligent control and tactical behavior development: A long term NIST partnership with the army. In 1st Jt. Emerg. Prep. Response/Robotic Remote Syst. Top. Meet., 2006.</p>
<p>Theory and Experimental Analysis of Cognitive Processes in Early Learning. J Albus, A Lacaze, A Meystel, Proc. IEEE Int. Conf. Syst. Man Cybern. IEEE Int. Conf. Syst. Man CybernJ. Albus, A. Lacaze, and A. Meystel. Theory and Experimental Analysis of Cognitive Processes in Early Learning. In Proc. IEEE Int. Conf. Syst. Man Cybern., pages 4404-4409, 1995.</p>
<p>A Reference Model Architecture for Intelligent Systems Design. J S Albus, An Introd. to Intell. Auton. Control. J. S. Albus. A Reference Model Architecture for Intelligent Systems Design. An Introd. to Intell. Auton. Control, pages 27-56, 1994.</p>
<p>4D/RCS A Reference Model Architecture for Intelligent Unmanned Ground Vehicles. J S Albus, Proc. SPIE 16th Annu. Int. Symp. Aerospace/Defense Sensing. SPIE 16th Annu. Int. Symp. Aerospace/Defense SensingJ. S. Albus. 4D/RCS A Reference Model Architecture for Intelligent Unmanned Ground Vehicles. In Proc. SPIE 16th Annu. Int. Symp. Aerospace/Defense Sensing, Simul. Control., 2002.</p>
<p>THE LAGR PROJECT Integrating learning into the 4D/RCS Control Hierarchy. James Albus, Roger Bostelman, Tsai Hong, Tommy Chang, Will Shackleford, Michael Shneier, In Int. Conf. Control. Autom. Robot. James Albus, Roger Bostelman, Tsai Hong, Tommy Chang, Will Shackleford, and Michael Shneier. THE LAGR PROJECT Integrating learning into the 4D/RCS Control Hierarchy. In Int. Conf. Control. Autom. Robot., 2006.</p>
<p>The NIST Real-time Control System (RCS): an approach to intelligent systems research. James S Albus, J. Exp. Theor. Artif. Intell. 92-3James S. Albus. The NIST Real-time Control System (RCS): an approach to intelligent systems research. J. Exp. Theor. Artif. Intell., 9(2-3):157-174, 1997.</p>
<p>RCS: A cognitive architecture for intelligent multi-agent systems. James S Albus, Anthony J Barbera, Annu. Rev. Control. 291James S. Albus and Anthony J. Barbera. RCS: A cognitive architecture for intelligent multi-agent systems. Annu. Rev. Control, 29(1):87-99, 2005.</p>
<p>4D/RCS: A Reference Model Architecture For Unmanned Vehicle Systems Version 2.0. James S Albus, Hui-Min Huang, Elena R Messina, Karl Murphy, Maris Juberts, Alberto Lacaze, Stephen B Balakirsky, Michael O Shneier, Hong Tsai, Harry A Hong, Frederick M Scott, William P Proctor, John L Shackleford, Albert J Michaloski, Thomas R Wavering, Nicholas G Kramer, William G Dagalakis, Rippey, Proc. SPIE 16th Annu. SPIE 16th AnnuSteven LegowikJames S. Albus, Hui-Min Huang, Elena R. Messina, Karl Murphy, Maris Juberts, Alberto Lacaze, Stephen B. Balakirsky, Michael O. Shneier, Tsai Hong Hong, Harry a. Scott, Frederick M. Proctor, William P. Shackleford, John L. Michaloski, Albert J. Wavering, Thomas R. Kramer, Nicholas G. Dagalakis, William G. Rippey, Keith a. Stouffer, and Steven Legowik. 4D/RCS: A Reference Model Architecture For Unmanned Vehicle Systems Version 2.0. In Proc. SPIE 16th Annu. Int. Symp. AerospaceDefense Sens. Simul. Control., 2002.</p>
<p>Modeling Human Performance: Impacting System Design, Performance, and Cost. Laurel Allender, Proc. Mil. Gov. Aerosp. Simul. Symp. Mil. Gov. Aerosp. Simul. SympLaurel Allender. Modeling Human Performance: Impacting System Design, Performance, and Cost. In Proc. Mil. Gov. Aerosp. Simul. Symp., pages 139-144, 2000.</p>
<p>Speaker normalization using cortical strip maps: a neural model for steady-state vowel categorization. Heather Ames, Stephen Grossberg, J. Acoust. Soc. Am. 124Heather Ames and Stephen Grossberg. Speaker normalization using cortical strip maps: a neural model for steady-state vowel categorization. J. Acoust. Soc. Am., 124:3918-3936, 2008.</p>
<p>Working memory: activation limitations on retrieval. J R Anderson, L M Reder, C Lebiere, Cogn. Psychol. 30J. R. Anderson, L. M. Reder, and C. Lebiere. Working memory: activation limitations on retrieval. Cogn. Psychol., 30:221-256, 1996.</p>
<p>Tracing problem solving in real time: fMRI analysis of the subject-paced Tower of Hanoi. John R Anderson, Mark V Albert, Jon M Fincham, J. Cogn. Neurosci. 178John R. Anderson, Mark V. Albert, and Jon M. Fincham. Tracing problem solving in real time: fMRI analysis of the subject-paced Tower of Hanoi. J. Cogn. Neurosci., 17(8):1261-1274, 2005.</p>
<p>An Integrated Theory of the Mind. John R Anderson, Daniel Bothell, Michael D Byrne, Scott Douglass, Christian Lebiere, Yulin Qin, Psychol. Rev. 1114John R. Anderson, Daniel Bothell, Michael D. Byrne, Scott Douglass, Christian Lebiere, and Yulin Qin. An Integrated Theory of the Mind. Psychol. Rev., 111(4):1036-1060, 2004.</p>
<p>Tower of Hanoi: Evidence for the cost of goal retrieval. John R Anderson, Scott Douglass, J. Exp. Psychol. Learn. Mem. Cogn. 276John R. Anderson and Scott Douglass. Tower of Hanoi: Evidence for the cost of goal retrieval. J. Exp. Psychol. Learn. Mem. Cogn., 27(6):1331-1346, 2001.</p>
<p>The Newell Test for a theory of cognition. R John, Christian Anderson, Lebiere, Behav. Brain Sci. 265John R Anderson and Christian Lebiere. The Newell Test for a theory of cognition. Behav. Brain Sci., 26(5):587-601, 2003.</p>
<p>Human trials: An Experiment in Intermedia Performance. Josephine Anstey, Sarah Bay-Cheng, Dave Pape, Stuart C Shapiro, ACM Comput. Entertain. 53Josephine Anstey, Sarah Bay-Cheng, Dave Pape, and Stuart C. Shapiro. Human trials: An Experiment in Intermedia Performance. ACM Comput. Entertain., 5(3), 2007.</p>
<p>Multimodal people engagement with iCub. Salvatore M Anzalone, Serena Ivaldi, Olivier Sigaud, Mohamed Chetouani, Biol. inspired Cogn. Archit. Salvatore M. Anzalone, Serena Ivaldi, Olivier Sigaud, and Mohamed Chetouani. Multimodal people engagement with iCub. Biol. inspired Cogn. Archit., pages 59-64, 2012.</p>
<p>A cognitive approach to multimodal attention. Raúl Arrabales, Agapito Ledezma, Araceli Sanchis, J. Phys. Agents. 31Raúl Arrabales, Agapito Ledezma, and Araceli Sanchis. A cognitive approach to multimodal attention. J. Phys. Agents, 3(1):53-63, 2009.</p>
<p>CERA-CRANIUM: A Test Bed for Machine Consciousness Research. Raul Arrabales, Agapito Ledezma, Araceli Sanchis, In Int. Work. Mach. Conscious. Raul Arrabales, Agapito Ledezma, and Araceli Sanchis. CERA-CRANIUM: A Test Bed for Machine Consciousness Research. In Int. Work. Mach. Conscious., 2009.</p>
<p>Simulating Visual Qualia in the CERA-CRANIUM Cognitive Architecture. Raúl Arrabales, Agapito Ledezma, Araceli Sanchis, From Brains to Syst. New YorkSpringerRaúl Arrabales, Agapito Ledezma, and Araceli Sanchis. Simulating Visual Qualia in the CERA-CRANIUM Cognitive Architecture. In From Brains to Syst. Springer New York, 2011.</p>
<p>A Machine Consciousness Approach to the Design of Human-Like Bots. Raúl Arrabales, Jorge Munoz, Agapito Ledezma, German Gutierrez, Araceli Sanchis, Believable Bots Can Comput. Play Like People. Philip HingstonBerlin HeidelbergSpringer-VerlagRaúl Arrabales, Jorge Munoz, Agapito Ledezma, German Gutierrez, and Araceli Sanchis. A Machine Consciousness Approach to the Design of Human-Like Bots. In Philip Hingston, editor, Believable Bots Can Comput. Play Like People? Springer-Verlag Berlin Heidelberg, 2013.</p>
<p>A machine consciousness approach to autonomous mobile robotics. Arrabales Raúl, Araceli Moreno, Miguel Sanchis De, Proc. 5th Int. Cogn. Robot. Work. 5th Int. Cogn. Robot. WorkRaúl Arrabales Moreno and Araceli Sanchis de Miguel. A machine consciousness approach to autonomous mobile robotics. In Proc. 5th Int. Cogn. Robot. Work., 2006.</p>
<p>Modeling Developmental Transitions in Reasoning about False Beliefs of Others. Niels A Burcu Arslan, Rineke Taatgen, Verbrugge, Model. Dev. Transitions Reason. about False Beliefs Others. Burcu Arslan, Niels A. Taatgen, and Rineke Verbrugge. Modeling Developmental Transitions in Reasoning about False Beliefs of Others. In Model. Dev. Transitions Reason. about False Beliefs Others, 2013.</p>
<p>. Amal Asselman, Souhaib Aammou, Az-Eddine Nasseh, Comparative Study of Cognitive Architectures. Int. Res. J. Comput. Sci. 29Amal Asselman, Souhaib Aammou, and Az-Eddine Nasseh. Comparative Study of Cognitive Architectures. Int. Res. J. Comput. Sci., 2(9):8-13, 2015.</p>
<p>Human Memory: A Proposed System and its Control Processes. R C Atkinson, R M Shiffrin, Psychol. Learn. Motiv. -Adv. Res. Theory. 2CR. C. Atkinson and R. M. Shiffrin. Human Memory: A Proposed System and its Control Processes. Psychol. Learn. Motiv. -Adv. Res. Theory, 2(C):89-195, 1968.</p>
<p>Global workspace theory of consciousness: Toward a cognitive neuroscience of human experience. J Bernard, Baars, Prog. Brain Res. 150Bernard J. Baars. Global workspace theory of consciousness: Toward a cognitive neuroscience of human experience. Prog. Brain Res., 150:45-53, 2005.</p>
<p>How deliberate, spontaneous and unwanted memories emerge in a computational model of consciousness. Involuntary Mem. J Bernard, Uma Baars, Stan Ramamurthy, Franklin, Bernard J. Baars, Uma Ramamurthy, and Stan Franklin. How deliberate, spontaneous and unwanted memories emerge in a computational model of consciousness. Involuntary Mem., 2007.</p>
<p>Principles of Synthetic Intelligence. Joscha Bach, PhD ThesisJoscha Bach. Principles of Synthetic Intelligence. PhD Thesis, 2007.</p>
<p>A motivational system for cognitive AI. Joscha Bach, In Int. Conf. Artif. Gen. Intell. Joscha Bach. A motivational system for cognitive AI. In Int. Conf. Artif. Gen. Intell., pages 232-242, 2011.</p>
<p>MicroPsi 2: The next generation of the MicroPsi framework. Joscha Bach, Proc. Int. Conf. Artif. Int. Conf. ArtifJoscha Bach. MicroPsi 2: The next generation of the MicroPsi framework. In Proc. Int. Conf. Artif. Gen. Intell., pages 11-20, 2012.</p>
<p>Modeling Motivation and the Emergence of Affect in a Cognitive Agent. Joscha Bach, In Theor. Found. Artif. Gen. Intell. Atlantis PressJoscha Bach. Modeling Motivation and the Emergence of Affect in a Cognitive Agent. In Theor. Found. Artif. Gen. Intell., pages 241-263. Atlantis Press, 2012.</p>
<p>Modeling motivation in MicroPsi 2. Joscha Bach, In Int. Conf. Artif. Gen. Intell. Joscha Bach. Modeling motivation in MicroPsi 2. In Int. Conf. Artif. Gen. Intell., pages 3-13, 2015.</p>
<p>MicroPsi: Contributions to a broad architecture of cognition. Joscha Bach, Colin Bauer, Ronnie Vuine, Annu. Conf. Artif. Intell. Joscha Bach, Colin Bauer, and Ronnie Vuine. MicroPsi: Contributions to a broad architecture of cognition. In Annu. Conf. Artif. Intell., pages 7-18, 2007.</p>
<p>Attentional Selection for Action in Mobile Robots. Pilar Bachiller, Pablo Bustos, Luis J Manso, Adv. Robot. Autom. Control. Pilar Bachiller, Pablo Bustos, and Luis J. Manso. Attentional Selection for Action in Mobile Robots. In Adv. Robot. Autom. Control, pages 111-136. 2008.</p>
<p>. Alan D Baddeley, Graham Hitch, Working Memory. Psychol. Learn. Motiv. -Adv. Res. Theory. 8CAlan D. Baddeley and Graham Hitch. Working Memory. Psychol. Learn. Motiv. -Adv. Res. Theory, 8(C):47-89, 1974.</p>
<p>CLARC: a Robotic Architecture for Comprehensive Geriatric Assessment. Antonio Bandera, Juan Pedro Bandera, Pablo Bustos, Luis V Calderita, Fernando Fern, Raquel Fuentetaja, Francisco Javier Garc, Ana Iglesias, J Luis, Rebeca Marfil, Carlos Pulido, Christian Reuther, Adrian Romero-Garces, Cristina Suarez, Proc. WAF2016. WAF2016Antonio Bandera, Juan Pedro Bandera, Pablo Bustos, Luis V. Calderita, Fernando Fern, Raquel Fuentetaja, Fran- cisco Javier Garc, Ana Iglesias, J. Luis, Rebeca Marfil, Carlos Pulido, Christian Reuther, Adrian Romero-Garces, and Cristina Suarez. CLARC: a Robotic Architecture for Comprehensive Geriatric Assessment. In Proc. WAF2016, 2016.</p>
<p>Toward the Development of Cognitive Robots. Antonio Bandera, Pablo Bustos, In Int. Work. Brain-Inspired Comput. Antonio Bandera and Pablo Bustos. Toward the Development of Cognitive Robots. In Int. Work. Brain-Inspired Comput., 2013.</p>
<p>Determining Information Technology Project Status using Recognition-primed Decision-making enabled Collaborative Agents for Simulating Teamwork (R-CAST). Anthony Barnes, Robert J Hammell, Proc. Conf. ConfAnthony Barnes and Robert J. Hammell. Determining Information Technology Project Status using Recognition-primed Decision-making enabled Collaborative Agents for Simulating Teamwork (R-CAST). In Proc. Conf. Inf. Syst. Appl. Res., 2008.</p>
<p>Nanoconnectomic Upper Bound on the Variability of Synaptic Plasticity. Thomas M Bartol, Cailey Bromer, Justin P Kinney, Micheal A Chirillo, Jennifer N Bourne, Kristen M Harris, Terrence J Sejnowski, Elife, 4(210778Thomas M. Bartol, Cailey Bromer, Justin P. Kinney, Micheal A. Chirillo, Jennifer N. Bourne, Kristen M. Harris, and Terrence J. Sejnowski. Nanoconnectomic Upper Bound on the Variability of Synaptic Plasticity. Elife, 4(210778), 2015.</p>
<p>Induced Behavior in a Real Agent Using the Multilevel Darwinist Brain. F Bellas, J A Becerra, R J Duro, In Int. Work. Conf. Interp. Nat. Artif. Comput. F. Bellas, J. A. Becerra, and R. J. Duro. Induced Behavior in a Real Agent Using the Multilevel Darwinist Brain. In Int. Work. Conf. Interp. Nat. Artif. Comput., pages 425-434, 2005.</p>
<p>Some experimental results with a two level memory management system in the Multilevel Darwinist Brain. F Bellas, J A Becerra, R J Duro, Proc. Eur. Symp. Artif. Neural Networks. Eur. Symp. Artif. Neural NetworksF. Bellas, J. A. Becerra, and R. J. Duro. Some experimental results with a two level memory management system in the Multilevel Darwinist Brain. In Proc. Eur. Symp. Artif. Neural Networks, Comput. Intell. Mach. Learn., 2006.</p>
<p>Some thoughts on the use of sampled fitness functions for the multilevel Darwinist brain. F Bellas, R J Duro, Inf. Sci. (Ny). 1613-4F. Bellas and R. J. Duro. Some thoughts on the use of sampled fitness functions for the multilevel Darwinist brain. Inf. Sci. (Ny)., 161(3-4):159-179, 2004.</p>
<p>Multilevel Darwinist Brain (MDB): Artificial evolution in a cognitive architecture for real robots. Francisco Bellas, Richard J Duro, Andrés Faiña, Daniel Souto, IEEE Trans. Auton. Ment. Dev. 24Francisco Bellas, Richard J. Duro, Andrés Faiña, and Daniel Souto. Multilevel Darwinist Brain (MDB): Artificial evolution in a cognitive architecture for real robots. IEEE Trans. Auton. Ment. Dev., 2(4):340-354, 2010.</p>
<p>Attentive and Pre-Attentive Processes in Multiple Object Tracking: A Computational Investigation Modeling Object Construction and Tracking. Paul Bello, Will Bridewell, Christina Wasylyshyn, Proc. 38th Annu. Meet. 38th Annu. MeetPaul Bello, Will Bridewell, and Christina Wasylyshyn. Attentive and Pre-Attentive Processes in Multiple Object Tracking: A Computational Investigation Modeling Object Construction and Tracking. In Proc. 38th Annu. Meet. Cogn. Sci. Soc., 2016.</p>
<p>A cognitive approach to classifying perceived behaviors. D P Benjamin, Damian Lyons, Proc. SPIE 7710, Multisensor. SPIE 7710, Multisensor7710D. P. Benjamin and Damian Lyons. A cognitive approach to classifying perceived behaviors. In Proc. SPIE 7710, Multisensor, Multisource Inf. Fusion Archit. Algorithms, Appl., volume 7710, 2010.</p>
<p>A cognitive approach to vision for a mobile robot. D , Paul Benjamin, Christopher Funk, Damian Lyons, SPIE Defense, Secur. Sens. D. Paul Benjamin, Christopher Funk, and Damian Lyons. A cognitive approach to vision for a mobile robot. SPIE Defense, Secur. Sens., 2013.</p>
<p>ADAPT: A Cognitive Architecture for Robotics. D , Paul Benjamin, Damian Lyons, Deryle Lonsdale, Proc. Sixth Int. Conf. Cogn. Model. Sixth Int. Conf. Cogn. ModelD. Paul Benjamin, Damian Lyons, and Deryle Lonsdale. ADAPT: A Cognitive Architecture for Robotics. Proc. Sixth Int. Conf. Cogn. Model., (October):337-338, 2004.</p>
<p>Evolution of GameBots project. Michal Bida, Martin Cerny, Jakub Gemrot, Cyril Brom, Int. Conf. Entertain. Comput. Michal Bida, Martin Cerny, Jakub Gemrot, and Cyril Brom. Evolution of GameBots project. In Int. Conf. Entertain. Comput., pages 397-400, 2012.</p>
<p>Affect and memory: A review. H Paul, Blaney, Psychol. Bull. 992Paul H. Blaney. Affect and memory: A review. Psychol. Bull., 99(2):229-246, 1986.</p>
<p>Improving Agent Learning through Rule Analysis. Cristina Boicu, Gheorghe Tecuci, Mihai Boicu, Proc. Int. Conf. Artif. Intell. Int. Conf. Artif. IntellCristina Boicu, Gheorghe Tecuci, and Mihai Boicu. Improving Agent Learning through Rule Analysis. In Proc. Int. Conf. Artif. Intell., 2005.</p>
<p>Mixed-initiative Control for Teaching and Learning in Disciple. Mihai Boicu, Dorin Marcu, Cristina Boicu, Bogdan Stanescu, Proc. IJCAI-03 Work. Mix. Intell. Syst. IJCAI-03 Work. Mix. Intell. SystMihai Boicu, Dorin Marcu, Cristina Boicu, and Bogdan Stanescu. Mixed-initiative Control for Teaching and Learning in Disciple. In Proc. IJCAI-03 Work. Mix. Intell. Syst., 2003.</p>
<p>Experiences with an architecture for intelligent, reactive agents. R Peter Bonasso, R James Firby, Erann Gat, David Kortenkamp, David P Miller, Marc G Slack, J. Exp. Theor. Artif. Intell. 2-3R. Peter Bonasso, R. James Firby, Erann Gat, David Kortenkamp, David P. Miller, and Marc G. Slack. Experiences with an architecture for intelligent, reactive agents. J. Exp. Theor. Artif. Intell., (2-3):187-202, 1997.</p>
<p>Using a Layered Control Architecture to Alleviate Planning with Incomplete Information. R , Peter Bonasso, David Kortenkamp, Proc. AAAI Spring Symp. with Incomplete Inf. Robot Probl. AAAI Spring Symp. with Incomplete Inf. Robot ProblR. Peter Bonasso and David Kortenkamp. Using a Layered Control Architecture to Alleviate Planning with Incomplete Information. In Proc. AAAI Spring Symp. with Incomplete Inf. Robot Probl., 1996.</p>
<p>Unstructured facility navigation by applying the NIST 4D/RCS architecture. Roger Bostelman, Tsai Hong, Tommy Chang, William Shackleford, Michael Shneier, Proc. Int. Conf. Cybern. Inf. Int. Conf. Cybern. InfRoger Bostelman, Tsai Hong, Tommy Chang, William Shackleford, and Michael Shneier. Unstructured facility navigation by applying the NIST 4D/RCS architecture. In Proc. Int. Conf. Cybern. Inf. Technol. Syst. Appl., pages 328-333, 2006.</p>
<p>Delivery of an Advanced Double-Hull Ship Welding. Roger V Bostelman, Adam Jacoff, Robert Bunch, In Third Int. ICSC (International Comput. Sci. Conv. Symp. Intell. Ind. Autom. Soft Comput. Roger V. Bostelman, Adam Jacoff, and Robert Bunch. Delivery of an Advanced Double-Hull Ship Welding. In Third Int. ICSC (International Comput. Sci. Conv. Symp. Intell. Ind. Autom. Soft Comput., 1999.</p>
<p>Active vision for sociable robots. C Breazeal, A Edsinger, P Fitzpatrick, B Scassellati, IEEE Trans. Syst. Man, Cybern. Part A Syst. Humans. 315C. Breazeal, A. Edsinger, P. Fitzpatrick, and B. Scassellati. Active vision for sociable robots. IEEE Trans. Syst. Man, Cybern. Part A Syst. Humans., 31(5):443-453, 2001.</p>
<p>Emotion and sociable humanoid robots. Cynthia Breazeal, Int. J. Hum. Comput. Stud. 591-2Cynthia Breazeal. Emotion and sociable humanoid robots. Int. J. Hum. Comput. Stud., 59(1-2):119-155, 2003.</p>
<p>Toward sociable robots. Cynthia Breazeal, Rob. Auton. Syst. 423-4Cynthia Breazeal. Toward sociable robots. Rob. Auton. Syst., 42(3-4):167-175, 2003.</p>
<p>Recognition of affective communicative intent in robot-directed speech. Cynthia Breazeal, Lijin Aryananda, Auton. Robots. 121Cynthia Breazeal and Lijin Aryananda. Recognition of affective communicative intent in robot-directed speech. Auton. Robots, 12(1):83-104, 2002.</p>
<p>Robot Emotion: A Functional Perspective. Cynthia Breazeal, Rodney Brooks, Who Needs Emot. Brain Meets Robot. Oxford University PressCynthia Breazeal and Rodney Brooks. Robot Emotion: A Functional Perspective. In Who Needs Emot. Brain Meets Robot. Oxford University Press, 2004.</p>
<p>Social Constraints on Animate Vision. Cynthia Breazeal, Aaron Edsinger, Paul Fitzpatrick, Brian Scassellati, Proc. HUMANOIDS. HUMANOIDSCynthia Breazeal, Aaron Edsinger, Paul Fitzpatrick, and Brian Scassellati. Social Constraints on Animate Vision. In Proc. HUMANOIDS, 2000.</p>
<p>That Certain Look: Social Amplification of Animate Vision. Cynthia Breazeal, Paul Fitzpatrick, Proc. AAAI 2000 Fall Symp. AAAI 2000 Fall SympCynthia Breazeal and Paul Fitzpatrick. That Certain Look: Social Amplification of Animate Vision. In Proc. AAAI 2000 Fall Symp., pages 18-22, 2000.</p>
<p>A context-dependent attention system for a social robot. Cynthia Breazeal, Brian Scassellati, In IJCAI Int. Jt. Conf. Artif. Intell. 2Cynthia Breazeal and Brian Scassellati. A context-dependent attention system for a social robot. In IJCAI Int. Jt. Conf. Artif. Intell., volume 2, pages 1146-1151, 1999.</p>
<p>Challenges in Building Robots That Imitate People. Cynthia Breazeal, Brian Scassellati, Imitation Anim. Artifacts, number 1998. K. Dautenhahn and C. NehanivCambridge, MAMIT PressCynthia Breazeal and Brian Scassellati. Challenges in Building Robots That Imitate People. In K. Dautenhahn and C. Nehaniv, editors, Imitation Anim. Artifacts, number 1998, pages 363-390. MIT Press, Cambridge, MA, 2002.</p>
<p>Integrating planning and reaction: A preliminary report. L John, Mark Bresina, Drummond, Proc. AAAI Spring Symp. Plan. Uncertain, Unpredictable, or Chang. Environ. NASA Ames Research Center. AAAI Spring Symp. Plan. Uncertain, Unpredictable, or Chang. Environ. NASA Ames Research CenterJohn L. Bresina and Mark Drummond. Integrating planning and reaction: A preliminary report. In Proc. AAAI Spring Symp. Plan. Uncertain, Unpredictable, or Chang. Environ. NASA Ames Research Center, 1990.</p>
<p>The Combat Automation Requirements Testbed (CART) Task 5 Interim Report: Modeling A Strike Fighter Pilot Conducting a Time Critical target Mission. E Bryan, Jeffrey A Brett, Doyal, A David, Edward A Malek, Martin, G David, Martin N Hoagland, Anesgart, Tech. Rep.Bryan E Brett, Jeffrey A Doyal, David A Malek, Edward A Martin, David G Hoagland, and Martin N Anesgart. The Combat Automation Requirements Testbed (CART) Task 5 Interim Report: Modeling A Strike Fighter Pilot Conducting a Time Critical target Mission. Tech. Rep., 2002.</p>
<p>Speech and action: Integration of action and language for mobile robots. Timothy Brick, Paul Schermerhorn, Matthias Scheutz, Proc. IEEE Int. Conf. Intell. Robot. Syst. IEEE Int. Conf. Intell. Robot. SystTimothy Brick, Paul Schermerhorn, and Matthias Scheutz. Speech and action: Integration of action and language for mobile robots. In Proc. IEEE Int. Conf. Intell. Robot. Syst., pages 1423-1428, 2007.</p>
<p>Incremental Object Perception in an Attention-Driven Cognitive Architecture. Will Bridewell, Paul F Bello, Proc. 37th Annu. Meet. 37th Annu. MeetWill Bridewell and Paul F. Bello. Incremental Object Perception in an Attention-Driven Cognitive Architecture. Proc. 37th Annu. Meet. Cogn. Sci. Soc., pages 279-284, 2015.</p>
<p>Inattentional Blindness in a Coupled Perceptual-Cognitive System. Will Bridewell, Paul F Bello, Proc. 38th Annu. Meet. 38th Annu. MeetWill Bridewell and Paul F. Bello. Inattentional Blindness in a Coupled Perceptual-Cognitive System. In Proc. 38th Annu. Meet. Cogn. Sci. Soc., 2016.</p>
<p>What Does Your Actor Remember? Towards Characters with a Full Episodic Memory. Cyril Brom, Klára Pešková, Jiri Lukavsky, Int. Conf. Virtual Storytell. Cyril Brom, Klára Pešková, and Jiri Lukavsky. What Does Your Actor Remember? Towards Characters with a Full Episodic Memory. In Int. Conf. Virtual Storytell., pages 89-101, 2007.</p>
<p>Planning is just a way of avoiding figuring out what to do next. Rodney A Brooks, Tech. Rep. Work. Pap. 303Rodney A. Brooks. Planning is just a way of avoiding figuring out what to do next. Tech. Rep. Work. Pap. 303, 1987.</p>
<p>A robot that walks; emergent behaviors from a carefully evolved network. Rodney A Brooks, Neural Comput. 12Rodney A. Brooks. A robot that walks; emergent behaviors from a carefully evolved network. Neural Comput., 1(2):253- 262, 1989.</p>
<p>Elephants don't play chess. Rodney A Brooks, Rob. Auton. Syst. 61-2Rodney A. Brooks. Elephants don't play chess. Rob. Auton. Syst., 6(1-2):3-15, 1990.</p>
<p>Robot Beings. Rodney A Brooks, Anita M Flynn, Proc. IEEE/RSJ Int. IEEE/RSJ IntRodney A. Brooks and Anita M. Flynn. Robot Beings. In Proc. IEEE/RSJ Int. Work. Intell. Robot. Syst., pages 2-10, 1989.</p>
<p>Attention based on information maximization. N Bruce, J Tsotsos, J. Vis. 7N. Bruce and J. Tsotsos. Attention based on information maximization. In J. Vis., volume 7, pages 950-950, 2007.</p>
<p>. P Bustos, J Martinez-Gomez, I Garcia-Varea, L Rodriguez-Ruiz, P Bachiller, L Calderita, L J Manso, A Sanchez, A Bandera, J P Bandera, Multimodal Interaction with Loki. In Work. Phys. Agents. P. Bustos, J. Martinez-Gomez, I. Garcia-Varea, L. Rodriguez-Ruiz, P. Bachiller, L. Calderita, L. J. Manso, A. Sanchez, A. Bandera, and J. P. Bandera. Multimodal Interaction with Loki. In Work. Phys. Agents, 2013.</p>
<p>A unified internal representation of the outer world for social robotics. Pablo Bustos, Luis J Manso, Juan P Bandera, Adrián Romero-Garcés, Luis V Calderita, Rebeca Marfil, Antonio Bandera, Proc. Second Iber. Robot. Conf. Second Iber. Robot. ConfPablo Bustos, Luis J. Manso, Juan P. Bandera, Adrián Romero-Garcés, Luis V. Calderita, Rebeca Marfil, and Antonio Bandera. A unified internal representation of the outer world for social robotics. In Proc. Second Iber. Robot. Conf., 2016.</p>
<p>Aneela Mazhar, Zafar Khattak, and Javaid Anjum Sheikh. The Soar of cognitive architectures. Ayesha Javed Butt, Proc. Int. Conf. Curr. Trends Inf. Technol. Int. Conf. Curr. Trends Inf. TechnolAyesha Javed Butt, Naveed Anwer Butt, Aneela Mazhar, Zafar Khattak, and Javaid Anjum Sheikh. The Soar of cognitive architectures. In Proc. Int. Conf. Curr. Trends Inf. Technol., 2013.</p>
<p>Fergal Byrne, arXiv1512.05245Symphony from Synapses: Neocortex as a Universal Dynamical Systems Modeller using Hierarchical Temporal Memory. arXiv Prepr.Fergal Byrne. Symphony from Synapses: Neocortex as a Universal Dynamical Systems Modeller using Hierarchical Tem- poral Memory. arXiv Prepr. arXiv1512.05245, 2015.</p>
<p>Modeling the development of vehicle lateral control skills in a cognitive architecture. Yulin Shi Cao, Lei Qin, Mowei Zhao, Shen, Transp. Res. Part F Traffic Psychol. Behav. 32Shi Cao, Yulin Qin, Lei Zhao, and Mowei Shen. Modeling the development of vehicle lateral control skills in a cognitive architecture. Transp. Res. Part F Traffic Psychol. Behav., 32:1-10, 2015.</p>
<p>. Jaime G Carbonell, Jim Blythe, Oren Etzioni, Yolanda Gil, Robert Joseph, Dan Kahn, Craig Knoblock, Steven Minton, P Alicia, Scott Reilly, Manuela Veloso, Xuemei Wang, PRODIGY4.0TheManual and Tutorial. Tech. Rep. C. Jaime G. Carbonell, Jim Blythe, Oren Etzioni, Yolanda Gil, Robert Joseph, Dan Kahn, Craig Knoblock, Steven Minton, P. Alicia, Scott Reilly, Manuela Veloso, and Xuemei Wang. PRODIGY4.0: TheManual and Tutorial. Tech. Rep. C., 1992.</p>
<p>Neural-network models of learning and memory: Leading questions and an emerging framework. Gail A Carpenter, TRENDS Cogn. Sci. 53Gail A. Carpenter. Neural-network models of learning and memory: Leading questions and an emerging framework. TRENDS Cogn. Sci., 5(3):114-118, 2001.</p>
<p>Biased ART: A neural architecture that shifts attention toward previously disregarded features following an incorrect prediction. Gail A Carpenter, Sai Chaitanya, Gaddam, Neural Networks. 233Gail A. Carpenter and Sai Chaitanya Gaddam. Biased ART: A neural architecture that shifts attention toward previously disregarded features following an incorrect prediction. Neural Networks, 23(3):435-451, 2010.</p>
<p>Neural dynamics of category learning and recognition: attention, memory consolidation, and amnesia. Gail A Carpenter, Stephen Grossberg, Adv. Psychol. 42Gail A. Carpenter and Stephen Grossberg. Neural dynamics of category learning and recognition: attention, memory consolidation, and amnesia. Adv. Psychol., 42:233-290, 1987.</p>
<p>ARTMAP: Supervised real-time learning and classification of nonstationary data by a self-organizing neural network. Gail A Carpenter, Stephen Grossberg, John H Reynolds, Neural Networks. 45Gail A. Carpenter, Stephen Grossberg, and John H. Reynolds. ARTMAP: Supervised real-time learning and classification of nonstationary data by a self-organizing neural network. Neural Networks, 4(5):565-588, 1991.</p>
<p>Adaptive Systems, and Neural Systems. A Gail, Stephen Carpenter, Grossberg, Mach. Learn. Data Min. Adaptive Resonance Theory. EncyclGail A Carpenter, Stephen Grossberg, Adaptive Systems, and Neural Systems. Adaptive Resonance Theory. Encycl. Mach. Learn. Data Min., 2016.</p>
<p>Human cognitive abilities: A survey of factor-analytic studies. John B Carroll, Cambridge University PressJohn B. Carroll. Human cognitive abilities: A survey of factor-analytic studies. Cambridge University Press, 1993.</p>
<p>The power of a nod and a glance: Envelope vs. emotional feedback in animated conversational agents. Justine Cassell, Kristinn R Thorisson, Appl. Artif. Intell. 134-5Justine Cassell and Kristinn R. Thorisson. The power of a nod and a glance: Envelope vs. emotional feedback in animated conversational agents. Appl. Artif. Intell., 13(4-5):519-538, 1999.</p>
<p>Harnessing Multiple Representations for Autonomous Full-Spectrum Political, Military, Economic, Social, Information and Infrastructure (PMESII) Reasoning. Final Tech. Rep. Nicholas L Cassimatis, AFRL-IF-RS-TR-2007-131Nicholas L. Cassimatis. Harnessing Multiple Representations for Autonomous Full-Spectrum Political, Military, Economic, Social, Information and Infrastructure (PMESII) Reasoning. Final Tech. Rep. AFRL-IF-RS-TR-2007-131, 2007.</p>
<p>Learning a Song: an ACT-R Model. Belkacem Chikhaoui, Helene Pigot, Mathieu Beaudoin, Guillaume Pratte, Philippe Bellefeuille, Fernando Laudares, Proc. Int. Conf. Comput. Intell. Int. Conf. Comput. IntellBelkacem Chikhaoui, Helene Pigot, Mathieu Beaudoin, Guillaume Pratte, Philippe Bellefeuille, and Fernando Laudares. Learning a Song: an ACT-R Model. Proc. Int. Conf. Comput. Intell., pages 405-410, 2009.</p>
<p>Online multiple instance learning applied to hand detection in a humanoid robot. Carlo Ciliberto, Fabrizio Smeraldi, Lorenzo Natale, Giorgio Metta, Proc. IEEE Int. Conf. Intell. Robot. Syst. IEEE Int. Conf. Intell. Robot. SystCarlo Ciliberto, Fabrizio Smeraldi, Lorenzo Natale, and Giorgio Metta. Online multiple instance learning applied to hand detection in a humanoid robot. In Proc. IEEE Int. Conf. Intell. Robot. Syst., pages 1526-1532, 2011.</p>
<p>Modeling Emotion: Arousal's Impact on Memory. Robert E Cochran, Frank J Lee, Eric Chown, Proc. 28th Annu. Conf. 28th Annu. ConfRobert E. Cochran, Frank J. Lee, and Eric Chown. Modeling Emotion: Arousal's Impact on Memory. In Proc. 28th Annu. Conf. Cogn. Sci. Soc., pages 1133-1138, 2006.</p>
<p>CHARISMA: A Context Hierarchy-based cognitive architecture for self-motivated social agents. Matthew Conforth, Yan Meng, Proc. Int. Jt. Conf. Neural Networks. Int. Jt. Conf. Neural NetworksMatthew Conforth and Yan Meng. CHARISMA: A Context Hierarchy-based cognitive architecture for self-motivated social agents. Proc. Int. Jt. Conf. Neural Networks, pages 1894-1901, 2011.</p>
<p>Self-reorganizing knowledge representation for autonomous learning in social agents. Matthew Conforth, Yan Meng, Proc. Int. Jt. Conf. Neural Networks. Int. Jt. Conf. Neural NetworksMatthew Conforth and Yan Meng. Self-reorganizing knowledge representation for autonomous learning in social agents. Proc. Int. Jt. Conf. Neural Networks, pages 1880-1887, 2011.</p>
<p>Embodied Intelligent Agents with Cognitive Conscious and Unconscious Reasoning. Matthew Conforth, Yan Meng, Proc. BMI ICBM. BMI ICBMMatthew Conforth and Yan Meng. Embodied Intelligent Agents with Cognitive Conscious and Unconscious Reasoning. In Proc. BMI ICBM, pages 15-20, 2012.</p>
<p>Driving Autonomously Offroad up to 35 Km/h. D Coombs, K Murphy, A Lacaze, S Legowik, Proc. IEEE Intell. Veh. Symp., number Mi. IEEE Intell. Veh. Symp., number MiD. Coombs, K. Murphy, A. Lacaze, and S. Legowik. Driving Autonomously Offroad up to 35 Km/h. In Proc. IEEE Intell. Veh. Symp., number Mi, pages 186-191, 2000.</p>
<p>A cognitive system model for human/automation dynamics in airspace management. Kevin Corker, Greg Pisanich, Marilyn Bunzo, Proc. First Eur. Symp. Air Traffic Manag. First Eur. Symp. Air Traffic ManagKevin Corker, Greg Pisanich, and Marilyn Bunzo. A cognitive system model for human/automation dynamics in airspace management. In Proc. First Eur. Symp. Air Traffic Manag., 1997.</p>
<p>Chapter 20 What are the differences between long-term, short-term, and working memory? In Prog. Nelson Cowan, Brain Res. 169ElsevierNelson Cowan. Chapter 20 What are the differences between long-term, short-term, and working memory? In Prog. Brain Res., volume 169, pages 323-338. Elsevier, 2008.</p>
<p>Modelling Memory and Learning Consistently from Psychology to Physiology. L , Andrew Coward, Perception-Action Cycle. Vassilis Cutsuridis, Amir Hussain, and John G. TaylorL. Andrew Coward. Modelling Memory and Learning Consistently from Psychology to Physiology. In Vassilis Cutsuridis, Amir Hussain, and John G. Taylor, editors, Perception-Action Cycle, pages 63-133. 2011.</p>
<p>Noting Anomalies in Streams of Symbolic Predicates Using A-Distance. Michael T Cox, Tim Oates, Matthew Paisner, Donald Perlis, Adv. Cogn. Syst. 2Michael T. Cox, Tim Oates, Matthew Paisner, and Donald Perlis. Noting Anomalies in Streams of Symbolic Predicates Using A-Distance. Adv. Cogn. Syst., 2:167-184, 2012.</p>
<p>Biologically Plausible, Human-scale Knowledge Representation. Eric Crawford, Matthew Gingerich, Chris Eliasmith, Cogn. Sci. 404Eric Crawford, Matthew Gingerich, and Chris Eliasmith. Biologically Plausible, Human-scale Knowledge Representation. Cogn. Sci., 40(4):412-417, 2015.</p>
<p>Chuck Norris rocks! In. Daniel Cuadrado, Yago Saez, Proc. IEEE Symp. Comput. Intell. Games. IEEE Symp. Comput. Intell. GamesDaniel Cuadrado and Yago Saez. Chuck Norris rocks! In Proc. IEEE Symp. Comput. Intell. Games, pages 69-74, 2009.</p>
<p>Continuous online sequence learning with an unsupervised neural network model. Yuwei Cui, Subutai Ahmad, Jeff Hawkins, arXiv1512.05463arXiv Prepr.Yuwei Cui, Subutai Ahmad, and Jeff Hawkins. Continuous online sequence learning with an unsupervised neural network model. arXiv Prepr. arXiv1512.05463, 2015.</p>
<p>Fault diagnosis of pneumatic systems with artificial neural network algorithms. M Demetgul, I N Tansel, S Taskin, Expert Syst. Appl. 367M. Demetgul, I. N. Tansel, and S. Taskin. Fault diagnosis of pneumatic systems with artificial neural network algorithms. Expert Syst. Appl., 36(7):10512-10519, 2009.</p>
<p>Competence-Preserving Retention of Learned Knowledge in Soar's Working and Procedural Memories. Nate Derbinsky, John E Laird, Proc. 11th Int. Conf. Cogn. Model. 11th Int. Conf. Cogn. ModelNate Derbinsky and John E. Laird. Competence-Preserving Retention of Learned Knowledge in Soar's Working and Procedural Memories. In Proc. 11th Int. Conf. Cogn. Model., 2012.</p>
<p>Computationally Efficient Forgetting via Base-Level Activation. Nate Derbinsky, John E Laird, Proc. 11th Int. Conf. Cogn. Model. 11th Int. Conf. Cogn. ModelNate Derbinsky and John E Laird. Computationally Efficient Forgetting via Base-Level Activation. In Proc. 11th Int. Conf. Cogn. Model., pages 109-110, 2012.</p>
<p>Omar Human Performance Modeling in a Decision Support Experiment. Stephen Deutsch, Nichael Cramer, Proc. Hum. Factors Ergon. Soc. 42nd Annu. Meet. Hum. Factors Ergon. Soc. 42nd Annu. MeetStephen Deutsch and Nichael Cramer. Omar Human Performance Modeling in a Decision Support Experiment. In Proc. Hum. Factors Ergon. Soc. 42nd Annu. Meet., pages 1232-1236, 1998.</p>
<p>Omar Human Performance Modeling in a Decision Support Experiment. Stephen Deutsch, Nichael Cramer, Proc. Hum. Factors Ergon. Soc. 42nd Annu. Meet. Hum. Factors Ergon. Soc. 42nd Annu. MeetStephen Deutsch and Nichael Cramer. Omar Human Performance Modeling in a Decision Support Experiment. In Proc. Hum. Factors Ergon. Soc. 42nd Annu. Meet., pages 1232-1236, 1998.</p>
<p>UAV Operator Human Performance Models. Stephen E Deutsch, AFRL-RI-RS-TR-2006-0158Tech. Rep.Stephen E. Deutsch. UAV Operator Human Performance Models. Tech. Rep. AFRL-RI-RS-TR-2006-0158, 2006.</p>
<p>Operability Model Architecture: Demonstration Final Report. Stephen E Deutsch, Jean Macmillan, Nichael L Camer, Sonu Chopra, AL/HR-TR-1996-0161Tech. Rep.Stephen E. Deutsch, Jean Macmillan, Nichael L. Camer, and Sonu Chopra. Operability Model Architecture: Demonstration Final Report. Tech. Rep. AL/HR-TR-1996-0161, 1997.</p>
<p>Grounding fingers, words and numbers in a cognitive developmental robot. Alessandro Di Nuovo, Vivian M De La, Cruz , Angelo Cangelosi, Proc. IEEE Symp. IEEE SympAlessandro Di Nuovo, Vivian M. De La Cruz, and Angelo Cangelosi. Grounding fingers, words and numbers in a cognitive developmental robot. In Proc. IEEE Symp. Comput. Intell. Cogn. Algorithms, Mind, Brain, 2014.</p>
<p>The dMARS architecture: A specification of the distributed multi-agent reasoning system. Michael Mark D&apos;inverno, Michael Luck, David Georgeff, Michael Kinny, Wooldridge, Auton. Agent. Multi. Agent. Syst. 91-2Mark D'Inverno, Michael Luck, Michael Georgeff, David Kinny, and Michael Wooldridge. The dMARS architecture: A specification of the distributed multi-agent reasoning system. Auton. Agent. Multi. Agent. Syst., 9(1-2):5-53, 2004.</p>
<p>Odor discrimination using adaptive resonance theory. Cosimo Distante, Pietro Siciliano, Lorenzo Vasanelli, Sensors and Actuators. 693Cosimo Distante, Pietro Siciliano, and Lorenzo Vasanelli. Odor discrimination using adaptive resonance theory. Sensors and Actuators, 69(3):248-252, 2000.</p>
<p>PSI: A Computational Architecture of Cognition. Dietrich Dörner, C. Dominik Güss, Motivation, and Emotion. Rev. Gen. Psychol. 173Dietrich Dörner and C. Dominik Güss. PSI: A Computational Architecture of Cognition, Motivation, and Emotion. Rev. Gen. Psychol., 17(3):297-317, 2013.</p>
<p>Large Declarative Memories in ACT-R. S A Douglass, J Ball, S Rodgers, Proc. 9th Int. Conf. Cogn. Model. 9th Int. Conf. Cogn. Model234S.A. Douglass, J. Ball, and S. Rodgers. Large Declarative Memories in ACT-R. Proc. 9th Int. Conf. Cogn. Model., page 234, 2009.</p>
<p>Cognitive Architectures: Where do we go from here?. W Duch, Richard J Oentaryo, Michel Pasquier, Artif. Intell. Appl. Pei Wang, Ben Goertzel, and Stan Franklin171IOS PressW. Duch, Richard J. Oentaryo, and Michel Pasquier. Cognitive Architectures: Where do we go from here? In Pei Wang, Ben Goertzel, and Stan Franklin, editors, Front. Artif. Intell. Appl., volume 171, pages 122-136. IOS Press, 2008.</p>
<p>Towards comprehensive foundations of computational intelligence. Duch W Lodzislaw, Stud. Comput. Intell. 63W lodzislaw Duch. Towards comprehensive foundations of computational intelligence. Stud. Comput. Intell., 63:261-316, 2007.</p>
<p>Evolutionary Architecture for Lifelong Learning and Real-Time Operation in Autonomous Robots. R J Duro, F Bellas, J A Becerra, Evol. Intell. Syst. Methodol. Appl. P. Angelov, D. P. Filev, and N. KasabovR. J. Duro, F. Bellas, and J. A. Becerra. Evolutionary Architecture for Lifelong Learning and Real-Time Operation in Autonomous Robots. In P. Angelov, D. P. Filev, and N. Kasabov, editors, Evol. Intell. Syst. Methodol. Appl., pages 365-400. 2010.</p>
<p>Learning in and from brain-based devices. Science (80-. ). Gerald M Edelman, 318Gerald M. Edelman. Learning in and from brain-based devices. Science (80-. )., 318(5853):1103-1105, 2007.</p>
<p>Marr's Attacks: On Reductionism and Vagueness. Chris Eliasmith, Carter Kolbeck, Top. Cogn. Sci. Chris Eliasmith and Carter Kolbeck. Marr's Attacks: On Reductionism and Vagueness. Top. Cogn. Sci., pages 1-13, 2015.</p>
<p>A Large-Scale Model of the Functioning Brain. Chris Eliasmith, Terrence C Stewart, Science (80-. )., 338(1202Chris Eliasmith and Terrence C Stewart. A Large-Scale Model of the Functioning Brain. Science (80-. )., 338(1202), 2012.</p>
<p>Metaknowledge for Autonomous Systems. S L Epstein, Proc. AAAI Spring Symp. AAAI Spring SympS. L. Epstein. Metaknowledge for Autonomous Systems. In Proc. AAAI Spring Symp. Knowl. Represent. Ontol. Auton. Syst., 2004.</p>
<p>The role of memory and concepts in learning. Susan L Epstein, Minds Mach. 23Susan L. Epstein. The role of memory and concepts in learning. Minds Mach., 2(3):239-265, 1992.</p>
<p>For the right reasons: The FORR architecture for learning in a skill domain. Susan L Epstein, Cogn. Sci. 183Susan L. Epstein. For the right reasons: The FORR architecture for learning in a skill domain. Cogn. Sci., 18(3):479-511, 1994.</p>
<p>Learning to Play Expertly: A Tutorial on Hoyle. Susan L Epstein, Mach. that Learn to Play games. Johannes Furnkranz and Miroslav KubatNova Science PublishersSusan L. Epstein. Learning to Play Expertly: A Tutorial on Hoyle. In Johannes Furnkranz and Miroslav Kubat, editors, Mach. that Learn to Play games, pages 153-178. Nova Science Publishers, 2001.</p>
<p>The Adaptive Constraint Engine. Susan L Epstein, Eugene C Freuder, Richard Wallace, Anton Morozov, Bruce Samuels, Proc. Int. Conf. Princ. Pract. Constraint Program. Int. Conf. Princ. Pract. Constraint ProgramSusan L. Epstein, Eugene C. Freuder, Richard Wallace, Anton Morozov, and Bruce Samuels. The Adaptive Constraint Engine. In Proc. Int. Conf. Princ. Pract. Constraint Program., pages 525-540, 2002.</p>
<p>The Role of Knowledge and Certainty in Understanding for Dialogue. Susan L Epstein, Rebecca Passonneau, Joshua Gordon, Tiziana Ligorio, AAAI Fall Symp. Susan L. Epstein, Rebecca Passonneau, Joshua Gordon, and Tiziana Ligorio. The Role of Knowledge and Certainty in Understanding for Dialogue. In AAAI Fall Symp. Adv. Cogn. Syst., 2012.</p>
<p>Acquiring search-control knowledge via static analysis. Oren Etzioni, Artif. Intell. 622Oren Etzioni. Acquiring search-control knowledge via static analysis. Artif. Intell., 62(2):255-301, 1993.</p>
<p>Populating VBS2 with Realistic Virtual Actors. Rick Evertsz, Matteo Pedrotti, Paolo Busetta, Hasan Acar, Frank E Ritter, Proc. 18th Conf. 18th ConfRick Evertsz, Matteo Pedrotti, Paolo Busetta, Hasan Acar, and Frank E. Ritter. Populating VBS2 with Realistic Virtual Actors. In Proc. 18th Conf. Behav. Represent. Model. Simul., 2009.</p>
<p>The use of emotions in the implementation of various types of learning in a cognitive agent. Usef Faghihi, PhD ThesisUsef Faghihi. The use of emotions in the implementation of various types of learning in a cognitive agent. PhD Thesis, 2011.</p>
<p>Implementing an efficient causal learning mechanism in a cognitive tutoring agent. Usef Faghihi, Philippe Fournier-Viger, Roger Nkambou, Int. Conf. Ind. Eng. Other Appl. Appl. Intell. Syst. Usef Faghihi, Philippe Fournier-Viger, and Roger Nkambou. Implementing an efficient causal learning mechanism in a cognitive tutoring agent. Int. Conf. Ind. Eng. Other Appl. Appl. Intell. Syst., 2011.</p>
<p>CELTS: A cognitive tutoring agent with human-like learning capabilities and emotions. Usef Faghihi, Philippe Fournier-Viger, Roger Nkambou, Smart Innov. Syst. Technol. Berlin HeidelbergSpringerUsef Faghihi, Philippe Fournier-Viger, and Roger Nkambou. CELTS: A cognitive tutoring agent with human-like learning capabilities and emotions. In Smart Innov. Syst. Technol. Springer Berlin Heidelberg, 2013.</p>
<p>The LIDA Model as a Foundational Architecture for AGI. Usef Faghihi, Stan Franklin, Theor. Found. Artif. Gen. Intell. 4Usef Faghihi and Stan Franklin. The LIDA Model as a Foundational Architecture for AGI. Theor. Found. Artif. Gen. Intell., 4:103-121, 2012.</p>
<p>. Usef Faghihi, Pierre Poirier, Othalia Larue, Emotional Cognitive Architectures. In Int. Conf. Affect. Comput. Intell. Interact. Usef Faghihi, Pierre Poirier, and Othalia Larue. Emotional Cognitive Architectures. In Int. Conf. Affect. Comput. Intell. Interact., 2011.</p>
<p>RPD-enabled agents teaming with humans for multi-context decision making. X Fan, B Sun, S Sun, M Mcneese, J Yen, Proc. Int. Conf. Auton. Agents. Int. Conf. Auton. AgentsX. Fan, B. Sun, S. Sun, M. McNeese, and J. Yen. RPD-enabled agents teaming with humans for multi-context decision making. In Proc. Int. Conf. Auton. Agents, 2006.</p>
<p>Human-agent collaboration for time-stressed multicontext decision making. Xiaocong Fan, Michael Mcneese, Bingjun Sun, Timothy Hanratty, Laurel Allender, John Yen, IEEE Trans. Syst. Man, Cybern. Part A Syst. 402HumansXiaocong Fan, Michael McNeese, Bingjun Sun, Timothy Hanratty, Laurel Allender, and John Yen. Human-agent col- laboration for time-stressed multicontext decision making. IEEE Trans. Syst. Man, Cybern. Part A Syst. Humans, 40(2):306-320, 2010.</p>
<p>NDM-Based Cognitive Agents for Supporting Decision-Making Teams. Xiaocong Fan, Michael Mcneese, John Yen, Human-Computer Interact. 253Xiaocong Fan, Michael McNeese, and John Yen. NDM-Based Cognitive Agents for Supporting Decision-Making Teams. Human-Computer Interact., 25(3):195-234, 2010.</p>
<p>View-invariant object category learning, recognition, and search: How spatial and object attention are coordinated using surface-based attentional shrouds. Arash Fazl, Stephen Grossberg, Ennio Mingolla, Cogn. Psychol. 581Arash Fazl, Stephen Grossberg, and Ennio Mingolla. View-invariant object category learning, recognition, and search: How spatial and object attention are coordinated using surface-based attentional shrouds. Cogn. Psychol., 58(1), 2009.</p>
<p>Cognitive Architecture with Evolutionary Dynamics Solves Insight Problem. Anna Fedor, István Zachar, András Szilágyi, Michaelöllinger , Front. Psychol. 8Anna Fedor, István Zachar, András Szilágyi, and MichaelÖllinger. Cognitive Architecture with Evolutionary Dynamics Solves Insight Problem. Front. Psychol., 8:1-15, 2017.</p>
<p>Anxiety restricts the analogical search in an analogy generation task. Veselina Feldman, Boicho Kokinov, New Front. Analog. Res. Veselina Feldman and Boicho Kokinov. Anxiety restricts the analogical search in an analogy generation task. New Front. Analog. Res., 2009.</p>
<p>Prodigy bidirectional planning. Eugene Fink, Jim Blythe, J. Exp. Theor. Artif. Intell. 173Eugene Fink and Jim Blythe. Prodigy bidirectional planning. J. Exp. Theor. Artif. Intell., 17(3):161-200, 2005.</p>
<p>An Architecture for Vision and Action. James R Firby, Roger E Kahn, Peter N Prokopowicz, Michael J Swain, Proc. 14th Int. Jt. Conf. Artif. Intell. 14th Int. Jt. Conf. Artif. IntellJames R. Firby, Roger E. Kahn, Peter N. Prokopowicz, and Michael J. Swain. An Architecture for Vision and Action. In Proc. 14th Int. Jt. Conf. Artif. Intell., 1995.</p>
<p>Adaptive Execution in Complex Dynamic Worlds. Robert James Firby, PhD thesisRobert James Firby. Adaptive Execution in Complex Dynamic Worlds. PhD thesis, 1989.</p>
<p>Brain-Based Devices: An embodied approach to linking nervous system structure and function to behavior. Jason G Fleischer, Gerald M Edelman, IEEE Robot. Autom. Mag. 163Jason G. Fleischer and Gerald M. Edelman. Brain-Based Devices: An embodied approach to linking nervous system structure and function to behavior. IEEE Robot. Autom. Mag., 16(3):33-41, 2009.</p>
<p>Extending SME to Handle Large-Scale Cognitive Modeling. D Kenneth, Ronald W Forbus, Andrew Ferguson, Lovett, Cogn. Sci. Kenneth D Forbus, Ronald W Ferguson, and Andrew Lovett. Extending SME to Handle Large-Scale Cognitive Modeling. Cogn. Sci., pages 1-50, 2016.</p>
<p>Companion Cognitive Systems: Design Goals and Lessons Learned. Kenneth D Forbus, Matthew Klenk, Thomas Hinrichs, IEEE Intell. Syst. PPKenneth D. Forbus, Matthew Klenk, and Thomas Hinrichs. Companion Cognitive Systems: Design Goals and Lessons Learned. IEEE Intell. Syst., PP(99):36-46, 2009.</p>
<p>. Douglas Foxvog. Cyc. In Theory Appl. Ontol. Comput. Appl. Douglas Foxvog. Cyc. In Theory Appl. Ontol. Comput. Appl., pages 259-278. 2010.</p>
<p>Modeling Consciousness and Cognition in Software Agents. S Franklin, Proc. Third Int. Conf. Cogn. Model. Third Int. Conf. Cogn. ModelS. Franklin. Modeling Consciousness and Cognition in Software Agents. In Proc. Third Int. Conf. Cogn. Model., pages 27-58, 2000.</p>
<p>Learning in "Conscious. Stan Franklin, Software Agents. In Work. Dev. Learn. Stan Franklin. Learning in "Conscious" Software Agents. In Work. Dev. Learn., 2000.</p>
<p>A Foundational Architecture for Artificial General Intelligence. Stan Franklin, Adv. Artif. Gen. Intell. Concepts, Archit. Algorithms. Stan Franklin. A Foundational Architecture for Artificial General Intelligence. Adv. Artif. Gen. Intell. Concepts, Archit. Algorithms, pages 36-54, 2007.</p>
<p>Pulin Agrawal, and Sheng Chen. A LIDA cognitive model tutorial. Stan Franklin, Tamas Madl, Steve Strain, Usef Faghihi, Daqi Dong, Sean Kugele, Javier Snaider, Biol. Inspired Cogn. Archit. 16Stan Franklin, Tamas Madl, Steve Strain, Usef Faghihi, Daqi Dong, Sean Kugele, Javier Snaider, Pulin Agrawal, and Sheng Chen. A LIDA cognitive model tutorial. Biol. Inspired Cogn. Archit., 16, 2016.</p>
<p>Global Workspace Theory, its LIDA model and the underlying neuroscience. Stan Franklin, Steve Strain, Javier Snaider, Ryan Mccall, Usef Faghihi, Biol. Inspired Cogn. Archit. 1Stan Franklin, Steve Strain, Javier Snaider, Ryan McCall, and Usef Faghihi. Global Workspace Theory, its LIDA model and the underlying neuroscience. Biol. Inspired Cogn. Archit., 1:32-43, 2012.</p>
<p>Making human-machine system simulation a practical engineering tool: An APEX overview. M Freed, R Remington, Proc. 3rd Int. Conf. Cogn. Model. 3rd Int. Conf. Cogn. ModelM. Freed and R. Remington. Making human-machine system simulation a practical engineering tool: An APEX overview. In Proc. 3rd Int. Conf. Cogn. Model., 2000.</p>
<p>Simulating human performance in complex, dynamic environments. M A Freed, PhD ThesisM. A. Freed. Simulating human performance in complex, dynamic environments. PhD Thesis, (June), 1998.</p>
<p>An Integrated Systems Approach to Explanation-Based Conceptual Change. E Scott, Kenneth D Friedman, Forbus, Assoc. Adv. Artif. Intell. Scott E. Friedman and Kenneth D. Forbus. An Integrated Systems Approach to Explanation-Based Conceptual Change. Assoc. Adv. Artif. Intell., 2010.</p>
<p>Computational Visual Attention Systems and their Cognitive Foundations: A Survey. Simone Frintrop, Erich Rome, Henrik I Christensen, ACM Trans. Appl. Percept. 71Simone Frintrop, Erich Rome, and Henrik I. Christensen. Computational Visual Attention Systems and their Cognitive Foundations: A Survey. ACM Trans. Appl. Percept., 7(1), 2010.</p>
<p>Supporting the Commander's information requirements: Automated support for battle drill processes using R-CAST. Jeffrey From, Patrick Perrin, O&apos; Daniel, John Neill, Yen, Proc. IEEE Mil. Commun. Conf. MILCOM. IEEE Mil. Commun. Conf. MILCOMJeffrey From, Patrick Perrin, Daniel O'Neill, and John Yen. Supporting the Commander's information requirements: Automated support for battle drill processes using R-CAST. In Proc. IEEE Mil. Commun. Conf. MILCOM, 2011.</p>
<p>Integrating Planning and Reacting in a Heterogeneous Asynchronous Architecture for Controlling Real-World Mobile Robots. Erann Gat, AAAIErann Gat. Integrating Planning and Reacting in a Heterogeneous Asynchronous Architecture for Controlling Real-World Mobile Robots. AAAI, pages 809-815, 1992.</p>
<p>Pogamut 3 can assist developers in building AI (not only) for their videogame agents. Agents for games and simulations. Jakub Gemrot, Rudolf Kadlec, Michal Bida, Ondrej Burkert, Radek Pibil, Jan Havlicek, Lukas Zemcak, Juraj Simlovic, Radim Vansa, Michal Stolba, Tomas Plch, Cyril Brom, Jakub Gemrot, Rudolf Kadlec, Michal Bida, Ondrej Burkert, Radek Pibil, Jan Havlicek, Lukas Zemcak, Juraj Simlovic, Radim Vansa, Michal Stolba, Tomas Plch, and Cyril Brom. Pogamut 3 can assist developers in building AI (not only) for their videogame agents. Agents for games and simulations, pages 1-15, 2009.</p>
<p>The Belief-Desire-Intention Model of Agency. Michael Georgeff, Barney Pell, Martha Pollack, Milind Tambe, Michael Wooldridge, In Int. Work. Agent Theor. Archit. Lang. Michael Georgeff, Barney Pell, Martha Pollack, Milind Tambe, and Michael Wooldridge. The Belief-Desire-Intention Model of Agency. In Int. Work. Agent Theor. Archit. Lang., 1998.</p>
<p>Decision-Making in an Embedded Reasoning System. P Michael, Francois Felix Georgeff, Ingrand, Proc. Elev. Int. Jt. Conf. Artif. Intell. Elev. Int. Jt. Conf. Artif. IntellMichael P. Georgeff and Francois Felix Ingrand. Decision-Making in an Embedded Reasoning System. In Proc. Elev. Int. Jt. Conf. Artif. Intell., 1989.</p>
<p>Procedural Knowledge. P Michael, Amy L Georgeff, Lansky, Proc. IEEE. IEEE74Michael P. Georgeff and Amy L. Lansky. Procedural Knowledge. In Proc. IEEE, volume 74, pages 1383-1398, 1986.</p>
<p>Memory for the meaningless: How chunks help. R Fernand, Gobet, Proc. 20th Meet. 20th MeetFernand R. Gobet. Memory for the meaningless: How chunks help. In Proc. 20th Meet. Cogn. Sci. Soc., pages 398-403, 2008.</p>
<p>A pragmatic path toward endowing virtually-embodied AIs with human-level linguistic capability. Ben Goertzel, Proc. Int. Jt. Conf. Neural Networks. Int. Jt. Conf. Neural NetworksBen Goertzel. A pragmatic path toward endowing virtually-embodied AIs with human-level linguistic capability. In Proc. Int. Jt. Conf. Neural Networks, 2008.</p>
<p>OpenCogBot: Achieving Generally Intelligent Virtual Agent Control and Humanoid Robotics via Cognitive Synergy. Ben Goertzel, Hugo De Garis, Cassio Pennachin, Nil Geisweiller, Samir Araujo, Joel Pitt, Shuo Chen, Ruiting Lian, Min Jiang, Ye Yang, Deheng Huang, Proc. Int. Conf. Artifical Intell. Int. Conf. Artifical IntellBen Goertzel, Hugo De Garis, Cassio Pennachin, Nil Geisweiller, Samir Araujo, Joel Pitt, Shuo Chen, Ruiting Lian, Min Jiang, Ye Yang, and Deheng Huang. OpenCogBot: Achieving Generally Intelligent Virtual Agent Control and Humanoid Robotics via Cognitive Synergy. In Proc. Int. Conf. Artifical Intell., 2010.</p>
<p>A world survey of artificial brain projects, Part II: Biologically inspired cognitive architectures. Ben Goertzel, Ruiting Lian, Itamar Arel, Shuo Hugo De Garis, Chen, Neurocomputing. 741-3Ben Goertzel, Ruiting Lian, Itamar Arel, Hugo de Garis, and Shuo Chen. A world survey of artificial brain projects, Part II: Biologically inspired cognitive architectures. Neurocomputing, 74(1-3):30-49, 2010.</p>
<p>The Novamente Artificial Intelligence Engine. Ben Goertzel, Cassio Pennachin, In Artif. Gen. Intell. SpringerBen Goertzel and Cassio Pennachin. The Novamente Artificial Intelligence Engine. In Artif. Gen. Intell., pages 63-129. Springer Berlin Heidelberg, 2007.</p>
<p>An Integrative Methodology for Teaching Embodied Non-Linguistic Agents, Applied to Virtual Animals in Second Life. Ben Goertzel, Cassio Pennachin, Nil Geissweiller, Moshe Looks, Andre Senna, Welter Silva, Ari Heljakka, Carlos Lopes, Front. Artif. Intell. Appl. 171Ben Goertzel, Cassio Pennachin, Nil Geissweiller, Moshe Looks, Andre Senna, Welter Silva, Ari Heljakka, and Carlos Lopes. An Integrative Methodology for Teaching Embodied Non-Linguistic Agents, Applied to Virtual Animals in Second Life. Front. Artif. Intell. Appl., 171:161-175, 2008.</p>
<p>Brief Survey of Cognitive Architectures. Ben Goertzel, Cassio Pennachin, Nil Geisweiller, Gen. Intell. Part. Eng1Atlantis PressBen Goertzel, Cassio Pennachin, and Nil Geisweiller. Brief Survey of Cognitive Architectures. In Eng. Gen. Intell. Part 1, pages 101-142. Atlantis Press, 2014.</p>
<p>Integrating deep learning based perception with probabilistic logic via frequent pattern mining. Ben Goertzel, Ted Sanders, Jade O&apos; Neill, In Int. Conf. Artif. Gen. Intell. Ben Goertzel, Ted Sanders, and Jade O'Neill. Integrating deep learning based perception with probabilistic logic via frequent pattern mining. In Int. Conf. Artif. Gen. Intell., 2013.</p>
<p>A cognitive API and its application to AGI intelligence assessment. Ben Goertzel, Gino Yu, In Int. Conf. Artif. Gen. Intell. Ben Goertzel and Gino Yu. A cognitive API and its application to AGI intelligence assessment. In Int. Conf. Artif. Gen. Intell., pages 242-245, 2014.</p>
<p>Learning to balance grounding rationales for dialogue systems. Joshua Gordon, Susan L Epstein, Proc. SIGDIAL Conf. SIGDIAL ConfJoshua Gordon and Susan L. Epstein. Learning to balance grounding rationales for dialogue systems. In Proc. SIGDIAL Conf., pages 266-271, 2011.</p>
<p>A computational implementation of a human attention guiding mechanism in MIDAS v5. Brian F Gore, Becky L Hooey, Christopher D Wickens, Shelly Scott-Nash, Int. Conf. Digit. Hum. Model. Brian F. Gore, Becky L. Hooey, Christopher D. Wickens, and Shelly Scott-Nash. A computational implementation of a human attention guiding mechanism in MIDAS v5. In Int. Conf. Digit. Hum. Model., 2009.</p>
<p>The Link between Brain Learning, Attention, and Consciousness. Stephen Grossberg, Conscious. Cogn. 8Stephen Grossberg. The Link between Brain Learning, Attention, and Consciousness. Conscious. Cogn., 8:1-44, 1999.</p>
<p>Resonant Neural Dynamics of Speech Perception. Stephen Grossberg, CAS/CNS-TR-02-008Tech. Rep.Stephen Grossberg. Resonant Neural Dynamics of Speech Perception. Tech. Rep. CAS/CNS-TR-02-008, 2003.</p>
<p>Towards a unified theory of neocortex: laminar cortical circuits for vision and cognition. Stephen Grossberg, Prog. Brain Res. 165Stephen Grossberg. Towards a unified theory of neocortex: laminar cortical circuits for vision and cognition. Prog. Brain Res., 165:79-104, 2007.</p>
<p>ARTSTREAM: a neural network model of auditory scene analysis and source segregation. Stephen Grossberg, Krishna K Govindarajan, Lonce L Wyse, Michael A Cohen, Neural Networks. 174Stephen Grossberg, Krishna K. Govindarajan, Lonce L. Wyse, and Michael A. Cohen. ARTSTREAM: a neural network model of auditory scene analysis and source segregation. Neural Networks, 17(4):511-536, 2004.</p>
<p>The Resonant Dynamics of Speech Perception: Interword Integration and Duration-Dependent Backward Effects. Stephen Grossberg, Christopher W Myers, Psychol. Rev. 1074Stephen Grossberg and Christopher W. Myers. The Resonant Dynamics of Speech Perception: Interword Integration and Duration-Dependent Backward Effects. Psychol. Rev., 107(4), 2015.</p>
<p>Sleep deprivation and sustained attention performance: Integrating mathematical and cognitive modeling. Glenn Gunzelmann, Joshua B Gross, Kevin A Gluck, David F Dinges, Cogn. Sci. 335Glenn Gunzelmann, Joshua B. Gross, Kevin A. Gluck, and David F. Dinges. Sleep deprivation and sustained attention performance: Integrating mathematical and cognitive modeling. Cogn. Sci., 33(5):880-910, 2009.</p>
<p>The OpenNARS implementation of the Non-Axiomatic Reasoning System. Patrick Hammer, Tony Lofthouse, Pei Wang, In Int. Conf. Artif. Gen. Intell. Patrick Hammer, Tony Lofthouse, and Pei Wang. The OpenNARS implementation of the Non-Axiomatic Reasoning System. In Int. Conf. Artif. Gen. Intell., 2016.</p>
<p>Guiding probabilistic logical inference with nonlinear dynamical attention allocation. Cosmo Harrigan, Ben Goertzel, Matthew Ikle, Amen Belayneh, Gino Yu, In Int. Conf. Artif. Gen. Intell. Cosmo Harrigan, Ben Goertzel, Matthew Ikle, Amen Belayneh, and Gino Yu. Guiding probabilistic logical inference with nonlinear dynamical attention allocation. In Int. Conf. Artif. Gen. Intell., pages 238-241, 2014.</p>
<p>Evaluation and Application of MIDAS v2.0. SAE Tech. Sandra Hart, David Dahn, Adolph Atencio, Michael K Dalal, Sandra Hart, David Dahn, Adolph Atencio, and Michael K. Dalal. Evaluation and Application of MIDAS v2.0. SAE Tech. Pap. 2001-01-2648, 2001.</p>
<p>Danijel Skocaj, Alen Vrecko, Nikodem Majer, and Michael Zillich. The Playmate System. Nick Hawes, Jeremy L Wyatt, Mohan Sridharan, Marek Kopicki, Somboon Hongeng, Ian Calvert, Aaron Sloman, Geert-Jan Kruijff, Henrik Jacobsson, Michael Brenner, Cogn. SystNick Hawes, Jeremy L. Wyatt, Mohan Sridharan, Marek Kopicki, Somboon Hongeng, Ian Calvert, Aaron Sloman, Geert- Jan Kruijff, Henrik Jacobsson, Michael Brenner, Danijel Skocaj, Alen Vrecko, Nikodem Majer, and Michael Zillich. The Playmate System. In Cogn. Syst. 2010.</p>
<p>Hierarchical temporal memory: Theory and applications. Jeff Hawkins, Dileep George, Jeff Hawkins and Dileep George. Hierarchical temporal memory: Theory and applications, 2006.</p>
<p>A domain-specific software architecture for a class of intelligent patient monitoring agents. Barbara Hayes-Roth, J. Exp. Theor. Artif. Intell. 82Barbara Hayes-Roth. A domain-specific software architecture for a class of intelligent patient monitoring agents. J. Exp. Theor. Artif. Intell., 8(2), 1996.</p>
<p>Directed Improvisation by Computer Characters. Barbara Hayes-Roth, Lee Brownston, Erik Sincoff, Proc. Int. Jt. Conf. Artif. Intell. Int. Jt. Conf. Artif. IntellBarbara Hayes-Roth, Lee Brownston, and Erik Sincoff. Directed Improvisation by Computer Characters. In Proc. Int. Jt. Conf. Artif. Intell., 1995.</p>
<p>Plans and Behavior in Intelligent Agents. Barbara Hayes-Roth, Philippe Lalanda, Philippe Morignot, Karl Pfleger, Marko Balabanovic, KSL Rep. Barbara Hayes-Roth, Philippe Lalanda, Philippe Morignot, Karl Pfleger, and Marko Balabanovic. Plans and Behavior in Intelligent Agents. KSL Rep. No. 93-43, 1993.</p>
<p>Guardian: A prototype intelligent agent for intensive-care monitoring. Barbara Hayes-Roth, Richard Washington, David Ash, Rattikorn Hewett, Anne Collinot, Angel Vina, Adam Seiver, Artif. Intell. Med. 42Barbara Hayes-Roth, Richard Washington, David Ash, Rattikorn Hewett, Anne Collinot, Angel Vina, and Adam Seiver. Guardian: A prototype intelligent agent for intensive-care monitoring. Artif. Intell. Med., 4(2):165-185, 1992.</p>
<p>An integrative account of memory and reasoning phenomena. Sebastien Helie, Ron Sun, New Ideas Psychol. 351Sebastien Helie and Ron Sun. An integrative account of memory and reasoning phenomena. New Ideas Psychol., 35(1):36- 52, 2014.</p>
<p>Probabilistic Logic Based Reinforcement Learning of Simple Embodied Behaviors in a. Ari Heljakka, Ben Goertzel, Welter Silva, Cassio Pennachin, Andre Senna, Izabela Goertzel, 3D Simulation World. Front. Artifical Intell. Appl. 157Ari Heljakka, Ben Goertzel, Welter Silva, Cassio Pennachin, Andre Senna, and Izabela Goertzel. Probabilistic Logic Based Reinforcement Learning of Simple Embodied Behaviors in a 3D Simulation World. Front. Artifical Intell. Appl., 157:253-275, 2007.</p>
<p>The Cognitive Symmetry Engine: An Active Approach to Knowledge. T C Henderson, H Peng, K Sikorski, N Deshpande, E Grant, Proc. IROS. IROST. C. Henderson, H. Peng, K. Sikorski, N. Deshpande, and E. Grant. The Cognitive Symmetry Engine: An Active Approach to Knowledge. In Proc. IROS 2011 Work. Knowl. Represent. Auton. Robot., 2011.</p>
<p>The Cognitive Symmetry Engine. C Thomas, Anshul Henderson, Joshi, UUCS-13-004Tech. Rep.Thomas C Henderson and Anshul Joshi. The Cognitive Symmetry Engine. Tech. Rep. UUCS-13-004, 2013.</p>
<p>Integrating theories of motor sequencing in the SAL hybrid architecture. Seth Herd, Andrew Szabados, Yury Vinokurov, Christian Lebiere, Ashley Cline, Randall C O&apos;reilly, Biol. Inspired Cogn. Archit. 8Seth Herd, Andrew Szabados, Yury Vinokurov, Christian Lebiere, Ashley Cline, and Randall C. O'Reilly. Integrating theories of motor sequencing in the SAL hybrid architecture. Biol. Inspired Cogn. Archit., 8:98-106, 2014.</p>
<p>Shmiming: It's About Knowing When &amp; Why Stimulated Memory Representations Become Active. E , Tory Higgins, Baruch Eitam, Priming, Soc. Cogn. 32E. Tory Higgins and Baruch Eitam. Priming. . . Shmiming: It's About Knowing When &amp; Why Stimulated Memory Rep- resentations Become Active. Soc. Cogn., 32:1-33, 2014.</p>
<p>An Overview of Strategies for Neurosymbolic Integration. Melanie Hilario, Connect. Integr. From unified to hybrid approaches. Ron Sun and Frederic AlexandrePsychology PressMelanie Hilario. An Overview of Strategies for Neurosymbolic Integration. In Ron Sun and Frederic Alexandre, editors, Connect. Integr. From unified to hybrid approaches, pages 13-35. Psychology Press, 1997.</p>
<p>Analogical learning in a turn-based strategy game. R Thomas, Kenneth D Hinrichs, Forbus, Proc. Int. Jt. Conf. Artif. Intell. Int. Jt. Conf. Artif. IntellThomas R. Hinrichs and Kenneth D. Forbus. Analogical learning in a turn-based strategy game. In Proc. Int. Jt. Conf. Artif. Intell., pages 853-858, 2007.</p>
<p>X Goes First: Teaching Simple Games through Multimodal Interaction. R Thomas, Kenneth D Hinrichs, Forbus, Adv. Cogn. Syst. 3218Thomas R. Hinrichs and Kenneth D. Forbus. X Goes First: Teaching Simple Games through Multimodal Interaction. Adv. Cogn. Syst., 3:218, 2014.</p>
<p>How could a COPYCAT ever be creative? AAAI Tech. Douglas Hofstadter, Rep. SS-93-01. Douglas Hofstadter. How could a COPYCAT ever be creative? AAAI Tech. Rep. SS-93-01, pages 8-21, 1993.</p>
<p>The Neural Basis of Human Error Processing: Reinforcement Learning, Dopamine, and the Error-Related Negativity. B Clay, Holroyd, G H Michael, Coles, Psychol. Rev. 1094Clay B. Holroyd and Michael G. H. Coles. The Neural Basis of Human Error Processing: Reinforcement Learning, Dopamine, and the Error-Related Negativity. Psychol. Rev., 109(4):679-709, 2002.</p>
<p>A Hierarchical World Model for an Autonomous Scout Vehicle. Hong Tsai, Stephen B Hong, Elena Balakirsky, Tommy Messina, Michael Chang, Shneier, 16th Annu. Int. Symp. Aerospace/Defense Sensing. Tsai Hong Hong, Stephen B. Balakirsky, Elena Messina, Tommy Chang, and Michael Shneier. A Hierarchical World Model for an Autonomous Scout Vehicle. In 16th Annu. Int. Symp. Aerospace/Defense Sensing, Simulation, Control. (SPIE 2002), pages 343-354, 2002.</p>
<p>Human Modelling in Assisted Transportation. Becky L Hooey, Brian F Gore, Christopher D Wickens, Shelly Scott-Nash, Connie M Socash, Ellen Salud, David C Foyle, In Proceeding Hum. Model. Assist. Transp. Conf. Becky L. Hooey, Brian F. Gore, Christopher D. Wickens, Shelly Scott-Nash, Connie M. Socash, Ellen Salud, and David C. Foyle. Human Modelling in Assisted Transportation. In Proceeding Hum. Model. Assist. Transp. Conf., pages 327-333, 2010.</p>
<p>Inherent Value Systems for Autonomous Mental Development. Xiao Huang, Juyang Weng, Int. J. Humanoid Robot. 42Xiao Huang and Juyang Weng. Inherent Value Systems for Autonomous Mental Development. Int. J. Humanoid Robot., 4(2):407-433, 2007.</p>
<p>This time with feeling: Integrated model of trait and state effects on cognition and behavior. Eva Hudlicka, Appl. Artif. Intell. 16Eva Hudlicka. This time with feeling: Integrated model of trait and state effects on cognition and behavior. Appl. Artif. Intell., 16:611-641, 2002.</p>
<p>Modeling Effects of Emotion and Personality on Political Decision-Making. Eva Hudlicka, Program. Peace. SpringerEva Hudlicka. Modeling Effects of Emotion and Personality on Political Decision-Making. In Program. Peace, pages 355-411. Springer, 2006.</p>
<p>Modeling the mechanisms of emotion effects on cognition. Eva Hudlicka, Proc. AAAI Fall Symp. AAAI Fall SympEva Hudlicka. Modeling the mechanisms of emotion effects on cognition. In Proc. AAAI Fall Symp. Biol. Inspired Cogn. Archit., pages 82-86, 2008.</p>
<p>Modeling Cultural and Personality Biases in Decision Making. Eva Hudlicka, Proc. 3rd Int. Conf. Appl. Hum. Factors Ergon. 3rd Int. Conf. Appl. Hum. Factors ErgonEva Hudlicka. Modeling Cultural and Personality Biases in Decision Making. In Proc. 3rd Int. Conf. Appl. Hum. Factors Ergon., 2010.</p>
<p>Affect, Risk and Uncertainty in Decision-Making. An Integrated Computational-Empirical Approach. Final Rep. Eva Hudlicka, Gerald Matthews, Eva Hudlicka and Gerald Matthews. Affect, Risk and Uncertainty in Decision-Making. An Integrated Computational- Empirical Approach. Final Rep., 2009.</p>
<p>Increasing realism of human agents by modeling individual differences: Methodology, architecture, and testbed. Simulating Hum. Agents. Eva Hudlicka, Greg Zacharias, Joseph Psotka, Am. Assoc. Artif. Intell. Fall. Symp. Ser.Eva Hudlicka, Greg Zacharias, and Joseph Psotka. Increasing realism of human agents by modeling individual differences: Methodology, architecture, and testbed. Simulating Hum. Agents, Am. Assoc. Artif. Intell. Fall 2000 Symp. Ser., pages 53-59, 2000.</p>
<p>Cognitive architecture for mixed human-machine team interactions for space exploration. Terry Huntsberger, IEEE Aerosp. Conf. Proc. Terry Huntsberger. Cognitive architecture for mixed human-machine team interactions for space exploration. In IEEE Aerosp. Conf. Proc., 2011.</p>
<p>Stereo vision-based navigation for autonomous surface vessels. Terry Huntsberger, Hrand Aghazarian, Andrew Howard, David C Trotz, J. F. Robot. 281Terry Huntsberger, Hrand Aghazarian, Andrew Howard, and David C. Trotz. Stereo vision-based navigation for au- tonomous surface vessels. J. F. Robot., 28(1):3-18, 2011.</p>
<p>Intelligent Autonomy for Unmanned Surface and Underwater Vehicles. Terry Huntsberger, Gail Woodward, Proc. Ocean. OceanTerry Huntsberger and Gail Woodward. Intelligent Autonomy for Unmanned Surface and Underwater Vehicles. In Proc. Ocean., pages 1-10, 2011.</p>
<p>Exploring Moral Reasoning in a Cognitive Architecture. Wayne Iba, Pat Langley, Proc. 33rd Annu. Meet. 33rd Annu. MeetWayne Iba and Pat Langley. Exploring Moral Reasoning in a Cognitive Architecture. In Proc. 33rd Annu. Meet. Cogn. Sci. Soc., pages 3381-3386, 2011.</p>
<p>Nonlinear-dynamical attention allocation via information geometry. Matthew Ikle, Ben Goertzel, In Int. Conf. Artif. Gen. Intell. Matthew Ikle and Ben Goertzel. Nonlinear-dynamical attention allocation via information geometry. In Int. Conf. Artif. Gen. Intell., 2011.</p>
<p>A Model of Saliency-Based Visual Attention for Rapid Scene Analysis. Laurent Itti, Christof Koch, Ernst Niebur, IEEE Trans. Pattern Anal. Mach. Intell. 2011Laurent Itti, Christof Koch, and Ernst Niebur. A Model of Saliency-Based Visual Attention for Rapid Scene Analysis. IEEE Trans. Pattern Anal. Mach. Intell., 20(11):1254-1259, 1998.</p>
<p>Perception and human interaction for developmental learning of objects and affordances. Serena Ivaldi, Natalia Lyubova, Damien Gerardeaux-Viret, Alain Droniou, Salvatore M Anzalone, Mohamed Chetouani, David Filliat, Olivier Sigaud, IEEE-RAS Int. Conf. Humanoid Robot. Serena Ivaldi, Natalia Lyubova, Damien Gerardeaux-Viret, Alain Droniou, Salvatore M. Anzalone, Mohamed Chetouani, David Filliat, and Olivier Sigaud. Perception and human interaction for developmental learning of objects and affordances. In IEEE-RAS Int. Conf. Humanoid Robot., pages 248-254, 2012.</p>
<p>Object learning through active exploration. Serena Ivaldi, Natalia Sao Mai Nguyen, Alain Lyubova, Vincent Droniou, David Padois, Pierre Yves Filliat, Olivier Oudeyer, Sigaud, EEE Trans. Auton. Ment. Dev. 61Serena Ivaldi, Sao Mai Nguyen, Natalia Lyubova, Alain Droniou, Vincent Padois, David Filliat, Pierre Yves Oudeyer, and Olivier Sigaud. Object learning through active exploration. EEE Trans. Auton. Ment. Dev., 6(1):56-72, 2014.</p>
<p>Building Internal Scene Representation in Cognitive Agents. Marek Jaszuk, A Janusz, Starzyk, Knowledge, Inf. Creat. Support Syst. Recent Trends. Marek Jaszuk and Janusz A Starzyk. Building Internal Scene Representation in Cognitive Agents. In Knowledge, Inf. Creat. Support Syst. Recent Trends, Adv. Solut., pages 479-491. 2016.</p>
<p>SAL: An explicitly pluralistic cognitive architecture. David J Jilk, Christian Lebiere, Randall C O&apos;reily, John R Anderson, J. Exp. Theor. Artif. Intell. 203David J. Jilk, Christian Lebiere, Randall C. O'Reily, and John R. Anderson. SAL: An explicitly pluralistic cognitive architecture. J. Exp. Theor. Artif. Intell., 20(3):197-218, 2008.</p>
<p>Automated Intelligent Pilots for Combat Flight Simulation. Randolph M Jones, John E Laird, Paul E Nielsen, Karen J Coulter, Patrick Kenny, Frank V Koss, AI Mag. 201Randolph M. Jones, John E. Laird, Paul E. Nielsen, Karen J. Coulter, Patrick Kenny, and Frank V. Koss. Automated Intelligent Pilots for Combat Flight Simulation. AI Mag., 20(1):27-42, 1999.</p>
<p>Efficient Computation of Spreading Activation Using Lazy Evaluation. J Steven, Arthur R Jones, John E Wandzel, Laird, Proc. Int. Conf. Cogn. Model. Int. Conf. Cogn. ModelSteven J. Jones, Arthur R. Wandzel, and John E. Laird. Efficient Computation of Spreading Activation Using Lazy Evaluation. In Proc. Int. Conf. Cogn. Model., 2016.</p>
<p>A capacity theory of comprehension: Individual differences in working memory. Marcel Adam Just, Patricia A Carpenter, Psychol. Rev. 991Marcel Adam Just and Patricia A. Carpenter. A capacity theory of comprehension: Individual differences in working memory. Psychol. Rev., 99(1):122-149, 1992.</p>
<p>The organization of thinking: What functional brain imaging reveals about the neuroarchitecture of complex cognition. Marcel Adam Just, Sashank Varma, Cogn. Affect. Behav. Neurosci. 73Marcel Adam Just and Sashank Varma. The organization of thinking: What functional brain imaging reveals about the neuroarchitecture of complex cognition. Cogn. Affect. Behav. Neurosci., 7(3):153-191, 2007.</p>
<p>Radek Pibil, Radim Vansa, and Cyril Brom. Extensions and applications of Pogamut 3 platform. Rudolf Kadlec, Jakub Gemrot, Michal Bida, Ondrej Burkert, Jan Havlicek, Lukas Zemcak, In Int. Work. Intell. Virtual Agents. Rudolf Kadlec, Jakub Gemrot, Michal Bida, Ondrej Burkert, Jan Havlicek, Lukas Zemcak, Radek Pibil, Radim Vansa, and Cyril Brom. Extensions and applications of Pogamut 3 platform. In Int. Work. Intell. Virtual Agents, 2009.</p>
<p>Back to Bentham? Explorations of Experienced Utility. D Kahneman, P Wakker, R Sarin, Quaterly J. Econ. 1122D. Kahneman, P. Wakker, and R. Sarin. Back to Bentham? Explorations of Experienced Utility. Quaterly J. Econ., 112(2):375-405, 1997.</p>
<p>A Cooperative Robotic Aid System. K Kawamura, M Cambron, K Fujiwara, J Barile, Proc. Conf. Virtual Real. Syst. Teleoperation Beyond Speech Recognit. Conf. Virtual Real. Syst. Teleoperation Beyond Speech RecognitK. Kawamura, M. Cambron, K. Fujiwara, and J. Barile. A Cooperative Robotic Aid System. In Proc. Conf. Virtual Real. Syst. Teleoperation Beyond Speech Recognit., 1993.</p>
<p>Implementation of Cognitive Control for a Humanoid Robot. Kazuhiko Kawamura, Stephen M Gordon, Palis Ratanaswasd, Erdem Erdemir, Joseph F Hall, Int. J. Humanoid Robot. 54Kazuhiko Kawamura, Stephen M. Gordon, Palis Ratanaswasd, Erdem Erdemir, and Joseph F. Hall. Implementation of Cognitive Control for a Humanoid Robot. Int. J. Humanoid Robot., 5(4):547-586, 2008.</p>
<p>A Parallel Distributed Cognitive Control System for a Humanoid Robot. Kazuhiko Kawamura, R Peters, Robert E Bodenheimer, Nilanjan Sarkar, Juyi Park, Charles A Clifton, Albert W Spratley, Int. J. Humanoid Robot. 11Kazuhiko Kawamura, R. Alan II Peters, Robert E. Bodenheimer, Nilanjan Sarkar, Juyi Park, Charles A. Clifton, and Albert W. Spratley. A Parallel Distributed Cognitive Control System for a Humanoid Robot. Int. J. Humanoid Robot., 1(1):65-93, 2004.</p>
<p>AG-ART: An adaptive approach to evolvong ART architectures. Assem Kaylani, Michael Georgiopoulos, Mansooreh Mollaghasemi, Georgios C Anagnostopoulos, Neurocomputing. 72Assem Kaylani, Michael Georgiopoulos, Mansooreh Mollaghasemi, and Georgios C. Anagnostopoulos. AG-ART: An adaptive approach to evolvong ART architectures. Neurocomputing, 72:2079-2092, 2009.</p>
<p>There is No Free Lunch: Tradeoffs in the Utility of Learned Knowledge. T Smadar, Kathleen B Kedar, Mckusick, Proc. First Int. Conf. First Int. ConfSmadar T. Kedar and Kathleen B. McKusick. There is No Free Lunch: Tradeoffs in the Utility of Learned Knowledge. In Proc. First Int. Conf. Artif. Intell. Plan. Syst., pages 281-282, 1992.</p>
<p>Symbolic and Sub-Symbolic Representations in Computational Models of Human Cognition: What Can be Learned from Biology?. Troy D Kelley, Theory Psychol. 136Troy D. Kelley. Symbolic and Sub-Symbolic Representations in Computational Models of Human Cognition: What Can be Learned from Biology? Theory Psychol., 13(6):847-860, 2003.</p>
<p>Characteristics of Long-Term Learning in Soar and its Application to the Utility Problem. W G Kennedy, K A Jong, Proc. fifth Int. Conf. Mach. Learn. W. G. Kennedy and K. A. De Jong. Characteristics of Long-Term Learning in Soar and its Application to the Utility Problem. Proc. fifth Int. Conf. Mach. Learn., pages 337-344, 2003.</p>
<p>Modeling Visual Search of Displays of Many Objects: The Role of Differential Acuity and Fixation Memory. David Kieras, Proc. 10th Int. Conf. Cogn. Model. 10th Int. Conf. Cogn. ModelDavid Kieras. Modeling Visual Search of Displays of Many Objects: The Role of Differential Acuity and Fixation Memory. Proc. 10th Int. Conf. Cogn. Model., 2010.</p>
<p>The Control of Cognition. David Kieras, Integr. Model. Cogn. Syst. W. GrayOxford University PressDavid Kieras. The Control of Cognition. In W. Gray, editor, Integr. Model. Cogn. Syst. Oxford University Press, 2012.</p>
<p>EPIC Architecture Principles of Operation. David E Kieras, David E. Kieras. EPIC Architecture Principles of Operation, 2004.</p>
<p>Towards accurate and practical predictive models of active-vision-based visual search. David E Kieras, Anthony J Hornof, Proc. Conf. Hum. Factors Comput. Syst. Conf. Hum. Factors Comput. SystDavid E. Kieras and Anthony J. Hornof. Towards accurate and practical predictive models of active-vision-based visual search. In Proc. Conf. Hum. Factors Comput. Syst., pages 3875-3884, 2014.</p>
<p>The Role of Cognitive Task Analysis in the Application of Predictive Models of Human Performance. David E Kieras, David E Meyer, David E. Kieras and David E. Meyer. The Role of Cognitive Task Analysis in the Application of Predictive Models of Human Performance. Epic Rep. No. 11, 1998.</p>
<p>Modeling Two-Channel Speech Processing With the EPIC Cognitive Architecture. David E Kieras, Gregory H Wakefield, Eric R Thompson, Nandini Iyer, Brian D Simpson, Top. Cogn. Sci. 81David E. Kieras, Gregory H. Wakefield, Eric R. Thompson, Nandini Iyer, and Brian D. Simpson. Modeling Two-Channel Speech Processing With the EPIC Cognitive Architecture. Top. Cogn. Sci., 8(1):291-304, 2016.</p>
<p>Intelligent Reasoning on Natural Language Data: A Non-Axiomatic Reasoning System Approach. Ozkan Kilic, PhD ThesisOzkan Kilic. Intelligent Reasoning on Natural Language Data: A Non-Axiomatic Reasoning System Approach. PhD Thesis, 2015.</p>
<p>Interactive Task Learning for Simple Games. James R Kirk, John E Laird, Adv. Cogn. Syst. 3James R. Kirk and John E. Laird. Interactive Task Learning for Simple Games. Adv. Cogn. Syst., 3:13-30, 2014.</p>
<p>Learning General and Efficient Representations of Novel Games Through Interactive Instruction. James R Kirk, John E Laird, Adv. Cogn. Syst. 4James R. Kirk and John E. Laird. Learning General and Efficient Representations of Novel Games Through Interactive Instruction. Adv. Cogn. Syst., 4, 2016.</p>
<p>The Interplay of Analogy-Making with Active Vision and Motor Control in Anticipatory Robots. Kiril Kiryazov, Georgi Petkov, Maurice Grinberg, Boicho Kokinov, Christian Balkenius, Work. Anticip. Behav. Adapt. Learn. Syst. Kiril Kiryazov, Georgi Petkov, Maurice Grinberg, Boicho Kokinov, and Christian Balkenius. The Interplay of Analogy- Making with Active Vision and Motor Control in Anticipatory Robots. Work. Anticip. Behav. Adapt. Learn. Syst., pages 233-253, 2007.</p>
<p>Dynamics of emergent computation in DUAL. Boicho Kokinov, Vassil Nikolov, Alexander Petrov, Artif. Intell. Methodol. Syst. Appl. Boicho Kokinov, Vassil Nikolov, and Alexander Petrov. Dynamics of emergent computation in DUAL. Artif. Intell. Methodol. Syst. Appl., 1996.</p>
<p>Associative Memory-Based Reasoning: Some Experimental Results. Kokinov Boicho Nikolov, Proc. twelfth Annu. Conf. twelfth Annu. ConfBoicho Nikolov Kokinov. Associative Memory-Based Reasoning: Some Experimental Results. In Proc. twelfth Annu. Conf. Cogn. Sci. Soc., 1990.</p>
<p>The DUAL Cognitive Architecture: A Hybrid Multi-Agent Approach. Kokinov Boicho Nikolov, Proc. 11th Eur. Conf. Artif. Intell. 11th Eur. Conf. Artif. IntellBoicho Nikolov Kokinov. The DUAL Cognitive Architecture: A Hybrid Multi-Agent Approach. In Proc. 11th Eur. Conf. Artif. Intell., 1994.</p>
<p>Defeasible Reasoning. Robert Koons, Robert Koons. Defeasible Reasoning, 2017.</p>
<p>Object recognition using saliency maps and HTM learning. Ioannis Kostavelis, Lazaros Nalpantidis, Antonios Gasteratos, Proc. IEEE Int. Conf. Imaging Syst. Tech. IEEE Int. Conf. Imaging Syst. TechIoannis Kostavelis, Lazaros Nalpantidis, and Antonios Gasteratos. Object recognition using saliency maps and HTM learning. In Proc. IEEE Int. Conf. Imaging Syst. Tech., pages 528-532, 2012.</p>
<p>Visual Attention in Dynamic Environments and Its Application To Playing Online Games. Iuliia Kotseruba, MSc ThesisIuliia Kotseruba. Visual Attention in Dynamic Environments and Its Application To Playing Online Games. MSc Thesis, 2016.</p>
<p>Modeling Behavior of Attention-Deficit-Disorder Patients in a N-Back Task. Jonathan Kottlors, Daniel Brand, Marco Ragni, Proc. 11th Int. Conf. Cogn. Model. (ICCM 2012). 11th Int. Conf. Cogn. Model. (ICCM 2012)Jonathan Kottlors, Daniel Brand, and Marco Ragni. Modeling Behavior of Attention-Deficit-Disorder Patients in a N-Back Task. In Proc. 11th Int. Conf. Cogn. Model. (ICCM 2012), pages 297-302, 2012.</p>
<p>Design principles for biologically inspired cognitive robotics. Jeffrey L Krichmar, Biol. Inspired Cogn. Archit. 1Jeffrey L. Krichmar. Design principles for biologically inspired cognitive robotics. Biol. Inspired Cogn. Archit., 1:73-81, 2012.</p>
<p>Brain-based devices for the study of nervous systems and the development of intelligent machines. L Jeffrey, Gerald M Krichmar, Edelman, Artif. Life. 111-2Jeffrey L. Krichmar and Gerald M. Edelman. Brain-based devices for the study of nervous systems and the development of intelligent machines. Artif. Life, 11(1-2):63-77, 2005.</p>
<p>Characterizing functional hippocampal pathways in a brain-based device as it solves a spatial memory task. Jeffrey L Krichmar, Douglas A Nitz, Joseph A Gally, Gerald M Edelman, Proc. Natl. Acad. Sci. U. S. A. 1026Jeffrey L. Krichmar, Douglas A. Nitz, Joseph A. Gally, and Gerald M. Edelman. Characterizing functional hippocampal pathways in a brain-based device as it solves a spatial memory task. Proc. Natl. Acad. Sci. U. S. A., 102(6):2111-2116, 2005.</p>
<p>A neural approach to adaptive behavior and multi-sensor action selection in a mobile device. L Jeffrey, James A Krichmar, Snook, Proc. IEEE Int. Conf. Robot. Autom. IEEE Int. Conf. Robot. AutomJeffrey L. Krichmar and James A. Snook. A neural approach to adaptive behavior and multi-sensor action selection in a mobile device. In Proc. IEEE Int. Conf. Robot. Autom., 2002.</p>
<p>Integrating Planning, Execution, and Learning. Daniel R Kuokka, Proc. NASA Conf. Sp. Telerobotics. NASA Conf. Sp. TeleroboticsDaniel R Kuokka. Integrating Planning, Execution, and Learning. In Proc. NASA Conf. Sp. Telerobotics, pages 377-386, 1989.</p>
<p>MAX: A Meta-Reasoning Architecture for. Daniel R Kuokka, SIGART Bull. 24Daniel R. Kuokka. MAX: A Meta-Reasoning Architecture for "X". SIGART Bull., 2(4):93-97, 1991.</p>
<p>An architectural framework for complex cognition. Unmesh Kurup, G Perrin, J R Bignoli, Nicholas L Scally, Cassimatis, Cogn. Syst. Res. 123-4Unmesh Kurup, Perrin G. Bignoli, J. R. Scally, and Nicholas L. Cassimatis. An architectural framework for complex cognition. Cogn. Syst. Res., 12(3-4):281-292, 2011.</p>
<p>Integrating intelligent computer generated forces in distributed simulations: TacAir-Soar in STOW-97. J E Laird, K J Coulter, R M Jones, P G Kenny, Frank Koss, P E Nielsen, Proc. Spring Simul. Interoperability Work. Spring Simul. Interoperability WorkJ. E. Laird, K. J. Coulter, R. M. Jones, P. G. Kenny, Frank Koss, and P. E. Nielsen. Integrating intelligent computer generated forces in distributed simulations: TacAir-Soar in STOW-97. In Proc. Spring Simul. Interoperability Work., 1998.</p>
<p>A Standard Model for the Mind: Toward a Common Computational Framework across Artificial Intelligence. J E Laird, C Lebiere, P S Rosenbloom, Neuroscience, and Robotics. AI Mag. Cognitive Science. In pressJ. E. Laird, C. Lebiere, and P. S. Rosenbloom. A Standard Model for the Mind: Toward a Common Computational Framework across Artificial Intelligence, Cognitive Science, Neuroscience, and Robotics. AI Mag., In press, 2017.</p>
<p>A case study of knowledge integration across multiple memories in Soar. J E Laird, S Mohan, Biol. Inspired Cogn. Archit. 8J. E. Laird and S. Mohan. A case study of knowledge integration across multiple memories in Soar. Biol. Inspired Cogn. Archit., 8:93-99, 2014.</p>
<p>Towards chunking as a general learning mechanism. J E Laird, P S Rosenbloom, A Newell, AAAI Proc. J. E. Laird, P. S. Rosenbloom, and A. Newell. Towards chunking as a general learning mechanism. In AAAI Proc., pages 188-192, 1984.</p>
<p>The Soar Cognitive Architecture. E John, Laird, MIT PressJohn E Laird. The Soar Cognitive Architecture. MIT Press, 2012.</p>
<p>The Soar Cognitive Architecture. John E Laird, AISB Q. 171134John E. Laird. The Soar Cognitive Architecture. AISB Q., 171(134):224-235, 2012.</p>
<p>Cognitive Robotics Using the Soar Cognitive Architecture. John E Laird, R Keegan, Shiwali Kinkade, Joseph Z Mohan, Xu, Proc. 6th Int. Conf. Cogn. Model. 6th Int. Conf. Cogn. ModelJohn E. Laird, Keegan R. Kinkade, Shiwali Mohan, and Joseph Z. Xu. Cognitive Robotics Using the Soar Cognitive Architecture. In Proc. 6th Int. Conf. Cogn. Model., pages 226-330, 2004.</p>
<p>Robo-Soar: An integration of external interaction, planning, and learning using Soar. John E Laird, Eric S Yager, Michael Hucka, Christopher M Tuck, Rob. Auton. Syst. 81-2John E. Laird, Eric S. Yager, Michael Hucka, and Christopher M. Tuck. Robo-Soar: An integration of external interaction, planning, and learning using Soar. Rob. Auton. Syst., 8(1-2):113-129, 1991.</p>
<p>How Much Do People Remember ! Some Estimates of the Quantity of Learned Information in Long-term Memory. K Landauer, Cogn. Sci. 493K Landauer. How Much Do People Remember ! Some Estimates of the Quantity of Learned Information in Long-term Memory. Cogn. Sci., 493:477-493, 1986.</p>
<p>Attention mechanisms in the CHREST cognitive architecture. C R Peter, Fernand Lane, Richard Ll Gobet, Smith, Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics). 5395Peter C R Lane, Fernand Gobet, and Richard Ll Smith. Attention mechanisms in the CHREST cognitive architecture. Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), 5395 LNAI:183-196, 2009.</p>
<p>Combining Low-Level Perception with Expectations in CHREST. C R Peter, Anthony Lane, Fernand Sykes, Gobet, Proc. Eur. EurPeter C. R. Lane, Anthony Sykes, and Fernand Gobet. Combining Low-Level Perception with Expectations in CHREST. In Proc. Eur. Cogn. Sci. Conf., pages 205-210, 2003.</p>
<p>Interleaving Learning, Problem Solving, and Execution in the ICARUS Architecture. Pat Langley, Dongkyu Choi, Seth Rogers, Comput. Learn. Lab. Tech. ReportPat Langley, Dongkyu Choi, and Seth Rogers. Interleaving Learning, Problem Solving, and Execution in the ICARUS Architecture. Tech. Report, Comput. Learn. Lab., 2005.</p>
<p>Hierarchical skills and cognitive architectures. Pat Langley, Kirstin Cummings, Daniel Shapiro, Proc. 26th Annu. Conf. 26th Annu. ConfPat Langley, Kirstin Cummings, and Daniel Shapiro. Hierarchical skills and cognitive architectures. In Proc. 26th Annu. Conf. Cogn. Sci. Soc., pages 779-784, 2004.</p>
<p>Cognitive architectures: Research issues and challenges. Pat Langley, John E Laird, Seth Rogers, Cogn. Syst. Res. 102Pat Langley, John E. Laird, and Seth Rogers. Cognitive architectures: Research issues and challenges. Cogn. Syst. Res., 10(2):141-160, 2009.</p>
<p>An Extended Theory of Human Problem Solving. Pat Langley, Seth Rogers, Proc. 27th Annu. Meet. 27th Annu. MeetPat Langley and Seth Rogers. An Extended Theory of Human Problem Solving. In Proc. 27th Annu. Meet. Cogn. Sci. Soc., pages 166-186, 2008.</p>
<p>A Lavin, S Ahmad, J Hawkins, Sparse Distributed Representations. A. Lavin, S. Ahmad, and J. Hawkins. Sparse Distributed Representations, 2016.</p>
<p>Evaluating Real-time Anomaly Detection Algorithms -the Numenta Anomaly Benchmark. Alexander Lavin, Subutai Ahmad, Proc. the14th Int. Conf. the14th Int. ConfAlexander Lavin and Subutai Ahmad. Evaluating Real-time Anomaly Detection Algorithms -the Numenta Anomaly Benchmark. In Proc. the14th Int. Conf. Mach. Learn. Appl., 2015.</p>
<p>A functional model of sensemaking in a neurocognitive architecture. Christian Lebiere, Peter Pirolli, Robert Thomson, Jaehyon Paik, Matthew Rutledge-Taylor, James Staszewski, John R Anderson, Comput. Intell. Neurosci. Christian Lebiere, Peter Pirolli, Robert Thomson, Jaehyon Paik, Matthew Rutledge-Taylor, James Staszewski, and John R. Anderson. A functional model of sensemaking in a neurocognitive architecture. Comput. Intell. Neurosci., 2013, 2013.</p>
<p>An integrated, modular framework for computer vision and cognitive robotics research (icVision). Jorgen Leitner, Simon Harding, Mikhail Frank, Alexander Forster, Jorgen Schmidhuber, Adv. Intell. Syst. Comput. Jorgen Leitner, Simon Harding, Mikhail Frank, Alexander Forster, and Jorgen Schmidhuber. An integrated, modular framework for computer vision and cognitive robotics research (icVision). Adv. Intell. Syst. Comput., pages 205-210, 2013.</p>
<p>Spreading Activation in an Attractor Network with Latching Dynamics: Automatic Semantic Priming Revisited. Itamar Lerner, Shlomo Bentin, Oren Shriki, Cogn. Sci. 368Itamar Lerner, Shlomo Bentin, and Oren Shriki. Spreading Activation in an Attractor Network with Latching Dynamics: Automatic Semantic Priming Revisited. Cogn. Sci., 36(8):1339-1382, 2012.</p>
<p>Recent developments in the NL-Soar garden path theory. R L Lewis, Tech. Rep. CR. L. Lewis. Recent developments in the NL-Soar garden path theory. Tech. Rep. C., 1992.</p>
<p>Sentence generation for artificial brains: A glocal similarity-matching approach. Ruiting Lian, Ben Goertzel, Rui Liu, Michael Ross, Murilo Queiroz, Linas Vepstas, Neurocomputing. 741-3Ruiting Lian, Ben Goertzel, Rui Liu, Michael Ross, Murilo Queiroz, and Linas Vepstas. Sentence generation for artificial brains: A glocal similarity-matching approach. Neurocomputing, 74(1-3):95-103, 2010.</p>
<p>Toward Integrating Cognitive Linguistics and Cognitive Language Processing. Peter Lindes, John E Laird, Proc. Int. Conf. Cogn. Model. Int. Conf. Cogn. ModelPeter Lindes and John E Laird. Toward Integrating Cognitive Linguistics and Cognitive Language Processing. In Proc. Int. Conf. Cogn. Model., 2016.</p>
<p>Salience-driven Contextual Priming of Speech Recognition for Human-Robot Interaction. Pierre Lison, Geert-Jan Kruijff, Language (Baltim). Pierre Lison and Geert-Jan Kruijff. Salience-driven Contextual Priming of Speech Recognition for Human-Robot Interac- tion. In Language (Baltim)., pages 636-640, 2008.</p>
<p>Piece of Mind: Long-Term Memory Structure in ACT-R and CHREST. Martyn Lloyd-Kelly, Fernand R Gobet, Peter C R Lane, Proc. 37th Annu. Meet. 37th Annu. MeetMartyn Lloyd-Kelly, Fernand R. Gobet, and Peter C. R. Lane. Piece of Mind: Long-Term Memory Structure in ACT-R and CHREST. In Proc. 37th Annu. Meet. Cogn. Sci. Soc., 2015.</p>
<p>The Effects of Bounding Rationality on the Performance and Learning of CHREST Agents in Tileworld. Martyn Lloyd-Kelly, C R Peter, Fernand Lane, Gobet, Res. Dev. Intell. Syst. XXXI. Max Bramer and Miltos PetridisMartyn Lloyd-Kelly, Peter C. R. Lane, and Fernand Gobet. The Effects of Bounding Rationality on the Performance and Learning of CHREST Agents in Tileworld. In Max Bramer and Miltos Petridis, editors, Res. Dev. Intell. Syst. XXXI. 2014.</p>
<p>Hybrid laser and vision based object search and localization. Dorian Gálvez López, Kristoffer Sjö, Chandana Paul, Patric Jensfelt, Proc. IEEE Int. Conf. Robot. Autom. Dorian Gálvez López, Kristoffer Sjö, Chandana Paul, and Patric Jensfelt. Hybrid laser and vision based object search and localization. Proc. IEEE Int. Conf. Robot. Autom., 2008.</p>
<p>NIST research in autonomous construction. Alan M Lytle, Kamel S Saidi, Auton. Robots. 223Alan M. Lytle and Kamel S. Saidi. NIST research in autonomous construction. Auton. Robots, 22(3):211-221, 2007.</p>
<p>Improving object learning through manipulation and robot selfidentification. Natalia Lyubova, David Filliat, Serena Ivaldi, Proceeding IEEE Int. Conf. Robot. Biomimetics. eeding IEEE Int. Conf. Robot. BiomimeticsNatalia Lyubova, David Filliat, and Serena Ivaldi. Improving object learning through manipulation and robot self- identification. In Proceeding IEEE Int. Conf. Robot. Biomimetics, 2013.</p>
<p>A LIDA-based model of the attentional blink. Tamas Madl, Stan Franklin, Proc. Int. Conf. Cogn. Model. Int. Conf. Cogn. ModelTamas Madl and Stan Franklin. A LIDA-based model of the attentional blink. In Proc. Int. Conf. Cogn. Model., pages 283-288, 2012.</p>
<p>Constrained Incrementalist Moral Decision Making for a Biologically Inspired Cognitive Architecture. Tamas Madl, Stan Franklin, ; A Constr, Man. Robot. Ethical Syst. Robert TrapplTamas Madl and Stan Franklin. Constrained Incrementalist Moral Decision Making for a Biologically Inspired Cognitive Architecture. In Robert Trappl, editor, A Constr. Man. Robot. Ethical Syst. 2015.</p>
<p>Towards real-world capable spatial memory in the LIDA cognitive architecture. Tamas Madl, Stan Franklin, Ke Chen, Daniela Montaldi, Robert Trappl, Biol. Inspired Cogn. Archit. 16Tamas Madl, Stan Franklin, Ke Chen, Daniela Montaldi, and Robert Trappl. Towards real-world capable spatial memory in the LIDA cognitive architecture. Biol. Inspired Cogn. Archit., 16, 2015.</p>
<p>An embodied biologically constrained model of foraging: From classical and operant conditioning to adaptive real-world behavior in DAC-X. Giovanni Maffei, Diogo Santos-Pata, Encarni Marcos, Marti Sánchez-Fibla, Paul F M J Verschure, Neural Networks. 72Giovanni Maffei, Diogo Santos-Pata, Encarni Marcos, Marti Sánchez-Fibla, and Paul F M J Verschure. An embodied biologically constrained model of foraging: From classical and operant conditioning to adaptive real-world behavior in DAC-X. Neural Networks, 72:88-108, 2015.</p>
<p>Simple Perception-Action Strategy Based on Hierarchical Temporal Memory. Xiaochun Mai, Xinzheng Zhang, Yichen Jin, Yi Yang, Jianfen Zhang, Proceeding IEEE Int. Conf. Robot. Biomimetics. eeding IEEE Int. Conf. Robot. BiomimeticsXiaochun Mai, Xinzheng Zhang, Yichen Jin, Yi Yang, and Jianfen Zhang. Simple Perception-Action Strategy Based on Hierarchical Temporal Memory. In Proceeding IEEE Int. Conf. Robot. Biomimetics, pages 1759-1764, 2013.</p>
<p>A General-Purpose Architecture to Control Mobile Robots. L J Manso, L V Calderita, P Bustos, J Garcia, M Martinez, F Fernandez, A Romero-Garces, A Bandera, XV Work. Phys. agents B. Proc. (WAF 2014). L. J. Manso, L. V. Calderita, P. Bustos, J. Garcia, M. Martinez, F. Fernandez, A. Romero-Garces, and A. Bandera. A General-Purpose Architecture to Control Mobile Robots. In XV Work. Phys. agents B. Proc. (WAF 2014), 2014.</p>
<p>Toward a Comprehensive Computational Model of Emotions and Feelings. P Robert, John E Marinier, Laird, Proc. Sixth Int. Conf. Cogn. Model. ICCM. Sixth Int. Conf. Cogn. Model. ICCMRobert P. Marinier and John E. Laird. Toward a Comprehensive Computational Model of Emotions and Feelings. In Proc. Sixth Int. Conf. Cogn. Model. ICCM, pages 172-177, 2004.</p>
<p>A computational unification of cognitive behavior and emotion. Robert P Marinier, John E Laird, Richard L Lewis, Cogn. Syst. Res. 101Robert P. Marinier, John E. Laird, and Richard L. Lewis. A computational unification of cognitive behavior and emotion. Cogn. Syst. Res., 10(1):48-69, 2009.</p>
<p>Vision: A Computational Investigation Into the Human Representation and Processing of Visual Information. D Marr, MIT PressD. Marr. Vision: A Computational Investigation Into the Human Representation and Processing of Visual Information. MIT Press, 2010.</p>
<p>Metacat: A Program That Judges Creative Analogies in a Microworld. James B Marshall, Proc. to Second Work. to Second WorkJames B. Marshall. Metacat: A Program That Judges Creative Analogies in a Microworld. In Proc. to Second Work. Creat. Syst., 2002.</p>
<p>Metacat: A Self-Watching Cognitive Architecture for Analogy-Making. James B Marshall, Proc. 24th Annu. Conf. 24th Annu. ConfJames B. Marshall. Metacat: A Self-Watching Cognitive Architecture for Analogy-Making. In Proc. 24th Annu. Conf. Cogn. Sci. Soc., 2002.</p>
<p>A self-watching model of analogy-making and perception. James B Marshall, J. Exp. Theor. Artif. Intell. 183James B. Marshall. A self-watching model of analogy-making and perception. J. Exp. Theor. Artif. Intell., 18(3):267-307, 2006.</p>
<p>ARDIS: Knowledge-based dynamic architecture for real-time surface visual inspection. D Martin, M Rincon, M C Garcia-Alegre, D Guinea, Lect. Notes Comput. Sci. 5601D. Martin, M. Rincon, M. C. Garcia-Alegre, and D. Guinea. ARDIS: Knowledge-based dynamic architecture for real-time surface visual inspection. Lect. Notes Comput. Sci., 5601:395-404, 2009.</p>
<p>ARDIS: Knowledge-based architecture for visual system configuration in dynamic surface inspection. D Martin, M Rincon, M C Garcia-Alegre, D Guinea, Expert Syst. 284D. Martin, M. Rincon, M. C. Garcia-Alegre, and D. Guinea. ARDIS: Knowledge-based architecture for visual system configuration in dynamic surface inspection. Expert Syst., 28(4):353-374, 2011.</p>
<p>Toward Social Cognition in Robotics: Extracting and Internalizing Meaning from Perception. Jesus Martinez-Gomez, Rebeca Marfil, Luis V Calderita, Juan Pedro Bandera, Luis J Manso, Antonio Bandera, Adrian Romero-Garces, Pablo Bustos, Work. Phys. Agents. Jesus Martinez-Gomez, Rebeca Marfil, Luis V. Calderita, Juan Pedro Bandera, Luis J. Manso, Antonio Bandera, Adrian Romero-Garces, and Pablo Bustos. Toward Social Cognition in Robotics: Extracting and Internalizing Meaning from Perception. In Work. Phys. Agents, 2014.</p>
<p>Neural networks and logical reasoning systems. A translation table. Joao Martins, Vilela Mendes, Int. J. Neural Syst. 112Joao Martins and Vilela Mendes. Neural networks and logical reasoning systems. A translation table. Int. J. Neural Syst., 11(2):179-186, 2001.</p>
<p>PASAR: An integrated model of prediction, anticipation, sensation, attention and response for artificial sensorimotor systems. Zenon Mathews, Sergi Bermúdez, I Badia, Paul F M J Verschure, Inf. Sci. (Ny). 1861Zenon Mathews, Sergi Bermúdez I Badia, and Paul F M J Verschure. PASAR: An integrated model of prediction, anticipation, sensation, attention and response for artificial sensorimotor systems. Inf. Sci. (Ny)., 186(1):1-19, 2012.</p>
<p>. Zenon Mathews, Miguel Lechon, J M Blanco Calvo, Anant Dhir Armin Duff, Sergi Bermudez I. Badia, and Paul FZenon Mathews, Miguel Lechon, J. M. Blanco Calvo, Anant Dhir Armin Duff, Sergi Bermudez I. Badia, and Paul F.</p>
<p>Insect-like mapless navigation based on head direction cells and contextual learning using chemo-visual sensors. M J Verschure, IEEE/RSJ Int. Conf. Intell. Robot. Syst. IROS. M. J. Verschure. Insect-like mapless navigation based on head direction cells and contextual learning using chemo-visual sensors. 2009 IEEE/RSJ Int. Conf. Intell. Robot. Syst. IROS 2009, pages 2243-2250, 2009.</p>
<p>Stereo vision for planetary rovers: Stochastic modeling to near real-time implementation. Larry Matthies, Int. J. Comput. Vis. 81Larry Matthies. Stereo vision for planetary rovers: Stochastic modeling to near real-time implementation. Int. J. Comput. Vis., 8(1):71-91, 1992.</p>
<p>Generative Music, Cognitive Modelling, and Computer-Assisted Composition in MusiCog and ManuScore. James B Maxwell, PhD ThesisJames B. Maxwell. Generative Music, Cognitive Modelling, and Computer-Assisted Composition in MusiCog and ManuS- core. PhD Thesis, 2014.</p>
<p>Evaluation of hierarchical temporal memory for a real world application. J C Wim, Shuhei Melis, Michitaka Chizuwa, Kameyama, Proc. 4th Int. Conf. Innov. Comput. Inf. Control. 4th Int. Conf. Innov. Comput. Inf. ControlWim J. C. Melis, Shuhei Chizuwa, and Michitaka Kameyama. Evaluation of hierarchical temporal memory for a real world application. Proc. 4th Int. Conf. Innov. Comput. Inf. Control, pages 144-147, 2009.</p>
<p>The iCub humanoid robot: An open-systems platform for research in cognitive development. Giorgio Metta, Lorenzo Natale, Francesco Nori, Giulio Sandini, David Vernon, Luciano Fadiga, Kerstin Claes Von Hofsten, Manuel Rosander, Jose Lopes, Alexandre Santos-Victor, Luis Bernardino, Montesano, Neural Networks. 238-9Giorgio Metta, Lorenzo Natale, Francesco Nori, Giulio Sandini, David Vernon, Luciano Fadiga, Claes von Hofsten, Kerstin Rosander, Manuel Lopes, Jose Santos-Victor, Alexandre Bernardino, and Luis Montesano. The iCub humanoid robot: An open-systems platform for research in cognitive development. Neural Networks, 23(8-9):1125-1134, 2010.</p>
<p>Tomas Mikolov, Armand Joulin, Marco Baroni, arXiv:1511.08130v1Roadmap towards Machine Intelligence. Tomas Mikolov, Armand Joulin, and Marco Baroni. A Roadmap towards Machine Intelligence. arXiv : 1511.08130v1, 2015.</p>
<p>A Simple Symbolic Algorithm for Incremental Concept Acquisition. Craig S Miller, John E Laird, Tech. RepCraig S. Miller and John E. Laird. A Simple Symbolic Algorithm for Incremental Concept Acquisition. Tech. Rep., 1992.</p>
<p>Global symbolic maps from local navigation. P David, Marc G Miller, Slack, Proc. ninth Natl. Conf. Artif. Intell. AAAI. ninth Natl. Conf. Artif. Intell. AAAIDavid P. Miller and Marc G. Slack. Global symbolic maps from local navigation. In Proc. ninth Natl. Conf. Artif. Intell. AAAI, pages 750-755, 1991.</p>
<p>Interactively Learning Strategies for Handling References to Unseen or Unknown Objects. Aaron Mininger, John Laird, Adv. Cogn. Syst. 5Aaron Mininger and John Laird. Interactively Learning Strategies for Handling References to Unseen or Unknown Objects. Adv. Cogn. Syst., 5, 2016.</p>
<p>The Society of Mind. Marvin Minsky, Simon &amp; Shuster, IncNew York, NYMarvin Minsky. The Society of Mind. Simon &amp; Shuster, Inc., New York, NY, 1986.</p>
<p>Explanation-Based Learning: A Problem Solving Perspective. Steven Minton, Jaime Carbonell, Craig A Knoblock, Daniel R Kuokka, Oren Etzioni, Yolanda Gil, Artif. Intell. 401-3Steven Minton, Jaime Carbonell, Craig A. Knoblock, Daniel R. Kuokka, Oren Etzioni, and Yolanda Gil. Explanation-Based Learning: A Problem Solving Perspective. Artif. Intell., 40(1-3):63-118, 1989.</p>
<p>Workload Analysis of the Crew of the Abrams V2 SEP: Phase I Baseline IMPRINT Model. D K Mitchell, ARL-TR-5028Tech. Rep.D. K. Mitchell. Workload Analysis of the Crew of the Abrams V2 SEP: Phase I Baseline IMPRINT Model. Tech. Rep. ARL-TR-5028, 2009.</p>
<p>A Procedure for Collecting Mental Workload Data During an Experiment That Is Comparable to IMPRINT Workload Data. Tehcnical Rep. D K Mitchell, Brooke Abounader, Shanell Henry, ARL-TR-5020D. K. Mitchell, Brooke Abounader, and Shanell Henry. A Procedure for Collecting Mental Workload Data During an Experiment That Is Comparable to IMPRINT Workload Data. Tehcnical Rep. ARL-TR-5020, 2009.</p>
<p>The emergence of understanding in a computer model of concepts and analogy-making. Phys. D Nonlinear Phenom. Melanie Mitchell, Douglas R Hofstadter, 42Melanie Mitchell and Douglas R. Hofstadter. The emergence of understanding in a computer model of concepts and analogy-making. Phys. D Nonlinear Phenom., 42(1-3):322-334, 1990.</p>
<p>Theo: A framework for self-improving systems. Tom Mitchell, John Allen, Prasad Chalasani, John Cheng, Oren Etzioni, Marc Ringuette, Jeffrey C Schlimmer, Archit. Intell. K. VanLehnErbaumTom Mitchell, John Allen, Prasad Chalasani, John Cheng, Oren Etzioni, Marc Ringuette, and Jeffrey C. Schlimmer. Theo: A framework for self-improving systems. In K. VanLehn, editor, Archit. Intell., pages 323-356. Erbaum, 1989.</p>
<p>Becoming Increasingly Reactive. Tom M Mitchell, Proc. Eighth Natl. Conf. Artif. Intell. Eighth Natl. Conf. Artif. IntellTom M. Mitchell. Becoming Increasingly Reactive. In Proc. Eighth Natl. Conf. Artif. Intell., pages 1051-1058, 1990.</p>
<p>Acquiring Grounded Representations of Words with Situated Interactive Instruction. Shiwali Mohan, Aaron H Mininger, James R Kirk, John E Laird, Adv. Cogn. Syst. 2Shiwali Mohan, Aaron H. Mininger, James R. Kirk, and John E. Laird. Acquiring Grounded Representations of Words with Situated Interactive Instruction. Adv. Cogn. Syst., 2:113-130, 2012.</p>
<p>Modelling a Human-Like Bot in a First Person Shooter Game. Antonio Miguel Mora, Francisco Aisa, Pablo García-Sánchez, Pedroángel Castillo, Juan Julián Merelo, Int. J. Creat. Interfaces Comput. Graph. 61Antonio Miguel Mora, Francisco Aisa, Pablo García-Sánchez, PedroÁngel Castillo, and Juan Julián Merelo. Modelling a Human-Like Bot in a First Person Shooter Game. Int. J. Creat. Interfaces Comput. Graph., 6(1):21-37, 2015.</p>
<p>Meta-case-based reasoning: self-improvement through self-understanding. J , William Murdock, Ashok K Goel, J. Exp. Theor. Artif. Intell. 201J. William Murdock and Ashok K. Goel. Meta-case-based reasoning: self-improvement through self-understanding. J. Exp. Theor. Artif. Intell., 20(1):1-36, 2008.</p>
<p>Meta-case-Based Reasoning : Using Functional Models to Adapt Case-Based Agents. William Murdock, Ashok Goel, Proc. 4th. Int. Conf. Case-Based Reason. 4th. Int. Conf. Case-Based ReasonWilliam Murdock and Ashok Goel. Meta-case-Based Reasoning : Using Functional Models to Adapt Case-Based Agents. In Proc. 4th. Int. Conf. Case-Based Reason., 2001.</p>
<p>CAD directed robotic deburring. K N Murphy, R J Norcross, F M Proctor, Proc. Second Int. Second IntK. N. Murphy, R. J. Norcross, and F. M. Proctor. CAD directed robotic deburring. In Proc. Second Int. Symp. Robot. Manuf. Res. Educ. Appl., 1988.</p>
<p>Physical symbol systems. Allen Newell, Cogn. Sci. 42Allen Newell. Physical symbol systems. Cogn. Sci., 4(2), 1980.</p>
<p>Précis of Unified theories of cognition. Allen Newell, Behav. Brain Sci. 15Allen Newell. Précis of Unified theories of cognition. Behav. Brain Sci., 15:425-492, 1992.</p>
<p>Scene Understanding using DSO Cognitive Architecture. G W Ng, Xuhong Xiao, R Z Chan, Y S Tan, Proc. 15th Int. Conf. Inf. Fusion. 15th Int. Conf. Inf. FusionG. W. Ng, Xuhong Xiao, R. Z. Chan, and Y. S. Tan. Scene Understanding using DSO Cognitive Architecture. In Proc. 15th Int. Conf. Inf. Fusion, pages 2277-2284, 2012.</p>
<p>Learning to recognize objects through curiosity-driven manipulation with the iCub humanoid robot. Serena Sao Mai Nguyen, Natalia Ivaldi, Alain Lyubova, Damien Droniou, David Gerardeaux-Viret, Vincent Filliat, Olivier Padois, Pierre Yves Sigaud, Oudeyer, Proc. 3rd Jt. Int. Conf. Dev. Learn. Epigenetic Robot. 3rd Jt. Int. Conf. Dev. Learn. Epigenetic RobotSao Mai Nguyen, Serena Ivaldi, Natalia Lyubova, Alain Droniou, Damien Gerardeaux-Viret, David Filliat, Vincent Padois, Olivier Sigaud, and Pierre Yves Oudeyer. Learning to recognize objects through curiosity-driven manipulation with the iCub humanoid robot. In Proc. 3rd Jt. Int. Conf. Dev. Learn. Epigenetic Robot., 2013.</p>
<p>Reinforcement learning in the brain. Yael Niv, J. Math. Psychol. 533Yael Niv. Reinforcement learning in the brain. J. Math. Psychol., 53(3), 2009.</p>
<p>Flexible Attention-based Cognitive Architecture for Robots. Rony Novianto, PhD ThesisRony Novianto. Flexible Attention-based Cognitive Architecture for Robots. PhD Thesis, 2014.</p>
<p>Attention in the ASMO cognitive architecture. Front. Rony Novianto, Benjamin Johnston, Mary Anne Williams, Artif. Intell. Appl. 221Rony Novianto, Benjamin Johnston, and Mary Anne Williams. Attention in the ASMO cognitive architecture. Front. Artif. Intell. Appl., 221:98-105, 2010.</p>
<p>Habituation and sensitisation learning in ASMO cognitive architecture. Rony Novianto, Benjamin Johnston, Mary Anne Williams, Lect. Notes Comput. Sci. 8239Rony Novianto, Benjamin Johnston, and Mary Anne Williams. Habituation and sensitisation learning in ASMO cognitive architecture. Lect. Notes Comput. Sci., 8239 LNAI:249-259, 2013.</p>
<p>The role of attention in robot self-awareness. Rony Novianto, Mary Anne Williams, Proc. IEEE Int. IEEE IntRony Novianto and Mary Anne Williams. The role of attention in robot self-awareness. In Proc. IEEE Int. Work. Robot Hum. Interact. Commun., pages 1047-1053, 2009.</p>
<p>Extending Cognitive Architecture with Episodic Memory. M Andrew, John E Nuxoll, Laird, Proc. Natl. Conf. Artif. Intell. Natl. Conf. Artif. IntellAndrew M. Nuxoll and John E. Laird. Extending Cognitive Architecture with Episodic Memory. In Proc. Natl. Conf. Artif. Intell., 2007.</p>
<p>Human Reasoning Module. E Nyamsuren, Niels A Taatgen, Biol. Inspired Cogn. Archit. 8E. Nyamsuren and Niels A. Taatgen. Human Reasoning Module. Biol. Inspired Cogn. Archit., 8, 2014.</p>
<p>Pre-attentive and attentive vision module. Enkhbold Nyamsuren, Niels A Taatgen, Cogn. Syst. Res. Enkhbold Nyamsuren and Niels A. Taatgen. Pre-attentive and attentive vision module. Cogn. Syst. Res., pages 211-216, 2013.</p>
<p>A Distributed, Decision-Theoretic Control System for a Mobile Robot. H Gary, Ogasawara, SIGART Bull. 24Gary H. Ogasawara. A Distributed, Decision-Theoretic Control System for a Mobile Robot. SIGART Bull., 2(4):140-145, 1991.</p>
<p>Planning Using Multiple Execution Architectures. H Gary, Stuart J Ogasawara, Russell, Proc. Int. Jt. Conf. Artif. Intell. Int. Jt. Conf. Artif. IntellGary H. Ogasawara and Stuart J. Russell. Planning Using Multiple Execution Architectures. In Proc. Int. Jt. Conf. Artif. Intell., 1993.</p>
<p>Modeling integration and dissociation in brain and cognitive development. R C O&apos;reilly, Process. essR. C. O'Reilly. Modeling integration and dissociation in brain and cognitive development. In Process. Chang. brain Cogn. Dev. Atten. Perform. XXI, pages 375-401. 2006.</p>
<p>Making working memory work: a computational model of learning in the prefrontal cortex and basal ganglia. C Randall, Michael J O&apos;reilly, Frank, Neural Comput. 182Randall C. O'Reilly and Michael J. Frank. Making working memory work: a computational model of learning in the prefrontal cortex and basal ganglia. Neural Comput., 18(2):283-328, 2006.</p>
<p>The Leabra cognitive architecture: how to play 20 principles with nature and win! In Oxford Handb. C Randall, Thomas E O&apos;reilly, Seth A Hazy, Herd, Cogn. Sci. Randall C. O'Reilly, Thomas E. Hazy, and Seth A. Herd. The Leabra cognitive architecture: how to play 20 principles with nature and win! In Oxford Handb. Cogn. Sci., pages 1-31. 2012.</p>
<p>Goal-Driven Cognition in the Brain: A Computational Framework. C Randall, Thomas E O&apos;reilly, Jessica Hazy, Prescott Mollick, Seth Mackie, Herd, arXiv1404.7591arXiv Prepr.Randall C. O'Reilly, Thomas E. Hazy, Jessica Mollick, Prescott Mackie, and Seth Herd. Goal-Driven Cognition in the Brain: A Computational Framework. arXiv Prepr. arXiv1404.7591, 2014.</p>
<p>Competition, Priming, and the Past Tense U-Shaped Developmental Curve. C Randall, James H O&apos;reilly, Hoeffner, Randall C. O'Reilly and James H. Hoeffner. Competition, Priming, and the Past Tense U-Shaped Developmental Curve. 2000.</p>
<p>Recurrent processing during object recognition. C Randall, Dean O&apos;reilly, Seth Wyatte, Brian Herd, David J Mingus, Jilk, Front. Psychol. 4Randall C. O'Reilly, Dean Wyatte, Seth Herd, Brian Mingus, and David J. Jilk. Recurrent processing during object recognition. Front. Psychol., 4, 2013.</p>
<p>Levels and Types of Action Selection: The Action Selection Soup. Pinar Ozturk, Adapt. Behav. Pinar Ozturk. Levels and Types of Action Selection: The Action Selection Soup. Adapt. Behav., 2009.</p>
<p>Embodied social interaction for service robots in hallway environments. Elena Pacchierotti, Henrik I Christensen, Patric Jensfelt, Proc. 5th Int. Conf. F. Serv. Robot. 5th Int. Conf. F. Serv. RobotElena Pacchierotti, Henrik I. Christensen, and Patric Jensfelt. Embodied social interaction for service robots in hallway environments. In Proc. 5th Int. Conf. F. Serv. Robot., 2005.</p>
<p>Goal-Driven Autonomy for Cognitive Systems. Matt Paisner, Michael T Cox, Michael Maynord, Don Perlis, Proc. 36th Annu. Conf. 36th Annu. ConfMatt Paisner, Michael T. Cox, Michael Maynord, and Don Perlis. Goal-Driven Autonomy for Cognitive Systems. In Proc. 36th Annu. Conf. Cogn. Sci. Soc., pages 2085-2090, 2013.</p>
<p>A Model of Time-Estimation Considering Working Memory Demands. Nele Pape, Leon Urbas, Proc. 30th Annu. Conf. 30th Annu. ConfNele Pape and Leon Urbas. A Model of Time-Estimation Considering Working Memory Demands. Proc. 30th Annu. Conf. Cogn. Sci. Soc., pages 1543-1548, 2008.</p>
<p>An experimental evaluation of a novel minimum-jerk Cartesian controller for humanoid robots. Ugo Pattacini, Francesco Nori, Lorenzo Natale, Giorgio Metta, Giulio Sandini, Proc. Int. Conf. Intell. Robot. Syst. Int. Conf. Intell. Robot. SystUgo Pattacini, Francesco Nori, Lorenzo Natale, Giorgio Metta, and Giulio Sandini. An experimental evaluation of a novel minimum-jerk Cartesian controller for humanoid robots. In Proc. Int. Conf. Intell. Robot. Syst., pages 1668-1674, 2010.</p>
<p>Action primitives for bionics inspired action planning system: Abstraction layers for action planning based on psychoanalytical concepts. Andreas Perner, Heimo Zeilinger, IEEE Int. Conf. Ind. Informatics. Andreas Perner and Heimo Zeilinger. Action primitives for bionics inspired action planning system: Abstraction layers for action planning based on psychoanalytical concepts. In IEEE Int. Conf. Ind. Informatics, pages 63-68, 2011.</p>
<p>ISAC Humanoid: An Architecture for Learning and Emotion. Kazuhiko Richard Alan Peters, D Mitchell Kawamura, Kimberly A Wilkes, Tamara E Hambuchen, W. Anthony Rogers, Alford, Proc. IEEE-RAS Int. Conf. Humanoid Robot. IEEE-RAS Int. Conf. Humanoid Robot459Richard Alan Peters, Kazuhiko Kawamura, D. Mitchell Wilkes, Kimberly A. Hambuchen, Tamara E. Rogers, and W. An- thony Alford. ISAC Humanoid: An Architecture for Learning and Emotion. In Proc. IEEE-RAS Int. Conf. Humanoid Robot., number 1, page 459, 2001.</p>
<p>Building Robots with Analogy-Based Anticipation. Georgi Petkov, Tchavdar Naydenov, Maurice Grinberg, Boicho Kokinov, Annu. Conf. Artif. Intell. Georgi Petkov, Tchavdar Naydenov, Maurice Grinberg, and Boicho Kokinov. Building Robots with Analogy-Based An- ticipation. Annu. Conf. Artif. Intell., 2006.</p>
<p>DiPRA: a layered agent architecture which integrates practical reasoning and sensorimotor schemas. Giovanni Pezzulo, Conn. Sci. 214Giovanni Pezzulo. DiPRA: a layered agent architecture which integrates practical reasoning and sensorimotor schemas. Conn. Sci., 21(4):297-326, 2009.</p>
<p>Dynamic Computation and Context Effects in the Hybrid Architecture AKIRA. Giovanni Pezzulo, Gianguglielmo Calvi, Int. Interdiscip. Conf. Model. Using Context. Giovanni Pezzulo and Gianguglielmo Calvi. Dynamic Computation and Context Effects in the Hybrid Architecture AKIRA. Int. Interdiscip. Conf. Model. Using Context., 2005.</p>
<p>DiPRA: Distributed Practical Reasoning Architecture. Giovanni Pezzulo, Gianguglielmo Calvi, Cristiano Castelfranchi, Proc. Int. Jt. Conf. Artif. Intell. Int. Jt. Conf. Artif. IntellGiovanni Pezzulo, Gianguglielmo Calvi, and Cristiano Castelfranchi. DiPRA: Distributed Practical Reasoning Architec- ture. In Proc. Int. Jt. Conf. Artif. Intell., pages 1458-1463, 2007.</p>
<p>Behavior Coordination Mechanisms. Paolo Pirjanian, Tech. Rep. IRIS-99-375Paolo Pirjanian. Behavior Coordination Mechanisms. Tech. Rep. IRIS-99-375, 1999.</p>
<p>Oscar -A General-Purpose Defeasible Reasoner. John L Pollock, FS-93-01AAAI Tech. Rep.John L. Pollock. Oscar -A General-Purpose Defeasible Reasoner. AAAI Tech. Rep. FS-93-01, 1993.</p>
<p>. John L Pollock, Planning in OSCAR. Minds Mach. 2John L. Pollock. Planning in OSCAR. Minds Mach., 2:113-144, 1993.</p>
<p>OSCAR: An Agent Architecture Based on Defeasible Reasoning. John L Pollock, AAAI Spring Symp. John L. Pollock. OSCAR: An Agent Architecture Based on Defeasible Reasoning. In AAAI Spring Symp. Emot. Personal. Soc. Behav., 2008.</p>
<p>OSCAR-MDA: An Artificially Intelligent Advisor for Emergency Room Medicine. L John, Devin Pollock, Hosea, John L. Pollock and Devin Hosea. OSCAR-MDA: An Artificially Intelligent Advisor for Emergency Room Medicine. 1995.</p>
<p>Visual dominance: An information-processing account of its origins and significance. Michael Posner, Mary Jo Nissen, Raymond M Klein, Psychol. Rev. 832Michael Posner, Mary Jo NIssen, and Raymond M. Klein. Visual dominance: An information-processing account of its origins and significance. Psychol. Rev., 83(2):157-171, 1976.</p>
<p>Cognitive architectures. Stefan Profanter, Hauptseminar Hum. Robot Interact. Stefan Profanter. Cognitive architectures. In Hauptseminar Hum. Robot Interact., 2012.</p>
<p>Reinforcement Learning for Adaptive Theory of Mind in the Sigma Cognitive Architecture. David V Pynadath, Paul S Rosenbloom, Stacy C Marsella, Proc. Conf. Artif. Gen. Intell. Conf. Artif. Gen. IntellDavid V. Pynadath, Paul S. Rosenbloom, and Stacy C. Marsella. Reinforcement Learning for Adaptive Theory of Mind in the Sigma Cognitive Architecture. In Proc. Conf. Artif. Gen. Intell., 2014.</p>
<p>Modeling two-player games in the sigma graphical cognitive architecture. David V Pynadath, Paul S Rosenbloom, Stacy C Marsella, Lingshan Li, In Int. Conf. Artif. Gen. Intell. David V. Pynadath, Paul S. Rosenbloom, Stacy C. Marsella, and Lingshan Li. Modeling two-player games in the sigma graphical cognitive architecture. In Int. Conf. Artif. Gen. Intell., 2013.</p>
<p>Habituation Revisited: An Updated and Revised Description of the Behavioral Characteristics of Habituation. Catharine H Rankin, Thomas Abrams, Robert J Barry, Seema Bhatnagar, David Clayton, John Colombo, Gianluca Coppola, Mark A Geyer, David L Glanzman, Stephen Marsland, Frances Mcsweeney, Donald A Wilson, Chun-Fang Wu, Richard F Thompson, Neurobiol. Learn. Mem. 922Catharine H. Rankin, Thomas Abrams, Robert J. Barry, Seema Bhatnagar, David Clayton, John Colombo, Gianluca Coppola, Mark A. Geyer, David L. Glanzman, Stephen Marsland, Frances Mcsweeney, Donald A. Wilson, Chun-Fang Wu, and Richard F. Thompson. Habituation Revisited: An Updated and Revised Description of the Behavioral Characteristics of Habituation. Neurobiol. Learn. Mem., 92(2):135-138, 2009.</p>
<p>Intelligent Real-Time Network Management. S Anand, Michael P Rao, George, Proc. Tenth Int. Conf. AI, Expert Syst. Nat. Lang. Tenth Int. Conf. AI, Expert Syst. Nat. LangAnand S. Rao and Michael P. George. Intelligent Real-Time Network Management. In Proc. Tenth Int. Conf. AI, Expert Syst. Nat. Lang., 1991.</p>
<p>Modeling Brain Function Current Developments and Future Prospects. Daniel Rasmussen, Chris Eliasmith, JAMA Neurol. 7010Daniel Rasmussen and Chris Eliasmith. Modeling Brain Function Current Developments and Future Prospects. JAMA Neurol., 70(10):1325-1329, 2013.</p>
<p>Object recognition in cortex: Neural mechanisms, and possible roles for attention. Maximilian Riesenhuber, Neurobiol. Atten. Maximilian Riesenhuber. Object recognition in cortex: Neural mechanisms, and possible roles for attention. Neurobiol. Atten., 2005.</p>
<p>Two Cognitive Modeling Frontiers. Frank E Ritter, Emotions and Usability. Inf. Media Technol. 41Frank E. Ritter. Two Cognitive Modeling Frontiers. Emotions and Usability. Inf. Media Technol., 4(1):76-84, 2009.</p>
<p>CoJACK: A highlevel cognitive architecture with demonstrations of moderators, variability, and implications for situation awareness. Frank E Ritter, Jennifer L Bittner, Sue E Kase, Rick Evertsz, Matteo Pedrotti, Paolo Busetta, Biol. Inspired Cogn. Archit. 1Frank E. Ritter, Jennifer L. Bittner, Sue E. Kase, Rick Evertsz, Matteo Pedrotti, and Paolo Busetta. CoJACK: A high- level cognitive architecture with demonstrations of moderators, variability, and implications for situation awareness. Biol. Inspired Cogn. Archit., 1:2-13, 2012.</p>
<p>A developmental agent for learning features, environment models, and general robotics tasks. ICDL/Eprirob. Brandon Rohrer, Brandon Rohrer. A developmental agent for learning features, environment models, and general robotics tasks. ICDL/Eprirob, 2011.</p>
<p>An implemented architecture for feature creation and general reinforcement learning. Brandon Rohrer, In Fourth Int. Conf. Artif. Gen. Intell. Work. Self-Programming AGI Syst. Brandon Rohrer. An implemented architecture for feature creation and general reinforcement learning. In Fourth Int. Conf. Artif. Gen. Intell. Work. Self-Programming AGI Syst., 2011.</p>
<p>Biologically inspired feature creation for multi-sensory perception. Brandon Rohrer, Biol. Inspired Cogn. Archit. Brandon Rohrer. Biologically inspired feature creation for multi-sensory perception. Biol. Inspired Cogn. Archit., pages 305-313, 2011.</p>
<p>BECCA version 0.4.5. User's Guide. Brandon Rohrer, Brandon Rohrer. BECCA version 0.4.5. User's Guide, 2013.</p>
<p>Model-free learning and control in a mobile robot. Brandon Rohrer, Michael Bernard, Dan J Morrow, Fred Rothganger, Patrick Xavier, Proc. 5th Int. Conf. Nat. Comput. ICNC 2009. 5th Int. Conf. Nat. Comput. ICNC 2009Brandon Rohrer, Michael Bernard, Dan J. Morrow, Fred Rothganger, and Patrick Xavier. Model-free learning and control in a mobile robot. In Proc. 5th Int. Conf. Nat. Comput. ICNC 2009, pages 566-572, 2009.</p>
<p>Testing a fully autonomous robotic salesman in real scenarios. Adrián Romero-Garcés, Luis Vicente Calderita, Jesús Martínez-Gómez, Juan Pedro Bandera, Rebeca Marfil, Luis J Manso, Antonio Bandera, Pablo Bustos, In IEEE Int. Conf. Auton. Robot. Syst. Compet. Adrián Romero-Garcés, Luis Vicente Calderita, Jesús Martínez-Gómez, Juan Pedro Bandera, Rebeca Marfil, Luis J. Manso, Antonio Bandera, and Pablo Bustos. Testing a fully autonomous robotic salesman in real scenarios. In IEEE Int. Conf. Auton. Robot. Syst. Compet., 2015.</p>
<p>The cognitive architecture of a robotic salesman. Adrián Romero-Garcés, Luis Vicente Calderita, Jesus Martinez-Gomez, Juan Pedro Bandera, Rebeca Marfil, Luis J Manso, Pablo Bustos, Antonio Bandera, Conf. Spanish Assoc. Artif. Intell. 156Adrián Romero-Garcés, Luis Vicente Calderita, Jesus Martinez-Gomez, Juan Pedro Bandera, Rebeca Marfil, Luis J. Manso, Pablo Bustos, and Antonio Bandera. The cognitive architecture of a robotic salesman. Conf. Spanish Assoc. Artif. Intell., 15(6), 2015.</p>
<p>Efficient message computation in Sigma's graphical architecture. Paul S Rosenbloom, Abram Demski, Volkan Ustun, Biol. Inspired Cogn. Archit. 11Paul S. Rosenbloom, Abram Demski, and Volkan Ustun. Efficient message computation in Sigma's graphical architecture. Biol. Inspired Cogn. Archit., 11:1-9, 2015.</p>
<p>Towards Emotion in Sigma: From Appraisal to Attention. Paul S Rosenbloom, Jonathan Gratch, Volkan Ustun, In Int. Conf. Artif. Gen. Intell. Paul S. Rosenbloom, Jonathan Gratch, and Volkan Ustun. Towards Emotion in Sigma: From Appraisal to Attention. In Int. Conf. Artif. Gen. Intell., 2015.</p>
<p>A preliminary analysis of the Soar architecture as a basis for general intelligence. Paul S Rosenbloom, John E Laird, Allen Newell, Robert Mccarl, Artif. Intell. 471-3Paul S. Rosenbloom, John E. Laird, Allen Newell, and Robert McCarl. A preliminary analysis of the Soar architecture as a basis for general intelligence. Artif. Intell., 47(1-3):289-325, 1991.</p>
<p>Multimodal saliency-based bottom-up attention a framework for the humanoid robot iCub. Jonas Ruesch, Manuel Lopes, Alexandre Bernardino, Jonas Hornstein, Jose Santos-Victor, Rolf Pfeifer, Proc. IEEE Int. Conf. Robot. Autom. IEEE Int. Conf. Robot. AutomJonas Ruesch, Manuel Lopes, Alexandre Bernardino, Jonas Hornstein, Jose Santos-Victor, and Rolf Pfeifer. Multimodal saliency-based bottom-up attention a framework for the humanoid robot iCub. In Proc. IEEE Int. Conf. Robot. Autom., pages 962-967, 2008.</p>
<p>Tower-noticing triggers strategy-change in the Tower of Hanoi: A Soar model. D Ruiz, A Newell, Tech. Rep. AIP-66D. Ruiz and A. Newell. Tower-noticing triggers strategy-change in the Tower of Hanoi: A Soar model. Tech. Rep. AIP-66, pages 522-529, 1989.</p>
<p>Decision-Theoretic Control of Reasoning: General Theory and an Application to Game-Playing. J Stuart, Eric Russel, Wefald, UCB/CSD 88/435Tech. Rep.Stuart J. Russel and Eric Wefald. Decision-Theoretic Control of Reasoning: General Theory and an Application to Game-Playing. Tech. Rep. UCB/CSD 88/435, 1988.</p>
<p>Artificial Intelligence: A Modern Approach. Stuart Russell, Peter Norvig, Prentice HallStuart Russell and Peter Norvig. Artificial Intelligence: A Modern Approach. Prentice Hall, 1995.</p>
<p>On Optimal Game-Tree Search using Rational Meta-Reasoning. Stuart Russell, Eric Wefald, Proc. Int. Jt. Conf. Artif. Intell. Int. Jt. Conf. Artif. IntellStuart Russell and Eric Wefald. On Optimal Game-Tree Search using Rational Meta-Reasoning. In Proc. Int. Jt. Conf. Artif. Intell., 1989.</p>
<p>Principles of metareasoning. Stuart Russell, Eric Wefald, Artif. Intell. 491-3Stuart Russell and Eric Wefald. Principles of metareasoning. Artif. Intell., 49(1-3):361-395, 1991.</p>
<p>A procedural Long Term Memory for cognitive robotics. R Salgado, F Bellas, P Caamano, B Santos-Diez, R J Duro, Proc. IEEE Conf. IEEE ConfR. Salgado, F. Bellas, P. Caamano, B. Santos-Diez, and R. J. Duro. A procedural Long Term Memory for cognitive robotics. In Proc. IEEE Conf. Evol. Adapt. Intell. Syst., pages 57-62, 2012.</p>
<p>A Model of Eye Movements and Visual Attention. Dario D Salvucci, Proc. Third Int. Conf. Cogn. Model. Third Int. Conf. Cogn. ModelDario D. Salvucci. A Model of Eye Movements and Visual Attention. Proc. Third Int. Conf. Cogn. Model., pages 252-259, 2000.</p>
<p>Biologically inspired cognitive architecture for socially competent agents. Alexei V Samsonovich, In Cogn. Model. Agent-Based Soc. Simul. Pap. from AAAI Work. Alexei V. Samsonovich. Biologically inspired cognitive architecture for socially competent agents. In Cogn. Model. Agent- Based Soc. Simul. Pap. from AAAI Work., pages 36-48, 2006.</p>
<p>Toward a unified catalog of implemented cognitive architectures. Alexei V Samsonovich, Proceeding Conf. eeding ConfAlexei V. Samsonovich. Toward a unified catalog of implemented cognitive architectures. In Proceeding Conf. Biol. Inspired Cogn. Archit., pages 195-244, 2010.</p>
<p>Cognitive constructor: An intelligent tutoring system based on a biologically inspired cognitive architecture (BICA). Front. Alexei V Samsonovich, Kenneth A De Jong, Anastasia Kitsantas, Erin E Peters, Nada Dabbagh, M Layne Kalbfleisch, Artif. Intell. Appl. 171Alexei V. Samsonovich, Kenneth A. De Jong, Anastasia Kitsantas, Erin E. Peters, Nada Dabbagh, and M. Layne Kalbfleisch. Cognitive constructor: An intelligent tutoring system based on a biologically inspired cognitive architec- ture (BICA). Front. Artif. Intell. Appl., 171:311-325, 2008.</p>
<p>Achieving Efficient and Cognitively Plausible Learning in Backgammon. Scott Sanner, John R Anderson, Christian Lebiere, Marsha C Lovett, Proc. Seventeenth Int. Conf. Mach. Learn. Seventeenth Int. Conf. Mach. LearnScott Sanner, John R. Anderson, Christian Lebiere, and Marsha C. Lovett. Achieving Efficient and Cognitively Plausible Learning in Backgammon. In Proc. Seventeenth Int. Conf. Mach. Learn., 2000.</p>
<p>A Quick Introduction to 4CAPS Programming. P Scott, Sanner, Scott P Sanner. A Quick Introduction to 4CAPS Programming, 1999.</p>
<p>Crystal Cassie: Use of a 3-D Gaming Environment for a Cognitive Agent. F John, Stuart C Santore, Shapiro, Pap. IJCAI. John F. Santore and Stuart C. Shapiro. Crystal Cassie: Use of a 3-D Gaming Environment for a Cognitive Agent. Pap. IJCAI 2003 Work. Cogn. Model. Agents Multi-Agent Interact., 2003.</p>
<p>Enabling Basic Normative HRI in a Cognitive Robotic Architecture. Vasanth Sarathy, Jason R Wilson, Thomas Arnold, Matthias Scheutz, Work. Cogn. Archit. Soc. Human-Robot Interac. Vasanth Sarathy, Jason R. Wilson, Thomas Arnold, and Matthias Scheutz. Enabling Basic Normative HRI in a Cognitive Robotic Architecture. In 2nd Work. Cogn. Archit. Soc. Human-Robot Interac, 2016.</p>
<p>Iterative learning of grasp adaptation through human corrections. Eric L Sauser, Brenna D Argall, Giorgio Metta, Aude G Billard, Rob. Auton. Syst. 60Eric L. Sauser, Brenna D. Argall, Giorgio Metta, and Aude G. Billard. Iterative learning of grasp adaptation through human corrections. Rob. Auton. Syst., 60:55-71, 2012.</p>
<p>Worlds as a unifying element of knowledge representation. Jonathan R Scally, Nicholas L Cassimatis, Hiroyuki Uchida, Biol. Inspired Cogn. Archit. 1Jonathan R. Scally, Nicholas L. Cassimatis, and Hiroyuki Uchida. Worlds as a unifying element of knowledge representation. Biol. Inspired Cogn. Archit., 1:14-22, 2012.</p>
<p>A psychoanalytically-inspired motivational and emotional system for autonomous agents. Samer Schaat, Klaus Doblhammer, Alexander Wendt, Friedrich Gelbard, Lukas Herret, Dietmar Bruckner, IECON 2013-39th Annu. Conf. Samer Schaat, Klaus Doblhammer, Alexander Wendt, Friedrich Gelbard, Lukas Herret, and Dietmar Bruckner. A psychoanalytically-inspired motivational and emotional system for autonomous agents. Ind. Electron. Soc. IECON 2013- 39th Annu. Conf., pages 6648-6653, 2013.</p>
<p>A multi-criteria exemplar model for holistic categorization in autonomous agents. Samer Schaat, Alexander Wendt, Dietmar Bruckner, IECON 2013-39th Annu. Conf. IEEE. Samer Schaat, Alexander Wendt, and Dietmar Bruckner. A multi-criteria exemplar model for holistic categorization in autonomous agents. Ind. Electron. Soc. IECON 2013-39th Annu. Conf. IEEE, pages 6642-6647, 2013.</p>
<p>ARS: An AGI agent architecture. Samer Schaat, Alexander Wendt, Matthias Jakubec, Friedrich Gelbard, Lukas Herret, Dietmar Dietrich, Lect. Notes Comput. Sci. 8598Samer Schaat, Alexander Wendt, Matthias Jakubec, Friedrich Gelbard, Lukas Herret, and Dietmar Dietrich. ARS: An AGI agent architecture. Lect. Notes Comput. Sci., 8598:155-164, 2014.</p>
<p>Interdisciplinary Development and Evaluation of Cognitive Architectures Exemplified with the SiMA Approach. Samer Schaat, Alexander Wendt, Stefan Kollmann, Friedrich Gelbard, Matthias Jakubec, EuroAsianPacific Jt. Conf. Cogn. Sci. Samer Schaat, Alexander Wendt, Stefan Kollmann, Friedrich Gelbard, and Matthias Jakubec. Interdisciplinary Develop- ment and Evaluation of Cognitive Architectures Exemplified with the SiMA Approach. In EuroAsianPacific Jt. Conf. Cogn. Sci., 2015.</p>
<p>DIARC: A Testbed for Natural Human-Robot Interactions. Paul Schermerhorn, James Kramer, Timothy Brick, David Anderson, Aaron Dingler, Matthias Scheutz, Proc. AAAI 2006 Robot Work. AAAI 2006 Robot WorkPaul Schermerhorn, James Kramer, Timothy Brick, David Anderson, Aaron Dingler, and Matthias Scheutz. DIARC: A Testbed for Natural Human-Robot Interactions. In Proc. AAAI 2006 Robot Work., pages 1972-1973, 2006.</p>
<p>Fast, reliable, adaptive, bimodal people tracking for indoor environments. M Scheutz, J Mcraven, Gy Cserey, Proc. IEEE/RSJ Int. Conf. Intell. Robot. Syst. IEEE/RSJ Int. Conf. Intell. Robot. SystM. Scheutz, J. McRaven, and Gy. Cserey. Fast, reliable, adaptive, bimodal people tracking for indoor environments. In Proc. IEEE/RSJ Int. Conf. Intell. Robot. Syst., pages 1347-1352, 2004.</p>
<p>An Embodied Real-Time Model of Language-Guided Incremental Visual Search. Matthias Scheutz, Evan Krause, Sepideh Sadeghi, Proc. 36th Annu. Meet. 36th Annu. MeetMatthias Scheutz, Evan Krause, and Sepideh Sadeghi. An Embodied Real-Time Model of Language-Guided Incremental Visual Search. In Proc. 36th Annu. Meet. Cogn. Sci. Soc., pages 1365-1370, 2014.</p>
<p>Think and do the right thing' -A Plea for morally competent autonomous robots. Matthias Scheutz, Bertram F Malle, Proc. nullMatthias Scheutz and Bertram F. Malle. 'Think and do the right thing' -A Plea for morally competent autonomous robots. In Proc. 2014 IEEE Int. Symp. Ethics Sci. Technol. Eng. ETHICS 2014, 2014.</p>
<p>Affective Goal and Task Selection for Social Robots. Matthias Scheutz, Paul Schermerhorn, Handb. Res. Synth. Emot. Sociable Robot. New Appl. Affect. Comput. Artif. Intell. 74Matthias Scheutz and Paul Schermerhorn. Affective Goal and Task Selection for Social Robots. Handb. Res. Synth. Emot. Sociable Robot. New Appl. Affect. Comput. Artif. Intell., page 74, 2009.</p>
<p>First steps toward natural human-like HRI. Matthias Scheutz, Paul Schermerhorn, James Kramer, David Anderson, Auton. Robots. 224Matthias Scheutz, Paul Schermerhorn, James Kramer, and David Anderson. First steps toward natural human-like HRI. Auton. Robots, 22(4):411-423, 2007.</p>
<p>A comparison between cognitive and AI models of blackjack strategy learning. R G Marvin, Fernand R Schiller, Gobet, Lect. Notes Comput. Sci. Marvin R. G. Schiller and Fernand R. Gobet. A comparison between cognitive and AI models of blackjack strategy learning. Lect. Notes Comput. Sci., pages 143-155, 2012.</p>
<p>Fusing Disparate Information Within the 4D / RCS Architecture. Craig Schlenoff, Raj Madhavan, Jim Albus, Elena Messina, Tony Barbera, Stephen Balakirsky, Proc. 7th Int. Conf. Inf. Fusion. 7th Int. Conf. Inf. FusionCraig Schlenoff, Raj Madhavan, Jim Albus, Elena Messina, Tony Barbera, and Stephen Balakirsky. Fusing Disparate Information Within the 4D / RCS Architecture. In Proc. 7th Int. Conf. Inf. Fusion, 2005.</p>
<p>Priming: Constraint Satisfaction and Interactive Competition. Tobias Schroder, Paul Thagard, Soc. Cogn. 32Tobias Schroder and Paul Thagard. Priming: Constraint Satisfaction and Interactive Competition. Soc. Cogn., 32:152-167, 2014.</p>
<p>Casimir: An architecture for mental spatial knowledge processing. Holger Schultheis, Thomas Barkowsky, Top. Cogn. Sci. 34Holger Schultheis and Thomas Barkowsky. Casimir: An architecture for mental spatial knowledge processing. Top. Cogn. Sci., 3(4):778-795, 2011.</p>
<p>Neurocognitive Mechanisms of Error-Based Motor Learning. Rachael D Seidler, Youngbin Kwak, Brett W Fling, Jessica A Bernard, Adv. Exp. Med. Biol. 782Rachael D. Seidler, Youngbin Kwak, Brett W. Fling, and Jessica A. Bernard. Neurocognitive Mechanisms of Error-Based Motor Learning. Adv. Exp. Med. Biol., 782:39-60, 2013.</p>
<p>Pandemonium: a paradigm for learning in mechanisation of thought processes. O G Selfridge, Proc. a Symp. a SympO.G. Selfridge. Pandemonium: a paradigm for learning in mechanisation of thought processes. In Proc. a Symp. Held Natl. Phys. Lab., 1958.</p>
<p>Visual binding through reentrant connectivity and dynamic synchronization in a brain-based device. K Anil, Jeffrey L Seth, Gerald M Mckinstry, Jeffrey L Edelman, Krichmar, Cereb. Cortex. 1411Anil K. Seth, Jeffrey L. McKinstry, Gerald M. Edelman, and Jeffrey L. Krichmar. Visual binding through reentrant connectivity and dynamic synchronization in a brain-based device. Cereb. Cortex, 14(11):1185-1199, 2004.</p>
<p>Using Background Knowledge to Speed Reinforcement Learning in Physical Agents. Daniel Shapiro, Pat Langley, Ross Shachter, Proc. 5th Int. Conf. Auton. Agents. 5th Int. Conf. Auton. AgentsDaniel Shapiro, Pat Langley, and Ross Shachter. Using Background Knowledge to Speed Reinforcement Learning in Physical Agents. In Proc. 5th Int. Conf. Auton. Agents, pages 254-261, 2001.</p>
<p>MGLAIR Agents in a. S C Shapiro, Josephine Anstey, D E Pape, T D Nayak, Michael Kandefer, O Telhan, Virtual Reality Drama. CSE Tech. Rep. S. C. Shapiro, Josephine Anstey, D. E. Pape, T. D. Nayak, Michael Kandefer, and O. Telhan. MGLAIR Agents in a Virtual Reality Drama. CSE Tech. Rep. 2005-08, 2005.</p>
<p>The GLAIR Cognitive Architecture. C Stuart, Jonathan P Shapiro, Bona, Int. J. Mach. Conscious. 22Stuart C. Shapiro and Jonathan P. Bona. The GLAIR Cognitive Architecture. Int. J. Mach. Conscious., 2(2):307-332, 2010.</p>
<p>A SNePS Approach to the Wumpus World Agent or Cassie Meets the Wumpus. C Stuart, Michael Shapiro, Kandefer, IJCAI-05 Work. Nonmonotonic Reason. Action, Chang. Work. Notes. Stuart C. Shapiro and Michael Kandefer. A SNePS Approach to the Wumpus World Agent or Cassie Meets the Wumpus. In IJCAI-05 Work. Nonmonotonic Reason. Action, Chang. Work. Notes, 2005.</p>
<p>Types and Quantifiers in SHRUTI -a connectionist model of rapid reasoning and relational processing. Lokendra Shastri, In Int. Work. Hybrid Neural Syst. Lokendra Shastri. Types and Quantifiers in SHRUTI -a connectionist model of rapid reasoning and relational processing. In Int. Work. Hybrid Neural Syst., 1998.</p>
<p>SHRUTI: A neurally motivated architecture for rapid, scalable inference. Lokendra Shastri, Stud. Berlin HeidelbergSpringerLokendra Shastri. SHRUTI: A neurally motivated architecture for rapid, scalable inference. In Stud. Comput. Intell., pages 183-203. Springer Berlin Heidelberg, 2007.</p>
<p>Learning to play Mario. Mohan Shiwali, John E Laird, CCA-TR-2009-03Tech. Rep.Mohan Shiwali and John E. Laird. Learning to play Mario. Tech. Rep. CCA-TR-2009-03, 2009.</p>
<p>. Kristoffer Sjoo, Hendrik Zender, Patric Jensfelt, M Geert-Jan, Andrzej Kruijff, Nick Pronobis, Michael Hawes, Brenner, The Explorer System. In Cogn. Syst. Kristoffer Sjoo, Hendrik Zender, Patric Jensfelt, Geert-Jan M. Kruijff, Andrzej Pronobis, Nick Hawes, and Michael Brenner. The Explorer System. In Cogn. Syst. 2010.</p>
<p>A framework with reasoning capabilities for crisis response decision-support systems. Nady Slam, Wenjun Wang, Guixiang Xue, Pei Wang, Eng. Appl. Artif. Intell. 46Nady Slam, Wenjun Wang, Guixiang Xue, and Pei Wang. A framework with reasoning capabilities for crisis response decision-support systems. Eng. Appl. Artif. Intell., 46:346-353, 2015.</p>
<p>The Cognition and Affect project: Architectures, architecture-schemas, and the new science of mind. Aaron Sloman, Tech. Rep.Aaron Sloman. The Cognition and Affect project: Architectures, architecture-schemas, and the new science of mind. Tech. Rep., 2003.</p>
<p>Agent Smith: Towards an evolutionary rule-based agent for interactive dynamic games. Ryan Small, Clare Bates Congdon, IEEE Congr. Evol. Comput. CEC. Ryan Small and Clare Bates Congdon. Agent Smith: Towards an evolutionary rule-based agent for interactive dynamic games. In 2009 IEEE Congr. Evol. Comput. CEC 2009, pages 660-666, 2009.</p>
<p>An Investigation into the Effect of Ageing on Expert Memory with CHREST. Richard Ll, Fernand Smith, Peter C R Gobet, Lane, Proc. United Kingdom Work. United Kingdom WorkRichard Ll. Smith, Fernand Gobet, and Peter C. R. Lane. An Investigation into the Effect of Ageing on Expert Memory with CHREST. In Proc. United Kingdom Work. Comput. Intell., 2007.</p>
<p>A deployed engineering design retrieval system using neural networks. D G Scott, Richard Smith, Michael Escobedo, Thomas P Anderson, Caudell, IEEE Trans. Neural Networks. 84Scott D. G. Smith, Richard Escobedo, Michael Anderson, and Thomas P. Caudell. A deployed engineering design retrieval system using neural networks. IEEE Trans. Neural Networks, 8(4):847-51, 1997.</p>
<p>Declarative and Nondeclarative Memory: Multiple Brain Systems Supporting Learning. Larry R Squire, J. Cogn. Neurosci. 43Larry R Squire. Declarative and Nondeclarative Memory: Multiple Brain Systems Supporting Learning. J. Cogn. Neurosci., 4(3):232-243, 1992.</p>
<p>MLECOG: Motivated Learning Embodied Cognitive Architecture. A Janusz, James T Starzyk, Graham, IEEE Syst. Journal. Spec. Issue Human-Like Intell. Robot. 99Janusz A. Starzyk and James T. Graham. MLECOG: Motivated Learning Embodied Cognitive Architecture. IEEE Syst. Journal. Spec. Issue Human-Like Intell. Robot., PP(99), 2015.</p>
<p>Explorations in Distributed Recurrent Biological Parsing. Terrence C Stewart, Peter Blouw, Chris Eliasmith, Int. Conf. Cogn. Model. Terrence C. Stewart, Peter Blouw, and Chris Eliasmith. Explorations in Distributed Recurrent Biological Parsing. In Int. Conf. Cogn. Model., 2015.</p>
<p>Parsing Sequentially Presented Commands in a Large-Scale Biologically Realistic Brain Model. Terrence C Stewart, Chris Eliasmith, Proc. 35th Annu. Conf. 35th Annu. ConfTerrence C. Stewart and Chris Eliasmith. Parsing Sequentially Presented Commands in a Large-Scale Biologically Realistic Brain Model. In Proc. 35th Annu. Conf. Cogn. Sci. Soc., pages 3460-3467, 2013.</p>
<p>Large-Scale Synthesis of Functional Spiking Neural Circuits. Terrence C Stewart, Chris Eliasmith, Proc. IEEE. IEEE102Terrence C. Stewart and Chris Eliasmith. Large-Scale Synthesis of Functional Spiking Neural Circuits. Proc. IEEE, 102(5):881-898, 2014.</p>
<p>The dominance of the visual. Dustin Stokes, Stephen Biggs, Percept. its Modalities. D. Stokes, M. Matthen, and S. BiggsOxford University PressDustin Stokes and Stephen Biggs. The dominance of the visual. In D. Stokes, M. Matthen, and S. Biggs, editors, Percept. its Modalities, pages 1-35. Oxford University Press, 2014.</p>
<p>Application of the computational intelligence network based on hierarchical temporal memory to face recognition. Svorad Stolc, Ivan Bajla, Proc. 10th IASTED Int. Conf. 10th IASTED Int. ConfSvorad Stolc and Ivan Bajla. Application of the computational intelligence network based on hierarchical temporal memory to face recognition. In Proc. 10th IASTED Int. Conf. Artif. Intell. Appl., pages 185-192, 2010.</p>
<p>Hybrid Connectionist-Symbolic Modules. Ron Sun, AI Mag. 172Ron Sun. Hybrid Connectionist-Symbolic Modules. AI Mag., 17(2):99-103, 1996.</p>
<p>Desiderata for cognitive architectures. Ron Sun, Philos. Psychol. 173Ron Sun. Desiderata for cognitive architectures. Philos. Psychol., 17(3):341-373, 2004.</p>
<p>Memory systems within a cognitive architecture. Ron Sun, New Ideas Psychol. 302Ron Sun. Memory systems within a cognitive architecture. New Ideas Psychol., 30(2):227-240, 2012.</p>
<p>Computational architectures integrating neural and symbolic processes: A perspective on the state of the art. Ron Sun and Lawrence A. BookmanSpringer Science &amp; Business MediaRon Sun and Lawrence A. Bookman, editors. Computational architectures integrating neural and symbolic processes: A perspective on the state of the art. Springer Science &amp; Business Media, 1994.</p>
<p>A bottom-up model of skill learning. Ron Sun, Edward Merrill, Todd Peterson, Proc. 20th Cogn. Sci. Soc. Conf. Ron Sun, Edward Merrill, and Todd Peterson. A bottom-up model of skill learning. Proc. 20th Cogn. Sci. Soc. Conf., pages 1037-1042, 1998.</p>
<p>A Hybrid Architecture for Situated Learning of Reactive Sequential Decision Making. Ron Sun, Todd Peterson, Edward Merrill, Appl. Intell. 11Ron Sun, Todd Peterson, and Edward Merrill. A Hybrid Architecture for Situated Learning of Reactive Sequential Decision Making. Appl. Intell., 11:109-127, 1999.</p>
<p>Accounting for Certain Mental Disorders Within a Comprehensive Cognitive Architecture. Ron Sun, Nick Wilson, Robert Mathews, Proc. Int. Jt. Conf. Neural Networks. Int. Jt. Conf. Neural NetworksRon Sun, Nick Wilson, and Robert Mathews. Accounting for Certain Mental Disorders Within a Comprehensive Cognitive Architecture. In Proc. Int. Jt. Conf. Neural Networks, 2011.</p>
<p>Top-Down versus Bottom-Up Learning in Skill Acquisition. Ron Sun, Xi Zhang, Proc. 24th Annu. Conf. 24th Annu. ConfRon Sun and Xi Zhang. Top-Down versus Bottom-Up Learning in Skill Acquisition. In Proc. 24th Annu. Conf. Cogn. Sci. Soc., 2002.</p>
<p>Accessibility versus Action-Centeredness in the Representation of Cognitive Skills. Ron Sun, Xi Zhang, Proc. Fifth Int. Conf. Cogn. Model. Fifth Int. Conf. Cogn. ModelRon Sun and Xi Zhang. Accessibility versus Action-Centeredness in the Representation of Cognitive Skills. In Proc. Fifth Int. Conf. Cogn. Model., 2003.</p>
<p>. Guy Taylor, Lin Padgham, WS-96-03An Intelligent Believable Agent Environment. AAAI Tech. Rep. Guy Taylor and Lin Padgham. An Intelligent Believable Agent Environment. AAAI Tech. Rep. WS-96-03, 1996.</p>
<p>Dorin Marcu, Ping Shyr, and Cristina Cascaval. An Experiment in Agent Teaching by Subject Matter Experts. Gheorghe Tecuci, Mihai Boicu, Michael Bowman, Int. J. Hum. Comput. Stud. 534Gheorghe Tecuci, Mihai Boicu, Michael Bowman, Dorin Marcu, Ping Shyr, and Cristina Cascaval. An Experiment in Agent Teaching by Subject Matter Experts. Int. J. Hum. Comput. Stud., 53(4):583-610, 2000.</p>
<p>A tool for training and assistance in emergency response planning. Gheorghe Tecuci, Mihai Boicu, Thomas Hajduk, Dorin Marcu, Marcel Barbulescu, Cristina Boicu, Vu Le, Proc. Annu. Hawaii Int. Conf. Syst. Sci. Annu. Hawaii Int. Conf. Syst. SciGheorghe Tecuci, Mihai Boicu, Thomas Hajduk, Dorin Marcu, Marcel Barbulescu, Cristina Boicu, and Vu Le. A tool for training and assistance in emergency response planning. In Proc. Annu. Hawaii Int. Conf. Syst. Sci., pages 1-10, 2007.</p>
<p>How Learning Enables Intelligence Analysts to Rapidly Develop Practical Cognitive Assistants. Gheorghe Tecuci, Mihai Boicu, Dorin Marcu, David Schum, Proc. 12th Int. Conf. 12th Int. ConfGheorghe Tecuci, Mihai Boicu, Dorin Marcu, and David Schum. How Learning Enables Intelligence Analysts to Rapidly Develop Practical Cognitive Assistants. In Proc. 12th Int. Conf. Mach. Learn. Appl., pages 105-110, 2013.</p>
<p>Apprenticeship Learning in Imperfect Domain Theories. Gheorghe Tecuci, Yves Kodratoff, Mach. Learn. An Artif. Intell. Approach. Gheorghe Tecuci and Yves Kodratoff. Apprenticeship Learning in Imperfect Domain Theories. In Mach. Learn. An Artif. Intell. Approach, pages 514-552. 1990.</p>
<p>Mixed-Initiative Assumption-Based Reasoning for Complex Decision-Making. Gheorghe Tecuci, Dorin Marcu, Mihai Boicu, Vu Le, Stud. Informatics Control. 164Gheorghe Tecuci, Dorin Marcu, Mihai Boicu, and Vu Le. Mixed-Initiative Assumption-Based Reasoning for Complex Decision-Making. Stud. Informatics Control, 16(4):459-468, 2007.</p>
<p>Intelligence analysis as agent-assisted discovery of evidence, hypotheses and arguments. Gheorghe Tecuci, David Schum, Mihai Boicu, Dorin Marcu, Benjamin Hamilton, Smart Innov. Syst. Technol. 4Gheorghe Tecuci, David Schum, Mihai Boicu, Dorin Marcu, and Benjamin Hamilton. Intelligence analysis as agent-assisted discovery of evidence, hypotheses and arguments. Smart Innov. Syst. Technol., 4:1-10, 2010.</p>
<p>Automating Knowledge Acquisition as Extending, Updating, and Improving a Knowledge Base. D Gheorghe, Tecuci, IEEE Trans. Syst. Man Cybern. 226Gheorghe D. Tecuci. Automating Knowledge Acquisition as Extending, Updating, and Improving a Knowledge Base. IEEE Trans. Syst. Man Cybern., 22(6):1444-1460, 1992.</p>
<p>Cognitive Architectures. Paul Thagard, Cambridge Handb. Cogn. Sci. W. Frankish and W. RamsayCambridge University PressPaul Thagard. Cognitive Architectures. In W. Frankish and W. Ramsay, editors, Cambridge Handb. Cogn. Sci., pages 50-70. Cambridge University Press, Cambridge, 2012.</p>
<p>A Model of the Time Course and Content of Reading. Robert Thibadeau, Marcel Adam Just, Patricia A Carpenter, Cogn. Sci. 6Robert Thibadeau, Marcel Adam Just, and Patricia A. Carpenter. A Model of the Time Course and Content of Reading. Cogn. Sci., 6:157-203, 1982.</p>
<p>Extending the Influence of Contextual Information in ACT-R using Buffer Decay. Robert Thomson, Stefano Bennati, Christian Lebiere, Proc. Annu. Meet. Annu. MeetRobert Thomson, Stefano Bennati, and Christian Lebiere. Extending the Influence of Contextual Information in ACT-R using Buffer Decay. In Proc. Annu. Meet. Cogn. Sci. Soc., 2014.</p>
<p>Cognitive Architectures and Autonomy: A Comparative Review. Kristinn Thórisson, Helgi Helgasson, J. Artif. Gen. Intell. 32Kristinn Thórisson and Helgi Helgasson. Cognitive Architectures and Autonomy: A Comparative Review. J. Artif. Gen. Intell., 3(2):1-30, 2012.</p>
<p>Real-time decision making in multimodal face-to-face communication. R Kristinn, Thorisson, Proc. Interantional Conf. Auton. Agents. Interantional Conf. Auton. AgentsKristinn R. Thorisson. Real-time decision making in multimodal face-to-face communication. In Proc. Interantional Conf. Auton. Agents, pages 16-23, 1998.</p>
<p>Mind model for multimodal communicative creatures and humanoids. R Kristinn, Thorisson, Appl. Artif. Intell. 134-5Kristinn R. Thorisson. Mind model for multimodal communicative creatures and humanoids. Appl. Artif. Intell., 13(4- 5):449-486, 1999.</p>
<p>A Multiparty Multimodal Architecture for Realtime Turntaking. R Kristinn, Olafur Thorisson, Gislason, Hrafn Gudny Ragna Jonsdottir, Th, Thorisson, Int. Conf. Intell. Virtual Agents. Kristinn R. Thorisson, Olafur Gislason, Gudny Ragna Jonsdottir, and Hrafn Th. Thorisson. A Multiparty Multimodal Architecture for Realtime Turntaking. In Int. Conf. Intell. Virtual Agents, 2010.</p>
<p>Character Recognition Using Hierarchical Vector Quantization and Temporal Pooling. John Thornton, Jolon Faichney, Michael Blumenstein, Trevor Hine, Proc. 21st Australas. Jt. Conf. 21st Australas. Jt. Conf5360John Thornton, Jolon Faichney, Michael Blumenstein, and Trevor Hine. Character Recognition Using Hierarchical Vector Quantization and Temporal Pooling. In Proc. 21st Australas. Jt. Conf. Artif. Intell. Adv. Artif. Intell., volume 5360, pages 562-572, 2008.</p>
<p>Integration of speech and action in humanoid robots: iCub simulation experiments. Vadim Tikhanoff, Angelo Cangelosi, Giorgio Metta, IEEE Trans. Auton. Ment. Dev. 31Vadim Tikhanoff, Angelo Cangelosi, and Giorgio Metta. Integration of speech and action in humanoid robots: iCub simulation experiments. IEEE Trans. Auton. Ment. Dev., 3(1):17-29, 2011.</p>
<p>Enabling Effective Human Robot Interaction Using Perspective-Taking in Robots. J , Gregory Trafton, Nicholas L Cassimatis, Magdalena D Bugajska, Derek P Brock, Farilee E Mintz, Alan C Schultz, IEEE Trans. Syst. Man, Cybern. -Part A Syst. Humans. 354J. Gregory Trafton, Nicholas L. Cassimatis, Magdalena D. Bugajska, Derek P. Brock, Farilee E. Mintz, and Alan C. Schultz. Enabling Effective Human Robot Interaction Using Perspective-Taking in Robots. IEEE Trans. Syst. Man, Cybern. -Part A Syst. Humans, 35(4):460-470, 2005.</p>
<p>Embodied Spatial Cognition. J , Gregory Trafton, Anthony M Harrison, Top. Cogn. Sci. 3J. Gregory Trafton and Anthony M. Harrison. Embodied Spatial Cognition. Top. Cogn. Sci., 3:686-706, 2011.</p>
<p>ACT-R/E: An Embodied Cognitive Architecture for Human-Robot Interaction. J , Gregory Trafton, Laura M Hiatt, Anthony M Harrison, P Tamborello, Sangeet S Khemlani, Alan C Schultz, J. Human-Robot Interact. 21J. Gregory Trafton, Laura M. Hiatt, Anthony M. Harrison, P. Tamborello, Sangeet S. Khemlani, and Alan C. Schultz. ACT-R/E: An Embodied Cognitive Architecture for Human-Robot Interaction. J. Human-Robot Interact., 2(1):30-54, 2013.</p>
<p>What Does it Take to Pass the False Belief Task? An ACT-R Model. M Lara, Amy M Triona, Bradley J Masnick, Morris, Proc. 24th Annu. Meet. 24th Annu. MeetLara M. Triona, Amy M. Masnick, and Bradley J. Morris. What Does it Take to Pass the False Belief Task? An ACT-R Model. In Proc. 24th Annu. Meet. Cogn. Sci. Soc., 2002.</p>
<p>Communicating, Interpreting, and Executing High-Level Instructions for Human-Robot Interaction. Nishant Trivedi, Pat Langley, Paul Schermerhorn, Matthias Scheutz, Proc. AAAI Fall Symp. AAAI Fall SympNishant Trivedi, Pat Langley, Paul Schermerhorn, and Matthias Scheutz. Communicating, Interpreting, and Executing High-Level Instructions for Human-Robot Interaction. In Proc. AAAI Fall Symp. Adv. Cogn. Syst., 2011.</p>
<p>Analyzing vision at the complexity level. John K Tsotsos, Behav. Brain Sci. 13John K. Tsotsos. Analyzing vision at the complexity level. Behav. Brain Sci., 13:423-469, 1990.</p>
<p>. K John, Tsotsos. Image Understanding. In Encycl. Artif. Intell. John K. Tsotsos. Image Understanding. In Encycl. Artif. Intell., pages 641-663. 1992.</p>
<p>A computational perspective on visual attention. John K Tsotsos, MIT PressJohn K. Tsotsos. A computational perspective on visual attention. MIT Press, 2011.</p>
<p>Attention and Cognition: Principles to Guide Modeling. John K Tsotsos, Comput. Cogn. Neurosci. Vis. Q. ZhaoElsevierJohn K. Tsotsos. Attention and Cognition: Principles to Guide Modeling. In Q. Zhao, editor, Comput. Cogn. Neurosci. Vis. Elsevier, 2017.</p>
<p>Modeling visual attention via selective tuning. John K Tsotsos, M Scan, Winky Culhane, Yan Kei, Yuzhong Wai, Neal Lai, Fernando Davis, Nuflo, Artif. Intell. 781-2John K. Tsotsos, Scan M. Culhane, Winky Yan Kei Wai, Yuzhong Lai, Neal Davis, and Fernando Nuflo. Modeling visual attention via selective tuning. Artif. Intell., 78(1-2):507-545, 1995.</p>
<p>Cognitive programs: Software for attention's executive. K John, Wouter Tsotsos, Kruijne, Front. Psychol. 5John K. Tsotsos and Wouter Kruijne. Cognitive programs: Software for attention's executive. Front. Psychol., 5:1-16, 2014.</p>
<p>The MIDAS human performance model. Sherman W Tyler, Christian Neukom, Michael Logan, Jay Shively, Proc. Hum. HumSherman W. Tyler, Christian Neukom, Michael Logan, and Jay Shively. The MIDAS human performance model. In Proc. Hum. Factors Ergon. Soc., pages 320-324, 1998.</p>
<p>Reflection in Action: Model-Based Self-Adaptation in Game Playing Agents. Patrick Ulam, Ashok Goel, Joshua Jones, Challenges Game Artif. Intell. Pap. from AAAI Work. Patrick Ulam, Ashok Goel, and Joshua Jones. Reflection in Action: Model-Based Self-Adaptation in Game Playing Agents. In Challenges Game Artif. Intell. Pap. from AAAI Work., 2004.</p>
<p>Application of a hybrid controller with non-contact impedance to a humanoid robot. Baris Ulutas, Erdem Erdemir, Kazuhiko Kawamura, Proc. IEEE 10th Int. IEEE 10th IntBaris Ulutas, Erdem Erdemir, and Kazuhiko Kawamura. Application of a hybrid controller with non-contact impedance to a humanoid robot. In Proc. IEEE 10th Int. Work. Var. Struct. Syst., pages 378-383, 2008.</p>
<p>Building High Fidelity Human Behavior Models in the Sigma Cognitive Rchitecture. Volkan Ustun, Paul S Rosenbloom, Julia Kim, Lingshan Li, Proc. 2015 Winter Simul. Conf. L. Yilmaz, W. K. V. Chan, I. Moon, T. M. K. Roeder, C. Macal, and M. D. Rossetti2015 Winter Simul. ConfVolkan Ustun, Paul S. Rosenbloom, Julia Kim, and Lingshan Li. Building High Fidelity Human Behavior Models in the Sigma Cognitive Rchitecture. In L. Yilmaz, W. K. V. Chan, I. Moon, T. M. K. Roeder, C. Macal, and M. D. Rossetti, editors, Proc. 2015 Winter Simul. Conf., 2015.</p>
<p>Hierarchical controller learning in a first-person shooter. Niels Van Hoorn, Julian Togelius, Jürgen Schmidhuber, IEEE Symp. Comput. Intell. Games. Niels Van Hoorn, Julian Togelius, and Jürgen Schmidhuber. Hierarchical controller learning in a first-person shooter. In 2009 IEEE Symp. Comput. Intell. Games, pages 294-301, 2009.</p>
<p>Discovering problem solving strategies: What humans do and machines don't (yet). K Vanlehn, Proc. Sixth Int. Sixth IntK. VanLehn. Discovering problem solving strategies: What humans do and machines don't (yet). In Proc. Sixth Int. Work. Mach. Learn., pages 215-217, 1989.</p>
<p>Non-Lifo Execution of Cognitive Procedures. K Vanlehn, W Ball, B Kowalski, Cogn. Sci. 133K. VanLehn, W. Ball, and B. Kowalski. Non-Lifo Execution of Cognitive Procedures. Cogn. Sci., 13(3):415-465, 1989.</p>
<p>Goal Reconstruction: How Teton Blends Situated Action and Planned Action. Kurt Vanlehn, William Ball, Department of Computer Science and Psychology, Carnegie Mellon UniversityTechnical reportKurt VanLehn and William Ball. Goal Reconstruction: How Teton Blends Situated Action and Planned Action. Technical report, Department of Computer Science and Psychology, Carnegie Mellon University, 1989.</p>
<p>Explanation-based learning of correctness: Towards a model of the self-explanation effect. Kurt Vanlehn, William Ball, Bernadette Kowalski, Proc. 12th Annu. Conf. 12th Annu. ConfKurt Vanlehn, William Ball, and Bernadette Kowalski. Explanation-based learning of correctness: Towards a model of the self-explanation effect. In Proc. 12th Annu. Conf. Cogn. Sci. Soc., 1990.</p>
<p>A computational model of Tower of Hanoi problem solving. Sashank Varma, PhD ThesisSashank Varma. A computational model of Tower of Hanoi problem solving. PhD Thesis, 2006.</p>
<p>PRODILOGY/ANALOGY: Analogical reasoning in general problem solving. Manuela Veloso, Top. Case-Based ReasonManuela Veloso. PRODILOGY/ANALOGY: Analogical reasoning in general problem solving. In Top. Case-Based Rea- son., 1993.</p>
<p>Linkability: Examining Causal Link Commitments in Partial-order Planning. Manuela M Veloso, Jim Blythe, Proc. Second Int. Conf. Second Int. ConfManuela M. Veloso and Jim Blythe. Linkability: Examining Causal Link Commitments in Partial-order Planning. In Proc. Second Int. Conf. Artif. Intell. Plan. Syst., 1994.</p>
<p>Rationale-Based Monitoring for Planning in Dynamic Environments. Manuela M Veloso, Martha E Pollack, Michael T Cox, AIPS 1998 Proc. Manuela M. Veloso, Martha E. Pollack, and Michael T. Cox. Rationale-Based Monitoring for Planning in Dynamic Environments. In AIPS 1998 Proc., pages 171-180, 1998.</p>
<p>A basic agent. Steven Vere, Timothy Bickmore, Comput. Intell. 61Steven Vere and Timothy Bickmore. A basic agent. Comput. Intell., 6(1):41-60, 1990.</p>
<p>Organization of the basic agent. Steven A Vere, ACM SIGART Bull. 24Steven A. Vere. Organization of the basic agent. ACM SIGART Bull., 2(4):164-168, 1991.</p>
<p>A Survey of Artificial Cognitive Systems: Implictions for the Autonomous Development of Mental Capbilities in Computational Agents. David Vernon, Giorgio Metta, Giulio Sandini, IEEE Trans. Evol. Comput. David Vernon, Giorgio Metta, and Giulio Sandini. A Survey of Artificial Cognitive Systems: Implictions for the Au- tonomous Development of Mental Capbilities in Computational Agents. IEEE Trans. Evol. Comput., pages 1-30, 2007.</p>
<p>The iCub Cognitive Architecture. David Vernon, Luciano Claes Von Hofsten, Fadiga, A Roadmap Cogn. Dev. Humanoid Robot. David Vernon, Claes von Hofsten, and Luciano Fadiga. The iCub Cognitive Architecture. In A Roadmap Cogn. Dev. Humanoid Robot., pages 121-153. 2010.</p>
<p>A real-world rational agent: Unifying old and new AI. Paul Verschure, Philipp Althaus, Cogn. Sci. 274Paul Verschure and Philipp Althaus. A real-world rational agent: Unifying old and new AI. Cogn. Sci., 27(4):561-590, 2003.</p>
<p>Integrating top-down expectations with bottom-up perceptual processing in a hybrid neural-symbolic architecture. Y Vinokurov, C Lebiere, A Szabados, S Herd, R O&apos;reilly, Biol. Inspired Cogn. Archit. 6Y. Vinokurov, C. Lebiere, A. Szabados, S. Herd, and R. O'Reilly. Integrating top-down expectations with bottom-up perceptual processing in a hybrid neural-symbolic architecture. Biol. Inspired Cogn. Archit., 6:140-146, 2013.</p>
<p>Vasiliki Vouloutsi, Maria Blancas Munoz, Klaudia Grechuta, Stephane Lallee, Armin Duff, Jordi Ysard, Llobet Puigbo, Paul F M J Verschure, A new biomimetic approach towards educational robotics: the Distributed Adaptive Control of a Synthetic Tutor Assistant. 4th Int. Symp. New Front. human-Robot Interact. Vasiliki Vouloutsi, Maria Blancas Munoz, Klaudia Grechuta, Stephane Lallee, Armin Duff, Jordi ysard Llobet Puigbo, and Paul F. M. J. Verschure. A new biomimetic approach towards educational robotics: the Distributed Adaptive Control of a Synthetic Tutor Assistant. 4th Int. Symp. New Front. human-Robot Interact., 2015.</p>
<p>Attentional Selection for Object Recognition a Gentle Way. Dirk Walther, Laurent Itti, Maximilian Riesenhuber, Tomaso Poggio, Christof Koch, In Int. Work. Biol. Motiv. Comput. Vis. Dirk Walther, Laurent Itti, Maximilian Riesenhuber, Tomaso Poggio, and Christof Koch. Attentional Selection for Object Recognition a Gentle Way. In Int. Work. Biol. Motiv. Comput. Vis., 2002.</p>
<p>Attention in Hierarchical Models of Object Recognition. Dirk B Walther, Christof Koch, Prog. Brain Res. 165Dirk B. Walther and Christof Koch. Attention in Hierarchical Models of Object Recognition. Prog. Brain Res., 165, 2007.</p>
<p>Creating human-like autonomous players in real-time first person shooter computer games. Di Wang, Budhitama Subagdja, Ah-Hwee Tan, G W Ng, Proc. 21st Annu. 21st AnnuDi Wang, Budhitama Subagdja, Ah-hwee Tan, and GW Ng. Creating human-like autonomous players in real-time first person shooter computer games. In Proc. 21st Annu. Conf. Innov. Appl. Artif. Intell., pages 173-178, 2009.</p>
<p>Wavelet-based feature-adaptive adaptive resonance theory neural network for texture identification. Jian Wang, Golshah Naghdy, Philip Ogunbona, J. Electron. Imaging. 63Jian Wang, Golshah Naghdy, and Philip Ogunbona. Wavelet-based feature-adaptive adaptive resonance theory neural network for texture identification. J. Electron. Imaging, 6(3):329-336, 1997.</p>
<p>Rigid flexibility: The logic of intelligence. Pei Wang, Springer34NetherlandsPei Wang. Rigid flexibility: The logic of intelligence, volume 34. Springer Netherlands, 2006.</p>
<p>Three fundamental misconceptions of Artificial Intelligence. Pei Wang, J. Exp. Theor. Artif. Intell. 193Pei Wang. Three fundamental misconceptions of Artificial Intelligence. J. Exp. Theor. Artif. Intell., 19(3):249-268, 2007.</p>
<p>Non-Axiomatic Logic (NAL) Specification. Pei Wang, Pei Wang. Non-Axiomatic Logic (NAL) Specification, 2010.</p>
<p>Natural language processing by reasoning and learning. Pei Wang, Proc. Int. Conf. Artif. Int. Conf. ArtifPei Wang. Natural language processing by reasoning and learning. In Proc. Int. Conf. Artif. Gen. Intell., pages 160-169, 2013.</p>
<p>Assumptions of decision-making models in AGI. Pei Wang, Patrick Hammer, Int. Conf. Artif. Gen. Intell. Pei Wang and Patrick Hammer. Assumptions of decision-making models in AGI. Int. Conf. Artif. Gen. Intell., pages 197-207, 2015.</p>
<p>Issues in Temporal and Causal Inference. Pei Wang, Patrick Hammer, Proc. Int. Conf. Artif. Int. Conf. ArtifPei Wang and Patrick Hammer. Issues in Temporal and Causal Inference. In Proc. Int. Conf. Artif. Gen. Intell., 2015.</p>
<p>Integrating Semantic Memory into a Cognitive Architecture. Yongjia Wang, John E Laird, CCA-TR- 2006-02Tech. Rep.Yongjia Wang and John E. Laird. Integrating Semantic Memory into a Cognitive Architecture. Tech. Rep. CCA-TR- 2006-02, 2006.</p>
<p>Connectionist mechanisms for cognitive control. Carter Wendelken, Lokendra Shastri, Neurocomputing. Carter Wendelken and Lokendra Shastri. Connectionist mechanisms for cognitive control. Neurocomputing, 65-66:663-672, 2005.</p>
<p>From neural networks to the brain: Autonomous mental development. Juyang Weng, Wey Shiuan, Hwang, IEEE Comput. Intell. Mag. 13Juyang Weng and Wey Shiuan Hwang. From neural networks to the brain: Autonomous mental development. IEEE Comput. Intell. Mag., 1(3):15-31, 2006.</p>
<p>Incremental hierarchical discriminant regression. Juyang Weng, Wey Shiuan, Hwang, IEEE Trans. Neural Networks. 182Juyang Weng and Wey Shiuan Hwang. Incremental hierarchical discriminant regression. IEEE Trans. Neural Networks, 18(2):397-415, 2007.</p>
<p>The Developmental Approach to Multimedia Speech Learning. Juyang Weng, Yong-Beom Lee, Colin H Evans, Proceedings., IEEE Int. Conf. Acoust. Speech, Signal Process. IEEE Int. Conf. Acoust. Speech, Signal ProcessJuyang Weng, Yong-Beom Lee, and Colin H. Evans. The Developmental Approach to Multimedia Speech Learning. In Proceedings., IEEE Int. Conf. Acoust. Speech, Signal Process., 1999.</p>
<p>Online learning for attention, recognition, and tracking by a single developmental framework. Juyang Weng, Matthew Luciw, Proc. Conf. Comput. Vis. Pattern Recognit. Conf. Comput. Vis. Pattern RecognitJuyang Weng and Matthew Luciw. Online learning for attention, recognition, and tracking by a single developmental framework. In Proc. Conf. Comput. Vis. Pattern Recognit., 2010.</p>
<p>Developmental Robots -A New Paradigm. Juyang Weng, Yilu Zhang, Proc. Second Int. Second Int94Juyang Weng and Yilu Zhang. Developmental Robots -A New Paradigm. In Proc. Second Int. Work. Epigenetic Robot. Model. Cogn. Dev. Robot. Syst., volume 94, pages 163-174, 2002.</p>
<p>Priming is not priming is not priming. Dirk Wentura, Klaus Rothermund, Soc. Cogn. 32Dirk Wentura and Klaus Rothermund. Priming is not priming is not priming. Soc. Cogn., 32:47-67, 2014.</p>
<p>Hybrid Approaches to Neural Network-based Language Processing. Stefan Wermter, TR-97-030Tech. Rep.Stefan Wermter. Hybrid Approaches to Neural Network-based Language Processing. Tech. Rep. TR-97-030, 1997.</p>
<p>Hybrid Neural Systems. Stefan Wermter and Ron SunBerlin Heidelberg; New YorkSpringer-VerlagStefan Wermter and Ron Sun, editors. Hybrid Neural Systems. Springer-Verlag Berlin Heidelberg, New York, 2000.</p>
<p>Attention-Situation Awareness (A-SA) Model of Pilot Error. Christopher D Wickens, Jason S Mccarley, Amy L Alexander, Lisa C Thomas, Michael Ambinder, Sam Zheng, Hum. Perform. Model. Aviat. Christopher D. Wickens, Jason S. Mccarley, Amy L. Alexander, Lisa C. Thomas, Michael Ambinder, and Sam Zheng. Attention-Situation Awareness (A-SA) Model of Pilot Error. Hum. Perform. Model. Aviat., pages 213-239, 2008.</p>
<p>A Framework for Resolving Open-World Referential Expressions in Distributed Heterogeneous Knowledge Bases. Tom Williams, Matthias Scheutz, Proc. Thirtieth AAAI Conf. Thirtieth AAAI ConfTom Williams and Matthias Scheutz. A Framework for Resolving Open-World Referential Expressions in Distributed Heterogeneous Knowledge Bases. In Proc. Thirtieth AAAI Conf. Artif. Intell., 2016.</p>
<p>Analogical generalization of activities from single demonstration. Jason R Wilson, Matthias Scheutz, Proc. Ibero-American Conf. Ibero-American ConfJason R. Wilson and Matthias Scheutz. Analogical generalization of activities from single demonstration. In Proc. Ibero-American Conf. Artif. Intell., pages 494-505, 2014.</p>
<p>An Overview of Spatial Processing in Soar/SVS Investigator. Samuel Wintermute, CCA-TR-2009-01Tech. Rep.Samuel Wintermute. An Overview of Spatial Processing in Soar/SVS Investigator. Tech. Rep. CCA-TR-2009-01, 2009.</p>
<p>Imagery in cognitive architecture: Representation and control at multiple levels of abstraction. Samuel Wintermute, Cogn. Syst. Res. Samuel Wintermute. Imagery in cognitive architecture: Representation and control at multiple levels of abstraction. Cogn. Syst. Res., 19-20:1-29, 2012.</p>
<p>Guided Search 2.0 A revised model of visual search. M Jeremy, Wolfe, Psychon. Bull. Rev. 12Jeremy M Wolfe. Guided Search 2.0 A revised model of visual search. Psychon. Bull. Rev., 1(2):202-238, 1994.</p>
<p>A mobile robot that recognizes people. C Wong, D Kortenkamp, M Speich, Proc. 7th IEEE Int. Conf. Tools with Artif. Intell. 7th IEEE Int. Conf. Tools with Artif. IntellC. Wong, D. Kortenkamp, and M. Speich. A mobile robot that recognizes people. In Proc. 7th IEEE Int. Conf. Tools with Artif. Intell., 1995.</p>
<p>Quantitative Explorations of Category Learning with Symbolic Concept Acquisition ATC Task &amp; Human Experimental Results. Robert E Wray, Ronald Chong, Proc. 5th Int. Conf. Cogn. Model. 5th Int. Conf. Cogn. ModelRobert E. Wray and Ronald Chong. Quantitative Explorations of Category Learning with Symbolic Concept Acquisition ATC Task &amp; Human Experimental Results. In Proc. 5th Int. Conf. Cogn. Model., 2003.</p>
<p>The role of competitive inhibition and top-down feedback in binding during object recognition. Dean Wyatte, Seth Herd, Brian Mingus, Randall O&apos; Reilly, Front. Psychol. 3Dean Wyatte, Seth Herd, Brian Mingus, and Randall O'Reilly. The role of competitive inhibition and top-down feedback in binding during object recognition. Front. Psychol., 3, 2012.</p>
<p>Scene parsing and fusion-based continuous traversable region formation. Xuhong Xiao, Gee Wah, Ng, Yeo Ye Yuan Sin Tan, Chuan, Comput. Vis. -ACCV. C. Jawahar and Shan S.Xuhong Xiao, Gee Wah Ng, Yuan Sin Tan, and Yeo Ye Chuan. Scene parsing and fusion-based continuous traversable region formation. In C. Jawahar and Shan S., editors, Comput. Vis. -ACCV 2014 Work., 2015.</p>
<p>RPD-based Hypothesis Reasoning for Cyber Situation Awareness. John Yen, Michael Mcneese, Tracy Mullen, David Hall, Xiaocong Fan, Peng Liu, Cyber Situational Aware. John Yen, Michael McNeese, Tracy Mullen, David Hall, Xiaocong Fan, and Peng Liu. RPD-based Hypothesis Reasoning for Cyber Situation Awareness. In Cyber Situational Aware., pages 39-49. 2010.</p>
<p>Investigating multimodal real-time patterns of joint attention in an HRI word learning task. Chen Yu, Matthias Scheutz, Paul Schermerhorn, Human-Robot Interact. (HRI), 2010 5th ACM/IEEE Int. Conf. Chen Yu, Matthias Scheutz, and Paul Schermerhorn. Investigating multimodal real-time patterns of joint attention in an HRI word learning task. In Human-Robot Interact. (HRI), 2010 5th ACM/IEEE Int. Conf., pages 309-316, 2010.</p>
<p>Interface Agents in Complex Systems. Wayne W Zachary, Jean-Christoph Le Mentec, Joan M Ryder, Hum. Interact. with Complex Syst. 141Wayne W. Zachary, Jean-Christoph Le Mentec, and Joan M. Ryder. Interface Agents in Complex Systems. Hum. Interact. with Complex Syst., 14(1):260-264, 2016.</p>
<p>Cognitive task analysis and modeling of decision making in complex environments. Joan M Wayne W Zachary, James H Ryder, Janis A Hicinbothom, Eduardo Cannon-Bowers, Salas, Mak. Decis. under Stress Implic. Individ. team training. J. Cannon-Bowers and E. SalasWashington, DCWayne W Zachary, Joan M Ryder, James H Hicinbothom, Janis A Cannon-Bowers, and Eduardo Salas. Cognitive task analysis and modeling of decision making in complex environments. In J. Cannon-Bowers and E. Salas, editors, Mak. Decis. under Stress Implic. Individ. team training., pages 315-344. Washington, DC, 1998.</p>
<p>COGNET Reprezentation of Tactical Decision-Making in Anti-Air Warfare. Wayne W Zachary, Allen L Zaklad, James H Hicinbothom, Joan M Ryder, Janine A Purcell, Proc. Hum. HumWayne W. Zachary, Allen L. Zaklad, James H. Hicinbothom, Joan M. Ryder, and Janine A. Purcell. COGNET Reprezen- tation of Tactical Decision-Making in Anti-Air Warfare. In Proc. Hum. Factors Ergon. Soc. 37th Annu. Meet., pages 1112-1116, 1993.</p>
<p>A developing sensory mapping for robots. N Zhang, J Weng, Z Zhang, Proc. 2nd Int. Conf. Dev. Learn. ICDL 2002. 2nd Int. Conf. Dev. Learn. ICDL 2002N. Zhang, J. Weng, and Z. Zhang. A developing sensory mapping for robots. In Proc. 2nd Int. Conf. Dev. Learn. ICDL 2002, pages 13-20, 2002.</p>
<p>Task transfer by a developmental robot. Yilu Zhang, Juyang Weng, IEEE Trans. Evol. Comput. 112Yilu Zhang and Juyang Weng. Task transfer by a developmental robot. IEEE Trans. Evol. Comput., 11(2):226-248, 2007.</p>
<p>Image classification using HTM cortical learning algorithms. Wen Zhuo, Zhiguo Cao, Yueming Qin, Zhenghong Yu, Yang Xiao, Proc. 21st Int. Conf. Pattern Recognit. 21st Int. Conf. Pattern RecognitWen Zhuo, Zhiguo Cao, Yueming Qin, Zhenghong Yu, and Yang Xiao. Image classification using HTM cortical learning algorithms. In Proc. 21st Int. Conf. Pattern Recognit., pages 2452-2455, 2012.</p>            </div>
        </div>

    </div>
</body>
</html>