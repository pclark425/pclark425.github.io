<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2604 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2604</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2604</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-9801612f212b1383124a1685268485bd832fe715</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/9801612f212b1383124a1685268485bd832fe715" target="_blank">Experimental discovery of structure–property relationships in ferroelectric materials via active learning</a></p>
                <p><strong>Paper Venue:</strong> Nature Machine Intelligence</p>
                <p><strong>Paper TL;DR:</strong> This approach combines the power of machine learning methods to learn the correlative relationships between high-dimensional data, as well as human-based physics insights encoded into the acquisition function, and demonstrates that on- and off-field hysteresis loops are dominated by different mechanisms.</p>
                <p><strong>Paper Abstract:</strong> Emergent functionalities of structural and topological defects in ferroelectric materials underpin an extremely broad spectrum of applications ranging from domain wall electronics to high dielectric and electromechanical responses. Many of these functionalities have been discovered and quantified via local scanning probe microscopy methods. However, the search has until now been based on either trial and error, or using auxiliary information such as the topography or domain wall structure to identify potential objects of interest on the basis of the intuition of operator or pre-existing hypotheses, with subsequent manual exploration. Here we report the development and implementation of a machine learning framework that actively discovers relationships between local domain structure and polarization-switching characteristics in ferroelectric materials encoded in the hysteresis loop. The hysteresis loops and their scalar descriptors such as nucleation bias, coercive bias and the hysteresis loop area (or more complex functionals of hysteresis loop shape) and corresponding uncertainties are used to guide the discovery of these relationships via automated piezoresponse force microscopy and spectroscopy experiments. As such, this approach combines the power of machine learning methods to learn the correlative relationships between high-dimensional data, as well as human-based physics insights encoded into the acquisition function. For ferroelectric materials, this automated workflow demonstrates that the discovery path and sampling points of on- and off-field hysteresis loops are largely different, indicating that on- and off-field hysteresis loops are dominated by different mechanisms. The proposed approach is universal and can be applied to a broad range of modern imaging and spectroscopy methods ranging from other scanning probe microscopy modalities to electron microscopy and chemical imaging. An automated workflow for scanning probe microscopy, steered by an active learning framework, can efficiently explore relationships between local domain structure and physical properties. Such a capability is demonstrated in a piezoresponse force microscopy experiment to guide measurements of ferroelectric materials.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2604.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2604.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DKL-BO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep Kernel Learning with Bayesian Optimization (DKL-BO)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An active-learning workflow that combines a neural-network feature extractor (deep kernel) with Gaussian process regression and acquisition-driven Bayesian optimization to select spectroscopic measurement locations guided by image-derived descriptors and uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DKL-BO (Deep Kernel Learning + Bayesian Optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A system that embeds high-dimensional structural image patches via a feedforward neural network (feature extractor) into a low-dimensional latent space; a Gaussian Process (GP) base kernel operates on that latent representation ('deep kernel'). The DKL GP is trained (stochastic variational inference) on a small set of patch–spectrum (or patch–scalar descriptor) observations to produce predictive means and variances for all unmeasured locations. An acquisition function (used: expected improvement, or other user-defined physics- or information-theoretic functions) computed from the predictive mean and variance ranks unmeasured points; the top-ranked point(s) are then measured on the physical microscope and the loop repeats. The system supports vector-valued outputs by shared latent spaces feeding multiple GPs and requires scalarization for single-objective acquisition. Implemented end-to-end in a Jupyter notebook that interfaces with LabView-NI to control the PFM hardware in closed-loop.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials science / scanning probe microscopy (piezoresponse force microscopy) — discovery of structure–property relationships (domain structure vs. hysteresis loops); broadly applicable to hyperspectral imaging, electron microscopy, chemical imaging, nanoindentation, combinatorial materials screening.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Sequential Bayesian optimization: allocate scarce spectroscopic measurement resources by maximizing an acquisition function acq(mean, variance) computed from the DKL GP predictions on all candidate image patches; begin with a small random seed sample, train DKL, predict over grid, pick argmax(acq) for next measurement, retrain, and iterate until budget exhausted (e.g., fixed number of measurements). The acquisition function can encode physics-based targets (e.g., loop area, loop width, coercive field) or information-theoretic objectives (e.g., entropy growth/curiosity).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Not given as an explicit numeric metric; cost is discussed qualitatively as wall-clock time for GP training/inference and end-to-end DKL training iterations. Paper notes standard GP training/inference time can exceed measurement time for high-dimensional spectroscopies, motivating dimensionality reduction via a neural embedding. DKL training cost includes neural network parameter updates (MLP with 3 hidden layers: 1000/500/50) and GP variational inference over latent dimensions; no FLOPs or monetary cost reported.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Predictive variance from the DKL GP (uncertainty) combined with predictive mean, used inside acquisition functions; implemented acquisition function: expected improvement (EI). Paper also mentions possible use of information-theoretic criteria such as entropy growth (curiosity learning) as alternative information-gain metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Balanced via acquisition functions that combine predicted mean and variance (explicitly: expected improvement). By design, EI targets points with high expected improvement over current best (exploitation) while also accounting for uncertainty (exploration). The operator can choose physics-driven scalar descriptors (exploitation) or information-theoretic/computation-driven descriptors (exploration/curiosity) to bias the acquisition.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit diversity emerges from uncertainty-driven acquisition (EI) and alternative acquisition criteria (entropy growth / curiosity); multi-output cases share latent embeddings, allowing correlated outputs to guide exploration across modalities. The paper does not implement an explicit diversity-regularizer (e.g., determinantal point process or penalized clustering), but suggests scalarization choices and curiosity/entropy objectives as ways to favor diverse behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed-number-of-experiments sampling budget (practical limits: measurement time, probe stability); examples: reconstruction experiments with 0.5%, 1%, 5%, 10%, 15% and operational runs with 200 measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Budget respected by stopping after a fixed number of sequential acquisitions; allocation optimized via BO to maximize acquisition objective per measurement; DKL reduces required sample fraction by leveraging image priors so fewer measurements produce accurate reconstructions under the fixed-budget constraint.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Defined by user-chosen physics descriptors or novelty criteria: e.g., loop area (A_loop), loop width (W_loop), coercive/nucleation biases, goodness-of-fit to model functions, or information-theoretic novelty (entropy growth). 'Breakthrough' corresponds to high values or novel values of these descriptors or high-uncertainty regions indicating new mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reconstruction mean-squared error (MSE) and structural similarity between DKL predictions and ground-truth high-density maps; qualitative demonstration of accurate map reconstructions using small sampled fractions (examples: 15% random sampling and DKL-BO runs with 0.5%–10% sampling produce visually accurate reconstructions). Operational run: 200 sequential DKL-BO measurements used to predict on-field and off-field loop area maps. No explicit numerical efficiency ratios reported in text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Random sampling, dense uniform grid sampling, and classical GP-based Bayesian Optimization (standard GP/BO) without deep-kernel embedding.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Qualitative/empirical improvements: DKL better reconstructs feature-rich maps from far fewer measurements compared to classical GP/BO and random sampling; preserves features at all length scales (claimed harder for classical BO). Specific numeric comparisons (e.g., percent MSE improvements) are shown in figures but not listed as explicit numbers in text.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Demonstrated ability to reconstruct complex hyperspectral-derived maps using orders-of-magnitude fewer spectroscopic measurements (examples: sensible reconstructions with 0.5%–15% of full grid), and to perform discovery-guided experiments of 200 measurements rather than full 10,000-point grids; no single overall percent reduction or speedup in wall-clock time is numerically reported.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Discusses tradeoffs qualitatively: (1) Standard GP/BO scales poorly with input dimensionality — computational training/inference cost may exceed measurement time, making full GP-BO impractical; (2) DKL trades added neural-network training cost and need for an embedding for drastically reduced GP dimensionality and tractable inference; (3) acquisition function choice trades exploration vs. exploitation and can encode physics goals (targeted discovery) or information objectives (curiosity); (4) pretraining (transfer learning) can reduce online cost but risks out-of-distribution drift and requires careful validation. No formal quantitative multi-objective tradeoff optimization presented.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Key insights: (a) Using image-derived embeddings as priors (DKL) meaningfully reduces the number of spectroscopic measurements required to reconstruct property maps under fixed budgets; (b) choice of scalar descriptor/acquisition function strongly determines sampling path and therefore which mechanisms are discovered (e.g., on-field vs off-field loop area objectives produced different sampled regions); (c) sequential BO with DKL enables targeted discovery under practical probe/time constraints; (d) pretraining and transfer learning are promising for faster allocation but need guardrails against distributional shifts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Experimental discovery of structure–property relationships in ferroelectric materials via active learning', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2604.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2604.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Standard GP-BO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gaussian Process Regression with Bayesian Optimization (standard GP/BO)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Classical GP-based active learning / Bayesian optimization that uses a Gaussian Process with a standard kernel (e.g., squared exponential) to predict mean and variance over the input space and an acquisition function to select next queries.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Standard GP-based Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses a GP with a base kernel (e.g., squared-exponential) trained on observed input–output pairs; predictive mean and variance are computed at candidate points and combined via an acquisition function (such as expected improvement) to choose subsequent experiments. Usually operates directly on low-dimensional input spaces; does not learn representations from high-dimensional structured data.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General active learning / experiment design across sciences; cited in the paper in the context of microscopy and probe trajectory control.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Select points that maximize an acquisition function constructed from GP predictive mean and variance (e.g., expected improvement), iteratively updating the GP with each new observation until a sampling budget is exhausted.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Discussed qualitatively as GP training/inference time (wall-clock). The paper notes poor scaling with input dimensionality; training and inference may become computationally expensive (matrix inversions) and exceed measurement time for high-dimensional spectroscopies.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Predictive variance and expected-improvement style acquisition functions are used as proxies for information gain; mutual-information style objectives are not explicitly described for standard GP in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Acquisition functions like expected improvement balance exploration (via variance term) and exploitation (via predicted mean).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity mechanisms are described; diversity arises indirectly from uncertainty-driven sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed sampling budget / measurement time; practical constraints include acquisition time and probe stability.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Stops after budget expended; no explicit budget-aware objective (e.g., cost-weighted acquisition) described.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Typically same scalar descriptors or acquisition-defined criteria (not specified here); paper notes standard GP/BO is limited to low-dimensional signals and so ill-suited for structure–property active learning with high-dimensional inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not quantified in the paper; referenced as a baseline with limitations in high-dimensional settings.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared conceptually/empirically against DKL-BO and random sampling in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Paper states standard GP-BO is ill-suited for high-dimensional spectroscopic measurements because of scaling and lack of representation learning; DKL-BO qualitatively outperforms classical GP-BO for image-guided spectroscopy reconstruction tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Standard GP achieves good uncertainty quantification but scales poorly; it lacks representation learning and cannot leverage image priors without dimensionality reduction, leading to a tradeoff between fidelity of GP uncertainty estimates and computational tractability.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Standard GP-BO works well in low-dimensional input spaces but should be combined with representation learning (as in DKL) or dimensionality reduction for high-dimensional experimental design.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Experimental discovery of structure–property relationships in ferroelectric materials via active learning', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2604.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2604.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Expected Improvement (EI)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Expected Improvement acquisition function</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Bayesian optimization acquisition function that selects the next point by maximizing the expected improvement over the current best observed value, combining predictive mean and variance from a probabilistic surrogate.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Expected Improvement (EI) acquisition function</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>EI computes the expected positive difference between the surrogate model’s predicted value and the best-observed value so far, integrating over the surrogate’s predictive distribution (mean and variance) at each candidate point; DKL uses EI to select next spectroscopic measurement locations in the experiments reported.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Acquisition in Bayesian optimization for experimental design and active learning (used here in scanning probe spectroscopy experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Ranks candidate experiments by expected improvement per measurement and selects the argmax under the available budget, thereby allocating experiments to points likely to improve target metrics while accounting for uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Cost is the computational time to evaluate the acquisition function across all candidate points (depends on number of candidates and the cost of evaluating GP predictive mean/variance). Paper does not provide explicit numeric metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Uses surrogate predictive mean and variance; not a direct information-theoretic measure but trades-off improvement potential and uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>EI naturally balances exploitation (high predicted mean) and exploration (high predictive variance) through expected improvement computation.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity regularization; EI may repeatedly select clustered points if they promise high improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed number of sequential acquisitions; selection repeated until budget exhausted.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Sequential greedy selection of max-acquisition point per iteration; no global budget-optimized plan is described.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Breakthroughs correspond to large expected improvements in the chosen scalar descriptor (e.g., loop area), as identified by EI.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Operationalized via resulting reconstructions and discovery trajectories (qualitative and via MSE figures), but no numeric EI-specific performance numbers reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared within the paper to alternative acquisition choices such as random sampling and entropy-based curiosity criteria.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>EI-driven DKL-BO produced targeted discovery and accurate reconstructions; paper asserts better outcomes vs random sampling and classical BO in high-dimensional settings when combined with DKL embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>EI offers a practical mechanism to trade exploration vs exploitation, but its effectiveness depends on the fidelity of surrogate uncertainty; embedding via DKL improves surrogate quality in high-dimensional image-guided spectroscopy settings.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Choosing EI on DKL predictions is an effective allocation strategy in the presented microscopy experiments; however, the scalar descriptor chosen for EI strongly shapes which physical behaviors are discovered.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Experimental discovery of structure–property relationships in ferroelectric materials via active learning', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2604.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2604.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Curiosity / Entropy Acquisition</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Information-theoretic / curiosity-driven acquisition (entropy growth)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An exploration strategy that targets regions expected to increase dataset entropy or uncertainty, promoting discovery of diverse and novel behaviors rather than solely optimizing a scalar target.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Curiosity-driven / entropy-maximizing acquisition</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Acquisition functions based on information theory (e.g., maximizing expected entropy growth or mutual information) that preferentially sample locations where the model expects to learn the most (largest uncertainty reduction or increase in dataset variability). The paper describes this as an alternative to physics-driven scalar objectives for curiosity learning and novelty discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Active learning for experimental discovery where novelty/diversity is a primary goal (e.g., exploratory microscopy, materials discovery).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates measurements to maximize expected information gain or entropy growth per experiment; encourages exploration of under-characterized regions that potentially reveal new mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Not specified; computing expected information-theoretic objectives usually requires additional computations over predictive distributions (e.g., integrals for mutual information) and can be more expensive than simple EI evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Entropy growth, mutual information, or other information-theoretic quantities are explicitly proposed as acquisition criteria.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Purely exploratory when used as the acquisition objective (prioritizes high-uncertainty / high-information locations); can be combined with exploitation metrics for mixed strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Explicit: by maximizing entropy or information gain the method promotes sampling of diverse behaviors and under-sampled regimes.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed sampling budget; practical measurement limits.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Selects measurements that maximize expected information gain per measurement under the budget, but the paper does not present a formal budget-utility optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Novelty identified by large increases in information (entropy) or by observing out-of-distribution / high-uncertainty behaviors that indicate new mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not empirically evaluated in this paper; mentioned as a qualitative alternative objective to physics-driven descriptors.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Conceptually compared to physics-driven acquisition like EI on scalar descriptors; no quantitative baseline comparisons provided.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not quantified in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper discusses curiosity learning as a complementary strategy to target discovery and diversity, noting human operator can choose between physics-based exploitation and information-theoretic exploration; computational cost of information-theoretic metrics is noted as a consideration.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Information-theoretic objectives are suitable when discovery/novelty/diversity are prioritized; they provide an explicit mechanism to promote exploring under-characterized behaviors, but the paper does not provide empirical allocation-optimization rules.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Experimental discovery of structure–property relationships in ferroelectric materials via active learning', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2604.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2604.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FerroBot (line-by-line AE)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FerroBot (line-by-line feedback autonomous experiment in PFM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A previously reported autonomous PFM system that used operator-defined image features and line-by-line feedback during classical rectangular scans to guide AFM/PFM imaging without human intervention.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>FerroBot (line-by-line AE implementation)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Autonomous AFM/PFM imaging system employing human-defined features of interest during line-by-line scanning to adapt imaging and highlight regions of interest; used as an early demonstration of AE feasibility in PFM, but relied on pre-defined feature engineering rather than learned embeddings or GP-based acquisition.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Piezoresponse force microscopy / autonomous scanning probe microscopy.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Operational adaptation of scan trajectory based on simple feedback rules tied to predefined image features; allocates scanning effort to regions flagged by features.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Not specified in paper; implicit low computational overhead due to simple feature-based rules.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Not formalized; selection based on operator-defined features rather than probabilistic information measures.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Feature-driven exploitation of regions deemed interesting by engineered criteria; limited exploration capability.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>None explicit; relies on hand-crafted feature definitions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Implicitly constrained by scan time and operator objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Adaptation of scan density/trajectory to prioritize regions of interest; no formal budget optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not specified; discovery depends on operator-chosen features correlating with interesting physics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Demonstrated feasibility of autonomously operating AFM in imaging modes; no quantitative comparison to BO methods provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Serves as a prior AE example contrasted with DKL-BO which uses representation learning and probabilistic acquisition.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not directly compared numerically; paper positions FerroBot as more limited due to reliance on engineered features.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Simple feedback methods have low computational cost and are straightforward to deploy, but lack the ability to learn complex correlative relationships from multidimensional data, reducing their effectiveness for structure–property discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Feature-engineered AE can efficiently allocate scanning resources when suitable heuristics exist, but for complex high-dimensional spectroscopy tasks, representation learning + probabilistic acquisition (DKL-BO) is preferable.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Experimental discovery of structure–property relationships in ferroelectric materials via active learning', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2604.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2604.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pretrained DCNN / Transfer Learning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pretrained deep convolutional neural network feature extractor / transfer learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The idea of pretraining the neural network feature extractor on prior experimental data (from same or related systems) to accelerate online DKL training and reduce required on-the-fly measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Pretrained DCNN / transfer learning for DKL feature extractor</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Proposal to pretrain the DKL neural network (or DCNN feature extractor) on earlier experiments or similar materials so that the online DKL-BO requires fewer iterations and less data to reach useful predictive performance. The paper notes that pretraining is analogous to transfer learning but highlights the need to analyze out-of-distribution drift when reusing pretrained extractors.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Accelerating active-learning workflows in microscopy and other experimental domains by reducing online data requirements.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Reduce online measurement allocation by leveraging pretrained representations, thereby allocating fewer new experiments toward representation learning and more toward targeted exploration/exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Qualitatively: decreases online training/inference wall-clock time and measurement budget but introduces upfront (offline) pretraining costs; no explicit numeric metrics provided.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Not explicitly defined; pretraining aims to improve surrogate predictive accuracy and hence the information gain per new measurement by starting from informative embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>By improving representation, pretrained extractors can shift the exploration-exploitation tradeoff toward more confident exploitation or more efficient exploration; specifics depend on downstream acquisition choices.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Not explicit; may reduce need for exploratory diversity if pretrained model is confident, but this raises risk of missing out-of-distribution discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Tradeoff between offline pretraining cost (time/computation) and online measurement budget; concern for out-of-distribution risk if pretraining mismatch occurs.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Not implemented in this paper; authors recommend careful analysis of distributional drift if pretraining is used.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not defined; pretraining could improve detection of known signatures but risks missing novel phenomena if OOD drift is not handled.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not empirically evaluated here; recommended as a direction to reduce online resource allocation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared conceptually to training the DKL feature extractor from scratch online with small seed samples.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>No empirical comparison presented; authors note both potential benefits (faster convergence) and risks (OOD drift).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Pretraining trades offline computational cost for reduced online sampling and faster active-learning loops; must be balanced against the risk that pretrained features may not generalize to the current experiment (distributional shift).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Pretraining is promising for improving allocation efficiency but requires validation for distributional mismatch before being used to bias experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Experimental discovery of structure–property relationships in ferroelectric materials via active learning', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Fast Scanning Probe Microscopy via Machine Learning: Non-Rectangular Scans with Compressed Sensing and Gaussian Process Optimization <em>(Rating: 2)</em></li>
                <li>Artificial-intelligence-driven scanning probe microscopy <em>(Rating: 2)</em></li>
                <li>An artificial intelligence atomic force microscope enabled by machine learning <em>(Rating: 2)</em></li>
                <li>Enabling autonomous scanning probe microscopy imaging of single molecules with deep learning <em>(Rating: 2)</em></li>
                <li>Automated and Autonomous Experiment in Electron and Scanning Probe Microscopy <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2604",
    "paper_id": "paper-9801612f212b1383124a1685268485bd832fe715",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "DKL-BO",
            "name_full": "Deep Kernel Learning with Bayesian Optimization (DKL-BO)",
            "brief_description": "An active-learning workflow that combines a neural-network feature extractor (deep kernel) with Gaussian process regression and acquisition-driven Bayesian optimization to select spectroscopic measurement locations guided by image-derived descriptors and uncertainty.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "DKL-BO (Deep Kernel Learning + Bayesian Optimization)",
            "system_description": "A system that embeds high-dimensional structural image patches via a feedforward neural network (feature extractor) into a low-dimensional latent space; a Gaussian Process (GP) base kernel operates on that latent representation ('deep kernel'). The DKL GP is trained (stochastic variational inference) on a small set of patch–spectrum (or patch–scalar descriptor) observations to produce predictive means and variances for all unmeasured locations. An acquisition function (used: expected improvement, or other user-defined physics- or information-theoretic functions) computed from the predictive mean and variance ranks unmeasured points; the top-ranked point(s) are then measured on the physical microscope and the loop repeats. The system supports vector-valued outputs by shared latent spaces feeding multiple GPs and requires scalarization for single-objective acquisition. Implemented end-to-end in a Jupyter notebook that interfaces with LabView-NI to control the PFM hardware in closed-loop.",
            "application_domain": "Materials science / scanning probe microscopy (piezoresponse force microscopy) — discovery of structure–property relationships (domain structure vs. hysteresis loops); broadly applicable to hyperspectral imaging, electron microscopy, chemical imaging, nanoindentation, combinatorial materials screening.",
            "resource_allocation_strategy": "Sequential Bayesian optimization: allocate scarce spectroscopic measurement resources by maximizing an acquisition function acq(mean, variance) computed from the DKL GP predictions on all candidate image patches; begin with a small random seed sample, train DKL, predict over grid, pick argmax(acq) for next measurement, retrain, and iterate until budget exhausted (e.g., fixed number of measurements). The acquisition function can encode physics-based targets (e.g., loop area, loop width, coercive field) or information-theoretic objectives (e.g., entropy growth/curiosity).",
            "computational_cost_metric": "Not given as an explicit numeric metric; cost is discussed qualitatively as wall-clock time for GP training/inference and end-to-end DKL training iterations. Paper notes standard GP training/inference time can exceed measurement time for high-dimensional spectroscopies, motivating dimensionality reduction via a neural embedding. DKL training cost includes neural network parameter updates (MLP with 3 hidden layers: 1000/500/50) and GP variational inference over latent dimensions; no FLOPs or monetary cost reported.",
            "information_gain_metric": "Predictive variance from the DKL GP (uncertainty) combined with predictive mean, used inside acquisition functions; implemented acquisition function: expected improvement (EI). Paper also mentions possible use of information-theoretic criteria such as entropy growth (curiosity learning) as alternative information-gain metrics.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Balanced via acquisition functions that combine predicted mean and variance (explicitly: expected improvement). By design, EI targets points with high expected improvement over current best (exploitation) while also accounting for uncertainty (exploration). The operator can choose physics-driven scalar descriptors (exploitation) or information-theoretic/computation-driven descriptors (exploration/curiosity) to bias the acquisition.",
            "diversity_mechanism": "Implicit diversity emerges from uncertainty-driven acquisition (EI) and alternative acquisition criteria (entropy growth / curiosity); multi-output cases share latent embeddings, allowing correlated outputs to guide exploration across modalities. The paper does not implement an explicit diversity-regularizer (e.g., determinantal point process or penalized clustering), but suggests scalarization choices and curiosity/entropy objectives as ways to favor diverse behaviors.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed-number-of-experiments sampling budget (practical limits: measurement time, probe stability); examples: reconstruction experiments with 0.5%, 1%, 5%, 10%, 15% and operational runs with 200 measurements.",
            "budget_constraint_handling": "Budget respected by stopping after a fixed number of sequential acquisitions; allocation optimized via BO to maximize acquisition objective per measurement; DKL reduces required sample fraction by leveraging image priors so fewer measurements produce accurate reconstructions under the fixed-budget constraint.",
            "breakthrough_discovery_metric": "Defined by user-chosen physics descriptors or novelty criteria: e.g., loop area (A_loop), loop width (W_loop), coercive/nucleation biases, goodness-of-fit to model functions, or information-theoretic novelty (entropy growth). 'Breakthrough' corresponds to high values or novel values of these descriptors or high-uncertainty regions indicating new mechanisms.",
            "performance_metrics": "Reconstruction mean-squared error (MSE) and structural similarity between DKL predictions and ground-truth high-density maps; qualitative demonstration of accurate map reconstructions using small sampled fractions (examples: 15% random sampling and DKL-BO runs with 0.5%–10% sampling produce visually accurate reconstructions). Operational run: 200 sequential DKL-BO measurements used to predict on-field and off-field loop area maps. No explicit numerical efficiency ratios reported in text.",
            "comparison_baseline": "Random sampling, dense uniform grid sampling, and classical GP-based Bayesian Optimization (standard GP/BO) without deep-kernel embedding.",
            "performance_vs_baseline": "Qualitative/empirical improvements: DKL better reconstructs feature-rich maps from far fewer measurements compared to classical GP/BO and random sampling; preserves features at all length scales (claimed harder for classical BO). Specific numeric comparisons (e.g., percent MSE improvements) are shown in figures but not listed as explicit numbers in text.",
            "efficiency_gain": "Demonstrated ability to reconstruct complex hyperspectral-derived maps using orders-of-magnitude fewer spectroscopic measurements (examples: sensible reconstructions with 0.5%–15% of full grid), and to perform discovery-guided experiments of 200 measurements rather than full 10,000-point grids; no single overall percent reduction or speedup in wall-clock time is numerically reported.",
            "tradeoff_analysis": "Discusses tradeoffs qualitatively: (1) Standard GP/BO scales poorly with input dimensionality — computational training/inference cost may exceed measurement time, making full GP-BO impractical; (2) DKL trades added neural-network training cost and need for an embedding for drastically reduced GP dimensionality and tractable inference; (3) acquisition function choice trades exploration vs. exploitation and can encode physics goals (targeted discovery) or information objectives (curiosity); (4) pretraining (transfer learning) can reduce online cost but risks out-of-distribution drift and requires careful validation. No formal quantitative multi-objective tradeoff optimization presented.",
            "optimal_allocation_findings": "Key insights: (a) Using image-derived embeddings as priors (DKL) meaningfully reduces the number of spectroscopic measurements required to reconstruct property maps under fixed budgets; (b) choice of scalar descriptor/acquisition function strongly determines sampling path and therefore which mechanisms are discovered (e.g., on-field vs off-field loop area objectives produced different sampled regions); (c) sequential BO with DKL enables targeted discovery under practical probe/time constraints; (d) pretraining and transfer learning are promising for faster allocation but need guardrails against distributional shifts.",
            "uuid": "e2604.0",
            "source_info": {
                "paper_title": "Experimental discovery of structure–property relationships in ferroelectric materials via active learning",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "Standard GP-BO",
            "name_full": "Gaussian Process Regression with Bayesian Optimization (standard GP/BO)",
            "brief_description": "Classical GP-based active learning / Bayesian optimization that uses a Gaussian Process with a standard kernel (e.g., squared exponential) to predict mean and variance over the input space and an acquisition function to select next queries.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Standard GP-based Bayesian Optimization",
            "system_description": "Uses a GP with a base kernel (e.g., squared-exponential) trained on observed input–output pairs; predictive mean and variance are computed at candidate points and combined via an acquisition function (such as expected improvement) to choose subsequent experiments. Usually operates directly on low-dimensional input spaces; does not learn representations from high-dimensional structured data.",
            "application_domain": "General active learning / experiment design across sciences; cited in the paper in the context of microscopy and probe trajectory control.",
            "resource_allocation_strategy": "Select points that maximize an acquisition function constructed from GP predictive mean and variance (e.g., expected improvement), iteratively updating the GP with each new observation until a sampling budget is exhausted.",
            "computational_cost_metric": "Discussed qualitatively as GP training/inference time (wall-clock). The paper notes poor scaling with input dimensionality; training and inference may become computationally expensive (matrix inversions) and exceed measurement time for high-dimensional spectroscopies.",
            "information_gain_metric": "Predictive variance and expected-improvement style acquisition functions are used as proxies for information gain; mutual-information style objectives are not explicitly described for standard GP in this paper.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Acquisition functions like expected improvement balance exploration (via variance term) and exploitation (via predicted mean).",
            "diversity_mechanism": "No explicit diversity mechanisms are described; diversity arises indirectly from uncertainty-driven sampling.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed sampling budget / measurement time; practical constraints include acquisition time and probe stability.",
            "budget_constraint_handling": "Stops after budget expended; no explicit budget-aware objective (e.g., cost-weighted acquisition) described.",
            "breakthrough_discovery_metric": "Typically same scalar descriptors or acquisition-defined criteria (not specified here); paper notes standard GP/BO is limited to low-dimensional signals and so ill-suited for structure–property active learning with high-dimensional inputs.",
            "performance_metrics": "Not quantified in the paper; referenced as a baseline with limitations in high-dimensional settings.",
            "comparison_baseline": "Compared conceptually/empirically against DKL-BO and random sampling in the paper.",
            "performance_vs_baseline": "Paper states standard GP-BO is ill-suited for high-dimensional spectroscopic measurements because of scaling and lack of representation learning; DKL-BO qualitatively outperforms classical GP-BO for image-guided spectroscopy reconstruction tasks.",
            "efficiency_gain": null,
            "tradeoff_analysis": "Standard GP achieves good uncertainty quantification but scales poorly; it lacks representation learning and cannot leverage image priors without dimensionality reduction, leading to a tradeoff between fidelity of GP uncertainty estimates and computational tractability.",
            "optimal_allocation_findings": "Standard GP-BO works well in low-dimensional input spaces but should be combined with representation learning (as in DKL) or dimensionality reduction for high-dimensional experimental design.",
            "uuid": "e2604.1",
            "source_info": {
                "paper_title": "Experimental discovery of structure–property relationships in ferroelectric materials via active learning",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "Expected Improvement (EI)",
            "name_full": "Expected Improvement acquisition function",
            "brief_description": "A Bayesian optimization acquisition function that selects the next point by maximizing the expected improvement over the current best observed value, combining predictive mean and variance from a probabilistic surrogate.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Expected Improvement (EI) acquisition function",
            "system_description": "EI computes the expected positive difference between the surrogate model’s predicted value and the best-observed value so far, integrating over the surrogate’s predictive distribution (mean and variance) at each candidate point; DKL uses EI to select next spectroscopic measurement locations in the experiments reported.",
            "application_domain": "Acquisition in Bayesian optimization for experimental design and active learning (used here in scanning probe spectroscopy experiments).",
            "resource_allocation_strategy": "Ranks candidate experiments by expected improvement per measurement and selects the argmax under the available budget, thereby allocating experiments to points likely to improve target metrics while accounting for uncertainty.",
            "computational_cost_metric": "Cost is the computational time to evaluate the acquisition function across all candidate points (depends on number of candidates and the cost of evaluating GP predictive mean/variance). Paper does not provide explicit numeric metrics.",
            "information_gain_metric": "Uses surrogate predictive mean and variance; not a direct information-theoretic measure but trades-off improvement potential and uncertainty.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "EI naturally balances exploitation (high predicted mean) and exploration (high predictive variance) through expected improvement computation.",
            "diversity_mechanism": "No explicit diversity regularization; EI may repeatedly select clustered points if they promise high improvement.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed number of sequential acquisitions; selection repeated until budget exhausted.",
            "budget_constraint_handling": "Sequential greedy selection of max-acquisition point per iteration; no global budget-optimized plan is described.",
            "breakthrough_discovery_metric": "Breakthroughs correspond to large expected improvements in the chosen scalar descriptor (e.g., loop area), as identified by EI.",
            "performance_metrics": "Operationalized via resulting reconstructions and discovery trajectories (qualitative and via MSE figures), but no numeric EI-specific performance numbers reported.",
            "comparison_baseline": "Compared within the paper to alternative acquisition choices such as random sampling and entropy-based curiosity criteria.",
            "performance_vs_baseline": "EI-driven DKL-BO produced targeted discovery and accurate reconstructions; paper asserts better outcomes vs random sampling and classical BO in high-dimensional settings when combined with DKL embeddings.",
            "efficiency_gain": null,
            "tradeoff_analysis": "EI offers a practical mechanism to trade exploration vs exploitation, but its effectiveness depends on the fidelity of surrogate uncertainty; embedding via DKL improves surrogate quality in high-dimensional image-guided spectroscopy settings.",
            "optimal_allocation_findings": "Choosing EI on DKL predictions is an effective allocation strategy in the presented microscopy experiments; however, the scalar descriptor chosen for EI strongly shapes which physical behaviors are discovered.",
            "uuid": "e2604.2",
            "source_info": {
                "paper_title": "Experimental discovery of structure–property relationships in ferroelectric materials via active learning",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "Curiosity / Entropy Acquisition",
            "name_full": "Information-theoretic / curiosity-driven acquisition (entropy growth)",
            "brief_description": "An exploration strategy that targets regions expected to increase dataset entropy or uncertainty, promoting discovery of diverse and novel behaviors rather than solely optimizing a scalar target.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Curiosity-driven / entropy-maximizing acquisition",
            "system_description": "Acquisition functions based on information theory (e.g., maximizing expected entropy growth or mutual information) that preferentially sample locations where the model expects to learn the most (largest uncertainty reduction or increase in dataset variability). The paper describes this as an alternative to physics-driven scalar objectives for curiosity learning and novelty discovery.",
            "application_domain": "Active learning for experimental discovery where novelty/diversity is a primary goal (e.g., exploratory microscopy, materials discovery).",
            "resource_allocation_strategy": "Allocates measurements to maximize expected information gain or entropy growth per experiment; encourages exploration of under-characterized regions that potentially reveal new mechanisms.",
            "computational_cost_metric": "Not specified; computing expected information-theoretic objectives usually requires additional computations over predictive distributions (e.g., integrals for mutual information) and can be more expensive than simple EI evaluations.",
            "information_gain_metric": "Entropy growth, mutual information, or other information-theoretic quantities are explicitly proposed as acquisition criteria.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Purely exploratory when used as the acquisition objective (prioritizes high-uncertainty / high-information locations); can be combined with exploitation metrics for mixed strategies.",
            "diversity_mechanism": "Explicit: by maximizing entropy or information gain the method promotes sampling of diverse behaviors and under-sampled regimes.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed sampling budget; practical measurement limits.",
            "budget_constraint_handling": "Selects measurements that maximize expected information gain per measurement under the budget, but the paper does not present a formal budget-utility optimization.",
            "breakthrough_discovery_metric": "Novelty identified by large increases in information (entropy) or by observing out-of-distribution / high-uncertainty behaviors that indicate new mechanisms.",
            "performance_metrics": "Not empirically evaluated in this paper; mentioned as a qualitative alternative objective to physics-driven descriptors.",
            "comparison_baseline": "Conceptually compared to physics-driven acquisition like EI on scalar descriptors; no quantitative baseline comparisons provided.",
            "performance_vs_baseline": "Not quantified in this work.",
            "efficiency_gain": null,
            "tradeoff_analysis": "Paper discusses curiosity learning as a complementary strategy to target discovery and diversity, noting human operator can choose between physics-based exploitation and information-theoretic exploration; computational cost of information-theoretic metrics is noted as a consideration.",
            "optimal_allocation_findings": "Information-theoretic objectives are suitable when discovery/novelty/diversity are prioritized; they provide an explicit mechanism to promote exploring under-characterized behaviors, but the paper does not provide empirical allocation-optimization rules.",
            "uuid": "e2604.3",
            "source_info": {
                "paper_title": "Experimental discovery of structure–property relationships in ferroelectric materials via active learning",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "FerroBot (line-by-line AE)",
            "name_full": "FerroBot (line-by-line feedback autonomous experiment in PFM)",
            "brief_description": "A previously reported autonomous PFM system that used operator-defined image features and line-by-line feedback during classical rectangular scans to guide AFM/PFM imaging without human intervention.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "FerroBot (line-by-line AE implementation)",
            "system_description": "Autonomous AFM/PFM imaging system employing human-defined features of interest during line-by-line scanning to adapt imaging and highlight regions of interest; used as an early demonstration of AE feasibility in PFM, but relied on pre-defined feature engineering rather than learned embeddings or GP-based acquisition.",
            "application_domain": "Piezoresponse force microscopy / autonomous scanning probe microscopy.",
            "resource_allocation_strategy": "Operational adaptation of scan trajectory based on simple feedback rules tied to predefined image features; allocates scanning effort to regions flagged by features.",
            "computational_cost_metric": "Not specified in paper; implicit low computational overhead due to simple feature-based rules.",
            "information_gain_metric": "Not formalized; selection based on operator-defined features rather than probabilistic information measures.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Feature-driven exploitation of regions deemed interesting by engineered criteria; limited exploration capability.",
            "diversity_mechanism": "None explicit; relies on hand-crafted feature definitions.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Implicitly constrained by scan time and operator objectives.",
            "budget_constraint_handling": "Adaptation of scan density/trajectory to prioritize regions of interest; no formal budget optimization.",
            "breakthrough_discovery_metric": "Not specified; discovery depends on operator-chosen features correlating with interesting physics.",
            "performance_metrics": "Demonstrated feasibility of autonomously operating AFM in imaging modes; no quantitative comparison to BO methods provided in this paper.",
            "comparison_baseline": "Serves as a prior AE example contrasted with DKL-BO which uses representation learning and probabilistic acquisition.",
            "performance_vs_baseline": "Not directly compared numerically; paper positions FerroBot as more limited due to reliance on engineered features.",
            "efficiency_gain": null,
            "tradeoff_analysis": "Simple feedback methods have low computational cost and are straightforward to deploy, but lack the ability to learn complex correlative relationships from multidimensional data, reducing their effectiveness for structure–property discovery.",
            "optimal_allocation_findings": "Feature-engineered AE can efficiently allocate scanning resources when suitable heuristics exist, but for complex high-dimensional spectroscopy tasks, representation learning + probabilistic acquisition (DKL-BO) is preferable.",
            "uuid": "e2604.4",
            "source_info": {
                "paper_title": "Experimental discovery of structure–property relationships in ferroelectric materials via active learning",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "Pretrained DCNN / Transfer Learning",
            "name_full": "Pretrained deep convolutional neural network feature extractor / transfer learning",
            "brief_description": "The idea of pretraining the neural network feature extractor on prior experimental data (from same or related systems) to accelerate online DKL training and reduce required on-the-fly measurements.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Pretrained DCNN / transfer learning for DKL feature extractor",
            "system_description": "Proposal to pretrain the DKL neural network (or DCNN feature extractor) on earlier experiments or similar materials so that the online DKL-BO requires fewer iterations and less data to reach useful predictive performance. The paper notes that pretraining is analogous to transfer learning but highlights the need to analyze out-of-distribution drift when reusing pretrained extractors.",
            "application_domain": "Accelerating active-learning workflows in microscopy and other experimental domains by reducing online data requirements.",
            "resource_allocation_strategy": "Reduce online measurement allocation by leveraging pretrained representations, thereby allocating fewer new experiments toward representation learning and more toward targeted exploration/exploitation.",
            "computational_cost_metric": "Qualitatively: decreases online training/inference wall-clock time and measurement budget but introduces upfront (offline) pretraining costs; no explicit numeric metrics provided.",
            "information_gain_metric": "Not explicitly defined; pretraining aims to improve surrogate predictive accuracy and hence the information gain per new measurement by starting from informative embeddings.",
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "By improving representation, pretrained extractors can shift the exploration-exploitation tradeoff toward more confident exploitation or more efficient exploration; specifics depend on downstream acquisition choices.",
            "diversity_mechanism": "Not explicit; may reduce need for exploratory diversity if pretrained model is confident, but this raises risk of missing out-of-distribution discoveries.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Tradeoff between offline pretraining cost (time/computation) and online measurement budget; concern for out-of-distribution risk if pretraining mismatch occurs.",
            "budget_constraint_handling": "Not implemented in this paper; authors recommend careful analysis of distributional drift if pretraining is used.",
            "breakthrough_discovery_metric": "Not defined; pretraining could improve detection of known signatures but risks missing novel phenomena if OOD drift is not handled.",
            "performance_metrics": "Not empirically evaluated here; recommended as a direction to reduce online resource allocation.",
            "comparison_baseline": "Compared conceptually to training the DKL feature extractor from scratch online with small seed samples.",
            "performance_vs_baseline": "No empirical comparison presented; authors note both potential benefits (faster convergence) and risks (OOD drift).",
            "efficiency_gain": null,
            "tradeoff_analysis": "Pretraining trades offline computational cost for reduced online sampling and faster active-learning loops; must be balanced against the risk that pretrained features may not generalize to the current experiment (distributional shift).",
            "optimal_allocation_findings": "Pretraining is promising for improving allocation efficiency but requires validation for distributional mismatch before being used to bias experiments.",
            "uuid": "e2604.5",
            "source_info": {
                "paper_title": "Experimental discovery of structure–property relationships in ferroelectric materials via active learning",
                "publication_date_yy_mm": "2021-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Fast Scanning Probe Microscopy via Machine Learning: Non-Rectangular Scans with Compressed Sensing and Gaussian Process Optimization",
            "rating": 2
        },
        {
            "paper_title": "Artificial-intelligence-driven scanning probe microscopy",
            "rating": 2
        },
        {
            "paper_title": "An artificial intelligence atomic force microscope enabled by machine learning",
            "rating": 2
        },
        {
            "paper_title": "Enabling autonomous scanning probe microscopy imaging of single molecules with deep learning",
            "rating": 2
        },
        {
            "paper_title": "Automated and Autonomous Experiment in Electron and Scanning Probe Microscopy",
            "rating": 2
        }
    ],
    "cost": 0.0177245,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Notice: This manuscript has been authored by UT-Battelle, LLC, under Contract No. DEAC0500OR22725 with the U.S. Department of Energy. The United States Government retains and the publisher, by accepting the article for publication, acknowledges that the United States Government retains a non-exclusive, paid-up, irrevocable, world-wide license to publish or reproduce the published form of this manuscript, or allow others to do so, for the United States Government purposes. The Department of Energy will provide public access to these results of federally sponsored research in accordance with the DOE Public Access Plan (http://energy.gov/downloads/doe-public-access-plan).</p>
<h1>Experimental discovery of structure-property relationships in ferroelectric materials via active learning</h1>
<p>Yongtao Liu, ${ }^{1}$ Kyle P. Kelley, ${ }^{1}$ Rama K. Vasudevan, ${ }^{1}$ Hiroshi Funakubo, ${ }^{2}$<br>Maxim A. Ziatdinov, ${ }^{1,3, \mathrm{a}}$ and Sergei V. Kalinin ${ }^{1, \mathrm{~b}}$<br>${ }^{1}$ Center for Nanophase Materials Sciences, Oak Ridge National Laboratory, Oak Ridge, TN 37831<br>${ }^{2}$ Department of Material Science and Engineering, Tokyo Institute of Technology, Yokohama 226-8502, Japan<br>${ }^{3}$ Computational Sciences and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, Tennessee 37831, USA</p>
<p>Emergent functionalities of structural and topological defects in ferroelectric materials underpin an extremely broad spectrum of applications ranging from domain wall electronics to high dielectric and electromechanical responses. Many of these have been discovered and quantified via local scanning probe microscopy methods. However, the search for these functionalities has until now been based by either trial and error or using auxiliary information such as topography or domain wall structure to identify potential objects of interest based on the intuition of operator or preexisting hypotheses, with subsequent manual exploration. Here, we report the development and implementation of a machine learning framework that actively discovers relationships between local domain structure and polarization switching characteristics in ferroelectric materials encoded in the hysteresis loop. The hysteresis loops per se and their scalar descriptors such as nucleation bias, coercive bias, hysteresis loop area, or more complex functionals of hysteresis loop shape and corresponding uncertainties are used to guide the discovery via automated piezoresponse force microscopy (PFM) and spectroscopy experiments. As such, this approach combines the power of machine learning methods to learn the correlative relationships between high dimensional data, and human-based physics insights encoded in the acquisition function. For ferroelectric, this automated workflow demonstrates that the discovery path and sampling points of on-field and offfield hysteresis loops are largely different, indicating the on-field and off-field hysteresis loops are dominated by different mechanisms. The proposed approach is universal and can be applied to a broad range of modern imaging and spectroscopy methods ranging from other scanning probe microscopy modalities to electron microscopy and chemical imaging.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>3</p>
<p>The rapid evolution of scanning probe and electron microscopy techniques over the last three decades has revolutionized the areas of science ranging from materials and condensed matter physics to chemistry and biochemistry. ${ }^{1-5}$ As such, the various microscopy imaging modes have now become a mainstay across virtually all scientific fields. Similarly, the combination of imaging and spectroscopic modes in these techniques has provided a wealth of information on structureproperty relations in these dissimilar systems. Examples include scanning tunneling microscopy and spectroscopy, ${ }^{6-8}$ dark and bright field imaging in electron microscopy and electron energy loss spectroscopies, ${ }^{9-11}$ topographic imaging and force-distance curve measurements in atomic force microscopy, ${ }^{12-14}$ and electromechanical hysteresis loop measurements in piezoresponse force microscopy. ${ }^{15-17}$ These structure-property relationships in turn yield a wealth of information on the underpinning physical, chemical, and biological mechanisms.</p>
<p>Very often the locations for spectroscopic measurements are selected manually based on the perceived (by human operator) interest of specific locations, as identified via features in a structural image. This point-and-click selection can be based on field-specific intuition, curiosity, and in special cases on a specific hypothesis. Alternatively, the measurements can be performed in the spectroscopic grid modes, where the spectral data is collected over a uniform sampling grid. ${ }^{6,18-20}$ These in turn necessitated development of the linear and non-linear dimensionality reduction methods for analysis of such multidimensional data, ${ }^{20,21}$ ushering exploratory machine learning methods into imaging areas. However, these imaging modalities are characterized by significant disparities in acquisition times for the spectroscopic and structural measurements. Correspondingly, the spatial density of the information is limited. While post-acquisition pansharpening methods based on compressed sensing, Gaussian process, etc. have been developed, ${ }^{22,23}$ these approaches do not change the fundamental limitation of the spectroscopic imaging methods. Similarly, correlative learning of structure property relationships implemented via im2spec approach requires the availability of the full data set, ${ }^{24}$ and implicitly assumes that the material properties did not change as the result of measurements.</p>
<p>The rapid progress in the computer vision methods enabled by the advent of the deep learning a decade ago ${ }^{25}$ as well as wave of interest towards autonomous driving systems have stimulated strong interest in autonomous microscopy, with several notable opinion pieces over the last 3 years. ${ }^{26-28}$ However, realization of this vision necessitates solution of three intertwined problems, including direct control of the microscope operation via external electronics, development of machine learning algorithms enabling the automated experiment (AE), and, perhaps less obviously, identifying the specific problems that AE seeks to resolve. Until now, this last problem has been largely overshadowed by the first two.</p>
<p>The direct control of microscopes has been available for decades, typically developed in the context of atomic and particle manipulation. ${ }^{29-33}$ For imaging, the adaptive non-rectangular scanning approach was demonstrated by Ovchinnikov et al in 2009. ${ }^{34}$ More recently, Huang et al ${ }^{35}$ and Stores et al ${ }^{36}$ have demonstrated the combination of machine learning algorithm with Atomic Force Microscopy (AFM) enabling autonomous operation of AFM without the need of human intervention in imaging modes, with the AE playing the role of (pretrained) feature identifier.</p>
<p>However, the second key component of the AE are the strongly coupled problem of machine learning algorithms and specific physical problem. Generally, the AE targeting the mechanisms of the ferroelectric domain wall pinning on structural defects will pursue a different strategy the experiment exploring the interaction of the ferroelectric and ferroelastic domain walls. Recently, we have reported the detailed analysis of the ML perspectives in automated/autonomous experiments in microscopy. ${ }^{37}$ In particular, we noted that the AE itself is defined only in the context of prior knowledge, and seeks to discover new information or minimize uncertainties in the known system behavior. This coupled machine learning and physics problem in the context of active learning makes the AE a highly domain specific problem.</p>
<p>To date, the AE's have been implemented either using the human-based features engineering, or simple DCNN based image recognition. ${ }^{36}$ For example, in piezoresponse force microscopy (PFM), the AE was introduced based on a line-by-line feedback system employed during classical rectangular scanning by Kelley et al. ${ }^{38}$, termed "FerroBot". The FerroBot has shown the feasibility of the AE in PFM by using simple operator-defined features of interest. Finally, a Gaussian Process/Bayesian Optimization framework has been recently developed to control the probe trajectory via leveraging the explored information and scanning sequence. ${ }^{39}$ At the same time, the classical Gaussian Process/Bayesian Optimization routines that underpin most AEs over the past years are based purely on the data available through the specific experiment and are further limited to low-dimensional signals. As such, they are ill-suited for the active learning of the structure-property relationships.</p>
<p>Here, we implement the deep kernel learning (DKL) based experimental workflow for active discovery of structure-property relationships in ferroelectric materials. This approach combines the power of machine learning to establish the correlative relationships between multidimensional data sets, and human based physical reasoning to establish targets for exploration based on observations and their uncertainties. Here, the relationship between the local domain structure and hysteresis loop is explored and future measurement locations are selected based on learnt relationships between local domain structure and polarization switching behavior.</p>
<p>To illustrate the principle of the DKL applications in experiment, we first implement DKL using a pre-acquired high density band excitation piezoresponse spectroscopy (BEPS) imaging data set, which hence provides the "known" ground truth image. Here, as a model system we have chosen a $\mathrm{PbTiO}<em 3="3">{3}$ (PTO) thin film grown on (001) $\mathrm{KTaO}</em>$ Shown in Figure 1a is the topography image of the PTO sample illustrating clear ferroelastic domain wall pattern. The clearly visible corrugations on the sample surface are associated with the ferroelastic domain walls between the domains with different polarization orientations. Here, the lattice mismatch across the single domain walls gives rise to strain and hence deformations. The superposition of deformations form multiple domain walls give rise to ripple-like structure.}$ substrates with a $\mathrm{SrRuO}_{3}$ conducting buffer layer by metalorganic chemical vapor deposition (MOCVD) method, as reported by H. Morioka et al. ${ }^{40</p>
<p>Shown in Figure 1b-c are the corresponding band excitation (BE) PFM amplitude and phase images, which indicate the existence of both in-plane a domains and out-of-plane c domains. In the in-plane $a$ domain, the polarization vector is parallel to the surface and hence associated</p>
<p>electromechanical response amplitude is close to zero. At the same time, in the out of plane $c$ domains the response amplitude is high. Finally, the phase image indicates whether polarization vector is parallel or antiparallel to surface normal.</p>
<p>To explore polarization dynamics in this system, we analyze the high density polarization loop measurements. ${ }^{41}$ In these measurements, the dc component of the tip bias is following the triangular waveform, inducing domain nucleation and growth below the tip. The resultant changes of the PFM signal are recorded as the local hysteresis loop. The shape of the hysteresis loop this reflects the mechanism of local polarization switching as affected by the ferroelastic walls, structural defects, etc. The resultant 3D data array can be analyzed to extract the descriptors of the hysteresis loop such as area under the loop, coercive and nucleation biases, etc. that can further be plotted as 2D maps. A high grid density (100x100) polarization image is show in Figure 1d, where the similar domain structure is visible. Shown in Figure 1e is a ferroelectric polarization hysteresis loop from the orange point marked on Figure 1d.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. PFM results from PTO film. (a), topography and corresponding band excitation (b) amplitude and (c) phase maps show $\mathrm{c} / \mathrm{c}$ and $\mathrm{a} / \mathrm{c}$ domains. (d), BEPS polarization map when $\mathrm{V}_{\mathrm{dc}}=$ 0 V . (e)-(f), BEPS polarization hysteresis loops from the locations labeled on (d); inserts in (e) and (f) show the domain structures around the locations where hysteresis loops are from, the correspondence between insert images and hysteresis loops is indicated by colors; these illustrate that different elements of hysteresis loops are correlated with different elements of domain structures. Note that ground truth BEPS image contains 10,000 hysteresis loops measured over uniform spatial grid.</p>
<p>As acquired, the combination of the PFM domain structure image and hysteresis loop mapping allows to reconstruct structure property relationships, defined here as a correlative link</p>
<p>between the local ferroelastic domain structure and hysteresis loop shape. Previously, we have demonstrated the use of machine learning methods, specifically an encoder-decoder type of neural networks, to build such relationships for ferroelectric ${ }^{42,43}$ and plasmonic ${ }^{44}$ structures. These correlative relationships allow answering questions such as, what responses are possible in a given system, what structures are necessary to maximize certain aspects of the response, etc. However, as with any correlative method, these answers are valid only for the in-distribution data (meaning for the same material under the same microscope settings), and do not allow answering counterfactual and interventional questions. ${ }^{45-47}$ Some of these can be answered via transition from correlative to generative physical models, ${ }^{48-50}$ but these raise further questions of theoryexperiment matching.</p>
<p>Furthermore, these analyses are limited to the case when the full data set is available $a$ priori, i.e., they allow analyzing the data after the experiment. However, it is not guaranteed that the pre-acquired data sets sampled most interesting locations, and the number of possible measurements are limited by acquisition time and probe stability. Contrarily, in an active machine learning setting, only the full topographic and PFM images are available, and information contained in these images is used to select the locations for spectroscopic measurements. Based on the examination of spectroscopic data, further locations are identified. For example, the operator can learn that the in-plane $a$-domain regions do not have measurable hysteresis loop, that all $a-c$ domain structures have similar switching behaviors, and that irregular domain edges or junctions may possess interesting dynamics. The subsequent selection of the target locations can then be based on these observations and curiosity (exploration) or perceived usefulness (exploitation). Importantly, this approach is the basis of DKL.</p>
<p>The DKL is based on the Gaussian Process (GP) regression, and can be represented as a combination of GP with deep neural networks. In general, GP generally refers to an indexed collection of random variables, any finite subcollection of which have a joint multivariate Gaussian distribution. ${ }^{51}$ A GP is completely determined by its mean and covariance functions, with the latter determining the functional form and strength of interaction between the points in the input space.</p>
<p>A common application of GP is in a regression setting where it can be used for reconstructing data from sparse observations with quantified uncertainty. ${ }^{52}$ Note that the uncertainty per se is important when gaining quantitative insights into physical behaviors, and locations with high uncertainty can indicate the presence of new physical mechanisms. ${ }^{53}$ Specifically, given the dataset $D=\left[x^{i}, y^{i}\right]_{i=1, \ldots, N}$, where $x$ and $y$ represent inputs/features and outputs/targets, respectively, the GP probabilistic regression model with a standard squared exponential kernel of the form $k\left(\mathbf{x}, \mathbf{x}^{\prime}\right)=\sigma^{2} \exp \left(\frac{1}{2}\left(\mathbf{x}-\mathbf{x}^{\prime}\right)^{2} / l^{2}\right)$ is defined as</p>
<p>$$
\begin{aligned}
&amp; y \sim \text { MultivariateNormal }\left(0, K\left(\mathbf{x}, \mathbf{x}^{\prime}, \sigma, l\right)\right) \
&amp; \sigma \sim \text { LogNormal }\left(0, s_{1}^{\text {const }}\right) \
&amp; l \sim \text { LogNormal }\left(0, s_{2}^{\text {const }}\right)
\end{aligned}
$$</p>
<p>where $K$ denotes a function that computes a kernel matrix such that $K_{i j}=k\left(x_{i}, x_{j}\right)$ for the sampled kernel hyperparameters. The GP model can be trained either using a Markov Chain Monte Carlo algorithm on the model to get posterior samples for the GP parameters or via a variational inference. It is commonly assumed that there is an observation noise such that $\mathbf{y}<em _noise="{noise" _text="\text">{\text {noisy }}=\mathbf{y}+\boldsymbol{\varepsilon}$ where $\boldsymbol{\varepsilon}$ is a normally distributed noise with zero mean and variance $s</em>$. Practically, this noise gets absorbed into a computation of the covariance function.}}^{2</p>
<p>Once the GP model parameters are learned, it can be used to make predictions on new "test" points. This is done by sampling from the multivariate normal posterior over the model outputs at the provided test points $x_{*}$ :</p>
<p>$$
f_{*} \sim \operatorname{MultivariateNormal}\left(\mu_{\theta}^{\text {post }}, \Sigma_{\theta}^{\text {post }}\right)
$$</p>
<p>where $\boldsymbol{\theta}=[\sigma, l]$ and</p>
<p>$$
\begin{aligned}
&amp; \mu_{\theta}^{\text {post }}=K\left(x_{<em>}, x \mid \boldsymbol{\theta}\right) K(x, x \mid \boldsymbol{\theta})^{-1} \mathbf{y} \
&amp; \Sigma_{\theta}^{\text {post }}=K\left(x_{</em>}, x_{<em>} \mid \boldsymbol{\theta}\right)-K\left(x_{</em>}, x \mid \boldsymbol{\theta}\right) K(x, x \mid \boldsymbol{\theta})^{-1} K\left(x, x_{*} \mid \boldsymbol{\theta}\right)
\end{aligned}
$$</p>
<p>The GP predictive mean $\left(\bar{f}<em>{<em>}\right)$ and variance $\left(\mathbb{V}\left[f_{</em>}\right]\right)$ can be used to select the next measurement point(s) via a so-called acquisition function, ${ }^{54} \operatorname{acq}\left(\bar{f}</em>{<em>}, \mathbb{V}\left[f_{</em>}\right]\right)$, so that $x_{\text {next }}=$ $\operatorname{argmax}(a c q)$. The acquisition function reflects the measure of interest to specific region based on expected function value and uncertainty, balancing exploration and exploitation. Implementationwise, one generally starts with a few sparse observations and trains a GP model. Then, a prediction on the "test" points - which usually represent all the unmeasured points in a selected parameter space - is made and used to derive an acquisition function for sampling the next query point. This approach is referred to as Bayesian optimization (BO) or 'active learning'. For structural imaging in microscopy, the parameter space corresponds to a 2D grid over a chosen scan area; for spectroscopic measurement, a third dimension corresponding to the energy axis can be added.</p>
<p>A significant limitation of the standard GP-based active learning is that it does not scale well with dimensionality of the parameter space. As a result, for many common hyperspectral measurements in 3D-5D space, the GP training and inference may take so long (even on modern Graphics Processing Units) that it is faster to perform the measurement by simply sampling all the points (i.e., the standard way of doing measurements). Another limitation is that the standard GP does not, strictly speaking, learn representations of data which precludes from using prior knowledge from different experimental modalities to assist in the experiment (something that a (good) experimentalist does all the time). In the context of the ferroelectric domain studies detailed here, the simple GP/BO does not use the information on the preexisting domain structure to build the relationship between these and switching behaviors.</p>
<p>To address these issues, here we have adapted a deep kernel learning ${ }^{55}$ approach where a neural network is used to convert high-dimensional input data into a set of low-dimensional descriptors on which a standard ('base') GP kernel operates (Figure 2a). Formally, we define our 'deep kernel' as</p>
<p>$$
k_{D K L}\left(x, x^{\prime} \mid \boldsymbol{w}, \boldsymbol{\theta}\right)=k_{\text {base }}\left(g(x \mid \boldsymbol{w}), g\left(x^{\prime} \mid \boldsymbol{w}\right) \mid \boldsymbol{\theta}\right)
$$</p>
<p>where $\boldsymbol{w}$ are the weights of the neural network. Hence, the deep kernel operates in the latent (embedding) space learned by a neural network from the (potentially high-dimensional) data and can be referred to as the data-informed kernel. The parameters of neural network and GP base kernel are learned simultaneously by maximizing the model evidence via a stochastic variational inference. ${ }^{56}$ The trained DKL GP model is then used for obtaining predictive mean and variances following the Eq. (2), that is, using the same procedure as for the standard GP. Then, the acquisition function for the expected improvement ${ }^{54}$ is used to predict the next measurement point. The DKL can operate both on scalar (single output) and vector (multiple outputs) targets. In the latter case, different function outputs (such as response function values at different energies) can be independent or correlated. Implementation-wise, the correlation between different function outputs is achieved by forcing them to share the same latent space, i.e. having a single neural network (feature extractor) connected to multiple GPs whose number is equal to the number of function outputs. Alternatively, one may assume independence between outputs, which would require training an independent neural network for each GP (i.e., for each output). For a singleobjective active learning, the vector-valued prediction of the DKL model must be scalarized in order to select the next measurement point.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2. Schematic illustration of active learning with deep kernel learning (DKL). Here, the algorithm has access to the full topographic data and uses Bayesian optimization to learn the relationship between the domain structure within the patch and hysteresis loop. (a) The inner structure of the DKL model. A feedforward neural network parametrized by weights $\boldsymbol{w}$ projects the potentially high-dimensional input data $X$ into the low-dimensional latent space, $g(x \mid \boldsymbol{w})$ in which a standard GP kernel $k\left(z, z^{\prime} \mid \boldsymbol{\theta}\right)$ operates (where $z$ are the embedded/latent features). (b) The Bayesian optimization loop. (c) At training step, the DKL-based Gaussian process (GP) regression model (for brevity, referred to as DKL model) is trained using a small number of observations where inputs are topographic image patches and outputs are corresponding spectra or scalar values of a specific property derived from the spectra. (d) At prediction step, a trained DKL model is used to predict spectra at every coordinate in the topographic image for which there is no measured</p>
<p>spectra. Importantly, this method outputs both expected mean value, $\bar{f}<em>{<em>}$, of the property of interest and the associated uncertainty, $\mathbb{V}\left[f_{</em>}\right]$, which are used to derive an acquisition function $\operatorname{acq}\left(\bar{f}</em>{<em>}, \mathbb{V}\left[f_{</em>}\right]\right)$ for selecting the next measurement point (see $\mathbf{b}$ ). Note that if the output is a vectorvalued function (such as spectra) it needs to be scalarized before passing to the acquisition function such that the exploration process is controlled by a single descriptor that is a function of the predicted functionality and its uncertainty. In this manner, the human operator defines what physical functionality is targeted during the experiment. Note that exploration can be based both on physical and on information-theoretical criteria, i.e. targeting variability of observed behaviors (curiosity learning).</p>
<p>To illustrate DKL approach, we first implement it on the pre-acquired data set. Here, we use the random sampling with the $15 \%$ of measured points for training the DKL model that subsequently makes predictions on the full dataset. Shown in Figure 3 are results of DKL analyses on the pre-acquired BEPS data (as shown in Figure 1d-e), where we show the ground truth, embedded variables, DKL prediction, and the associated uncertainty. Both analyses on hysteresis loop area and hysteresis loop width indicate good reconstructions of loop area and loop width maps (Figure 3d and 3i) when comparing with the ground truth maps (Figure 3a and 3f). The embedded variables highlight the tiny domains (Figure 3b and 3g) and the large domains (Figure 3c and 3h), respectively. Shown in Figure $3 \mathrm{k}-\mathrm{m}$ are several examples demonstrating the reconstruction of hysteresis loops comparing with the ground truth hysteresis loops.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3. Deep kernel learning on the pre-acquired data set for $15 \%$ of measured locations. (a-h) DKL analysis of loop area: (a) $15 \%$ randomly sampled loop area data for training session, (b) ground truth loop area map, (c) DKL predicted loop area, (d) DKL uncertainty map, (e, f) absolute error map of DKL prediction and the histogram distribution of errors, (g, h) the embedded latent maps of the trained DKL (the embedding dimensions were set to 2). (i-p) DKL analysis of loop width: (i) $15 \%$ randomly sampled loop width data for training session, (j) ground truth loop width map, (k) DKL predicted loop width, (l) DKL uncertainty map, (m-n) absolute error map of DKL prediction and the histogram distribution of error, (o-p) the embedded latent maps of the trained DKL. (i, j) DKL predicted loop width and DKL uncertainty maps. (q-s) examples of DKL prediction on hysteresis loops, showing DKL predicted loops and ground truth loops.</p>
<p>We further explore the effect of the number of sampling points for random sampling. Here, we show the DKL reconstruction of coercive field, hysteresis loop area, and loop width based on $1 \%, 3 \%, 5 \%$, and $10 \%$ of random sample data in Figure 4a-c. Note that in this approach DKL aims to reconstruct the relationship between the local domain structure and the hysteresis loop properties based on fully known collection of image patches, and patch-spectrum pairs available for only (very small) fraction of the data. With this relationship established, it aims to reconstruct the spectra properties and their uncertainties for the full data set. Figure 4d-e show the quality of reconstruction as the mean squared error (MSE) between the reconstruction and the ground truth as a function of the number of sampled data points. Note that in Figure 4a, the coercive field is the average of positive and negative coercive field; in Figure 4b and 4c, the loop area and width are from off field hysteresis loops. More results about separated positive and negative coercive fields, and on field loop area are shown in Supplementary Information Figure S1. More details about how the random sampling of data affects the DKL reconstruction are shows in Supplementary Information as videos Supplementary Videos S1-S5.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4. DKL reconstruction from randomly sampled data. (a) ground truth coercive field map and DKL reconstructed coercive field maps based on $1 \%, 5 \%, 10 \%$, and $50 \%$ of randomly sampled data. (b) ground truth hysteresis loop area map and DKL reconstructed loop area maps based on $1 \%, 5 \%, 10 \%$, and $50 \%$ of randomly sampled data. (c) ground truth hysteresis loop width map</p>
<p>and DKL reconstructed loop width maps based on $1 \%, 5 \%, 10 \%$, and $50 \%$ of randomly sampled data. (d-f) DKL reconstruction error and structure similarity between ground truth and reconstruction of coercive field map, loop area map, and loop width map, respectively. Note that reconstructed images preserve features at all length scales, which very difficult to achieve with classical BO. ${ }^{39}$</p>
<p>We further illustrate the transition from the reconstruction based on predefined (e.g. random or low-density grid) sampling towards science-driven discovery, and experimental implementation of this approach. Here, the critical new element is the definition of the scalar descriptor that reflects the physical behaviors we are interested in and use to guide the exploration process. For hysteresis loops a shown in Figure 5a, these can be parameters such as loop area or width, coercive field, and nucleation bias, or more complex descriptors such as quality of functional fit by predefined function, fit parameters, etc. Alternatively, the exploration can be based on information-theoretical criteria such as growth of entropy of the data set, i.e. curiosity learning. The key element here is that the acquisition function summarizing the degree of interest to specific behavior allows human-level decision making searching for specific physical signatures, and allows to incorporate associated uncertainties.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5. Physics-based descriptors for DKL BO. (a) example of hysteresis loop and definition of possible physical descriptors, $\mathrm{A}<em _loop="{loop" _text="\text">{\text {loop }}$ : loop area; $\mathrm{W}</em>}}$ : loop width; $-\mathrm{E<em _mathrm_c="\mathrm{c">{\mathrm{c}}$ : negative coercive field; $+\mathrm{E}</em>$ :}</p>
<p>positive coercive field; $-\mathrm{V}<em _mathrm_n="\mathrm{n">{\mathrm{n}}$ : negative nucleation bias; $+\mathrm{V}</em>$ : positive nucleation bias. (b) exploration path for loop area discovery. (c) exploration path for loop width discovery. (d) ground truth loop area map and DKL BO reconstructed loop area maps based on loop area discovery for $0.5 \%, 1 \%$, $5 \%$, and $10 \%$ sampling points. (e) ground truth loop width map and DKL BO reconstructed loop area maps based on loop width discovery for $0.5 \%, 1 \%, 5 \%$, and $10 \%$ points predicted by DKL BO. The associated videos and the behavior of uncertainty are available in the supplementary materials.}</p>
<p>Shown in Figure 5b-c are the DKL BO navigation sequence with the acquisition function based on hysteresis loop area and loop width, respectively. Shown in Figure 4d-e are the DKL reconstruction of loop area and width with $0.5 \%, 1 \%, 5 \%$, and $10 \%$ of the points where the DKL BO suggested to perform measurements. The reconstruction quality can be evaluated by comparison with the random sampling points in Figure 4. We show the videos of acquisition function image with labels of discovered points in Supplementary Information for both loop area and loop width cases. The reconstruction videos with the DKL-BO sampled points, DKL prediction, and DKL uncertainty are also shown in Supplementary Information.</p>
<p>Finally, we deploy the DKL discovery workflow on the operational microscope. Here, we combined the DKL discovery workflow in Jupyter notebook with an in-house LabView-based script for National Instruments hardware (LabView-NI) to control the tip position for BEPS waveform generation and data acquisition. First, we performed a BEPFM measurement to acquire the domain structure image, which will be used to generated domain structure image patches for DKL. At the beginning of BEPS hysteresis loop measurement, the sampling point is initialized by the LabView-NI at a random location to obtain hysteresis loop. Then, the Jupyter notebook analyzes the hysteresis loop and the corresponding pre-acquired domain structure image patch to train the DKL model. The DKL was trained for 200 iterations after which a prediction on all the image patches was made and the pre-selected acquisition function was used to derive the next location for hysteresis measurement to LabView-NI. Then the process is repeated. A schematic of this specific workflow used is shown in Figure 6a. Figure 6b-c shows BEPFM amplitude and phase images with $256 * 256$ grid size which will be used to generate image patches for DKL. It can be seen that the PTO film contains both in-plane $a$ domains and out-of-plane $c$ domains as demonstrated previously. The size of the generated image patches for DKL-BO is $20 * 20$ grid and the BEPS measurement was performed at $237 * 237$ grid size. The DKL-BO process was continued for 200 steps, i.e., until 200 pixels worth of data were captured.</p>
<p>We used the image patches generated from the BEPFM results in Figure 6b and 6c for guide the discovery workflow using on-field hysteresis loop area and off-field hysteresis loop area, respectively. The discovered points are labeled in Figure 6b-c. The detailed discovery processes are shown in Supplementary Information as videos of acquisition function images with labeled exploration point. Interestingly, the DKL BO sampled points for on-field hysteresis loop area are concentrated around $c^{\prime} / c^{+}$ferroelectric domain walls (Figure 6b), while the DKL-BO sampled points for off-field hysteresis loop area are concentrated around a/c ferroelastic domain walls, demonstrating the potential of this approach to discover different behaviors based on predefined exploration targets. This is an indicative of the different properties included in the on-field and off-</p>
<p>field hysteresis loops. With the obtained 200 hysteresis loops and the BEPFM domain structure images, we are able to make predictions on the hysteresis loop area maps. Shown in Figure 6d-e are the DKL prediction of on-field and off-field hysteresis loop area maps, respectively, along with the DKL uncertainty. The domain structures are visible in the predicted loop area maps, indicating the hysteresis loop is associated with the domain structure.</p>
<p>Here, these observations can be readily rationalized (but not predicted!) based on the known physics of ferroelectric domain walls. Here, the larger polarization mobility in the vicinity of the 180 walls results in more significant hysteresis loop opening in the on-field measurements. At the same time, the off-field measurements detect only the slowly relaxing (on the measurement time scale) components, indicative of the stronger pinning at the ferroelastic walls. These behaviors generally agree with some of the prior observations of similar systems. ${ }^{57,58}$
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6. DKL-BO based automated PFM experiment. (a). schematic of the DKL-BO PFM workflow. (b)-(c) BEPFM amplitude and phase images used for generation of domain structure image patches for DKL-BO BEPS measurements; the BEPFM results in (b) and (c) are used for DKL-BO discovery of on-field loop area and off-field area, respectively; the discovered points are labeled in the image in (b) and (c). (d)-(e), DKL prediction of on-field and off-field loop area maps based on the obtained 200 hysteresis loops.</p>
<p>To summarize, we have developed the DKL approach that allows the physical discovery in automated experiment. Compared to the classical Bayesian Optimization based strategies that use a single (or small number) of scalar descriptors to guide the navigation process and do not incorporate the prior knowledge, this approach uses the data contained in structural images to</p>
<p>identify the locations of the spectroscopic measurements, and identifies new locations and builds the structure property relationships simultaneously. This discovery process is guided by the acquisition function that is constructed from predicted behavior and its uncertainty, and reflects the target of the experiment. This target can be optimization of specific property, similarity to a given model, or novelty discovery. In this manner, we combine the power of correlative machine learning methods to establish relationships between multidimensional data set and derive corresponding uncertainties, and human physics-based decision making encoded in the choice of the acquisition function.</p>
<p>Here, we implemented this approach for PFM measurement to investigate the relationship between polarization hysteresis and ferroelectric/ferroelastic domain structures. The obtained results show different exploration path and sampled points when the DKL is guided by on-field and off-field hysteresis loops, indicating structure-hysteresis relationship varies under different circumstances, i.e. on-field or off-field. We also note that in principle the DCNN part of the DKL can be pre-trained on previous experimental data from the same or similar systems, somewhat equivalent to the transfer learning approach. However, this will necessitate the stringent analysis of the out of distribution drift effects (e.g. due to different microscope settings).</p>
<p>Similarly, this workflow can be readily extended to other SPM modalities, including current-voltage curve measurements or relaxation measurement. We expect that most significant benefit will be achieved for measurements with the readily identifiable connection to materials physics (e.g. signature of Majorana fermions in STM), large acquisition times, and especially destructive measurements such as nanoindentation and irreversible electrochemical measurements. Beyond SPM, similar approaches can be used to techniques such electron microscopy, chemical and mas-spectroscopic imaging, and nanoindentation and micromechanical testing. Finally, the DKL approach can be implemented over more complex parameter spaces, e.g. for material discovery in combinatorial spread libraries or molecular systems.</p>
<h1>Methods</h1>
<h2>Data analysis</h2>
<p>The detailed methodologies of DKL analysis on pre-acquired data are established in Jupyter notebooks and are available from https://git.io/JRspC. A standard MLP with three hidden layers containing 1000, 500, and 50 "neurons" was used as a 'feature extractor' in the DKL model.</p>
<p>PTO sample
The PTO film was grown by chemical vapor deposition on a $\mathrm{SrRuO}<em 3="3">{3}$ bottom electrode on a $\mathrm{KTaO}</em>$ substrate.</p>
<h2>BEPFM and BEPS measurements</h2>
<p>The PFM was performed using an Oxford Instrument Asylum Research Cypher microscope with Budget Sensor Multi75E-G Cr/Pt coated AFM probes ( $\sim 3 \mathrm{~N} / \mathrm{m}$ ). Band excitation data are acquired with a National Instruments DAQ card and chassis operated with a LabView framework.</p>
<h2>DKL-PFM implementation</h2>
<p>The DKL deployment notebook for BEPS measurement is available from https://git.io/JRspC, which can be adapted for other modalities.</p>
<h2>Conflict of Interest</h2>
<p>The authors declare no conflict of interest.</p>
<h2>Authors Contribution</h2>
<p>S.V.K. conceived the project and M.Z. realized the DKL-BO workflow. Y.L. performed detailed analyses with basic workflow from M.Z. Y.L. deployed the DKL to PFM measurement and obtained results. R.K.V. and K.K. helped with the deployment. H.F. provided the PTO sample. All authors contributed to discussions and the final manuscript.</p>
<h2>Acknowledgements</h2>
<p>This effort (ML) was supported as part of the center for 3D Ferroelectric Microelectronics (3DFeM), an Energy Frontier Research Center funded by the U.S. Department of Energy (DOE), Office of Science, Basic Energy Sciences under Award Number DE-SC0021118 (Y.L., K.K., S.V.K.), and the Oak Ridge National Laboratory's Center for Nanophase Materials Sciences (CNMS), a U.S. Department of Energy, Office of Science User Facility (M.Z., R.K.V).</p>
<h2>Data Availability Statement</h2>
<p>The data that support the findings of this study are available at https://git.io/JRspC.</p>
<h1>References</h1>
<p>1 Gerber, C. \&amp; Lang, H. P. How the doors to the nanoworld were opened. Nat. Nanotechnol. 1, 3-5, doi:10.1038/nnano.2006.70 (2006).
2 Oxley, M. P., Lupini, A. R. \&amp; Pennycook, S. J. Ultra-high resolution electron microscopy. Rep. Prog. Phys. 80, 64, doi:10.1088/1361-6633/80/2/026101 (2017).
3 Müller, D. J. et al. Atomic force microscopy-based force spectroscopy and multiparametric imaging of biomolecular and cellular systems. Chemical Reviews (2020).
4 Fukuma, T. \&amp; Garcia, R. Atomic-and Molecular-resolution mapping of solid-liquid interfaces by 3D atomic force microscopy. ACS nano 12, 11785-11797 (2018).
5 Gross, L. et al. Atomic force microscopy for molecular structure elucidation. Angewandte Chemie International Edition 57, 3888-3908 (2018).
6 Asenjo, A., Gomezrodriguez, J. M. \&amp; Baro, A. M. CURRENT IMAGING TUNNELING SPECTROSCOPY OF METALLIC DEPOSITS ON SILICON. Ultramicroscopy 42, 933-939, doi:10.1016/0304-3991(92)90381-s (1992).
7 Pan, S. H. et al. Imaging the effects of individual zinc impurity atoms on superconductivity in Bi2Sr2CaCu2O8+delta. Nature 403, 746-750 (2000).
8 Roushan, P. et al. Topological surface states protected from backscattering by chiral spin texture. Nature 460, 1106-U1164, doi:10.1038/nature08308 (2009).
9 Pennycook, S. J., Varela, M., Lupini, A. R., Oxley, M. P. \&amp; Chisholm, M. F. Atomic-resolution spectroscopic imaging: past, present and future. J. Electron Microsc. 58, 87-97, doi:10.1093/jmicro/dfn030 (2009).
10 Varela, M. et al. Spectroscopic imaging of single atoms within a bulk solid. Phys. Rev. Lett. 92, 095502, doi:10.1103/PhysRevLett.92.095502 (2004).
11 Botton, G. A. A new approach to study bonding anisotropy with EELS. J. Electron Spectrosc. Relat. Phenom. 143, 129-137, doi:10.1016/j.elspec.2004.09.023 (2005).
12 Noy, A., Frisbie, C. D., Rozsnyai, L. F., Wrighton, M. S. \&amp; Lieber, C. M. CHEMICAL FORCE MICROSCOPY - EXPLOITING CHEMICALLY-MODIFIED TIPS TO QUANTIFY ADHESION, FRICTION, AND FUNCTIONAL-GROUP DISTRIBUTIONS IN MOLECULAR ASSEMBLIES. Journal of the American Chemical Society 117, 7943-7951, doi:10.1021/ja00135a012 (1995).
13 Garcia, R. \&amp; Perez, R. Dynamic atomic force microscopy methods. Surf. Sci. Rep. 47, 197-301, doi:10.1016/s0167-5729(02)00077-8 (2002).
14 Butt, H. J., Cappella, B. \&amp; Kappl, M. Force measurements with the atomic force microscope: Technique, interpretation and applications. Surf. Sci. Rep. 59, 1-152, doi:10.1016/j.surfrep.2005.08.003 (2005).
15 Bdikin, I. K., Shvartsman, V. V. \&amp; Kholkin, A. L. Nanoscale domains and local piezoelectric hysteresis in $\mathrm{Pb}(\mathrm{Zn} 1 / 3 \mathrm{Nb} 2 / 3) \mathrm{O}-3-4.5 \% \mathrm{PbTIO} 3$ single crystals. Appl. Phys. Lett. 83, 4232-4234, doi:10.1063/1.1627476 (2003).
16 Eng, L. M. et al. in Advances in Solid State Physics 41 Vol. 41 Advances in Solid State Physics (ed B. Kramer) 287-298 (Springer-Verlag Berlin, 2001).
17 Kalinin, S. V. et al. Defect-Mediated Polarization Switching in Ferroelectrics and Related Materials: From Mesoscopic Mechanisms to Atomistic Control. Adv. Mater. 22, 314-322, doi:10.1002/adma. 200900813 (2010).
18 Jesse, S., Lee, H. N. \&amp; Kalinin, S. V. Quantitative mapping of switching behavior in piezoresponse force microscopy. Rev. Sci. Instrum. 77, 073702, doi:10.1063/1.2214699 (2006).
19 Jesse, S., Baddorf, A. P. \&amp; Kalinin, S. V. Switching spectroscopy piezoresponse force microscopy of ferroelectric materials. Appl. Phys. Lett. 88, 062908, doi:10.1063/1.2172216 (2006).</p>
<p>20 Bosman, M., Watanabe, M., Alexander, D. T. L. \&amp; Keast, V. J. Mapping chemical and bonding information using multivariate analysis of electron energy-loss spectrum images. Ultramicroscopy 106, 1024-1032, doi:10.1016/j.ultramic.2006.04.016 (2006).
21 Jesse, S. \&amp; Kalinin, S. V. Principal component and spatial correlation analysis of spectroscopicimaging data in scanning probe microscopy. Nanotechnology 20, 085714, doi:10.1088/0957$4484 / 20 / 8 / 085714$ (2009).
22 Wei, Q., Bioucas-Dias, J., Dobigeon, N. \&amp; Tourneret, J. Y. Hyperspectral and Multispectral Image Fusion Based on a Sparse Representation. IEEE Trans. Geosci. Remote Sensing 53, 3658-3668, doi:10.1109/tgrs.2014.2381272 (2015).
23 Kelley, K. P. et al. Fast Scanning Probe Microscopy via Machine Learning: Non-Rectangular Scans with Compressed Sensing and Gaussian Process Optimization. Small 16, doi:ARTN 2002878
10.1002/smll. 202002878 (2020).</p>
<p>24 Kalinin, S. V., Kelley, K., Vasudevan, R. K. \&amp; Ziatdinov, M. Toward decoding the relationship between domain structure and functionality in ferroelectrics via hidden latent variables. ACS Applied Materials \&amp; Interfaces 13, 1693-1703 (2021).
25 Deng, J. et al. in 2009 IEEE conference on computer vision and pattern recognition. 248-255 (leee).
26 Krull, A., Hirsch, P., Rother, C., Schiffrin, A. \&amp; Krull, C. Artificial-intelligence-driven scanning probe microscopy. Commun. Phys. 3, 8, doi:10.1038/s42005-020-0317-3 (2020).
27 Dyck, O., Jesse, S. \&amp; Kalinin, S. V. A self-driving microscope and the Atomic Forge. MRS Bull. 44, 669-670, doi:10.1557/mrs.2019.211 (2019).
28 Kelley, K. P. et al. Dynamic Manipulation in Piezoresponse Force Microscopy: Creating Nonequilibrium Phases with Large Electromechanical Response. ACS nano 14, 10569-10577 (2020).</p>
<p>29 Requicha, A. et al. in Proceedings of the 2001 1st IEEE Conference on Nanotechnology. IEEE-NANO 2001 (Cat. No. 01EX516). 81-86 (IEEE).
30 Baur, C. et al. Nanoparticle manipulation by mechanical pushing: underlying phenomena and realtime monitoring. Nanotechnology 9, 360 (1998).
31 Mokaberi, B., Yun, J., Wang, M. \&amp; Requicha, A. A. in Proceedings 2007 IEEE International Conference on Robotics and Automation. 1406-1412 (IEEE).
32 Xie, H., Onal, C., Régnier, S. \&amp; Sitti, M. in Atomic force microscopy based nanorobotics 237-311 (Springer, 2011).
33 Mokaberi, B. \&amp; Requicha, A. A. Drift compensation for automatic nanomanipulation with scanning probe microscopes. IEEE Transactions on Automation Science and Engineering 3, 199-207 (2006).
34 Ovchinnikov, O. S., Jesse, S. \&amp; Kalinin, S. V. Adaptive probe trajectory scanning probe microscopy for multiresolution measurements of interface geometry. Nanotechnology 20, doi:255701
10.1088/0957-4484/20/25/255701 (2009).</p>
<p>35 Huang, B., Li, Z. \&amp; Li, J. An artificial intelligence atomic force microscope enabled by machine learning. Nanoscale 10, 21320-21326 (2018).
36 Sotres, J., Boyd, H. \&amp; Gonzalez-Martinez, J. F. Enabling autonomous scanning probe microscopy imaging of single molecules with deep learning. Nanoscale (2021).
37 Kalinin, S. V. et al. Automated and Autonomous Experiment in Electron and Scanning Probe Microscopy. arXiv preprint arXiv:2103.12165 (2021).
38 Kelley, K. P. et al. Dynamic Manipulation in Piezoresponse Force Microscopy: Creating Nonequilibrium Phases with Large Electromechanical Response. ACS Nano 14, 10569-10577, doi:10.1021/acsnano.0c04601 (2020).</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{a}$ ziatdinovma@ornl.gov
${ }^{\mathrm{b}}$ sergei2@ornl.gov&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>