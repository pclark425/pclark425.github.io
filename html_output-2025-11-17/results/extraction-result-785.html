<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-785 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-785</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-785</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-21.html">extraction-schema-21</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <p><strong>Paper ID:</strong> paper-265019383</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2311.01928v1.pdf" target="_blank">Constructing Temporal Dynamic Knowledge Graphs from Interactive Text-based Games</a></p>
                <p><strong>Paper Abstract:</strong> In natural language processing, interactive text-based games serve as a test bed for interactive AI systems. Prior work has proposed to play text-based games by acting based on discrete knowledge graphs constructed by the Discrete Graph Updater (DGU) to represent the game state from the natural language description. While DGU has shown promising results with high interpretability, it suffers from lower knowledge graph accuracy due to its lack of temporality and limited generalizability to complex environments with objects with the same label. In order to address DGU's weaknesses while preserving its high interpretability, we propose the Temporal Discrete Graph Updater (TDGU), a novel neural network model that represents dynamic knowledge graphs as a sequence of timestamped graph events and models them using a temporal point based graph neural network. Through experiments on the dataset collected from a text-based game TextWorld, we show that TDGU outperforms the baseline DGU. We further show the importance of temporal information for TDGU's performance through an ablation study and demonstrate that TDGU has the ability to generalize to more complex environments with objects with the same label. All the relevant code can be found at \url{https://github.com/yukw777/temporal-discrete-graph-updater}.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e785.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e785.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TDGU</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Temporal Discrete Graph Updater</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural model that constructs interpretable, dynamic belief knowledge graphs from textual observations by emitting timestamped graph events and modeling them with a temporal point-based graph neural network; preserves discreteness and supports multiple objects with identical labels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>TDGU</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Encoder-decoder architecture with: (1) a Transformer-based text encoder for current observation and previous action; (2) a graph encoder that builds node and edge attribute matrices from timestamped graph events (node-add/delete, edge-add/delete) and uses a graph Transformer (TransConv) to produce node embeddings; (3) a representation aggregator that computes cross-attention/similarity between text and graph embeddings; (4) an autoregressive Transformer-based graph-event decoder with four autoregressive heads (event type, source node, destination node, event label) that outputs a sequence of timestamped graph events to update the discrete belief graph.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>TextWorld (FTWP dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Text-based interactive game environment used for research; partially observable (agent only receives textual observations describing parts of the full world), contains many locations and objects, and includes spatial navigation and object interactions that require incremental mapping/remembering.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>Discrete timestamped belief graph represented as a sequence of timestamped graph events; internal representation: node attribute matrix V_t and edge attribute matrix E_t (rows correspond to node/edge indices with concatenated text label embeddings and temporal positional encodings). The graph encoder converts V_t/E_t to node embeddings H_G_t via a graph Transformer; these embeddings are aggregated with text encodings to drive the graph-event decoder.</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>Belief updated by appending generated timestamped graph events (node-add/delete, edge-add/delete) produced autoregressively by the decoder. On node-add events the corresponding row is added to V_t, on node-delete the row is removed, similarly for edges; after each update V_t/E_t are re-encoded to H_G_t. Temporal information (two-dimensional timestamps [t_g, t_e]) is encoded into event attribute vectors to disambiguate same-label objects and to capture recency.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>Not a planner — TDGU's scope is representation construction (knowledge-graph updating); action selection/planning is out of scope (downstream agents would use the constructed graphs to plan).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Timestamped graph-event representation and explicit temporal embeddings substantially improve construction of belief graphs in partially observable text worlds (higher FR-F1), enable distinguishing multiple objects with identical labels, and reduce error accumulation compared to label-only discrete updates (DGU). The model focuses on belief maintenance; it does not integrate outputs from external planning tools.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Constructing Temporal Dynamic Knowledge Graphs from Interactive Text-based Games', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e785.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e785.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DGU</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Discrete Graph Updater</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior interpretable model that incrementally updates a discrete belief graph by emitting graph update commands (add/delete RDF-like triples), but lacks temporality and cannot cleanly represent multiple objects with identical labels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Building dynamic knowledge graphs from text-based games</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>DGU</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Generates sequences of graph update commands (add(node1,node2,relation) and delete(...)) as token outputs from a Seq2Seq model; updates are applied by an oracle U to the belief graph after generation. Graph representation is label-based (nodes identified by labels), without timestamps or index-based node identities.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>TextWorld (FTWP dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Partially observable text-based games where agents receive textual observations and must incrementally build a seen-state graph; includes spatial locations and objects requiring memory.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>Discrete label-based belief graph updated via generated graph update commands; the oracle U applies add/delete commands to maintain the current belief graph. Nodes are identified by labels only (no unique indices or timestamps).</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>Model generates a batch of add/delete commands for the current step without accessing the updated graph during generation; after generation the oracle applies all commands to produce the updated belief graph. This delayed-application design leads to forgetting and accumulation of errors; lacks temporal history.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>Not a planner; used as a state-construction module for downstream planners/agents in prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Interpretable but suffers from lower graph accuracy due to lack of temporality and label-based node identity (cannot represent multiple identical-label objects); prone to error accumulation because update commands are generated without incremental access to the applied updates.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Constructing Temporal Dynamic Knowledge Graphs from Interactive Text-based Games', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e785.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e785.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CGU</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Continuous Graph Updater</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A continuous representation model that maintains the belief graph as dense adjacency/feature matrices updated as hidden states of recurrent networks, trading interpretability for higher task performance in prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning Dynamic Belief Graphs to Generalize on Text-Based Games</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>CGU</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Represents the knowledge graph as continuous, dense adjacency/feature matrices that are updated recurrently (hidden states of an RNN), producing embeddings used by downstream action-selection modules; unlike discrete updaters, it is not directly interpretable as symbolic graph edit events.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>TextWorld (FTWP dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Partially observable text-based games requiring incremental state estimation and navigation; CGU used as a state estimator in prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>Dense continuous adjacency/feature matrices stored as RNN hidden states (implicit belief representation), rather than explicit symbolic graph events.</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>Belief evolves via recurrent updates conditioned on incoming text and actions; the adjacency/features are continuous and not human-interpretable.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>Used as part of end-to-end agents that learn policies; planning is learned rather than explicit search-based.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CGU attained better task performance than earlier discrete updaters by using dense continuous representations, but at the cost of interpretability; motivates TDGU which aims to combine interpretability and temporal accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Constructing Temporal Dynamic Knowledge Graphs from Interactive Text-based Games', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e785.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e785.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Textual-SLAM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Textual Simultaneous Localization and Mapping (Textual-SLAM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conceptual framing equating the problem of building a belief graph and localizing the agent in a text-based environment to the robotics SLAM problem; the agent must incrementally map unseen environment structure and determine its position from textual observations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Textual-SLAM (concept)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Not an implemented agent in this paper but a conceptual analogy: an agent incrementally builds a map (belief graph) of the textual environment while simultaneously tracking its own location; techniques from SLAM motivate the need for temporality and consistent mapping in text domains.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Text-based interactive games (TextWorld)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Partially observable textual environments where localization and mapping must be inferred from incremental textual descriptions, analogous to robot SLAM but in language modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>Conceptual: incremental map (knowledge graph) plus self-localization; concrete mechanisms not specified in this paper (TDGU implements the mapping side via timestamped graph events).</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Paper draws an analogy to SLAM to motivate temporality and incremental mapping in partially observable text environments; does not describe a specific planner or external tool integration for navigation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Constructing Temporal Dynamic Knowledge Graphs from Interactive Text-based Games', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Learning Dynamic Belief Graphs to Generalize on Text-Based Games <em>(Rating: 2)</em></li>
                <li>Building dynamic knowledge graphs from text-based games <em>(Rating: 2)</em></li>
                <li>Textworld: A learning environment for text-based games <em>(Rating: 1)</em></li>
                <li>Graph constrained reinforcement learning for natural language action spaces <em>(Rating: 2)</em></li>
                <li>Learning Knowledge Graph-based World Models of Textual Environments <em>(Rating: 2)</em></li>
                <li>Simultaneous localization and mapping: part I <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-785",
    "paper_id": "paper-265019383",
    "extraction_schema_id": "extraction-schema-21",
    "extracted_data": [
        {
            "name_short": "TDGU",
            "name_full": "Temporal Discrete Graph Updater",
            "brief_description": "A neural model that constructs interpretable, dynamic belief knowledge graphs from textual observations by emitting timestamped graph events and modeling them with a temporal point-based graph neural network; preserves discreteness and supports multiple objects with identical labels.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "TDGU",
            "agent_description": "Encoder-decoder architecture with: (1) a Transformer-based text encoder for current observation and previous action; (2) a graph encoder that builds node and edge attribute matrices from timestamped graph events (node-add/delete, edge-add/delete) and uses a graph Transformer (TransConv) to produce node embeddings; (3) a representation aggregator that computes cross-attention/similarity between text and graph embeddings; (4) an autoregressive Transformer-based graph-event decoder with four autoregressive heads (event type, source node, destination node, event label) that outputs a sequence of timestamped graph events to update the discrete belief graph.",
            "environment_name": "TextWorld (FTWP dataset)",
            "environment_description": "Text-based interactive game environment used for research; partially observable (agent only receives textual observations describing parts of the full world), contains many locations and objects, and includes spatial navigation and object interactions that require incremental mapping/remembering.",
            "is_partially_observable": true,
            "external_tools_used": null,
            "tool_output_types": null,
            "belief_state_mechanism": "Discrete timestamped belief graph represented as a sequence of timestamped graph events; internal representation: node attribute matrix V_t and edge attribute matrix E_t (rows correspond to node/edge indices with concatenated text label embeddings and temporal positional encodings). The graph encoder converts V_t/E_t to node embeddings H_G_t via a graph Transformer; these embeddings are aggregated with text encodings to drive the graph-event decoder.",
            "incorporates_tool_outputs_in_belief": false,
            "belief_update_description": "Belief updated by appending generated timestamped graph events (node-add/delete, edge-add/delete) produced autoregressively by the decoder. On node-add events the corresponding row is added to V_t, on node-delete the row is removed, similarly for edges; after each update V_t/E_t are re-encoded to H_G_t. Temporal information (two-dimensional timestamps [t_g, t_e]) is encoded into event attribute vectors to disambiguate same-label objects and to capture recency.",
            "planning_approach": "Not a planner — TDGU's scope is representation construction (knowledge-graph updating); action selection/planning is out of scope (downstream agents would use the constructed graphs to plan).",
            "uses_shortest_path_planning": false,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": false,
            "key_findings": "Timestamped graph-event representation and explicit temporal embeddings substantially improve construction of belief graphs in partially observable text worlds (higher FR-F1), enable distinguishing multiple objects with identical labels, and reduce error accumulation compared to label-only discrete updates (DGU). The model focuses on belief maintenance; it does not integrate outputs from external planning tools.",
            "uuid": "e785.0",
            "source_info": {
                "paper_title": "Constructing Temporal Dynamic Knowledge Graphs from Interactive Text-based Games",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "DGU",
            "name_full": "Discrete Graph Updater",
            "brief_description": "A prior interpretable model that incrementally updates a discrete belief graph by emitting graph update commands (add/delete RDF-like triples), but lacks temporality and cannot cleanly represent multiple objects with identical labels.",
            "citation_title": "Building dynamic knowledge graphs from text-based games",
            "mention_or_use": "use",
            "agent_name": "DGU",
            "agent_description": "Generates sequences of graph update commands (add(node1,node2,relation) and delete(...)) as token outputs from a Seq2Seq model; updates are applied by an oracle U to the belief graph after generation. Graph representation is label-based (nodes identified by labels), without timestamps or index-based node identities.",
            "environment_name": "TextWorld (FTWP dataset)",
            "environment_description": "Partially observable text-based games where agents receive textual observations and must incrementally build a seen-state graph; includes spatial locations and objects requiring memory.",
            "is_partially_observable": true,
            "external_tools_used": null,
            "tool_output_types": null,
            "belief_state_mechanism": "Discrete label-based belief graph updated via generated graph update commands; the oracle U applies add/delete commands to maintain the current belief graph. Nodes are identified by labels only (no unique indices or timestamps).",
            "incorporates_tool_outputs_in_belief": false,
            "belief_update_description": "Model generates a batch of add/delete commands for the current step without accessing the updated graph during generation; after generation the oracle applies all commands to produce the updated belief graph. This delayed-application design leads to forgetting and accumulation of errors; lacks temporal history.",
            "planning_approach": "Not a planner; used as a state-construction module for downstream planners/agents in prior work.",
            "uses_shortest_path_planning": false,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": false,
            "key_findings": "Interpretable but suffers from lower graph accuracy due to lack of temporality and label-based node identity (cannot represent multiple identical-label objects); prone to error accumulation because update commands are generated without incremental access to the applied updates.",
            "uuid": "e785.1",
            "source_info": {
                "paper_title": "Constructing Temporal Dynamic Knowledge Graphs from Interactive Text-based Games",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "CGU",
            "name_full": "Continuous Graph Updater",
            "brief_description": "A continuous representation model that maintains the belief graph as dense adjacency/feature matrices updated as hidden states of recurrent networks, trading interpretability for higher task performance in prior work.",
            "citation_title": "Learning Dynamic Belief Graphs to Generalize on Text-Based Games",
            "mention_or_use": "mention",
            "agent_name": "CGU",
            "agent_description": "Represents the knowledge graph as continuous, dense adjacency/feature matrices that are updated recurrently (hidden states of an RNN), producing embeddings used by downstream action-selection modules; unlike discrete updaters, it is not directly interpretable as symbolic graph edit events.",
            "environment_name": "TextWorld (FTWP dataset)",
            "environment_description": "Partially observable text-based games requiring incremental state estimation and navigation; CGU used as a state estimator in prior work.",
            "is_partially_observable": true,
            "external_tools_used": null,
            "tool_output_types": null,
            "belief_state_mechanism": "Dense continuous adjacency/feature matrices stored as RNN hidden states (implicit belief representation), rather than explicit symbolic graph events.",
            "incorporates_tool_outputs_in_belief": false,
            "belief_update_description": "Belief evolves via recurrent updates conditioned on incoming text and actions; the adjacency/features are continuous and not human-interpretable.",
            "planning_approach": "Used as part of end-to-end agents that learn policies; planning is learned rather than explicit search-based.",
            "uses_shortest_path_planning": false,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": false,
            "key_findings": "CGU attained better task performance than earlier discrete updaters by using dense continuous representations, but at the cost of interpretability; motivates TDGU which aims to combine interpretability and temporal accuracy.",
            "uuid": "e785.2",
            "source_info": {
                "paper_title": "Constructing Temporal Dynamic Knowledge Graphs from Interactive Text-based Games",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Textual-SLAM",
            "name_full": "Textual Simultaneous Localization and Mapping (Textual-SLAM)",
            "brief_description": "Conceptual framing equating the problem of building a belief graph and localizing the agent in a text-based environment to the robotics SLAM problem; the agent must incrementally map unseen environment structure and determine its position from textual observations.",
            "citation_title": "",
            "mention_or_use": "mention",
            "agent_name": "Textual-SLAM (concept)",
            "agent_description": "Not an implemented agent in this paper but a conceptual analogy: an agent incrementally builds a map (belief graph) of the textual environment while simultaneously tracking its own location; techniques from SLAM motivate the need for temporality and consistent mapping in text domains.",
            "environment_name": "Text-based interactive games (TextWorld)",
            "environment_description": "Partially observable textual environments where localization and mapping must be inferred from incremental textual descriptions, analogous to robot SLAM but in language modalities.",
            "is_partially_observable": true,
            "external_tools_used": null,
            "tool_output_types": null,
            "belief_state_mechanism": "Conceptual: incremental map (knowledge graph) plus self-localization; concrete mechanisms not specified in this paper (TDGU implements the mapping side via timestamped graph events).",
            "incorporates_tool_outputs_in_belief": null,
            "belief_update_description": null,
            "planning_approach": null,
            "uses_shortest_path_planning": null,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": null,
            "key_findings": "Paper draws an analogy to SLAM to motivate temporality and incremental mapping in partially observable text environments; does not describe a specific planner or external tool integration for navigation.",
            "uuid": "e785.3",
            "source_info": {
                "paper_title": "Constructing Temporal Dynamic Knowledge Graphs from Interactive Text-based Games",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Learning Dynamic Belief Graphs to Generalize on Text-Based Games",
            "rating": 2,
            "sanitized_title": "learning_dynamic_belief_graphs_to_generalize_on_textbased_games"
        },
        {
            "paper_title": "Building dynamic knowledge graphs from text-based games",
            "rating": 2,
            "sanitized_title": "building_dynamic_knowledge_graphs_from_textbased_games"
        },
        {
            "paper_title": "Textworld: A learning environment for text-based games",
            "rating": 1,
            "sanitized_title": "textworld_a_learning_environment_for_textbased_games"
        },
        {
            "paper_title": "Graph constrained reinforcement learning for natural language action spaces",
            "rating": 2,
            "sanitized_title": "graph_constrained_reinforcement_learning_for_natural_language_action_spaces"
        },
        {
            "paper_title": "Learning Knowledge Graph-based World Models of Textual Environments",
            "rating": 2,
            "sanitized_title": "learning_knowledge_graphbased_world_models_of_textual_environments"
        },
        {
            "paper_title": "Simultaneous localization and mapping: part I",
            "rating": 1,
            "sanitized_title": "simultaneous_localization_and_mapping_part_i"
        }
    ],
    "cost": 0.01217425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Constructing Temporal Dynamic Knowledge Graphs from Interactive Text-based Games
3 Nov 2023</p>
<p>Keunwoo Peter Yu 
Constructing Temporal Dynamic Knowledge Graphs from Interactive Text-based Games
3 Nov 202305F1DB38E23BFCEF578189F61849AECDarXiv:2311.01928v1[cs.CL]
In natural language processing, interactive text-based games serve as a test bed for interactive AI systems.Prior work has proposed to play text-based games by acting based on discrete knowledge graphs constructed by the Discrete Graph Updater (DGU) to represent the game state from the natural language description.While DGU has shown promising results with high interpretability, it suffers from lower knowledge graph accuracy due to its lack of temporality and limited generalizability to complex environments with objects with the same label.In order to address DGU's weaknesses while preserving its high interpretability, we propose the Temporal Discrete Graph Updater (TDGU), a novel neural network model that represents dynamic knowledge graphs as a sequence of timestamped graph events and models them using a temporal point based graph neural network.Through experiments on the dataset collected from a text-based game TextWorld, we show that TDGU outperforms the baseline DGU.We further show the importance of temporal information for TDGU's performance through an ablation study and demonstrate that TDGU has the ability to generalize to more complex environments with objects with the same label.All the relevant code can be found at https://github.com/yukw777/temporal-discrete-graph-updater.</p>
<p>Introduction</p>
<p>Text-based games are electronic games that employ text-based user interfaces.In contrast with video games that rely on visual feedback, a text-based game uses natural language to describe the state of the game and accept input from the user to interact with the game environment.More formally, a text-based game can be thought of as a partially observable environment in which an agent perceives and interacts with the environment purely through textual natural language [4].In natural language processing, text-based games serve as a test bed for interactive AI systems that attempt to comprehend natural language and perform actions to interact with the environment as well as humans [9].</p>
<p>Prior work that has attempted to effectively play text-based games has focused on constructing an accurate representation of the game state from the natural language descriptions in the form of a knowledge graph and then acting in the game based on the graph.Some attempts have focused on heuristics to build knowledge graphs, which are then used as the input to a deep learning model that selects the next action [2,5], while more recent work has proposed more general, data-driven approaches to building knowledge graphs [1,3,26].</p>
<p>Particularly, Adhikari et al. [1] have proposed two models that incrementally update knowledge graphs based on textual observations that describe the game state instead of building them from scratch.The first model is the Continuous Graph Updater (CGU) that represents knowledge graphs as continuous and dense adjacency matrices updated as the hidden states of a recurrent neural network, making them uninterpretable.The second model is the Discrete Graph Updater (DGU) first proposed by Zelinka et al. [26] that updates knowledge graphs using "graph update commands," in the form of object-relation-object RDF triples such as add (table, kitchen, in).Thanks to this design choice, DGU produces interpretable knowledge graphs unlike CGU; however, DGU has resulted in worse game performance than CGU due to its lower knowledge graph accuracy caused by its lack of temporality, errors accumulating over game steps and errors caused by its discrete nature (e.g., round-off error).Furthermore, DGU's generalizability is limited as it cannot represent multiple objects with the same label due to label conflicts.</p>
<p>The goal of this work is to acquire interpretable knowledge graphs from interactive textbased games without sacrificing accuracy.We focus on constructing knowledge graphs, rather than choosing actions based on them, and on improving DGU so that it suffers less from errors while preserving its interpretability and improving its generalizability.To that end, we propose to replace the graph update commands with timestamped graph events and model them using a temporal point based graph neural network so that the model produces humaninterpretable knowledge graphs that are more accurate and generalizable to environments with multiple objects with the same label.</p>
<p>We compare the performance of our model to DGU using the dataset provided by Adhikari et al. [1] and show that our model outperforms it.We also perform an ablation study to show the importance of modeling temporality in constructing dynamic knowledge graphs.Furthermore, we demonstrate that our model supports multiple objects with the same label by modifying the dataset to contain such objects and retraining our model on it.All the relevant code can be found at https://github.com/yukw777/temporal-discrete-graph-updater.</p>
<p>Background and Related Work Interactive Text-based Games</p>
<p>One of the major goals of AI research is to develop an agent that can seamlessly converse with humans and carry out appropriate actions.A key challenge to this goal is the fact that it is not scalable to test such agents directly with humans.Interactive text-based games have garnered interest in the AI research community as they can alleviate this scalability problem.There are two recent text-based game engines that have been designed for AI research: TextWorld [7] and Jericho [9], which researchers can use to generate interactive text-based games that involve spatial navigation.There are pre-generated collections of games available for each of the game engines: the First TextWorld Problems (FTWP) dataset1 and JerichoWorld [4].There is another collection of games called LIGHT [21] that has been collected via crowdsourcing unlike procedurally generated FTWP and JerichoWorld.In this paper, we focus on TextWorld and the FTWP dataset as our baseline has used them.</p>
<p>Knowledge Representation and Knowledge Graphs</p>
<p>As text-based games contain many distinct locations with different objects, finding a good knowledge representation is important to help the agent remember and focus on the most relevant information.This echos the Mental Model Theory [10] from cognitive science, which states that humans reason by first constructing mental models.In robotics, this knowledge representation problem has been formalized as the simultaneous localization and mapping (SLAM) problem where a robot needs to incrementally build a consistent map of an unknown environment while simultaneously determining its location within the map [8].Text-based games involve a variant of the SLAM problem, Textual-SLAM, where the agent needs to localize itself and build a model of its environment as it navigates and receives textual descriptions of an unknown environment [4].Adhikari et al. [1], Ammanabrolu and Hausknecht [2], Ammanabrolu and Riedl [5], and Murugesan et al. [15] have demonstrated that agents equipped with knowledge graphs as their knowledge representation perform better in textbased games than an end-to-end baseline that attempts to map textual observations directly to actions.In particular, Adhikari et al. [1] have established an upper bound on the performance of their agent by providing it with the ground truth knowledge graphs, showing the importance of the accuracy of constructed knowledge graphs.As a result, some works [3,26] have focused on improving the accuracy of constructed knowledge graphs.In this work, we follow this line of research and propose a novel model that can construct interpretable knowledge graphs more accurately.</p>
<p>Dynamic Graph Neural Networks</p>
<p>Knowledge graphs that are used to play text-based games are dynamic by nature as they need to be updated based on new textual observations and agent actions.However, traditional graph neural networks only handle static graphs.A simple way to circumvent this limitation is to represent a dynamic graph as a series of static graphs and use a traditional graph neural network in conjunction with a time series model like a recurrent neural network [20].On the other hand, STGCN [25] transforms the series of static graphs into one static graph by connecting the related nodes across the series and uses a traditional graph neural network to model it instead of using a time series model.Another way to model a dynamic graph is to model the changes in graph structure as changes in edge weights.CN 3 [13] calculates pair-wise node attention at each step to update edge weights, while Hybrid GNN [14] uses the structure-aware global attention mechanism.</p>
<p>The approaches described above do not apply to newly added or deleted nodes, which is crucial for text-based games as they represent new or removed objects.Furthermore, they use dense graph representations which are not scalable for a longer time horizon.In order to address these issues, researchers have recently proposed temporal point process based models that represent graphs as graph events from the graph stream representation, which can explicitly represent node and edge additions and deletions while staying sparse and compact even for a longer time horizon [20].In this work, we reference two of the latest temporal point process based models TGAT [24] and TGN [16].</p>
<p>Dynamic Knowledge Graph Construction from Text</p>
<p>In this section, we give details about the task of constructing dynamic knowledge graphs from text in text-based games.Specifically, we describe the way in which a dynamic knowledge graph can be built by repeatedly applying updates to it.</p>
<p>Task Definition</p>
<p>We follow the definition from [26] where the full game state s t at any game step t in a text-based game is represented by a knowledge graph G f ull t = (V t , E t ).In TextWorld, nodes V t represents entities (e.g., objects, the player and locations) and their states (e.g., closed, fried, sliced, etc.), while edges E t that connect the nodes represent a set of relations between entities (e.g., north of, in, is, etc.).</p>
<p>Text-based games like TextWorld are partially observable; therefore, the agent does not have access to G f ull t .Instead, it needs to build its own belief graph about the game state, G belief t , based on textual observations.The goal of the agent should be to construct G belief t so that it matches the ground truth G seen t , which is a subgraph of G f ull t that represents only the entities and relations that have been seen so far in the game.Figure 1 shows an example of a ground truth G seen t based on a textual observation.</p>
<p>Dynamic Knowledge Graph Construction</p>
<p>Zelinka et al. [26] have proposed to construct dynamic knowledge graphs by representing updates to the agent's belief graph, ∆g t , using graph update commands such that G belief t = U(G belief t−1 , ∆g t ) where U is an oracle function that applies ∆g t .They have defined two types of update commands:</p>
<p>• add(n1, n2, r): add a directed edge, labeled r, from n1 to n2, while adding nodes that do not already exist.</p>
<p>• delete(n1, n2, r): delete a directed edge, labeled r, from n1 to n2.Ignore the command if any of the nodes or the edge does not exist.</p>
<p>The oracle function U does not apply ∆g t until all the graph update commands have been generated.This means that each graph update command is generated without access to the latest knowledge graph, making the model prone to "forgetting" to add or delete nodes and edges.Also, the updated knowledge graph from U is a flat, static graph without any historical information about how the graph has been updated to the current state.This lack of temporality makes it difficult for the model to differentiate between similar nodes that have been added at different times, and prevents the model from exploiting useful biases such as recency bias (a new node is more likely to be attached to a recently added node than an old one).All of these limitations hamper the ability of the model to produce accurate knowledge graphs.</p>
<p>Zelinka et al. [26]   commands separated by a delimiter token.However, as these graph update commands are purely based on labels, they cannot represent more complex graphs that have multiple objects with the same label.For example, consider a case where the textual observation is "There is an apple on the table.There is another apple on the chair."The resulting ∆g t , would be [add(apple, table, on), add(apple, chair, on)], which results in an inaccurate graph where one apple exists both on the table and the chair simultaneously.Ideally, we want our graph to have two separate nodes for the two apples, each connected to the table and chair vertices separately.</p>
<p>We propose to address these limitations by replacing graph updated commands with timestamped graph events to represent the updates to the graph.First, we define timestamp t to be a two-dimensional vector [t g , t e ] where t g denotes the game step and t e denotes the graph event step within the game step.For example, the fifth graph event in the second game step would have t of [1,4] (zero-indexed).This two-dimensional timestamp vector allows us to handle the enhanced granularity provided by timestamped graph events.Following the definitions proposed by Rossi et al. [16] with the two-dimensional timestamp vector defined above, we define four types of timestamped graph events:</p>
<p>• node-add event represented by v i (t) where i denotes the index of the added node and v is the attribute vector associated with the event.</p>
<p>• node-delete event represented by a tuple (i, t) where i denotes the index of the deleted node.</p>
<p>• edge-add event represented by e ij (t) where i denotes the index of the source node, j denotes the index of the destination node and e is the attribute vector associated with the event.</p>
<p>• edge-delete event represented by a tuple (i, j, t) where i denotes the index of the source node and j denotes the index of the destination node of the deleted edge.</p>
<p>It is easy to see that timestamped graph events provide us with the flexibility to represent graphs with multiple objects with the same label.Given the textual observation from the earlier example, the resulting sequence of timestamped graph events would be [v apple 0 4]), e on 23 ([t g , 5])], where v l and e l represent the attribute vectors for a node and an edge with label l respectively.Note that node 0 and 2 are both labeled "apple," and yet they are represented by separate nodes, which is not possible when using graph update commands from [26].
([t g , 0]), v table 1 ([t g , 1]), e on 01 ([t g , 2]), v apple 2 ([t g , 3]), v chair 3 ([t g ,
Generating timestamped graph events can also be formulated as a Seq2Seq problem where given a textual observation O tg and the current belief graph G belief t , the model generates a sequence of timestamped graph events as structured prediction.</p>
<p>Temporal Discrete Graph Updater (TDGU)</p>
<p>In this section, we introduce the Temporal Discrete Graph Updater (TDGU), a novel neural network model that updates discrete belief graphs based on textual observations.As shown in Figure 2, the architecture consists of four main modules:</p>
<p>Text Encoder</p>
<p>TDGU uses the same Transformer-based [22] encoder used by Adhikari et al. [1] and Zelinka et al. [26], which consists of a word embedding layer and a Transformer block, as its text encoder.TDGU's text encoder encodes the current textual observation O tg and the previous action A tg−1 separately to produce context-dependent representations H Ot g ∈ R L O tg ×H and )) + Pos text (L Ot g )])
H A tg −1 ∈ R L A tg −1 ×H respectively, where L Ot g is the length of O tg , L A tg −1 is the length of A tg−
(1)
H A tg −1 = TransEnc([Lin text (WordEmb(A 0 tg−1 )) + Pos text (0); ...; Lin text (WordEmb(A L A tg −1 tg−1 )) + Pos text (A tg−1 )])(2)
O i tg and A i tg−1 refer to the i'th token for O tg and A tg−1 respectively.WordEmb is the word embedding layer, which is initialized using the 300-dimensional fastText [6] word embeddings pretrained on Common Crawl (600B tokens).Lin text is a linear layer that reduces the dimension of the word embeddings to H, which is the dimension of the input and output of the Transformer block.[•; •] is the vector concatenation operator.TransEnc is the Transformer encoder block that consists of a stack of five convolutional layers and a self-attention layer, followed by two linear layers with a ReLU non-linear activation layer in between.Pos text (i) ∈ R H is the positional encoding [22] for position i.</p>
<p>Graph Encoder</p>
<p>We first formally define the node-add event v l i (t) ∈ R H+Htemp and the edge-add event e l ij (t) ∈ R H+Htemp :
v l i (t) = [
where t denotes the current timestamp [t g , t e ], l is the label of length L l and Pos graph (i) ∈ R Htemp/2 is the positional encoding for position i.Note that we use positional encoding as the temporal embeddings, which is a departure from some of the latest temporal point based graph neural networks such as TGAT and TGN.Their temporal embedding scheme relies on harmonic analysis in order to capture the relative time difference.However, absolute timestamps are more important in TextWorld given its incremental nature and shorter time horizon, which is better captured by positional encoding.</p>
<p>We then dynamically construct a node attribute matrix V t ∈ R N V t ×(H+Htemp) and an edge attribute matrix E t ∈ R N E t ×(H+Htemp) where N V t and N E t are the number of nodes and the number of edges at timestamp t.Specifically, for each node-add event v l i (t), we add a row to V t at position i with the attribute vector as defined in Equation 3, and for each node-delete event (i, t), we remove row i from V t .Edge events are handled similarly with respect to E t .</p>
<p>Once V t and E t are updated, we use an off-the-shelf graph neural network to obtain the final node embeddings H G t ∈ R N V t ×H .Specifically,
H G t = Lin graph (ReLU(TransConv(V t , E t ))) (5)
where TransConv is a one-headed graph Transformer operator [19], ReLU is the ReLU activation layer and Lin graph is a linear layer that reduces the dimension of its input from H + H temp to H.</p>
<p>Representation Aggregator</p>
<p>TDGU uses the same representation aggregator used by Adhikari et al. [1] and Zelinka et al. [26] to aggregate text and graph representations.Specifically, we obtain an aggregated observation-to-graph representation
H OG t ∈ R L O tg ×H by first calculating a similarity matrix S ∈ R L O tg ×N V t : S = Sim(H Ot g , H G t ) (6)
where Sim is a trilinear similarity function [18].By applying softmax along both axes of S, we obatin S G and S Ot g .Finally, H OG t is calculated:
P = S G H G t (7) Q = S Ot g S Ot g ⊺ H Ot g(8)H OG t = Lin aggr ([H Ot g ; P; H Ot g ⊙ P; H Ot g ⊙ Q])(9)
where Lin aggr is a linear layer that reduces the input dimension from 4H to H and ⊙ is the element-wise multiplication operator.An aggregated graph-to-observation representation
H GO t ∈ R N V t ×H can be calculated similarly. H AG t ∈ R L A tg −1 ×H and H GA t ∈ R N V t ×H
are calculated the same way between H A tg −1 and H G t .</p>
<p>Graph Event Decoder</p>
<p>We formulate the task of generating a sequence of timestamped graph events as a Seq2Seq problem and use an autoregressive Transformer-based decoder similar to the one used by Adhikari et al. [1] and Zelinka et al. [26].The input to the decoder is a sequence of timestamped graph event embeddings, which are constructed by concatenating the learned event type embedding, the mean projected word embeddings of the source node, destination and event labels.Furthermore, the aggregated representations from the representation aggregator are given to the decoder to attend over.The output of the decoder then goes through a series of autoregressive heads, similar to the ones proposed by Vinyals et al. [23], that are designed to handle structured and combinatorial timestamped graph events.There are four autoregressive heads: the event type head, the event source node head, the event destination node head and the event label head.A new graph event is generated based on the predictions made by the four heads, which is then appended to the sequence of timestamped graph events and fed back to the decoder to generate the next graph event.</p>
<p>Transformer-based Decoder</p>
<p>In order to formulate timestamped graph event generation as a Seq2Seq problem, we first represent e i , the ith graph event in the sequence generated so far, as a tuple of four arguments (τ i , s i , d i , l i ) where τ i denotes the event type, s i denotes the source node, d i denotes the destination node, and l i denotes the event label.Timestamp information is not included in this tuple, as t g is encoded in the aggregated representations and t e is given to the decoder via positional encoding.Each argument in the tuple is then transformed into an embedding and concatenated to produce a graph event embedding g i ∈ R Hτ +3H :
g i = [EventTypeEmb(τ i ); 1 L ls i w∈ls i Lin text (WordEmb(w)); 1 L l d i w∈l d i Lin text (WordEmb(w)); 1 L l i w∈l i Lin text (WordEmb(w))] (10)
where EventTypeEmb is the learned event type embedding layer with dimension H τ , l s i is the label of the source node and l d i is the label of the destination node.Following the standard practice for Seq2Seq models, we add two additional special event types, start and end, to the event type vocabulary.Furthermore, as certain event types do not require all the arguments, we appropriately mask out parts of g i : for the special event types, we mask all the embeddings except for the event type embedding; for node-add, we mask the embeddings for the source and destination nodes; for node-delete, we mask the embeddings for the destination node and the event label; for edge-add, we do not apply any masking; for edge-delete, we mask the embedding for the event label.We pass the sequence of graph event embeddings as well as the aggregated representations to a Transformer-based decoder with masked attention to generate a hidden vector h dec t ∈ R H :
h dec t = TransDec([Lin dec (g 0 ) + Pos dec (0); ...; Lin dec (g te ) + Pos dec (t e )],H OG t , H GO t , H AG t , H GA t ) (11)
where Lin dec is a linear layer that reduces the dimension of the input from H τ +3H to H and TransDec is the Transformer-based decoder block, which consists of a self-attention layer, a multihead-attention layer for each of the aggregated representation, followed by two linear layers with a ReLU activation layer in between.</p>
<p>Event Type Head</p>
<p>The event type head is the first of the autoregressive heads as the event type determines which graph event argument is necessary.It calculates a distribution over the event types
P (T = τ |O tg , A tg−1 , G belief t
) that can be used to generate the next event type.Specifically,</p>
<p>Event Destination Node Head</p>
<p>The event destination node head uses the same architecture as the event source node head to calculate a distribution over the nodes P (D = d|O tg , A tg−1 , G belief t , τ te+1 , s te+1 ), except it takes h auto(s) t instead of h auto(τ ) t as its input.We also assume that the set of possible destination nodes D is V t .The event destination node then calculates an autoregressive embedding h auto(d) t ∈ R Hauto the same way using the selected destination node d te+1 .</p>
<p>Event Label Head</p>
<p>The event label head uses h auto(d) t to calculate a distribution over the label vocabulary 24)
P (L = l|O tg , A tg−1 , G belief t , τ te+1 , s te+1 , d te+1 ): h l(0) t = ReLU(LN(Lin 0 l (h auto(d) t )))) (23) h l(1) t = ReLU(LN(Lin 1 l (h l(0) t ))) (P (L|O tg , A tg−1 , G belief t , τ te+1 , s te+1 , d te+1 ) = Softmax(Lin 2 l (h l(1) t )) (25)l te+1 = argmax i P (L = i|O tg , A tg−1 , G belief t , τ te+1 , s te+1 , d te+1 ) (26)
Since this is the last autoregressive head, the autoregressive embedding is not updated.</p>
<p>Having gone through all the autoregressive heads, the next graph event e te+1 can now be generated as (τ te+1 , s te+1 , d te+1 , l te+1 ).</p>
<p>Experiments</p>
<p>Dataset</p>
<p>We use the command generation dataset provided by Adhikari et al. [1], which they have used to train DGU.This is an updated version of the dataset provided by Zelinka et al. [26].The command generation dataset was collected from the games in the FTWP dataset by taking the difference between two consecutive ground truth seen knowledge graphs.Specifically, an agent follows the "walkthrough" steps for each game, which are the most efficient steps to beat the game provided by TextWorld, while additionally taking 10 random steps at each walkthrough step.At each game step, differences between the ground truth seen knowledge graphs are calculated and encoded as graph update commands described in Section 3.2.As a result, each datapoint in the command generation dataset contains the textual observation, previous action, previous ground truth seen knowledge graph and the target update commands.Table 1 shows the basic statistics for the command generation dataset.</p>
<p>Preprocessing</p>
<p>We preprocess the command generation dataset by turning the graph update commands into timestamped graph events.We first sort the update commands the same way Adhikari et al. [1] and Zelinka et al. [26] have done.Then for each datapoint, the previous ground truth seen knowledge graph and the target graph update commands are each transformed into a sequence of timestamped graph events by progressively building a graph using the graph update commands.During this process, exit nodes and state nodes need to be handled properly as they need to be treated as separate nodes despite having the same label due to the limitations in expressiveness of the update commands described in Section 3.2.For example, a room in TextWorld can have multiple exits, and multiple food items can be sliced.</p>
<p>The textual observation and previous action are tokenized using spaCy2 as Adhikari et al.</p>
<p>[1] and Zelinka et al. [26] have done.As a result, each preprocessed datapoint contains the tokenized textual observation and previous action, the current ground truth seen knowledge graph as a sequence of timestamped graph events and the target graph events.</p>
<p>Training Setup</p>
<p>TDGU is trained via teacher-forcing where the model is given the ground truth sequence of timestamped graph events as its input.Specifically, the graph encoder receives the current ground truth seen knowledge graph in the form of a sequence of timestamped graph events, and each of the autoregressive heads receives the previous ground truth event argument, i.e. the source node head receives the ground truth event type; the destination node head receives the ground truth source node; and the event label head receives the ground truth destination node.The text encoder simply receives the preprocessed textual observation and previous action.We calculate a negative log-likelihood loss for each autoregressive head.The total loss is a weighted sum of all the losses from the heads.We use the weighting strategy proposed by Kendall, Gal, and Cipolla [11] with a small modification proposed by Liebel and Körner [12] to calculate the weights for the losses.Table 2 shows the various hyperparameters of TDGU.The model was trained for 2.5 days on a NVIDIA A40 GPU.</p>
<p>Experimental Setup and Results</p>
<p>Dynamic Knowledge Graph Construction</p>
<p>We first test the effectiveness of TDGU by comparing its performance in dynamic knowledge graph construction to DGU.For fair comparison with the baseline, we follow the evaluation strategy proposed by Zelinka et al. [26]  as the free-run (FR) F 1 score.These scores are based on the intersection of the generated set of graph update commands or RDF triples and the ground truth set.</p>
<p>• TF F 1 : the model uses greedy decoding to generate timestamped graph events based on the current ground truth belief graph G belief t .As Zelinka et al. [26] measured this score based on graph update commands, we convert the model's generated timestamped graph events into graph update commands.Specifically, we take the event type, the source node label, destination node label and event label of a timestamped edge event to create a graph update command.Then we calculate the F 1 score using the set of converted graph update commands and the ground truth update commands.</p>
<p>• FR F 1 : Unlike Zelinka et al. [26] who measured this score per game, we calculate this score per "trajectory", which consists of walkthrough steps and random steps.For example, given a game with 5 walkthrough steps, the second trajectory would consist of the first two walkthrough steps and 10 random steps taken from the second walkthrough step.For each trajectory, we start with an empty belief graph and update it using greedy decoding without using any ground truth belief graph until the end of the trajectory.Then we convert each edge in the final belief graph into an RDF triple and calculate the F 1 score against the final ground truth belief graph.This is the metric that is most representative of the actual performance of the model in realistic settings.</p>
<p>Zelinka et al. [26] have only reported the scores on the older version of the command generation dataset and have not released their code.The code released by Adhikari et al. [1] only reports TF F 1 on the updated version of the command generation dataset.In order to establish a fair comparison, we retrain DGU using their released code on the updated command generation dataset, and use the same evaluation code we wrote for TDGU to calculate FR F 1 .Results are reported in Table 3. Figure 3 and 4 show example graphs constructed by TDGU and the baseline DGU respectively.</p>
<p>Modeling Temporality</p>
<p>We train a version of TDGU, TDGU no-temp , with static (zero) positional encoding in order to gauge the importance of modeling temporality.The same preprocessed command generation  3), DGU correctly labeled the "kitchen" node.However, it missed the "closed" node that should be attached to the "fridge" node.Furthermore, it struggled with placing food items correctly "on" the "counter".As described in Section 3.2, it only created one "uncut" node to which all the food item nodes are attached, instead of creating one for each of the uncut food items. .Unlike TDGU (Figure 3), TDGU no-temp correctly labeled the "kitchen" node.However, it also missed the "yellow apple" node and added an erroneous "banna" node.Most critically, it struggled with attaching nodes with the same label (e.g., "uncut") to the correct nodes, which TDGU did not struggle with.This is because the embeddings of these nodes become very similar without the temporal embeddings, and TDGU no-temp struggles to differentiate between them.</p>
<p>dataset is used to train TDGU no-temp .The performance of TDGU no-temp is also reported in Table 3. Figure 5 shows an example graphs constructed by TDGU no-temp .</p>
<p>Multiple Objects with Same Label</p>
<p>In order to demonstrate TDGU's flexibility in handling multiple objects with the same label, we train another version of TDGU, TDGU multi , on a modified version of the command generation dataset that contains multiple objects with the same label.TextWorld does not natively support multiple objects with the same label within a game.However, it does contain food items in different colors such as yellow potatoes and purple potatoes.We split the nodes for these colored food items into two, one for the food item and the other for the color, and connect them with an edge labeled "is".For example, if the textual observation is "There is a purple potato on the table.There is a yellow potato on the chair.", the resulting graph events would be [v potato 0 3]), e on 02 ([t g , 4]), in terms of FR F 1 , which shows that the extra temporal information is indeed helpful in accurately updating knowledge graphs.
([t g , 0]), v purple 1 ([t g , 1]), e is 01 ([t g , 2]), v table 2 ([t g ,
Both TDGU and TDGU no-temp performed worse than the baseline in terms of TF F 1 .We hypothesize that it might be due to the fact that the extra temporal information is a distraction when generating graph events for one game step based on ground truth knowledge graphs.The fact that both TDGU and TDGU no-temp have similar TF F 1 scores may be another piece of evidence that for short horizons, i.e. one game step, the extra temporal information may not help.We leave the investigation into this phenomenon for future studies.</p>
<p>The FR F 1 score of TDGU on the modified dataset with multiple objects with the same label was not as high as its performance on the original dataset mostly due to the fact that the modified dataset is harder as TDGU has to learn to differentiate between nodes with the same label.Even so, it outperformed the baseline while properly handling multiple objects with the same label as shown in Figure 6.</p>
<p>Future Directions</p>
<p>There are a few architectural improvements we can make to TDGU to enhance its performance and generalizability.The first is adding an event edge head to the graph event decoder.Currently, TDGU makes separate classifications for the source node and destination node of the deleted edges.These classifications are autoregressive, but an event edge head that directly classifies which edge should be deleted can provide a larger architectural inductive bias, thereby increasing TDGU's performance.Furthermore, we can replace the current event label head, which is a simple classification layer, with an autoregressive decoder with the same vocabulary as the text encoder.This would allow TDGU to be more general in terms of the labels it can use for nodes and edges and easily be used in more complex environments beyond TextWorld.Moreover, we could add "extractiveness" to the model by using the pointer-generator network [17] to further enhance the accuracy of the event label head.It would also be interesting to try other graph neural networks for the graph encoder to see if they would have a positive impact on the model performance.</p>
<p>Upon implementing the architectural improvements described above, we plan to test TDGU on other benchmarks such as LIGHT and Jericho.It would also be interesting to see if using pretrained language models could enhance TDGU's performance on these benchmarks, especially LIGHT which should have more variability in textual descriptions as it was crowdsourced.</p>
<p>As graph events can have any kind of attribute vectors, they can be used to represent dynamic graphs with more complex node and edge features.One interesting future direction in this regard would be to use TDGU in multi-modal settings where node and edge features are formed from text as well as vision.This multi-modal model can use a pretrained large language model and vision model as its encoders in order to handle natural language and images better.</p>
<p>Another interesting future direction is to explore ways to train TDGU in a self-supervised way.Currently, one of the biggest challenges in building a knowledge graph construction model like TDGU is the dearth of training data.If we can introduce appropriate architectural changes to TDGU so that it can be trained without the ground truth knowledge graphs, we can use TDGU for more complex tasks like commonsense reasoning where the inductive bias provided by the graphical nature of TDGU would be very helpful.</p>
<p>Conclusion</p>
<p>In this work, we have presented a novel neural network model that constructs dynamic knowledge graphs using timestamped graph events, and showed that it outperforms the baseline on a text-based game knowledge graph dataset in terms of the FR F 1 score, which is more representative of the performance in realistic settings.Furthermore, we have shown that our model is more generalizable to more complex environments than the baseline, specifically the ones with multiple objects with the same label; and therefore, it may open up opportunities to use dynamic knowledge graphs in tasks other than text-based games.</p>
<p>Figure 1 :
1
Figure 1: The ground truth seen belief graph given the textual observation.Emphasis in the textual observation is ours.</p>
<p>Figure 2 :. 3 .
23
Figure 2: TDGU model architecture diagram that depicts the unrolled graph event generation process.The primary input to the model consists of the textual observation O tg and the previous action A tg−1 that are encoded by the text encoder, and the current belief graph G belief [tg,te] that is encoded by the graph encoder.The encoded representations are then aggregated by the representation aggregator, whose output is passed to the Transformer-based decoder alongside the graph event embedding.Finally, the decoder hidden state is given to the autoregressive heads that generate the next graph event e te+1 = (τ te+1 , s te+1 , d te+1 , l te+1 ), which is used to update G belief [tg,te] .The process continues until an end event is generated, at which point a start event, the textual input for the next game step, O tg+1 and A tg , and the current belief graph for the next game step G belief [tg+1,0] are given to the model to generate the next sequence of graph events.</p>
<p>Figure 4 :
4
Figure4: A graph constructed by DGU based on the same textual observation from Figure1.Unlike TDGU (Figure3), DGU correctly labeled the "kitchen" node.However, it missed the "closed" node that should be attached to the "fridge" node.Furthermore, it struggled with placing food items correctly "on" the "counter".As described in Section 3.2, it only created one "uncut" node to which all the food item nodes are attached, instead of creating one for each of the uncut food items.</p>
<p>Figure 5 :
5
Figure5: A graph constructed by TDGU no-temp based on the same textual observation from Figure1.Unlike TDGU (Figure3), TDGU no-temp correctly labeled the "kitchen" node.However, it also missed the "yellow apple" node and added an erroneous "banna" node.Most critically, it struggled with attaching nodes with the same label (e.g., "uncut") to the correct nodes, which TDGU did not struggle with.This is because the embeddings of these nodes become very similar without the temporal embeddings, and TDGU no-temp struggles to differentiate between them.</p>
<p>yellow potato on uncut is yellow apple on uncut is raw is red potato on uncut is red hot pepper on uncut is raw is red apple on</p>
<p>have formulated the task of generating graph update commands into a classic token-based Seq2Seq problem where, given a textual observation O t and a previous belief graph G belief t−1 , the model generates a sequence of tokens that represent multiple update You are hungry!Let's cook a delicious meal.Check the cookbook in the kitchen for the recipe.… You're in the kitchen.… You make out a closed fridge right there by you.You can see a closed oven.You make out a table.On the table you see a knife.You see a gleam over in a corner, where you can see a counter.… On the counter you see a red apple, a raw yellow potato, a raw red potato, a chopped raw purple potato, a yellow apple, a red hot pepper and a cookbook.You hear a noise behind you and spin around, but you can't see anything other than a stove.… player kitchen at knife table on at stove at oven at fridge at closed is counter at uncut is raw is purple potato on chopped is cookbook on</p>
<p>Ot g = TransEnc([Lin text (WordEmb(O 0 tg )) + Pos text (0); ...; Lin text (WordEmb(O L O tg tg</p>
<p>1and H is the dimension of the encoded representations: H</p>
<p>Table 1 :
1
Train Valid Test Avg.Obs.Avg.Cmds.Nodes Edges Avg.Conns.Statistics of the command generation dataset.Avg.Obs. is the average number of tokens for textual observations.Avg.Cmds. is the average number of graph update commands.Nodes and Edges refer to the number of node and edge types.Avg.Conns. is the average number of edges per graph.
413455 20177 6474929.32.67991030.47</p>
<p>Table 2 :
2
and measure the teacher-force (TF) F 1 score, as well Various hyperparameters for TDGU training.
HyperparameterValueH64H temp16H τ16H auto128H node16Batch size64Learning rate5 × 10 −4Optimization algorithm AdamW
https://aka.ms/ftwp
https://spacy.io/
))) (13))) (14)where LN is layer normalization and Lin j τ is the jth linear layer for the event type head.The event type head also creates an autoregressive embedding h auto(τ ) t ∈ R Hauto from h dec t and τ te+1 :where OneHot is a function that returns a one-hot vector, Lin dec τ is a linear layer that maps h dec t to the autoregressive embedding space and Lin auto(i) τ is the ithe linear layer to map the one-hot event type vector to the autoregressive embedding space.Event Source Node HeadThe event source node head uses the query-key attention mechanism to calculate a distribution over the nodes P (S = s|O tg , A tg−1 , G belief t , τ te+1 ) where S is the set of possible source nodes, which we assume to be all nodes V t , in G belief t .Specifically, it calculates a key matrix K ∈ R N V t ×H node and a query vector q ∈ R H node :q = Lin 1 src (ReLU(Lin 0 src (hwhere Conv1D is a 1D convolution layer and Lin i src is the ith linear layer that maps h auto(τ ) tto the query-key space.It then multiplies K and q together to calculate the distribution over the nodes:The event source node head then creates an autoregressive embedding hwhere K i denotes the ith row of K and Lin auto src is a linear layer that maps from the query-key space to the autoregressive embedding space.It is mostly accurate but has some glaring issues such as the mislabeled "kitchen" node (labeled as "livingroom"), misattached "cookbook" node, missing "yellow apple", and the self-looped "pork chop" node with a "pantry" edge.1.It performed the best out of all the models on this example, only missing the "yellow apple" node.Note that it handled objects with the same label, e.g."potato", correctly.8]), e on 35 ([t g , 9])].TF F 1 cannot be measured in this setting as the graph update commands cannot represent updates for multiple objects with the same label.RDF triples also lack the ability to represent such objects, but we were able to circumvent this limitation and measure FR F 1 by merging the nodes of colored food items into one when generating RDF triples, and comparing them with the original ground truth RDF triples.The FR F 1 score for this experiment is also reported in Table3. Figure6shows an example of graphs with multiple objects with the same label generated by TDGU.DiscussionTDGU outperformed the baseline DGU in terms of FR F 1 .This is evidence that TDGU has better performance in realistic settings where ground truth knowledge graphs are not provided.TDGU no-temp performed worse than TDGU but slightly outperformed the baseline
Learning Dynamic Belief Graphs to Generalize on Text-Based Games. Ashutosh Adhikari, Advances in Neural Information Processing Systems. Curran Associates, Inc202033</p>
<p>Graph constrained reinforcement learning for natural language action spaces. Prithviraj Ammanabrolu, Matthew Hausknecht, arXiv:2001.088372020arXiv preprint</p>
<p>Learning Knowledge Graph-based World Models of Textual Environments. Prithviraj Ammanabrolu, Mark O Riedl, arXiv:2106.096082021arXiv preprint</p>
<p>Modeling Worlds in Text. Prithviraj Ammanabrolu, Mark O Riedl, arXiv:2106.095782021arXiv preprint</p>
<p>Playing text-adventure games with graph-based deep reinforcement learning. Prithviraj Ammanabrolu, Mark O Riedl, arXiv:1812.016282018arXiv preprint</p>
<p>Enriching Word Vectors with Subword Information. Piotr Bojanowski, arXiv:1607.046062016arXiv preprint</p>
<p>Textworld: A learning environment for text-based games. Marc-Alexandre Côté, Workshop on Computer Games. Springer2018</p>
<p>Simultaneous localization and mapping: part I. Hugh Durrant, - Whyte, Tim Bailey, IEEE robotics &amp; automation magazine. 1322006</p>
<p>Interactive fiction games: A colossal adventure. Matthew Hausknecht, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202034</p>
<p>Mental models and human reasoning. Johnson-Laird Philip, Proceedings of the National Academy of Sciences. 1072010</p>
<p>Multi-task learning using uncertainty to weigh losses for scene geometry and semantics. Alex Kendall, Yarin Gal, Roberto Cipolla, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2018</p>
<p>Auxiliary tasks in multi-task learning. Lukas Liebel, Marco Körner, arXiv:1805.063342018arXiv preprint</p>
<p>Contextualized non-local neural networks for sequence learning. Pengfei Liu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence201933</p>
<p>Retrieval-Augmented Generation for Code Summarization via Hybrid GNN. Shangqing Liu, International Conference on Learning Representations. 2020</p>
<p>Enhancing text-based reinforcement learning agents with commonsense knowledge. Keerthiram Murugesan, arXiv:2005.008112020arXiv preprint</p>
<p>Temporal graph networks for deep learning on dynamic graphs. Emanuele Rossi, arXiv:2006.106372020arXiv preprint</p>
<p>Get to the point: Summarization with pointer-generator networks. Abigail See, Peter J Liu, Christopher D Manning, arXiv:1704.043682017arXiv preprint</p>
<p>Bidirectional attention flow for machine comprehension. Minjoon Seo, arXiv:1611.016032016arXiv preprint</p>
<p>Masked label prediction: Unified message passing model for semisupervised classification. Yunsheng Shi, arXiv:2009.035092020arXiv preprint</p>
<p>Foundations and modelling of dynamic networks using dynamic graph neural networks: A survey. Joakim Skardinga, Bogdan Gabrys, Katarzyna Musial, IEEE Access. 2021</p>
<p>Learning to speak and act in a fantasy text adventure game. Jack Urbanek, arXiv:1903.030942019arXiv preprint</p>
<p>Attention is all you need. Ashish Vaswani, Advances in neural information processing systems. 2017</p>
<p>Grandmaster level in StarCraft II using multi-agent reinforcement learning. Oriol Vinyals, Nature. 5752019</p>
<p>Inductive representation learning on temporal graphs. Da Xu, arXiv:2002.079622020arXiv preprint</p>
<p>Spatial temporal graph convolutional networks for skeleton-based action recognition. Sijie Yan, Yuanjun Xiong, Dahua Lin, Thirty-second AAAI conference on artificial intelligence. 2018</p>
<p>Building dynamic knowledge graphs from text-based games. Mikuláš Zelinka, arXiv:1910.095322019arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>