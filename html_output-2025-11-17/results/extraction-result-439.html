<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-439 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-439</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-439</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-270564180</p>
                <p><strong>Paper Title:</strong> <a href="https://api.elsevier.com/content/article/pii/S1389041724000512" target="_blank">Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture</a></p>
                <p><strong>Paper Abstract:</strong> In the last years, the System 1/System 2 cognitive architecture, proposed by psychologist Daniel Kahneman, raised the interest of many researchers in the ﬁeld. System 1 is an intuitive, automatic, and fast-thinkingsystemworkingeortlessly,withoutconsciouse�ort. System2 isadeliberate,analytical, and slower-thinking system employing conscious e�ort and attention. This work proposes an innovative approach that exploits techniques typical of information retrieval (the trie data structure) to e�ciently encode the solutions’ repository at the border between System 2 and System 1. This repository stores the solutions (successful plans) the agent has already used and can re-enact to achieve the goals. System 2 conceives new plans and delegates System 1 to execute them. If the plan is successful (and so it becomes a solution), System 1 stores that in the repository to quickly retrieve any solution that may help fulﬁl the goals deliberated by System 2 in the future.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e439.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e439.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GLITTER</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GoaL-orIenTed TriE stRucture (GLITTER)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A five-layered trie-based solution repository implementing the System1 side of a System1/System2 cognitive architecture: stores goal-oriented successful plans as sequences of tasks keyed by goal, precondition, and quality for fast retrieval and execution.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GLITTER (trie-based System1/System2 hybrid)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GLITTER is a modular hybrid reasoning system where System 2 performs goal-oriented planning using declarative Boolean goal formulas and System 1 provides a fast imperative executor and retriever implemented as a layered trie. The trie stores tuples across five layers (Goal, Preconditions, Quality of Solution, Solution Steps, Final State). System 2 creates and canonicalizes plans/goals and, after a successful execution, System 1 stores the tested solution in GLITTER; on later requests System 1 quickly retrieves candidate solutions meeting goal, precondition and QoS constraints and executes the stored procedural task sequence, escalating to System 2 on failure or unmet quality.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Goal and precondition representations are declarative Boolean formulas (canonical Sum-of-Products) and task pre/postconditions; System 2 uses goal trees and symbolic goal descriptions (logical formulas, predicate-based representations).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>An imperative procedural execution layer implemented as a trie of recorded sequential tasks; each SolutionStep stores TaskName([params]) and expected PostCondition — i.e., stored procedural plans (rule/sequence execution engine).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular, sequential division of labor: System 2 provides canonicalized declarative goals/plans (BFO format) and populates a temporary plan repository; after successful trial System1 stores the procedural plan in the GLITTER trie. At runtime System2 delegates execution request (optionally with QoS) to System1 which retrieves by keys (goal, precondition, QoS) and executes the stored imperative sequence; System1 raises exceptions to System2 on failure. No end-to-end differentiable integration — tight semantic mapping via canonicalization (Boolean Formula Ordering) and key-based retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Very fast retrieval/execution of previously successful, goal-directed procedures (low-latency reactive behaviour); ability to reuse procedural knowledge across logically related goals via canonical goal ordering (subsumption of SOP terms), transparency and explainability of chosen solution path (explicit goal/precondition/QoS/task representation), and emergent 'personality' differences determined by ordering and QoS evaluation policies (different agents may prefer different solutions).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Not evaluated on external benchmarks; intended for goal-oriented planning/execution and human-robot interaction contexts (planning, plan retrieval, and execution monitoring).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Generalization is procedural and conservative: solutions are reused when the current state satisfies stored preconditions; canonical SOP ordering allows reuse of solutions for broader goals whose SOP contains a stored product term (subsumption). Limited adaptation — GLITTER assumes same initial conditions or light parameter adaptation; no reported out-of-distribution or compositional generalization benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High interpretability: layers separate Goals, Preconditions, QoS, Steps and Final State enabling explicit inspection, debugging and explanations for why a plan was selected (transparent string-based representation and explicit final-state checks).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>No empirical evaluation reported; System1 limited to replaying stored procedural sequences with simple QoS metrics (single integer or 'don't care'); limited built-in adaptation to changed environments; the full System1/System2 architecture (other System1 modules and System2 planner) remains work-in-progress; potential memory cost of tries; reliance on exact precondition matching may limit applicability when environments are noisy or dynamics change.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Dual-process (System1/System2) division of labor inspired by Kahneman: System2 performs deliberate, symbolic planning and canonicalization; System1 provides fast reactive retrieval/execution via an information-retrieval-style trie. Uses Boolean Formula Ordering (BFO) as a canonicalization principle to map declarative goals to retrieval keys.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e439.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e439.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DUAL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DUAL cognitive architecture</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid cognitive architecture integrating connectionist and symbolic approaches via interacting micro-agents, each with a symbolic and a connectionist part, producing computations that emerge from their interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DUAL (Kokinov)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>DUAL is described as a hybrid multi-agent cognitive architecture in which many micro-agents each possess symbolic and connectionist components; cognition emerges from interactions and spread of activation among agents, providing integrated symbolic and subsymbolic processing.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Symbolic representations embedded in each micro-agent (symbolic part per agent, rule-like structures or symbolic memory).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Connectionist/subsymbolic networks inside agents (neural-network-like processing, spread of activation).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Tightly coupled micro-agent architecture where each agent contains both symbolic and connectionist parts and computations emerge from their interaction and message passing (emergent hybrid integration rather than an explicit pipeline).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Distributed emergent computations arising from agent interactions; integration of symbolic reasoning and subsymbolic pattern processing enabling flexible cognitive behaviours (perception, memory, decision-making) via emergent dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>General cognitive modelling (perception, attention, memory, learning, decision-making); no specific benchmark reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Described qualitatively as supporting flexible cognition via emergent interactions; no quantitative generalization claims reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Intermediate: symbolic parts can be inspected but emergent behavior from connectionist interactions may reduce transparency.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>No performance metrics here; potential complexity in analysis due to emergent interactions and difficulty in guaranteeing reliability or exact behavior across runs.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Hybrid micro-agent framework relying on complementary symbolic/subsymbolic representations and emergent computation via interaction.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e439.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e439.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ACT-R</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adaptive Control of Thought — Rational (ACT-R)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid cognitive architecture combining symbolic production-rule based knowledge with subsymbolic mechanisms for activation and utility, often used to model human cognitive processes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ACT-R (hybrid)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>ACT-R combines declarative memory structures and production rules (symbolic) with subsymbolic activation and learning mechanisms; the paper notes ACT-R does not inherently operate on a dual-process basis but can implement System1-like behaviour via schemas and production rules and uses declarative/procedural knowledge representations.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Declarative memory represented as symbolic chunks and logical predicates; production-rule (if-then) systems for procedural knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Subsymbolic activation dynamics and learning (utility learning, activation decay) and connectionist-like parameterized mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Hybrid integration with symbolic rules acting on declarative chunks and subsymbolic parameters guiding selection and learning — modular but tightly coupled within the ACT-R framework.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Ability to model human-like timing, errors, and learning through the interaction of symbolic rules and subsymbolic dynamics; quick automatic behaviours can be modelled by learned productions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Cognitive task modeling (memory, attention, learning); no specific numeric benchmark in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Used to model human generalization in cognitive tasks via learned productions and activation spreading; no quantitative claims here.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High interpretability at symbolic level (production rules) with subsymbolic parameters explaining probabilistic behaviour.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Not inherently dual-process; requires design work to implement explicit System1/System2 separation; potential mismatch when modeling fast associative processes vs. deliberative ones.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Hybrid cognitive architecture combining symbolic production systems with subsymbolic learning and activation — supports mapping of both automatic and controlled processes when explicitly engineered.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e439.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e439.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CLARION</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CLARION cognitive architecture</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cognitive architecture that explicitly separates implicit (subsymbolic) and explicit (symbolic) processing, structuring cognition into subsystems each with dual representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CLARION</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CLARION organizes cognition into multiple subsystems (ACS, NACS, MS, MCS), each with an implicit (subsymbolic distributed representations such as neural networks) and explicit (symbolic) layer, enabling the modeling of both implicit learning and explicit reasoning within a single architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Explicit symbolic representations and rule-like structures for high-level reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Implicit subsymbolic distributed representations (neural-network style) for procedural/associative processes.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Dual-representation per subsystem; implicit and explicit representations interact within and across subsystems (modular coupling between symbolic and subsymbolic levels).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Ability to model both implicit learning and explicit reasoning in the same architecture, capturing phenomena like skill learning, habits, and conscious deliberation; interactions produce richer cognitive behaviours than either alone.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>General cognitive modelling (learning, decision-making); no numeric benchmark reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Qualitatively supports both procedural skill generalization via subsymbolic learning and compositional explicit reasoning via symbolic layer; no quantitative evaluation provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Explicit symbolic layer offers interpretability; implicit layer is less transparent.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Complexity in coordinating implicit/explicit levels; no empirical metrics provided in this paper's discussion.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Dual-representation theory: separating implicit and explicit processes and connecting them within modular subsystems.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e439.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e439.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dual-PECCS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dual-PECCS hybrid knowledge representation and reasoning system</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid KR&R system integrating Conceptual Spaces (prototype/exemplar similarity-based Type1 processes) with ontological Description Logic-based deductive Type2 processes, executed sequentially to combine fast similarity-based retrieval and symbolic deduction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Dual-PECCS</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Dual-PECCS contains a hybrid knowledge base representing the same conceptual entities in multiple forms: Conceptual Spaces for prototype/exemplar retrieval (Type1/System1) and Description Logic ontologies for deductive inference (Type2/System2). Type1 processes perform similarity-based categorization which is then refined by Type2 deductive processing in sequence.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Ontological representation using Description Logic for symbolic, deductive reasoning (Type2).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Conceptual Spaces framework representing prototypes/exemplars and similarity metrics implementing fast, associative retrieval (Type1), arguably sub-symbolic or metric-based reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Sequential pipeline: Type1 (similarity/prototype/exemplar retrieval in Conceptual Spaces) runs first and its outputs are refined by Type2 (deductive inference in Description Logic); multiple representations of same entities enable cross-checking and refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Combines fast associative categorization with rigorous deductive refinement, providing quicker initial responses with subsequent symbolic validation/refinement, reducing errors of pure similarity-based classification.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Categorization and reasoning tasks within cognitive architectures (integrated into ACT-R and CLARION in the cited work); no quantitative benchmarks reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Expected to generalize better than pure symbolic systems on prototype/exemplar tasks due to similarity metrics, and better than pure subsymbolic systems in terms of logical consistency due to subsequent DL inference; no empirical measures provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Symbolic DL component supports explainability of deductive conclusions; Conceptual Spaces provide geometric/metric explanations for prototype-based judgments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Sequential reliance means errors in Type1 retrieval can propagate; complexity of maintaining multiple representations; no performance metrics reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Dual-process mapping: Type1 ~ System1 (Conceptual Spaces similarity), Type2 ~ System2 (description-logic deduction); complementary division of labour.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e439.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e439.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CogQA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cognitive Graph Question Answering (CogQA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid QA framework building a cognitive graph by coordinating an implicit extraction module (BERT) with an explicit reasoning module (graph neural network) to solve multi-hop question answering.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CogQA (implicit+explicit modules)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CogQA coordinates two modules: an implicit extraction module (associable with System1) implemented using BERT to extract candidate facts, and an explicit reasoning module (associable with System2) implemented with a graph neural network to perform structured multi-hop reasoning over a constructed cognitive graph.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Explicit reasoning over a cognitive graph using a Graph Neural Network (GNN) that encodes relations and performs structured inference; graph structures act as symbolic-like relational representations.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Implicit extraction implemented with BERT (Transformer-based neural language model) performing sub-symbolic evidence extraction and association.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular coordination: BERT-based extraction populates/augments the cognitive graph; a GNN performs explicit multi-hop reasoning over that graph. The modules are coordinated to build and reason over the graph (pipeline-like integration).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Leverages both powerful contextual representation and extraction (BERT) and structured relational multi-hop reasoning (GNN), enabling better performance on web-scale multi-hop QA than purely extractive or purely symbolic systems (as described qualitatively).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Multi-hop question answering over web-scale documents (reading comprehension, QA).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Designed for multi-hop reasoning that requires bridging implicit extraction with explicit relational reasoning; expected improved robustness to multi-hop chains versus purely implicit models, but no numerical OOD claims given here.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Graph-based explicit reasoning offers some interpretability for the multi-hop inference chain; implicit extractor (BERT) remains less transparent.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>No numeric evaluation reported in this paper; potential brittleness if implicit extraction misses key facts; complexity in scaling graph construction on web-scale data.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Hybrid implicit-extraction plus explicit relational reasoning where associative neural extraction feeds structured symbolic-like reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e439.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e439.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sigma (reactive+deliberative)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sigma cognitive architecture (reactive vs deliberative layers)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graphical cognitive architecture where a reactive layer provides efficient short-horizon processing (System1-like) and a deliberative layer provides explicit reasoning (System2-like).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Sigma (dual-layer)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Sigma is discussed as an architecture where reactive (fast, automatic) and deliberative (controlled) layers map to automatic vs controlled processing; the reactive layer enables efficient calculations with short processing time, while the deliberative layer performs more complex reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Deliberative layer: explicit symbolic or graph-based representations for higher-level reasoning (as per Sigma's graphical paradigms).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Reactive layer: subsymbolic or numerically efficient mechanisms for fast processing (short time-horizon reactive modules).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Layered modular architecture with mapping between reactive and deliberative layers; reactive provides quick content to deliberative processes and vice versa.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Short-latency reactive responses combined with capacity for deliberative correction/plan synthesis; improved real-time performance while maintaining more structured reasoning capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Theory of Mind realization and general cognitive tasks; no benchmarks provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Layered mapping supports both quick heuristics and deeper deliberation but no quantitative generalization claims are presented.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Deliberative layer supports interpretability; reactive operations are faster but less transparent.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Reactive layer may face uncertainty in complex or long-horizon tasks; paper provides conceptual description without evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Reactive vs deliberative mapping to dual-process theories, realizing a computational separation of timescales and function.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e439.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e439.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LIDA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Learning Intelligent Distribution Agent (LIDA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A systems-level cognitive architecture modeling cognition, emotion and learning, with System1-like decisions based on Perceptual Associative Memory and Episodic Memory (transient and declarative).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LIDA</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>LIDA models cognitive cycles where fast intuitive decisions (System1-like) are driven by Perceptual Associative Memory (PAM) and Episodic Memory, while longer deliberative processes are handled separately; memory subsystems supply content to working memory in a hybrid fashion.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Episodic and declarative memory stores symbolic-like episodic descriptions and semantic content for deliberative processing.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Perceptual Associative Memory (PAM) and transient memory rely on associative/subsymbolic processes for fast decisions and recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular memory and processing cycles where associative and episodic modules feed working memory and influence decision modules; hybrid via staged cognitive cycles.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Fast, intuition-driven decisions with episodic grounding and the ability to escalate to deliberation; supports emotion/imagery-influenced quick decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>General cognitive modeling; no benchmarks reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Designed to handle perceptual variability via associative memory and to support episodic generalization; no quantitative evaluation here.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Memory structures provide traceable bases for decisions, improving interpretability relative to pure subsymbolic models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Conceptual description in this paper; lacks quantitative performance or failure-mode analysis here.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Cognitive-cycle-based hybrid architecture integrating associative memory and episodic/declarative stores to realize System1/System2 functions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e439.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e439.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MECA (Dynamic Subsumption)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MECA cognitive architecture (Dynamic Subsumption Architecture)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cognitive architecture that integrates a plan-based subsystem with a subsumption-based reactive layer using a double-layer subsumption mechanism (Dynamic Subsumption Architecture) for System1 behaviour.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MECA with Dynamic Subsumption</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MECA integrates a plan-based (deliberative) subsystem with a Dynamic Subsumption reactive subsystem (System1), implementing fast reactive behaviours via subsumption while preserving plan-based cognitive control.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Plan-based subsystem (symbolic plan representations and higher-level cognitive control).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Dynamic Subsumption Architecture (reactive, layered behaviors implemented procedurally/subsymbolically).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Two-layer integration: deliberative plan-based system is complemented by a reactive subsumption layer; the architecture coordinates the two via a double-layer subsumption mechanism and toolkit support (Cognitive Subsumption Toolkit).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Sequential enforcement of reactive behaviors combined with the ability to fallback to plan-based corrections; improved robustness in sequential behavior enforcement.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Cognitive sequential behavior control and embedded robotics tasks (urban traffic controller example cited); no numeric benchmarks in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Enables robust sequential behaviours in environments requiring reactive control; generalization properties not quantified here.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Plan-based layer is interpretable; reactive subsumption behaviors can be inspected via subsumption rules, offering some transparency.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Potential conflicts between subsumption priorities and higher-level plans; requires careful arbitration; no empirical metrics reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Combines subsumption (reactive layering) with plan-based deliberation via a double-layer mechanism; emphasizes sequential behavior enforcement and fallback.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e439.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e439.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Umbrico et al. HRI architecture</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dual-process inspired control architecture for Human-Robot Interaction (Umbrico et al. 2022)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A control architecture for HRI mapping System1 to fast sub-symbolic perception/action modules and System2 to deliberative planners, used when facing high uncertainty and short time horizons for System1.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Dual-process HRI control architecture</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The referenced HRI control architecture maps dual-process theory onto robot control: System1 handles perception and immediate reactive behaviors using sub-symbolic machine learning modules, while System2 handles deliberative planning; System1 operates under high uncertainty and short horizons and delegates complex reasoning to System2.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Deliberative planner and symbolic reasoning modules for longer-horizon decisions (System2).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Sub-symbolic machine-learning-based perception and reactive modules (System1) for fast interaction with humans and the environment.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular integration where System1 sub-symbolic modules supply fast responses and perceptions and System2 deliberative modules intervene for longer, more complex decisions; arbitration based on uncertainty and time horizon.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Fast human-aware reactive behaviours combined with deliberative planning when time allows; improved real-time responsiveness in HRI contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Human-robot interaction scenarios requiring rapid responses under uncertainty; no numeric benchmarks presented in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Expected to handle variability in HRI through learned perception modules plus deliberative fallback; no empirical generalization reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Deliberative actions can be explained; reactive ML modules are less transparent.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Reactive modules can produce incorrect actions under unseen conditions and require robust arbitration; no empirical metrics given.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Dual-process theory applied to robot control: division by time-horizon and uncertainty with modular delegation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The DUAL cognitive architecture: A hybrid multi-agent approach. <em>(Rating: 2)</em></li>
                <li>ACT-r: A cognitive architecture for modeling cognition. <em>(Rating: 2)</em></li>
                <li>The CLARION cognitive architecture: Toward a comprehensive theory of the mind. <em>(Rating: 2)</em></li>
                <li>Integrating a cognitive framework for knowledge representation and categorization in diverse cognitive architectures. <em>(Rating: 2)</em></li>
                <li>Cognitive graph for multi-hop reading comprehension at scale. <em>(Rating: 2)</em></li>
                <li>LIDA: A systems-level architecture for cognition, emotion, and learning. <em>(Rating: 2)</em></li>
                <li>A double-layer subsumption mechanism for enforcing sequential behaviors in a cognitive architecture. <em>(Rating: 2)</em></li>
                <li>A cognitive model fleshes out kahneman's fast and slow systems. <em>(Rating: 1)</em></li>
                <li>Shaping cognitive control for HRI through the dual process theory. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-439",
    "paper_id": "paper-270564180",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "GLITTER",
            "name_full": "GoaL-orIenTed TriE stRucture (GLITTER)",
            "brief_description": "A five-layered trie-based solution repository implementing the System1 side of a System1/System2 cognitive architecture: stores goal-oriented successful plans as sequences of tasks keyed by goal, precondition, and quality for fast retrieval and execution.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "GLITTER (trie-based System1/System2 hybrid)",
            "system_description": "GLITTER is a modular hybrid reasoning system where System 2 performs goal-oriented planning using declarative Boolean goal formulas and System 1 provides a fast imperative executor and retriever implemented as a layered trie. The trie stores tuples across five layers (Goal, Preconditions, Quality of Solution, Solution Steps, Final State). System 2 creates and canonicalizes plans/goals and, after a successful execution, System 1 stores the tested solution in GLITTER; on later requests System 1 quickly retrieves candidate solutions meeting goal, precondition and QoS constraints and executes the stored procedural task sequence, escalating to System 2 on failure or unmet quality.",
            "declarative_component": "Goal and precondition representations are declarative Boolean formulas (canonical Sum-of-Products) and task pre/postconditions; System 2 uses goal trees and symbolic goal descriptions (logical formulas, predicate-based representations).",
            "imperative_component": "An imperative procedural execution layer implemented as a trie of recorded sequential tasks; each SolutionStep stores TaskName([params]) and expected PostCondition — i.e., stored procedural plans (rule/sequence execution engine).",
            "integration_method": "Modular, sequential division of labor: System 2 provides canonicalized declarative goals/plans (BFO format) and populates a temporary plan repository; after successful trial System1 stores the procedural plan in the GLITTER trie. At runtime System2 delegates execution request (optionally with QoS) to System1 which retrieves by keys (goal, precondition, QoS) and executes the stored imperative sequence; System1 raises exceptions to System2 on failure. No end-to-end differentiable integration — tight semantic mapping via canonicalization (Boolean Formula Ordering) and key-based retrieval.",
            "emergent_properties": "Very fast retrieval/execution of previously successful, goal-directed procedures (low-latency reactive behaviour); ability to reuse procedural knowledge across logically related goals via canonical goal ordering (subsumption of SOP terms), transparency and explainability of chosen solution path (explicit goal/precondition/QoS/task representation), and emergent 'personality' differences determined by ordering and QoS evaluation policies (different agents may prefer different solutions).",
            "task_or_benchmark": "Not evaluated on external benchmarks; intended for goal-oriented planning/execution and human-robot interaction contexts (planning, plan retrieval, and execution monitoring).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Generalization is procedural and conservative: solutions are reused when the current state satisfies stored preconditions; canonical SOP ordering allows reuse of solutions for broader goals whose SOP contains a stored product term (subsumption). Limited adaptation — GLITTER assumes same initial conditions or light parameter adaptation; no reported out-of-distribution or compositional generalization benchmarks.",
            "interpretability_properties": "High interpretability: layers separate Goals, Preconditions, QoS, Steps and Final State enabling explicit inspection, debugging and explanations for why a plan was selected (transparent string-based representation and explicit final-state checks).",
            "limitations_or_failures": "No empirical evaluation reported; System1 limited to replaying stored procedural sequences with simple QoS metrics (single integer or 'don't care'); limited built-in adaptation to changed environments; the full System1/System2 architecture (other System1 modules and System2 planner) remains work-in-progress; potential memory cost of tries; reliance on exact precondition matching may limit applicability when environments are noisy or dynamics change.",
            "theoretical_framework": "Dual-process (System1/System2) division of labor inspired by Kahneman: System2 performs deliberate, symbolic planning and canonicalization; System1 provides fast reactive retrieval/execution via an information-retrieval-style trie. Uses Boolean Formula Ordering (BFO) as a canonicalization principle to map declarative goals to retrieval keys.",
            "uuid": "e439.0",
            "source_info": {
                "paper_title": "Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "DUAL",
            "name_full": "DUAL cognitive architecture",
            "brief_description": "A hybrid cognitive architecture integrating connectionist and symbolic approaches via interacting micro-agents, each with a symbolic and a connectionist part, producing computations that emerge from their interactions.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "DUAL (Kokinov)",
            "system_description": "DUAL is described as a hybrid multi-agent cognitive architecture in which many micro-agents each possess symbolic and connectionist components; cognition emerges from interactions and spread of activation among agents, providing integrated symbolic and subsymbolic processing.",
            "declarative_component": "Symbolic representations embedded in each micro-agent (symbolic part per agent, rule-like structures or symbolic memory).",
            "imperative_component": "Connectionist/subsymbolic networks inside agents (neural-network-like processing, spread of activation).",
            "integration_method": "Tightly coupled micro-agent architecture where each agent contains both symbolic and connectionist parts and computations emerge from their interaction and message passing (emergent hybrid integration rather than an explicit pipeline).",
            "emergent_properties": "Distributed emergent computations arising from agent interactions; integration of symbolic reasoning and subsymbolic pattern processing enabling flexible cognitive behaviours (perception, memory, decision-making) via emergent dynamics.",
            "task_or_benchmark": "General cognitive modelling (perception, attention, memory, learning, decision-making); no specific benchmark reported in this paper.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Described qualitatively as supporting flexible cognition via emergent interactions; no quantitative generalization claims reported here.",
            "interpretability_properties": "Intermediate: symbolic parts can be inspected but emergent behavior from connectionist interactions may reduce transparency.",
            "limitations_or_failures": "No performance metrics here; potential complexity in analysis due to emergent interactions and difficulty in guaranteeing reliability or exact behavior across runs.",
            "theoretical_framework": "Hybrid micro-agent framework relying on complementary symbolic/subsymbolic representations and emergent computation via interaction.",
            "uuid": "e439.1",
            "source_info": {
                "paper_title": "Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "ACT-R",
            "name_full": "Adaptive Control of Thought — Rational (ACT-R)",
            "brief_description": "A hybrid cognitive architecture combining symbolic production-rule based knowledge with subsymbolic mechanisms for activation and utility, often used to model human cognitive processes.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "ACT-R (hybrid)",
            "system_description": "ACT-R combines declarative memory structures and production rules (symbolic) with subsymbolic activation and learning mechanisms; the paper notes ACT-R does not inherently operate on a dual-process basis but can implement System1-like behaviour via schemas and production rules and uses declarative/procedural knowledge representations.",
            "declarative_component": "Declarative memory represented as symbolic chunks and logical predicates; production-rule (if-then) systems for procedural knowledge.",
            "imperative_component": "Subsymbolic activation dynamics and learning (utility learning, activation decay) and connectionist-like parameterized mechanisms.",
            "integration_method": "Hybrid integration with symbolic rules acting on declarative chunks and subsymbolic parameters guiding selection and learning — modular but tightly coupled within the ACT-R framework.",
            "emergent_properties": "Ability to model human-like timing, errors, and learning through the interaction of symbolic rules and subsymbolic dynamics; quick automatic behaviours can be modelled by learned productions.",
            "task_or_benchmark": "Cognitive task modeling (memory, attention, learning); no specific numeric benchmark in this paper.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Used to model human generalization in cognitive tasks via learned productions and activation spreading; no quantitative claims here.",
            "interpretability_properties": "High interpretability at symbolic level (production rules) with subsymbolic parameters explaining probabilistic behaviour.",
            "limitations_or_failures": "Not inherently dual-process; requires design work to implement explicit System1/System2 separation; potential mismatch when modeling fast associative processes vs. deliberative ones.",
            "theoretical_framework": "Hybrid cognitive architecture combining symbolic production systems with subsymbolic learning and activation — supports mapping of both automatic and controlled processes when explicitly engineered.",
            "uuid": "e439.2",
            "source_info": {
                "paper_title": "Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "CLARION",
            "name_full": "CLARION cognitive architecture",
            "brief_description": "A cognitive architecture that explicitly separates implicit (subsymbolic) and explicit (symbolic) processing, structuring cognition into subsystems each with dual representations.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "CLARION",
            "system_description": "CLARION organizes cognition into multiple subsystems (ACS, NACS, MS, MCS), each with an implicit (subsymbolic distributed representations such as neural networks) and explicit (symbolic) layer, enabling the modeling of both implicit learning and explicit reasoning within a single architecture.",
            "declarative_component": "Explicit symbolic representations and rule-like structures for high-level reasoning.",
            "imperative_component": "Implicit subsymbolic distributed representations (neural-network style) for procedural/associative processes.",
            "integration_method": "Dual-representation per subsystem; implicit and explicit representations interact within and across subsystems (modular coupling between symbolic and subsymbolic levels).",
            "emergent_properties": "Ability to model both implicit learning and explicit reasoning in the same architecture, capturing phenomena like skill learning, habits, and conscious deliberation; interactions produce richer cognitive behaviours than either alone.",
            "task_or_benchmark": "General cognitive modelling (learning, decision-making); no numeric benchmark reported here.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Qualitatively supports both procedural skill generalization via subsymbolic learning and compositional explicit reasoning via symbolic layer; no quantitative evaluation provided here.",
            "interpretability_properties": "Explicit symbolic layer offers interpretability; implicit layer is less transparent.",
            "limitations_or_failures": "Complexity in coordinating implicit/explicit levels; no empirical metrics provided in this paper's discussion.",
            "theoretical_framework": "Dual-representation theory: separating implicit and explicit processes and connecting them within modular subsystems.",
            "uuid": "e439.3",
            "source_info": {
                "paper_title": "Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Dual-PECCS",
            "name_full": "Dual-PECCS hybrid knowledge representation and reasoning system",
            "brief_description": "A hybrid KR&R system integrating Conceptual Spaces (prototype/exemplar similarity-based Type1 processes) with ontological Description Logic-based deductive Type2 processes, executed sequentially to combine fast similarity-based retrieval and symbolic deduction.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Dual-PECCS",
            "system_description": "Dual-PECCS contains a hybrid knowledge base representing the same conceptual entities in multiple forms: Conceptual Spaces for prototype/exemplar retrieval (Type1/System1) and Description Logic ontologies for deductive inference (Type2/System2). Type1 processes perform similarity-based categorization which is then refined by Type2 deductive processing in sequence.",
            "declarative_component": "Ontological representation using Description Logic for symbolic, deductive reasoning (Type2).",
            "imperative_component": "Conceptual Spaces framework representing prototypes/exemplars and similarity metrics implementing fast, associative retrieval (Type1), arguably sub-symbolic or metric-based reasoning.",
            "integration_method": "Sequential pipeline: Type1 (similarity/prototype/exemplar retrieval in Conceptual Spaces) runs first and its outputs are refined by Type2 (deductive inference in Description Logic); multiple representations of same entities enable cross-checking and refinement.",
            "emergent_properties": "Combines fast associative categorization with rigorous deductive refinement, providing quicker initial responses with subsequent symbolic validation/refinement, reducing errors of pure similarity-based classification.",
            "task_or_benchmark": "Categorization and reasoning tasks within cognitive architectures (integrated into ACT-R and CLARION in the cited work); no quantitative benchmarks reported here.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Expected to generalize better than pure symbolic systems on prototype/exemplar tasks due to similarity metrics, and better than pure subsymbolic systems in terms of logical consistency due to subsequent DL inference; no empirical measures provided in this paper.",
            "interpretability_properties": "Symbolic DL component supports explainability of deductive conclusions; Conceptual Spaces provide geometric/metric explanations for prototype-based judgments.",
            "limitations_or_failures": "Sequential reliance means errors in Type1 retrieval can propagate; complexity of maintaining multiple representations; no performance metrics reported here.",
            "theoretical_framework": "Dual-process mapping: Type1 ~ System1 (Conceptual Spaces similarity), Type2 ~ System2 (description-logic deduction); complementary division of labour.",
            "uuid": "e439.4",
            "source_info": {
                "paper_title": "Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "CogQA",
            "name_full": "Cognitive Graph Question Answering (CogQA)",
            "brief_description": "A hybrid QA framework building a cognitive graph by coordinating an implicit extraction module (BERT) with an explicit reasoning module (graph neural network) to solve multi-hop question answering.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "CogQA (implicit+explicit modules)",
            "system_description": "CogQA coordinates two modules: an implicit extraction module (associable with System1) implemented using BERT to extract candidate facts, and an explicit reasoning module (associable with System2) implemented with a graph neural network to perform structured multi-hop reasoning over a constructed cognitive graph.",
            "declarative_component": "Explicit reasoning over a cognitive graph using a Graph Neural Network (GNN) that encodes relations and performs structured inference; graph structures act as symbolic-like relational representations.",
            "imperative_component": "Implicit extraction implemented with BERT (Transformer-based neural language model) performing sub-symbolic evidence extraction and association.",
            "integration_method": "Modular coordination: BERT-based extraction populates/augments the cognitive graph; a GNN performs explicit multi-hop reasoning over that graph. The modules are coordinated to build and reason over the graph (pipeline-like integration).",
            "emergent_properties": "Leverages both powerful contextual representation and extraction (BERT) and structured relational multi-hop reasoning (GNN), enabling better performance on web-scale multi-hop QA than purely extractive or purely symbolic systems (as described qualitatively).",
            "task_or_benchmark": "Multi-hop question answering over web-scale documents (reading comprehension, QA).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Designed for multi-hop reasoning that requires bridging implicit extraction with explicit relational reasoning; expected improved robustness to multi-hop chains versus purely implicit models, but no numerical OOD claims given here.",
            "interpretability_properties": "Graph-based explicit reasoning offers some interpretability for the multi-hop inference chain; implicit extractor (BERT) remains less transparent.",
            "limitations_or_failures": "No numeric evaluation reported in this paper; potential brittleness if implicit extraction misses key facts; complexity in scaling graph construction on web-scale data.",
            "theoretical_framework": "Hybrid implicit-extraction plus explicit relational reasoning where associative neural extraction feeds structured symbolic-like reasoning.",
            "uuid": "e439.5",
            "source_info": {
                "paper_title": "Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Sigma (reactive+deliberative)",
            "name_full": "Sigma cognitive architecture (reactive vs deliberative layers)",
            "brief_description": "A graphical cognitive architecture where a reactive layer provides efficient short-horizon processing (System1-like) and a deliberative layer provides explicit reasoning (System2-like).",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Sigma (dual-layer)",
            "system_description": "Sigma is discussed as an architecture where reactive (fast, automatic) and deliberative (controlled) layers map to automatic vs controlled processing; the reactive layer enables efficient calculations with short processing time, while the deliberative layer performs more complex reasoning.",
            "declarative_component": "Deliberative layer: explicit symbolic or graph-based representations for higher-level reasoning (as per Sigma's graphical paradigms).",
            "imperative_component": "Reactive layer: subsymbolic or numerically efficient mechanisms for fast processing (short time-horizon reactive modules).",
            "integration_method": "Layered modular architecture with mapping between reactive and deliberative layers; reactive provides quick content to deliberative processes and vice versa.",
            "emergent_properties": "Short-latency reactive responses combined with capacity for deliberative correction/plan synthesis; improved real-time performance while maintaining more structured reasoning capabilities.",
            "task_or_benchmark": "Theory of Mind realization and general cognitive tasks; no benchmarks provided here.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Layered mapping supports both quick heuristics and deeper deliberation but no quantitative generalization claims are presented.",
            "interpretability_properties": "Deliberative layer supports interpretability; reactive operations are faster but less transparent.",
            "limitations_or_failures": "Reactive layer may face uncertainty in complex or long-horizon tasks; paper provides conceptual description without evaluation.",
            "theoretical_framework": "Reactive vs deliberative mapping to dual-process theories, realizing a computational separation of timescales and function.",
            "uuid": "e439.6",
            "source_info": {
                "paper_title": "Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "LIDA",
            "name_full": "Learning Intelligent Distribution Agent (LIDA)",
            "brief_description": "A systems-level cognitive architecture modeling cognition, emotion and learning, with System1-like decisions based on Perceptual Associative Memory and Episodic Memory (transient and declarative).",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "LIDA",
            "system_description": "LIDA models cognitive cycles where fast intuitive decisions (System1-like) are driven by Perceptual Associative Memory (PAM) and Episodic Memory, while longer deliberative processes are handled separately; memory subsystems supply content to working memory in a hybrid fashion.",
            "declarative_component": "Episodic and declarative memory stores symbolic-like episodic descriptions and semantic content for deliberative processing.",
            "imperative_component": "Perceptual Associative Memory (PAM) and transient memory rely on associative/subsymbolic processes for fast decisions and recognition.",
            "integration_method": "Modular memory and processing cycles where associative and episodic modules feed working memory and influence decision modules; hybrid via staged cognitive cycles.",
            "emergent_properties": "Fast, intuition-driven decisions with episodic grounding and the ability to escalate to deliberation; supports emotion/imagery-influenced quick decisions.",
            "task_or_benchmark": "General cognitive modeling; no benchmarks reported here.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Designed to handle perceptual variability via associative memory and to support episodic generalization; no quantitative evaluation here.",
            "interpretability_properties": "Memory structures provide traceable bases for decisions, improving interpretability relative to pure subsymbolic models.",
            "limitations_or_failures": "Conceptual description in this paper; lacks quantitative performance or failure-mode analysis here.",
            "theoretical_framework": "Cognitive-cycle-based hybrid architecture integrating associative memory and episodic/declarative stores to realize System1/System2 functions.",
            "uuid": "e439.7",
            "source_info": {
                "paper_title": "Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "MECA (Dynamic Subsumption)",
            "name_full": "MECA cognitive architecture (Dynamic Subsumption Architecture)",
            "brief_description": "A cognitive architecture that integrates a plan-based subsystem with a subsumption-based reactive layer using a double-layer subsumption mechanism (Dynamic Subsumption Architecture) for System1 behaviour.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "MECA with Dynamic Subsumption",
            "system_description": "MECA integrates a plan-based (deliberative) subsystem with a Dynamic Subsumption reactive subsystem (System1), implementing fast reactive behaviours via subsumption while preserving plan-based cognitive control.",
            "declarative_component": "Plan-based subsystem (symbolic plan representations and higher-level cognitive control).",
            "imperative_component": "Dynamic Subsumption Architecture (reactive, layered behaviors implemented procedurally/subsymbolically).",
            "integration_method": "Two-layer integration: deliberative plan-based system is complemented by a reactive subsumption layer; the architecture coordinates the two via a double-layer subsumption mechanism and toolkit support (Cognitive Subsumption Toolkit).",
            "emergent_properties": "Sequential enforcement of reactive behaviors combined with the ability to fallback to plan-based corrections; improved robustness in sequential behavior enforcement.",
            "task_or_benchmark": "Cognitive sequential behavior control and embedded robotics tasks (urban traffic controller example cited); no numeric benchmarks in this paper.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Enables robust sequential behaviours in environments requiring reactive control; generalization properties not quantified here.",
            "interpretability_properties": "Plan-based layer is interpretable; reactive subsumption behaviors can be inspected via subsumption rules, offering some transparency.",
            "limitations_or_failures": "Potential conflicts between subsumption priorities and higher-level plans; requires careful arbitration; no empirical metrics reported here.",
            "theoretical_framework": "Combines subsumption (reactive layering) with plan-based deliberation via a double-layer mechanism; emphasizes sequential behavior enforcement and fallback.",
            "uuid": "e439.8",
            "source_info": {
                "paper_title": "Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Umbrico et al. HRI architecture",
            "name_full": "Dual-process inspired control architecture for Human-Robot Interaction (Umbrico et al. 2022)",
            "brief_description": "A control architecture for HRI mapping System1 to fast sub-symbolic perception/action modules and System2 to deliberative planners, used when facing high uncertainty and short time horizons for System1.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Dual-process HRI control architecture",
            "system_description": "The referenced HRI control architecture maps dual-process theory onto robot control: System1 handles perception and immediate reactive behaviors using sub-symbolic machine learning modules, while System2 handles deliberative planning; System1 operates under high uncertainty and short horizons and delegates complex reasoning to System2.",
            "declarative_component": "Deliberative planner and symbolic reasoning modules for longer-horizon decisions (System2).",
            "imperative_component": "Sub-symbolic machine-learning-based perception and reactive modules (System1) for fast interaction with humans and the environment.",
            "integration_method": "Modular integration where System1 sub-symbolic modules supply fast responses and perceptions and System2 deliberative modules intervene for longer, more complex decisions; arbitration based on uncertainty and time horizon.",
            "emergent_properties": "Fast human-aware reactive behaviours combined with deliberative planning when time allows; improved real-time responsiveness in HRI contexts.",
            "task_or_benchmark": "Human-robot interaction scenarios requiring rapid responses under uncertainty; no numeric benchmarks presented in this paper.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Expected to handle variability in HRI through learned perception modules plus deliberative fallback; no empirical generalization reported here.",
            "interpretability_properties": "Deliberative actions can be explained; reactive ML modules are less transparent.",
            "limitations_or_failures": "Reactive modules can produce incorrect actions under unseen conditions and require robust arbitration; no empirical metrics given.",
            "theoretical_framework": "Dual-process theory applied to robot control: division by time-horizon and uncertainty with modular delegation.",
            "uuid": "e439.9",
            "source_info": {
                "paper_title": "Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture",
                "publication_date_yy_mm": "2024-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The DUAL cognitive architecture: A hybrid multi-agent approach.",
            "rating": 2,
            "sanitized_title": "the_dual_cognitive_architecture_a_hybrid_multiagent_approach"
        },
        {
            "paper_title": "ACT-r: A cognitive architecture for modeling cognition.",
            "rating": 2,
            "sanitized_title": "actr_a_cognitive_architecture_for_modeling_cognition"
        },
        {
            "paper_title": "The CLARION cognitive architecture: Toward a comprehensive theory of the mind.",
            "rating": 2,
            "sanitized_title": "the_clarion_cognitive_architecture_toward_a_comprehensive_theory_of_the_mind"
        },
        {
            "paper_title": "Integrating a cognitive framework for knowledge representation and categorization in diverse cognitive architectures.",
            "rating": 2,
            "sanitized_title": "integrating_a_cognitive_framework_for_knowledge_representation_and_categorization_in_diverse_cognitive_architectures"
        },
        {
            "paper_title": "Cognitive graph for multi-hop reading comprehension at scale.",
            "rating": 2,
            "sanitized_title": "cognitive_graph_for_multihop_reading_comprehension_at_scale"
        },
        {
            "paper_title": "LIDA: A systems-level architecture for cognition, emotion, and learning.",
            "rating": 2,
            "sanitized_title": "lida_a_systemslevel_architecture_for_cognition_emotion_and_learning"
        },
        {
            "paper_title": "A double-layer subsumption mechanism for enforcing sequential behaviors in a cognitive architecture.",
            "rating": 2,
            "sanitized_title": "a_doublelayer_subsumption_mechanism_for_enforcing_sequential_behaviors_in_a_cognitive_architecture"
        },
        {
            "paper_title": "A cognitive model fleshes out kahneman's fast and slow systems.",
            "rating": 1,
            "sanitized_title": "a_cognitive_model_fleshes_out_kahnemans_fast_and_slow_systems"
        },
        {
            "paper_title": "Shaping cognitive control for HRI through the dual process theory.",
            "rating": 1,
            "sanitized_title": "shaping_cognitive_control_for_hri_through_the_dual_process_theory"
        }
    ],
    "cost": 0.0185885,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Cognitive Systems Research
18 June 2024</p>
<p>Massimo Cossentino 
ICAR-CNR
National Research Council of Italy
Via Ugo La Malfa153, 90146PalermoItaly</p>
<p>Giovanni Pilato 
ICAR-CNR
National Research Council of Italy
Via Ugo La Malfa153, 90146PalermoItaly</p>
<p>A Samsonovich 
ICAR-CNR
National Research Council of Italy
Via Ugo La Malfa153, 90146PalermoItaly</p>
<p>Cognitive Systems Research
18 June 202495E6BD111BBD7384C1DC2EAB1566D49C10.1016/j.cogsys.2024.101257System 1/System 2 Cognitive architectures Goal-oriented plan Trie
In the last years, the System 1/System 2 cognitive architecture, proposed by psychologist Daniel Kahneman, raised the interest of many researchers in the field.System 1 is an intuitive, automatic, and fast-thinking system working effortlessly, without conscious effort.System 2 is a deliberate, analytical, and slower-thinking system employing conscious effort and attention.This work proposes an innovative approach that exploits techniques typical of information retrieval (the trie data structure) to efficiently encode the solutions' repository at the border between System 2 and System 1.This repository stores the solutions (successful plans) the agent has already used and can re-enact to achieve the goals.System 2 conceives new plans and delegates System 1 to execute them.If the plan is successful (and so it becomes a solution), System 1 stores that in the repository to quickly retrieve any solution that may help fulfil the goals deliberated by System 2 in the future.</p>
<p>Introduction</p>
<p>Cognitive architectures refer to computational frameworks or models that aim to understand and simulate human cognitive processes, such as perception, memory, attention, reasoning, and decision-making.These architectures attempt to capture the complex interactions and mechanisms underlying human cognition.Several prominent cognitive architectures have been developed over the years.As an example, ACT-R (Adaptive Control of Thought-Rational), see Ritter, Tehranchi, and Oury (2019), is a cognitive architecture developed by John R. Anderson et al. that focuses on cognitive processes related to perception, attention, memory, and learning; it encodes knowledge using production rules and aims to explain human performance in various cognitive tasks.SOAR (State, Operator, And Result), Laird (2012), is another cognitive architecture that aims to model human intelligence and problem-solving capabilities; it uses a production system approach and represents knowledge as rules, states, and operators; CLARION, Sun (2015), is a cognitive architecture developed by Ron Sun, it combines neural networks and symbolic processing to model various cognitive processes, including learning, decision-making, and cognitive control.It incorporates both implicit and explicit learning mechanisms.Other popular cognitive architectures are LIDA (Learning Intelligent Distribution Agent), Franklin, Madl, D'mello, and Snaider (2013), and CogPrime, see Goertzel et al. (2013).</p>
<p>✩ We acknowledge the support of the PNRR project FAIR -Future AI Research (PE00000013), Spoke 9 -Green-aware AI, under the NRRP MUR program funded by the NextGenerationEU.</p>
<ul>
<li>Corresponding author.</li>
</ul>
<p>E-mail addresses: massimo.cossentino@icar.cnr.it(M.Cossentino), giovanni.pilato@icar.cnr.it(G.Pilato).</p>
<p>In recent years, a noteworthy approach in cognitive systems research was the System 1/System 2 cognitive architecture, popularized by psychologist Daniel Kahneman in Kahneman (2011Kahneman ( , 2012)).It is a conceptual framework that describes two distinct modes of thinking or decision-making processes that operate within human cognition.In the following, we summarize these systems, labelled System 1 and System 2; they represent different cognitive processes with varying characteristics, which have been described in the already cited (Kahneman, 2011(Kahneman, , 2012)), and also in Conway-Smith and West (2022), Evans and Stanovich (2013), Lieto, Radicioni, and Rho (2015), Stocco, Lebiere, and Anderson (2010) and Strack and Deutsch (2004).</p>
<p>System 1 is an intuitive, automatic, and fast-thinking system.It operates in a straightforward manner, without conscious effort, and is associated with quick and spontaneous judgments.This system relies on heuristics, mental shortcuts, and associative thinking to make rapid decisions based on patterns, prior experiences, and immediate impressions.System 1 is highly efficient, but it can also lead to biases and errors due to its reliance on automatic processes.</p>
<p>System 2 is a deliberate, analytical, and slower-thinking system.It requires conscious effort and attention.System 2 is responsible for rational and logical reasoning, problem-solving, and more controlled decision-making.It involves conscious evaluation, rule-based thinking, and consideration of multiple variables.System 2 thinking is typically https://doi.org/10.1016/j.cogsys.2024.101257Received 9 November 2023; Received in revised form 14 May 2024; Accepted 12 June 2024 more accurate and less prone to biases, but it requires more cognitive resources and effort to operate.</p>
<p>The division between System 1 and System 2 thinking helps explain various cognitive phenomena and decision-making processes.For example, System 1 thinking is often associated with intuitive judgments, quick assessments, and automatic responses to stimuli.It is helpful in situations where immediate reactions or fast-paced decision-making is necessary.On the other hand, System 2 thinking is engaged when faced with complex problems or novel situations or when a task requires sustained attention and cognitive effort.It involves mental effort, concentration, and conscious processing.System 2 thinking is particularly relevant when evaluating evidence, performing mathematical calculations, or engaging in logical reasoning.</p>
<p>The System 1/System 2 framework is, of course, a simplification and abstraction of the complex cognitive processes that take place in the human brain.It provides a valuable way to understand and discuss the different modes of thinking and decision-making, but it does not literally represent specific brain regions or mechanisms.</p>
<p>This paper focuses on an innovative approach that exploits techniques typical of Information Retrieval (IR) to efficiently encode a part of the System 1 cognitive architecture into an agent.More specifically, we deal with the repository storing the solutions the agent has already used and can re-enact to achieve the goals deliberated by the System 2 level.System 1 is, as already said, reactive; it is not bound to a complex reasoning process, which is typical of System 2 instead.System 1's task is to immediately retrieve information for acting quickly without involving any time-consuming reasoning process.According to this perspective, a fast and efficient way to encode information that can be retrieved later is through Information Retrieval techniques.In particular, this work proposes using a trie, see Bodon and Rónyai (2003), and Comer and Sethi (1977), to store the solutions already learned through System 2 for immediate reuse.System 1 stores solutions as a sequence of actions to be sequentially executed.</p>
<p>The approach described in this paper is a first step towards a future work that aims at conceiving and implementing a System 1/System 2 cognitive architecture with the aim of complementing that with a traditional goal-oriented reasoning approach.The proposed repository has been conceived to support a goal-oriented perspective because we aim to somehow emulate the natural goal-oriented behaviour of human beings.</p>
<p>The structure of the trie we propose for this aim is specifically conceived to satisfy some requirements: the solutions are stored for quick retrieval starting from a specific set of inputs: the goal to pursue, the current state of the world, and the expected quality of the result (if applicable).The data structure is a layered trie composed of five layers:</p>
<p>(1) Goals, (2) Preconditions, (3) Quality of Solution, (4) Solution Steps, and (5) Final State.The actual working plan is stored as a successive set of trie nodes in the ''Solution Steps'' layer, where each node reports one task and the result expected from its execution in terms of changes to the state of the world.This is included to let the agent monitor that the process is going in the expected direction, i.e., the satisfaction of the goal.The agent may check the correctness of the outcome by verifying that the current state of the world matches the one reported in the last layer of the trie (the Final State layer).We named our solution GLITTER (GoaL-orIenTed TriE stRucture).</p>
<p>The paper is organized as follows: Section 2 introduces some background for the proposed solution repository approach.Namely, we discuss how System 1 is implemented in several cognitive architectures; we recall the trie structure that is at the basis of GLITTER.We also discuss agent-related concepts like goal, plan, and solution.In Section 3 we discuss the objective of this work which is enabling a mapping between a goal-oriented/model-oriented representation of the solutions conceived by System 2 and their information retrieval-oriented representation in a way that makes them quickly accessible by System 1, providing a description of the GLITTER structure and how it is used.In Section 4 we illustrate the GLITTER repository structure more in detail, focusing on its multi-level features.Finally, in Section 5 we draw some conclusions and summarize our future works.</p>
<p>Background</p>
<p>In this section, we summarize the fundamental concepts involved in the definition of the proposed solution repository structure for System 1. First, in Section 2.1 we will discuss different approaches, from the literature to the implementation of System 1.In Section 2.2 we introduce the concept of trie since GLITTER is essentially an application of the trie data structure to store solutions and make them easily retrievable according to the case at hand.Finally in Section 2.3 we define the concepts of goal, task and solutions that we will use in the proposed data structure.</p>
<p>System 1 in the literature</p>
<p>System 1 can be implemented in cognitive architectures in different manners, according to the specific model considered.However, some standard and common elements can be found in the different implementations of System 1, which is usually realized as an automatic and parallel processing system.This characteristic is due to the need to provide a module capable of processing data quickly and without providing computationally expensive and time-consuming reasoning capabilities.In the following, we give an overview on some approaches that implement System 1 in various cognitive architectures.</p>
<p>A first example is given by DUAL, Kokinov (1994), which is a hybrid cognitive architecture that integrates the connectionist and symbolic approaches.DUAL can simulate a variety of human cognitive abilities, including perception, attention, memory, learning, and decision-making.Computations in DUAL emerge from the interaction of many micro-agents.Each DUAL agent has a symbolic part and a connectionist part.DUAL somehow implements System 1 as a connectionist model that uses neural networks to process information.Typically, the neural networks are trained for specific functions, like facial recognition or object detection.</p>
<p>Another example can be found in ACT-R (Adaptive Control of Thought -Rational), Ritter et al. (2019), which is a hybrid architecture: it combines symbolic and connectionist approaches to cognitive modelling.ACT-R does not intrinsically operate on a dual-process basis; the dual reasoning mechanisms must be designed and implemented within an existing comprehensive framework by exploiting its declarative and procedural knowledge, Lieto et al. (2015).System 1 can be implemented in ACT-R as a schema-based model that can process information automatically as a set of production rules that are triggered by specific stimuli.</p>
<p>CLARION, Sun (2015), is a cognitive framework structured in modules; it includes four subsystems: the Action Centered Subsystem (ACS), Non-Action Centered Subsystem (NACS), Motivational Subsystem (MS), and Meta-Cognitive Subsystem (MCS).The basic assumption of CLAR-ION is the distinction between implicit and explicit processes, which can be related to the differentiation between symbolic and sub-symbolic processing.Consequently, each subsystem has a dual representation structure: implicit and explicit.Implicit knowledge is captured through subsymbolic distributed representations, such as those offered by neural networks.Larue, Poirier, and Nkambou (2012) introduced another interesting approach that implements a cognitive architecture based on the Stanovich's tripartite framework described in Evans and Stanovich (2013) and Stanovich (2009Stanovich ( , 2011)).It includes an Autonomous Mind, corresponding with System 1 in dual system theories, responsible for instinctive behaviours and implicit learning.The Autonomous Mind includes perceptual processes, memory access and retrieval, and preattentive processes that supply content to working memory.It is implemented through a network of agents that interact with each other through the exchange of messages and spread activation in the network.Pynadath, Rosenbloom, Marsella, and Li (2013) present an investigation into methods for realizing the Theory of Mind within Sigma, a graphical cognitive architecture.In Sigma, the distinction between reactive and deliberative layers maps onto the automatic versus controlled processing distinction in human cognition, which is described in the System 1/System 2 approach.The Sigma's reactive layer provides an efficient calculation, resulting in a short processing time.Faghihi, Estey, McCall, and Franklin (2015) introduce specific underlying mechanisms for Kahneman's Systems 1 and 2 within the framework of the LIDA (Learning Intelligent Distribution Agent) model, which is a comprehensive, high-level cognitive architecture.System 1 decisions in LIDA, characterized by intuitive and quick decision-making based on emotions and imagery, are based on Perceptual Associative Memory (PAM) and Episodic Memory.PAM recognizes higher-level features; Episodic memories refer to two forms of memory: transient and declarative.Transient episodic memory involves remembering specific events or experiences, while declarative episodic memory includes autobiographical and semantic memory.Gudwin et al. (2018aGudwin et al. ( , 2018bGudwin et al. ( , 2021) ) present a double-layer subsumption mechanism that integrates a plan-based subsystem with a subsumption architecture in the MECA Cognitive Architecture.System 1 in the MECA Cognitive Architecture is implemented using a Dynamic Subsumption Architecture on top of the Cognitive Subsumption Toolkit (CST), a framework that provides the necessary tools and resources for developing and implementing cognitive architectures.</p>
<p>Ding, Zhou, Chen, Yang, and Tang (2020) illustrate a Cognitive Graph Question Answering (CogQA) framework for multi-hop question answering in web-scale documents.CogQA progressively builds a cognitive graph by coordinating two modules: an ''implicit extraction'' module and an ''explicit reasoning'' module.The former is associable with System 1, and the latter with System 2. System 1 in the CogQA framework has been implemented using BERT, see Devlin, Chang, Lee, and Toutanova (2019), a language model based on the Transformer neural architecture that has achieved significant success in many natural language processing (NLP) tasks, see Vaswani et al. (2017).The CogQA framework also exploits a variant of a graph neural network (GNN) for System 2, see Battaglia et al. (2018).</p>
<p>The design of a control architecture inspired by the Dual Process Theory has also been discussed in the field of Human-Robot Interaction by Umbrico, Cesta, Fracasso, Orlandini, and Cortellessa (2022).System 1 in this control architecture faces high uncertainty and operates on a short time horizon.It is implemented by integrating modules that use sub-symbolic approaches, mainly based on machine learning.These modules are dedicated to perceiving the environment, acquiring input, and physically interacting with different entities in the domain.They support quick reasoning processes to rapidly generate reactive behaviours in response to the observed state of the environment and the actions of human users.</p>
<p>An interesting approach is described in Lieto et al. (2015), which propose the integration of Dual-PECCS, a knowledge representation and reasoning system, into ACT-R and CLARION cognitive architectures.Dual-PECCS incorporates a hybrid knowledge base containing different representations of the same conceptual entities.Type 1 processes, associable with System 1, handle prototype-and exemplar-based retrieval and categorization, while Type 2 processes, associable with System 2, manage deductive inference.These two processes interact in sequence: Type 1 processes are executed at first, and their outcomes are subsequently refined by Type 2 processes.In this system, the standard representational and reasoning functions are attributed to System 1, which is linked to the Conceptual Spaces framework, where reasoning functions are executed as similarity assessments in a metric space.The conventional representational and reasoning functions are delegated to System 2 and they are linked to a typical ontological representation based on Description Logic.</p>
<p>Tries</p>
<p>In information retrieval, a popular data structure is the ''trie'', a short name for ''retrieval tree'' or ''prefix tree'', Bodon and Rónyai (2003), Comer and Sethi (1977) and Fredkin (1960).It is a tree-like data structure commonly used in contexts where there is a need to efficiently store and search for words or sequences of characters.</p>
<p>One of the key advantages of a trie is its ability to provide fast prefix-based searches.Traversing the trie from the root to a specific node enables the retrieval of all words or strings that share a common prefix up to that particular point.This feature makes tries particularly useful for auto-completion features in search engines or word suggestion systems.</p>
<p>In a classical trie, each node represents a single character or a portion of a word.The root node is usually associated with an empty string, and subsequent nodes correspond to characters that are matched during the traverse of the trie.Each node may have multiple child nodes, each one representing a possible next character in the word.A typical implementation involves using linked nodes, where each node contains a character, a boolean flag indicating whether it marks the end of a word and pointers to its child nodes.</p>
<p>Tries offer efficient search and insertion operations, typically with a time complexity of (), where  is the length of the search or insertion string.However, in their basic implementation, they may require more memory than other data structures due to the large number of nodes required to represent the words.</p>
<p>Goals, tasks and plans</p>
<p>From the beginning, we defined a clear requirement for our repository, which is the key idea of the approach illustrated in this paper: the system must be able to store and quickly retrieve goal-oriented solutions.</p>
<p>In the following, we will define and illustrate what we address as a ''goal-oriented solution''.For this, it may help to remind that the need for a goal orientation of the repository comes from our choice of implementing System 2 as a goal-directed decision-maker like, for instance, the Practical Reasoner proposed by Bratman (1981) and Bratman, Israel, and Pollack (1988).</p>
<p>When referring to a goal, we address a desired state of the world the agent desires (and is committed) to achieving.Formally, we will express our goals as Boolean propositions in the form:
⟨𝑔⟩ ∶=⟨𝜙⟩ | ⟨𝑔⟩𝑎𝑛𝑑 … (1) 𝑎𝑛𝑑⟨𝑔⟩ | ⟨𝑔⟩𝑎𝑙𝑡 … 𝑎𝑙𝑡⟨𝑔⟩ ⟨𝜙⟩ ∶=⟨𝑎𝑡𝑜𝑚⟩ | ¬⟨𝜙⟩ | ⟨𝜙⟩ ∧ ⟨𝜙⟩ | (2) | ⟨𝜙⟩ ∨ ⟨𝜙⟩
where  is a logical formula, and atom a predicate.</p>
<p>According to this definition, we will deal with goals like:
𝑆𝑐ℎ𝑒𝑑𝑢𝑙𝑒_𝑀𝑒𝑒𝑡𝑖𝑛𝑔 ∶=𝑅𝑜𝑜𝑚_𝑅𝑒𝑠𝑒𝑟𝑣𝑒𝑑∧ ∧ 𝑃 𝑎𝑟𝑡𝑖𝑐𝑖𝑝𝑎𝑛𝑡𝑠_𝐼𝑛𝑣𝑖𝑡𝑒𝑑
where _ is a predicate, ( in (2), that holds when a room has been reserved for the meeting. _ is another predicate; it holds when all the required participants have been invited to the meeting.Finally, ℎ_ is a goal that is satisfied when the conjunction (represented by the ∧ symbol) of the above-described predicates holds).</p>
<p>A goal may also be defined by referring to other goals, for instance:
𝑀𝑒𝑒𝑡𝑖𝑛𝑔_𝑂𝑟𝑔𝑎𝑛𝑖𝑧𝑒𝑑 ∶=𝑆𝑐ℎ𝑒𝑑𝑢𝑙𝑒_𝑀𝑒𝑒𝑡𝑖𝑛𝑔 𝑎𝑛𝑑 𝑎𝑛𝑑 𝑃 𝑟𝑒𝑝𝑎𝑟𝑒_𝑆𝑙𝑖𝑑𝑒𝑠
where ℎ_ and  _ are goals and their conjunction defines the goal _.</p>
<p>We assume an agent will pursue its goals (the first time it encounters them) by letting System 1 enact that.Once a plan has been successfully tested, the agent will store it in the GLITTER solution repository for easy retrieval (i.e., if it needs to achieve the same goal again, starting from the same initial conditions).Indeed, we have to highlight that there is a specific difference between a 'plan' and a 'solution'.</p>
<p>With the term 'plan' we address a sequence of tasks the System 2 of the agent decided to use to achieve some goals, but that it has never attempted to achieve that goal with exactly that sequence of tasks.This means that the agent is not a-priori sure the plan will be successful, nor it knows the result's quality in advance.</p>
<p>A 'solution' is a sequence of tasks the agent has already executed to achieve the desired goal, and it also has information about the quality results.The assumption is that in the same situation (the same initial state of the world), the agent may re-execute the same list of actions, and they will (likely) bring the same result with the same quality.In other words, a solution is a successful plan.Such a solution is goal-oriented because it is explicitly bound to a specific goal.</p>
<p>A concept that is common to both plans and solutions is task.A 'task' describes an action that should be performed to change the state of the world.A task may represent an atomic action or a sequence of actions (a composite task).</p>
<p>A task is modelled in this way:
Task_name([PRE], [POST], 𝑜𝑝𝑡[INV])
where:</p>
<p>PRE is a precondition formula, usually expressed by predicates combined in a Boolean proposition.Such predicates should be part of the agent's beliefs, and they may regard the agent's perception of the environment or parameters describing the agent's status.POST is a Boolean proposition (similar to the precondition) describing the state of the world that will be achieved by the correct execution of the task.INV is the (optional) specification of some conditions of the state of the world that a correct execution of the tasks leaves unchanged, again expressed as a Boolean proposition.</p>
<p>As already said, an ordered sequence of tasks composes a solution that the agent may reuse to achieve some goal successfully.The hope to achieve the goal using the selected solution depends on previous experience.The number of times the same solution has been reused qualifies it as a possible quality metric for that solution in some, not frequently changing, application domains.</p>
<p>Of course, new, unexpected events may alter the result of the action flow and forbid the achievement of the goal; for this reason, each task includes the specification of the state of the world that has to be expected after its execution.If the plan fails, the agent needs to conceive a new strategy; that is part of System 2's duty, and therefore its description falls out of the scope of this work.</p>
<p>The tackled problem and the proposed solution</p>
<p>This work presents the first step of research aiming to conceive an agent that fully implements the cognitive architecture proposed by Kahneman.This paper deals with the problem of memorizing solutions in System 1 for quick reuse.The remaining part of System 1 and the entire System 2 are still at a work-in-progress stage.</p>
<p>For System 2, we made the strategic decision to adopt a goaloriented approach, also supporting hierarchical planning described in Botvinick and Weinstein (2014) and Dezfouli, Lingawi, and Balleine (2014), and the possibility of dealing with plans where there are missing parts, as discussed in Sutton, Precup, and Singh (1999).Such a decision deeply affects the conception of the System 1 part of the agent since it should be quick and reactive as it is supposed to be, but it should also be able to understand and make a profit of the goal-oriented reasoning performed by its rational counterpart.</p>
<p>This means that the problem faced in this paper essentially consists of enabling a mapping between a goal-oriented/model-oriented representation of the solutions conceived by System 2 and their information retrieval-oriented representation in a way that makes them quickly accessible by System 1.</p>
<p>As already discussed, System 1 refers to a mode of thinking characterized by fast, intuitive, and automatic processes.It operates based on heuristics, quick associations, and patterns, allowing for rapid judgments and responses.On the other hand, System 1 processing is often subconscious and does not involve conscious effort or deliberate analysis.</p>
<p>According to the above statements, we believe that even if System 1 behaviour is an aspect of human cognition, a trie data structure, even if belonging to a different domain and serving different purposes, can be used to computationally emulate the typical heuristics and quick associations of System 1.</p>
<p>To ensure the compatibility of the proposed solution to the System 2 architecture we are developing in parallel, we defined two operating scenarios where the two will collaborate.Such scenarios become requirements for both of them, and the solution proposed in Section 3.1 is conceived to fully support them.In the following, we will introduce these scenarios.</p>
<p>The proposed data structure is conceived to become the backbone of a solution repository that enables better collaboration between System 2 and System 1 when they cooperate in terms of goal achievements.We assume the System 2 agent's reasoner aims to satisfy a set of goals (usually modelled as a goal tree) and can conceive new plans for achieving them using the agent's capabilities.We suppose System 2 asks System 1 to pursue some goal (goal commitment is part of System 2's responsibilities), completing the request with an expected result quality specification.For instance, the System 2 layer of an agent controlling a manufacturing robot may ask its System 1 to perform some construction operation at a specific time or within a specific energy consumption rate.</p>
<p>It is a matter for System 1 to correctly select and reuse one of the previously executed plans (solutions), and it should do that both quickly and efficiently, i.e.: quickly selecting the plan that in the past solved the same problem, or a problem that at present seems identical.</p>
<p>It is worth noting that given a goal G, not all the plans that have been successfully employed in the past to achieve G may be reused.Two different factors may affect that:</p>
<p>• The current state of the world may not fit the pre-conditions for the execution of the tasks composing the plan.• The memorized solutions do not ensure the quality of the result required in the specific execution.</p>
<p>The proposed data structure should, therefore, be the backbone of a solutions repository that can support two different scenarios: (i) a straight insertion procedure of new plans, (ii) a quick retrieval based on the following search keys: goal, expected result quality, and preconditions.</p>
<p>In the next subsection, we will provide an overview of the proposed solution repository that we named GLITTER.</p>
<p>The GLITTER trie structure</p>
<p>GLITTER is specifically conceived for supporting the plans repository of a cognitive agent, operating according to the scenarios that will be detailed in Section 3.2.</p>
<p>In synthesis, we suppose that System 2 makes a request to System 1 that deals with the pursuit of a goal in the current environment conditions, optionally also adopting a plan offering some expected quality.From the point of view of the repository, the state of the world should match the preconditions required by the first task in the plan.It is worth reminding that although we are addressing the concept of ''plan's tasks'' (or steps), such tasks, more properly, belong to a solution since the plan is stored in the repository only if it has already been successfully executed.</p>
<p>The GLITTER repository tackles these requirements by storing the Goal, the Precondition, and (optionally) the Quality of the Solution.These will be the keys used for searching a plan in the repository; the intended output is the solution in the form of a set of steps (tasks) that, once executed, bring about some final state of the world (that is, by itself, to be stored in the repository).</p>
<p>In summary, the repository should store five items: the goal, the precondition, the quality of the plan, the solution steps, and the final state.</p>
<p>GLITTER supports these requirements by introducing a five-layered trie structure.The five layers are goals, preconditions, quality of solution (QoS), solution steps, and final state (see Fig. 1).This is obtained by memorizing, in each edge of the trie, a 5-tuple where each element corresponds to one of the aforementioned items as follows:</p>
<p>[,  ,  , , 𝐹 𝑖𝑛𝑎𝑙𝑆𝑡𝑎𝑡𝑒] where:</p>
<p>• Goal is a portion of the Boolean formula used to formalize the goal as described in Section 2.3.It is worth noting that we assume the formula is ordered in some lexicographic way.More on that will be reported later.• Precondition is a portion of the Boolean formula constraining the execution of the plan reported in the following extension nodes of the same branch.Again, we assume some lexicographic order is used to organize the insertion of new branches and their search.• QualityOfSolution is the figure used to represent the quality of the result assessed by the agent after the (successful) execution of the plan.• SolutionStep is one atomic step of the solution.Indeed we expect to find a set of subsequent extension nodes, one for each task in solution.</p>
<p>• FinalState is a string containing the Boolean proposition that should be verified after successfully executing the solution steps.</p>
<p>Usually, this formula corresponds to the goal definition formula, but other parts (predicates) may be present as well because different solution strategies may lead to different states of the world that are compatible with the requested one (for instance, this happens by adding predicates that are outside the goal specification but are a collateral effect of the executed tasks).</p>
<p>We suppose that only one of the tuple fields is filled in each edge of the trie (see Fig. 1).This somehow resembles the concept of storing just one string or key on each edge of the trie and allows us to talk about a layered trie.With its position in the tuple, the filled element identifies the layer the edge belongs to.For instance, if some word is present in the first element of the tuple, that edge belongs to the Goal layer; if the word is in the second position, that edge belongs to the Precondition layer and so on.</p>
<p>This choice generates interesting properties of the proposed data structure for both the agent owning the repository and the designer debugging/analysing the agent's knowledge; in fact, it offers advantages to the agent searching its repository trie because it is easy to differentiate goal/precondition/. . .edges from each other while maintaining a basic string representation of data instead of a complex record structure.</p>
<p>The layered structure is also an advantage for the designer/analyst who desires to examine the repository stored in the knowledge of a running agent.In fact, it is easy to conceive an inspection/debugging tool proposing different abstraction levels and queries (only goals, preconditions under which plans exist for some goal, and so on).</p>
<p>We also adopt the convention that when successive edges in a branch have strings in the same position in the tuple, such strings are to be merged according to the specific merging method defined in each layer.For instance, in the Solution Steps layer (see Fig. 1), successive tasks are to be considered as elements of a list and are to be executed one after the other (more on that later).</p>
<p>As already said, this repository's structure is conceived to support specific but common usage scenarios.In the following subsection, we will detail such scenarios.</p>
<p>Scenarios</p>
<p>The first scenario concerns the first execution of a new plan.It involves both System 1 and System 2, and usually, this happens after the agent has committed to pursue some goal g; we label this scenario ''First Plan Execution'' and, more specifically, it develops as follows:</p>
<p>Scenario ''First Plan Execution'' 1. System 2 conceives a new plan to pursue goal g.</p>
<p>We assume the agent's System 2 commits to pursuing a new goal g and delegates System 1 to find and execute a plan that could satisfy the goal (Fig. 2).In this first scenario, we will examine the situation when the agent experiences one of the following conditions: (i) this is the first time goal this agent pursues g ; (ii) previously experienced and successful plans (solutions) cannot be used; for instance, because of the lack of the required preconditions or tasks, (iii) all the known solutions have failed.Indeed, there is another specific case: none of the available solutions offer satisfactory results.This situation differs from the previous ones because it involves achieving some nonfunctional requirement (a quality goal/constraint on the plan's outcome) rather than a functional one (the mere achievement of an operational goal).Whether to accept a compromise on the quality or build up a new plan may depend on the agent's nature; dealing with such a situation would require an extended study that falls out of this paper's scope.</p>
<p>When System 1 does not find a suitable plan in the GLITTER solution repository, it asks System 2 to conceive a new one.System 2 writes the new plan in a temporary repository.The unique difference between this repository and the solution repository is the lack of information about the quality of the results obtained by the plan execution.</p>
<p>System 2 delegates System 1 to execute the new plan.</p>
<p>System 2 delegates the execution of the new plan to System 1.This latter retrieves the plan from the temporary repository and, after verifying that the precondition still holds, executes that.</p>
<p>System 1 stores the new plan in the solution repository.</p>
<p>When goal g is finally achieved and the result quality evaluated, System 1 can memorize the plan in the solution repository.This procedure will be described in the next section after introducing the details of the GLITTER data structure.Now we propose the second scenario: the System 1 layer retrieves an existing plan from the repository in order to pursue some goal g.</p>
<p>Scenario ''Solution Retrieval''</p>
<p>System 2 deliberates to pursue some goal g</p>
<p>System 2 performs some deliberation process and decides to pursue goal g.System 2 delegates System 1 to pursue goal g, optionally specifying a minimum result quality (see Fig. 3).</p>
<p>System 1 searches the GLITTER repository for goal g</p>
<p>System 1 accesses the GLITTER repository, searching for goal nodes corresponding to g.It is worth noting that the equivalence between g and the examined goal nodes is evaluated by considering the Boolean formula that describes the desired state of the world.</p>
<p>System 1 selects the solutions with matching preconditions</p>
<p>Generally speaking, the repository may store multiple solutions for the same goal, and one of their possible differences is in the set of preconditions.The agent selects all the solutions whose preconditions are verified by the current state of the world and considers them as candidate solutions.If no plan exists whose preconditions are satisfied by the current state of the world, an exception is raised to System 2, and System 1 aborts its work.</p>
<p>System 1 selects the solution with the highest quality</p>
<p>We expect the highest quality solution to be preferred; anyway, the selected one should always offer a result quality equal to or greater than the one requested by System 2. This evaluation is easily done in the case of a single-parameter description of the quality.In some cases, the specification may involve multiple parameters, but we argue an easy and quick comparison method should always be available since affording a complex multiparameter evaluation is out of the capabilities and duties of System 1.If no plan offers satisfactory quality, an exception is raised to System 2, and System 1 aborts its work.</p>
<p>In the next section, we will discuss in detail the GLITTER trie repository, which is fully compliant with the above-reported scenarios.</p>
<p>The GLITTER layered structure in detail</p>
<p>In the following subsections, we will detail each layer and discuss some specific issues arising from the need to store Boolean formulas in the trie.</p>
<p>The goal layer</p>
<p>As shown in Fig. 1, the upper part of a GLITTER trie comprises edges representing the goals pursued by the plans in the repository.In Fig. 1, we can see three different branches of the trie departing from the root.This means the agent has stored, in the repository, plans addressing only three goals.For simplicity, we are here supposing these goals are defined by simple formulas, each one composed of just one predicate (G1, G2, G3 in Fig. 1).As already said, the position of the predicate in the tuple identifies that as a goal, like in [ G1,,,, ].</p>
<p>There is a need to deal with complex goal formulas that can include several predicates; this generates a few interesting issues.Let us suppose we have the following goals:
𝑔 1 ∶= 𝐶𝐴 ∨ 𝐷𝐵, 𝑔 2 ∶= 𝐵𝐷 ∨ 𝐴𝐶, (3)𝑔 3 ∶= 𝐶𝐴.
where A, B, C, D are Boolean predicates.We can note that all the goals are satisfied by the conjunction of the predicates C and A: the term CA (or equivalently AC) is present in all formulas; it is coincident with goal  3 , and it is one of the disjunction terms in  1 and  2 .</p>
<p>The issue is: should the agent store the plans for these three goals in different branches (because they are different goals), or should they be clustered together (because they are satisfied by the same term CA)?</p>
<p>Indeed, only a subset of the solutions of  1 satisfy also  2 and  3 .The same happens for  2 .This leads us to the need for a more versatile data structure that allows us to smoothly consider all known solutions of  3 as solutions of  1 and  2 as well, without losing the possibility to add specific solutions for these two latter goals.</p>
<p>Moreover, we can also note that the same term that defines  3 is written in a different way in  1 .This does not alter the meaning of the formula, but a string search would report different results for the two goals.</p>
<p>We solved these issues by supposing that the System 2 layer communicates the goal formula to the System 1 layer according to the following Boolean Formula Ordering (BFO) format:</p>
<p>1.The goal formula is expressed in the canonical form SoP (Sum of Products) where with ''product'' we mean a term whose variables are all connected by the conjunction operator.Therefore, the goal is expressed using a formula of this kind:  ∶=  1 ∨ 2 ∨ 3 where  1 ,  2 ,  3 are products in the form   ∶=   ∧   ∧   ∧ … 2. Variables   in each product are ordered according to some specific criterion (for instance, alphabetically).3. Variables in the negated form follow the direct ones in the ordering (this may change according to the chosen ordering criterion).4. Products are ordered according to the same criterion in the disjunction, this means that  2 ∨  1 is to be represented as  1 ∨  2 if  1 is before  2 according to the adopted ordering criterion.</p>
<p>Going back to the definitions introduced in (3), according to the proposed BFO format, and selecting an alphabetical ordering criterion, they should be rewritten as follows:
𝑔 1 ∶= 𝐶𝐴 ∨ 𝐷𝐵 ⟹ 𝑔 ′ 1 ∶= 𝐴𝐶 ∨ 𝐵𝐷 𝑔 2 ∶= 𝐵𝐷 ∨ 𝐴𝐶 ⟹ 𝑔 ′ 2 ∶= 𝐴𝐶 ∨ 𝐵𝐷 𝑔 3 ∶= 𝐶𝐴 ⟹ 𝑔 ′ 3
∶=  where:</p>
<p>• In  1 , the predicates , , ,  in the terms  and  have to be ordered in an alphabetic way; thus the goal becomes  ′ 1 ∶=  ∨ .The positions of the two terms  and  do not need to be swapped since they are already in an alphabetic order ( appears before ).</p>
<p>• In  2 , the predicates , , ,  in the terms ,  are already alphabetically ordered but the two terms in  ∨  have to be swapped ( has to be before ) thus the goal becomes  ′ 2 ∶=  ∨ .This ordering operation (supported by the adoption of a canonical form) enables easy identification of equivalent goals ( ′ 1 ≡  ′ 2 ).Finally, as regards the proposed  3 goal (stored using the  ′ 3 expression), we can remark that it makes sense to suppose that the agent is able to easily retrieve all the plans regarding  ′ 3 while searching for those addressing  ′ 1 since solutions of  ′ 3 are also solutions of  ′ 1 .We will now define an insertion method that supports this feature.</p>
<p>When System 1 has to introduce a new goal, it follows a precise procedure: goals will be stored as a sequence of successive edges, each one reporting one successive product term of the goal formula.</p>
<p>This means that the insertion of goal  ′ 1 in an empty trie, is done by inserting two successive edges, the first one labelled by the tuple [, , , , ], and the second one labelled by [, , , , ] (see Fig. 4).Navigating the (by now unique) branch of the trie from the root downwards, we visit two different goal configurations:  and  ∨ .We can note that the first formula defines  ′ 3 while the second corresponds to  ′ 1 .If the agent also has to introduce the goal  4 =  ∨  ∨ , this can be done by appending the node [, , , , ] to the sequence ∕[, , , , ]∕ [𝐵𝐷, , , , ].</p>
<p>More generally, if we want to insert the goal  =  1 ∨  2 ∨  3 , reminding that we suppose variables in the products are ordered, and   terms are ordered as well, in the simplest case (when the trie is empty), the insert phase consists in appending to the root the three successive edges , , , ].If a subset of the product terms (for instance,  1 ,  2 ) is already in the trie in the form of the sequence ∕[ 1 , , , , ]∕[ 2 , , , , ], the insertion procedure will append a new edge after that sequence with the label [ 3 , , , , ].
[𝑝 1 , , , , ]∕[𝑝 2 , , , , ]∕[𝑝 3 ,
These nodes may be intermediate or solution nodes (or both at the same time).An intermediate node is followed by nodes containing other parts of a goal formula (the string is in the first position of the tuple), while a solution node is followed by nodes reporting preconditions for the solution plan (the precondition string is in the second position of the tuple).A node may also be intermediate and solution at the same time.In fact, in Fig. 5, we can see that node ∕[, , , , ] is followed by both a solution node (labelled [,  1, , , ]) and a node containing a part of a goal formula ([𝐵𝐷, , , , ]).Differently, the node labelled [, , , , ] is an intermediate node while [, , , , ] is a pure solution node.</p>
<p>It is worth considering that the discussed pre-processing work on the goal expressions is not a significant issue for the architecture we are referring to since we suppose this is done by System 2 before inserting the new solution in the GLITTER trie.This kind of job is perfectly coherent with System 2's nature.System 1 will only search the trie for solutions once System 2 has ordered to pursue some goal, and this is a straight operation as would be expected by System 1.</p>
<p>We suppose that if the System 1 layer does not find the searched goal in the trie, it will raise an exception to the System 2 layer, asking it to compute a new solution for the goal at hand.</p>
<p>A complete GLITTER trie is reported in Fig. 1.As we can see, it stores the solutions to four different goals:  1 ∨  2,  3,  4,  4 ∨  5.It is worth noting what happens when an agent finds successive solution nodes in the correct path while searching the trie for a goal.This may be found in Fig. 1 when searching for solutions fulfilling goal  4 ∨  5.In fact, the first step of this path is node  4, which reports a solution.Indeed, this is also a solution for the  4∨ 5 goal, and the agent should consider that and the others that will be found after node  5.For this reason, the order the products are stored in the repository becomes a sensitive issue.It expresses a 'preference' meaning that the agent wills or does not will to solve some goal ( 4 ∨  5) by using a more narrow solution (addressing only  4 and not considering  5).More on this topic will be discussed in Section 4.6.</p>
<p>In the next subsection, we will discuss how the plan's preconditions are reported in the Precondition layer.</p>
<p>The precondition layer</p>
<p>After the Goal layer, we find edges representing the preconditions to be checked before applying the plan stored in this branch of the trie; these compose the Preconditions layer.Preconditions are stored in the second place in the tuple.A precondition is a Boolean proposition that we, again, suppose is written in the SOP (sum of predicates) form.We also assume that the formula is formatted according to the previously presented BOF format.</p>
<p>The precondition collects all the constraints on the state of the world that should hold for the successful execution of the tasks listed in the solution plan.</p>
<p>Although the presence of preconditions is very common, that is not mandatory, and in this case, the entire part of the trie branch belonging to this layer may be omitted, i.e., in navigating the trie branch related to the intended goal, we will not find any edge whose label has information on the second place of the tuple; thus after the goal edges, we will find the quality of plan edges (identified by a string in the third place of the tuple).</p>
<p>The selection procedure of the correct branch, when more than one solution departs from the same goal, is straightforward: the agent visits the first edge of the branch and verifies the compliance of this condition with the current state of the world.If the result is positive, it continues down on the same edge.It may find other portions of the precondition formula (i.e. products written in the second slot of the tuple), or it may enter the Quality of Solution layer (something it is written in the third slot of the tuple).Preconditions formulas are reconstructed exactly as discussed for goal formulas.For instance, looking at the leftmost branch in Fig. 1, we can see that goal  1 ∨  2 has a solution under the precondition  1 and another under  1 ∨  2.</p>
<p>If more than one precondition is verified, the agent can choose among different plans; we assume the decision will consist of adopting the plan offering the best quality.For instance, in Fig. 1, when trying to satisfy the goal  4 ∨  5 (rightmost branch in Fig. 1), the agent will find that different solutions are available according to the truth status of the preconditions  4 ∨  5.If the current state of the world is  4 ∧  5, then all three solutions are viable, and the selection will be done according to the Quality of Solution as discussed in the next subsection.</p>
<p>Quality of solution layer</p>
<p>The Quality of Solution (QoS) layer comprises edges reporting a value in the third place of the tuple.We here decided to adopt the simple strategy of measuring the plan's quality by using an integer value.Of course, a multi-parametric approach could be preferred according to the complexity of the problem at hand and the number of significant variables in the solution.In this case, the QoP layer may include more than one edge for each path, adopting the previously introduced method.We also admit the possibility that, in some cases, the agent does not want to store a quality value for the plan, so a classical ''X'' or another conventional symbol may be used to show the ''don't care'' value of quality for that branch.</p>
<p>If the agent is satisfied with the value of QoS reported in one of the candidate branches, it selects this plan and starts its execution.When multiple candidate solutions exist, we assume the agent will instinctively choose the one with the highest quality.</p>
<p>Reconsidering the branch of the trie in Fig. 1 regarding goal  4∨ 5, we can note that two different solutions marked with different values of QoS start after the precondition  4.This means that the agent, in the past, has tried two different plans for solving that problem; they were both successful, but they reported different quality results.Even the existence of plans with the same QoS makes perfect sense since the repository is conceived to store all the successful experiences of the agent in achieving its goals, whatever their QoS.</p>
<p>Solution steps layer</p>
<p>After the QoS edge(s), we find the edges composing the Solution layer.Here a sequence of edges reports the list of tasks composing the solution.In each of them, the task is reported in the fourth position of the label tuple in the form of a couple composed in this way:</p>
<p>[TaskName([params]), PostCondition]</p>
<p>where:</p>
<p>• TaskName is the task's name, and [params] is the list of parameter values used to execute that in the successful run of that plan.We are here talking about the values of the parameters since the plan aims to replicate an already executed solution.Indeed, some (limited) degree of adaptation may be assumed to be in the capability of the System 1 layer, but the discussion of this issue is well beyond the scope of this paper.• PostCondition is a Boolean proposition representing the state of the world (or a subset of that) after the successful execution of the task.This is supposed to be used by the agent to monitor the correctness of the execution flow at each step.</p>
<p>For the goal  4 ∨  5, in Fig. 1, under the precondition  4, we suppose the agent chooses the solution with QoS = Q5.In this case, the agent will initially execute task T10, verifying that at the end of this task, the state of the world matches the condition PostT10.After that, it will execute task T11 and verify the condition PostT11.If any condition is not verified, we assume the System 1 layer will ask for help from the System 2 layer, likely in the form of a correction plan that could achieve the goal starting from the new, erroneous state.</p>
<p>The final state layer</p>
<p>The Final State layer includes the last node of the branch, which is a Boolean proposition the agent may use to perform a final check on the world's achieved state.This proposition is not necessarily compliant with the SOP canonical form since we store it as a string in a unique node, which is conceived to be easily checked by the agent.</p>
<p>We assume this condition satisfies the goal described in the current branch of the trie, but it may also include some other terms coming from the specific solution and list of tasks.For this reason, we decided to report that the final state's availability in the repository allows System 1 to easily check if the expected state of the world has been achieved (and, therefore, the goal is satisfied).In fact, even if all tasks are successfully executed and their post-conditions positively verified, environment changes may alter the expected flow of states.In this case, the last task post-condition is not a sufficient check of the correct goal achievement.</p>
<p>In Fig. 1, we can see several different final states even for the same goal.For instance, for goal  4 ∨  5 we find three different final states but all of them are a solution to the goal, they are:  5,  5 ∧ ,  4 ∧ .If we suppose the agent has adopted the solution marked by a QoS = Q5 (as proposed in the previous subsection), the formula to be checked would be  5 ∧  , meaning that the state of the world satisfies the goal ( 5 is a solution to the goal  4 ∨  5).Still, in executing the plan the first time, the agent noted that some specific condition ( ) comes after the execution of the tasks as well.In the future, we plan to further investigate these situations since these kinds of collateral effects could contribute to the selection of the plan (for instance, suppose the agent does not want to generate the condition   in the environment).</p>
<p>Ordering criteria and QoS values</p>
<p>Although in Section 4.1 we referred to the adoption of a simple lexicographic criterion for ordering the predicates in the products, and the products in the disjunction, we would like to stress the importance that the ordering algorithm may play in the implementation of some features of the agent.</p>
<p>In fact, the ordering algorithm may become a way to implement different agent personalities.Two agents acting in the same situation, with the same background knowledge, may behave differently if their goals have been ordered differently in the repository.In fact, if goals are stored differently, the retrieving phase would offer different solutions.</p>
<p>Let us consider goals  1 ,  2 ,  3 from Section 4.1 again and let us suppose that the ordering criterion of predicate names for a new agent is: , , , .As a result, the GOF form of the three goals for this agent becomes:
𝑔 1 ∶= 𝐶𝐴 ∨ 𝐷𝐵 ⟹ 𝑔 ′′ 1 ∶= 𝐵𝐷 ∨ 𝐶𝐴 𝑔 2 ∶= 𝐵𝐷 ∨ 𝐴𝐶 ⟹ 𝑔 ′′ 2 ∶= 𝐵𝐷 ∨ 𝐶𝐴 𝑔 3 ∶= 𝐶𝐴 ⟹ 𝑔 ′′ 3 ∶= 𝐶𝐴 The equivalence of goals 𝑔 ′′
1 and  ′′ 2 is, of course, maintained, but the resulting GLITTER trie (at the goal layer) would be the one reported in Fig. 6 that is different from the original one proposed in Fig. 4.This means that this new agent, when attempting to fulfil goal  ′′ 1 will not find the solutions stored for goal  ′′ 3 that are instead attempted by the agent using the lexicographic order reported in Fig. 4.This new configuration of the trie expresses the agent's preference for satisfying the part  of the goal formula (i.e., moving to this specific state of the world) in place of the product  (a different state of the world) the first agent prefers.</p>
<p>The ordering algorithm becomes a way to generate agents that consider different sets of candidate solutions.If we mix that with the fact that these agents may adopt a different evaluation algorithm for the QoS, we obtain that different agents exhibit different personalities although they conceived (or are given) the same solution plans and experienced the same success in attempting them.In some way, we may consider that a different priority order for the predicates (the ordering algorithm) represents a different scale of values for each agent.Some agents regard it as more important to achieve a specific condition, while others regard it as less important.</p>
<p>A similar consideration may be made for the value assigned to the QoS.Each agent evaluates that according to some personal preference and sensibility.For this reason, we already discussed the possibility of dealing with a multi-parametric expression of QoS.</p>
<p>Let us suppose the agent wants to go from place A to place B and three roads are available: (i) the first road is long and it requires a lot of time, (ii) another is comparable in length but it is quicker because it is a highway, it also requires the payment of a toll, (iii) finally another one is panoramic and it takes more time than all the others.It is obvious that different agents may choose different alternatives according to their personality or attitude at the moment of decision: an agent that has the need to move quickly will choose the second solution (the highway), an agent looking for a compromise between time and cost will prefer the first road (long but without toll), finally, an agent preferring to enjoy the ride will select the third alternative (the panoramic road).</p>
<p>Conclusions and future work</p>
<p>In cognitive approaches based on System 1/System 2, one of the basic requirements that System 1 must possess is speed.For this reason, we chose a ''trie'' structure, allowing for easy information storage and quick retrieval.However, we modified the approach by focusing on whether such a structure can store and retrieve goal-oriented solutions.</p>
<p>The reason is straightforward: System 2 is the reflective and rational part and tries to apply problem-solving methodologies as efficiently as possible: once such a solution to the new problem has been found and it is successful, that procedure is stored in System 1 by exploiting a trie data structure.This allows for quick subsequent retrieval of the steps to be sequentially executed: this approach is characterized by immediacy and ''instinct''.If the stored and retrieved plan does not lead to a solution or any inconsistency is found, then System 2 is invoked, which provides a re-planning of the actions to be taken, considering the context into account.</p>
<p>The use of trie is natural and easily explainable.This feature could be seen as a peculiarity in contrast with System1's associative nature, which is typically addressed by sub-symbolic connectionist methods in the literature.However, it meets the need for clarity and explainability that can improve human-robot interaction in terms of trust and transparency of why the robot may make some decisions instead of others.In particular, the structure of GLITTER encompasses the advantages of fast retrieval of plans already devised by System2, tested and verified ''in the field'', and also the clarity due to its multi-layer structure, in which Goals, Preconditions, Quality of Solutions, various ''solution steps'' and final states are distinguished in the end.In addition, specific arrangements for storing information, such as, for example, the ''Boolean Formula Ordering format'' enable the identification of equivalent goals, all in a highly transparent manner.</p>
<p>Thanks to the GLITTER framework, it will be possible to implement human-robot interaction systems that allow robots to explain why certain choices were made by System1 as well.In addition, when choosing between alternative plans, we will add other parameters in the future, not only considering the obtained result quality.In particular, we plan to consider the following: (1) the number of times the plan was successfully executed vs. the number of failures, and (2) the obsolescence of the plan (how long ago it was last executed).</p>
<p>We could also include annotations about specific features of the plan: economic plan (in terms of resources spent), shorter or shorter execution time, difficulty or simplicity of execution, etc.These parameters could allow different agents to make other selections based on emotional/character parameters.For example, an agent with a more ''insecure'' ''personality'' will probably prefer the more straightforward plan.</p>
<p>CRediT authorship contribution statement</p>
<p>Massimo Cossentino: Writing -review &amp; editing, Writing -original draft, Methodology, Investigation, Funding acquisition, Conceptualization.Giovanni Pilato: Writing -review &amp; editing, Writing -original draft, Methodology, Investigation, Conceptualization.</p>
<p>Declaration of competing interest</p>
<p>The authors declare the following financial interests/personal relationships which may be considered as potential competing interests: Massimo Cossentino reports financial support was provided by Ministry of University and Research of Italy.If there are other authors, they declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
<p>Fig. 1 .
1
Fig. 1.The layered structure of the GLITTER trie.</p>
<p>Fig. 2 .
2
Fig. 2. System 1/System 2 collaboration the first time a plan is executed and stored after achieving the goal (Scenario ''First Plan Execution'').</p>
<p>Fig. 3 .
3
Fig. 3. System 1 plan retrieval and execution of an existing solution (Scenario ''Solution Retrieval'').</p>
<p>Fig. 4 .
4
Fig. 4.An example of trie containing the goals  ′ 1 ,  ′ 3 .</p>
<p>Fig. 5 .
5
Fig. 5.An example of trie containing the goals  ′ 1 ,  ′ 3 ,  4 and preconditions for some solution plans.</p>
<p>Fig. 6 .
6
Fig. 6.The same goals of Fig. 4 stored using a different ordering algorithm.</p>
<p>Data availabilityNo data was used for the research described in the article.
P W Battaglia, J B Hamrick, V Bapst, A Sanchez-Gonzalez, V Zambaldi, M Malinowski, arXiv:1806.01261Relational inductive biases, deep learning, and graph networks. 2018arXiv preprint</p>
<p>Trie: an alternative data structure for data mining algorithms. F Bodon, L Rónyai, 10.1016/0895-7177(03)90058-6Mathematical and Computer Modelling. 387-92003</p>
<p>Model-based hierarchical reinforcement learning and human action control. M Botvinick, A Weinstein, 10.1098/rstb.2013.0480Philosophical Transactions of the Royal Society, Series B (Biological Sciences). 3692014. 1655</p>
<p>Intention and means-end reasoning. M Bratman, 10.2307/2184441The Philosophical Review. 9021981</p>
<p>Plans and resource-bounded practical reasoning. M E Bratman, D J Israel, M E Pollack, 10.1111/j.1467-8640.1988.tb00284.xComputational Intelligence. 431988</p>
<p>The complexity of trie index construction. D Comer, R Sethi, 10.1145/322017.322023Journal of the ACM. 2431977</p>
<p>System-1 and system-2 realized within the common model of cognition. B Conway-Smith, R L West, AAAI 2022 fall symposium. 2022</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. J Devlin, M.-W Chang, K Lee, K Toutanova, Proceedings of naacL-HLT. naacL-HLT20191</p>
<p>Habits as action sequences: hierarchical action control and changes in outcome value. A Dezfouli, N W Lingawi, B W Balleine, 10.1098/rstb.2013.0482Philosophical Transactions of the Royal Society, Series B (Biological Sciences). 3692014. 1655</p>
<p>Cognitive graph for multi-hop reading comprehension at scale. M Ding, C Zhou, Q Chen, H Yang, J Tang, 10.18653/v1/p19-1259ACL 2019 -57th annual meeting of the association for computational linguistics, proceedings of the conference. 2020</p>
<p>Dual-process theories of higher cognition: Advancing the debate. J S B Evans, K E Stanovich, 10.1177/1745691612460685Perspectives on Psychological Science. 832013</p>
<p>A cognitive model fleshes out kahneman's fast and slow systems. U Faghihi, C Estey, R Mccall, S Franklin, 10.1016/j.bica.2014.11.014Biologically Inspired Cognitive Architectures. 112015</p>
<p>LIDA: A systems-level architecture for cognition, emotion, and learning. S Franklin, T Madl, S D'mello, J Snaider, 10.1109/tamd.2013.2277589IEEE Transactions on Autonomous Mental Development. 612013</p>
<p>Trie memory. E Fredkin, 10.1145/367390.367400Communications of the ACM. 391960</p>
<p>The cogprime architecture for embodied artificial general intelligence. B Goertzel, S Ke, R Lian, J O'neill, K Sadeghi, D Wang, 10.1109/cihli.2013.66132662013 IEEE symposium on computational intelligence for human-like intelligence. 2013IEEE</p>
<p>An overview of the multipurpose enhanced cognitive architecture (MECA). R Gudwin, A Paraense, S De Paula, E Fróes, W Gibaut, E Castro, 10.1016/j.procs.2018.01.025Procedia Computer Science. 1232018a</p>
<p>An urban traffic controller using the MECA cognitive architecture. R Gudwin, A Paraense, S M De Paula, E Fróes, W Gibaut, E Castro, 10.1016/j.bica.2018.07.015Biologically Inspired Cognitive Architectures. 262018b</p>
<p>A double-layer subsumption mechanism for enforcing sequential behaviors in a cognitive architecture. R Gudwin, E Rohmer, A Paraense, E Fróes, W Gibaut, K Raizer, 10.1109/ssci50451.2021.96601102021 IEEE symposium series on computational intelligence. 2021IEEE</p>
<p>Thinking, fast and slow. D Kahneman, 10.4324/97819124532072011Macmillan</p>
<p>Two systems in the mind. D Kahneman, Bulletin of the American Academy of Arts and Sciences. 6522012</p>
<p>The DUAL cognitive architecture: A hybrid multi-agent approach. B N Kokinov, ECAI. 1994</p>
<p>The Soar cognitive architecture. J E Laird, 10.7551/mitpress/7688.001.00012012MIT Press</p>
<p>A cognitive architecture based on cognitive/neurological dual-system theories. O Larue, P Poirier, R Nkambou, 10.1007/978-3-642-35139-6_27International conference on brain informatics. Springer2012</p>
<p>Integrating a cognitive framework for knowledge representation and categorization in diverse cognitive architectures. A Lieto, D P Radicioni, V Rho, D V Pynadath, P S Rosenbloom, S C Marsella, L Li, 10.1007/978-3-642-39521-5_11Artificial general intelligence: 6th international conference. Beijing, ChinaSpringer2015. 2013. July 31-August 3, 201371proceedings</p>
<p>ACT-r: A cognitive architecture for modeling cognition. F E Ritter, F Tehranchi, J D Oury, 10.1002/wcs.1488Article e1488. 201910</p>
<p>Distinguishing the reflective, algorithmic, and autonomous minds: Is it time for a tri-process theory?. K E Stanovich, 10.1093/acprof:oso/9780199230167.003.0003In two minds: Dual processes and beyond. 2009</p>
<p>Rationality and the reflective mind. K Stanovich, 10.1093/acprof:oso/9780195341140.001.00012011Oxford University PressUSA</p>
<p>Conditional routing of information to the cortex: a model of the basal ganglia's role in cognitive coordination. A Stocco, C Lebiere, J R Anderson, 10.1037/a0019077Psychological Review. 11725412010</p>
<p>Reflective and impulsive determinants of social behavior. F Strack, R Deutsch, 10.1207/s15327957pspr0803_1Personality and Social Psychology Review. 832004</p>
<p>The CLARION cognitive architecture: Toward a comprehensive theory of the mind. The Oxford Handbook of Cognitive Science. R Sun, 10.1093/oxfordhb/9780199842193.013.112015</p>
<p>Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning. R S Sutton, D Precup, S Singh, 10.1016/s0004-3702(99)00052-1Artificial Intelligence. 1121-21999</p>
<p>Shaping cognitive control for HRI through the dual process theory. A Umbrico, A Cesta, F Fracasso, A Orlandini, G Cortellessa, 2022</p>
<p>Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, Advances in Neural Information Processing Systems. 201730</p>            </div>
        </div>

    </div>
</body>
</html>