<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-579 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-579</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-579</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-16.html">extraction-schema-16</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <p><strong>Paper ID:</strong> paper-632a3e8971f6a26cf127a03689c28399d2fce7d8</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/632a3e8971f6a26cf127a03689c28399d2fce7d8" target="_blank">Domain Adaptation Problems: A DASVM Classification Technique and a Circular Validation Strategy</a></p>
                <p><strong>Paper Venue:</strong> IEEE Transactions on Pattern Analysis and Machine Intelligence</p>
                <p><strong>Paper TL;DR:</strong> Experimental results confirmed the effectiveness and the reliability of both the DASVM technique and the proposed circular validation strategy for validating the learning of domain adaptation classifiers when no true labels for the target--domain instances are available.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e579.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e579.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DASVM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Domain Adaptation Support Vector Machine</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An SVM-based algorithm explicitly adapted to domain adaptation problems that initializes a discriminant from labeled source data then iteratively incorporates unlabeled target samples (semilabeled) while progressively erasing source samples and adapting regularization weights to produce a final classifier defined on target data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Domain Adaptation Support Vector Machine (DASVM)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>An iterative SVM training procedure that: (1) initializes an SVM discriminant using labeled source-domain data; (2) at each iteration labels the unlabeled target samples with the current discriminant, selects semilabeled target samples from inside the margin band nearest the margins (parameter ρ), inserts them into the training set, and removes a corresponding number of source samples that lie far from the hyperplane; (3) associates temporally-varying regularization weights—increasing quadratically for semilabeled target samples (C_u^*) according to how long they have retained a label, and decreasing quadratically for source samples C^{(i)}—to control influence; (4) repeats until an empirical convergence criterion is met, and (5) outputs a classifier labeling all target samples. Uses kernel SVM (Gaussian in experiments) and One-Against-All for multiclass.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / algorithmic adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>standard supervised SVMs / machine learning (classification)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>domain adaptation problems across domains (toy 2D datasets, brain–computer interface ECoG, remote sensing multitemporal image classification)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Extended standard SVM training with an iterative semi-labeling and source-erasure loop: (a) semilabeled-target-selection heuristic that selects up to ρ target samples per side from the margin band M(i); (b) dynamic deletion of source samples (Q^{(i)}) based on distance from the current hyperplane; (c) temporally-varying regularization: C_u^* for semilabeled target samples increases quadratically with the number of stable iterations k (from C^* to C^{*max} = τ·C with τ=0.5), while C^{(i)} for source samples decreases quadratically to reduce their influence; (d) label inconsistency handling: if a semilabeled sample's label changes, its label is removed and it is returned to the unlabeled pool; (e) stopping criterion using counts of margin-band samples, inconsistent labels and an empirical β·M threshold. These changes were made to (i) avoid assuming source and target are same-distribution, (ii) progressively move the model to rely on target data, and (iii) stabilize learning given initially noisy target labels.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - produced substantial improvements over baseline supervised SVMs and other domain-adaptation competitors in experiments: Toy rotations (Problem I) DASVM_best achieved 100% OA for rotation angles φ ∈ [10°,50°] (versus SVM_CV decreasing from 99.67% to 32.67%); for φ=50° DASVM improved OA by ≈+67.33 percentage points over SVM_CV in that case. Brain–computer interface (Problem II): DASVM_best OA = 93.00% vs supervised SVM_CV OA = 79.00% (+14%). Remote sensing (Problem III): DASVM_best OA = 94.78% vs SVM_CV 75.73% (+19.05%). In many cases circular validation identified subsets of DASVM models that are both consistent and high-performing (e.g., circular-validated average OA ~91.65% BCI, ~90.88% remote sensing).</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>If the initial discriminant from source data is very poor on target (low initial OA), most target samples are misclassified at iteration 0 and iterative semilabeling cannot recover (algorithm may fail). High divergence between source and target distributions (measured with Jensen-Shannon divergence) degrades adaptation success. Specific challenges included class overlap due to rotation where identical instances map to different labels between domains. Computational cost: iterative algorithm requires roughly one SVM training per iteration (typical ~100 iterations for binary DASVM), so higher compute than single supervised SVM.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Availability of unlabeled target data and labeled source data; some intrinsic correlation between source and target distributions (not uncorrelated) so that structure can be leveraged; use of kernel methods (Gaussian kernel) to model nonlinear boundaries; parameter schedule (temporal regularization) that stabilizes progressive incorporation of target samples.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Requires labeled source-domain data and unlabeled target-domain data; need to choose/ tune SVM kernel (σ) and regularization C that are reasonable for the source problem; user-set parameters ρ (number of semilabeled samples per side), γ (max iterations for raising semilabeled weight), C^*, C^{*max} (and τ), and β for stopping criterion; computational resources to run many SVM trainings iteratively; assumes same label set (classes) across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Moderately generalizable: authors applied it to synthetic toy problems, BCI (ECoG) and remote sensing multitemporal images and report success, but effectiveness depends strongly on correlation between domains; authors note it is conceptually general and can be applied to multiclass via One-Against-All but will fail or underperform when source and target are too different.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps (algorithmic), plus theoretical principles (use of SVM margin theory) and practical heuristics (semilabel selection, schedule for regularization).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation Problems: A DASVM Classification Technique and a Circular Validation Strategy', 'publication_date_yy_mm': '2010-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e579.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e579.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Circular validation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Circular Indirect Accuracy Assessment Strategy</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An empirical validation procedure for domain adaptation without target labels that validates a candidate target solution by applying the same adaptation method in reverse (using predicted target labels as pseudo-training) and checking source accuracy against known source labels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Circular indirect validation strategy</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Given a candidate classifier trained from source→target (and producing predicted labels on target), the method constructs a pseudo-labeled training set for the reverse problem by using target instances with their predicted labels, then re-applies the same domain-adaptation algorithm (keeping same hyperparameters) to learn a reverse target→source classifier that attempts to recover source labels for the original source instances (now unlabeled). The recovered source accuracy (measured against known source labels) is compared to a threshold Λ_th (authors used OA%_th = 85%). If reverse accuracy ≥ threshold, the forward target solution is considered validated (consistent); otherwise it is rejected. Classifiers are then categorized into sets A/B/C/D based on forward/backward consistency, and probabilities like P(A|B) are estimated empirically.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>validation strategy / empirical assessment method</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>standard classifier validation (supervised accuracy assessment / cross-validation)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>domain adaptation validation where target labels are unavailable (applied to DASVM on toy, BCI, and remote sensing datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context (use of reverse-application of algorithm to indirectly validate target results)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Takes standard supervised validation concept (measure accuracy on labeled data) and applies it indirectly by (1) using predicted target labels as a surrogate labeled set to train in reverse; (2) keeping identical learning parameters for forward and reverse runs; (3) defining a binary consistency threshold (Λ_th = 85% OA used in experiments); (4) defining the A/B/C/D state taxonomy and empirical decision rule (accept if reverse OA≥threshold).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful - in experiments it reliably rejected nonconsistent target solutions (P(A|D)=0 empirically), and it identified a nontrivial fraction of genuinely consistent solutions: Problem I toy rotations P(A|B) ranged from ~0.65 down to ~0.15 as rotation increased (for angles where DASVM could find consistent solutions); Problem II (BCI) circular validation recognized ~66% of consistent solutions with average OA ≈91.65% (when forward DASVM had high target accuracy); Problem III (remote sensing) recognized ~49% of consistent solutions with average OA ≈90.88%. Authors note the method may miss some valid solutions (false negatives) because backward adaptation parameters may not be symmetric.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Asymmetry between forward and backward adaptation problems — a valid forward solution may not be recoverable in reverse with same hyperparameters, causing false rejects. Requires that forward solution capture intrinsic source–target structure; if domains are too different or learning parameters poorly chosen, reverse process won't recover source labels. Computational cost increases (each candidate forward model requires a backward adaptation run).</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Availability of labeled source data to evaluate reverse accuracy; intrinsic correlation between domains so that a correct forward mapping is invertible enough to help recover source structure; ability to run many candidate models (authors trained 350 backward DASVMs for analysis).</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Requires access to labeled source data, unlabeled target data, and the ability to re-run the same adaptation algorithm in reverse; requires a user-set accuracy threshold (Λ_th) and sufficient computational resources; assumes same class set across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Authors claim general applicability: strategy can be used with any domain-adaptation learning method, not only DASVM, but practical effectiveness depends on domain symmetry/correlation and hyperparameter choices; may be used across different application domains conditional on those factors.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps and interpretive framework (heuristic decision rules and taxonomy of solution states).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation Problems: A DASVM Classification Technique and a Circular Validation Strategy', 'publication_date_yy_mm': '2010-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e579.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e579.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TSVM / PTSVM principles</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transductive SVM and Progressive Transductive SVM principles</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Existing semi-supervised / transductive SVM approaches that use unlabeled data to modify the decision boundary; the DASVM adapts and extends ideas from TSVM and Progressive TSVM (PTSVM) to the domain adaptation setting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Transductive SVM / Progressive TSVM principles (as adapted)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>TSVMs augment SVM objective by incorporating unlabeled data, typically assigning labels to unlabeled samples and minimizing a nonconvex objective to find label assignments and hyperplane jointly; PTSVM adds a progressive strategy to include unlabeled samples iteratively (e.g., insert most confidently-labeled examples). DASVM borrows the progressive semilabeling/insertion idea and margin-based selection heuristics from PTSVM but changes the semantics to progressively erase source samples and manage dynamic regularization to accommodate different source and target distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / algorithmic inspiration</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>semi-supervised / transductive machine learning (text classification and other ML tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>domain adaptation problems (where labeled and unlabeled data are from different distributions)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context (algorithmic inspiration and adaptation of heuristics)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>DASVM modifies PTSVM heuristics by: (a) using semilabeled target-sample insertion targeted at samples in the margin band rather than assuming same-domain unlabeled data; (b) adding systematic deletion of source samples to move reliance to target; (c) adding temporally-varying regularization to stabilize the influence of semilabeled samples; (d) label-inconsistency handling returning samples to unlabeled pool if label flips.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful as a conceptual transfer: the progressive insertion idea improved DASVM stability and produced high-quality results in experiments where TSVM/PTSVM (as-is) would be inappropriate since they assume same-domain labeled and unlabeled data. The paper reports DASVM outperformed other methods on the tested tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>TSVM/PTSVM objective functions are typically nonconvex and depend on the same-distribution assumption; naive application without modifications to domain adaptation can be ineffective because unlabeled target data distribution differs from the source-labeled distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Underlying conceptual similarity that unlabeled data near the margin are most informative; ability to control influence via regularization schedules enabled adaptation of the progressive idea.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Need to alter original TSVM/PTSVM assumptions and introduce mechanisms to handle distribution shift (source deletion, weight schedules).</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Heuristic principles (progressive inclusion of confident unlabeled samples) are general and can be adapted to other domain-adaptation algorithms, but require careful safeguards to avoid propagating initial label errors when domains differ.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit algorithmic heuristics and theoretical principles (margin-based sampling, semi-supervised labeling strategies).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation Problems: A DASVM Classification Technique and a Circular Validation Strategy', 'publication_date_yy_mm': '2010-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e579.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e579.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ML_retrain / ML_cascade</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Maximum-Likelihood retraining and Maximum-Likelihood Cascade classifiers (remote-sensing adaptation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Parametric maximum-likelihood (ML) domain-adaptation approaches from prior remote-sensing work that update a trained classifier using unlabeled target data via EM/Gaussian mixture modeling and cascade architectures; used as baselines/competitors in the paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Unsupervised retraining of maximum-likelihood classifier and multiple-cascade-classifier system</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>ML_retrain: update parameters of a parametric ML classifier for a new (target) image without labeled samples by modeling observed spaces as finite Gaussian mixtures and using a version of the EM algorithm to infer mixture components on unlabeled target data guided by source parameters. ML_cascade: an ensemble/cascade architecture that integrates parametric ML classifiers and nonparametric RBF-NN classifiers into a multiple-cascade-classifier system for partially unsupervised updating of land-cover maps, using unlabeled target data to adapt cascade stages.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / statistical parameter estimation and classifier adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>statistical pattern recognition / remote sensing (parametric ML classifiers, EM, mixture models)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>multitemporal remote sensing image classification (automatic land-cover map updating)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context (apply general EM/GMM parameter update ideas for temporal image update)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Applied EM with finite Gaussian mixture models tailored to image spectral distributions and temporal correlations; integrated ML classifiers in cascade architectures combined with RBF-NN to improve robustness to distribution shifts in multitemporal imagery.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful in experiments: both ML_retrain and ML_cascade improved over naive supervised SVM trained on source only but were outperformed by DASVM in many cases. Example numeric outcomes (Problem III remote sensing): ML_retrain OA = 92.76% and ML_cascade OA = 91.48% versus DASVM_best OA = 94.78% and SVM_CV = 75.73%. For Problem I (toy rotations) ML methods performed worse than DASVM for large rotations (e.g., at φ=50° ML_retrain OA=65.33%, ML_cascade OA=67.67% vs DASVM_best 100%).</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Parametric assumptions (Gaussian mixtures) can be violated under strong distributional shifts; EM may converge to local optima; cascade architectures add complexity and require careful tuning; these approaches can be less flexible than kernel-based methods for complex nonlinear class boundaries.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Temporal correlation assumptions for multitemporal remote sensing data and availability of many unlabeled pixels facilitated EM-based adaptation; combination with nonparametric components (RBF-NN) helped robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Requires modeling assumptions (finite Gaussian mixtures), sufficient unlabeled target data to fit mixture components, and domain knowledge about likely component correspondence between images. Computational cost for EM and mixture estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Good within remote sensing multitemporal scenarios where parametric assumptions are reasonable; less generalizable to arbitrary domain-adaptation tasks with strong nonlinearities or severe class overlap where nonparametric kernel methods may be better.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps (EM-based parameter updates), statistical modeling principles, and algorithmic system design (cascade classifiers).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation Problems: A DASVM Classification Technique and a Circular Validation Strategy', 'publication_date_yy_mm': '2010-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e579.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e579.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Instance-weighting / NLP adaptation methods</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Instance-weighting and prior/parameter transfer methods from NLP/text classification</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of domain adaptation techniques originating in text classification that reuse source-domain models or reweight instances / parameters (e.g., Dirichlet priors for MAP, Gaussian priors on maxent parameters, instance weighting frameworks) to adapt to target domains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Instance-weighting, parameter priors, and feature-augmentation methods (text-classification domain-adaptation techniques)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Includes approaches such as: constructing Dirichlet priors from source data for MAP estimation on target (Roark & Bacchiani), using source-model parameters as Gaussian priors when training new models on target (Chelba & Acero), Conditional Expectation Maximization (CEM) to exploit unlabeled target data (Daumé & Marcu), and instance-weighting frameworks that remove misleading source samples or upweight target-predicted samples (Jiang & Zhai). Also includes feature-augmentation (Daumé) and structural correspondence learning (Blitzer et al.) that build cross-domain feature correspondences.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational methods / model-regularization and feature-transform techniques</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>natural language processing / text classification</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>general domain adaptation tasks (mentioned as prior art; techniques used mainly in text but discussed as general approaches to transfer learning/domain adaptation)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>mention of cross-context application (methods developed for text classification being applied/adapted conceptually to domain adaptation problems more broadly)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Paper mentions these methods in related work but does not implement them; typical modifications in literature include reweighting of source instances, augmenting features with domain-specific and domain-general copies, and using source-trained parameters as priors for target training.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>not evaluated in this paper (mentioned as related work). In the literature these methods have had success in NLP tasks; their applicability to other modalities depends on feature correspondence and domain similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Methods often assume some representational correspondence or availability of features that can be mapped/correlated across domains; may be less effective when feature spaces or class-conditional distributions change drastically (e.g., remote sensing spectral changes between dates).</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Availability of large unlabeled target data, ability to define feature correspondences or construct priors from source parameters, and similarity between source and target tasks/modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Require feature-level correspondences or reasoning about instance importance; in some approaches need small labeled target set or confident predicted labels.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Some approaches (feature augmentation, instance weighting) are broadly applicable across domains when feature correspondences exist; others are more specific to NLP representations.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>theoretical principles (regularization via priors), explicit procedures (instance reweighting, feature augmentation), and interpretive frameworks (feature correspondence learning).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation Problems: A DASVM Classification Technique and a Circular Validation Strategy', 'publication_date_yy_mm': '2010-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e579.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e579.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CSSD (feature extraction)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Common Spatial Subspace Decomposition (CSSD)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A spatial filtering / signal decomposition technique used to extract components maximally related to a condition (e.g., movement vs. rest) from multichannel electrophysiological recordings; used in this paper to produce features for BCI ECoG data before domain adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Common Spatial Subspace Decomposition (CSSD) for feature extraction</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Preprocessing pipeline for BCI: bandpass filtering to isolate MRD (0–3 Hz) and ERD (8–30 Hz) signals, then apply CSSD to extract signal components specific to one condition and suppress background activity. Authors selected the two most relevant CSSD components from each frequency band and concatenated them to form a four-dimensional feature vector for each event used in DASVM training/adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>experimental signal-processing preprocessing / feature-extraction technique</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>neuroscience / signal processing for electrophysiology (ECoG/EEG analysis)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>input feature preparation for machine-learning domain-adaptation (BCI adaptation across recording sessions)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application within same broader scientific domain (signal-processing technique applied as input preprocessing for ML pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Applied CSSD separately on two band-limited signals (0–3 Hz and 8–30 Hz) and selected two components per band to construct features for ML; merged features across bands before DASVM.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - CSSD-based features enabled the DASVM to improve OA from 79.00% (supervised SVM_CV on source) to 93.00% (DASVM_best) on the BCI target data, indicating the feature extraction provided discriminative inputs suitable for adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>ECoG signals vary across days due to subject state and electrode changes; selection of appropriate components and frequency bands requires domain expertise.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Domain knowledge about MRD and ERD physiological phenomena and CSSD's capability to isolate condition-specific components facilitated robust features for adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Access to multichannel ECoG recordings, filtering hardware/software, and domain expertise to choose frequencies and interpret CSSD results.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>CSSD and similar spatial-filtering methods are broadly applicable across electrophysiological BCI contexts but are specific to multichannel neurophysiological signals.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>instrumental/technical skills (signal filtering and spatial decomposition) and explicit procedural steps.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation Problems: A DASVM Classification Technique and a Circular Validation Strategy', 'publication_date_yy_mm': '2010-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Transductive Inference for Text Classification Using Support Vector Machines <em>(Rating: 2)</em></li>
                <li>Learning with Progressive Transductive Support Vector Machine <em>(Rating: 2)</em></li>
                <li>Unsupervised Retraining of a Maximum-Likelihood Classifier for the Analysis of Multitemporal Remote-Sensing Images <em>(Rating: 2)</em></li>
                <li>A Partially Unsupervised Approach to the Automatic Classification of Multitemporal Remote-Sensing Images <em>(Rating: 2)</em></li>
                <li>Frustratingly Easy Domain Adaptation <em>(Rating: 1)</em></li>
                <li>Domain Adaptation for Statistical Classifiers <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-579",
    "paper_id": "paper-632a3e8971f6a26cf127a03689c28399d2fce7d8",
    "extraction_schema_id": "extraction-schema-16",
    "extracted_data": [
        {
            "name_short": "DASVM",
            "name_full": "Domain Adaptation Support Vector Machine",
            "brief_description": "An SVM-based algorithm explicitly adapted to domain adaptation problems that initializes a discriminant from labeled source data then iteratively incorporates unlabeled target samples (semilabeled) while progressively erasing source samples and adapting regularization weights to produce a final classifier defined on target data.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "Domain Adaptation Support Vector Machine (DASVM)",
            "procedure_description": "An iterative SVM training procedure that: (1) initializes an SVM discriminant using labeled source-domain data; (2) at each iteration labels the unlabeled target samples with the current discriminant, selects semilabeled target samples from inside the margin band nearest the margins (parameter ρ), inserts them into the training set, and removes a corresponding number of source samples that lie far from the hyperplane; (3) associates temporally-varying regularization weights—increasing quadratically for semilabeled target samples (C_u^*) according to how long they have retained a label, and decreasing quadratically for source samples C^{(i)}—to control influence; (4) repeats until an empirical convergence criterion is met, and (5) outputs a classifier labeling all target samples. Uses kernel SVM (Gaussian in experiments) and One-Against-All for multiclass.",
            "procedure_type": "computational method / algorithmic adaptation",
            "source_domain": "standard supervised SVMs / machine learning (classification)",
            "target_domain": "domain adaptation problems across domains (toy 2D datasets, brain–computer interface ECoG, remote sensing multitemporal image classification)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Extended standard SVM training with an iterative semi-labeling and source-erasure loop: (a) semilabeled-target-selection heuristic that selects up to ρ target samples per side from the margin band M(i); (b) dynamic deletion of source samples (Q^{(i)}) based on distance from the current hyperplane; (c) temporally-varying regularization: C_u^* for semilabeled target samples increases quadratically with the number of stable iterations k (from C^* to C^{*max} = τ·C with τ=0.5), while C^{(i)} for source samples decreases quadratically to reduce their influence; (d) label inconsistency handling: if a semilabeled sample's label changes, its label is removed and it is returned to the unlabeled pool; (e) stopping criterion using counts of margin-band samples, inconsistent labels and an empirical β·M threshold. These changes were made to (i) avoid assuming source and target are same-distribution, (ii) progressively move the model to rely on target data, and (iii) stabilize learning given initially noisy target labels.",
            "transfer_success": "successful - produced substantial improvements over baseline supervised SVMs and other domain-adaptation competitors in experiments: Toy rotations (Problem I) DASVM_best achieved 100% OA for rotation angles φ ∈ [10°,50°] (versus SVM_CV decreasing from 99.67% to 32.67%); for φ=50° DASVM improved OA by ≈+67.33 percentage points over SVM_CV in that case. Brain–computer interface (Problem II): DASVM_best OA = 93.00% vs supervised SVM_CV OA = 79.00% (+14%). Remote sensing (Problem III): DASVM_best OA = 94.78% vs SVM_CV 75.73% (+19.05%). In many cases circular validation identified subsets of DASVM models that are both consistent and high-performing (e.g., circular-validated average OA ~91.65% BCI, ~90.88% remote sensing).",
            "barriers_encountered": "If the initial discriminant from source data is very poor on target (low initial OA), most target samples are misclassified at iteration 0 and iterative semilabeling cannot recover (algorithm may fail). High divergence between source and target distributions (measured with Jensen-Shannon divergence) degrades adaptation success. Specific challenges included class overlap due to rotation where identical instances map to different labels between domains. Computational cost: iterative algorithm requires roughly one SVM training per iteration (typical ~100 iterations for binary DASVM), so higher compute than single supervised SVM.",
            "facilitating_factors": "Availability of unlabeled target data and labeled source data; some intrinsic correlation between source and target distributions (not uncorrelated) so that structure can be leveraged; use of kernel methods (Gaussian kernel) to model nonlinear boundaries; parameter schedule (temporal regularization) that stabilizes progressive incorporation of target samples.",
            "contextual_requirements": "Requires labeled source-domain data and unlabeled target-domain data; need to choose/ tune SVM kernel (σ) and regularization C that are reasonable for the source problem; user-set parameters ρ (number of semilabeled samples per side), γ (max iterations for raising semilabeled weight), C^*, C^{*max} (and τ), and β for stopping criterion; computational resources to run many SVM trainings iteratively; assumes same label set (classes) across domains.",
            "generalizability": "Moderately generalizable: authors applied it to synthetic toy problems, BCI (ECoG) and remote sensing multitemporal images and report success, but effectiveness depends strongly on correlation between domains; authors note it is conceptually general and can be applied to multiclass via One-Against-All but will fail or underperform when source and target are too different.",
            "knowledge_type": "explicit procedural steps (algorithmic), plus theoretical principles (use of SVM margin theory) and practical heuristics (semilabel selection, schedule for regularization).",
            "uuid": "e579.0",
            "source_info": {
                "paper_title": "Domain Adaptation Problems: A DASVM Classification Technique and a Circular Validation Strategy",
                "publication_date_yy_mm": "2010-05"
            }
        },
        {
            "name_short": "Circular validation",
            "name_full": "Circular Indirect Accuracy Assessment Strategy",
            "brief_description": "An empirical validation procedure for domain adaptation without target labels that validates a candidate target solution by applying the same adaptation method in reverse (using predicted target labels as pseudo-training) and checking source accuracy against known source labels.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "Circular indirect validation strategy",
            "procedure_description": "Given a candidate classifier trained from source→target (and producing predicted labels on target), the method constructs a pseudo-labeled training set for the reverse problem by using target instances with their predicted labels, then re-applies the same domain-adaptation algorithm (keeping same hyperparameters) to learn a reverse target→source classifier that attempts to recover source labels for the original source instances (now unlabeled). The recovered source accuracy (measured against known source labels) is compared to a threshold Λ_th (authors used OA%_th = 85%). If reverse accuracy ≥ threshold, the forward target solution is considered validated (consistent); otherwise it is rejected. Classifiers are then categorized into sets A/B/C/D based on forward/backward consistency, and probabilities like P(A|B) are estimated empirically.",
            "procedure_type": "validation strategy / empirical assessment method",
            "source_domain": "standard classifier validation (supervised accuracy assessment / cross-validation)",
            "target_domain": "domain adaptation validation where target labels are unavailable (applied to DASVM on toy, BCI, and remote sensing datasets)",
            "transfer_type": "adapted/modified for new context (use of reverse-application of algorithm to indirectly validate target results)",
            "modifications_made": "Takes standard supervised validation concept (measure accuracy on labeled data) and applies it indirectly by (1) using predicted target labels as a surrogate labeled set to train in reverse; (2) keeping identical learning parameters for forward and reverse runs; (3) defining a binary consistency threshold (Λ_th = 85% OA used in experiments); (4) defining the A/B/C/D state taxonomy and empirical decision rule (accept if reverse OA≥threshold).",
            "transfer_success": "partially successful - in experiments it reliably rejected nonconsistent target solutions (P(A|D)=0 empirically), and it identified a nontrivial fraction of genuinely consistent solutions: Problem I toy rotations P(A|B) ranged from ~0.65 down to ~0.15 as rotation increased (for angles where DASVM could find consistent solutions); Problem II (BCI) circular validation recognized ~66% of consistent solutions with average OA ≈91.65% (when forward DASVM had high target accuracy); Problem III (remote sensing) recognized ~49% of consistent solutions with average OA ≈90.88%. Authors note the method may miss some valid solutions (false negatives) because backward adaptation parameters may not be symmetric.",
            "barriers_encountered": "Asymmetry between forward and backward adaptation problems — a valid forward solution may not be recoverable in reverse with same hyperparameters, causing false rejects. Requires that forward solution capture intrinsic source–target structure; if domains are too different or learning parameters poorly chosen, reverse process won't recover source labels. Computational cost increases (each candidate forward model requires a backward adaptation run).",
            "facilitating_factors": "Availability of labeled source data to evaluate reverse accuracy; intrinsic correlation between domains so that a correct forward mapping is invertible enough to help recover source structure; ability to run many candidate models (authors trained 350 backward DASVMs for analysis).",
            "contextual_requirements": "Requires access to labeled source data, unlabeled target data, and the ability to re-run the same adaptation algorithm in reverse; requires a user-set accuracy threshold (Λ_th) and sufficient computational resources; assumes same class set across domains.",
            "generalizability": "Authors claim general applicability: strategy can be used with any domain-adaptation learning method, not only DASVM, but practical effectiveness depends on domain symmetry/correlation and hyperparameter choices; may be used across different application domains conditional on those factors.",
            "knowledge_type": "explicit procedural steps and interpretive framework (heuristic decision rules and taxonomy of solution states).",
            "uuid": "e579.1",
            "source_info": {
                "paper_title": "Domain Adaptation Problems: A DASVM Classification Technique and a Circular Validation Strategy",
                "publication_date_yy_mm": "2010-05"
            }
        },
        {
            "name_short": "TSVM / PTSVM principles",
            "name_full": "Transductive SVM and Progressive Transductive SVM principles",
            "brief_description": "Existing semi-supervised / transductive SVM approaches that use unlabeled data to modify the decision boundary; the DASVM adapts and extends ideas from TSVM and Progressive TSVM (PTSVM) to the domain adaptation setting.",
            "citation_title": "",
            "mention_or_use": "mention",
            "procedure_name": "Transductive SVM / Progressive TSVM principles (as adapted)",
            "procedure_description": "TSVMs augment SVM objective by incorporating unlabeled data, typically assigning labels to unlabeled samples and minimizing a nonconvex objective to find label assignments and hyperplane jointly; PTSVM adds a progressive strategy to include unlabeled samples iteratively (e.g., insert most confidently-labeled examples). DASVM borrows the progressive semilabeling/insertion idea and margin-based selection heuristics from PTSVM but changes the semantics to progressively erase source samples and manage dynamic regularization to accommodate different source and target distributions.",
            "procedure_type": "computational method / algorithmic inspiration",
            "source_domain": "semi-supervised / transductive machine learning (text classification and other ML tasks)",
            "target_domain": "domain adaptation problems (where labeled and unlabeled data are from different distributions)",
            "transfer_type": "adapted/modified for new context (algorithmic inspiration and adaptation of heuristics)",
            "modifications_made": "DASVM modifies PTSVM heuristics by: (a) using semilabeled target-sample insertion targeted at samples in the margin band rather than assuming same-domain unlabeled data; (b) adding systematic deletion of source samples to move reliance to target; (c) adding temporally-varying regularization to stabilize the influence of semilabeled samples; (d) label-inconsistency handling returning samples to unlabeled pool if label flips.",
            "transfer_success": "successful as a conceptual transfer: the progressive insertion idea improved DASVM stability and produced high-quality results in experiments where TSVM/PTSVM (as-is) would be inappropriate since they assume same-domain labeled and unlabeled data. The paper reports DASVM outperformed other methods on the tested tasks.",
            "barriers_encountered": "TSVM/PTSVM objective functions are typically nonconvex and depend on the same-distribution assumption; naive application without modifications to domain adaptation can be ineffective because unlabeled target data distribution differs from the source-labeled distribution.",
            "facilitating_factors": "Underlying conceptual similarity that unlabeled data near the margin are most informative; ability to control influence via regularization schedules enabled adaptation of the progressive idea.",
            "contextual_requirements": "Need to alter original TSVM/PTSVM assumptions and introduce mechanisms to handle distribution shift (source deletion, weight schedules).",
            "generalizability": "Heuristic principles (progressive inclusion of confident unlabeled samples) are general and can be adapted to other domain-adaptation algorithms, but require careful safeguards to avoid propagating initial label errors when domains differ.",
            "knowledge_type": "explicit algorithmic heuristics and theoretical principles (margin-based sampling, semi-supervised labeling strategies).",
            "uuid": "e579.2",
            "source_info": {
                "paper_title": "Domain Adaptation Problems: A DASVM Classification Technique and a Circular Validation Strategy",
                "publication_date_yy_mm": "2010-05"
            }
        },
        {
            "name_short": "ML_retrain / ML_cascade",
            "name_full": "Maximum-Likelihood retraining and Maximum-Likelihood Cascade classifiers (remote-sensing adaptation)",
            "brief_description": "Parametric maximum-likelihood (ML) domain-adaptation approaches from prior remote-sensing work that update a trained classifier using unlabeled target data via EM/Gaussian mixture modeling and cascade architectures; used as baselines/competitors in the paper's experiments.",
            "citation_title": "",
            "mention_or_use": "use",
            "procedure_name": "Unsupervised retraining of maximum-likelihood classifier and multiple-cascade-classifier system",
            "procedure_description": "ML_retrain: update parameters of a parametric ML classifier for a new (target) image without labeled samples by modeling observed spaces as finite Gaussian mixtures and using a version of the EM algorithm to infer mixture components on unlabeled target data guided by source parameters. ML_cascade: an ensemble/cascade architecture that integrates parametric ML classifiers and nonparametric RBF-NN classifiers into a multiple-cascade-classifier system for partially unsupervised updating of land-cover maps, using unlabeled target data to adapt cascade stages.",
            "procedure_type": "computational method / statistical parameter estimation and classifier adaptation",
            "source_domain": "statistical pattern recognition / remote sensing (parametric ML classifiers, EM, mixture models)",
            "target_domain": "multitemporal remote sensing image classification (automatic land-cover map updating)",
            "transfer_type": "adapted/modified for new context (apply general EM/GMM parameter update ideas for temporal image update)",
            "modifications_made": "Applied EM with finite Gaussian mixture models tailored to image spectral distributions and temporal correlations; integrated ML classifiers in cascade architectures combined with RBF-NN to improve robustness to distribution shifts in multitemporal imagery.",
            "transfer_success": "partially successful in experiments: both ML_retrain and ML_cascade improved over naive supervised SVM trained on source only but were outperformed by DASVM in many cases. Example numeric outcomes (Problem III remote sensing): ML_retrain OA = 92.76% and ML_cascade OA = 91.48% versus DASVM_best OA = 94.78% and SVM_CV = 75.73%. For Problem I (toy rotations) ML methods performed worse than DASVM for large rotations (e.g., at φ=50° ML_retrain OA=65.33%, ML_cascade OA=67.67% vs DASVM_best 100%).",
            "barriers_encountered": "Parametric assumptions (Gaussian mixtures) can be violated under strong distributional shifts; EM may converge to local optima; cascade architectures add complexity and require careful tuning; these approaches can be less flexible than kernel-based methods for complex nonlinear class boundaries.",
            "facilitating_factors": "Temporal correlation assumptions for multitemporal remote sensing data and availability of many unlabeled pixels facilitated EM-based adaptation; combination with nonparametric components (RBF-NN) helped robustness.",
            "contextual_requirements": "Requires modeling assumptions (finite Gaussian mixtures), sufficient unlabeled target data to fit mixture components, and domain knowledge about likely component correspondence between images. Computational cost for EM and mixture estimation.",
            "generalizability": "Good within remote sensing multitemporal scenarios where parametric assumptions are reasonable; less generalizable to arbitrary domain-adaptation tasks with strong nonlinearities or severe class overlap where nonparametric kernel methods may be better.",
            "knowledge_type": "explicit procedural steps (EM-based parameter updates), statistical modeling principles, and algorithmic system design (cascade classifiers).",
            "uuid": "e579.3",
            "source_info": {
                "paper_title": "Domain Adaptation Problems: A DASVM Classification Technique and a Circular Validation Strategy",
                "publication_date_yy_mm": "2010-05"
            }
        },
        {
            "name_short": "Instance-weighting / NLP adaptation methods",
            "name_full": "Instance-weighting and prior/parameter transfer methods from NLP/text classification",
            "brief_description": "A set of domain adaptation techniques originating in text classification that reuse source-domain models or reweight instances / parameters (e.g., Dirichlet priors for MAP, Gaussian priors on maxent parameters, instance weighting frameworks) to adapt to target domains.",
            "citation_title": "",
            "mention_or_use": "mention",
            "procedure_name": "Instance-weighting, parameter priors, and feature-augmentation methods (text-classification domain-adaptation techniques)",
            "procedure_description": "Includes approaches such as: constructing Dirichlet priors from source data for MAP estimation on target (Roark & Bacchiani), using source-model parameters as Gaussian priors when training new models on target (Chelba & Acero), Conditional Expectation Maximization (CEM) to exploit unlabeled target data (Daumé & Marcu), and instance-weighting frameworks that remove misleading source samples or upweight target-predicted samples (Jiang & Zhai). Also includes feature-augmentation (Daumé) and structural correspondence learning (Blitzer et al.) that build cross-domain feature correspondences.",
            "procedure_type": "computational methods / model-regularization and feature-transform techniques",
            "source_domain": "natural language processing / text classification",
            "target_domain": "general domain adaptation tasks (mentioned as prior art; techniques used mainly in text but discussed as general approaches to transfer learning/domain adaptation)",
            "transfer_type": "mention of cross-context application (methods developed for text classification being applied/adapted conceptually to domain adaptation problems more broadly)",
            "modifications_made": "Paper mentions these methods in related work but does not implement them; typical modifications in literature include reweighting of source instances, augmenting features with domain-specific and domain-general copies, and using source-trained parameters as priors for target training.",
            "transfer_success": "not evaluated in this paper (mentioned as related work). In the literature these methods have had success in NLP tasks; their applicability to other modalities depends on feature correspondence and domain similarity.",
            "barriers_encountered": "Methods often assume some representational correspondence or availability of features that can be mapped/correlated across domains; may be less effective when feature spaces or class-conditional distributions change drastically (e.g., remote sensing spectral changes between dates).",
            "facilitating_factors": "Availability of large unlabeled target data, ability to define feature correspondences or construct priors from source parameters, and similarity between source and target tasks/modalities.",
            "contextual_requirements": "Require feature-level correspondences or reasoning about instance importance; in some approaches need small labeled target set or confident predicted labels.",
            "generalizability": "Some approaches (feature augmentation, instance weighting) are broadly applicable across domains when feature correspondences exist; others are more specific to NLP representations.",
            "knowledge_type": "theoretical principles (regularization via priors), explicit procedures (instance reweighting, feature augmentation), and interpretive frameworks (feature correspondence learning).",
            "uuid": "e579.4",
            "source_info": {
                "paper_title": "Domain Adaptation Problems: A DASVM Classification Technique and a Circular Validation Strategy",
                "publication_date_yy_mm": "2010-05"
            }
        },
        {
            "name_short": "CSSD (feature extraction)",
            "name_full": "Common Spatial Subspace Decomposition (CSSD)",
            "brief_description": "A spatial filtering / signal decomposition technique used to extract components maximally related to a condition (e.g., movement vs. rest) from multichannel electrophysiological recordings; used in this paper to produce features for BCI ECoG data before domain adaptation.",
            "citation_title": "",
            "mention_or_use": "use",
            "procedure_name": "Common Spatial Subspace Decomposition (CSSD) for feature extraction",
            "procedure_description": "Preprocessing pipeline for BCI: bandpass filtering to isolate MRD (0–3 Hz) and ERD (8–30 Hz) signals, then apply CSSD to extract signal components specific to one condition and suppress background activity. Authors selected the two most relevant CSSD components from each frequency band and concatenated them to form a four-dimensional feature vector for each event used in DASVM training/adaptation.",
            "procedure_type": "experimental signal-processing preprocessing / feature-extraction technique",
            "source_domain": "neuroscience / signal processing for electrophysiology (ECoG/EEG analysis)",
            "target_domain": "input feature preparation for machine-learning domain-adaptation (BCI adaptation across recording sessions)",
            "transfer_type": "direct application within same broader scientific domain (signal-processing technique applied as input preprocessing for ML pipeline)",
            "modifications_made": "Applied CSSD separately on two band-limited signals (0–3 Hz and 8–30 Hz) and selected two components per band to construct features for ML; merged features across bands before DASVM.",
            "transfer_success": "successful - CSSD-based features enabled the DASVM to improve OA from 79.00% (supervised SVM_CV on source) to 93.00% (DASVM_best) on the BCI target data, indicating the feature extraction provided discriminative inputs suitable for adaptation.",
            "barriers_encountered": "ECoG signals vary across days due to subject state and electrode changes; selection of appropriate components and frequency bands requires domain expertise.",
            "facilitating_factors": "Domain knowledge about MRD and ERD physiological phenomena and CSSD's capability to isolate condition-specific components facilitated robust features for adaptation.",
            "contextual_requirements": "Access to multichannel ECoG recordings, filtering hardware/software, and domain expertise to choose frequencies and interpret CSSD results.",
            "generalizability": "CSSD and similar spatial-filtering methods are broadly applicable across electrophysiological BCI contexts but are specific to multichannel neurophysiological signals.",
            "knowledge_type": "instrumental/technical skills (signal filtering and spatial decomposition) and explicit procedural steps.",
            "uuid": "e579.5",
            "source_info": {
                "paper_title": "Domain Adaptation Problems: A DASVM Classification Technique and a Circular Validation Strategy",
                "publication_date_yy_mm": "2010-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Transductive Inference for Text Classification Using Support Vector Machines",
            "rating": 2
        },
        {
            "paper_title": "Learning with Progressive Transductive Support Vector Machine",
            "rating": 2
        },
        {
            "paper_title": "Unsupervised Retraining of a Maximum-Likelihood Classifier for the Analysis of Multitemporal Remote-Sensing Images",
            "rating": 2
        },
        {
            "paper_title": "A Partially Unsupervised Approach to the Automatic Classification of Multitemporal Remote-Sensing Images",
            "rating": 2
        },
        {
            "paper_title": "Frustratingly Easy Domain Adaptation",
            "rating": 1
        },
        {
            "paper_title": "Domain Adaptation for Statistical Classifiers",
            "rating": 1
        }
    ],
    "cost": 0.02205975,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Domain Adaptation Problems: A DASVM Classification Technique and a Circular Validation Strategy</h1>
<p>Lorenzo Bruzzone, Fellow, IEEE, and Mattia Marconcini, Member, IEEE</p>
<h4>Abstract</h4>
<p>This paper addresses pattern classification in the framework of domain adaptation by considering methods that solve problems in which training data are assumed to be available only for a source domain different (even if related) from the target domain of (unlabeled) test data. Two main novel contributions are proposed: 1) a domain adaptation support vector machine (DASVM) technique which extends the formulation of support vector machines (SVMs) to the domain adaptation framework and 2) a circular indirect accuracy assessment strategy for validating the learning of domain adaptation classifiers when no true labels for the target-domain instances are available. Experimental results, obtained on a series of two-dimensional toy problems and on two real data sets related to brain computer interface and remote sensing applications, confirmed the effectiveness and the reliability of both the DASVM technique and the proposed circular validation strategy.</p>
<p>Index Terms-Domain adaptation, transfer learning, semi-supervised learning, support vector machines, accuracy assessment, validation strategy.</p>
<h2>1 INTRODUCTION</h2>
<p>THe complexity of pattern classification problems depends on both the investigated application and the available prior information. Two main families of learning methods can be used for training a classifier: supervised learning methods (when labeled training samples are given) or unsupervised learning methods (when labeled training samples are not available). Let us define a domain D as a distribution $\hat{P}(\mathbf{x}, y), \mathbf{x} \in \mathcal{X}, y \in \Omega$, which governs the classification problem under investigation, where $\mathcal{X}$ and $\Omega$ represent all possible instances and all possible information classes for the considered problem, respectively. In the supervised learning setting, classification algorithms are designed under the hypothesis that the distribution $\hat{P}(\mathbf{x}, y)$ estimated from available labeled training data $\mathcal{T}=\left{\left(\mathbf{x}<em i="i">{i}, y</em>\right)\right}<em i="i">{i}, \mathbf{x}</em>, y)$. Hence, it is possible to obtain high classification accuracies over unseen test data drawn from the same domain. In the unsupervised learning setting, no training data are available. Thus, the problem can be addressed only through clustering methods. However, in many operational applications, there are hybrid situations where, even if prior information is available, it is not sufficient to define a training set representative of the distribution to which the trained model should be applied. These kinds of problems can be addressed according to transfer learning methods.} \in \mathcal{X} \subset \mathcal{X}, y_{i} \in \Omega$ drawn from D well approximates $\hat{P}(\mathbf{x</p>
<ul>
<li>The authors are with the Department of Information Engineering and Computer Science, University of Trento, 38050, Povo, Trento, Italy. E-mail: lorenzo.bruzzone@ing.unitn.it, mattia.marconcini@gmail.com.
Manuscript received 16 Jan. 2008; revised 19 Feb. 2009; accepted 2 Mar. 2009; published online 10 Mar. 2009.
Recommended for acceptance by A. Smola.
For information on obtaining reprints of this article, please send e-mail to: tpan@computer.org, and reference IEEECS Log Number
TPAMI-2008-01-0033.
Digital Object Identifier no. 10.1109/TPAMI.2009.57.</li>
</ul>
<p>Transfer learning refers to the problem of retaining and applying the knowledge available for one or more tasks, domains, or distributions to efficiently develop an effective hypothesis for a new task, domain, or distribution. Instead of involving generalization across problem instances, transfer learning emphasizes the transfer of knowledge across tasks, domains, and distributions that are similar but not the same. When the objective is to transfer knowledge across different tasks, this results in the multitask learning subproblem. Multitask learning methods aim at improving the generalization capability by exploiting the information contained in training data available for the considered tasks (where the set of considered information classes is allowed to vary). In particular, what is learned for each task is used as a bias for other tasks in order to improve the classification performances [1], [2], [3]. In the single-task framework, the default assumption of supervised learning methods is that training and test data are drawn from the same distribution. When the two distributions do not match, two distinct transfer learning subproblems can be defined depending on whether training and test data refer to the same domain or not: 1) learning under sample selection bias and 2) learning under domain adaptation.</p>
<p>In the case of sample selection bias, unlabeled test data are drawn from the same domain D of training data, but the estimated distribution $\hat{P}(\mathbf{x}, y)=\hat{P}(\mathbf{x}) \hat{P}(y \mid \mathbf{x})$ does not correctly model the true underlying distribution that governs D since the number (or the quality) of available training samples is not sufficient for an adequate learning of the classifier. The small amount of labeled data generally leads to a poor estimation $\hat{P}(\mathbf{x})$ of the prior distribution $P(\mathbf{x})$ (i.e., $\hat{P}(\mathbf{x}) \neq P(\mathbf{x})$ ). Moreover, if the few available training data do not represent the general target population and introduce a bias in the estimated class prior distribution (i.e., $\hat{P}(y) \neq P(y)$ ), this may cause a poor estimation of the</p>
<p>TABLE 1
Taxonomy of Learning Types and Problems
( $\bar{X}$ and $\Omega$ Represent All Possible Instances and All Possible Information Classes, Respectively, for the Considered Problem)</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">TYPE OF LEARNING</th>
<th style="text-align: center;">HYPOTHESES</th>
<th style="text-align: center;">OBJECTIVE</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Supervised Learning</td>
<td style="text-align: center;">- Labeled training data $\mathcal{T}=\left{\left(\mathbf{x}<em 1="1">{1}, y</em>\right)\right}<em 1="1">{1}, \mathbf{x}</em>} \in \mathcal{X} \subset \overline{\mathcal{X}}, y_{1} \in \Omega$, are drawn from domain D ; <br> - Unlabeled test data $\mathcal{X}^{\prime}=\left{\mathbf{x<em 1="1">{1}\right}</em>}, \mathcal{X}^{\prime} \subset \overline{\mathcal{X}}$, are drawn from the same domain D of training data; <br> - It is possible to estimate a distribution $\hat{P}(\mathbf{x}, y)$ from $\mathcal{T}=\left{\left(\mathbf{x<em 1="1">{1}, y</em>, y)$ governing D .}\right)\right}_{1}$ that correctly models the true distribution $P(\mathbf{x</td>
<td style="text-align: center;">Infer a good approximation $\hat{P}(\mathbf{x}, y)$ for $P(\mathbf{x}, y)$ by exploiting labeled training data $\mathcal{T}=\left{\left(\mathbf{x}<em 1="1">{1}, y</em>$.}\right)\right}_{1</td>
</tr>
<tr>
<td style="text-align: center;">Transfer Learning</td>
<td style="text-align: center;">Multi-task Learning</td>
<td style="text-align: center;">- Labeled training data $\mathcal{T}=\mathcal{T}<em 2="2">{1} \cup \mathcal{T}</em>} \cup \ldots \cup \mathcal{T<em k="k">{K}$ refer to $K$ related tasks characterizing $K$ different domains, where the generic $k$ th domain $\mathrm{D}</em>}$ is governed by the distribution $P^{k}(\mathbf{x}, y)$, $\mathbf{x} \in \mathcal{X<em k="k">{k} \subset \overline{\mathcal{X}}, y \in \Omega</em>} \subset \Omega$; <br> - For the $k$ th task, it is not possible to estimate a distribution $\hat{P}^{k}(\mathbf{x}, y)$ from $\mathcal{T<em 1="1">{k}=\left{\left(\mathbf{x}</em>\right)\right}}^{\prime}, y_{1}^{\prime<em 1="1">{1}, \mathbf{x}</em>}^{\prime} \in \mathcal{X<em 1="1">{k} \subset \overline{\mathcal{X}}, y</em>$.}^{\prime} \in \Omega_{k}$ that correctly models the true distribution $P^{k}(\mathbf{x}, y)$ governing $\mathrm{D}_{k</td>
<td style="text-align: center;">Infer a good approximation $\hat{P}^{k}(\mathbf{x}, y)$ for $P^{k}(\mathbf{x}, y)$ by jointly exploiting all labeled training data $\mathcal{T}=\mathcal{T}<em 2="2">{1} \cup \mathcal{T}</em>$.} \cup \ldots \cup \mathcal{T}_{K</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Learning Under Sample Selection Bias / Covariate Shift</td>
<td style="text-align: center;">- Labeled training data $\mathcal{T}=\left{\left(\mathbf{x}<em 1="1">{1}, y</em>\right)\right}<em 1="1">{1}, \mathbf{x}</em>} \in \mathcal{X} \subset \overline{\mathcal{X}}, y_{1} \in \Omega$, are drawn from domain D ; <br> - Unlabeled test data $\mathcal{X}^{\prime}=\left{\mathbf{x<em 1="1">{1}\right}</em>}, \mathcal{X}^{\prime} \subset \overline{\mathcal{X}}$, are drawn from the same domain D of training data; <br> - It is not possible to estimate a distribution $\hat{P}(\mathbf{x}, y)$ from $\mathcal{T}=\left{\left(\mathbf{x<em 1="1">{1}, y</em>)$ the problem is referred to as covariate shift.}\right)\right}_{1}$ that correctly models the true distribution $P(\mathbf{x}, y)$ governing D . There are two possible cases: <br> - If $\hat{P}(\mathbf{x}) \neq P(\mathbf{x})$ and $\hat{P}(y \mid \mathbf{x}) \neq P(y \mid \mathbf{x})$ the problem is referred to as sample selection bias; <br> - If $\hat{P}(\mathbf{x}) \neq P(\mathbf{x})$ and $\hat{P}(y \mid \mathbf{x}) \approx P(y \mid \mathbf{x</td>
<td style="text-align: center;">Infer a good approximation $\hat{P}(\mathbf{x}, y)$ for $P(\mathbf{x}, y)$ by jointly exploiting labeled training data $\mathcal{T}=\left{\left(\mathbf{x}<em 1="1">{1}, y</em>\right)\right}<em 1="1">{1}$ and unlabeled test data $\mathcal{X}^{\prime}=\left{\mathbf{x}</em>$.}\right}_{1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Learning Under Domain Adaptation</td>
<td style="text-align: center;">- Labeled training data $\mathcal{T}<em 1="1">{s}=\left{\left(\mathbf{x}</em>\right)\right}}^{\prime}, y_{1}^{\prime<em 1="1">{s}, \mathbf{x}</em>}^{\prime} \in \mathcal{X<em s="s">{s} \subset \overline{\mathcal{X}}, y</em>}^{\prime} \in \Omega$, are drawn from source domain $\mathrm{D<em s="s">{s}$; <br> - Unlabeled test data $\mathcal{X}</em>}=\left{\mathbf{x<em s="s">{1}^{\prime}\right}</em>}, \mathcal{X<em s="s">{s} \subset \overline{\mathcal{X}}$, are drawn from target domain $\mathrm{D}</em>} \neq \mathrm{D<em s="s">{s}$; <br> - Distribution $P^{s}(\mathbf{x}, y)=P^{s}(y \mid \mathbf{x}) \cdot P^{s}(\mathbf{x})$ governing $\mathrm{D}</em>$.}$ is different yet correlated ${ }^{t}$ to distribution $P^{t}(\mathbf{x}, y)=P^{t}(y \mid \mathbf{x}) \cdot P^{s}(\mathbf{x})$ governing $\mathrm{D}_{s</td>
<td style="text-align: center;">Infer a good approximation $\hat{P}^{t}(\mathbf{x}, y)$ for $P^{t}(\mathbf{x}, y)$ by jointly exploiting labeled source-domain training data $\mathcal{T}<em 1="1">{s}=\left{\left(\mathbf{x}</em>\right)\right}}^{\prime}, y_{1}^{\prime<em s="s">{1}$ and unlabeled target-domain test data $\mathcal{X}</em>}=\left{\mathbf{x<em 1="1">{1}^{\prime}\right}</em>$.</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Unsupervised Learning</td>
<td style="text-align: center;">- Only unlabeled data $\mathcal{X}^{\prime}=\left{\mathbf{x}<em 1="1">{1}\right}</em>, y)$ are available.}, \mathcal{X}^{\prime} \subset \overline{\mathcal{X}}$, drawn from domain D governed by distribution $P(\mathbf{x</td>
<td style="text-align: center;">Infer a good approximation $\hat{P}(\mathbf{x}, y)$ for $P(\mathbf{x}, y)$ by exploiting unlabeled data $\mathcal{X}^{\prime}=\left{\mathbf{x}<em 1="1">{1}\right}</em> .$</td>
</tr>
</tbody>
</table>
<p>conditional distribution (i.e., $\hat{P}(y \mid \mathbf{x}) \neq P(y \mid \mathbf{x})$ ). On one hand, if both $\hat{P}(\mathbf{x}) \neq P(\mathbf{x})$ and $\hat{P}(y \mid \mathbf{x}) \neq P(y \mid \mathbf{x})$, the problem is referred to as sample selection bias [4], [5], [6]. On the other hand, the particular case where the true and estimated distributions are assumed to differ only via $\hat{P}(\mathbf{x}) \neq P(\mathbf{x})$, but $\hat{P}(y \mid \mathbf{x}) \approx P(y \mid \mathbf{x})$ is denoted by covariate shift [7], [8].</p>
<p>In the case of domain adaptation, unlabeled test patterns $\mathcal{X}<em 1="1">{t}=\left{\mathbf{x}</em>\right}}^{t<em t="t">{t}, \mathcal{X}</em>} \subset \overline{\mathcal{X}}$, are drawn from a target domain $\mathrm{D<em s="s">{t}$ different from the source domain $\mathrm{D}</em>}$ of training samples $\mathcal{T<em s="s">{s}=\left{\left(\mathbf{x}</em>\right)\right}}^{s}, y_{s}^{s<em s="s">{s}, \mathbf{x}</em>}^{s} \in \mathcal{X<em s="s">{s} \subset \overline{\mathcal{X}}, y</em>)$ to a given extent, domain adaptation is necessary. In the framework of domain adaptation, most of the learning methods are inspired by the idea that, although different, the two
considered domains are correlated. ${ }^{1}$ In particular, it is intuitive to observe that considering the (unlabeled) data of the target domain in the training phase could improve the performances with respect to ignore this information source. ${ }^{2}$ Table 1 summarizes the main characteristics of all the aforementioned learning methods.}^{s} \in \Omega$. This may happen when the available labeled data are out of date, whereas the test data are obtained from fast evolving information sources, or when series of data acquired at different times should be classified, but training samples collected only at one time are available. In this context, let $P^{s}(\mathbf{x}, y)=P^{s}(y \mid \mathbf{x}) \cdot P^{s}(\mathbf{x})$ and $P^{t}(\mathbf{x}, y)=$ $P^{t}(y \mid \mathbf{x}) \cdot P^{t}(\mathbf{x})$ be the true underlying distributions for the source and target domains, respectively. The key idea is to infer a good approximation of $P^{t}(\mathbf{x}, y)$ by exploiting $P^{s}(\mathbf{x}, y)$. If $P^{t}(y \mid \mathbf{x})$ deviates from $P^{s}(y \mid \mathbf{x</p>
<p>In the last few years, transfer learning has been recognized as an important topic in the machine learning and pattern recognition community. However, the attention has been focused mainly on developing methodologies for addressing multitask learning or learning under sample selection bias, whereas less attention has been devoted to</p>
<ol>
<li>The correlation between probability distributions (which allows estimating quantitatively how similar they are) can be empirically evaluated according to some similarity metrics. Hence, two domains are considered correlated if the distance between the corresponding underlying distributions is relatively small according to proper metrics (e.g., [9], [10], [11]).</li>
<li>A simple toy example for domain adaptation problems is described and investigated in Section 6, where source-domain samples are distributed according to two intertwining moons associated with two specific information classes, while target-domain samples are obtained by a free rotation of the original source-domain patterns (i.e., due to rotation, sourceand target-domain data exhibit different distributions: $P^{s}(\mathbf{x}) \neq P^{t}(\mathbf{x})$ and $P^{s}(y \mid \mathbf{x}) \neq P^{t}(y \mid \mathbf{x}))$.</li>
</ol>
<p>domain adaptation problems. This is due to two main motivations: 1) Domain adaptation is a more critical and challenging problem with respect to the other transfer learning subproblems, as training data are assumed to be available only for a source domain different (even if related) from the target domain of the (unlabeled) test samples, and 2) unlike other problems, in practice, there are no strategies to assess the effectiveness of the classification results using standard statistical validation methods as no labeled samples are assumed to be available for the target domain. Considering the complexity of the problem, the lack of procedures for the accuracy assessment is crucial, and at present, seems to be a major limitation for the development of operational domain adaptation learning methods.</p>
<p>In this paper, we address domain adaptation problems by introducing two main novel contributions: 1) a domain adaptation support vector machine (DASVM) technique that extends support vector machines (SVMs) to the domain adaptation framework by exploiting labeled source-domain data and unlabeled target domain data in the training phase of the algorithm and 2) a circular indirect accuracy assessment strategy for the domain adaptation learning that permits to automatically identify reliable solutions for the target-domain classification problem by only exploiting source-domain labeled samples.</p>
<p>The rationale for developing a domain adaptation technique in the framework of SVMs [12], [13] is due to the effectiveness of this classification methodology that attempts to separate samples belonging to different classes by defining maximum margin hyperplanes [14], [15], [16]. The relevance of SVMs is mainly related to their desirable properties that can be summarized as follows:</p>
<ol>
<li>Empirical effectiveness with respect to other traditional classifiers, which results in relatively high classification accuracies and very good generalization capabilities.</li>
<li>Convexity of the objective function used in the learning of the classifier, which results in a unique solution (i.e., the system cannot fall into suboptimal solutions associated with local minima).</li>
<li>Possibility of representing the optimization problem in a dual formulation, where only nonzero Lagrange multipliers are necessary for defining the separation hyperplane (sparsity of the solution).</li>
<li>Capability of addressing classification problems in which no explicit parametric models on the distribution of information classes are assumed (distribu-tion-free classifier).</li>
<li>Possibility of defining nonlinear decision boundaries by implicitly mapping the available observations into a higher dimensional space (i.e., kernel trick).
In the literature, semi-supervised [17], [18], [19] and transductive [20], [21] techniques based on SVMs have been proposed for solving problems under sample selection bias characterized by a large amount of unlabeled data but a reduced number of labeled data. ${ }^{3}$ In particular, they try to recover information from the distribution of unlabeled data</li>
<li>It is worth noting that the objective functions used in the learning of semi-supervised and transductive SVMs are often not convex.
in the input space in order to improve the final classification performances. Nevertheless, these techniques are designed for handling problems where labeled and unlabeled data come from the same domain; thus, they are ineffective on domain adaptation problems, especially when the sourceand target-domain distributions are significantly different. In order to overcome such a drawback, the proposed DASVM technique exploits and extends to domain adaptation problems principles of both transductive SVMs (TSVMs) [20] and progressive transductive SVMs (PTSVMs) [21]. From a general perspective, available labeled data from the source domain $D_{s}$ are used for determining an initial unreliable solution for the target-domain problem; then, unlabeled samples of the target domain $D_{t}$ are exploited for properly adjusting the decision function, while labeled samples of $D_{s}$ are gradually erased. The final classification function is determined only on the basis of semilabeled samples, i.e., originally unlabeled target-domain instances that obtain labels during the learning process.</li>
</ol>
<p>In order to estimate the correctness of the solutions for domain adaptation problems (where no prior information for $D_{f}$ is available), we propose a novel validation strategy developed under the assumption that there exists an intrinsic structure intimately relating $D_{s}$ and $D_{f}$. Under the hypothesis that data in the two domains do not follow uncorrelated distributions, we assume that it is possible to obtain an indirect evaluation of the reliability of the solution to the investigated target problem. The effectiveness of the solution for the target-domain samples can be inferred at the end of a circular procedure by exploiting available labeled samples (i.e., prior information) related to the source domain $D_{s}$.</p>
<p>Experimental results obtained on a series of simulated domain adaptation toy problems and on two real domain adaptation problems defined in the framework of brain computer interface and remote sensing point out the effectiveness and the reliability of both the presented DASVM and the proposed circular validation strategy. It is worth noting that the circular validation strategy is general and can be used with any classification technique applied to domain adaptation problems.</p>
<p>The paper is organized into seven sections. In Section 2, a survey on domain adaptation methods is presented. Section 3 introduces the notation and the assumptions considered in this work. Section 4 presents the proposed DASVM technique. Section 5 describes the circular validation strategy devised for assessing the accuracy of domain adaptation learning algorithms. In Section 6, experimental results are reported and discussed. Finally, Section 7 draws the conclusions of this paper.</p>
<h2>2 Related Work</h2>
<p>In the last few years, the scientific community has devoted a growing interest to the definition of classification techniques for addressing domain adaptation problems. It is worth mentioning that a series of preliminary algorithms has been developed under the assumption that a small amount of target-domain labeled samples are available in the learning phase, thus violating one of the key hypotheses for domain adaptation. However, the role of these studies</p>
<p>has been particularly important for later development of domain adaptation classifiers. In the following, we first briefly review some of the most relevant algorithms developed in the aforementioned framework; then, we focus the attention on current state-of-the-art domain adaptation techniques.</p>
<h3>2.1 Algorithms Assuming Labeled Data Available for the Target Domain</h3>
<p>Most of the techniques presented in this framework have been developed for solving text classification problems. A common approach is to treat source-domain data as prior knowledge and to estimate the target-domain model parameters under such prior distribution. Hwa [22] and Gildea [23] proved that simple techniques based on using adequately selected subsets of source-domain data and parameter pruning can improve the performance on unlabeled target data. In [24], Roark and Bacchiani used source-domain data to construct a Dirichlet prior for MAP estimation of the target domain. In [25], Li and Bilmes proposed an accuracyregularization objective function, which minimizes the empirical risk on target data while maximizing a Bayesian divergence prior determined on the source-domain data distribution. Another approach proposed in [26] by Chelba and Acero is to use the parameters of the maximum entropy model learned from the source domain as the means of a Gaussian prior when training a new model on target data. A different technique based on the Conditional Expectation Maximization (CEM) algorithm developed in the maximum entropy framework has been presented by Daumé and Marcu in [27]. Unlike the aforementioned techniques that do not consider unlabeled samples of the target domain in the learning phase, in [28], a domain adaptation method that can exploit information intrinsic in unlabeled target-domain data has been presented. Jiang and Zhai proposed a general instance weighting framework that implements several adaptation heuristics: removing misleading training samples in the source domain, assigning more weights to labeled target patterns than labeled source patterns, and augmenting training samples with target samples with predicted labels. Other techniques aim at bridging the gap between source and target distributions by changing data representation. As an example, in [29], Florian et al. developed an algorithm that builds a source-domain model and considers its predictions as features for the target domain. In this context, another interesting approach has been recently proposed in [30], where Daumé presented an algorithm based on the idea of transforming domain adaptation problems into standard supervised learning problems (to which any standard algorithm may be applied) by augmenting the size of the feature space of both source and target data.</p>
<h3>2.2 Domain Adaptation Algorithms</h3>
<p>At present, several domain adaptation algorithms rely on defining new features for capturing the correspondence between source and target domains [31], [32]. In this way, the two domains appear to have similar distributions, thus enabling effective domain adaptation. Moreover, as often features are correlated, careful feature subsetting could lead to significant accuracy gains [33]. In [31], Blitzer et al. describe a heuristic method for domain adaptation, which exploits unlabeled data from both domains to induce correspondences among features in the two domains. The
unlabeled target samples are exploited for inferring a good feature representation, which can be regarded as weighting the features. In [32], rather than choosing a common feature representation heuristically, Ben-David et al. try to directly learn a new representation which minimizes a bound on the target generalization error. The bound is determined both using source-domain labeled samples and source and target-domain unlabeled samples, and it is stated in terms of a representation function designed to minimize domain divergence, as well as classification error. The algorithm aims at jointly minimizing a trade-off between source-target similarity and source-domain training error. In [33], Satpal and Sarawagi present a method for addressing domain adaptation problems that selects a subset of features for which the distance (evaluated in terms of a particular distortion metric) between the source and target distributions is minimized, while maximizing the likelihood of labeled training data.</p>
<p>Other interesting approaches for domain adaptation have been presented by Dai et al. [34] and [35]. In [34], they introduced a naive Bayes algorithm for addressing domain adaptation in the context of text categorization, where the EM algorithm is used to find a locally optimal posterior hypothesis under the target distribution. An initial model based on the source training data is first estimated. Such a model is treated as a poor estimation of the target distribution. The EM algorithm is applied to find a local optimal in the hypothesis space, where the estimation should gradually approach the target distribution. In [35], a co-clusteringbased classification algorithm is presented, where co-clustering is used as a bridge to propagate the class structure and knowledge from the source domain to the target domain.</p>
<p>Domain adaptation without labeled target-domain data has also been previously analyzed by the authors in the context of remote sensing image classification [36], [37], [38], [39] for addressing automatic updating of land-cover maps. In [36], a domain adaptation approach is proposed that is able to update the parameters of an already trained parametric maximum-likelihood (ML) classifier on the basis of the distribution of a new image for which no labeled samples are available. In [37], in order to take into account the temporal correlation between images acquired on the same area at different times, the ML-based domain adaptation approach is reformulated in the framework of the Bayesian rule for cascade classification (i.e., the classification process is performed by jointly considering information contained in the source and target domains). The basic idea in both approaches is modeling the observed spaces by a mixture of distributions whose components are estimated by the use of unlabeled target data and according to a proper inference applied to source samples of the reference image. This is achieved by using a specific version of the EM algorithm with finite Gaussian Mixture Models [40]. In [38], domain adaptation approaches based on a multiple-classifier system and a multiple-cascade-classifier system (MCCS) have been defined, respectively. In particular, in [39], the proposed MCCS architecture is composed of an ensemble of classifiers developed in the framework of cascade classification, which is integrated in a multiple-classifier architecture. Both a parametric ML classification approach and a nonparametric radial basis function neural network (RBF-NN) classification technique are used as basic classifiers. In addition, in order to increase both the effectiveness and robustness of the</p>
<p>ensemble, hybrid ML and RBF-NN cascade classifiers are defined.</p>
<h2>3 Problem Formulation and Assumptions</h2>
<p>Given an input space $\tilde{\mathcal{X}}$ and a set of information classes $\Omega$, a classifier is any function $g(\mathbf{x}): \tilde{\mathcal{X}} \rightarrow \Omega$ that maps instances $\mathbf{x} \in \tilde{\mathcal{X}}$ to information classes. In supervised learning problems, training samples $\mathcal{T}=\left{\left(\mathbf{x}<em i="i">{i}, y</em>\right)\right}<em i="i">{i}$, $\mathbf{x}</em>$ that is specific for each family of classifiers.} \in \mathcal{X} \subset \tilde{\mathcal{X}}, y_{i} \in \Omega$, drawn from the probability distribution $P(\mathbf{x}, y)=P(y \mid \mathbf{x}) \cdot P(\mathbf{x})$ are assumed to be available. Accordingly, the learning problem is to determine a supervised classifier $g(\mathbf{x} \mid \mathcal{T}, \boldsymbol{\theta})^{4}$ that permits to obtain high predictive accuracy for unlabeled test samples drawn from the same distribution $P(\mathbf{x}, y)$ by exploiting the available training set $\mathcal{T}$. The discrimination capability depends on the classifier model, which is described by a vector of parameters $\boldsymbol{\theta</p>
<p>In the framework of domain adaptation, the problem is more complex as test patterns are drawn from a targetdomain distribution $P^{t}(\mathbf{x}, y)=P^{t}(y \mid \mathbf{x}) \cdot P^{t}(\mathbf{x})$ different from the source-domain distribution of training samples $P^{s}(\mathbf{x}, y)=P^{s}(y \mid \mathbf{x}) \cdot P^{s}(\mathbf{x})$. Obtaining a good adaptation requires an adequate modeling of the relationship between source and target domains $\mathrm{D}<em t="t">{s}$ and $\mathrm{D}</em>}$. There are two extreme cases for domain adaptation problems: 1) If $P^{s}(\mathbf{x}, y) \equiv P^{t}(\mathbf{x}, y)$, adaptation is not necessary and standard supervised learning algorithms can be employed and 2) if $P^{s}(\mathbf{x}, y)$ and $P^{t}(\mathbf{x}, y)$ are uncorrelated, then sourcedomain data are useless for building a model for $\mathrm{D<em s="s">{t}$. Nevertheless, in real applications, $\mathrm{D}</em>, y)$.}$ and $\mathrm{D}_{t}$ are generally neither identical nor uncorrelated. In these situations, it is reasonable to assume the existence of an intrinsic relationship between the two domains that makes it possible adaptation. We expect that the probability to succeed in the adaptation process is associated with the complexity of the problem, which depends on the correlation between $P^{s}(\mathbf{x}, y)$ and $P^{t}(\mathbf{x</p>
<p>In this context, let us consider two sets $\mathcal{X}<em t="t">{s}=\left{\mathbf{x}</em>\right}}^{s<em t="t">{t=1}^{N}$ and $\mathcal{X}</em>}=\left{\mathbf{x<em s="1">{s}^{t}\right}</em>}^{M}$ composed of $N$ source-domain and $M$ targetdomain patterns, respectively. Let $\mathbf{x}^{s}$ and $\mathbf{x}^{t}$ be the $d$-dimensional feature vectors related to $\mathrm{D<em t="t">{s}$ and $\mathrm{D}</em>$, respectively ( $d$ represents the dimensionality of the input space). The proposed techniques are formulated under the following assumptions:</p>
<ul>
<li>The same set of $L$ classes $\Omega=\left{\omega_{i}\right}<em s="s">{i=1}^{L}$ characterizes $\mathrm{D}</em>$.}$ and $\mathrm{D}_{t</li>
<li>A set of true labels $\mathcal{Y}<em t="t">{s}=\left{y</em>\right}}^{s<em s="s">{t=1}^{N}$ for $\mathcal{X}</em>}$ is available, thus, it is possible to define a training set $\mathcal{T<em s="s">{s}=$ $\left{\mathcal{X}</em>}, \mathcal{Y<em t="t">{s}\right}=\left{\left(\mathbf{x}</em>\right)\right}}^{s}, y_{t}^{s<em s="s">{t=1}^{N}$ for $\mathrm{D}</em>$.</li>
<li>
<p>A set of true labels $\mathcal{Y}<em u="u">{t}=\left{y</em>\right}}^{t<em t="t">{u=1}^{M}$ for $\mathcal{X}</em>$.
Under such a hypothesis, our goals are:}$ is not available, thus, it is not possible to define a training set for $\mathrm{D}_{t</p>
</li>
<li>
<p>to define a domain adaptation classifier $g(\mathbf{x} \mid$ $\left.\mathcal{T}<em t="t">{s}, \mathcal{X}</em>, \psi\right)$ based on SVMs which permits us to</p>
</li>
<li>This notation has been adopted for pointing out all the input variables (data and learning parameters) that affect the output of a classifier.
obtain an accurate classification for target-domain samples by exploiting labeled training samples $\mathcal{T}<em s="s">{s}$ from $\mathrm{D}</em>}$ and unlabeled samples $\mathcal{X<em t="t">{t}$ from $\mathrm{D}</em>$ (as for supervised classifiers, the model adopted for classification is described by a vector of parameters $\psi$, which is specific for each family of domain adaptation classifiers);</li>
<li>to develop a strategy for validating the learning of the domain adaptation classifier without labeled target-domain data.</li>
</ul>
<h2>4 Proposed DASVM Technique</h2>
<p>In this section, for simplicity, we describe the proposed DASVM technique in the case of a two-class problem. Unlike transductive and semi-supervised SVMs, the DASVM algorithm takes into account that unlabeled target-domain samples are drawn from a distribution $P^{t}(\mathbf{x}, y)$ different from the one of source-domain training patterns $P^{s}(\mathbf{x}, y)$. Therefore, source-domain samples are only exploited for initializing the discriminant function for the target-domain problem, while they are successively gradually erased in order to obtain a final separation hyperplane defined only on the basis of target-domain samples. This represents an important conceptual difference with respect to both transductive and semi-supervised SVMs techniques, which recover information from unlabeled samples under the assumption that the labeled and unlabeled samples are drawn from the same domain. Thus, they cannot be used for solving domain adaptation problems. On the contrary, the DASVM technique, by iteratively deleting source-domain samples and adapting the discriminant function step by step to the target-domain instances, can recover useful information and properly seize the target-domain classification problem.</p>
<p>The proposed DASVM algorithm is made up of three main phases: 1) initialization (only $\mathcal{T}<em s="s">{s}$ is used for initializing the discriminant function), 2) iterative domain adaptation $\left(\mathcal{T}</em>}\right.$ and $\mathcal{X<em t="t">{t}$ are used for gradually adapting the discriminant function to $\mathrm{D}</em>}$ ), and 3) convergence (only $\mathcal{X<em t="t">{t}$ is used for defining the final discriminant function). In the following, we will denote by $\mathcal{T}^{(i)}$ and $\mathcal{X}</em>$ ) at the generic iteration $i$, respectively. These phases are described in the following.}^{(i)}$ the training set and the unlabeled set (i.e., the set containing the target-domain samples that have not been inserted into the training set $\mathcal{T}^{(i)</p>
<h3>4.1 Phase 1: Initialization</h3>
<p>In the first phase, an initial separation hyperplane is determined on the basis of source-domain training data alone. We have that $\mathcal{T}^{(0)}=\left{\mathcal{X}<em s="s">{s}, \mathcal{Y}</em>}\right}=\left{\left(\mathbf{x<em t="t">{t}^{s}, y</em>\right)\right}}^{s<em t="t">{t=1}^{N}$ and $\mathcal{X}</em>}^{(0)}=\left{\mathbf{x<em u="1">{u}^{t}\right}</em>$. As for standard supervised SVMs, the bound cost function to minimize is the following:}^{M</p>
<p>$$
\left{\begin{array}{c}
\min <em l="l">{\mathbf{w}, b, \xi}\left{\frac{1}{2}\left|\mathbf{w}^{(0)}\right|^{2}+C \sum</em>\right} \
y_{t}^{s}\left(\mathbf{w}^{(0)} \cdot \mathbf{x}} \xi_{l}^{s<em t="t">{t}^{s}+b^{(0)}\right) \geq 1-\xi</em>}^{s} \quad \forall l=1, \ldots, N,\left(\mathbf{x<em t="t">{t}^{s}, y</em>
\end{array}\right.
$$}^{s}\right) \in \mathcal{T}^{(0)</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. Separation hyperplane (solid line) and margin bounds (dashed lines) at different stages of the DASVM algorithm for a toy data set. Labeled source-domain patterns are shown as white and black circles. Semilabeled target-domain patterns are shown as white and black squares, respectively. Unlabeled target-domain patterns are represented as gray squares. Feature space structure obtained: (a) at the first iteration (the dashed circles highlight the ρ semilabeled patterns selected from both sides of the margin; in the example ρ = 3); (b) at the second iteration and (c) at the last iteration, respectively, in an ideal situation (the dashed gray lines represent both the separation hyperplane and the margin bounds at the beginning of the learning process).</p>
<p>where w(0) is a vector normal to the separation hyperplane h(0) : w(0) · x + b(0) = 0, b is a constant such that b(0) / ||w(0)||2 represents the distance of the hyperplane from the origin, ξ; are slack variables, and C is a penalization parameter (also called regularization parameter).</p>
<h2>4.2 Phase 2: Iterative Domain Adaptation</h2>
<p>At the generic iteration i, all the original unlabeled target-domain samples x^{t}<em u="u">{u} ∈ X^{i}^{(0)} are associated with an estimated label î</em>}^{(i)} = sgn[f(i) (x^{t<em u="u">{u})], determined according to the current decision function f(i) (x^{t}</em> are those with the highest probability to be associated with nonzero Lagrange multipliers (and thus, to affect the position of h(i+1)) once inserted in T(i+1) with their current estimated label (patterns falling outside the margin band are more likely to be associated with null multipliers). According to these two observations, at each iteration, we progressively take into account the unlabeled target-domain samples falling into M(i) closest to the margin bounds. Let us define the following two subsets:}) = w(i) · x^{t}_{u} + b(i). Then, a subset of the (remaining) unlabeled samples X^{i}^{(i)} is iteratively selected and moved (with the corresponding estimated labels) into the training set T(i+1). On one hand, the higher the distance from the separation hyperplane h(i) : w(i) · x + b(i) = 0, the higher the probability for an unlabeled sample to be correctly classified. On the other hand, the current unlabeled samples falling into the margin band M(i) = {x | -1 ≤ f(i) (x) ≤ 1</p>
<p>$$
\mathcal{H}<em u="u">{\text{up}}^{(i)} = { (\mathbf{x}</em>}^{t}, \mathcal{Y<em u="u">{u}^{(i)}) \mid \mathbf{x}</em>}^{t} \in \mathcal{X<em u="u">{t}^{(i)}, 1 \ge f^{(i)} (\mathbf{x}</em>}^{t}) \ge f^{(i)} (\mathbf{x<em _text_low="\text{low">{u+1}^{t}) \ge 0 }, \mathcal{H}</em>}}^{(i)} = { (\mathbf{x<em u="u">{u}^{t}, \mathcal{Y}</em>}^{(i)}) \mid \mathbf{x<em t="t">{u}^{t} \in \mathcal{X}</em>}^{(i)}, -1 \le f^{(i)} (\mathbf{x<em u_1="u+1">{u}^{t}) \le f^{(i)} (\mathbf{x}</em>
$$}^{t}) &lt; 0 }, \tag{2</p>
<p>where H(ij) and H(ij) are made up of the patterns of the current unlabeled set X^{i}^{(i)} (considered with their corresponding estimated labels) lying in the upper and lower sides of the margin band M(i), respectively. Samples of H(ij) and H(ij) are sorted in ascending order with respect to their distance from the upper and lower bound of the margin, respectively. The DASVM approach exploits a strategy inspired by the PTSVM algorithm [21] in which, at each iteration of the learning process, the unlabeled samples inside the margin band M(i) with the maximum and minimum values of the decision function are moved into the training set. As two patterns may not be sufficiently representative for tuning the position of the hyperplane, in the proposed DASVM, at each iteration, the first ρ patterns (where the parameter ρ ≥ 1 is defined a priori by the user) belonging to H(ij) and to H(ij) whose current estimated labels î_{u}^{(i)} are "+1" and "−1," respectively, are selected and inserted into the training set T(i) (see Figs. 1a and 1b). Such samples are defined as semilabeled patterns. As the cardinality of H(ij) and H(ij) may be lower than ρ, the subset of target-domain patterns selected at the generic iteration i becomes</p>
<p>$$
\mathcal{H}^{(i)} = { (\mathbf{x}<em u="u">{u}^{t}, \mathcal{Y}</em>}^{(i)}) \in \mathcal{H<em u="u">{\text{up}}^{(i)} | 1 \le u \le \lambda^{(i)} } \cup { (\mathbf{x}</em>}^{t}, \mathcal{Y<em _text_low="\text{low">{u}^{(i)}) \in \mathcal{H}</em>
$$}}^{(i)} | 1 \le u \le \delta^{(i)} }, \tag{3</p>
<p>where λ(i) = min(ρ, |H(ij) (i)) and δ(i) = min(ρ, |H(ij) (i)). Patterns belonging to H(i) are then merged with T(i). A dynamical adjustment is necessary for taking into account that the position of the separation hyperplane h(i) changes at each iteration. Let</p>
<p>$$
\mathcal{S}^{(i)} = { (\mathbf{x}<em u="u">{u}^{t}, \mathcal{Y}</em>}^{(i-1)}) \in \mathcal{T}^{(i)} | \mathcal{Y<em u="u">{u}^{(i)} \neq \mathcal{Y}</em>
$$}^{(i-1)} } \tag{4</p>
<p>represent the set of semilabeled samples belonging to T(i) whose labels at iteration i are different from those at iteration i − 1. If the label of a semilabeled pattern at iteration i is different from the one at iteration i − 1 (label inconsistency), such a label is erased and the semilabeled pattern is reset to the unlabeled state and moved to X(i+1). In this way, it is possible to reconsider this pattern in the following iterations of the learning procedure.</p>
<p>Let $\mathcal{J}^{(i)}$ represent the set containing all the semilabeled patterns at the $i$ th iteration. $\mathcal{J}^{(i)}$ is partitioned into a finite number of subsets $\gamma \in \mathbb{N}_{0}$,</p>
<p>$$
\begin{aligned}
\mathcal{J}^{(i)}=\mathcal{J}<em 2="2">{1}^{(i)} \cup \mathcal{J}</em>}^{(i)} \cup \cdots \cup \mathcal{J<em 1="1">{\gamma}^{(i)} \
\left{\begin{array}{l}
\mathcal{J}</em> \
\mathcal{J}}^{(i)}=\mathcal{H}^{(i)<em k-1="k-1">{k}^{(i)}=\mathcal{J}</em>, \quad \forall k=2, \ldots, \gamma-1 \
\mathcal{J}}^{(i-1)}-\mathcal{S}^{(i)<em _gamma="\gamma">{\gamma}^{(i)}=\left(\mathcal{J}</em>
\end{array}\right.
\end{aligned}
$$}^{(i-1)} \cup \mathcal{J}_{\gamma-1}^{(i-1)}\right)-\mathcal{S}^{(i)</p>
<p>where each $k$ th subset includes all of the semilabeled samples that do not change their label after the tuning of the separation hyperplane at the $i$ th iteration and that belonged to the subset with index $k-1$ at iteration $i-1$. As will be pointed out in the following, the DASVM algorithm aims at gradually increasing the regularization parameter for the semilabeled patterns according to a time-dependent criterion; accordingly, $\gamma$ is defined as the maximum number of iterations for which the user allows the regularization parameter for semilabeled samples to increase.</p>
<p>As the main purpose of the proposed technique is to define and solve a bound minimization problem with respect only to the target-domain samples, at each iteration a subset $\mathcal{Q}^{(i)}$ of the original source-domain training patterns is deleted. The higher the distance from the separation hyperplane $h^{(i)}$, the lower the influence in affecting its position. Accordingly, it is reasonable to erase from $\mathcal{T}^{(i)}$ the source-domain samples lying farther from $h^{(i)}$ (see Fig. 1a). Let us define the following two subsets:</p>
<p>$$
\begin{aligned}
&amp; \mathcal{Q}<em t="t">{\text {up }}^{(i)}=\left{\left(\mathbf{x}</em>}^{s}, y_{t}^{s}\right) \in \mathcal{T}^{(i)} \mid f^{(i)}\left(\mathbf{x<em t_1="t+1">{t}^{s}\right) \geq f^{(i)}\left(\mathbf{x}</em>\right) \geq 0\right} \
&amp; \mathcal{Q}}^{s<em t="t">{\text {low }}^{(i)}=\left{\left(\mathbf{x}</em>}^{s}, y_{t}^{s}\right) \in \mathcal{T}^{(i)} \mid f^{(i)}\left(\mathbf{x<em t_1="t+1">{t}^{s}\right) \leq f^{(i)}\left(\mathbf{x}</em>\right)&lt;0\right}
\end{aligned}
$$}^{s</p>
<p>where $\mathcal{Q}<em _low="{low" _text="\text">{\text {up }}^{(i)}$ and $\mathcal{Q}</em>}}^{(i)}$ contain the unlabeled target-domain patterns that lie above and under the separation hyperplane, respectively, sorted in descending order with respect to their distance from $h^{(i)}$. At the $i$ th iteration, the number of patterns to erase from $\mathcal{Q<em _low="{low" _text="\text">{\text {up }}^{(i)}$ and $\mathcal{Q}</em>=\emptyset\right)$, the number of patterns to delete is set to $\rho$. As a consequence, we have:}}^{(i)}$ is set equal to the number of semilabeled patterns selected from the upper and lower sides of the margin band (i.e., $\lambda^{(i)}$ and $\delta^{(i)}$ ), respectively. If none of the remaining unlabeled samples fall into the margin band $\left(\mathcal{H}^{(i)</p>
<p>$$
\begin{aligned}
\mathcal{Q}^{(i)}={ &amp; \left(\mathbf{x}<em t="t">{t}^{s}, y</em>}^{s}\right) \in \mathcal{Q<em t="t">{\mathrm{up}}^{(i)} \mid 1 \leq l \leq \nu^{(i)}} \
&amp; \cup\left{\left(\mathbf{x}</em>\right}
\end{aligned}
$$}^{s}, y_{t}^{s}\right) \in \mathcal{Q}_{\mathrm{low}}^{(i)} \mid 1 \leq l \leq \kappa^{(i)</p>
<p>where</p>
<p>$$
\begin{aligned}
\nu^{(i)}= &amp; \left{\begin{array}{ll}
\min \left(\lambda^{(i)}, \mid \mathcal{Q}<em _mathrm_up="\mathrm{up">{\mathrm{up}}^{(i)} \mid\right) &amp; \text { if } \mathcal{H}^{(i)} \neq \emptyset \
\min \left(\rho, \mid \mathcal{Q}</em>=\emptyset
\end{array} \text { and }\right. \
\kappa^{(i)}= &amp; \left{\begin{array}{ll}
\min \left(\delta^{(i)}, \mid \mathcal{Q}}}^{(i)} \mid\right) &amp; \text { if } \mathcal{H}^{(i)<em _mathrm_low="\mathrm{low">{\mathrm{low}}^{(i)} \mid\right) &amp; \text { if } \mathcal{H}^{(i)} \neq \emptyset \
\min \left(\rho, \mid \mathcal{Q}</em>=\emptyset
\end{array}\right.
\end{aligned}
$$}}^{(i)} \mid\right) &amp; \text { if } \mathcal{H}^{(i)</p>
<p>Let $\mu^{(i)}=\left|\mathcal{T}^{(i)}\right|-\left|\mathcal{J}^{(i-1)}\right|$ and $\eta^{(i)}=\left|\mathcal{J}^{(i-1)}\right|$ represent the number of original source-domain and semilabeled samples belonging to the current training set $\mathcal{T}^{(i)}$, respectively. For $i \geq 1$, the bound minimization problem can be written as</p>
<p>$$
\left{\begin{array}{l}
\min <em l="l">{\mathbf{w}, b, \xi^{\prime}, \xi^{\prime}}\left{\frac{1}{2}\left|\mathbf{w}^{(i)}\right|^{2}+C^{(i)} \sum</em>\right} \
y_{l}^{s} \cdot\left(\mathbf{w}^{(i)} \cdot \mathbf{x}} \xi_{l}^{s}+\sum_{u} C_{u}^{*} \xi_{u}^{t<em t="t">{t}^{s}+b^{(i)}\right) \geq 1-\xi</em> \
\forall l=1, \ldots, \mu^{(i)},\left(\mathbf{x}}^{s<em t="t">{t}^{s}, y</em> \
\hat{y}}^{s}\right) \in \mathcal{T}^{(i)<em u="u">{u}^{t(i-1)} \cdot\left(\mathbf{w}^{(i)} \cdot \mathbf{x}</em> \
\forall u=1, \ldots, \eta^{(i)},\left(\mathbf{x}}^{t}+b^{(i)}\right) \geq 1-\xi_{u}^{t<em u="u">{u}^{t}, \hat{y}</em> \
\xi_{t}^{s}, \xi_{u}^{t} \geq 0
\end{array}\right.
$$}^{(i-1)}\right) \in \mathcal{T}^{(i)</p>
<p>The semilabeled samples $\left(\mathbf{x}<em u="u">{u}^{t}, \hat{y}</em>^{}^{(i-1)}\right) \in \mathcal{T}^{(i)}$ are associated with a regularization parameter $C_{u<em>}=C_{u}^{</em>}(k) \in \mathbb{R}^{+}$that depends on the $k$ th subset $\mathcal{J}<em u="u">{k}^{(i-1)}$ which they belong to at iteration $i-1$. The original source-domain patterns, instead, are associated with a regularization parameter $C^{(i)}$ that directly depends on the $i$ th iteration. The purpose of $C^{(i)}$ and $C</em>}^{*}$ is to control the number of misclassified samples of the current training set $\mathcal{T}^{(i)}$ drawn from $\mathrm{D<em t="t">{s}$ and $\mathrm{D}</em>$ (see Fig. 2a):}$, respectively. On increasing their values, the penalty associated with errors increases. In other words, the larger the regularization parameter, the higher the influence of the associated samples on the selection of the separation hyperplane. As $P^{t}(\mathbf{x}, y)$ in general could be rather different compared to $P^{s}(\mathbf{x}, y)$, unlabeled samples should be considered gradually in the learning process in order to avoid instabilities. For this reason, the algorithm adopts a weighting strategy based on a temporal criterion. The regularization parameter for the semilabeled patterns increases in a quadratic way, depending on the number of iterations $k$ they had last inside the set containing the semilabeled patterns $\mathcal{J}^{(i)</p>
<p>$$
\begin{aligned}
\forall u &amp; =1, \ldots,\left|\mathcal{J}^{(i)}\right| \
C_{u}^{<em>} &amp; =\frac{C^{</em> \max }-C^{<em>}}{(\gamma-1)^{2}}(k-1)^{2}+C^{</em>} \Leftrightarrow\left(\mathbf{x}<em u="u">{u}^{t}, \hat{y}</em> \
k &amp; =1, \ldots, \gamma
\end{aligned}
$$}^{(i)}\right) \in \mathcal{J}_{k}^{(i)</p>
<p>where $C^{<em>}$ is the initial regularization value for semilabeled samples (this is a user-defined parameter), and $C^{</em> \max }$ is the maximum cost value of semilabeled samples and is related to that of training patterns (i.e., $C^{* \max }=\tau \cdot C, 0&lt;\tau \leq 1$ being a constant; a reasonable choice has proved to be $\tau=0.5$ ). The greater $k$ is, the higher the reliability of a semilabeled sample is expected to be.</p>
<p>Likewise, the algorithm makes the cost factor for the original source-domain labeled samples $C^{(i)}$ to decrease in a quadratic way (see Fig. 2b). At the beginning, the position of the separation hyperplane strongly depends on sourcedomain patterns $\left(\mathbf{x}<em t="t">{t}^{s}, y</em>\right)$, but their influence always gets lower as the number of iterations increases (until $i=\gamma$ ):}^{s</p>
<p>$$
C^{(i)}=\max \left(\frac{C^{<em>}-C}{\gamma^{2}} i^{2}+C, C^{</em>}\right)
$$</p>
<p>The second phase ends when the convergence criterion described below is satisfied.</p>
<h3>4.3 Phase 3: Convergence</h3>
<p>From a theoretical viewpoint, it can be assumed that convergence is reached if none of the remaining targetdomain samples lies into the margin band, $\mathcal{H}^{(i)}=\emptyset$, after all of the source-domain labeled samples have been erased, $\mathcal{Q}^{(i)}=\emptyset$ (see Fig. 1c). Nevertheless, such a choice might result in a high computational load. Moreover, it may</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2. (a) Behavior of $C_{n}^{s}$, regularization parameter for the semilabeled patterns belonging to $\mathcal{J}^{(i)} \circ \mathcal{J}<em 2="2">{1}^{(i)} \cup \mathcal{J}</em>}^{(i)} \cup \ldots \cup \mathcal{J<em n="n">{r}^{(i)}$, versus $k$ (index corresponding to the subset $\mathcal{J}</em>$, versus the number of iterations $i$.
happen that even if the margin band is empty, the number of inconsistent patterns is not negligible. For these reasons, the following empirical stopping criterion has been defined:}^{(i)}$, which is related to the number of iterations in which a semilabeled pattern is associated with the same label). (b) Behavior of the regularization parameter for the original source-domain labeled patterns, $C^{(i)</p>
<p>$$
\left{\begin{array}{l}
\mathcal{Q}^{(i)}=\emptyset \
\left|\mathcal{H}^{(i)}\right| \leq\lceil\beta \cdot M\rceil \
\left|\mathcal{S}^{(i)} \leq\lceil\beta \cdot M\rceil\right.
\end{array}\right.
$$</p>
<p>where $M$ is the number of target-domain samples and $\beta$ is a constant fixed a priori that tunes the sensitivity of the learning process. This means that convergence is reached if both the number of mislabeled and remaining unlabeled patterns lying in the margin band at the current iteration is lower than or equal to $\lceil\beta \cdot M\rceil$. The final minimization problem at the last iteration $\tilde{i}$ becomes</p>
<p>$$
\left{\begin{array}{c}
\min <em u="u">{\mathbf{w}, b, \xi}\left{\frac{1}{2}|\mathbf{w}|^{2}+\sum</em>\right} \
\hat{y}} C_{u}^{s} \xi_{u<em u="u">{u}^{(\tilde{i}-1)} \cdot\left(\mathbf{w} \cdot \mathbf{x}</em> \
\forall u=1, \ldots,\left|\mathcal{T}^{(\tilde{i})}\right|,\left(\mathbf{x}}^{t}+b\right) \geq 1-\xi_{u<em u="u">{u}^{t}, \hat{y}</em> \
\xi_{u} \geq 0
\end{array}\right.
$$}^{(\tilde{i}-1)}\right) \in \mathcal{T}^{(\tilde{i})</p>
<p>At the end, all of the target-domain patterns $\mathbf{x}<em t="t">{u}^{t} \in \mathcal{X}</em>}$ are labeled according to the resulting separation hyperplane, i.e., $\mathcal{Y<em u="u">{t}=\left{\hat{y}</em>}^{t}=\operatorname{sgn}\left[\mathbf{w} \cdot \mathbf{x<em u="1">{u}^{t}+b\right]\right}</em>$.}^{M</p>
<p>The above-described algorithm is defined for two-class problems. When a multiclass problem has to be investigated, a One-Against-All (OAA) strategy [41] can be employed.</p>
<h2>5 Proposed Circular Validation Strategy</h2>
<p>In this section, we present a novel general empirical strategy for validating the solutions obtained with a domain adaptation classifier when no labeled data related to the target domain are available. This method can also be used with the DASVM presented in the previous section.</p>
<h3>5.1 Background and Rationale of the Proposed Strategy</h3>
<p>The proposed strategy is based on the two following assumptions.</p>
<ol>
<li>Assumption 1: Under the assumption that $P^{s}(\mathbf{x}, y)$ and $P^{t}(\mathbf{x}, y)$ are neither uncorrelated nor identical, it is reasonable to assume the existence of an intrinsic relationship between solutions that are satisfactory
for the two domains. This relationship is associated with the intrinsic structure of the considered problem (which is related to the correlation between $P^{s}(\mathbf{x}, y)$ and $P^{t}(\mathbf{x}, y)$ ). We expect that an adequately trained domain adaptation algorithm seizes the structure of the problem and can move from modeling the source-domain problem to modeling the target-domain problem, and vice versa. On the contrary, if the learning process fails, the considered domain adaptation algorithm completely loses the structure of the problem and results in an unpredictable behavior that involves a random solution. This solution has no relation to the considered problem. In this condition, it is no more possible to recover the intrinsic structure of the problem, and thus, moving from modeling the target-domain problem to modeling the source-domain problem.</li>
<li>Assumption 2: The only labeled samples available are those related to the source domain $\mathrm{D}<em t="t">{s}$. Thus, for validating the learning for $\mathrm{D}</em>}$, we should devise an indirect procedure based on the training set $\mathcal{T<em n="n">{s}$.
On the basis of these observations, the proposed strategy relies on the following rationale: Let us consider that, starting from a reliable estimated distribution $\hat{P}</em>}^{s}(\mathbf{x}, y)$ for $\mathrm{D<em n="n">{s}$ (and thus, from an acceptable classification accuracy on source-domain patterns), the $n$th generic domain adaptation classifier results in an accurate estimate $\hat{P}</em>}^{t}(\mathbf{x}, y)$ for $P^{t}(\mathbf{x}, y)$ (and hence, in a satisfactory classification accuracy for the instances related to $\mathrm{D<em t="t">{t}$ ). In such a case, the domain adaptation classifier seizes the structure of the targetdomain problem. In this condition, we assume that, by again applying the same learning algorithm in the reverse sense (using the classification labels in place of the missing prior knowledge for target-domain patterns $\mathcal{X}</em>}$, keeping the same learning parameters, and considering the problem of classifying source-domain patterns $\mathcal{X<em t="t">{s}$ ), it is possible to infer an accurate estimate for $P^{s}(\mathbf{x}, y)$ (thus obtaining a good discrimination capability also for the source-domain problem). On the contrary, if the domain adaptation algorithm does not identify an acceptable solution for $\mathrm{D}</em>, y)$ does not}$, this means that it does not capture the relationship between the two domains but converges to a solution which is not related to the investigated problem (i.e., the resulting $\hat{P}_{n}^{t}(\mathbf{x</li>
</ol>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3. Diagram of all the possible state transitions exploited from the proposed circular validation strategy.
represent an adequate estimation of the real distribution $P^{t}(\mathbf{x}, y))$. In this condition, by again applying the algorithm in the reverse sense (from target to source), it seems impossible to recover a reliable solution for the sourcedomain problem, but rather, it is reasonable to expect a poor estimate for $P^{s}(\mathbf{x}, y)$. This reasoning has some analogies with the definition of specific trajectories that model transitions between different states in chaotic systems. On the basis of these expected properties, we can use the accuracy evaluated on the original training samples from $\mathrm{D}_{s}$ for validating the solution obtained for targetdomain instances after a circular (forward and backward) application of the considered domain adaptation algorithm.</p>
<h3>5.2 Formulation of the Proposed Circular Validation Strategy</h3>
<p>Given a classification accuracy measure $\Lambda\left(\mathcal{Y}<em j="j" n="n">{j}, \hat{\mathcal{Y}}</em>}\right)$ that evaluates the similarity between a set of labels $\hat{\mathcal{Y}<em n="n">{j n}$ (i.e., a solution) predicted by the generic classifier $\mathbf{g}</em>}(\mathbf{x})$ and the corresponding set of true labels $\mathcal{Y<em _text="\text" _th="{th">{j}$, and given a threshold $\Lambda</em>$ for $\Lambda$, let us define the following four sets of classifiers (see Fig. 3):}</p>
<p>$$
\begin{aligned}
\mathcal{A} &amp; =\left{g_{n}(\mathbf{x}) \mid \Lambda\left(\mathcal{Y}<em n="n" s="s">{s}, \hat{\mathcal{Y}}</em>\right} \
\mathcal{B} &amp; =\left{g_{n}(\mathbf{x}) \mid \Lambda\left(\mathcal{Y}}\right) \geq \Lambda_{\mathrm{th}<em n="n" t="t">{t}, \hat{\mathcal{Y}}</em>\right} \
\mathcal{C} &amp; =\left{g_{n}(\mathbf{x}) \mid \Lambda\left(\mathcal{Y}}\right) \geq \Lambda_{\mathrm{th}<em n="n" s="s">{s}, \hat{\mathcal{Y}}</em>\right} \
\mathcal{D} &amp; =\left{g_{n}(\mathbf{x}) \mid \Lambda\left(\mathcal{Y}}\right)&lt;\Lambda_{\mathrm{th}<em n="n" t="t">{t}, \hat{\mathcal{Y}}</em>\right}
\end{aligned}
$$}\right)&lt;\Lambda_{\mathrm{th}</p>
<p>where $\hat{\mathcal{Y}}<em i="i" n="n">{s n}=\left{\hat{y}</em>}^{t}=g_{n}\left(\mathbf{x<em n="n" t="t">{i}^{s}\right)\right}$ and $\hat{\mathcal{Y}}</em>}=\left{\hat{y<em n="n">{i n}^{t}=g</em>}\left(\mathbf{x<em n="n">{i}^{t}\right)\right}$ are the labels predicted by $g</em>$ contain all of the classifiers that provide solutions whose accuracy is lower
than $\Lambda_{t h}$ for source and target-domain samples (nonconsistent solutions), respectively. $\Lambda_{\text {th }}$ represents the smallest value for $\Lambda$ such that a solution can be considered acceptable for the problem under investigation.}(\mathbf{x})$ for source and target-domain samples, respectively. It is worth noting that the subscript $n$ points out a classification model obtained starting from the same classification technique using different values of parameters in the training phase (e.g., a DASVM classifier with different values of learning parameters). On one hand, $\mathcal{A}$ and $\mathcal{B}$ contain all of the classifiers that permit to obtain solutions whose accuracy is higher than or equal to $\Lambda_{\text {th }}$ for source and target-domain samples (consistent solutions), respectively. On the other hand, $\mathcal{C}$ and $\mathcal{D</p>
<p>Each classifier $g_{n}(\mathbf{x})$ is associated with an estimate of the joint probability distribution $\hat{P}<em n="n">{n}(\mathbf{x}, y)=\hat{P}</em>}(y \mid \mathbf{x}) \cdot \hat{P}(\mathbf{x})$ for the considered domain. Indeed, while $\hat{P}(\mathbf{x})$ directly depends on the instances available for the considered domain, the estimated conditional posterior distribution $\hat{P<em n="n">{n}(y \mid \mathbf{x})$ is related to the information class associated by the classifier to the generic sample $\mathbf{x}$, i.e., $\hat{P}</em>\right)$. Accordingly, both the source and target-domain estimated joint distributions can be written as}(y \mid \mathbf{x})=\hat{P}\left(g_{n}(\mathbf{x}) \mid \mathbf{x</p>
<p>$$
\begin{aligned}
&amp; \hat{P}<em n="n">{n}^{s}(\mathbf{x}, y)=\hat{P}</em>) \
&amp; \hat{P}}^{s}(y \mid \mathbf{x}) \cdot \hat{P}^{s}(\mathbf{x})=\hat{P}^{s}\left(g_{n}(\mathbf{x}) \mid \mathbf{x}\right) \cdot \hat{P}^{s}(\mathbf{x<em n="n">{n}^{t}(\mathbf{x}, y)=\hat{P}</em>)
\end{aligned}
$$}^{t}(y \mid \mathbf{x}) \cdot \hat{P}^{t}(\mathbf{x})=\hat{P}^{t}\left(g_{n}(\mathbf{x}) \mid \mathbf{x}\right) \cdot \hat{P}^{t}(\mathbf{x</p>
<p>Therefore, it is possible to relate the quality of these estimated distributions with the four sets of classifiers described above:</p>
<ul>
<li>If $g_{n}(\mathbf{x}) \in \mathcal{A}$, we assume that $\hat{P}_{n}^{s}(\mathbf{x}, y)$ is consistent with $P^{s}(\mathbf{x}, y)$ (the system is in state $\bar{A}$ ).</li>
<li>If $g_{n}(\mathbf{x}) \in \mathcal{B}$, we assume that $\hat{P}_{n}^{t}(\mathbf{x}, y)$ is consistent with $P^{t}(\mathbf{x}, y)$ (the system is in state $\bar{B}$ ).</li>
<li>If $g_{n}(\mathbf{x}) \in \mathcal{C}$, we assume that $\hat{P}_{n}^{s}(\mathbf{x}, y)$ is not consistent with $P^{s}(\mathbf{x}, y)$ (the system is in state $\bar{C}$ ).</li>
<li>If $g_{n}(\mathbf{x}) \in \mathcal{D}$, we assume that $\hat{P}<em n="n" t="t">{n}^{t}(\mathbf{x}, y)$ is not consistent with $P^{t}(\mathbf{x}, y)$ (the system is in state $\bar{D}$ ).
Starting from state $\bar{A}$, with a proper choice of the learning parameters, a domain adaptation classifier is expected to move to state $\bar{B}$ (thus belonging to $\mathcal{B}$ ). On the contrary, if the choice of the parameters is not adequate (or $P^{t}(\mathbf{x}, y)$ is too different from $P^{s}(\mathbf{x}, y)$ ), the classifier moves to state $\bar{D}$ (thus belonging to $\mathcal{D}$ ). Let us now consider the solution obtained for the target-domain samples. We can address the reverse domain adaptation problem (from target to source) with the same classifier keeping the same learning parameters and jointly exploiting the classification labels $\hat{\mathcal{Y}}</em>}$ (instead of the training set, thus defining $\hat{\mathcal{T}<em t="t">{t}=\left{\mathcal{X}</em>}, \hat{\mathcal{Y}<em s="s">{t n}\right}$ ) and sourcedomain samples $\mathcal{X}</em>}$ (considered without their labels $\mathcal{Y<em i="i">{s}$ ). As the true labels $\left{y</em>\right}}^{s<em _text="\text" _th="{th">{i=1}^{N}$ for source-domain instances are known, we can compute the value for $\Lambda$ associated with the results obtained after the circular learning process. If $\Lambda&lt;\Lambda</em>$.}}$, the classification accuracy for the source-domain problem is considered nonacceptable, then the backward classifier moves to state $\bar{C}$ (thus belonging to $\mathcal{C}$ ). On the contrary, if $\Lambda \geq \Lambda_{\text {th }}$, the solution is consistent, thus the backward classifier belongs to $\mathcal{A}$ and the system moves back to state $\bar{A</li>
</ul>
<p>Our assumption is that, when the domain adaptation classifier starting from state $\bar{C}$ is able to return into state $\bar{A}$, the classification accuracy for target-domain data is satisfactory and $\hat{P}_{n}^{t}(\mathbf{x}, y)$ is a good approximation of $P^{t}(\mathbf{x}, y)$. This aspect is crucial because it means that, in such situations, we are able to assess that target-domain data are classified with a proper accuracy even if no prior knowledge is available. The two main hypotheses under which the proposed validation technique is effective are the following:</p>
<ul>
<li>Starting from state $\bar{D}$ the system must never move back to state $\bar{A}$. If the solution obtained in the forward sense (from source to target) for target-domain instances is not satisfactory (i.e., $\bar{P}<em n="n">{n}^{t}(\mathbf{x}, y)$ is not consistent with $P^{t}(\mathbf{x}, y)$ ), by applying the considered algorithm in the backward sense (from target to source), it must never be possible to obtain an acceptable solution for source-domain instances (i.e., the resulting $\bar{P}</em>, y)$ ).}^{s}(\mathbf{x}, y)$ is always not consistent with $P^{s}(\mathbf{x</li>
<li>Starting from state $\bar{B}$ the system can return to state $\bar{A}$. If there exists a set of satisfactory solutions obtained in the forward sense (from source to target) for targetdomain instances (i.e., the related $\bar{P}<em n="n">{n}^{t}(\mathbf{x}, y)$ are consistent with $P^{s}(\mathbf{x}, y)$ ), by applying the domain adaptation classifier in the backward sense (from target to source), it must be possible to obtain for at least one of them an acceptable solution for sourcedomain samples (i.e., the related $\bar{P}</em>, y)$ ).
It is worth noting that, under the aforementioned assumptions, the system may reject some solutions that are actually consistent with the target-domain problem as the learning parameters are not optimized for the backward process and we cannot assume a perfect symmetry between the domain adaptation problems from source to target, and vice versa. Nevertheless, the very important aspect is that the system never accepts and validates solutions that are nonconsistent, which is definitely a more critical aspect of validation in operational problems.}^{s}(\mathbf{x}, y)$ is consistent with $P^{s}(\mathbf{x</li>
</ul>
<h2>6 EXPERIMENTAL RESULTS</h2>
<p>In order to assess the effectiveness of both the proposed DASVM technique and the presented circular validation strategy, we carried out several experiments on different data sets. We analyzed three different domain adaptation problems: 1) a series of two-dimensional toy problems having different complexity, 2) a real problem in the framework of brain computer interface, and 3) a real problem in the context of remote sensing. For all of the data sets, true labels were available for both source and target-domain instances. However, prior information related to the target domain $\mathrm{D}_{t}$ was considered only for an objective and quantitative assessment of the performances of the proposed techniques. In the following, we will describe the common procedure adopted for analyzing the considered data sets; then, in the next sections, we will present in detail the results obtained for each of them.</p>
<p>In all of the trials, we employed Gaussian kernel functions (ruled by the free parameter $\sigma$ ) as they proved effective in addressing different kinds of problems. We chose the percentage overall accuracy $O A \%$ (i.e., the percentage of correctly labeled samples over the whole number of considered samples) as reference classification accuracy measure $\Lambda$ and fixed $\Lambda_{t h}=O A \%_{t h}=85$ in the validation strategy. This means that, both for the sourceand target-domain classification problems, we assumed that a solution was consistent if $O A \% \geq 85$.</p>
<p>In order to estimate the complexity of the investigated domain adaptation problems, we first analyzed the "distance" between source and target-domain distributions. To
this aim, a common choice in the literature is to compute the Kullback-Leibler (KL) [10] divergence, which is defined as</p>
<p>$$
D[P(\mathbf{x}) | Q(\mathbf{x})]=\sum_{n} p_{n} \log \frac{p_{n}}{q_{n}}
$$</p>
<p>where $p_{n}$ and $q_{n}$ are point probabilities of the two considered source and target distributions $P$ and $Q$, respectively [11]. Note that $D[P(\mathbf{x}) | Q(\mathbf{x})] \in[0 ; \infty)$. Even if KL divergence is generally considered as a kind of distance between two distributions, it is not symmetric (i.e., $D[P(\mathbf{x}) | Q(\mathbf{x})] \neq D[Q(\mathbf{x}) | P(\mathbf{x})])$. Therefore, in our experiments, we considered the Jensen-Shannon divergence $\left(D_{J S}\right)$, which is a symmetrized and smoothed version of the KL divergence [11]. $D_{J S}$ is defined as</p>
<p>$$
\begin{aligned}
D_{J S}[P(\mathbf{x}), Q(\mathbf{x})]= &amp; \alpha \cdot D[P(\mathbf{x}) | M(\mathbf{x})] \
&amp; +\beta \cdot D[Q(\mathbf{x}) | M(\mathbf{x})]
\end{aligned}
$$</p>
<p>where $M(\mathbf{x})=\alpha \cdot P(\mathbf{x})+\beta \cdot Q(\mathbf{x})$. In particular, we considered the case where $\alpha=\beta=0.5$, (referred in the literature as specific $D_{J S}$ ) for which it holds that $D_{J S}[P(\mathbf{x}), Q(\mathbf{x})] \in[0 ; \log 2]$. The existence of both a lower and an upper bound for $D_{J S}$ is particularly important as it permits us to understand how different the two considered distributions are. If $D_{J S}[P(\mathbf{x}), Q(\mathbf{x})]=0$, then $P$ and $Q$ are considered identical, whereas if $D_{J S}=\log 2 \simeq 0.693, P$ and $Q$ are considered uncorrelated. Besides the distance $D_{J S}\left[P^{s}(\mathbf{x}), P^{t}(\mathbf{x})\right]$ evaluated between general distributions, we also analyzed the distance $D_{J S}\left[P^{s}\left(\mathbf{x}\left|\omega_{i}\right\rangle, P^{t}\left(\mathbf{x}\left|\omega_{i}\right\rangle\right]\right.$ between class conditional distributions.</p>
<p>In all experiments, we trained several supervised SVMs on the labeled source-domain samples $\mathcal{T}<em s="s">{s}=\left{\mathcal{X}</em>}, \mathcal{Y<em s="s">{s}\right}$, in order to identify the models (and thus, the values of the supervised parameters $\sigma$ and $C$ ) that resulted in accurate (consistent) solutions for source-domain samples. Successively, we trained a number of DASVMs using $\mathcal{T}</em>}$ as labeled set and target-domain instances $\mathcal{X<em s="s">{t}$ as unlabeled set. In the learning phase, we assigned to $\sigma$ and $C$ pairs of values associated with solutions consistent with $\mathrm{D}</em>}$. On the remaining learning parameters (i.e., $C^{s}, \rho$, and $\gamma$ ), we applied a grid search. Note that, for the sake of comparison, we also evaluated the performances obtained by other two state-of-the-art domain adaptation techniques: 1) the retraining technique for maximum likelihood classifiers presented in [36] (denoted by $\mathrm{ML<em _cascade="{cascade" _text="\text">{\text {retrain }}$ ) and 2) the maximum likelihood cascade classifier proposed in [37] (denoted by $\mathrm{ML}</em>$ ).}</p>
<p>For validating the potentialities of the proposed domain adaptation technique, we identified the DASVM that provided the highest overall accuracy on the basis of the available target-domain true labels (which were not taken into account in the learning phase). This accuracy value represents an upper bound for the performances of the presented method. In order to assess the effectiveness of the empirical circular validation strategy introduced in Section 4, for all of the considered DASVMs, we applied the proposed domain adaptation algorithm in the reverse sense. Starting from the corresponding set of target-domain predicted labels, $\hat{\mathcal{Y}}<em n="n" t="t">{t n}$, for the generic $n$ th DASVM, we defined an estimated training set $\hat{\mathcal{T}}</em>}=\left{\mathcal{X<em n="n" t="t">{t}, \hat{\mathcal{Y}}</em>}\right}$ for $\mathrm{D<em n="n" t="t">{t}$ and trained the correspondent $n$ th "backward" DASVM using $\hat{\mathcal{T}}</em>$ as labeled</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4. Problem I: (a) original source-domain data; (b) decision regions obtained for the source-domain problem by a supervised SVM trained according to a 10 -fold CV strategy. Decision regions obtained for the target-domain problem by the proposed DASVM technique with optimal selection of learning parameters when (c) $\phi=10^{\circ}$, (d) $\phi=20^{\circ}$, (e) $\phi=30^{\circ}$, (f) $\phi=40^{\circ}$, and (g) $\phi=50^{\circ}$. (h) Superimposition of source data and target data for $\phi=50^{\circ}$ (the dashed circles point out regions, where target data that belong to class $\omega_{1}$ overlap source data that belong to class $\omega_{2}$, and vice versa) and decision regions obtained for the source-domain problem by a supervised SVM trained according to a 10 -fold CV strategy.
set and source-domain samples $\mathcal{X}<em n="n">{s}$ (considered without their labels) as unlabeled set (the same learning parameters employed in the forward learning were used). By exploiting available prior information for $\mathrm{D}</em>}$, we determined whether the final solution $\hat{\mathcal{Y}<em n="n" t="t">{m}$ was consistent or not and, accordingly, inferred the correctness of the related solution to the targetdomain problem $\hat{\mathcal{Y}}</em>}$. By using the available target-domain true labels, we could compute the average percentage overall accuracy of the solutions correctly identified as consistent with $\mathrm{D<em t="t">{t}$ by the circular validation strategy. This value is very important as it represents an average measure for the quality of the solutions consistent with $D</em>$. Note that, in order to obtain significant estimations, for all of the considered problems, we trained 350 backward DASVMs both starting from consistent and nonconsistent solutions with the target-domain problem. For the sake of comparison, we also evaluated the accuracies exhibited on target-domain samples by a supervised SVM trained on source-domain data according to a 10 -fold cross validation (CV).}$ identified by the proposed validation strategy without any prior information on $\mathcal{X}_{t</p>
<p>In all experiments, we employed the Sequential Minimal Optimization algorithm [42] for training both the supervised SVMs and, with proper modifications, the proposed DASVMs. As pointed out in Section 4, we fixed $\tau=0.5$. Concerning the convergence criterion, a reasonable empirical choice has proven to be $\beta=3 \cdot 10^{-2}$.</p>
<h3>6.1 Problem I: Synthetic Data Set</h3>
<p>The first set of experiments was aimed at characterizing the behavior of both the DASVM algorithm and the circular
validation strategy when addressing a well-defined problem in a controlled environment at different levels of complexity. This analysis is particularly important for empirically understanding the operational conditions for which we can expect to obtain satisfactory performances with the proposed methods. We considered as sourcedomain data a toy data set made up of 300 samples generated according to a bidimensional pattern of two intertwining moons associated with two specific information classes ( 150 samples each), as shown in Fig. 4a. Target data were generated by rotating anticlockwise the original source data set 11 times by $10,15,20,25,30,35,40,45,50$, 55 , and 60 degrees, respectively. Due to rotation, source and target-domain data exhibit different distributions (i.e., $P^{s}(\mathbf{x}) \neq P^{t}(\mathbf{x})$ and $P^{v}(y \mid \mathbf{x}) \neq P^{t}(y \mid \mathbf{x})$ ). In particular, the greater the rotation angle $(\phi)$, the more complex the resulting domain adaptation problem, as confirmed by the values for $D_{J S}$ reported in Table 2.</p>
<p>The proposed DASVM algorithm proved to be particularly effective for solving this kind of problem and involved very high accuracies even in very critical conditions. From Table 3, one can observe that, for an optimal selection of learning parameters ( $\mathrm{DASVM}^{\text {best }}$ ), we could obtain perfect separation between information classes when $\phi \in\left[10^{\circ} ; 50^{\circ}\right]$ (see Figs. 4c, 4d, 4e, 4f, and 4g). The accuracies are always higher than those exhibited by the supervised SVM trained according to a 10 -fold CV on source-domain data (the $O A \%$ grows almost quadratically with respect to the rotation angle, i.e., from +0.33 for $\phi=10^{\circ}$ to +67.33 for $\phi=50^{\circ}$ ). Only for greater values of $\phi$ (i.e., $55^{\circ}$ and $60^{\circ}$ ) the DASVM</p>
<p>TABLE 2
Problem I: Jensen-Shannon Divergence Values for Different Rotation Angles</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Rotation Angle</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$10^{\circ}$</td>
<td style="text-align: center;">$15^{\circ}$</td>
<td style="text-align: center;">$20^{\circ}$</td>
<td style="text-align: center;">$25^{\circ}$</td>
<td style="text-align: center;">$30^{\circ}$</td>
<td style="text-align: center;">$35^{\circ}$</td>
<td style="text-align: center;">$40^{\circ}$</td>
<td style="text-align: center;">$45^{\circ}$</td>
<td style="text-align: center;">$50^{\circ}$</td>
<td style="text-align: center;">$55^{\circ}$</td>
<td style="text-align: center;">$60^{\circ}$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$D_{i b}\left[P^{\prime}(\mathbf{x}), P^{\prime}(\mathbf{x})\right]$</td>
<td style="text-align: center;">0.040</td>
<td style="text-align: center;">0.091</td>
<td style="text-align: center;">0.150</td>
<td style="text-align: center;">0.211</td>
<td style="text-align: center;">0.260</td>
<td style="text-align: center;">0.291</td>
<td style="text-align: center;">0.378</td>
<td style="text-align: center;">0.410</td>
<td style="text-align: center;">0.435</td>
<td style="text-align: center;">0.442</td>
<td style="text-align: center;">0.457</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$D_{i b}\left[P^{\prime}(\mathbf{x} \mid \omega)$,</td>
<td style="text-align: center;">0.061</td>
<td style="text-align: center;">0.159</td>
<td style="text-align: center;">0.225</td>
<td style="text-align: center;">0.335</td>
<td style="text-align: center;">0.386</td>
<td style="text-align: center;">0.437</td>
<td style="text-align: center;">0.536</td>
<td style="text-align: center;">0.554</td>
<td style="text-align: center;">0.559</td>
<td style="text-align: center;">0.574</td>
<td style="text-align: center;">0.576</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$D_{i b}\left[P^{\prime}(\mathbf{x} \mid \omega)$,</td>
<td style="text-align: center;">0.071</td>
<td style="text-align: center;">0.170</td>
<td style="text-align: center;">0.203</td>
<td style="text-align: center;">0.304</td>
<td style="text-align: center;">0.371</td>
<td style="text-align: center;">0.438</td>
<td style="text-align: center;">0.468</td>
<td style="text-align: center;">0.486</td>
<td style="text-align: center;">0.538</td>
<td style="text-align: center;">0.572</td>
<td style="text-align: center;">0.573</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>was not able to find a solution consistent with $\mathrm{D}<em J="J" S="S">{t}$. Nevertheless, this behavior seems reasonable due to the complexity of the corresponding domain adaptation problems. In these cases, the initial separation hyperplane determined according to source-domain samples resulted in an average $O A \%$ on target-domain data smaller than 30 . Accordingly, it was not possible to recover correct classification labels as more than 70 percent of target-domain samples were misclassified at the first iteration of the DASVM algorithm. The complexity of this problem is also confirmed from the high values of $D</em>$.</p>
<p>It should be pointed out that, as soon as the rotation angle becomes greater than $35^{\circ}$, target-domain data that actually belong to the class $\omega_{1}$ overlap source-domain data belonging to the class $\omega_{2}$, and vice versa (see, for instance, Fig. 4h). Note that, due to rotation, there are target-domain instances that coincide with source-domain instances but with different true labels. This represents a strong limitation for other state-of-the-art domain adaptation techniques reported in Section 2. The proposed DASVM technique, due do to the fact that iteratively erases original training samples in the iterative learning phase, does not suffer from this drawback and is able to obtain satisfactory performances also in such critical cases. It is worth noting that DASVMs outperformed both $\mathrm{ML}<em _cascade="{cascade" _text="\text">{\text {retrain }}$ and $\mathrm{ML}</em>$, the increase in $O A \%$ is around 30 , thus further
confirming the effectiveness of the proposed technique in addressing also very critical situations.}}$ : the greater the rotation angle $\phi$ (and thus, the greater the problem complexity), the higher the gap in terms of classification accuracy (see Table 3). In particular, for $\phi=50^{\circ</p>
<p>With regard to the presented circular validation strategy, we obtained very promising results. In particular, for all of the considered cases, the proposed strategy was always able to correctly reject solutions that were not consistent with $\mathrm{D}<em s="s">{t}$, thus satisfying the most critical assumption for the operational employment of the proposed technique. As expected, when the DASVM started from a solution that did not adequately model the source-domain classification problem, the system could not recover a solution consistent with $\mathrm{D}</em>\right]$ ). It is possible to notice that, for small values of $\phi$, the proposed circular strategy identified more than one half of correct solutions, while, by increasing $\phi$ values, the number of correct solutions properly recognized gradually decreased. This is a reasonable behavior if we consider that the distance between distributions sharply increases and learning parameters are not optimized for the backward process.}$, thus $P(\bar{A} \mid \bar{D})=0$. Table 3 also reports the probability of correct validation of solutions consistent with $\mathrm{D}_{t}, P(\bar{A} \mid \bar{B})$, for the cases in which it was possible to obtain at least one of them in the forward learning phase (i.e., $\phi \in\left[10^{\circ} ; 50^{\circ</p>
<p>Fig. 5 shows some examples of the empirical estimated probability distribution $\hat{P}(O A \%)$ of the $O A \%$ for the solutions obtained for source-domain data at the end of the backward learning process when the system starts from both state $\bar{B}$ (black line) and state $\bar{D}$ (gray line). If we consider as</p>
<p>TABLE 3
Problem I: Percentage Overall Accuracy Exhibited on Target-Domain Instances for Different Rotation Angles</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Rotation Angle</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$10^{\circ}$</td>
<td style="text-align: center;">$15^{\circ}$</td>
<td style="text-align: center;">$20^{\circ}$</td>
<td style="text-align: center;">$25^{\circ}$</td>
<td style="text-align: center;">$30^{\circ}$</td>
<td style="text-align: center;">$35^{\circ}$</td>
<td style="text-align: center;">$40^{\circ}$</td>
<td style="text-align: center;">$45^{\circ}$</td>
<td style="text-align: center;">$50^{\circ}$</td>
<td style="text-align: center;">$55^{\circ}$</td>
<td style="text-align: center;">$60^{\circ}$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">SVM ${ }^{\text {CV }}$</td>
<td style="text-align: center;">99.67</td>
<td style="text-align: center;">96.67</td>
<td style="text-align: center;">89.33</td>
<td style="text-align: center;">77.67</td>
<td style="text-align: center;">62.00</td>
<td style="text-align: center;">52.33</td>
<td style="text-align: center;">43.67</td>
<td style="text-align: center;">37.33</td>
<td style="text-align: center;">32.67</td>
<td style="text-align: center;">29.33</td>
<td style="text-align: center;">28.67</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">DASVM ${ }^{\text {best }}$</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">57.33</td>
<td style="text-align: center;">52.33</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">DASVM ${ }^{\text {sinc }}$</td>
<td style="text-align: center;">99.76</td>
<td style="text-align: center;">99.17</td>
<td style="text-align: center;">99.33</td>
<td style="text-align: center;">99.71</td>
<td style="text-align: center;">99.64</td>
<td style="text-align: center;">99.72</td>
<td style="text-align: center;">96.19</td>
<td style="text-align: center;">98.54</td>
<td style="text-align: center;">96.03</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$P(\bar{A} \mid \bar{B})$</td>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.51</td>
<td style="text-align: center;">0.50</td>
<td style="text-align: center;">0.48</td>
<td style="text-align: center;">0.45</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">0.22</td>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">(a)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Rotation Angle</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$10^{\circ}$</td>
<td style="text-align: center;">$15^{\circ}$</td>
<td style="text-align: center;">$20^{\circ}$</td>
<td style="text-align: center;">$25^{\circ}$</td>
<td style="text-align: center;">$30^{\circ}$</td>
<td style="text-align: center;">$35^{\circ}$</td>
<td style="text-align: center;">$40^{\circ}$</td>
<td style="text-align: center;">$45^{\circ}$</td>
<td style="text-align: center;">$50^{\circ}$</td>
<td style="text-align: center;">$55^{\circ}$</td>
<td style="text-align: center;">$60^{\circ}$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{ML}_{\text {retrain }}$</td>
<td style="text-align: center;">99.67</td>
<td style="text-align: center;">98.67</td>
<td style="text-align: center;">96.33</td>
<td style="text-align: center;">94.33</td>
<td style="text-align: center;">92.00</td>
<td style="text-align: center;">89.33</td>
<td style="text-align: center;">84.67</td>
<td style="text-align: center;">80.00</td>
<td style="text-align: center;">65.33</td>
<td style="text-align: center;">54.00</td>
<td style="text-align: center;">51.33</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{ML}_{\text {cascade }}$</td>
<td style="text-align: center;">99.67</td>
<td style="text-align: center;">98.33</td>
<td style="text-align: center;">97.33</td>
<td style="text-align: center;">94.67</td>
<td style="text-align: center;">93.33</td>
<td style="text-align: center;">89.67</td>
<td style="text-align: center;">86.00</td>
<td style="text-align: center;">78.33</td>
<td style="text-align: center;">67.67</td>
<td style="text-align: center;">54.67</td>
<td style="text-align: center;">51.00</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>(b)
(a) Percentage OA exhibited by: 1) A supervised SVM trained on source-domain samples according to a 10-fold CV strategy (SVM ${ }^{\mathrm{CV}}$ ); 2) the proposed DASVM technique with optimal selection of learning parameters ( $D A S V M^{\text {best }}$ ). The average accuracy associated with the consistent solutions obtained by the proposed DASVM technique and correctly identified by the circular validation strategy (DASVM ${ }^{\text {sinc }}$ ) and the probability $P(\bar{A} \mid B)$ of identifying consistent solutions with the proposed circular validation strategy are also given. (b) Percentage OA exhibited by: 1) The retraining technique for maximum likelihood classifier ( $M L_{\text {retrain }}$ ); 2) the maximum likelihood cascade classifier ( $M L_{\text {cascade }}$ ).</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 5. Problem I: Empirical estimated probability distribution $\hat{P}(O A \%)$ of the percentage overall accuracy ( $O A \%$ ) for the solutions obtained on the source domain when the system starts from both state $\bar{D}$ (black line) and state $\bar{D}$ (gray line) for (a) $\phi=10^{\circ}$, (b) $\phi=20^{\circ}$, (c) $\phi=30^{\circ}$, (d) $\phi=40^{\circ}$, and (e) $\phi=50^{\circ}$. If $O A \%&lt;85$, the system moves to state $\bar{C}$; if $O A \% \geq 85$, the system moves to state $\bar{A}$.
an example Fig. 2b (which refers to the case $\phi=20^{\circ}$ ), we can see that $q_{0.85}(O A \%)$ (i.e., the quantile corresponding to $O A \%<em _h="(h">{(h}=85)$ is equal to 0.48 . Accordingly, as the systems move to state $\bar{C}$ if $O A \%&lt;O A \%</em>$, we can see that it is comparable with that obtained with optimal selection of leaning parameters, thus confirming the effectiveness of the proposed circular validation strategy.}$, we have that $P(\bar{C} \mid \bar{B})=$ $q_{0.85}(O A \%)=0.48$; therefore, $P(\bar{A} \mid \bar{B})=1-P(\bar{C} \mid \bar{B})$, which means that the classifier can go back to state $\bar{A}$ in the 52 percent of the cases. The very important conclusion of this analysis is that even in critical situations, the proposed circular validation strategy was able to identify correct solutions without considering any prior information on the labels of target-domain data. Moreover, if we consider the average $O A \%$ of solutions correctly identified as consistent with $\mathrm{D}_{t</p>
<h3>6.2 Problem II: Brain Computer Interface Data Set</h3>
<p>The second data set considered refers to a Brain Computer Interface (BCI) problem. A BCI is an assistive communication system, which helps people with severe disabilities to realize the control of motor neuroprotheses. The data set we considered was made up of electrocorticogram (ECoG) signals recorded from the same subject performing the same task in two different days (i.e., at times $t_{1}$ and $t_{2}$ ) with about one week in between. In the considered case, the subject had to perform imagined movements of either the left small finger or the tongue (associated with the classes $\omega_{1}$ and $\omega_{2}$, respectively) for at least 3 seconds. For greater details about this data set, the reader is referred to [43], [44]. It is worth noting that the design of a classifier for a BCI system is very challenging when a classifier trained on data
acquired on a certain day should classify data recorded in other days without retraining. On one hand, the patient might be in a different state concerning motivation, fatigue, etc. Therefore, his brain will show different electrical activity. On the other hand, the recording system might have undergone slight changes concerning electrode positions and impedances.</p>
<p>Fig. 6a presents the system designed for extracting the features used in our experiments. Original ECoG signals were first low-pass ( $0-3 \mathrm{~Hz}$ ) and band-pass ( $8-30 \mathrm{~Hz}$ ) filtered in order to acquire movement-related potentials (MRD) and event-related desynchronization (ERD) signals, respectively, which are electrical physiological phenomena activated by limb movements or imagined movements [45], [46]. Then, we used the common spatial subspace decomposition (CSSD) technique, which allows us to extract signal components specific to one condition and eliminate background activities [47]. For both frequency intervals, we selected the two components that, according to the CSSD technique, are more related to the considered information classes. The final data set is obtained by merging together these two pairs of features. For the source domain at time $t_{1}$, the brain activity was monitored for 278 events (139 associated with each information class), whereas, for the target domain at time $t_{2}, 100$ events were considered ( 50 for each information class).</p>
<p>The resulting domain adaptation problem proved to be particularly challenging, as confirmed by the values for the $D_{J S}$ reported in Table 4. Source and target-domain overall distributions were rather different ( 0.408 ), but the gap was even more relevant for the conditional class distributions ( 0.625 for the class $\omega_{1}$ and 0.616 for the class $\omega_{2}$ ). Even in such critical conditions, the DASVM algorithm proved effective</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 6. Problem II: (a) Architecture of the system employed for extracting the features used in the experiments. (b) Empirical estimated probability distribution $P(O A\%)$ of the percentage overall accuracy (OA\%) for the solutions obtained on the source domain when the system starts from both state $B$ (black line) and state $D$ (gray line). If $O A \%&lt;85$, the system moves to state $\bar{C}$; if $O A \% \geq 85$, the system moves to state $\bar{A}$.</p>
<p>TABLE 4
Problem II: Jensen-Shannon Divergence Values</p>
<table>
<thead>
<tr>
<th style="text-align: center;">$D_{i 0}\left[P^{\prime}(\mathbf{x}), P^{\prime}(\mathbf{x})\right]$</th>
<th style="text-align: center;">$D_{i 1}\left[P^{\prime}\left(\mathbf{x} \mid \omega_{i}\right), P^{\prime}\left(\mathbf{x} \mid \omega_{i}\right)\right]$</th>
<th style="text-align: center;">$D_{i 0}\left[P^{\prime}\left(\mathbf{x} \mid \omega_{i}\right), P^{\prime}\left(\mathbf{x} \mid \omega_{i}\right)\right]$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">0.408</td>
<td style="text-align: center;">0.625</td>
<td style="text-align: center;">0.616</td>
</tr>
</tbody>
</table>
<p>TABLE 5
Problem II: Percentage Overall Accuracy (OA\%) Exhibited on Target-Domain Instances by:</p>
<p>1) a Supervised SVM Trained on Source-Domain Instances According to a 10-Fold CV Strategy (SVM ${ }^{\mathrm{CV}}$ );
2) the Proposed DASVM Technique with Optimal Selection of Learning Parameters (DASVM ${ }^{\text {best }}$ );
3) the Maximum Likelihood Classifier ( $\mathrm{ML}<em _cascade="{cascade" _text="\text">{\text {retruin }}$ ); and 4) the Maximum Likelihood Cascade Classifier ( $\mathrm{ML}</em>$ )}</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">SVM $^{\text {CV }}$</th>
<th style="text-align: center;">DASVM $^{\text {best }}$</th>
<th style="text-align: center;">DASVM $^{\text {star }}$</th>
<th style="text-align: center;">ML $_{\text {retruin }}$</th>
<th style="text-align: center;">ML $_{\text {cascade }}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$O A \%$</td>
<td style="text-align: center;">79.00</td>
<td style="text-align: center;">93.00</td>
<td style="text-align: center;">91.65</td>
<td style="text-align: center;">88.00</td>
<td style="text-align: center;">87.00</td>
</tr>
</tbody>
</table>
<p>The average accuracy associated with the consistent solutions obtained by the proposed DASVM technique and correctly identified by the circular validation strategy (DASVM ${ }^{\text {sec }}$ ) is also given.
(see Table 5). In particular, in the best case, we were able to obtain an $O A \%$ equal to 93.00 , which corresponds to an increase of +14.00 with respect to the $O A \%$ yielded with the standard supervised SVM trained according to the 10 -fold CV strategy at time $t_{1}$. Moreover, DASVMs provided also higher $O A \%$ than both $\mathrm{ML}<em _cascade="{cascade" _text="\text">{\text {retruin }}(+5)$ and $\mathrm{ML}</em>$, thus exhibiting the crucial property to be always able to reject wrong solutions.}}(+6)$. The proposed technique exhibited a very good capability of seizing the structure of the investigated domain adaptation problem, as it is possible to infer from the behavior of $\hat{P}(O A \%)$ (see Fig. 6b). In particular, with the circular validation strategy, we were able to correctly identify 66 percent of solutions consistent at time $t_{2}$ (i.e., $q_{0.85}(O A \%)=0.44)$ with an average $O A \%$ equal to 91.65 ( +11.65 with respect to the supervised SVM). This means that it was possible to recover a satisfactory accuracy for source-domain data only starting from high accuracies for target-domain data, thus confirming that solutions are correctly validated as consistent only if the target-domain problem is well modeled. Accordingly, also for this data set, the system never moved back from state $D$ to state $\bar{A</p>
<h3>6.3 Problem III: Remote Sensing Data Set</h3>
<p>The third set of experiments was carried out on a multiclass problem in the context of a remote sensing application. We investigated the task of automatic updating of land-cover
maps by classification of remote sensing images acquired over the same geographical area at two different times $t_{1}$ and $t_{2}$. We considered two coregistered multispectral images acquired in September 1995 and July 1996 by the Thematic Mapper (TM) sensor of the Landsat 5 Satellite (see Figs. 7a and 7b). The selected test site was a section of about $11.7 \mathrm{~km} \times 10.8 \mathrm{~km}$ (i.e., $412 \times 382$ pixels) of a scene including Lake Mulargia on the Island of Sardinia, Italy. The five information classes that characterized the investigated site at both times were taken into account, i.e., forest, pasture, urban area, water body, and vineyard. For both source and target-domain problems, the same number of samples was considered for each information class (see Table 6). It is worth noting that, due to many differences at the two acquisition times (e.g., different acquisition system state, dissimilar illumination conditions, alterations in the phenologic state of vegetation, changes occurred on the ground, etc.), the distance between spectral distributions of the two images is considerable.</p>
<p>Among the seven available spectral bands, as commonly done in the literature, we did not take into account band 6, which corresponds to the low-resolution channel acquired in the thermal infrared. In order to characterize the texture properties of the considered classes and to exploit the distribution-free nature of SVMs, we extracted five texture features based on the gray-level co-occurrence matrix (i.e.,</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Fig. 7. Problem III: Spectral channel 5 of the multispectral Landsat-5 Thematic Mapper images used in the experiments. (a) Image acquired in September 1995. (b) Image acquired in July 1996. (c) Empirical estimated probability distribution $P(O A \%)$ of the percentage overall accuracy ( $O A \%$ ) for the solutions obtained on the source domain when the system starts from both state $B$ (black line) and state $D$ (gray line). If $O A \%&lt;85$, the system moves to state $C$; if $O A \% \geq 85$, the system moves to state $A$.</p>
<p>TABLE 6
Problem III: Number of Both Source-Domain (September 1995 Image) and Target-Domain (July 1996 Image) Patterns and Jensen-Shannon Divergence Values</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Pasture</th>
<th style="text-align: center;">Forest</th>
<th style="text-align: center;">Urban Area</th>
<th style="text-align: center;">Water Body</th>
<th style="text-align: center;">Vineyard</th>
<th style="text-align: center;">Overall</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Number of Patterns</td>
<td style="text-align: center;">$1143(27.23 \%)$</td>
<td style="text-align: center;">$578(13.77 \%)$</td>
<td style="text-align: center;">$826(19.68 \%)$</td>
<td style="text-align: center;">$1355(32.27 \%)$</td>
<td style="text-align: center;">$296(7.05 \%)$</td>
<td style="text-align: center;">4198</td>
</tr>
<tr>
<td style="text-align: center;">$D_{J S}$</td>
<td style="text-align: center;">0.517</td>
<td style="text-align: center;">0.278</td>
<td style="text-align: center;">0.391</td>
<td style="text-align: center;">0.423</td>
<td style="text-align: center;">0.567</td>
<td style="text-align: center;">0.391</td>
</tr>
</tbody>
</table>
<p>TABLE 7
Problem III: Percentage Overall Accuracy ( $O A \%$ ), Producer's Accuracies ( $P A \%$ ), and User's Accuracies ( $U A \%$ ) Exhibited on Target-Domain Instances by: 1) a Supervised SVM Trained on Source-Domain Instances
According to a 10-Fold CV Strategy (SVM ${ }^{\text {CT }}$ ); 2) the Proposed DASVM Technique with Optimal Selection of Learning Parameters (DASVM ${ }^{\text {best }}$ ); 3) the Retraining Technique for the Maximum Likelihood Classifier ( $\mathrm{ML}<em _cascade="{cascade" _text="\text">{\text {retrain }}$ ), and 4) the Maximum Likelihood Cascade Classifier ( $\mathrm{ML}</em>$ )}</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">$O A \%$</th>
<th style="text-align: center;">Pasture</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Forest</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Urban Area</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Water Body</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Vineyard</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$P A \%$</td>
<td style="text-align: center;">$U A \%$</td>
<td style="text-align: center;">$P A \%$</td>
<td style="text-align: center;">$U A \%$</td>
<td style="text-align: center;">$P A \%$</td>
<td style="text-align: center;">$U A \%$</td>
<td style="text-align: center;">$P A \%$</td>
<td style="text-align: center;">$U A \%$</td>
<td style="text-align: center;">$P A \%$</td>
<td style="text-align: center;">$U A \%$</td>
</tr>
<tr>
<td style="text-align: center;">SVM $^{\text {CT }}$</td>
<td style="text-align: center;">75.73</td>
<td style="text-align: center;">26.86</td>
<td style="text-align: center;">85.28</td>
<td style="text-align: center;">98.10</td>
<td style="text-align: center;">79.30</td>
<td style="text-align: center;">87.17</td>
<td style="text-align: center;">99.72</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">96.85</td>
<td style="text-align: center;">77.70</td>
<td style="text-align: center;">22.95</td>
</tr>
<tr>
<td style="text-align: center;">DASVM ${ }^{\text {best }}$</td>
<td style="text-align: center;">94.78</td>
<td style="text-align: center;">90.64</td>
<td style="text-align: center;">94.35</td>
<td style="text-align: center;">98.27</td>
<td style="text-align: center;">96.92</td>
<td style="text-align: center;">92.49</td>
<td style="text-align: center;">99.87</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">86.82</td>
<td style="text-align: center;">65.22</td>
</tr>
<tr>
<td style="text-align: center;">DASVM ${ }^{\text {sov }}$</td>
<td style="text-align: center;">90.88</td>
<td style="text-align: center;">79.79</td>
<td style="text-align: center;">92.49</td>
<td style="text-align: center;">98.10</td>
<td style="text-align: center;">86.83</td>
<td style="text-align: center;">89.71</td>
<td style="text-align: center;">99.86</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">81.08</td>
<td style="text-align: center;">51.95</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{ML}_{\text {retrain }}$</td>
<td style="text-align: center;">92.76</td>
<td style="text-align: center;">94.06</td>
<td style="text-align: center;">88.50</td>
<td style="text-align: center;">87.22</td>
<td style="text-align: center;">88.19</td>
<td style="text-align: center;">93.06</td>
<td style="text-align: center;">97.49</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">64.10</td>
<td style="text-align: center;">73.53</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{ML}_{\text {cascade }}$</td>
<td style="text-align: center;">91.48</td>
<td style="text-align: center;">94.25</td>
<td style="text-align: center;">83.53</td>
<td style="text-align: center;">90.51</td>
<td style="text-align: center;">97.45</td>
<td style="text-align: center;">81.48</td>
<td style="text-align: center;">95.69</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">86.90</td>
<td style="text-align: center;">62.39</td>
</tr>
</tbody>
</table>
<p>The average accuracies associated with the consistent solutions obtained by the proposed DASVM technique and correctly identified by the circular validation strategy (DASVM ${ }^{\text {cor }}$ ) are also given.
correlation, sum average, sum variance, difference variance, and entropy) and added them to the six TM channels. As the images were acquired in different periods of the year, the resulting overall $D_{J S}$ distance between source-domain distribution at time $t_{1}$ and target-domain distribution at time $t_{2}$ was considerable (i.e., 0.391 ). The complexity of the investigated domain adaptation problem is stressed up by the distances between conditional class distribution at the two dates, which assume high values, in particular, for the classes pasture (i.e., 0.517 ) and vineyard (i.e., 0.567 ). As pointed out in Section 3, one of the constraints imposed by the DASVM algorithm is the use of the OAA multiclass architecture; therefore, we adopted the same multiclass strategy also when dealing with supervised SVMs used for comparisons.</p>
<p>Table 7 shows the results obtained in terms of $O A \%$ and both percentage producer's and user's accuracies ${ }^{5}$ (i.e., $P A \%$ and $U A \%$, respectively) for each information class. Taking into account the complexity of the problem under investigation, the obtained classification accuracies confirmed also in this case the good adaptation capabilities of the proposed DASVM technique, which was able to sharply increase the accuracy with respect to the supervised SVM trained according to a 10 -fold CV on sourcedomain samples. In particular, in the best case, the $O A \%$
5. For each specific information class: 1) Producer's accuracy is defined as the ratio between the number of samples correctly classified as belonging to that class and the total number of reference samples available for that class; 2) user's accuracy is defined as the ratio between the number of samples correctly classified as belonging to that class and the total number of samples classified as belonging to that class.</p>
<p>increased up to 94.78 (i.e., +19.05 ). Moreover, the improvement in the $P A \%$ is huge for pasture (i.e., +63.78 ) and remarkable for vineyard ( +9.12 ), whereas the increase in the $U A \%$ is noteworthy for vineyard (i.e., +42.27 ), forest $(+17.62)$, and pasture $(+9.07)$.</p>
<p>Also, in this case, DASVMs exhibited higher accuracies than $\mathrm{ML}<em _cascade="{cascade" _text="\text">{\text {retrain }}$ and $\mathrm{ML}</em>(+2.02$ and +3.03 in terms of $O A \%$ for optimal selection of learning parameters), thus confirming their effectiveness also when addressing multiclass problems.}</p>
<p>Fig. 7c points out the effectiveness of the proposed circular validation strategy also on this data set. This strategy allowed us to correctly reject all of the solutions that were not consistent with $\mathrm{D}<em 0.85="0.85">{t}$. In addition, when the system started from state $\bar{B}$, we had $q</em>$ was particularly high. This is confirmed by the high average $O A \%$ obtained for target-domain instances for the solutions correctly identified as consistent by the validation strategy. The average $O A \%$ is equal to $90.88(+15.15$ with respect to the supervised SVM), whereas as concerns both $P A \%$ and $U A \%$, the behavior is similar to that obtained for the best case described above. In particular, the increase in pasture $P A \%$ and vineyard $U A \%$ is considerable (i.e., +52.93 and +29.00 , respectively).}(O A \%)=0.51$, which corresponds to almost one-half (i.e., 49 percent) of consistent solutions properly validated without any prior information for the image at time $t_{2}$. It is worth noting that, in most part of the cases, the system moved back to state $\bar{A}$ when the classification accuracy at $t_{2</p>
<h2>7 Discussion and Conclusion</h2>
<p>In this paper, we have addressed domain adaptation problems by introducing two main novel contributions: 1) a domain adaptation classifier based on SVMs (DASVM) and 2) a circular strategy aimed at validating the results obtained with a domain adaptation classifier.</p>
<p>The proposed DASVM technique extends the principles of SVMs to the domain adaptation framework by taking into account that unlabeled test samples are drawn from a target domain $\mathrm{D}<em s="s">{t}$ different from the source domain $\mathrm{D}</em>}$ of training samples. Labeled patterns drawn from $\mathrm{D<em t="t">{s}$ are used only for constraining the learning phase of the classifier, but the final solution only models the structure of $\mathrm{D}</em>}$. In particular, labeled source-domain data are employed for determining an initial discriminant function for the target-domain problem; then, unlabeled samples from $\mathrm{D<em s="s">{t}$ are exploited for properly adjusting the decision function, while samples from $\mathrm{D}</em>$ are gradually erased. The final classification function is determined only on the basis of semilabeled samples, i.e., originally unlabeled target-domain instances that obtain labels during the learning process. For better controlling the behavior and stability of the classifier, an adaptive weighting strategy for the regularization parameters based on a temporal criterion is adopted. This permits us to tune the influence of unlabeled patterns and, in general, prevents the system from converging to improper solutions.</p>
<p>It is worth noting that the proposed DASVM is designed for addressing a problem conceptually different from those faced by transductive and semi-supervised SVMs, which have been defined for handling problems where labeled
and unlabeled data are drawn from the same domain. Thus, they are ineffective in domain adaptation, where training data are assumed to be available only for a source domain different (even if related) from the target domain of the (unlabeled) test samples.</p>
<p>As for transductive and semi-supervised SVMs, also for DASVMs it is not possible to guarantee for obtaining reliable solutions to the classification problem. In fact, if the accuracy after the initialization phase is particularly low (i.e., most of the unlabeled target-domain samples are incorrectly classified at the beginning of the learning process), it becomes difficult to obtain satisfactory performances. The convergence of the algorithm to a consistent solution depends on the intrinsic correlation between the two domains: The farther $\mathrm{D}<em s="s">{t}$ is from $\mathrm{D}</em>}$, the harder the resulting domain adaptation problem. This correlation can be measured by computing similarity metrics between $\mathrm{D<em t="t">{s}$ and $\mathrm{D}</em>$.</p>
<p>In the framework of domain adaptation, due to the absence of prior information for target-domain instances, standard statistical validation strategies proposed in the literature cannot be used for assessing the effectiveness of learning and the validity of the resulting classifier. In this context, we proposed an indirect circular validation strategy based on the idea that an intrinsic structure relates the solutions consistent with $\mathrm{D}<em t="t">{s}$ and $\mathrm{D}</em>$ (for which no prior information is available) is assumed to be consistent if the solution obtained by applying the same domain adaptation learning algorithm in the reverse sense (i.e., using the classification labels in place of missing prior knowledge for target-domain instances) to source-domain data (considered as unlabeled in the reverse domain adaptation learning) is associated with an acceptable accuracy (which can be evaluated due to the available true labels for source-domain samples).}$. A solution for $\mathrm{D}_{t</p>
<p>From the analysis of experimental results obtained on a series of two-dimensional toy problems and on two real problems defined in the context of brain computer interface and remote sensing, we can conclude that the presented DASVM resulted in high and satisfactory classification accuracy, outperforming other state-of-the-art domain adaptation techniques. Several trials also confirmed the effectiveness of the proposed circular validation strategy, which always proved able to reject solutions that were not consistent with the investigated classification task and identified acceptable solutions for $\mathrm{D}_{t}$ even in very critical conditions. In this framework, the joint use of both the proposed DASVM classification technique and the circular validation strategy seems particularly suitable to define systems capable of solving real application problems.</p>
<p>As a final remark, it is worth noting that, from a computational viewpoint, each iteration of the DASVMs requires a time equivalent to that taken from the learning of a supervised SVM. In fact, as the number of target-domain semilabeled patterns increases, the number of sourcedomain labeled patterns decreases; therefore, the cardinality of the training set does not increase with the number of iterations. Accordingly, it is possible to state that the computational load grows linearly with the number of iterations. In general, the computational time is comparable to the one of semi-supervised methods and higher than the</p>
<p>one required by supervised SVMs (on average, a hundred of iterations for each binary DASVM are needed). Nevertheless, taking into account both the very promising results obtained and the complexity of the investigated problems, we can consider this cost reasonable.</p>
<h2>AcKnowledGMENTS</h2>
<p>The authors would like to thank the associate editor and the anonymous reviewers for their valuable comments.</p>
<h2>REFERENCES</h2>
<p>[1] R. Caruana, "Multitask Learning," Machine Learning J., vol. 28, no. 1, pp. 41-75, 1997.
[2] S. Thrun and L.Y. Pratt, Learning to Learn. Kluwer Academic Publishers, 1998.
[3] S. Ben-David and R. Schuller, "Exploiting Task Relatedness for Multiple Task Learning," Proc. 16th Ann. Conf. Learning Theory, 2003.
[4] B. Zadrozny, "Learning and Evaluating Classifiers under Sample Selection Bias," Proc. 21st Int'l Conf. Machine Learning, 2004.
[5] M. Dudik, R.E. Schapire, and J.S. Philips, "Correcting Sample Selection Bias in Maximum Entropy Density Estimation," Advances in Neural Information Processing Systems 17, MIT Press, 2005.
[6] J. Huang, A. Smola, A. Gretton, K.M. Borgwardt, and B. Schölkopf, "Correcting Sample Selection Bias by Unlabeled Data," Advances in Neural Information Processing Systems 20, MIT Press, 2007.
[7] H. Shimodaira, "Improving Predictive Inference under Covariate Shift by Weighting the Loglikelihood Function" J. Statistical Planning and Inference, vol. 90, pp. 227-244, 2000.
[8] M. Sugiyama and K.R. Müller, "Input-Dependent Estimation of Generalization Error under Covariate Shift," Statistics and Decisions, vol. 23, pp. 249-279, 2005.
[9] H. Jeffreys, "An Invariant Form for the Prior Probability in Estimation Problems," Proc. Royal Soc. London, vol. 186, pp. 453461, 1946.
[10] S. Kullback and R. Leibler, "On Information and Sufficiency," Annals of Math. Statistics, vol. 22, pp. 79-86, 1951.
[11] J. Lin, "Divergence Measures Based on the Shannon Entropy," IEEE Trans. Information Theory, vol. 37, pp. 145-151, 1991.
[12] V.N. Vapnik, Statistical Learning Theory. John Wiley \&amp; Sons, Inc., 1998.
[13] V.N. Vapnik, The Nature of Statistical Learning Theory, second ed. Springer-Verlag, 1995.
[14] M. Pontil and A. Verri, "Support Vector Machines for 3D Object Recognition," IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 20, no. 6, pp. 637-646, June 1998.
[15] G. Ratsch, S. Mika, B. Schölkopf, and K.R. Muller, "Constructing Boosting Algorithms from SVMs: An Application to One-Class Classification," IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 24, no. 9, pp. 1184-1199, Sept. 2002.
[16] K. In Kim, K. Jung, S.H. Park, and H.J. Kim, "Support Vector Machines for Texture Classification," IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 24, no. 11, pp. 1542-1550, Nov. 2002.
[17] K.P. Bennett and A. Demiriz, "Semi-Supervised Support Vector Machines," Advances in Neural Information Processing Systems, vol. 10, pp. 368-374, MIT Press, 1998.
[18] G. Fung and O.L. Mangasarian, "Semi-Supervised Support Vector Machines for Unlabeled Data Classification," Optimization Methods and Software, vol. 15, no. 1, 2001.
[19] X. Zhu, "Semi-Supervised Learning Literature Survey," TR-1530, Computer Sciences, Univ. of Wisconsin-Madison, 2005.
[20] T. Joachims, "Transductive Inference for Text Classification Using Support Vector Machines," Proc. 16th Int'l Conf. Machine Learning, 1999.
[21] Y. Chen, G. Wang, and S. Dong, "Learning with Progressive Transductive Support Vector Machine," Pattern Recognition Letters, vol. 24, no. 12, pp. 1845-1855, 2003.
[22] R. Hwa, "Supervised Grammar Induction Using Training Data with Limited Constituent Information," Proc. 37th Ann. Meeting of the Assoc. for Computational Linguistics, 1999.
[23] D. Gildea, "Corpus Variation and Parser Performance," Proc. 2001 Conf. Empirical Methods in Natural Language Processing, 2001.
[24] B. Roark and M. Bacchiani, "Supervised and Unsupervised PCFG Adaptation to Novel Domains," Proc. 2003 Conf. North Am. Chapter of the Assoc. for Computational Linguistics and Human Language Technology, 2003.
[25] X. Li and J. Bilmes, "A Bayesian Divergence Prior for Classifier Adaptation," Proc. 11th Int'l Conf. Artificial Intelligence and Statistics, 2007.
[26] C. Chelba and A. Acero, "Adaptation of Maximum Entropy Capitalizer: Little Data Can Help a Lot," Proc. 2004 Conf. Empirical Methods in Natural Language Processing, 2004.
[27] H. Daumé III and D. Marcu, "Domain Adaptation for Statistical Classifiers," J. Artificial Intelligence Research, vol. 26, pp. 101-126, 2006.
[28] J. Jiang and C. Zhai, "Instance Weighting for Domain Adaptation in NLP," Proc. 45th Ann. Meeting of the Assoc. for Computational Linguistics, 2007.
[29] R. Florian, H. Hassan, A. Ittycheriah, H. Jing, N. Kambhatla, X. Luo, N. Nicolov, and S. Roukos, "A Statistical Model for Multilingual Entity Detection and Tracking," Proc. 2004 Conf. North Am. Chapter of the Assoc. for Computational Linguistics and Human Language Technology, 2004.
[30] H. Daumé III, "Frustratingly Easy Domain Adaptation," Proc. 45th Ann. Meeting of the Assoc. for Computational Linguistics, 2007.
[31] J. Blitzer, R. McDonald, and F. Pereira, "Domain Adaptation with Structural Correspondence Learning," Proc. 2006 Conf. Empirical Methods in Natural Language Processing, 2006.
[32] S. Ben-David, J. Blitzer, K. Crammer, and F. Pereira, "Analysis of Representation for Domain Adaptation," Advances in Neural Information Processing Systems 19, MIT Press, 2006.
[33] S. Satpal and S. Sarawagi, "Domain Adaptation of Conditional Probability Models via Feature Subsetting," Proc. 11th European Conf. Principles and Practice of Knowledge Discovery in Databases, 2007.
[34] W. Dai, G.R. Xue, Q. Yang, and Y. Yu, "Transferring Naïve Bayes Classifier for Text Classification," Proc. 22nd Nat'l Conf. Artificial Intelligence, 2007.
[35] W. Dai, G.R. Xue, Q. Yang, and Y. Yu, "Co-Clustering Based Classification for Out-of-Domain Documents," Proc. ACM SIGKDD, 2007.
[36] L. Bruzzone and D. Fernández Prieto, "Unsupervised Retraining of a Maximum-Likelihood Classifier for the Analysis of Multitemporal Remote-Sensing Images," IEEE Trans. Geosciences and Remote Sensing, vol. 39, pp. 456-460, 2001.
[37] L. Bruzzone and D. Fernández Prieto, "A Partially Unsupervised Approach to the Automatic Classification of Multitemporal Remote-Sensing Images," Pattern Recognition Letters, vol. 33, no. 9, pp. 1063-1071, 2002.
[38] L. Bruzzone and R. Cossu, "A Multiple-Cascade-Classifier System for a Robust and Partially Unsupervised Updating of Land-Cover Maps," IEEE Trans. Geosciences and Remote Sensing, vol. 40, no. 9, pp. 1984-1996, Sept. 2002.
[39] L. Bruzzone, R. Cossu, and G. Vernazza, "Combining Parametric and Non-Parametric Algorithms for a Partially Unsupervised Classification of Multitemporal Remote-Sensing Images," Information Fusion, vol. 3, no. 4, pp. 289-297, 2002.
[40] S. Tajudin and D. Landgrebe, "Robust Parameter Estimation for Mixture Model," IEEE Trans. Geoscience and Remote Sensing, vol. 38, pp. 439-445, 2000.
[41] N. Cristianini and J. Shawe-Taylor, An Introduction to Support Vector Machines. Cambridge Univ. Press, 2000.
[42] J. Platt, "Fast Training of Support Vector Machines Using Sequential Minimal Optimization," Advances in Kernel Methods: Support Vector Learning, B. Schölkopf, C. Burges, and A. Smola, eds., pp. 185-208, MIT Press, 1998.
[43] http://ida.first.traunhofer.de/projects/bci/competition_iii/, 2008.
[44] T. Lal, T. Hinterberger, G. Widman, M. Schröder, J. Hill, W. Rosenstiel, C. Elger, B. Schölkopf, and N. Birbaumer, "Methods Towards Invasive Human Brain Computer Interfaces," Advances in Neural Information Processing Systems 17, MIT Press, 2004.
[45] C. Toro, G. Deuschl, R. Thatcher, S. Sato, C. Kufta, and M. Hallett, "Event-Related Desynchronization and Movement-Related Cortical Potentials on the ECoG and EEG," Electroencephalography and Clinical Neurophysiology, vol. 93, pp. 380-389, 1994.</p>
<p>[46] C. Babiloni, F. Carducci, F. Cincotti, P.M. Rossini, C. Neuper, G. Pfurtscheller, and F. Babiloni, "Human Movement-Related Potentials vs Desynchronization of EEG Alpha Rhythm: A HighResolution EEG Study," Neuroimage, vol. 10, pp. 658-665, 1999.
[47] Y. Wang, P. Berg, and M. Scherg, "Common Spatial Subspace Decomposition Applied to Analysis of Brain Responses Under Multiple Task Conditions: A Simulation Study," Clinical Neurophysiology, vol. 110, pp. 604-614, 1999.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Lorenzo Bruzzone received the laurea (MS) degree in electronic engineering (summa cum laude) and the PhD degree in telecommunications from the University of Genoa, Italy, in 1993 and 1998, respectively. He is currently a full professor of telecommunications at the University of Trento, Italy, where he teaches remote sensing, pattern recognition, radar, and electrical communications. His current research interests are in the areas of remote sensing, signal processing, and pattern recognition (analysis of multitemporal images, feature extraction and selection, classification, regression and estimation, data fusion, machine learning). He conducts and supervises research on these topics within the frameworks of several national and international projects. He is the author (or coauthor) of 86 scientific publications in refereed international journals ( 58 in IEEE journals), more than 140 papers in conference proceedings, and 11 book chapters. He is editor/coeditor of nine books/conference proceedings. He is a referee for many international journals and has served on the scientific committees of several international conferences. He is a member of the managing committee of the Italian Interuniversity Consortium on Telecommunications and a member of the scientific committee of the India-Italy Center for Advanced Research. Since 2009, he has been a member of the administrative committee of the IEEE Geoscience and Remote Sensing Society. He ranked first place in the Student Prize Paper Competition of the 1998 IEEE International Geoscience and Remote Sensing Symposium (Seattle, July 1998). He was a recipient of the Recognition of the IEEE Transactions on Geoscience and Remote Sensing Best Reviewers in 1999 and was a guest coeditor of several special issues of the IEEE Transactions on Geoscience and Remote Sensing. He was the general chair and cochair of the First and Second IEEE International Workshops on the Analysis of Multitemporal Remote Sensing Images (MultiTemp), and is currently a member of the permanent steering committee of this series of workshops. Since 2003, he has been the chair of the SPIE Conference on Image and Signal Processing for Remote Sensing. From 2004 to 2006, he served as an associate editor of the IEEE Geoscience and Remote Sensing Letters and currently is an associate editor for the IEEE Transactions on Geoscience and Remote Sensing and the Canadian Journal of Remote Sensing. In 2008 he was appointed a member of the joint NASA/ESA Science Definition Team for Outer Planet Flagship Missions. He is also a member of the International Association for Pattern Recognition and the Italian Association for Remote Sensing (AIT). He is a fellow of the IEEE.
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Mattia Marconcini received the "laurea" (BS) and the "laurea specialistica" (MS) degrees in telecommunication engineering (summa cum laude) and the PhD degree in communication and information technologies from the University of Trento, Italy, in 2002, 2004, and 2008, respectively. He is presently with the Remote Sensing Laboratory in the Department of Information Engineering and Computer Science, University of Trento. His current research activities are in the area of machine learning, pattern recognition, and remote sensing. In particular, his interests are related to transfer learning and domain adaptation classification and image segmentation problems. He conducts research on these topics within the frameworks of several national and international projects. He was a finalist in the Student Prize Paper Competition of the 2007 IEEE International Geoscience and Remote Sensing Symposium (Barcelona, July 2007). He is a member of the IEEE.</p>
<p>For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib.</p>            </div>
        </div>

    </div>
</body>
</html>