<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5650 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5650</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5650</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-115.html">extraction-schema-115</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <p><strong>Paper ID:</strong> paper-265128824</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2311.05733v1.pdf" target="_blank">LogShield: A Transformer-based APT Detection System Leveraging Self-Attention</a></p>
                <p><strong>Paper Abstract:</strong> Cyber attacks are often identified using system and network logs. There have been significant prior works that utilize provenance graphs and ML techniques to detect attacks, specifically advanced persistent threats, which are very difficult to detect. Lately, there have been studies where transformer-based language models are being used to detect various types of attacks from system logs. However, no such attempts have been made in the case of APTs. In addition, existing state-of-the-art techniques that use system provenance graphs, lack a data processing framework generalized across datasets for optimal performance. For mitigating this limitation as well as exploring the effectiveness of transformer-based language models, this paper proposes LogShield, a framework designed to detect APT attack patterns leveraging the power of self-attention in transformers. We incorporate customized embedding layers to effectively capture the context of event sequences derived from provenance graphs. While acknowledging the computational overhead associated with training transformer networks, our framework surpasses existing LSTM and Language models regarding APT detection. We integrated the model parameters and training procedure from the RoBERTa model and conducted extensive experiments on well-known APT datasets (DARPA OpTC and DARPA TC E3). Our framework achieved superior F1 scores of 98% and 95% on the two datasets respectively, surpassing the F1 scores of 96% and 94% obtained by LSTM models. Our findings suggest that LogShield's performance benefits from larger datasets and demonstrates its potential for generalization across diverse domains. These findings contribute to the advancement of APT attack detection methods and underscore the significance of transformer-based architectures in addressing security challenges in computer systems.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5650.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5650.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogShield</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogShield: Transformer-based APT Detection System Leveraging Self-Attention</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A supervised framework introduced in this paper that processes provenance-graph-derived event traces with custom token and temporal embeddings and fine-tunes a transformer encoder (pretrained RoBERTa) to detect Advanced Persistent Threat (APT) attack sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa (pretrained, fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A pretrained transformer encoder (RoBERTa is a BERT-variant using multi-head self-attention, trained with larger batches and without next-sentence objective). In LogShield it is augmented with custom token embeddings and a temporal embedding layer, and fine-tuned with a masked log-key cross-entropy objective and supervised classification.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Supervised fine-tuning of a pretrained transformer encoder (RoBERTa) on sequences of log-event tokens with (1) masked-log-key prediction via a log-key cross-entropy loss (MLM-style) to learn contextual priors, and (2) sequence classification to separate benign vs malicious traces; includes custom temporal embeddings and token masking during training.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured sequential data: event traces (ordered sequences) generated from system provenance graphs (tokenized object-action pairs with timestamps).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Semantic/temporal sequence anomalies corresponding to malicious APT behaviors ("low-and-slow" attack patterns, rare/malicious event sequences, temporal anomalies in inter-event timing).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>DARPA OpTC and DARPA TC E3</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1 reported. Paper reports F1 = 98% and 95% on the two datasets (respectively), surpassing compared LSTM F1 scores of 96% and 94%.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Outperforms LSTM baselines (reported F1 improvements ~2 percentage points) and performs better than other investigated transformer variants when temporal embedding is used; LSTM may do better on very small training sizes but LogShield surpasses LSTM as training data increases.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Higher memory consumption and longer training time compared to LSTM; some short traces are misclassified by LogShield while LSTM correctly classifies them (transformers may emphasize global patterns and miss local sequential nuances); difficulty when training on raw logs without preprocessing; challenges from class imbalance (upsampling malicious examples did not help; downsampling benign improved F1); experiments constrained by compute so not trained on entire datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogShield: A Transformer-based APT Detection System Leveraging Self-Attention', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5650.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5650.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RoBERTa (as used)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RoBERTa (A Robustly Optimized BERT Pretraining Approach) - used as backbone</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>RoBERTa—an optimized BERT-family transformer encoder—was used as the pretrained backbone for LogShield and fine-tuned on provenance-derived event sequences with added temporal embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer encoder (BERT-family) using multi-head self-attention; in general RoBERTa differs from BERT by training longer, using larger batches, and removing the next-sentence prediction objective. Specific parameter counts not stated in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Fine-tuning a pretrained RoBERTa encoder on tokenized event sequences with masked-token prediction (log-key cross-entropy) and supervised sequence classification; temporal embeddings added to encode inter-event timing.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured sequential log/event traces derived from provenance graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Malicious event sequences / semantic and temporal anomalies (APTs).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>DARPA OpTC and DARPA TC E3 (used in LogShield experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Same evaluation metrics used as for LogShield (Precision, Recall, F1); reported LogShield results reflect fine-tuned RoBERTa backbone performance (F1 reported: 98% and 95%).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>RoBERTa-based LogShield outperformed LSTM baselines and other transformer variants in experiments, particularly when using temporal embeddings and larger training data.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>High memory and computation requirements; sensitivity to preprocessing (raw logs perform poorly unless key fields and temporal info are encoded); may underperform on very small training sets compared to LSTM.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogShield: A Transformer-based APT Detection System Leveraging Self-Attention', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5650.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5650.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT (mentioned)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERT (Bidirectional Encoder Representations from Transformers)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>BERT is cited in this paper as a representative transformer-based language model; prior works used BERT variants for malware classification and intrusion detection, motivating LogShield's transformer-based approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Bidirectional transformer encoder trained with masked language modeling and next-sentence prediction (original architecture described by Vaswani et al. for Transformers and BERT by Devlin et al.). Specific sizes not given in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Referenced uses include fine-tuning / masked-language-model based approaches for logs (e.g., masked token prediction and classification) in prior work (not executed in this paper's experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured/semi-structured log sequences and textual encodings of events (prior work treated logs as language sequences).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Log anomalies, malware/intrusion detection (semantic sequence anomalies).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Mentioned qualitatively; prior works (cited) achieved satisfactory results for malware classification and intrusion detection, but exact metrics and datasets are not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Mentioned as prior successful LM approach; LogShield builds on this prior evidence but uses RoBERTa variants and custom temporal embeddings for improved APT detection.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper notes that raw logs may cause transformer models to miss crucial indicators unless appropriate preprocessing and temporal encoding are applied.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogShield: A Transformer-based APT Detection System Leveraging Self-Attention', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5650.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5650.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogBERT (Guo et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogBERT: Log Anomaly Detection via BERT (prior work cited)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A self-supervised transformer-based framework for log anomaly detection cited in this paper; reported to outperform previous state-of-the-art approaches on three log datasets in its own work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Logbert: Log Anomaly Detection via BERT.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LogBERT (BERT-based self-supervised model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A transformer/BERT-based model applied to logs with self-supervised pretraining tailored to log data (details presented in the cited work; this paper only references it).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Self-supervised pretraining on logs (masked-token objectives) and downstream anomaly detection (as reported by the cited work); not run within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Log sequences (textualized log events).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Log anomalies (sequential and contextual anomalies in logs).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Paper states that Guo et al. 'outperformed state-of-the-art approaches' on three log datasets, but exact metrics and dataset names are not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Reported in original (cited) work to beat previous SOTA log anomaly detectors; LogShield references it as related transformer-based log anomaly work.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not detailed in this paper; LogShield authors note that transformer-based methods can fail on raw logs unless key properties and temporal info are encoded.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogShield: A Transformer-based APT Detection System Leveraging Self-Attention', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5650.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5650.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CAN-BERT (Alkhatib et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CAN-BERT Do It? Controller Area Network Intrusion Detection System Based on BERT (prior work cited)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior framework using BERT for intrusion detection in controller area networks, cited as an example of applying transformer language models to security-related sequence data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CAN-BERT Do It? Controller Area Network Intrusion Detection System Based on BERT.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>CAN-BERT (BERT fine-tuned for intrusion detection)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>BERT-based model adapted to network intrusion detection tasks; paper references it as prior art but does not include experiments with it.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Fine-tuning BERT for intrusion detection on network message sequences (as reported in the cited work); not applied in the present experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Network message sequences / structured sequential data (CAN bus messages)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Intrusion/anomalous network sequences</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not reported in this paper (referenced work contains details).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Mentioned as an example of successful transformer application to security tasks; no direct comparison in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not discussed in the current paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogShield: A Transformer-based APT Detection System Leveraging Self-Attention', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5650.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5650.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LSTM (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Long Short-Term Memory recurrent neural network (LSTM baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An RNN-based sequence model used as a baseline in this paper for APT detection on provenance-derived event traces; LSTM performs competitively on small datasets but is outperformed by the transformer-based LogShield as training size increases.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Recurrent neural network architecture that models sequences via gated memory cells (LSTM); used here as a supervised classifier on sequences of log-event tokens (implementation details not exhaustively specified).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Supervised training of LSTM on sequences of log-event tokens for binary classification (benign vs malicious traces).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured sequential data: provenance-graph-derived event traces.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>APT malicious sequences / anomalous event sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>DARPA OpTC and DARPA TC E3</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1. Reported LSTM F1 scores cited in paper: 96% and 94% on the two datasets (the transformer-based LogShield reported 98% and 95%).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>LSTM performs better than LogShield when training data size is small, but is surpassed by LogShield as training data size increases; LSTM uses less memory and trains faster.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Suffers from vanishing/exploding gradients for long-range dependencies and limited ability to capture long-range contextual interactions; lower performance than transformer models on larger and longer sequences; however, LSTM can sometimes correctly classify very short traces that LogShield misclassifies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogShield: A Transformer-based APT Detection System Leveraging Self-Attention', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Logbert: Log Anomaly Detection via BERT. <em>(Rating: 2)</em></li>
                <li>CAN-BERT Do It? Controller Area Network Intrusion Detection System Based on BERT. <em>(Rating: 2)</em></li>
                <li>Malware Detection and Classification Using fastText and BERT. <em>(Rating: 1)</em></li>
                <li>Log Anomaly Detection via BERT (Guo et al.) <em>(Rating: 2)</em></li>
                <li>LogAnomaly: Unsupervised Detection of Sequential and Quantitative Anomalies in Unstructured Logs. <em>(Rating: 1)</em></li>
                <li>DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5650",
    "paper_id": "paper-265128824",
    "extraction_schema_id": "extraction-schema-115",
    "extracted_data": [
        {
            "name_short": "LogShield",
            "name_full": "LogShield: Transformer-based APT Detection System Leveraging Self-Attention",
            "brief_description": "A supervised framework introduced in this paper that processes provenance-graph-derived event traces with custom token and temporal embeddings and fine-tunes a transformer encoder (pretrained RoBERTa) to detect Advanced Persistent Threat (APT) attack sequences.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "RoBERTa (pretrained, fine-tuned)",
            "model_description": "A pretrained transformer encoder (RoBERTa is a BERT-variant using multi-head self-attention, trained with larger batches and without next-sentence objective). In LogShield it is augmented with custom token embeddings and a temporal embedding layer, and fine-tuned with a masked log-key cross-entropy objective and supervised classification.",
            "model_size": null,
            "anomaly_detection_method": "Supervised fine-tuning of a pretrained transformer encoder (RoBERTa) on sequences of log-event tokens with (1) masked-log-key prediction via a log-key cross-entropy loss (MLM-style) to learn contextual priors, and (2) sequence classification to separate benign vs malicious traces; includes custom temporal embeddings and token masking during training.",
            "data_type": "Structured sequential data: event traces (ordered sequences) generated from system provenance graphs (tokenized object-action pairs with timestamps).",
            "anomaly_type": "Semantic/temporal sequence anomalies corresponding to malicious APT behaviors (\"low-and-slow\" attack patterns, rare/malicious event sequences, temporal anomalies in inter-event timing).",
            "dataset_name": "DARPA OpTC and DARPA TC E3",
            "performance_metrics": "Precision, Recall, F1 reported. Paper reports F1 = 98% and 95% on the two datasets (respectively), surpassing compared LSTM F1 scores of 96% and 94%.",
            "baseline_comparison": "Outperforms LSTM baselines (reported F1 improvements ~2 percentage points) and performs better than other investigated transformer variants when temporal embedding is used; LSTM may do better on very small training sizes but LogShield surpasses LSTM as training data increases.",
            "limitations_or_failure_cases": "Higher memory consumption and longer training time compared to LSTM; some short traces are misclassified by LogShield while LSTM correctly classifies them (transformers may emphasize global patterns and miss local sequential nuances); difficulty when training on raw logs without preprocessing; challenges from class imbalance (upsampling malicious examples did not help; downsampling benign improved F1); experiments constrained by compute so not trained on entire datasets.",
            "uuid": "e5650.0",
            "source_info": {
                "paper_title": "LogShield: A Transformer-based APT Detection System Leveraging Self-Attention",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "RoBERTa (as used)",
            "name_full": "RoBERTa (A Robustly Optimized BERT Pretraining Approach) - used as backbone",
            "brief_description": "RoBERTa—an optimized BERT-family transformer encoder—was used as the pretrained backbone for LogShield and fine-tuned on provenance-derived event sequences with added temporal embeddings.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "RoBERTa",
            "model_description": "Transformer encoder (BERT-family) using multi-head self-attention; in general RoBERTa differs from BERT by training longer, using larger batches, and removing the next-sentence prediction objective. Specific parameter counts not stated in the paper.",
            "model_size": null,
            "anomaly_detection_method": "Fine-tuning a pretrained RoBERTa encoder on tokenized event sequences with masked-token prediction (log-key cross-entropy) and supervised sequence classification; temporal embeddings added to encode inter-event timing.",
            "data_type": "Structured sequential log/event traces derived from provenance graphs.",
            "anomaly_type": "Malicious event sequences / semantic and temporal anomalies (APTs).",
            "dataset_name": "DARPA OpTC and DARPA TC E3 (used in LogShield experiments)",
            "performance_metrics": "Same evaluation metrics used as for LogShield (Precision, Recall, F1); reported LogShield results reflect fine-tuned RoBERTa backbone performance (F1 reported: 98% and 95%).",
            "baseline_comparison": "RoBERTa-based LogShield outperformed LSTM baselines and other transformer variants in experiments, particularly when using temporal embeddings and larger training data.",
            "limitations_or_failure_cases": "High memory and computation requirements; sensitivity to preprocessing (raw logs perform poorly unless key fields and temporal info are encoded); may underperform on very small training sets compared to LSTM.",
            "uuid": "e5650.1",
            "source_info": {
                "paper_title": "LogShield: A Transformer-based APT Detection System Leveraging Self-Attention",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "BERT (mentioned)",
            "name_full": "BERT (Bidirectional Encoder Representations from Transformers)",
            "brief_description": "BERT is cited in this paper as a representative transformer-based language model; prior works used BERT variants for malware classification and intrusion detection, motivating LogShield's transformer-based approach.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "BERT",
            "model_description": "Bidirectional transformer encoder trained with masked language modeling and next-sentence prediction (original architecture described by Vaswani et al. for Transformers and BERT by Devlin et al.). Specific sizes not given in the paper.",
            "model_size": null,
            "anomaly_detection_method": "Referenced uses include fine-tuning / masked-language-model based approaches for logs (e.g., masked token prediction and classification) in prior work (not executed in this paper's experiments).",
            "data_type": "Structured/semi-structured log sequences and textual encodings of events (prior work treated logs as language sequences).",
            "anomaly_type": "Log anomalies, malware/intrusion detection (semantic sequence anomalies).",
            "dataset_name": null,
            "performance_metrics": "Mentioned qualitatively; prior works (cited) achieved satisfactory results for malware classification and intrusion detection, but exact metrics and datasets are not provided in this paper.",
            "baseline_comparison": "Mentioned as prior successful LM approach; LogShield builds on this prior evidence but uses RoBERTa variants and custom temporal embeddings for improved APT detection.",
            "limitations_or_failure_cases": "Paper notes that raw logs may cause transformer models to miss crucial indicators unless appropriate preprocessing and temporal encoding are applied.",
            "uuid": "e5650.2",
            "source_info": {
                "paper_title": "LogShield: A Transformer-based APT Detection System Leveraging Self-Attention",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "LogBERT (Guo et al.)",
            "name_full": "LogBERT: Log Anomaly Detection via BERT (prior work cited)",
            "brief_description": "A self-supervised transformer-based framework for log anomaly detection cited in this paper; reported to outperform previous state-of-the-art approaches on three log datasets in its own work.",
            "citation_title": "Logbert: Log Anomaly Detection via BERT.",
            "mention_or_use": "mention",
            "model_name": "LogBERT (BERT-based self-supervised model)",
            "model_description": "A transformer/BERT-based model applied to logs with self-supervised pretraining tailored to log data (details presented in the cited work; this paper only references it).",
            "model_size": null,
            "anomaly_detection_method": "Self-supervised pretraining on logs (masked-token objectives) and downstream anomaly detection (as reported by the cited work); not run within this paper.",
            "data_type": "Log sequences (textualized log events).",
            "anomaly_type": "Log anomalies (sequential and contextual anomalies in logs).",
            "dataset_name": null,
            "performance_metrics": "Paper states that Guo et al. 'outperformed state-of-the-art approaches' on three log datasets, but exact metrics and dataset names are not provided in this paper.",
            "baseline_comparison": "Reported in original (cited) work to beat previous SOTA log anomaly detectors; LogShield references it as related transformer-based log anomaly work.",
            "limitations_or_failure_cases": "Not detailed in this paper; LogShield authors note that transformer-based methods can fail on raw logs unless key properties and temporal info are encoded.",
            "uuid": "e5650.3",
            "source_info": {
                "paper_title": "LogShield: A Transformer-based APT Detection System Leveraging Self-Attention",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "CAN-BERT (Alkhatib et al.)",
            "name_full": "CAN-BERT Do It? Controller Area Network Intrusion Detection System Based on BERT (prior work cited)",
            "brief_description": "A prior framework using BERT for intrusion detection in controller area networks, cited as an example of applying transformer language models to security-related sequence data.",
            "citation_title": "CAN-BERT Do It? Controller Area Network Intrusion Detection System Based on BERT.",
            "mention_or_use": "mention",
            "model_name": "CAN-BERT (BERT fine-tuned for intrusion detection)",
            "model_description": "BERT-based model adapted to network intrusion detection tasks; paper references it as prior art but does not include experiments with it.",
            "model_size": null,
            "anomaly_detection_method": "Fine-tuning BERT for intrusion detection on network message sequences (as reported in the cited work); not applied in the present experiments.",
            "data_type": "Network message sequences / structured sequential data (CAN bus messages)",
            "anomaly_type": "Intrusion/anomalous network sequences",
            "dataset_name": null,
            "performance_metrics": "Not reported in this paper (referenced work contains details).",
            "baseline_comparison": "Mentioned as an example of successful transformer application to security tasks; no direct comparison in this paper.",
            "limitations_or_failure_cases": "Not discussed in the current paper.",
            "uuid": "e5650.4",
            "source_info": {
                "paper_title": "LogShield: A Transformer-based APT Detection System Leveraging Self-Attention",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "LSTM (baseline)",
            "name_full": "Long Short-Term Memory recurrent neural network (LSTM baseline)",
            "brief_description": "An RNN-based sequence model used as a baseline in this paper for APT detection on provenance-derived event traces; LSTM performs competitively on small datasets but is outperformed by the transformer-based LogShield as training size increases.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LSTM",
            "model_description": "Recurrent neural network architecture that models sequences via gated memory cells (LSTM); used here as a supervised classifier on sequences of log-event tokens (implementation details not exhaustively specified).",
            "model_size": null,
            "anomaly_detection_method": "Supervised training of LSTM on sequences of log-event tokens for binary classification (benign vs malicious traces).",
            "data_type": "Structured sequential data: provenance-graph-derived event traces.",
            "anomaly_type": "APT malicious sequences / anomalous event sequences.",
            "dataset_name": "DARPA OpTC and DARPA TC E3",
            "performance_metrics": "Precision, Recall, F1. Reported LSTM F1 scores cited in paper: 96% and 94% on the two datasets (the transformer-based LogShield reported 98% and 95%).",
            "baseline_comparison": "LSTM performs better than LogShield when training data size is small, but is surpassed by LogShield as training data size increases; LSTM uses less memory and trains faster.",
            "limitations_or_failure_cases": "Suffers from vanishing/exploding gradients for long-range dependencies and limited ability to capture long-range contextual interactions; lower performance than transformer models on larger and longer sequences; however, LSTM can sometimes correctly classify very short traces that LogShield misclassifies.",
            "uuid": "e5650.5",
            "source_info": {
                "paper_title": "LogShield: A Transformer-based APT Detection System Leveraging Self-Attention",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Logbert: Log Anomaly Detection via BERT.",
            "rating": 2,
            "sanitized_title": "logbert_log_anomaly_detection_via_bert"
        },
        {
            "paper_title": "CAN-BERT Do It? Controller Area Network Intrusion Detection System Based on BERT.",
            "rating": 2,
            "sanitized_title": "canbert_do_it_controller_area_network_intrusion_detection_system_based_on_bert"
        },
        {
            "paper_title": "Malware Detection and Classification Using fastText and BERT.",
            "rating": 1,
            "sanitized_title": "malware_detection_and_classification_using_fasttext_and_bert"
        },
        {
            "paper_title": "Log Anomaly Detection via BERT (Guo et al.)",
            "rating": 2,
            "sanitized_title": "log_anomaly_detection_via_bert_guo_et_al"
        },
        {
            "paper_title": "LogAnomaly: Unsupervised Detection of Sequential and Quantitative Anomalies in Unstructured Logs.",
            "rating": 1,
            "sanitized_title": "loganomaly_unsupervised_detection_of_sequential_and_quantitative_anomalies_in_unstructured_logs"
        },
        {
            "paper_title": "DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning.",
            "rating": 1,
            "sanitized_title": "deeplog_anomaly_detection_and_diagnosis_from_system_logs_through_deep_learning"
        }
    ],
    "cost": 0.013108499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LogShield: A Transformer-based APT Detection System Leveraging Self-Attention
9 Nov 2023</p>
<p>Sihat Afnan 
Bangladesh University of Engineering and Technology ‡ National Research Council
Canada</p>
<p>Mushtari Sadia 
Bangladesh University of Engineering and Technology ‡ National Research Council
Canada</p>
<p>Shahrear Iqbal 
Bangladesh University of Engineering and Technology ‡ National Research Council
Canada</p>
<p>Anindya Iqbal 
Bangladesh University of Engineering and Technology ‡ National Research Council
Canada</p>
<p>LogShield: A Transformer-based APT Detection System Leveraging Self-Attention
9 Nov 2023AEA54D4FFCAAF3EA0F1C5D8640C0CA38arXiv:2311.05733v1[cs.CR]Log AnalysisProvenance GraphAPTTransformer
Cyber attack detection is a critical task in ensuring the security and reliability of a system.Attacks are often identified using system and network logs, a primary data source across computer systems.There have been significant prior works that utilize provenance graphs and machine learning techniques to detect attacks, specifically Advanced Persistent Threats (APT) which are very difficult to detect due to their low and slow approach.Lately, there has been emerging research where transformer-based language models are being used to detect various types of attacks from system logs.However, no such attempts have been made in the case of APTs.In addition, existing state-of-the-art techniques that use system provenance graphs, lack a data processing framework generalized across datasets for optimal performance.For exploring the effectiveness of transformer-based language models as well as mitigating the aforementioned limitation, this paper proposes LogShield, a framework designed to detect APT attack patterns leveraging the power of self-attention in transformers.We incorporate customized embedding layers to effectively capture the context of event sequences derived from provenance graphs.While acknowledging the computational overhead associated with training transformer networks, our framework surpasses existing LSTM and Language models regarding APT detection performance.We integrated the model parameters and training procedure from the RoBERTa model and conducted extensive experiments on well-known APT datasets (DARPA OpTC and DARPA TC E3).Our framework achieved superior F1 scores of 98% and 95% on the two datasets respectively, surpassing the F1 scores of 96% and 94% obtained by LSTM models.Our findings suggest that LogShield's performance benefits from larger datasets and demonstrates its potential for generalization across diverse domains.These findings contribute to the advancement of APT attack detection methods and underscore the significance of transformer-based architectures in addressing security challenges in computer systems.</p>
<p>I. INTRODUCTION</p>
<p>The dynamic nature of cyber-attacks, especially advanced persistent threats or APTs, demands a proactive approach to safeguarding sensitive information and critical infrastructures.APTs are characterized by their stealth nature and ability to remain undetected for long periods of time.They are typically targeted attacks, meaning that they are directed at specific organizations or individuals for the purpose of stealing sensitive data or disrupting operations.These attacks are often carried out by nation-states or other well-funded and skilled cybercrime groups, and they may involve the use of custom * Both authors contributed equally.malware and other advanced tactics.According to APT trends report Q3 2022 [1], APT campaigns are very widely spread geographically, expanding into Europe, the US, Korea, Brazil, the Middle East and various parts of Asia.</p>
<p>According to recent research [2], [11], data provenance may be a reliable data source for APT detection.Data provenance utilizes system logs by representing all system events as a directed acyclic graph (DAG) that describes information flow between system subjects (processes) and objects (files and sockets).It connects causally-related events in the graph, even when those events are separated by a long time period.Thus, even though systems under attack usually behave similarly to unattacked systems, the richer contextual information in provenance allows for better separation of benign and malicious events.</p>
<p>In recent years, as demonstrated by BERT or GPT-3, language models have been seen to receive state of the art results in various fields [3].One possible domain of their application can be APT detection.Numerous types of system data such as system logs or event traces can be structured as texts and viewed as a separate language.There has already been notable work in this field.In Yesir et al. [4], malware classification was performed using BERT and fastText and a satisfactory result was achieved.More recently, in Alkhatib et al. [5], a framework called CAN-BERT was developed to perform intrusion detection using BERT .In Guo et al [6], a self-supervised framework for log anomaly detection based on Transformers was developed which outperformed state-ofthe-art approaches for anomaly detection, by experimenting on three log datasets.</p>
<p>The motivation behind using language models to detect malicious event traces lies in the fact that language models are designed to take into account the sequence of words in a sentence.Therefore, sequential log data, which refers to a log or record of events that are recorded in a specific order, can be processed by language models.This is important because the sequence of events can convey the meaning and context of a process which would be lost if the event traces were rearranged.For example, consider a web browser (e.g., chrome.exe)that opens a PDF file by triggering a PDF viewer (e.g., acrobat.exe).This is a benign action.The opposite sequence, where the PDF viewer triggers the web browser, could potentially be considered a malicious action, as it might indicate an attempt by the PDF file to execute code within the web browser.Another example to consider is a chat program (e.g., slack.exe) opening a chat window by triggering a web browser (e.g., firefox.exe).In contrast, if the web browser triggers the chat process, it could be indicative of a malicious event.</p>
<p>Another reason behind using language models for APT detection is that the self-attention mechanism of transformerbased language models allows each word, or in the case of logs, each event in a sequence to interact with all other events, fostering a holistic understanding of the entire sequence.This attention mechanism assigns different weights to different events based on their relevance, dynamically adjusting each event's importance as the model processes the sequence.In the context of log data, this translates to the model being able to focus on critical events that might indicate malicious activities while considering the broader context of the entire log sequence.</p>
<p>As deep learning models, particularly recurrent neural networks (RNNs) can represent sequential data, they are now frequently used for log anomaly detection.Nevertheless, there are still certain limitations of RNNs to detect sequences in log data.Traditional RNNs suffer from vanishing and exploding gradient problems, which restrict their ability to capture longrange dependencies effectively.In contrast, the self-attention mechanism in Transformer models is not subject to these limitations.This allows Transformers to capture both local and global dependencies efficiently, making them well-suited for handling the complex and diverse patterns found in log data.</p>
<p>In this paper, we propose a generalized framework to process log data collected from systems under APT attack and detect the attack leveraging self-attention.We have adopted a system provenance-based approach to generate event traces.Our findings indicate that existing deep learning techniques employed for APT detection experience performance degradation compared to transformer-based language models, as the volume and length of event sequences grow.However, we also observed that transformer-based models face challenges when provided with raw log data, as they fail to capture certain crucial aspects indicating malicious events.To address this issue, our framework focuses on extracting specific, essential information from the log data enabling language models to effectively capture these critical indicators.By doing so, our approach ensures that transformer-based models perform optimally in detecting attacks, surpassing the limitations of existing methods.</p>
<p>We have used the DARPA OpTC [7] and the DARPA TC E3 [8] datasets to validate our approach.The DARPA TC E3 dataset is obtained from the third engagement exercise of the DARPA Transparent Computing (TC) program, which involved benign data generation initially, followed by simulation of APT attack behaviors during specific weekday hours while maintaining continuous benign background traffic.The DARPA OpTC dataset is the largest publicly available dataset that contains APT attack traces injected by a red team over the course of two days.This dataset solely includes event logs from windows machines and encompasses over 17 billion events, with only 0.0016% of events being malicious.While the dataset's class imbalance may lead to less accurate predictions of various attack scenarios, its extensive log volume makes it an ideal candidate to evaluate the performance of language models in detecting APT, compared to other APT sources.</p>
<p>The contributions of this paper are briefly summarized as follows:</p>
<p>1) We introduce a novel approach to process system logs, creating a system provenance graph-based attack detection framework that leverages transformer-based language models for APT detection.2) We evaluate the proposed framework using two recent APT datasets, comparing its performance against other transformer-based language models and LSTM.Results demonstrate that our approach achieves the highest accuracy and F1-score in detecting APTs.3) We establish that our approach is generalizable and outperforms LSTM by a notable margin as the training data size increases, highlighting its superiority in handling larger and more complex log datasets.This paper is organized as follows.In sections II and III we discuss the background related to the transformer architecture, advanced persistent threats and previous works in this field respectively.We present our approach and methodology in section IV.The dataset construction and further analysis are detailed in sections V and VI.Our experimentation and results are presented in section VII.Finally, our conclusion is presented in section VIII.</p>
<p>II. BACKGROUND</p>
<p>In this section, we briefly overview the Transformer architecture and the characteristics of an APT attack.</p>
<p>A. Transformer</p>
<p>The Transformer architecture is a sequence-to-sequence network that relies solely on attention mechanisms, eliminating the need for recurrent and convolutional components.In recent studies, the Transformer has demonstrated exceptional performance, surpassing many RNN-based models in Neural Machine Translation.The Transformer consists of two main components: an encoder and a decoder, each comprising stacks of multiple identity blocks.</p>
<p>Within the encoder, each block consists of two subnetworks: a multi-head attention mechanism and a feed-forward network.Within the decoder, each block includes an additional masked multi-head attention mechanism compared to the encoder block.Both encoder and decoder blocks are equipped with residual connection and layer normalization, contributing to the overall stability and effectiveness of the Transformer architecture.</p>
<p>Transformer employs self-attention as a fundamental mechanism to process input sequences.Self-attention allows the model to focus on different elements of the input sequence when generating the output at each position.It is a key factor in the Transformer's ability to capture long-range dependencies and relationships between elements in the input sequence.</p>
<p>B. Language Models</p>
<p>Language models (LMs) are a subset of machine learning models trained to predict the next word in a sequence, given the words that came before it.At their core, LMs capture the underlying structure and patterns in the language, enabling them to generate coherent and contextually relevant text.</p>
<p>The development of deep learning has paved the way for more sophisticated LMs, with the transformer architecture being particularly transformative.Introduced by Vaswani et al. [14] in 2017, transformers utilize self-attention mechanisms to weigh the relevance of each word in a sequence when predicting the next word.This allows for greater contextual understanding, making transformers particularly adept at capturing long-range dependencies in text.</p>
<p>One significant implementation of the transformer architecture is BERT (Bidirectional Encoder Representations from Transformers) introduced by Google in 2018.Unlike traditional LMs that predict words in a unidirectional manner (either left-to-right or right-to-left), BERT is trained to predict words in a bidirectional manner, considering both the left and the right context in all layers.This deep bidirectional understanding enabled BERT to achieve state-of-the-art results on a range of NLP tasks.</p>
<p>Following BERT's success, Facebook introduced RoBERTa (A Robustly Optimized BERT Pretraining Approach), which is a variant of BERT.RoBERTa modifies key hyperparameters in BERT, training the model longer and on more data, and removing the next-sentence pretraining objective, which further improved performance on several benchmarks.</p>
<p>While LMs have been predominantly applied in natural language processing tasks such as translation, summarization, and question-answering, their ability to recognize patterns and nuances in large datasets can be harnessed in other domains, including cybersecurity.In the context of detecting Advanced Persistent Threat (APT) attacks, transformer-based LMs like BERT and RoBERTa can be utilized to understand and identify suspicious patterns in textual data, such as logs or network traffic metadata, thus providing a novel approach to cyber threat detection.</p>
<p>C. Advanced Persistent Threat</p>
<p>Advanced persistent threats, or APTs, are a type of cyber attack that is characterized by its stealthiness and ability to remain undetected for long periods of time.APTs are typically targeted attacks, meaning that they are directed at specific organizations or individuals for the purpose of stealing sensitive data or disrupting operations.These attacks are often carried out by nation-states or other well-funded and skilled cybercrime groups, and they may involve the use of custom malware and other advanced tactics.One of the key features of APTs is their ability to adapt and evolve over a longer period of time, making them difficult to detect.While some threat actors work alone, multiple government authorities such as the Cybersecurity and Infrastructure Security Agency (CISA) have linked attacks to APT groups-with some having ties to specific nation-states who use them to further their country's interests.According to APT trends report Q3 2022, APT campaigns are very widely spread geographically, expanding into Europe, the US, Korea, Brazil, the Middle East and various parts of Asia.</p>
<p>III. RELATED WORK</p>
<p>In this section, we discuss some of the state-of-theart techniques and approaches for detecting attacks, with a specific focus on advanced persistent threats (APTs).Our work occupies the intersection of several domainsprovenance-graph based APT detection, APT detection using machine learning techniques, applications of transformerbased language models in the field of cybersecurity, and log data analysis for threat detection.Hence, we position LogShield within the context of prior research in these realms.Provenance Graph-based APT Detection.There have been significant prior efforts exploring the use of data provenance for APT detection.Milajerdi et al. [12] proposed HOLMES, a graph-based method for detecting APT attacks which utilizes a set of manually crafted rules to describe various APT information flows in an attack provenance graph.However, the manual rule generation process has limitations in recognizing zero-day APT attacks.Han et.al. [21] introduced UNICORN, an anomaly based APT detector that effectively leverages data provenance analysis by using Fig. 2. Overview of Our Approach a graph sketching technique.However, UNICORN suffers the limitation of having a high false-positive rate in some datasets.Xiong et.al. [2] presented CONAN, a state-based detection framework built upon provenance graphs, which helps to detect APTs with constant and limited memory usage and high efficiency, though the state-based approach can also struggle in identifying zero-day APT attacks.</p>
<p>APT Detection Using Machine Learning Techniques.</p>
<p>Applying Machine Learning techniques to detect attack patterns is a relatively new idea whereas traditional approaches included either rule-based or signature based methods for attack detection, performance of which were unsatisfactory when detecting zero day APTs.Ghafir et.al. [13] introduced a machine learning-based correlation analysis method for APT detection.Similarly, Xuan et.al. [22] proposed another ML-based approach using a multi-layer analysis technique.However, their approach demonstrated limitations in effectively detecting novel attacks.In other recent studies, various deep learning based methods have been explored for the detection of APT attacks [10], [15]- [18].Recurrent neural networks, notably Long Short-Term Memory (LSTM) or Gated Recurrent Unit (GRU), have been extensively utilized in multiple approaches to model normal log sequences [10], [19].Machine learning based approaches include supervised and unsupervised deep learning to detect attack sequences.Historically, supervised methods have been employed to tackle the log anomaly detection problem.For example, Liang et al. [26] took a support vector machine (SVM) method to detect attacks where labels for both benign and malicious samples were available.Various unsupervised learning methods have also been proposed.Xu et al. [27] suggested using Principal Component Analysis (PCA) assuming distinct sessions in log files are identifiable through session-ids attached to log entries.Additionally, Lou et al. [28] introduced Invariant Mining (IM) to extract linear relationships among log events from log event count vectors.</p>
<p>APT Detection Using System Provenance Graphs and Machine Learning-based Techniques.Our work most closely aligns with prior works in this area.For APT detection, Ayoade et al. [11] presented a deep learning-based approach where they extracted features from a provenance graph and then used those features to train an online adaptive metric learning model.In another work, ANUBIS [31], representation learning of event sequences extracted from provenance graph was performed using LSTM network followed by a Bayesian Neural Network classifier for APT detection.</p>
<p>Applications of Transformer-based Language Models in the Field of Cybersecurity.While no prior works have utilized transformer-based language models for APT detection, in the realm of cybersecurity, there is a growing body of research utilizing transformer-based language models for various tasks.Yesir et al. [4] successfully applied BERT and fastText for malware classification, achieving satisfactory results.More recently, Alkhatib et al. [5] introduced CAN-BERT, a framework that utilizes BERT for intrusion detection.Similar to our work, Guo et al. [15] employed the BERT model to capture log sequence information and introduced two selfsupervised tasks for model training.However, logBERT relies on a log key parser to convert events in raw log files to log keys.</p>
<p>Log Data Analysis for Threat Detection.Several studies have utilized natural language processing (NLP) techniques to analyze log data, treating logs as natural language sequences.Zhang et al. [18] employed the LSTM model along with TF-IDF weighting for predicting anomalous log messages.Similarly, LogRobust [10] and LogAnomaly [17] integrated pre-trained word vectors to train a Bi-LSTM model for learning log sequences.</p>
<p>To the best of our knowledge, our work is the first attempt to leverage the prowess of transformer-based language models for detecting APT attacks.In addition, our approach stands apart from previous methods as we have added customized embeddings on sequence of events generated from provenance graphs, and used transformer architecture to employ selfattention along with log-key cross entropy loss function to enrich the separation of benign and malicious event sequences, leading to significant improvements in APT detection performance.</p>
<p>IV. OVERVIEW OF OUR APPROACH</p>
<p>In this section, we introduce LogShield, a framework inspired by Transformer architecture for detecting APT attacks.Logshield has been trained in a supervised manner with customized objective function and embedding layers that learns the separation between benign and malicious event sequences.Our framework utilizes a host-based approach for generating event sequences from provenance graphs and detecting APT attacks.The unique characteristics of APTs, such as "low-andslow" attack pattern and the use of zero-day exploits, are taken into consideration during specific preprocessing.Our approach has two parts: (i) learning log representations from a large log file, and (ii) accurately detecting APT attack patterns.Figure 1 provides a detailed view of this process, which includes: (1) generating log sequences from a provenance graph in the data preprocessing stage, (2) encoding log strings and time in the embedding layer, and (3) learning encoded log representations in the transformer layer.</p>
<p>A. Data Preprocessing Layer</p>
<p>The layer in question allows for the examination of events that occurred at different times by creating a provenance graph from raw data.Data provenance can be used to model various types of event sequences, such as system logs.While creating a provenance graph, a set of properties (such as object, action etc.) are extracted from each record in the log data to be included in each node of the graph.Through analyzing causality relationships within the provenance graph, a clear understanding of the system's behavior can be gained.</p>
<p>After generation of the provenance graph, we generate event traces.An event trace is a sequence of events that are connected by parent-child relationships.A node in the provenance graph is selected randomly and the path starting from the node to the leaf is selected.Since different paths might have different lengths (which was found to be 31 events per trace on average for the DARPA-OPTC dataset), all the event traces are padded with an offset to make them of exactly same length.As shown by several prior works [19], [28]- [30], a convenient way to use log data is to generate a more structured representation by storing key properties that preserve causality, while discarding unnecessary information.The resulting representation is referred to as log keys.</p>
<p>B. Embedding Layer</p>
<p>At this stage, the event traces have been encoded to contain information about each type of event, and on which object the action is being performed upon.Additionally, they possess the time difference information from parent to child event.</p>
<p>1) Log Embedding: A log embedding is a vector representation for each event trace.For each event, we already have its representative object-action pair.We use it to encode an event into natural language text, such as "File Read" or "Process Create" which is then passed on to the encoder architecture of Transformer.Each object-action pair in a sequence will be converted to a token and a sequence will be differentiated from other sequences by a special token.We appended the [DTC] token to mark the start of a sequence and [END] token to denote the end of a sequence, before passing it to the token embedding layer.Some of the tokens are randomly masked by the token embedding layer for the training purpose.BERT and the language models derived from it uses masked language modeling where a masked token is predicted in the output sequence.MLM consists of giving BERT a sequence and optimizing the weights inside BERT to output the same sequence on the other side.</p>
<p>2) Temporal Embedding: We have the time differences for each event from its parent and leveraging this information, we use a sliding window technique to divide the log keys into multiple time segments.In BERT or any other language model, the original input is texts and the temporal information between words is not of much value, unlike our case, where timestamps of each event is very significant.Let's think of two child events: c1 and c2 generated from the same parent.The two events c1 and c2 were not triggered at the same point in time and therefore they cannot be handled similarly.This temporal information becomes handy while detecting APT attacks due to their slow and steady nature.We have introduced temporal embedding layer to differentiate between these type of events.</p>
<p>Due to the nature of APT attacks, the attack sequence is executed slowly and might be kept hidden for a longer amount of time.In our approach, the Temporal Embedding layer leverages the sliding window w to divide the log keys into multiple time slots where each log key is placed into one slot.We also divide the value of each time slot by the total number of time slots to ensure the time slot of log keys never surpasses 1.For example, given the sequence of pairs: (k1, 1s), (k2, 1.5s), (k3, 2.5s), (k4, 5s), where the first element of each pair denotes log key, and the second element denotes its corresponding timestamp.If w is defined to be 2 seconds, then the first two pairs, i.e., (k1, 1s) and (k2, 1.5s) are placed into the first slot of time, i.e., 1/3.With the same token, the third and fourth elements in the sequence are placed into the second and the third time-slot, i.e., 2/3 and 3/3, respectively.</p>
<p>C. Transformer Layer</p>
<p>Transformer, an encoder-decoder architecture that utilizes self-attention mechanisms.In our approach, the transformer layer uses multiple self-attention layers and pointwise fully connected layers that are stacked on the top of each other.It is used to learn the contextual relations among log keys in a sequence.For example, a shell process sh1 triggers two different shell processes sh2 and sh3 at two different timestamps.It also triggers a File Create process that creates two files f2 and f3 respectively to be used by sh2 and sh3.It is obvious from the context that the temporal embedding of sh2 and f2 and that of sh3 and f3 should be similar.This similarity score is captured by transformer architecture.The temporal embeddings in the Embedding Layer allows selfattention mechanism to quantify the embedding changes at any given time in the latent space via calculating the cosine similarity.</p>
<p>In our approach, each attention head operates on the output of embedding layer, i.e.,
X i = {x i [DT C] , x i 1 , ..., x i [M ASK]j , ..., x i m , x i [EN D]
} where X i ∈ X is the input to the embedding layer, which is a vector encoded to jointly capture information of different aspects at different positions over the input log sequence.We will refer to X i as log key henceforth.The transformer layer outputs the sequence
H i = {h i [DT C] , h i 1 , ..., h i [M ASK]j , ..., h i m , h i [EN D]
} where H i ∈ H , and H i is a representative of the input log key X i , and H i is calculated using a self-supervised objective function explained in the following.</p>
<p>1) Log Key Cross-Entropy Loss: This objective function is employed to capture context information of encoded log sequences in K i .The log keys in each sequence are masked using a specific token [MASK] randomly.Since APT attacks usually exhibit low and slow attack patterns, a system that has been compromised can work similarly to an unattacked system.Thus, the richer contextual information extracted from log key sequence, the better the separation between benign and malicious event sequences will become.</p>
<p>During the training process, the model is expected to learn how to predict masked log keys accurately.The purpose is to encode the prior knowledge of benign log key sequences.To this end, we take the output of the l-th encoder in the transformer layer, i.e., H i .Then, each masked log key h i</p>
<p>[MASK]j is fed into a softmax function which outputs a probability distribution over the entire set of log keys in the vocabulary V.The highest probability determines the log key in V that the masked element h i</p>
<p>[MASK]j belongs to.The following equation explains this process where ki j indicates the predicted log key for the j-th masked element in H i .
ki j = Softmax(W c h i [MASK]j + B c )
Where W c and B c are trainable parameters.Finally, we adopt the cross entropy loss function to examine how well it could predict the masked log keys, with respect to the corresponding log keys in the same log key sequence.
Loss = − 1 |H| |H| i=1 | Ki | j=1 k i j log ( ki j )
Where |H| and | Ki | indicate the number of input log key sequences and the number of masked log keys in the i-th sequence, respectively.</p>
<p>V. CONSTRUCTING THE DATASET</p>
<p>Our experimental datasets includes Darpa OpTC and DARPA Transparent Computing Engagement 3 (TC3).In this section, we present our methodology of constructing the dataset.</p>
<p>From the DARPA OPTC Dataset, the log data was collected from 3 Hosts, namely SysClient0201, SysClient0321 and SysClient0501.Similarly, from the DARPA TC E3 dataset, data of the host TA1-Cadets was collected.The process begins by creating a provenance graph, from the raw data in the log file.This allows for the causal connection of system events even when they occur at different times.The structure of the provenance graph is similar to an n-ary tree.A set of properties are extracted from each record in the log file to be included in the nodes of the tree.The more properties included, the more comprehensive and generalized the model will be.For our provenance tree, we included the following propertiesthe id of the actor initiating an event, the type of the event (object), the action that was performed (create/modify) and the time difference between the parent event and the child event.Each node of the provenance tree had a unique parent node and multiple child nodes.The parent-child relationship is defined by an event triggering another event.</p>
<p>By following Alg 1, the provenance tree was created from the data, which contained encoded 4 tuples for all nodes starting from parent to child.Since each child has a unique parent but not the other way around, a back provenance tree (a tree containing child to parent mapping) was created by following Alg 2. That way, we could walk from leaf to root and generate sequence of events known as event traces (Alg 3).Thus, a collection of benign and malicious event traces was achieved.
Algorithm 1: Generate Tree T Input : Raw Dataset from Host Output: T = (list of C i ), where C i is child node C i = (I d , O, A, t d )
Generate child to parent mapping dictionary C P : v → u where u is the id of the first event in the dataset (ordered by timestamp) that has that actorID of v as it's objectID;
for</p>
<p>VI. EXPLORATORY DATA ANALYSIS</p>
<p>A. DARPA OPTC dataset</p>
<p>The provenance graph of the Darpa OPTC dataset comprised of 4 types of objects and 8 types of actions, leading to 32 possible object-action pairs.However, some of these pairs were more commonly observed in the data, while others were rare.By utilizing a heatmap shown in figure 3(a), we could obtain a visual representation of the prevalence of these object-action pairs and gain insights about the data.</p>
<p>Once the event traces were generated, we attempted to compare the characteristics of malicious and benign traces.By analyzing figure 3(b), it was observed that the proportion of FLOW, FILE and SHELL objects was higher in the malicious traces, while the PROCESS object was more prominent in the benign traces.Similarly, the actions MESSAGE, MODIFY, RENAME, DELETE, and COMMAND can be regarded as more suspicious due to their higher frequency in malicious actions.</p>
<p>By examining the time differences between events in the dataset, another observation that could be made is that malicious actions typically exhibit longer time intervals compared to benign actions.This is logical since the DARPA OPTC dataset contains the data of advanced persistent threats, which are characterized by a slow and steady approach.Furthermore, analyzing the mutual information (MI) (figure 6) between the target and each feature reveals that the features "PROCESS" and the actions "CREATE" and "OPEN" exhibit the strongest correlation with the target variable.</p>
<p>B. DARPA TC E3 dataset</p>
<p>In this dataset, there are 17 types of events including READ, WRITE, OPEN, CONNECT, MODIFY, etc.An analysis (figure 4) of the frequency of the events in benign and malicious logs show us that the MODIFY, EXECUTE and MMAP events could be regarded as more suspicious due to their higher frequency in the malicious traces.</p>
<p>VII. EXPERIMENTATION AND EVALUATION</p>
<p>In this section, we aim to evaluate the robustness and effectiveness of our approach.We conducted our experiment on a workstation with an Intel Core i7-10750H running at 2.6 GHz, 16G RAM and 6 cores.We did not use any provenance capturing tool for provenance graph generation except for python libraries.To implement LogShield, a pretrained RoBERTa model was utilized, and the key hyperparameters were adjusted, including the elimination of the next-sentence pretraining objective, as well as training with significantly larger mini-batches and learning rates.Training was conducted using the logs obtained from SysClient0201 and SysClient0501.Considering the computational resource constraints, it was not feasible to train LogShield on the entire Darpa OpTC or Darpa TC E3 dataset.</p>
<p>A. Metrics</p>
<p>We leverage the widely used metrics, namely Precision, Recall, and F1-score to measure the effectiveness of our approach.The detailed definitions of our metrics are described in the following (TP, FP, FN represent True Positive, False Positive, and False Negative respectively).</p>
<p>Precision: The percentage of correctly detected anomalies amongst all detected anomalies.</p>
<p>P r = T P T P + F P</p>
<p>(2)</p>
<p>Recall: The percentage of correctly detected anomalies amongst all real anomalies.</p>
<p>B. Effectiveness of the Temporal Embedding layer</p>
<p>To figure out the effectiveness and robustness of our temporal embedding layer, added on top of our preprocessing layer, we evaluate the performance of existing language models with and without the temporal embedding.By default, language models lack any temporal information pertaining to the textual elements, and instead rely solely on the interplay between word embeddings for text processing.The outcomes of this evaluation, presented in Table-??, demonstrate the notable impact of the temporal embedding layer in enhancing model effectiveness.The models under investigation were subjected to training and testing using distinct collections of host machines.Remarkably, it was observed that when the models were assessed on unfamiliar data from another host machine within the same network, their performance exhibited a slight decline.This observation suggests that our model possesses a degree of generalizability, whereby training on a specific set of host machine data allows for successful application to other hosts, as the individual host being tested does not exert a significant impact on model performance.This generalization holds greater feasibility when employing large language models as opposed to LSTM or other sequence classifiers, as training on the entire dataset necessitates substantially higher computational power.</p>
<p>Our experimentation shows that LSTM doesn't improve significantly with temporal embedding like BERT, RoBERTa or ELECTRA.Among the three models we used, RoBERTa has been found to perform better in most of the cases.In the BERT framework, the masking procedure is executed once during data preparation, wherein each sentence undergoes masking in 10 distinct manners.Consequently, during the training phase, the model exclusively encounters these 10 variations of each sentence.On the other hand, the probable reason why RoBERTa might have performed well in event sequence classification is the masking process takes place during training, implying that every time a sequence is included in a minibatch, it undergoes the masking procedure.Consequently, the number of potentially different masked versions for each sentence is not limited as it is in BERT.</p>
<p>Finally, Figure-8 shows how the F1-score improves after integrating temporal embedding for different combinations of trainset and testset.</p>
<p>C. Effectiveness in terms of APT attack detection</p>
<p>We evaluate the effectiveness of LogShield in terms of APT attack pattern detection.LogShield's performance was evaluated on data collected from SysClient0201, SysClient0321, and SysClient0501.The performance metrics of LogShield are presented in Table-I.</p>
<p>We also conducted a comprehensive analysis to investigate the ability of LogShield to accurately classify traces that were misclassified by the LSTM model.Through various permutations of trainset and testset combinations, we examined the performance of LogShield in correctly categorizing these misclassified traces.The detailed findings of our analysis are presented in Table-II.</p>
<p>D. Relation of Training Data Size with Performance</p>
<p>We also evaluated the performance of LogShield and LSTM models with varying sizes of training data.The results, presented in Fig- 7, demonstrate that LSTM exhibits superior performance when the training data size is small.However, as the training data size increases, LogShield gradually surpasses LSTM in terms of effectiveness.Considering the prevalence of substantial system logs in real-life security scenarios, it is reasonable to assume that most attack detection tasks will have access to a considerable amount of training data.Consequently, LogShield emerges as the preferred choice in the majority of cases.</p>
<p>E. Misclassifications by LogShield</p>
<p>There are some traces, although few, which were misclassified by LogShield yet correctly classified by LSTMs, as seen in Table - This can happen for traces that are much shorter than average, as LSTMs are known to be capable of learning effectively from smaller amounts of data.Also, language models may focus more on capturing global patterns and may not fully exploit the local sequential information in some cases, where LSTMs might be more successful.</p>
<p>F. Handling Class Imbalance</p>
<p>In our analysis of the DARPA OPTC dataset, we extracted 103,329 benign traces and 20,924 malicious traces.For the DARPA TC E3 dataset, we obtained 19,152 benign traces and 9,455 malicious traces.Due to the significant class imbalance, we conducted experiments involving upsampling the malicious traces and downsampling the benign traces.While upsampling the malicious traces did not enhance the performance, downsampling the benign traces resulted in improved model F1-score.Figure-9 illustrates our experimentation process to determine the optimal downsampled count for the benign traces.After finding the optimal count of benign traces for</p>
<p>Fig. 1 .
1
Fig. 1.Locating the position of our work in a brief part of the history of APT attack detection</p>
<p>Fig. 3 .
3
Fig. 3. Comparison of Percentages of Object-Actions in DARPA OPTC</p>
<p>Fig. 5 .
5
Fig. 4. Comparison of Percentage of Actions</p>
<p>Fig. 6 .
6
Fig. 6.Mutual Information between features and target</p>
<p>Fig. 7 .
7
Fig. 7. Comparison of Performance of LSTM and LogShield with respect to varying sizes of training data</p>
<p>III.
Trained OnTested OnCorrectly Classified by LSTM (Misclassified traces by LogShield)Sysclient020145 (2503)SysClient0201Sysclient 0321197 (14573)Sysclient0501243 (17048)Sysclient0201587 (13046)SysClient0501Sysclient 0321369 (14503)Sysclient050165 (2503)Darpa TC E3TA1-cadets14 (1147)TABLE IIICOUNT OF TRACES CORRECTLY CLASSIFIED BY LSTM WHICH WEREMISCLASSIFIED BY LOGSHIELD
ModelG. LimitationsLanguage models, with their superior performance, outperform LSTMs in terms of accuracy and F1-score, thereby detecting attacks successfully in cases where LSTMs fail.However, it is important to note that this improved performance comes at the expense of increased memory consumption and longer computational time.In Figure-10, we illustrate the comparison of training time and memory usage between LogShield and LSTM models using our training data.Considering systems with memory constraints, LSTM models might still be relevant and viable for attack detection applications.In conclusion, our evaluation demonstrates the superiority of our temporal embedding approach in attack detection, as evidenced by higher precision, recall, and F1-scores across different hosts in the datasets.We also demonstrate that as the training data size increases, LogShield gradually surpasses LSTM in terms of effectiveness.Furthermore, LogShield is able to correctly classify many traces that LSTM fails to detect.We also discussed how we handled the class imbalance of the dataset, as well as the limitation of higher memory consumption of our approach compared to LSTM.Our work could be extended in the following directions in future:1) Pretraining LogShield on Larger Dataset: The DARPA OPTC dataset contains event logs from 1000 hosts, of which we have used the data of only three hosts.There are also a number of similar cyber attack datasets.One similar dataset to OpTC is the Los Alamos National Laboratory (LANL) Unified Host and Network dataset, which records network and host activities from the laboratory over a 90-day period.These additional data could be used to pretrain LogShield to improve its performance.2) Upgrading the Architecture: The architecture of LogShield might be improved by further modifying the preprocessing layer.More classes of information from system logs can be incorporated to enrich the information in the traces.For example, in the DARPA TC E3 dataset, there were object information of each event such as File Object, Memory Object which was not incorporated in our pre-processing.Additionally, the incorporation of timestamps into the temporal embedding resulted in some loss of information.This aspect could be enhanced by including more precise timing values to improve accuracy and fidelity.3) Improving Prediction: To improve prediction performance, conducting additional experiments with thorough hyperparameter tuning can be beneficial.Techniques like Grid Search can aid in identifying more appropriate hyperparameters for the model.VIII. CONCLUSIONThere have been several successful past efforts in attack detection using deep learning approaches.In this paper, we have explored the effectiveness of transformer based language models in attack detection, particularly advanced persistent threat detection.We have designed a novel approach for processing the system logs from APT datasets, encoding the generated event sequences with multiple embedding layers leveraging transformer architectures.Through extensive experimentation, we have shown that LogShield achieves 98% F1 score in APT detection.The results substantiate the potential of transformer models in the field of cybersecurity to outperform traditional methods.Looking ahead, our future work will focus on enhancing the architecture by incorporating more comprehensive information from the logs into the embeddings.By harnessing additional contextual data, we aim to further boost the accuracy and robustness of our model, contributing to more effective APT detection strategies.IX. ACKNOWLEDGEMENTWe express our sincere gratitude to Md.Monowar Anjum and Majid Babaei, whose expertise and support significantly contributed to the completion of this study.
CONAN: A Practical Real-time APT Detection System with High Accuracy and Efficiency. Chunlin Xiong, IEEE Transactions on Dependable and Secure Computing. 1912020</p>
<p>Language Models Are Few-shot Learners. Tom Brown, Advances in Neural Information Processing Systems. 202033</p>
<p>Malware Detection and Classification Using fastText and BERT. Salih Yesir, İbrahim Sogukpinar, 2021 9th International Symposium on Digital Forensics and Security (ISDFS). IEEE2021</p>
<p>CAN-BERT Do It? Controller Area Network Intrusion Detection System Based on BERT Language Model. Natasha Alkhatib, IEEE/ACS 19th International Conference on Computer Systems and Applications (AICCSA). IEEE2022. 2022</p>
<p>Logbert: Log Anomaly Detection via BERT. Haixuan Guo, Shuhan Yuan, Xintao Wu, 2021 International Joint Conference on Neural Networks (IJCNN). IEEE2021</p>
<p>OpTC-data. GitHub Repository. 2021</p>
<p>Transparent Computing. GitHub Repository, DARPA. </p>
<p>A Graph-based Model for Transmission Network Vulnerability Analysis. Shenhao Yang, IEEE Systems Journal. 1412019</p>
<p>Robust Log-Based Anomaly Detection on Unstable Log Data. Xu Zhang, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering2019ESEC/FSE2019</p>
<p>Evolving Advanced Persistent Threat Detection using Provenance Graph and Metric Learning. Gbadebo Ayoade, Proceedings of the 2020 9th CNS Conference on Communications and Network Security (CNS). the 2020 9th CNS Conference on Communications and Network Security (CNS)2020</p>
<p>HOLMES: Real-Time APT Detection through Correlation of Suspicious Information Flows. Sadegh M Milajerdi, Rigel Gjomemo, R Birhanu Eshete, V N Sekar, Venkatakrishnan, 2019 IEEE Symposium on Security and Privacy (SP). 2019</p>
<p>Detection of Advanced Persistent Threat using Machine-learning Correlation Analysis. Ibrahim Ghafir, Future Generation Computer Systems. 892018</p>
<p>Attention is All You Need. Ashish Vaswani, Advances in Neural Information Processing Systems. 2017</p>
<p>LogBERT: Log Anomaly Detection via BERT. Haixuan Guo, Shuhan Yuan, Xintao Wu, arXiv:2103.04475CoRR. 2021</p>
<p>Log2vec: A Heterogeneous Graph Embedding Based Approach for Detecting Cyber Threats within Enterprise. Fucheng Liu, Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security (CCS '19). the 2019 ACM SIGSAC Conference on Computer and Communications Security (CCS '19)2019</p>
<p>LogAnomaly: Unsupervised Detection of Sequential and Quantitative Anomalies in Unstructured Logs. Weibin Meng, Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-192019</p>
<p>Automated IT System Failure Prediction: A Deep Learning Approach. Ke Zhang, IEEE International Conference on Big Data (Big Data). 2016. 2016</p>
<p>DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning. Min Du, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. the 2017 ACM SIGSAC Conference on Computer and Communications Security2017</p>
<p>A Novel Deep Learning Stack for APT Detection. Tero Bodstrom, Timo Hamalainen, 10.3390/app9061055Applied Sciences. 92019</p>
<p>Unicorn: Runtime Provenance-based Detector for Advanced Persistent Threats. Xueyuan Han, arXiv:2001.015252020arXiv preprint</p>
<p>A Multi-layer Approach for Advanced Persistent Threat Detection Using Machine Learning Based on Network Traffic. Cho Xuan, Duc Do, Duong, Xuan Hoang, Dau, Journal of Information Security. 1212021</p>
<p>A Method of Monitoring and Detecting APT Attacks Based on Unknown Domains. Do Cho, Ha Xuan, Nam Hai, Procedia Computer Science. 1502019</p>
<p>Fast Memory-efficient Anomaly Detection in Streaming Heterogeneous Graphs. Emaad A Manzoor, arXiv:1602.04844CoRR. 2016</p>
<p>Learning Deep Representations for Graph Clustering. Fei Tian, Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence (AAAI'14). the Twenty-Eighth AAAI Conference on Artificial Intelligence (AAAI'14)2014</p>
<p>Failure Prediction in IBM BlueGene/L Event Logs. Y Liang, Y Zhang, H Xiong, R Sahoo, Seventh IEEE International Conference on Data Mining (ICDM 2007). 2007</p>
<p>Detecting Large-scale System Problems by Mining Console Logs. W Xu, L Huang, A Fox, D Patterson, M I Jordan, Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles. the ACM SIGOPS 22nd Symposium on Operating Systems Principles2009</p>
<p>Mining Invariants from Console Logs for System Problem Detection. J.-G Lou, </p>
<p>SPELL: Streaming Parsing of System Event Logs. Min Du, Feifei Li, Proc. IEEE International Conference on Data Mining (ICDM). IEEE International Conference on Data Mining (ICDM)2016</p>
<p>Detecting Large-scale System Problems by Mining Console Logs. Wei Xu, Proc. ACM Symposium on Operating Systems Principles (SOSP. ACM Symposium on Operating Systems Principles (SOSP2009</p>
<p>ANUBIS: a provenance graph-based framework for advanced persistent threat detection. Md Monowar Anjum, Shahrear Iqbal, Benoit Hamelin, Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing. the 37th ACM/SIGAPP Symposium on Applied Computing2022</p>            </div>
        </div>

    </div>
</body>
</html>