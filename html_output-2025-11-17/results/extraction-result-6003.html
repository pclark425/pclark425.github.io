<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6003 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6003</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6003</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-120.html">extraction-schema-120</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.</div>
                <p><strong>Paper ID:</strong> paper-270379850</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.07259v1.pdf" target="_blank">Scientific Computing with Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> We provide an overview of the emergence of large language models for scientific computing applications. We highlight use cases that involve natural language processing of scientific documents and specialized languages designed to describe physical systems. For the former, chatbot style applications appear in medicine, mathematics and physics and can be used iteratively with domain experts for problem solving. We also review specialized languages within molecular biology, the languages of molecules, proteins, and DNA where language models are being used to predict properties and even create novel physical systems at much faster rates than traditional computing methods.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6003.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6003.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Paper summarization (scientific)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Summarization of research papers / literature synthesis using LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Generic use of LLMs to read, extract, and summarize scientific documents to assist researchers; described in the paper as a primary application of LLMs for scientific workflows (e.g., summarization of research papers and chat-style iterative interactions with domain experts).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>unnamed LLM summarization / chatbot pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A generic pipeline where a pre-trained LLM ingests scientific text (papers, abstracts, or sections) and produces condensed summaries or answers via chat-style interaction; often combined with iterative prompting and human-in-the-loop review.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>not specified in this paper (generic references to modern LLMs such as GPT-family, Gemini, LLaMA are made but no single model is prescribed for this task)</td>
                        </tr>
                        <tr>
                            <td><strong>input_type_and_size</strong></td>
                            <td>Described qualitatively as scientific documents / research papers or sections thereof; no concrete numbers of papers or token counts are provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_approach</strong></td>
                            <td>Summarization and iterative dialogue (prompt engineering) possibly combined with retrieval (RAG) for grounding; the paper frames this as extracting relevant information and proposing solutions for human review.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Condensed summaries, answers to researcher queries, proposed solution steps or derivations (chatbot responses).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not specified for a concrete system in this paper; the paper mentions human expert review and iterative correction by experts as the intended evaluation/validation mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>results</strong></td>
                            <td>No concrete quantitative results reported in this paper for a summarization system; described qualitatively as a promising application enabling faster triage of textual scientific knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>datasets_or_benchmarks</strong></td>
                            <td>None specific for summarization reported in this paper (general corpora for LLM pretraining are referenced elsewhere).</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Hallucination risk, domain-specific vocabulary and semantics differing from general language, need for human expert verification; limited details provided.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons_to_other_methods</strong></td>
                            <td>No direct empirical comparisons in this paper; the paper notes RAG and fine-tuning as complementary techniques to improve reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Scientific Computing with Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6003.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6003.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval-Augmented Generation (RAG)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that augments a generative LLM with retrieved documents from a local database to ground generation in external evidence and mitigate model hallucinations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Retrieval-augmented generation for knowledge-intensive nlp tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Retrieval-Augmented Generation (method)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A two-stage approach where a retrieval component fetches relevant passages/documents from an external corpus and a generative LLM conditions on these retrieved texts to produce answers or summaries, enabling use of local information not embedded in the model.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>not fixed in this paper (RAG presented as a general technique; the paper cites RAG literature and notes its utility to reduce hallucinations in medical contexts)</td>
                        </tr>
                        <tr>
                            <td><strong>input_type_and_size</strong></td>
                            <td>Query + external indexed corpus / local database; no concrete corpus sizes given here.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_approach</strong></td>
                            <td>Evidence-grounded generation: retrieve supporting documents then synthesize/compose final output conditioned on retrieved evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Grounded answers, summaries, or responses that reference retrieved evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not specified concretely in this review; the paper notes RAG is known to reduce hallucinations and is useful in high-stakes domains (e.g., medicine) where human validation is required.</td>
                        </tr>
                        <tr>
                            <td><strong>results</strong></td>
                            <td>No new experimental results in this paper; RAG is recommended as an important tool to reduce hallucination and to enable LLMs to operate on local domain knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>datasets_or_benchmarks</strong></td>
                            <td>Not specified here; RAG literature typically uses domain corpora (not enumerated in this survey).</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Quality depends on retrieval effectiveness and the indexing corpus; requires system integration (retriever + generator); does not fully eliminate need for human verification.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons_to_other_methods</strong></td>
                            <td>Presented as complementary to fine-tuning and prompt engineering; contrasted qualitatively with pure in-model knowledge approaches (i.e., fine-tuning or relying solely on pretrained parameters).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Scientific Computing with Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6003.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6003.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FunSearch</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FunSearch (LLM-guided function search)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-driven system that searches for interpretable functional formalisms (candidate analytic expressions or heuristics) and evaluates them with a systematic external evaluator in a feedback loop with domain experts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>FunSearch</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An approach that uses an LLM to propose interpretable function forms (analytical expressions or heuristics) and couples the LLM with a systematic evaluator that tests candidates, enabling iterative refinement and human-in-the-loop validation.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>not specified in this paper (the survey references FunSearch generically without giving the underlying model name or size)</td>
                        </tr>
                        <tr>
                            <td><strong>input_type_and_size</strong></td>
                            <td>Problem specifications from combinatorics/algorithmic tasks (e.g., cap set problem, online bin packing); number of input documents not described—this is a problem-driven synthesis rather than a many-papers distillation.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_approach</strong></td>
                            <td>Search-and-evaluate loop: LLM proposes symbolic/interpretable hypotheses; a separate evaluator executes systematic evaluation of candidate functions; human experts can be in the loop to guide or correct.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Interpretable functions, new constructions for mathematical/combinatorial problems, novel heuristics for algorithmic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Domain-specific empirical evaluation: FunSearch tested candidate constructions on the cap set problem and online bin packing benchmarks; success judged by whether proposed constructions improve over known baselines or solve formal properties.</td>
                        </tr>
                        <tr>
                            <td><strong>results</strong></td>
                            <td>Reported qualitative successes in the survey: FunSearch discovered new constructions of large cap sets and found novel heuristics that improved on widely used baselines in online bin packing (no numerical metrics provided in this survey text).</td>
                        </tr>
                        <tr>
                            <td><strong>datasets_or_benchmarks</strong></td>
                            <td>Problem-specific evaluation scenarios (cap set constructions, online bin packing benchmarks); no standardized literature corpora used or reported in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Described at a high level: requires a reliable external evaluator; applicability may be problem-specific; the paper does not provide failure-mode details.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons_to_other_methods</strong></td>
                            <td>Reported to find novel solutions improving on traditional heuristics in at least one domain (online bin packing); compared qualitatively against brute-force/intractable methods by offering interpretable constructions rather than raw brute-force search.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Scientific Computing with Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6003.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6003.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaGeometry</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AlphaGeometry (LLM-guided symbolic proof engine)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system that uses an LLM to guide a symbolic deduction engine to construct formal, human-readable mathematical proofs (here applied to Euclidean plane geometry).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AlphaGeometry</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An architecture in which an LLM proposes steps/branches and a symbolic deduction engine carries out formal derivations; the LLM steers the proof search at branching points and the combined system outputs human-readable proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>not specified in this paper (survey mentions AlphaGeometry generically without model details)</td>
                        </tr>
                        <tr>
                            <td><strong>input_type_and_size</strong></td>
                            <td>Individual mathematical problems (Euclidean geometry theorems); not framed as processing large numbers of scholarly papers.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_approach</strong></td>
                            <td>Chain-of-thought / guided symbolic search: LLM provides high-level guidance for branching points, integrated with a formal symbolic verifier/engine to ensure correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Human-readable formal proofs, comparable in style to human proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Benchmarking against human performance: performance is reported as close to an average IMO gold medallist on Euclidean geometry tasks in this survey description.</td>
                        </tr>
                        <tr>
                            <td><strong>results</strong></td>
                            <td>Survey states AlphaGeometry generates human-readable proofs close to the performance of an average IMO gold medallist; no detailed metrics are provided in this review text.</td>
                        </tr>
                        <tr>
                            <td><strong>datasets_or_benchmarks</strong></td>
                            <td>Geometry problem sets (implied IMO-level problems); not a literature corpus or paper-distillation dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Requires tightly integrated symbolic verifier to avoid hallucinated or invalid steps; survey does not detail broader failure modes.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons_to_other_methods</strong></td>
                            <td>Compared qualitatively to human expert performance (IMO gold medallist level); contrasted with purely neural end-to-end proof attempts by emphasizing symbolic verification plus LLM guidance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Scientific Computing with Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6003.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6003.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hartree-Fock chatbot</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-guided derivation chatbot for Hartree-Fock re-derivations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A chatbot-based application where an LLM is given specialized prompts to guide analytic derivations (Hartree-Fock Hamiltonians) and can re-derive many results from research papers with minor mistakes corrected by humans.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM-based analytic derivation chatbot</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A prompt-engineered chatbot that is given specialized instructions to follow correct analytic steps for a scientific derivation; the chatbot outputs stepwise derivations which are then reviewed and corrected by human experts.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>not specified in this paper (referred to generically as 'an LLM' guided by specialized prompts)</td>
                        </tr>
                        <tr>
                            <td><strong>input_type_and_size</strong></td>
                            <td>Individual research papers or derivation tasks (e.g., published Hartree-Fock Hamiltonians); not described as ingesting large corpora of papers.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_approach</strong></td>
                            <td>Iterative prompt engineering and chain-of-thought style guidance to produce derivations; human-in-the-loop correction.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Stepwise analytic derivations (re-derived Hamiltonians) and textual explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Practical correctness check: in the cited example the LLM successfully re-derived 13 of 15 Hartree-Fock Hamiltonians with only minor mistakes that were correctable by humans.</td>
                        </tr>
                        <tr>
                            <td><strong>results</strong></td>
                            <td>Qualitative result reported in this paper: high success rate (13/15) in re-deriving Hamiltonians from research papers using the prompt-engineered chatbot, with errors small and fixable by experts.</td>
                        </tr>
                        <tr>
                            <td><strong>datasets_or_benchmarks</strong></td>
                            <td>Not applicable / not reported; evaluation was done on a set of derivations (15 Hamiltonians) in the cited study.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Mistakes still occur and require expert correction; mathematical/scientific precision is challenging for LLMs and benefits from careful prompting and human oversight.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons_to_other_methods</strong></td>
                            <td>No formal comparison to non-LLM approaches provided; the approach is presented as a tool to assist experts rather than fully replace formal derivation methods.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Scientific Computing with Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6003.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6003.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Meditron-70B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Meditron-70B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source generative medical LLM trained from scratch on medical papers, abstracts, and clinical guidelines, designed for biomedical Q&A and related tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Meditron-70b: Scaling medical pretraining for large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Meditron-70B (medical LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A domain-specific large language model pre-trained on a large medical corpus (papers, abstracts, clinical guidelines) to provide medical QA and related capabilities; open-source to enable community fine-tuning and evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>Meditron-70B (the paper reports this model as the system itself)</td>
                        </tr>
                        <tr>
                            <td><strong>input_type_and_size</strong></td>
                            <td>Medical domain text: research papers, abstracts, clinical guidelines; the survey does not provide exact corpus size in this summary but indicates training from scratch on medical literature.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_approach</strong></td>
                            <td>Domain-specific pretraining (scaling medical pretraining) and fine-tuning on biomedical benchmarks; effectively synthesizes medical literature into model parameters via pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Biomedical question answering and other medical NLP outputs (text responses, summaries, QA).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Benchmark evaluation on biomedical Q&A benchmarks; compared against closed-source Med-PaLM-2.</td>
                        </tr>
                        <tr>
                            <td><strong>results</strong></td>
                            <td>Reported in this paper: Meditron-70B achieved accuracy within ~10% of Med-PaLM-2 on medical benchmarks (as stated in the survey). No further numerical breakdown is provided in this survey text.</td>
                        </tr>
                        <tr>
                            <td><strong>datasets_or_benchmarks</strong></td>
                            <td>Biomedical Q&A benchmarks (not enumerated in the survey); trained from corpora of medical papers, abstracts, and clinical guidelines.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Medical hallucination remains a major concern; domain explainability and regulatory approval (e.g., FDA) remain barriers to clinical adoption; survey emphasizes need for RAG and human oversight.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons_to_other_methods</strong></td>
                            <td>Compared qualitatively to closed-source Med-PaLM-2 (within ~10% accuracy) and presented as an open-source alternative enabling broader research.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Scientific Computing with Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Retrieval-augmented generation for knowledge-intensive nlp tasks <em>(Rating: 2)</em></li>
                <li>Meditron-70b: Scaling medical pretraining for large language models <em>(Rating: 2)</em></li>
                <li>Llava-med: Training a large language-and-vision assistant for biomedicine in one day <em>(Rating: 1)</em></li>
                <li>Can generalist foundation models outcompete special-purpose tuning? case study in medicine <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6003",
    "paper_id": "paper-270379850",
    "extraction_schema_id": "extraction-schema-120",
    "extracted_data": [
        {
            "name_short": "Paper summarization (scientific)",
            "name_full": "Summarization of research papers / literature synthesis using LLMs",
            "brief_description": "Generic use of LLMs to read, extract, and summarize scientific documents to assist researchers; described in the paper as a primary application of LLMs for scientific workflows (e.g., summarization of research papers and chat-style iterative interactions with domain experts).",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "unnamed LLM summarization / chatbot pipeline",
            "system_description": "A generic pipeline where a pre-trained LLM ingests scientific text (papers, abstracts, or sections) and produces condensed summaries or answers via chat-style interaction; often combined with iterative prompting and human-in-the-loop review.",
            "llm_model_used": "not specified in this paper (generic references to modern LLMs such as GPT-family, Gemini, LLaMA are made but no single model is prescribed for this task)",
            "input_type_and_size": "Described qualitatively as scientific documents / research papers or sections thereof; no concrete numbers of papers or token counts are provided in this paper.",
            "distillation_approach": "Summarization and iterative dialogue (prompt engineering) possibly combined with retrieval (RAG) for grounding; the paper frames this as extracting relevant information and proposing solutions for human review.",
            "output_type": "Condensed summaries, answers to researcher queries, proposed solution steps or derivations (chatbot responses).",
            "evaluation_methods": "Not specified for a concrete system in this paper; the paper mentions human expert review and iterative correction by experts as the intended evaluation/validation mechanism.",
            "results": "No concrete quantitative results reported in this paper for a summarization system; described qualitatively as a promising application enabling faster triage of textual scientific knowledge.",
            "datasets_or_benchmarks": "None specific for summarization reported in this paper (general corpora for LLM pretraining are referenced elsewhere).",
            "challenges_or_limitations": "Hallucination risk, domain-specific vocabulary and semantics differing from general language, need for human expert verification; limited details provided.",
            "comparisons_to_other_methods": "No direct empirical comparisons in this paper; the paper notes RAG and fine-tuning as complementary techniques to improve reliability.",
            "uuid": "e6003.0",
            "source_info": {
                "paper_title": "Scientific Computing with Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "RAG",
            "name_full": "Retrieval-Augmented Generation (RAG)",
            "brief_description": "A method that augments a generative LLM with retrieved documents from a local database to ground generation in external evidence and mitigate model hallucinations.",
            "citation_title": "Retrieval-augmented generation for knowledge-intensive nlp tasks",
            "mention_or_use": "mention",
            "system_name": "Retrieval-Augmented Generation (method)",
            "system_description": "A two-stage approach where a retrieval component fetches relevant passages/documents from an external corpus and a generative LLM conditions on these retrieved texts to produce answers or summaries, enabling use of local information not embedded in the model.",
            "llm_model_used": "not fixed in this paper (RAG presented as a general technique; the paper cites RAG literature and notes its utility to reduce hallucinations in medical contexts)",
            "input_type_and_size": "Query + external indexed corpus / local database; no concrete corpus sizes given here.",
            "distillation_approach": "Evidence-grounded generation: retrieve supporting documents then synthesize/compose final output conditioned on retrieved evidence.",
            "output_type": "Grounded answers, summaries, or responses that reference retrieved evidence.",
            "evaluation_methods": "Not specified concretely in this review; the paper notes RAG is known to reduce hallucinations and is useful in high-stakes domains (e.g., medicine) where human validation is required.",
            "results": "No new experimental results in this paper; RAG is recommended as an important tool to reduce hallucination and to enable LLMs to operate on local domain knowledge.",
            "datasets_or_benchmarks": "Not specified here; RAG literature typically uses domain corpora (not enumerated in this survey).",
            "challenges_or_limitations": "Quality depends on retrieval effectiveness and the indexing corpus; requires system integration (retriever + generator); does not fully eliminate need for human verification.",
            "comparisons_to_other_methods": "Presented as complementary to fine-tuning and prompt engineering; contrasted qualitatively with pure in-model knowledge approaches (i.e., fine-tuning or relying solely on pretrained parameters).",
            "uuid": "e6003.1",
            "source_info": {
                "paper_title": "Scientific Computing with Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "FunSearch",
            "name_full": "FunSearch (LLM-guided function search)",
            "brief_description": "An LLM-driven system that searches for interpretable functional formalisms (candidate analytic expressions or heuristics) and evaluates them with a systematic external evaluator in a feedback loop with domain experts.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "FunSearch",
            "system_description": "An approach that uses an LLM to propose interpretable function forms (analytical expressions or heuristics) and couples the LLM with a systematic evaluator that tests candidates, enabling iterative refinement and human-in-the-loop validation.",
            "llm_model_used": "not specified in this paper (the survey references FunSearch generically without giving the underlying model name or size)",
            "input_type_and_size": "Problem specifications from combinatorics/algorithmic tasks (e.g., cap set problem, online bin packing); number of input documents not described—this is a problem-driven synthesis rather than a many-papers distillation.",
            "distillation_approach": "Search-and-evaluate loop: LLM proposes symbolic/interpretable hypotheses; a separate evaluator executes systematic evaluation of candidate functions; human experts can be in the loop to guide or correct.",
            "output_type": "Interpretable functions, new constructions for mathematical/combinatorial problems, novel heuristics for algorithmic tasks.",
            "evaluation_methods": "Domain-specific empirical evaluation: FunSearch tested candidate constructions on the cap set problem and online bin packing benchmarks; success judged by whether proposed constructions improve over known baselines or solve formal properties.",
            "results": "Reported qualitative successes in the survey: FunSearch discovered new constructions of large cap sets and found novel heuristics that improved on widely used baselines in online bin packing (no numerical metrics provided in this survey text).",
            "datasets_or_benchmarks": "Problem-specific evaluation scenarios (cap set constructions, online bin packing benchmarks); no standardized literature corpora used or reported in this survey.",
            "challenges_or_limitations": "Described at a high level: requires a reliable external evaluator; applicability may be problem-specific; the paper does not provide failure-mode details.",
            "comparisons_to_other_methods": "Reported to find novel solutions improving on traditional heuristics in at least one domain (online bin packing); compared qualitatively against brute-force/intractable methods by offering interpretable constructions rather than raw brute-force search.",
            "uuid": "e6003.2",
            "source_info": {
                "paper_title": "Scientific Computing with Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "AlphaGeometry",
            "name_full": "AlphaGeometry (LLM-guided symbolic proof engine)",
            "brief_description": "A system that uses an LLM to guide a symbolic deduction engine to construct formal, human-readable mathematical proofs (here applied to Euclidean plane geometry).",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "AlphaGeometry",
            "system_description": "An architecture in which an LLM proposes steps/branches and a symbolic deduction engine carries out formal derivations; the LLM steers the proof search at branching points and the combined system outputs human-readable proofs.",
            "llm_model_used": "not specified in this paper (survey mentions AlphaGeometry generically without model details)",
            "input_type_and_size": "Individual mathematical problems (Euclidean geometry theorems); not framed as processing large numbers of scholarly papers.",
            "distillation_approach": "Chain-of-thought / guided symbolic search: LLM provides high-level guidance for branching points, integrated with a formal symbolic verifier/engine to ensure correctness.",
            "output_type": "Human-readable formal proofs, comparable in style to human proofs.",
            "evaluation_methods": "Benchmarking against human performance: performance is reported as close to an average IMO gold medallist on Euclidean geometry tasks in this survey description.",
            "results": "Survey states AlphaGeometry generates human-readable proofs close to the performance of an average IMO gold medallist; no detailed metrics are provided in this review text.",
            "datasets_or_benchmarks": "Geometry problem sets (implied IMO-level problems); not a literature corpus or paper-distillation dataset.",
            "challenges_or_limitations": "Requires tightly integrated symbolic verifier to avoid hallucinated or invalid steps; survey does not detail broader failure modes.",
            "comparisons_to_other_methods": "Compared qualitatively to human expert performance (IMO gold medallist level); contrasted with purely neural end-to-end proof attempts by emphasizing symbolic verification plus LLM guidance.",
            "uuid": "e6003.3",
            "source_info": {
                "paper_title": "Scientific Computing with Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Hartree-Fock chatbot",
            "name_full": "LLM-guided derivation chatbot for Hartree-Fock re-derivations",
            "brief_description": "A chatbot-based application where an LLM is given specialized prompts to guide analytic derivations (Hartree-Fock Hamiltonians) and can re-derive many results from research papers with minor mistakes corrected by humans.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "LLM-based analytic derivation chatbot",
            "system_description": "A prompt-engineered chatbot that is given specialized instructions to follow correct analytic steps for a scientific derivation; the chatbot outputs stepwise derivations which are then reviewed and corrected by human experts.",
            "llm_model_used": "not specified in this paper (referred to generically as 'an LLM' guided by specialized prompts)",
            "input_type_and_size": "Individual research papers or derivation tasks (e.g., published Hartree-Fock Hamiltonians); not described as ingesting large corpora of papers.",
            "distillation_approach": "Iterative prompt engineering and chain-of-thought style guidance to produce derivations; human-in-the-loop correction.",
            "output_type": "Stepwise analytic derivations (re-derived Hamiltonians) and textual explanations.",
            "evaluation_methods": "Practical correctness check: in the cited example the LLM successfully re-derived 13 of 15 Hartree-Fock Hamiltonians with only minor mistakes that were correctable by humans.",
            "results": "Qualitative result reported in this paper: high success rate (13/15) in re-deriving Hamiltonians from research papers using the prompt-engineered chatbot, with errors small and fixable by experts.",
            "datasets_or_benchmarks": "Not applicable / not reported; evaluation was done on a set of derivations (15 Hamiltonians) in the cited study.",
            "challenges_or_limitations": "Mistakes still occur and require expert correction; mathematical/scientific precision is challenging for LLMs and benefits from careful prompting and human oversight.",
            "comparisons_to_other_methods": "No formal comparison to non-LLM approaches provided; the approach is presented as a tool to assist experts rather than fully replace formal derivation methods.",
            "uuid": "e6003.4",
            "source_info": {
                "paper_title": "Scientific Computing with Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Meditron-70B",
            "name_full": "Meditron-70B",
            "brief_description": "An open-source generative medical LLM trained from scratch on medical papers, abstracts, and clinical guidelines, designed for biomedical Q&A and related tasks.",
            "citation_title": "Meditron-70b: Scaling medical pretraining for large language models",
            "mention_or_use": "mention",
            "system_name": "Meditron-70B (medical LLM)",
            "system_description": "A domain-specific large language model pre-trained on a large medical corpus (papers, abstracts, clinical guidelines) to provide medical QA and related capabilities; open-source to enable community fine-tuning and evaluation.",
            "llm_model_used": "Meditron-70B (the paper reports this model as the system itself)",
            "input_type_and_size": "Medical domain text: research papers, abstracts, clinical guidelines; the survey does not provide exact corpus size in this summary but indicates training from scratch on medical literature.",
            "distillation_approach": "Domain-specific pretraining (scaling medical pretraining) and fine-tuning on biomedical benchmarks; effectively synthesizes medical literature into model parameters via pretraining.",
            "output_type": "Biomedical question answering and other medical NLP outputs (text responses, summaries, QA).",
            "evaluation_methods": "Benchmark evaluation on biomedical Q&A benchmarks; compared against closed-source Med-PaLM-2.",
            "results": "Reported in this paper: Meditron-70B achieved accuracy within ~10% of Med-PaLM-2 on medical benchmarks (as stated in the survey). No further numerical breakdown is provided in this survey text.",
            "datasets_or_benchmarks": "Biomedical Q&A benchmarks (not enumerated in the survey); trained from corpora of medical papers, abstracts, and clinical guidelines.",
            "challenges_or_limitations": "Medical hallucination remains a major concern; domain explainability and regulatory approval (e.g., FDA) remain barriers to clinical adoption; survey emphasizes need for RAG and human oversight.",
            "comparisons_to_other_methods": "Compared qualitatively to closed-source Med-PaLM-2 (within ~10% accuracy) and presented as an open-source alternative enabling broader research.",
            "uuid": "e6003.5",
            "source_info": {
                "paper_title": "Scientific Computing with Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Retrieval-augmented generation for knowledge-intensive nlp tasks",
            "rating": 2,
            "sanitized_title": "retrievalaugmented_generation_for_knowledgeintensive_nlp_tasks"
        },
        {
            "paper_title": "Meditron-70b: Scaling medical pretraining for large language models",
            "rating": 2,
            "sanitized_title": "meditron70b_scaling_medical_pretraining_for_large_language_models"
        },
        {
            "paper_title": "Llava-med: Training a large language-and-vision assistant for biomedicine in one day",
            "rating": 1,
            "sanitized_title": "llavamed_training_a_large_languageandvision_assistant_for_biomedicine_in_one_day"
        },
        {
            "paper_title": "Can generalist foundation models outcompete special-purpose tuning? case study in medicine",
            "rating": 1,
            "sanitized_title": "can_generalist_foundation_models_outcompete_specialpurpose_tuning_case_study_in_medicine"
        }
    ],
    "cost": 0.0145155,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Scientific Computing with Large Language Models</p>
<p>Christopher Culver 
Peter Hicks 
Mihailo Milenkovic 
Sanjif Shanmugavelu 
Tobias Becker 
Scientific Computing with Large Language Models
3927A47F28D29D760D32CA4B37FAA278Maxeler Technologies, a Groq Company
We provide an overview of the emergence of large language models for scientific computing applications.We highlight use cases that involve natural language processing of scientific documents and specialized languages designed to describe physical systems.For the former, chatbot style applications appear in medicine, mathematics and physics and can be used iteratively with domain experts for problem solving.We also review specialized languages within molecular biology, the languages of molecules, proteins, and DNA where language models are being used to predict properties and even create novel physical systems at much faster rates than traditional computing methods.</p>
<p>INTRODUCTION</p>
<p>Language is a key component of human communication that has greatly enhanced the evolution of the species.Using language, humans are able to express ideas, exchange information, and collectively make plans at scales unlike any other in the animal kingdom.</p>
<p>Since the dawn of computing, humans have strived to create AI to automate human tasks.</p>
<p>Recently, large language models (LLMs) demonstrated the ability to generate text that is often indistinguishable from human-written text.This enables them to aid a wide range of language-oriented tasks such as customer support, document summarization, language translation, coding assistance or content generation.</p>
<p>As with most AI applications, using LLMs requires two distinct phases: training and inference.Training is the process of feeding large amounts of text data from books, articles, and websites into the model in order to embed syntactical and semantic rules as well as a wide range of knowledge into the model.This process has to occur only once but is computationally demanding, taking weeks to months on high performance computing (HPC) arXiv:2406.07259v1[cs.CL] 11 Jun 2024 systems.Inference refers to using a trained model: A query is provided to the model and it will predict an output sequence that will provide a suitable answer to the query.A single inference is less computationally demanding than training, but the challenge lies in that potentially thousands to millions of users interacting with a model will all require inferences to be computed in fractions of a second.Until recently, LLMs has been hampered by the extreme combinatorial complexity that arises from the large vocabulary of human language and its complex rules.This has made it impossible to generate longer, high quality text sequences.However, a number of recent innovations have led to a breakthrough in LLM performance.Modern LLMs are based on a type of artificial neural network called the transformer [1], one of the most important innovations in the field of AI in recent years.</p>
<p>Central to the transformer architecture is a technique called attention that allows the model to capture long-range dependencies while limiting the combinatorial complexity in longer text sequences.At the same time, models have also increased from millions to billions of parameters, giving them enough capacity to not only understand the syntax, but also the semantics of natural language.Finally, the introduction of new AI inference accelerators, such as the Groq Language Processing Unit (LPU TM ) [2], has led to significant improvements in throughput and latency during inference.This has made LLMs usable without encountering tedious delays during queries, paving the way for a new design space of real time applications.</p>
<p>Many current LLM use cases focus on direct and simple language-related tasks such as question answering, customer support, chat bots, etc.There is potential for LLMs to be useful in a wider range of application areas including scientific computing.Here, we envision broadly two different approaches: firstly, LLMs could assist scientific processes by being used as a tool on scientific text, e.g., summarization of research papers.Scientific language is noticeably distinct from ordinary language due to using complex noun combinations and a specialized vocabulary.Within science, different disciplines employ language in different ways, it was shown that biology has imprecise yet densely packed language while physics typically has the opposite [3].The description of sciences through natural language is the mechanism the enables humans to collectively solve problems and amass knowledge.Secondly, it is also conceivable to treat processes in physics, biology, or chemistry as specialized languages.</p>
<p>Molecules, proteins, and DNA all can be seen as languages made up of a specific character set with syntactic rules and semantic meaning completely unlike any ordinary language.It is therefore possible to train special language models just for the purpose of understanding DNA as a language.For general languages applied to scientific disciplines and the specialized languages encoding the behavior of physical processes its natural to apply LLMs to these language tasks.</p>
<p>SEQUENCE MODELLING ARCHITECTURES</p>
<p>Originally, sequence modelling tasks were done by RNNs [4], and LSTMs [5], until the introduction of the Transformer model [1], which are now ubiquitous for sequence modelling tasks.In this section, we give a brief overview of the historical and current state-of-the-art models in this area.</p>
<p>The transformer architecture consists of stacked layers of feed-forward networks and attention blocks.The attention mechanism works as follows: Given the inputs Q, K, V ∈ R N ×d , it computes the outputs O according to O = softmax(QK T )V , ignoring a normalization factor.We can interpret the attention mechanism as measuring the similarity between a set of d queries and keys (d is the length of the input sequence), and retrieving a weighted sum of the values corresponding to those keys based on the similarity scores.There are three main variants of the transformer architecture: encoder models, which process input sequences in parallel, decoder models, which generate sequences sequentially, and encoder-decoder models, which take a sequence of inputs and generate a new sequence of outputs.</p>
<p>Originally, transformer encoder-only models were popularized by the BERT architecture [6].Encoders can be trained by masked language modelling -removing some words and predicting them based on the surrounding context during training.Other methods such as contrastive objectives like CLIP [7] based models, or classification objectives with sentence transformers [8] exist.Encoder style language models have been used for a wide variety of applications, such as clustering and classification tasks, aligning different modalities in models like LLaVA [9], Stable Diffusion [10], and retrieval augmented generation (RAG) [11].</p>
<p>Another popular framework is auto-regressive language modelling, which generates a sequence x by predicting a sequence of symbols based on the previous symbols in the sequence one at a time, i.e. p(x) = n i=1 p(s n |s 1 , . . ., s n−1 ).The GPT series of models [12], which are decoder only transformers, work exactly this way and can be trained on large amounts of unlabelled textual data.</p>
<p>Transformer-based language models have exhibited predictable improvement in perplex-ity, ability to predict dataset information, both by increasing the size of the model as well as the amount of data used for training [13].This has led to a drastic increase in the capabilities of recent language models, with models spanning trillions of parameters including GPT4 [14],Gemini [15], Llama [16,17] and Mixtral [18] achieving state of the art performance in many language modelling tasks.</p>
<p>One of the challenges with pre-trained language models is that the information embedded into the model if fixed and may be lacking specialised domain knowledge.One possible solution is fine-tuning the model: it is a much more lightweight training step where a model can be specialised for certain tasks, significantly improving the performance of the model [19].</p>
<p>Another important specialisation technique is retrieval augmented generation (RAG) where information from a local database is fed into the model, which enables the model to operate on local information which is not part of the model itself [11].</p>
<p>A current limitation of transformers is the quadratic time complexity of the attention mechanism, which poses practical limits on sequence lengths and limits a model's ability to understand long distance context.This is driving research into more efficient operations to replace the attention mechanism, such as the Hyena operator [20], sparse matrix multiplications such as MonarchMixer [21], and most recently state space models like S4 and Mamba [22].Newer architectures achieve very good performance on numerous tasks and even achieve lower perplexity for language modelling compared to transformer models with the same number of parameters.There are still some tasks such as the copying task [23], leading to combinations of attention mechanism with more efficient primitives, such as SSM blocks [24] which were recently scaled up to sizes comparable to leading transformer-based models [25].</p>
<p>Notably, the architectures mentioned above are not limited to only natural language related tasks, but can also model other discrete sequential data of different modalities such as audio [26,27], images [28,29], video [30], and the "language" of biology.</p>
<p>MOLECULAR BIOLOGY</p>
<p>Molecular biology is the study of living organisms through the interaction of molecules, the building blocks of all materials.If we can understand how specific molecules dictate the interactions between proteins, then drugs that target specific diseases or viruses can be designed more readily as key ingredients will be identified.Unfortunately, this link between molecules and their biological utility is so complex that serendipitous drug discovery is still relatively common [31].Part of this is due to the intractably complex chemical space of drug like molecules (about 10 33 ) that are estimated to be synthesizable [32].Immense computing and automation efforts are required to explore only a tiny fraction of this domain.In the following we highlight some applications of LLMs to the language of molecules, proteins, and DNA, and refer to Ref. [33] for a thorough survey.</p>
<p>Molecules</p>
<p>Molecules are a group of atoms held together by chemical bonds, attractive forces between the constituent atoms.Before trying to physically synthesize a molecule, computations are performed on a candidate molecule to predict its physical properties to ensure it meets the target criteria.These computations are performed using molecular dynamics (MD) or density functional theory (DFT) simulations which require HPC resources.MD simulations compute the positions of up to billions of atoms while DFT computations simulate only the electrons of the system using a mean field approach.While there exist efforts to use neural networks to accelerate such algorithms, we focus here on the application of transformers to the language of molecular structure which bypasses these expensive algorithms.</p>
<p>The atomic content and even physical structure of a molecule can be represented precisely by a 1-D string, i.e., the chemical formula for water is H 2 O.A string encoding in principle encompasses all of the properties of the molecule: size, shape, toxicity, 3-D structure, etc since these are the only building blocks for molecules.Traditionally the properties have to be explicitly computed through the atomic interactions using MD or DFT solvers.With the recent advancements of transformers to understand not just syntactic but semantic information, its natural to wonder to try and employ transformers to learn the semantic relationship between atomic sequences and physical properties.The chemical formula above is a bit naive and a more complete molecular description can be specified by, for example, SMILES [34] or SELFIES [35].These molecular languages map both the atoms and chemical bonds to characters, for example in SMILES CO 2 is represented as C(=O)=O where "=" represents a double bond.</p>
<p>The production of enough molecular data to train LLMs has only become available over the last two decades through the use of high-throughput screening (HTS).HTS with robotic assistance can currently screen over 100,000 compounds per day producing orders of magnitude more data than previously possible.There are quite large data sets for both training and bench-marking purposes such as PubChem [36] and MoleculeNet [37].Much of this data is unlabelled which works well with the self-supervised training language models usually undergo.These data sets are especially useful for validating a model's ability to predict properties given an atomic string representation.</p>
<p>Encoder style models are primarily used for molecular property prediction and there are many BERT [38] based models due to the large collections of unlabelled chemical data.[39] is one such example which is trained using masked language modelling where input molecular strings will be randomly masked.Applying masking to the pretraining phases enables the model to learn a very general embedding of the molecular space and the role different atoms and bonds play.After this fine-tuning is applied for classification tasks, SMILES-BERT outperformed other state-of-the-art models in property prediction as of the time of its publication.One drawback to BERT style models is they focus too heavily on sequence information, causing them to struggle with comprehending molecular structure [33].Architectures which are also able to learn chemical structure information are emerging through specialised transformers, one based on relative position transformers is MolFormer [40].This model was trained on one billion molecules and shown to capture the molecular substructure and spatial interatomic distances.These kinds of advancements are critical to enabling downstream inference tasks like determining a physiological effect from quantum mechanical properties of molecules.</p>
<p>SMILES-BERT</p>
<p>For designing novel molecules with specific behavior it is common to use GPT like architectures where the transformer will output molecular strings.A pioneering work was MolGPT [41] which as far as the authors are aware was the first attempt at using GPT architectures on molecular language.MolGPT is able to be trained on multiple properties and then used to generate novel valid and unique atomic configurations with the desired behavior.There have since been several advancements based around this architecture, for example cMolGPT [42] which can be used to design molecules that target specific proteins.</p>
<p>By inputting SMILES strings of a target molecule, the generated molecule should interact with, every inference of cMolGPT produces a new molecular sequence, which can be checked against databases for uniqueness.The cMolGPT model had a 90% unique compound rate when generating 10,000 valid molecules on three different targets.These generative models output new molecular compounds but not their properties making it important that encoder only models, like BERT style ones above, continue improving their predictive power.</p>
<p>Proteins</p>
<p>Proteins are made up of amino acids, organic molecules composed of specific compounds, and perform numerous functions inside living organisms.While there are hundreds of known amino acids, only 20 are needed to encode the function of proteins and their biological purpose.Proteins can serve as enzymes, send messages between cells, or provide solid structure in an otherwise fluid environment.Proteins are created at a molecular level by ribosome which reads the RNA of a cell and produces a 1-dimensional chain of amino acids.This helps validate the usage of our language of proteins, which are characters representing the amino acids as a 1-D sequence.Atomic interactions will cause this 1-dimensional chain to fold into a 3-D structure after it has been created.The 3-D structure of a protein is directly responsible for its biological function and is in principle encoded in the textual representation.</p>
<p>There are two traditional methods to protein folding, the task of computing its 3-D structure from its textual encoding.One method is to perform a direct numerical simulation based on the physics of molecular interactions.Another approach is to use an evolutionary algorithm and do a simulation, which starts with a "bad" protein and evolves into a useful one.There are both HPC and distributed computing solutions for these algorithms, one example of the latter is Folding@Home, which anyone can contribute personal computing resources too, and has had tens of thousands of users.</p>
<p>For training LLMs on the language of proteins two resources are UniProt [43], which is a hub for protein functional information containing both manually and automatically annotated proteins, and Big Fantastic Database (BFD) which contains over 2 billion protein sequences.A general analysis of transformer architectures applied to datasets in UniProt and to BFD was performed by the ProtTrans project [44].The project showed that certain architectures were able to perform better than state-of-the-art evolutionary methods while avoiding expensive database searches.Compared to traditional protein sequence algorithms the LLMs were 5-30 times faster, dependent on model architecture, still the entire human proteome (20,353 proteins with a median length of 415 amino acids) takes 40 minutes to process.</p>
<p>The first protein folding LLM to accurately predict atomic resolution structure was Al-phaFold [45].They employed a new architecture using multiple sequence alignment, which highlights homologous features that appear between sequences, which is common in protein strings.To compute the structure of a protein with 2,500 residues took 18 hours, only after this process can researchers learn about the protein's functionality.A more recent model is ESM-2 [46] which uses transformers with up to 15B parameters and avoids multi sequence alignments.Though there is no substantial improvement to protein structure accuracy there is an almost 60x inference speedup in comparison to other state-of-the-art models.The fast time to 3-D structure prediction will furthermore guide the understanding of how specific proteins have impact at much larger scales [47].</p>
<p>Genomics</p>
<p>Genomics and transcriptomics are the study of DNA and RNA respectively.These subject areas both aim to deepen our knowledge of the biological macro-molecules they relate to, and then apply this knowledge to various downstream tasks.On a high level these tasks are: the understanding of coding-DNA/RNA and its effects on proteins, and the understanding of non-coding-DNA/RNA and its effects on gene expression and regulation.</p>
<p>Given the vast scale of DNA and RNA sequences, with sequences of the order 3 billion nucleotides in the case of humans [48], the analysis side of genomics and transcriptomics is largely driven by computational algorithms.Classically, these have been deterministic, statistical, and classical machine learning algorithms, however, as the availability of genomics and transcriptomics data [49] has rapidly grown there has been an uptick in the usage of deep learning models in these areas [50].We can consider DNA and RNA to be the languages of life, with their own patterns, grammar and semantic rules.Accordingly, it is no surprise that LLMs, deep learning models typically intended for natural language processing (NLP), have been proven highly effective in the areas of DNA and RNA sequencing analysis.</p>
<p>One of the earlier applications of LLMs to DNA was DNABERT [51], a genomics foundation model able to be finetuned on a variety of downstream tasks.Unlike with natural language processing where we loosely tokenize on the word or sub-word level, there are many valid tokenization strategies for DNA and RNA.In the simplest cases tokenization could be done at the single nucleotide level or codon level (3 nucleotide), but more complicated heuristics exist.The DNABERT authors choose to train multiple models with differing tokenization techniques, splitting on varying length k-mers, overlapping sub sequences of a given length.Training for a single model took 25 days with a cluster of 8xNVIDIA 2080Ti GPUs using a masked token replacement strategy.Finetuned DNABERT models achieved, at the time, state-of-the-art performance in promoter site, splice site, and transcription binding site prediction which are, broadly speaking, related to gene expression and regulation.</p>
<p>While DNABERT focuses on local aspects of DNA, other works, for example the award winning [52] GenSLM [53], handle entire viral RNA genome sequences.The GenSLM authors adopt a codon (3 neuclotide bases) level tokenization strategy, with whole viral genomes of the order 30,000 nucleotides, yielding sequence lengths of the order 10,000.GenSLM was pretrained on a dataset of over 110 million prokaryotic gene sequences.This base model was then further trained on whole SARS-CoV-2 genomes [53] and adapted for predictive and generative workloads for early warning of variants of concern (VOCs).In the first case, the model predicts whether a sampled viral genome is likely to be a VOC, i.e., one that is highly aggressive or more harmful.The generative iteration of the model is used to create candidate SARS-CoV-2 genomes to serve as an early warning for potential VOCs [53].As the size of the sequences being handled by the model and the size of the training data scaled in this project, so did the hardware requirements.</p>
<p>Due to the computational challenges that come with the transformer architectures, we are seeing advancements driven by challenges faced in natural language processing trickle down into DNA-LLM research.One such example of this is in the introduction of hyena layers to genomics LLMs [54].The Hyena layer was introduced to handle long context NLP problems, an issue parallel to the long sequence lengths found when dealing with whole genomes.HyenaDNA [54] is trained on sequence lengths of 1 million nucleotides, a scale much greater than the earlier transformer-based DNA-language models.As well as the increased scale, HyenaDNA has achieved state of the art performance on a number of genomics benchmarks.</p>
<p>The focus of DNA/RNA LLMs thus far has primarily been proof of concept, that is to say, although DNA-LLMs are already achieving state of the art performance on genomics-based benchmarks, they are yet to be adopted as common practice in a clinical setting [55].This is largely due to barriers such as model explain-ability and the need for approval by bodies such as the FDA.In this early proof of concept phase the focus of research has been on the rapid training and development of new models, the necessity for large powerful hardware systems to support the training of these models is clear [38,53].However, as DNA-LLM systems move into production the focus will need to shift from fast time-to-product (training) to inference.</p>
<p>Accordingly, the hardware requirements for this will need to be addressed, looking toward running the DNA/RNA based LLMs on inference focused hardware systems.</p>
<p>Medical Language Processing</p>
<p>In the medical field there are copious amounts of text written with specialized vocabulary for healthcare workers like doctors and pharmacists.One of the important features of LLMs is the speed at which they can retrieve and summarize information, which is orders of magnitude faster than a human would require just to gather the appropriate material.Since 2018 there has been widespread use of BERT and other related LLMs in medical NLP tasks to assist with this problem.Applications of BERT-style transformer models in medicine have included: medical Q&amp;A bots [56], medical text mining/annotation [57], and filtering of public health information [58].</p>
<p>More recently research of generative text-to-text LLMs in the medical domain has become increasingly popular especially due to the relative ease of model fine-tuning.This has allowed for a high throughput of papers [59][60][61] that investigate the fine-tuning of generative LLMs for medical work.Notably, from Google&amp;DeepMind fine-tuning their PaLM [59] model achieved state-of-the-art performance on multiple biomedical Q&amp;A benchmarks.Other works, for example Ref. [62], have investigated prompt tuning and engineering as methods for enhancing the performance of generative LLMs in the medical domain.There have also been efforts to train generative medical LLMs from scratch on medical papers, abstracts, and clinical guidelines, such as Meditron-70B [63].Meditron-70B is an open-source model and was able to achieve accuracy within 10% of the closed-source Med-PaLM-2 [59] on medical benchmarks, open-source pretrained models such as this are important as they open up new research avenues, that is to say, anyone can access, fine-tune, and or prompt engineer these models for new medical applications.</p>
<p>Another exciting new area of research in medical LLMs is in combined vision language models.[64] Vision transformers have already been proven useful in the medical domain, for example, MedVInT [65] is a vision transformer that showed good performance on a range of medical classification tasks such as chest x-ray analysis.As such, combined visionlanguage models similar to the LLaVa [64] model could prove an exciting new area of research.Work [66] is already being done to fine-tune LLaVA models for Q&amp;A on medical images.In the paper [66] the authors use the LLM to dicuss a CT scan, the LLM is able accurately describe the location of a lesion in said scan.Due to the visual nature of a large amount of medical diagnosis vision and languagae models are a very appealing area of research.</p>
<p>One of the major difficulties in using LLMs in a medical context is the fact that they hallucinate [67].In a setting like medicine, where the stakes are high, clinicians cannot risk an LLM presenting them with incorrect information.Accordingly, methods such as retrieval augmented generation (RAG) [68], that are known to reduce hallucinations, will be of heightened importance in medical language processing tasks.</p>
<p>MATH AND PHYSICS</p>
<p>The language of mathematics and physics can be described as ordinary language with mathematical symbols, but this understates the importance of the specialized vocabulary that would not appear in ordinary text.Mathematical and physics terminology have precise meaning which can be understood with a single sample, which is very different from the usual training of LLMs which learn through many examples.There are attempts to guide an LLM chatbot to aid researchers through prompt engineering, one such example is Ref. [69].</p>
<p>Here a chatbot is given specialized prompts to guide the LLM towards following the correct analytic steps for applying the Hartree-Fock method, a way to solve quantum many-body problems.The LLM is able to successfully re-derive 13 of 15 Hartree-Fock Hamiltonians from research papers with only minor mistakes otherwise.These mistakes can be easily corrected by peer review from the chatbots human counterpart.Another example of using general LLMs is to guide numerical simulations [70].In this work an LLM is prompted to generate a 3-D mesh from a textual description, for example "Create a bar with a square section centered on the end".Physical simulations can then be run on the generated meshes, either traditional physics solvers or machine learning powered solutions.</p>
<p>In mathematics there is work to try and solve problems for which brute-force solutions are known, but intractable.One such is FunSearch [71], an LLM that searches for interpretable function formalisms rather than direct solutions to the cap set problem, a combinatorial problem.The LLM has attached to it a systematic evaluator to search the function space, which is designed to enable a feedback loop with domain experts.In the cap set problem, FunSearch discovered new constructions of large cap sets, it was applied to online bin packing where it found novel heuristics improving on widely used baselines.Efforts are also underway to enable LLMs to directly solve mathematical proofs, for example AlphaGeometry proves theorems for Euclidean plane geometry [72].AlphaGeometry utilizes an LLM to guide a symbolic deduction engine through branching points encountered while writing proofs.AlpaGeometry generates human readable proofs, close to the performance of an average International Mathematical Olympiad (IMO) gold medallist.</p>
<p>CONCLUSION</p>
<p>LLMs are being rapidly developed and deployed for software applications that involve natural language processing.Beyond the world of chatbot style applications there are many scientific domains that employ human language or have their own rigorous scientific language.Physics, mathematics and medicine use natural language with specialized vocabularies and different semantic meaning from ordinary language and are therefore suitable target for traditional LLMs.In chemistry and biology, molecules, proteins, and DNA have their own scientific language that represents the underlying physical processes, and they can be targeted with specialised language models.</p>
<p>In the domains of mathematics, physics and medicine, LLMs can already be employed to aid researchers by gathering the relevant information and proposing solutions to be reviewed by the human domain experts.In medicine, this can greatly aid in the ability to sift through the massive amount of textual medical knowledge to focus on only the most relevant information.In mathematics and physics, LLMs can be used in an iterative process to solve problems too complicated for brute force computation and automate derivations with a well-defined set of steps.There is also work to train LLMs to perform mathematical proofs, which could enable rapid progression into the understanding of complex mathematical fields, maybe one day generative LLMs will be able to spawn novel mathematical ideas.
 Beyond natural language processing, scientists often encode physical processes in a novel language.Molecules, proteins, and DNA have special languages which have different syntactic and semantic meaning from natural language.For molecular and protein research LLMs are able to predict properties from the textual representation as well as design novel structures with target behavior and accomplish this with significant computational speedup.While research using LLMs in such applications is still evolving, it holds promise of enabling entirely new processes of material science, chemistry, and drug design.Finally, in order to serve these wide range of applications, computer systems and services need to evolve to provide token capacity at massive scale, with high throughput, low latency, low energy, and low cost.
. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, 1706.037622017</p>
<p>D Abts, G Kimmell, A Ling, J Kim, M Boyd, A Bitar, S Parmar, I Ahmed, R Dicecco, D Han, J Thompson, M Bye, J Hwang, J Fowers, P Lillian, A Murthy, E Mehtabuddin, C Tekur, T Sohmers, K Kang, S Maresh, J Ross, 10.1145/3470496.3527405Proceedings of the 49th Annual International Symposium on Computer Architecture, ISCA '22. the 49th Annual International Symposium on Computer Architecture, ISCA '22New York, NY, USAAssociation for Computing Machinery2022</p>
<p>. T Persson, Å Geijerstam, C Liberg, Nordic Studies in Science Education. 121762016</p>
<p>. D E Rumelhart, G E Hinton, R J Williams, Biometrika. 715991986</p>
<p>. S Hochreiter, J Schmidhuber, Neural computation. 917351997</p>
<p>. J Devlin, M.-W Chang, K Lee, K Toutanova, arXiv:1810.048052018arXiv preprint</p>
<p>A Radford, J W Kim, C Hallacy, A Ramesh, G Goh, S Agarwal, G Sastry, A Askell, P Mishkin, J Clark, International conference on machine learning. PMLR2021</p>
<p>. N Reimers, I Gurevych, arXiv:1908.100842019arXiv preprint</p>
<p>. H Liu, C Li, Y Li, Y J Lee, arXiv:2310.037442023arXiv preprint</p>
<p>R Rombach, A Blattmann, D Lorenz, P Esser, B Ommer, CVF Conference on Computer Vision and Pattern Recognition (CVPR. 2021</p>
<p>. P Lewis, E Perez, A Piktus, F Petroni, V Karpukhin, N Goyal, H Küttler, M Lewis, W -T. Yih, T Rocktäschel, Advances in Neural Information Processing Systems. 3394592020</p>
<p>. A Radford, K Narasimhan, T Salimans, I Sutskever, 2018</p>
<p>. J Kaplan, S Mccandlish, T Henighan, T B Brown, B Chess, R Child, S Gray, A Radford, J Wu, D Amodei, arXiv:2001.083612020arXiv preprint</p>
<p>. J Achiam, S Adler, S Agarwal, L Ahmad, I Akkaya, F L Aleman, D Almeida, J Altenschmidt, S Altman, S Anadkat, arXiv:2303.087742023arXiv preprint</p>
<p>. G Team, R Anil, S Borgeaud, Y Wu, J.-B Alayrac, J Yu, R Soricut, J Schalkwyk, A M Dai, A Hauth, arXiv:2312.118052023arXiv preprint</p>
<p>. H Touvron, T Lavril, G Izacard, X Martinet, M.-A Lachaux, T Lacroix, B Rozière, N Goyal, E Hambro, F Azhar, arXiv:2302.139712023arXiv preprint</p>
<p>. H Touvron, L Martin, K Stone, P Albert, A Almahairi, Y Babaei, N Bashlykov, S Batra, P Bhargava, S Bhosale, arXiv:2307.092882023arXiv preprint</p>
<p>. A Q Jiang, A Sablayrolles, A Roux, A Mensch, B Savary, C Bamford, D S Chaplot, D Casas, E B Hanna, F Bressand, arXiv:2401.040882024arXiv preprint</p>
<p>. L Ouyang, J Wu, X Jiang, D Almeida, C Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, Advances in neural information processing systems. 35277302022</p>
<p>M Poli, S Massaroli, E Nguyen, D Y Fu, T Dao, S Baccus, Y Bengio, S Ermon, C Ré, International Conference on Machine Learning. PMLR2023</p>
<p>. D Fu, S Arora, J Grogan, I Johnson, E S Eyuboglu, A Thomas, B Spector, M Poli, A Rudra, C Ré, Advances in Neural Information Processing Systems. 362024</p>
<p>. A Gu, T Dao, arXiv:2312.007522023arXiv preprint</p>
<p>. S Jelassi, D Brandfonbrener, S M Kakade, E Malach, arXiv:2402.010322024arXiv preprint</p>
<p>. S De, S L Smith, A Fernando, A Botev, G Cristian-Muraru, A Gu, R Haroun, L Berrada, Y Chen, S Srinivasan, arXiv:2402.194272024arXiv preprint</p>
<p>. O Lieber, B Lenz, H Bata, G Cohen, J Osin, I Dalmedigos, E Safahi, S Meirom, Y Belinkov, S Shalev-Shwartz, arXiv:2403.198872024arXiv preprint</p>
<p>A Radford, J W Kim, T Xu, G Brockman, C Mcleavey, I Sutskever, International Conference on Machine Learning. PMLR2023</p>
<p>. D Lyth, S King, arXiv:2402.019122024arXiv preprint</p>
<p>W Peebles, S Xie, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2023</p>
<p>. A Dosovitskiy, L Beyer, A Kolesnikov, D Weissenborn, X Zhai, T Unterthiner, M Dehghani, M Minderer, G Heigold, S Gelly, arXiv:2010.119292020arXiv preprint</p>
<p>. Y Liu, K Zhang, Y Li, Z Yan, C Gao, R Chen, Z Yuan, Y Huang, H Sun, J Gao, arXiv:2402.171772024arXiv preprint</p>
<p>. E Hargrave-Thomas, B Yu, J Reynisson, World J Clin Oncol. 312012</p>
<p>. P G Polishchuk, T I Madzhidov, A Varnek, 10.1007/s10822-013-9672-4Journal of Computer-Aided Molecular Design. 276752013</p>
<p>. Q Zhang, K Ding, T Lyv, X Wang, Q Yin, Y Zhang, J Yu, Y Wang, X Li, Z Xiang, Z Xiang, Z Wang, M Qin, M Zhang, J Zhang, J Cui, R Xu, H Chen, X Fan, H Xing, H Chen, ArXiv abs/2401.146562024</p>
<p>. D Weininger, 10.1021/ci00057a005Journal of Chemical Information and Computer Sciences. 28311988</p>
<p>. M Krenn, F Häse, A Nigam, P Friederich, A Aspuru-Guzik, 10.1088/2632-2153/aba947Machine Learning: Science and Technology. 1450242020</p>
<p>. S Kim, J Chen, T Cheng, A Gindulyte, J He, S He, Q Li, B A Shoemaker, P A Thiessen, B Yu, L Zaslavsky, J Zhang, E E Bolton, 10.1093/nar/gkac956Nucleic Acids Research. 51D13732022</p>
<p>. Z Wu, B Ramsundar, E N Feinberg, J Gomes, C Geniesse, A S Pappu, K Leswing, V Pande, Chem Sci. 95132017</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. J Devlin, M.-W Chang, K Lee, K Toutanova, 10.48550/ARXIV.1810.048052018</p>
<p>S Wang, Y Guo, Y Wang, H Sun, J Huang, Proceedings of the 10th ACM International Conference on Bioinformatics. the 10th ACM International Conference on Bioinformatics2019</p>
<p>. J Ross, B Belgodere, V Chenthamarakshan, I Padhi, Y Mroueh, P Das, 10.1038/s42256-022-00580-7Nature Machine Intelligence. 412562022</p>
<p>. V Bagal, R Aggarwal, P K Vinod, U D Priyakumar, J Chem Inf Model. 6220642021</p>
<p>. Y Wang, H Zhao, S Sciabola, W Wang, 10.3390/molecules28114430Molecules. 282023</p>
<p>. 10.3390/molecules281144303390/molecules28114430</p>
<p>. T U Consortium, 10.1093/nar/gkac1052Nucleic Acids Research. 512022</p>
<p>. A Elnaggar, M Heinzinger, C Dallago, G Rehawi, Y Wang, L Jones, T Gibbs, T Feher, C Angerer, M Steinegger, D Bhowmik, B Rost, 10.1109/TPAMI.2021.3095381IEEE Transactions on Pattern Analysis and Machine Intelligence. 4471122022</p>
<p>. Z Yang, X Zeng, Y Zhao, R Chen, 10.1038/s41392-023-01381-zSignal Transduction and Targeted Therapy. 81152023</p>
<p>. Z Lin, H Akin, R Rao, B Hie, Z Zhu, W Lu, N Smetanin, R Verkuil, O Kabeli, Y Shmueli, A Dos Santos Costa, M Fazel-Zarandi, T Sercu, S Candido, A Rives, 10.1126/science.ade2574Science. 37911232023</p>
<p>. K Tunyasuvunakool, J Adler, Z Wu, T Green, M Zielinski, A Žídek, A Bridgland, A Cowie, C Meyer, A Laydon, S Velankar, G J Kleywegt, A Bateman, R Evans, A Pritzel, M Figurnov, O Ronneberger, R Bates, S A A Kohl, A Potapenko, A J Ballard, B Romera-Paredes, S Nikolov, R Jain, E Clancy, D Reiman, S Petersen, A W Senior, K Kavukcuoglu, E Birney, P Kohli, J Jumper, D Hassabis, 10.1038/s41586-021-03828-1Nature. 5965902021</p>
<p>Committee on Mapping and Sequencing the Human Genome, Mapping and Sequencing the Human Genome. 1988National Academies PressUS), Washington, DCNational Research CouncilIntroduction</p>
<p>. L Hood, L Rowen, 10.1186/gm483Genome Medicine. 5792013</p>
<p>. W S Alharbi, M Rashid, 10.1186/s40246-022-00396-xHuman Genomics. 162022</p>
<p>. Y Ji, Z Zhou, H Liu, R V Davuluri, 10.1093/bioinformatics/btab083Bioinformatics. 372021</p>
<p>A. for Computing Machinery. </p>
<p>. M Zvyagin, A Brace, K Hippe, Y Deng, B Zhang, C O Bohorquez, A Clyde, B Kale, D Perez-Rivera, H Ma, C M Mann, M Irvin, J G Pauloski, L Ward, V Hayot, M Emani, S Foreman, Z Xie, D Lin, M Shukla, W Nie, J Romero, C Dallago, A Vahdat, C Xiao, T Gibbs, I Foster, J J Davis, M E Papka, T Brettin, R Stevens, A Anandkumar, V Vishwanath, A Ramanathan, 10.1101/2022.10.10.511571bioRxiv. 2022</p>
<p>. E Nguyen, M Poli, M Faizi, A Thomas, M Wornow, C Birch-Sykes, S Massaroli, A Patel, C Rabideau, Y Bengio, Advances in neural information processing systems. 362024</p>
<p>. R Dias, A Torkamani, 10.1186/s13073-019-0689-8Genome Medicine. 112019</p>
<p>. J A Alzubi, R Jain, A Singh, P Parwekar, M Gupta, 10.1007/s13369-021-05810-5Arabian Journal for Science and Engineering. 482021</p>
<p>. L Luo, P.-T Lai, C.-H Wei, C N Arighi, Z Lu, 10.1093/bib/bbac282Briefings in Bioinformatics. 232022</p>
<p>D Q Nguyen, T Vu, A Rahimi, M H Dao, L T Nguyen, L Doan, 10.18653/v1/2020.wnut-1.41Proceedings of the Sixth Workshop on Noisy User-generated Text. the Sixth Workshop on Noisy User-generated TextAssociation for Computational Linguistics2020. 2020</p>
<p>. K Singhal, S Azizi, T Tu, S S Mahdavi, J Wei, H W Chung, N Scales, A Tanwani, H Cole-Lewis, S Pfohl, P Payne, M Seneviratne, P Gamble, C Kelly, A Babiker, N Schärli, A Chowdhery, P Mansfield, D Demner-Fushman, B Agüera Y Arcas, D Webster, G S Corrado, Y Matias, K Chou, J Gottweis, N Tomasev, Y Liu, A Rajkomar, J Barral, C Semturs, A Karthikesalingam, V Natarajan, 10.1038/s41586-023-06291-2Nature. 6202023</p>
<p>Clinicalgpt: Large language models finetuned with diverse medical data and comprehensive evaluation. G Wang, G Yang, Z Du, L Fan, X Li, 10.48550/ARXIV.2306.099682023</p>
<p>Chatdoctor: A medical chat model fine-tuned on a large language model meta-ai (llama) using medical domain knowledge. Y Li, Z Li, K Zhang, R Dan, S Jiang, Y Zhang, 10.48550/ARXIV.2303.140702023</p>
<p>Can generalist foundation models outcompete special-purpose tuning? case study in medicine. H Nori, Y T Lee, S Zhang, D Carignan, R Edgar, N Fusi, N King, J Larson, Y Li, W Liu, R Luo, S M Mckinney, R O Ness, H Poon, T Qin, N Usuyama, C White, E Horvitz, 10.48550/ARXIV.2311.164522023</p>
<p>Meditron-70b: Scaling medical pretraining for large language models. Z Chen, A H Cano, A Romanou, A Bonnet, K Matoba, F Salvi, M Pagliardini, S Fan, A Köpf, A Mohtashami, A Sallinen, A Sakhaeirad, V Swamy, I Krawczuk, D Bayazit, A Marmet, S Montariol, M.-A Hartley, M Jaggi, A Bosselut, 10.48550/ARXIV.2311.160792023</p>
<p>C Li, C Wong, S Zhang, N Usuyama, H Liu, J Yang, T Naumann, H Poon, J Gao, Advances in Neural Information Processing Systems. 202436</p>
<p>. X Zhang, C Wu, Z Zhao, W Lin, Y Zhang, Y Wang, W Xie, arXiv:2305.104152023arXiv preprint</p>
<p>Llava-med: Training a large language-and-vision assistant for biomedicine in one day. C Li, C Wong, S Zhang, N Usuyama, H Liu, J Yang, T Naumann, H Poon, J Gao, 10.48550/ARXIV.2306.008902023</p>
<p>. R Azamfirei, S R Kudchadkar, J Fackler, 10.1186/s13054-023-04393-xCritical Care. 272023</p>
<p>Retrieval-augmented generation for knowledge-intensive nlp tasks. P Lewis, E Perez, A Piktus, F Petroni, V Karpukhin, N Goyal, H Küttler, M Lewis, W -T. Yih, T Rocktäschel, S Riedel, D Kiela, 10.48550/ARXIV.2005.114012020</p>
<p>. H Pan, N Mudur, W Taranto, M Tikhanovskaya, S Venugopalan, Y Bahri, M P Brenner, E.-A Kim, arXiv:2403.031542024arXiv e-prints</p>
<p>. A Alexiadis, B Ghiassi, 10.1016/j.rineng.2023.101721Results in Engineering. 211017212024</p>
<p>. B Romera-Paredes, M Barekatain, A Novikov, M Balog, M P Kumar, E Dupont, F J R Ruiz, J S Ellenberg, P Wang, O Fawzi, P Kohli, A Fawzi, 10.1038/s41586-023-06924-6Nature. 6254682024</p>
<p>. T H Trinh, Y Wu, Q V Le, H He, T Luong, Nature. 6254762024</p>            </div>
        </div>

    </div>
</body>
</html>