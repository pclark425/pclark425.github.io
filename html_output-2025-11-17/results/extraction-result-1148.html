<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1148 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1148</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1148</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-25.html">extraction-schema-25</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-789711d62b6f0eae9cedc68ff2e935ab6c2dcaa8</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/789711d62b6f0eae9cedc68ff2e935ab6c2dcaa8" target="_blank">Variational Bayesian Optimal Experimental Design</a></p>
                <p><strong>Paper Venue:</strong> Neural Information Processing Systems</p>
                <p><strong>Paper TL;DR:</strong> This work introduces several classes of fast EIG estimators by building on ideas from amortized variational inference, and shows theoretically and empirically that these estimators can provide significant gains in speed and accuracy over previous approaches.</p>
                <p><strong>Paper Abstract:</strong> Bayesian optimal experimental design (BOED) is a principled framework for making efficient use of limited experimental resources. Unfortunately, its applicability is hampered by the difficulty of obtaining accurate estimates of the expected information gain (EIG) of an experiment. To address this, we introduce several classes of fast EIG estimators by building on ideas from amortized variational inference. We show theoretically and empirically that these estimators can provide significant gains in speed and accuracy over previous approaches. We further demonstrate the practicality of our approach on a number of end-to-end experiments.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1148.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1148.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VBOED</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Variational Bayesian Optimal Experimental Design</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A family of BOED algorithms that estimate Expected Information Gain (EIG) using amortized variational approximations (posterior, marginal, VNMC, and marginal+likelihood) to enable fast, adaptive experiment selection via Bayesian optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>VBOED (BOED system using variational EIG estimators)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A BOED pipeline that (1) trains amortized variational approximations (q_p for posterior, q_m for marginal, q_v for importance proposals, and q_ell for implicit-likelihood approximations), (2) uses those approximations to rapidly estimate EIG, and (3) optimizes designs with Bayesian optimization. Key components: amortized variational networks, stochastic gradient training of variational parameters, MC estimators for final EIG, and a BO optimizer over designs.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Information-gain maximization (Bayesian optimal experimental design using EIG) with Bayesian optimization for design selection</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>At each sequential step the system replaces the prior with the current posterior (conditioning on past designs/outcomes), re-estimates EIG for candidate designs using a trained variational estimator (q_p, q_m, q_v or q_{m+ell}), and selects the next design that maximizes EIG; variational components are amortized across possible outcomes so inner expectations are shared.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>General latent-parameter inference environments (explicit and implicit likelihood models); applied to mixed-effects psychology experiment and CES revealed-preference simulation in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Stochastic outcome generation y conditioned on latent θ and design d; partial observability of θ (only y observed); some models have implicit likelihoods due to nuisance latent variables (random effects ψ), censored/noisy observations, and heteroskedastic noise.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Varies by experiment: discrete design set of 36 in mixed-effects online human experiment with 8 participants and 6 feature dimensions; continuous design space [0,100]^6 for CES revealed-preference experiment; models include nuisance latent variables (random effects) leading to implicit likelihoods.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Adaptive VBOED produced faster posterior concentration and lower posterior entropy than random design and earlier baselines; in the mixed-effects online human experiment BOED with the marginal+likelihood estimator produced a more certain (lower entropy) posterior than random design (Figure 3). In the CES simulation BOED with the marginal estimator reduced posterior entropy and RMSE for θ faster than both random design and BOED using NMC (Figure 4). (Qualitative performance reported in paper; see figures.)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td>Random design: made virtually no progress in learning parameters in the CES task; NMC-based adaptive design struggled initially when the prior/posterior variance was large (paper reports BOED with NMC particularly struggled at the outset). (Quantitative numbers for comparisons are shown in figures and discussed qualitatively.)</td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Variational estimators (when variational family contains target) converge at O(T^{-1/2}) versus NMC's O(T^{-1/3}); this yields substantially fewer samples to reach a given EIG estimation error in experiments. Empirically, variational methods outperformed NMC across benchmarks under fixed computational budgets (Table 2 and Figure 1).</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Design selection is driven by EIG (information-seeking): the algorithm explicitly trades exploration and exploitation by selecting designs that maximize expected reduction in posterior entropy; Bayesian optimization handles noisy EIG evaluations and balances sampling of promising designs versus exploring uncertain regions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared against Random design, Nested Monte Carlo (NMC), Laplace approximation, LFIRE (likelihood-free ratio estimation), and Donsker-Varadhan (DV) mutual information estimator in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>1) Introduced four variational EIG estimators (variational posterior hat_mu_post, variational marginal hat_mu_marg, variational-NMC hat_mu_VNMC, and marginal+likelihood hat_mu_{m+ell}); 2) proved variational estimators converge at O(T^{-1/2}) (when variational family contains target) and empirically demonstrated large gains in EIG-estimation accuracy and end-to-end BOED performance; 3) VNMC enables asymptotically unbiased EIG estimation by combining learned proposal with importance sampling (bias removed as number of inner samples M increases); 4) marginal+likelihood estimator supports implicit-likelihood models and worked well in the mixed-effects human experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>If variational families do not contain the true distributions, posterior and marginal estimators are biased (term III asymptotic bias). Convergence proofs rely on strong assumptions (e.g. convexity/strong-convexity) that may not hold in practice; training may converge to local optima, increasing asymptotic bias. NMC still needed (or VNMC with large M) to remove variational bias. Computational cost of training variational proposals can be non-trivial and the choice of variational family affects accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Variational Bayesian Optimal Experimental Design', 'publication_date_yy_mm': '2019-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1148.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1148.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>hat_mu_post</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Variational posterior EIG estimator (\hat{\mu}_{post})</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An amortized variational estimator that learns q_p(θ|y,d) and estimates EIG via the variational lower bound E_p(y,θ|d)[log q_p(θ|y,d) - log p(θ)], yielding a fast, lower-bound EIG estimator applicable when sampling from the model is possible.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>BOED using hat_mu_post (amortized posterior proposal)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Learns an amortized approximate posterior q_p(θ|y,d;φ) via stochastic gradient ascent on the variational lower bound, then uses MC samples y,θ∼p(y,θ|d) and q_p to compute EIG estimates; used as the EIG estimator inside a BOED loop.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Information gain maximization (EIG) with variational posterior approximation</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Trains q_p on samples from the current model (and current posterior in sequential setting) to amortize inner inference across y; uses the learned q_p to evaluate candidate designs quickly and choose the design maximizing the variational lower bound on EIG.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>A/B test, Preference and Mixed-effects benchmark problems (explicit and implicit likelihoods; applied across benchmarks in the paper)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Stochastic observations y; may be moderate-dimensional θ (example A/B θ dim=2, y dim=10; preference θ dim=1 with censored/noisy y; mixed-effects includes nuisance latent ψ making likelihood implicit).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Benchmark specifics: A/B test n=10 participants with 11 discrete designs; preference experiment uses real-valued design grid in [-80,80]; mixed-effects: 36 possible designs, 8 participants, 6 feature dimensions; model-dependent complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Empirically strong: in EIG estimation accuracy experiments hat_mu_post often substantially outperformed hat_mu_marg when dim(θ) < dim(y) (Figure 1); Table 2 shows for mixed-effects benchmark hat_mu_post had bias^2 = 2.34e-3 and variance = 2.92e-3 (averaged over designs, 5 runs). In sequential experiments, BOED using hat_mu_post/methods produced faster posterior concentration than baselines in many settings.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Converges empirically faster than NMC with the same computational budget; theoretical MC+optimization error scales O(T^{-1/2}) when variational family contains target, so fewer MC samples are needed than NMC to reach same RMSE.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>EIG-driven selection: exploration is induced by choosing designs with high expected posterior entropy reduction; amortization reduces per-candidate inference cost enabling more candidate evaluations (improved exploration capability).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared against hat_mu_marg, hat_mu_VNMC, hat_mu_{m+ell}, NMC, Laplace, LFIRE, DV in benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>hat_mu_post gave lower RMSE than NMC and often outperformed hat_mu_marg when θ was lower dimensional than y (empirical results and Figure 1). It provides a lower bound on EIG and is tight iff q_p equals the true posterior. It is applicable when only sampling from the model is required (does not need explicit marginal).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Biased if the variational posterior family does not include the true posterior (asymptotic bias), leading to plateauing RMSE with increased MC samples; may be harder to use when θ is very high-dimensional.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Variational Bayesian Optimal Experimental Design', 'publication_date_yy_mm': '2019-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1148.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1148.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>hat_mu_marg</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Variational marginal EIG estimator (\hat{\mu}_{marg})</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Learns an approximation q_m(y|d) to the marginal p(y|d) and uses the variational upper bound E_p(y,θ|d)[log p(y|θ,d) - log q_m(y|d)] to estimate EIG; useful when dim(y) << dim(θ) and explicit likelihood is available.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>BOED using hat_mu_marg (amortized marginal approximation)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Trains a variational density q_m(y|d;φ) over outcome space y by maximizing the variational upper bound and then uses q_m to compute EIG estimates for candidate designs; used inside an adaptive BOED loop to select designs.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Information-gain maximization (EIG) using variational marginal approximation</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Amortizes learning of the marginal over y across outcomes to cheaply evaluate many candidate designs; in sequential settings replaces prior with posterior conditioned on past data (can sample from posterior) and recomputes q_m as needed or use samples to evaluate the EIG bound.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>CES revealed-preference simulation (preference benchmark) and other explicit-likelihood tasks in the paper</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Stochastic, partially observed outcomes y; explicit likelihood available (p(y|θ,d)) in settings where hat_mu_marg is applied; example CES experiment: design space continuous in [0,100]^6; observation y lower-dimensional relative to θ in some cases.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>CES experiment: design d ∈ [0,100]^6; θ includes (ρ, α, u) with α a vector; revealed-preference responses are noisy and censored; other benchmarks vary.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>In CES revealed-preference sequential experiment, BOED using hat_mu_marg reduced posterior entropy and RMSE more quickly than random design and NMC-based BOED (Figure 4). In EIG-estimation benchmarks hat_mu_marg was best for the Preference benchmark in Table 2 (bias^2 = 1.10e-3, var = 1.99e-3, bolded as best).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td>Random design: much slower/no improvement in parameter recovery in CES task (qualitative, Figure 4).</td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Empirically sample-efficient in settings with low-dim y: achieves lower EIG-estimation MSE under fixed compute budgets compared to NMC and many baselines (Table 2 and Figure 1a–1d).</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Pure EIG maximization (information-seeking); by providing low-cost EIG estimates over many candidate designs, it enables better exploration of the design space early in adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared against hat_mu_post, hat_mu_VNMC, hat_mu_{m+ell}, NMC, LFIRE, DV, Laplace.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>hat_mu_marg can be the most accurate estimator when y is lower-dimensional than θ; used successfully for the CES sequential design task to select informative designs that concentrate the posterior rapidly; provides an upper bound on EIG and is tight when q_m = p(y|d).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Requires an explicit likelihood (cannot directly apply with implicit-likelihood models unless extended to m+ℓ variant). Biased if q_m does not equal p(y|d) (asymptotic bias).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Variational Bayesian Optimal Experimental Design', 'publication_date_yy_mm': '2019-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1148.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1148.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>hat_mu_VNMC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Variational-Nested Monte Carlo estimator (\hat{\mu}_{VNMC})</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid estimator that trains an amortized proposal q_v(θ|y,d) and then uses importance sampling / NMC with that proposal to estimate p(y|d) and hence EIG; combines fast variational training with the asymptotic consistency of NMC.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>BOED using hat_mu_VNMC (variationally trained proposal + NMC refinement)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>First trains a proposal q_v(θ|y,d;φ) by minimizing an upper bound (U_VNMC) with small L, then constructs an importance-sampling-based nested MC estimator using many inner samples M (often M >> L) from q_v to obtain asymptotically unbiased EIG estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Information-gain maximization (EIG) via variationally trained importance-sampling/NMC estimator</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Uses a two-stage strategy: quick variational training to learn a good proposal for p(θ|y,d), then performs importance-weighted nested MC with the learned proposal to refine EIG estimates and select designs; proposal improves sample efficiency for the inner loop.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>A/B test and Preference benchmarks (explicit-likelihood examples in the paper); general EIG estimation tasks</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Stochastic outcomes y with explicit likelihoods in reported experiments; can be applied in settings where p(y|θ,d) is evaluable. Environments may have high variance priors/posteriors where vanilla NMC struggles.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Benchmarks in paper: A/B test (θ dim=2, y dim=10) and Preference; complexity depends on M (inner samples) and learned q_v dimension.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>In EIG estimation benchmarks VNMC had much lower bias and variance than plain NMC under fixed budgets (Table 2): e.g., for A/B test hat_mu_VNMC bias^2 = 3.44e-3 and var = 3.38e-3 versus NMC bias^2 = 4.70e0 and var = 3.47e-1. VNMC continues to improve (does not plateau) after initial training as M and N are increased, converging to true EIG as M→∞.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>More sample-efficient than vanilla NMC because learned q_v produces lower-variance importance weights; theoretical two-stage cost is T = O(KL + NM) where small KL for training and NM refinement with M ∝ √N yields asymptotic rate O((NM)^{-1/3}) for bias-removal stage. Empirically much lower MSE under fixed compute budgets (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>EIG-driven; VNMC's proposal reduces variance in EIG estimates enabling better exploration of design space under fixed compute. No explicit additional exploration heuristic beyond EIG maximization.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared against NMC, hat_mu_post, hat_mu_marg, Laplace, LFIRE, DV in benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>VNMC bridges variational speed and NMC consistency: fast variational training yields good proposals that dramatically reduce bias/variance at practical budgets, and increasing inner sample count M recovers asymptotic unbiasedness. Empirically outperforms NMC by large margins on benchmark EIG estimation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Requires an explicit likelihood for the importance weights (p(y,θ)/q_v); asymptotic unbiasedness requires increasing M (inner samples), which increases computational cost and reintroduces NMC-like scaling; effectiveness depends on quality of trained proposal q_v.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Variational Bayesian Optimal Experimental Design', 'publication_date_yy_mm': '2019-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1148.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1148.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mixed-effects adaptive human study</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adaptive mixed-effects psychology experiment (online Mechanical Turk)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An end-to-end adaptive experiment where VBOED (using the marginal+likelihood estimator hat_mu_{m+ell}) selected face-stimulus designs online for human participants to maximize information about fixed effects while treating individual differences as nuisance random effects.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>BOED system using hat_mu_{m+ell} in online human experiment</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Online pipeline: present stimulus to participant, observe response y, update model (mixed effects posterior over θ with nuisance ψ), train/maintain q_m and q_ell approximations (marginal+likelihood) for implicit likelihoods, compute EIG estimates and select next stimulus via Bayesian optimization; repeated across 36 possible designs and 8 participants.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Information-gain maximization (EIG) using marginal+likelihood variational estimator (suitable for implicit-likelihood mixed-effects model)</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>At each trial uses current data to update posterior over fixed effects θ (marginalizing nuisance ψ via sampling), trains q_m and q_ell through stochastic gradient ascent on the bounding objective, and selects the next design that maximizes the learned EIG surrogate via Bayesian optimization. The pipeline runs online between subject responses.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Mixed-effects regression model for human psychophysics (8 participants, 36 possible designs)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Partially observable latent fixed effects θ and participant-specific random effects ψ (nuisance); implicit likelihood due to nuisance integration; censored sigmoid observation model; heteroskedastic noise and non-Gaussian observation transform.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>36 discrete designs (image-pairs formed from 6 feature levels -> design matrix dim 6), 8 participants (random effects per participant), θ modeled as 6-dim fixed-effects vector; implicit likelihood requires sampling over nuisance variables; online, real-time constraints for design selection.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>BOED with hat_mu_{m+ell} led to a more certain posterior (lower entropy) than random design in the online human experiment (Figure 3). The paper reports qualitative and plotted reductions in posterior entropy over trials demonstrating improved learning speed; exact numeric trajectory shown in figure.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td>Random design baseline: produced higher posterior entropy and slower parameter concentration (Figure 3 indicates BOED obtains lower entropy posterior trajectories than random).</td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Adaptive BOED concentrated posterior with fewer trials than random; demonstrated real-time feasibility for an online experiment with per-trial updates. (No single-number sample count reported; see figure for trial-wise entropy curves.)</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>EIG selection naturally balances exploration/exploitation by selecting trials expected to provide maximum posterior-entropy reduction given current posterior over θ and sampled nuisance ψ.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared against random design baseline in the online human experiment for efficacy; EIG estimator choice justified by benchmark results in Table 2.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>Demonstrated that variational EIG estimators (specifically marginal+likelihood) are practical and robust enough for real-time adaptive experiments with humans and implicit likelihoods, yielding more informative data and faster posterior concentration than random designs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Real-time requirement constrains complexity of variational training; estimator bias possible if variational families are misspecified; marginal+likelihood is not a formal bound on EIG in general (but error can be bounded and the method performed well empirically).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Variational Bayesian Optimal Experimental Design', 'publication_date_yy_mm': '2019-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1148.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1148.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CES revealed-preference simulation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adaptive design for Constant Elasticity of Substitution (CES) revealed-preference model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simulated revealed-preference experiment where BOED using hat_mu_marg sought designs in d∈[0,100]^6 to efficiently identify an agent's utility parameters (ρ, α, u); compared BOED vs random and NMC-based BOED.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>BOED system using hat_mu_marg for CES agent inference</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Simulates agent responses under a CES utility model with latent parameters θ=(ρ, α, u); trains q_m(y|d) to approximate p(y|d), uses Bayesian optimization over d to maximize estimated EIG and selects designs adaptively to reveal agent preferences.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Information-gain maximization (EIG) with variational marginal estimator</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>After each simulated response updates posterior over θ, retrains/uses q_m to estimate EIG for candidate designs and selects the maximal-EIG design via Bayesian optimization; repeated sequentially to concentrate posterior on true θ.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>CES revealed-preference simulation (synthetic agent)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Stochastic, partially observable responses determined by agent utility under CES model; observation noise and potential censoring; design space continuous and high-dimensional (6-D), responses lower-dimensional relative to θ in this setup.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Design d ∈ [0,100]^6; latent θ includes scalar ρ, vector α, and scalar u; experiments simulate many candidate designs and iteratively update posterior; complexity arises from multi-dimensional design and latent space.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>BOED with hat_mu_marg reduced posterior entropy and RMSE of posterior estimates for (ρ, α, u) faster than random design and BOED with NMC (Figure 4); random design made almost no progress, and NMC-based BOED struggled early when the prior/posterior variance was large.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td>Random design baseline: essentially no inroads into learning problem across same iterations (qualitative, Figure 4).</td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>BOED produced significantly faster concentration of posterior per simulated trial compared to baselines (no single numeric sample-count threshold reported; see trial-wise entropy and RMSE plots).</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>EIG criterion picks designs that are maximally informative about θ (explicitly encourages exploration that reduces epistemic uncertainty); Bayesian optimization manages exploration over design space under noisy EIG estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Random design; BOED with NMC (vanilla nested MC) as baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>Demonstrated that marginal variational estimator enabled informative design selection in a challenging continuous 6D design space and outperformed NMC and random baselines in terms of posterior entropy reduction and RMSE over sequential trials.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>NMC-based BOED struggled in the early iterations under high prior variance; quality of q_m approximation is critical—misspecification would bias EIG estimates and degrade design selection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Variational Bayesian Optimal Experimental Design', 'publication_date_yy_mm': '2019-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>A tutorial on adaptive design optimization <em>(Rating: 2)</em></li>
                <li>Sequential optimal design of neurophysiology experiments <em>(Rating: 2)</em></li>
                <li>Efficient Bayesian experimental design for implicit models <em>(Rating: 2)</em></li>
                <li>Efficient dynamic discovery of high-value information with partial VAE <em>(Rating: 1)</em></li>
                <li>Bayesian inference and online experimental design for mapping neural microcircuits <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1148",
    "paper_id": "paper-789711d62b6f0eae9cedc68ff2e935ab6c2dcaa8",
    "extraction_schema_id": "extraction-schema-25",
    "extracted_data": [
        {
            "name_short": "VBOED",
            "name_full": "Variational Bayesian Optimal Experimental Design",
            "brief_description": "A family of BOED algorithms that estimate Expected Information Gain (EIG) using amortized variational approximations (posterior, marginal, VNMC, and marginal+likelihood) to enable fast, adaptive experiment selection via Bayesian optimization.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "VBOED (BOED system using variational EIG estimators)",
            "agent_description": "A BOED pipeline that (1) trains amortized variational approximations (q_p for posterior, q_m for marginal, q_v for importance proposals, and q_ell for implicit-likelihood approximations), (2) uses those approximations to rapidly estimate EIG, and (3) optimizes designs with Bayesian optimization. Key components: amortized variational networks, stochastic gradient training of variational parameters, MC estimators for final EIG, and a BO optimizer over designs.",
            "adaptive_design_method": "Information-gain maximization (Bayesian optimal experimental design using EIG) with Bayesian optimization for design selection",
            "adaptation_strategy_description": "At each sequential step the system replaces the prior with the current posterior (conditioning on past designs/outcomes), re-estimates EIG for candidate designs using a trained variational estimator (q_p, q_m, q_v or q_{m+ell}), and selects the next design that maximizes EIG; variational components are amortized across possible outcomes so inner expectations are shared.",
            "environment_name": "General latent-parameter inference environments (explicit and implicit likelihood models); applied to mixed-effects psychology experiment and CES revealed-preference simulation in this paper",
            "environment_characteristics": "Stochastic outcome generation y conditioned on latent θ and design d; partial observability of θ (only y observed); some models have implicit likelihoods due to nuisance latent variables (random effects ψ), censored/noisy observations, and heteroskedastic noise.",
            "environment_complexity": "Varies by experiment: discrete design set of 36 in mixed-effects online human experiment with 8 participants and 6 feature dimensions; continuous design space [0,100]^6 for CES revealed-preference experiment; models include nuisance latent variables (random effects) leading to implicit likelihoods.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Adaptive VBOED produced faster posterior concentration and lower posterior entropy than random design and earlier baselines; in the mixed-effects online human experiment BOED with the marginal+likelihood estimator produced a more certain (lower entropy) posterior than random design (Figure 3). In the CES simulation BOED with the marginal estimator reduced posterior entropy and RMSE for θ faster than both random design and BOED using NMC (Figure 4). (Qualitative performance reported in paper; see figures.)",
            "performance_without_adaptation": "Random design: made virtually no progress in learning parameters in the CES task; NMC-based adaptive design struggled initially when the prior/posterior variance was large (paper reports BOED with NMC particularly struggled at the outset). (Quantitative numbers for comparisons are shown in figures and discussed qualitatively.)",
            "sample_efficiency": "Variational estimators (when variational family contains target) converge at O(T^{-1/2}) versus NMC's O(T^{-1/3}); this yields substantially fewer samples to reach a given EIG estimation error in experiments. Empirically, variational methods outperformed NMC across benchmarks under fixed computational budgets (Table 2 and Figure 1).",
            "exploration_exploitation_tradeoff": "Design selection is driven by EIG (information-seeking): the algorithm explicitly trades exploration and exploitation by selecting designs that maximize expected reduction in posterior entropy; Bayesian optimization handles noisy EIG evaluations and balances sampling of promising designs versus exploring uncertain regions.",
            "comparison_methods": "Compared against Random design, Nested Monte Carlo (NMC), Laplace approximation, LFIRE (likelihood-free ratio estimation), and Donsker-Varadhan (DV) mutual information estimator in experiments.",
            "key_results": "1) Introduced four variational EIG estimators (variational posterior hat_mu_post, variational marginal hat_mu_marg, variational-NMC hat_mu_VNMC, and marginal+likelihood hat_mu_{m+ell}); 2) proved variational estimators converge at O(T^{-1/2}) (when variational family contains target) and empirically demonstrated large gains in EIG-estimation accuracy and end-to-end BOED performance; 3) VNMC enables asymptotically unbiased EIG estimation by combining learned proposal with importance sampling (bias removed as number of inner samples M increases); 4) marginal+likelihood estimator supports implicit-likelihood models and worked well in the mixed-effects human experiment.",
            "limitations_or_failures": "If variational families do not contain the true distributions, posterior and marginal estimators are biased (term III asymptotic bias). Convergence proofs rely on strong assumptions (e.g. convexity/strong-convexity) that may not hold in practice; training may converge to local optima, increasing asymptotic bias. NMC still needed (or VNMC with large M) to remove variational bias. Computational cost of training variational proposals can be non-trivial and the choice of variational family affects accuracy.",
            "uuid": "e1148.0",
            "source_info": {
                "paper_title": "Variational Bayesian Optimal Experimental Design",
                "publication_date_yy_mm": "2019-03"
            }
        },
        {
            "name_short": "hat_mu_post",
            "name_full": "Variational posterior EIG estimator (\\hat{\\mu}_{post})",
            "brief_description": "An amortized variational estimator that learns q_p(θ|y,d) and estimates EIG via the variational lower bound E_p(y,θ|d)[log q_p(θ|y,d) - log p(θ)], yielding a fast, lower-bound EIG estimator applicable when sampling from the model is possible.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "BOED using hat_mu_post (amortized posterior proposal)",
            "agent_description": "Learns an amortized approximate posterior q_p(θ|y,d;φ) via stochastic gradient ascent on the variational lower bound, then uses MC samples y,θ∼p(y,θ|d) and q_p to compute EIG estimates; used as the EIG estimator inside a BOED loop.",
            "adaptive_design_method": "Information gain maximization (EIG) with variational posterior approximation",
            "adaptation_strategy_description": "Trains q_p on samples from the current model (and current posterior in sequential setting) to amortize inner inference across y; uses the learned q_p to evaluate candidate designs quickly and choose the design maximizing the variational lower bound on EIG.",
            "environment_name": "A/B test, Preference and Mixed-effects benchmark problems (explicit and implicit likelihoods; applied across benchmarks in the paper)",
            "environment_characteristics": "Stochastic observations y; may be moderate-dimensional θ (example A/B θ dim=2, y dim=10; preference θ dim=1 with censored/noisy y; mixed-effects includes nuisance latent ψ making likelihood implicit).",
            "environment_complexity": "Benchmark specifics: A/B test n=10 participants with 11 discrete designs; preference experiment uses real-valued design grid in [-80,80]; mixed-effects: 36 possible designs, 8 participants, 6 feature dimensions; model-dependent complexity.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Empirically strong: in EIG estimation accuracy experiments hat_mu_post often substantially outperformed hat_mu_marg when dim(θ) &lt; dim(y) (Figure 1); Table 2 shows for mixed-effects benchmark hat_mu_post had bias^2 = 2.34e-3 and variance = 2.92e-3 (averaged over designs, 5 runs). In sequential experiments, BOED using hat_mu_post/methods produced faster posterior concentration than baselines in many settings.",
            "performance_without_adaptation": null,
            "sample_efficiency": "Converges empirically faster than NMC with the same computational budget; theoretical MC+optimization error scales O(T^{-1/2}) when variational family contains target, so fewer MC samples are needed than NMC to reach same RMSE.",
            "exploration_exploitation_tradeoff": "EIG-driven selection: exploration is induced by choosing designs with high expected posterior entropy reduction; amortization reduces per-candidate inference cost enabling more candidate evaluations (improved exploration capability).",
            "comparison_methods": "Compared against hat_mu_marg, hat_mu_VNMC, hat_mu_{m+ell}, NMC, Laplace, LFIRE, DV in benchmarks.",
            "key_results": "hat_mu_post gave lower RMSE than NMC and often outperformed hat_mu_marg when θ was lower dimensional than y (empirical results and Figure 1). It provides a lower bound on EIG and is tight iff q_p equals the true posterior. It is applicable when only sampling from the model is required (does not need explicit marginal).",
            "limitations_or_failures": "Biased if the variational posterior family does not include the true posterior (asymptotic bias), leading to plateauing RMSE with increased MC samples; may be harder to use when θ is very high-dimensional.",
            "uuid": "e1148.1",
            "source_info": {
                "paper_title": "Variational Bayesian Optimal Experimental Design",
                "publication_date_yy_mm": "2019-03"
            }
        },
        {
            "name_short": "hat_mu_marg",
            "name_full": "Variational marginal EIG estimator (\\hat{\\mu}_{marg})",
            "brief_description": "Learns an approximation q_m(y|d) to the marginal p(y|d) and uses the variational upper bound E_p(y,θ|d)[log p(y|θ,d) - log q_m(y|d)] to estimate EIG; useful when dim(y) &lt;&lt; dim(θ) and explicit likelihood is available.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "BOED using hat_mu_marg (amortized marginal approximation)",
            "agent_description": "Trains a variational density q_m(y|d;φ) over outcome space y by maximizing the variational upper bound and then uses q_m to compute EIG estimates for candidate designs; used inside an adaptive BOED loop to select designs.",
            "adaptive_design_method": "Information-gain maximization (EIG) using variational marginal approximation",
            "adaptation_strategy_description": "Amortizes learning of the marginal over y across outcomes to cheaply evaluate many candidate designs; in sequential settings replaces prior with posterior conditioned on past data (can sample from posterior) and recomputes q_m as needed or use samples to evaluate the EIG bound.",
            "environment_name": "CES revealed-preference simulation (preference benchmark) and other explicit-likelihood tasks in the paper",
            "environment_characteristics": "Stochastic, partially observed outcomes y; explicit likelihood available (p(y|θ,d)) in settings where hat_mu_marg is applied; example CES experiment: design space continuous in [0,100]^6; observation y lower-dimensional relative to θ in some cases.",
            "environment_complexity": "CES experiment: design d ∈ [0,100]^6; θ includes (ρ, α, u) with α a vector; revealed-preference responses are noisy and censored; other benchmarks vary.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "In CES revealed-preference sequential experiment, BOED using hat_mu_marg reduced posterior entropy and RMSE more quickly than random design and NMC-based BOED (Figure 4). In EIG-estimation benchmarks hat_mu_marg was best for the Preference benchmark in Table 2 (bias^2 = 1.10e-3, var = 1.99e-3, bolded as best).",
            "performance_without_adaptation": "Random design: much slower/no improvement in parameter recovery in CES task (qualitative, Figure 4).",
            "sample_efficiency": "Empirically sample-efficient in settings with low-dim y: achieves lower EIG-estimation MSE under fixed compute budgets compared to NMC and many baselines (Table 2 and Figure 1a–1d).",
            "exploration_exploitation_tradeoff": "Pure EIG maximization (information-seeking); by providing low-cost EIG estimates over many candidate designs, it enables better exploration of the design space early in adaptation.",
            "comparison_methods": "Compared against hat_mu_post, hat_mu_VNMC, hat_mu_{m+ell}, NMC, LFIRE, DV, Laplace.",
            "key_results": "hat_mu_marg can be the most accurate estimator when y is lower-dimensional than θ; used successfully for the CES sequential design task to select informative designs that concentrate the posterior rapidly; provides an upper bound on EIG and is tight when q_m = p(y|d).",
            "limitations_or_failures": "Requires an explicit likelihood (cannot directly apply with implicit-likelihood models unless extended to m+ℓ variant). Biased if q_m does not equal p(y|d) (asymptotic bias).",
            "uuid": "e1148.2",
            "source_info": {
                "paper_title": "Variational Bayesian Optimal Experimental Design",
                "publication_date_yy_mm": "2019-03"
            }
        },
        {
            "name_short": "hat_mu_VNMC",
            "name_full": "Variational-Nested Monte Carlo estimator (\\hat{\\mu}_{VNMC})",
            "brief_description": "A hybrid estimator that trains an amortized proposal q_v(θ|y,d) and then uses importance sampling / NMC with that proposal to estimate p(y|d) and hence EIG; combines fast variational training with the asymptotic consistency of NMC.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "BOED using hat_mu_VNMC (variationally trained proposal + NMC refinement)",
            "agent_description": "First trains a proposal q_v(θ|y,d;φ) by minimizing an upper bound (U_VNMC) with small L, then constructs an importance-sampling-based nested MC estimator using many inner samples M (often M &gt;&gt; L) from q_v to obtain asymptotically unbiased EIG estimates.",
            "adaptive_design_method": "Information-gain maximization (EIG) via variationally trained importance-sampling/NMC estimator",
            "adaptation_strategy_description": "Uses a two-stage strategy: quick variational training to learn a good proposal for p(θ|y,d), then performs importance-weighted nested MC with the learned proposal to refine EIG estimates and select designs; proposal improves sample efficiency for the inner loop.",
            "environment_name": "A/B test and Preference benchmarks (explicit-likelihood examples in the paper); general EIG estimation tasks",
            "environment_characteristics": "Stochastic outcomes y with explicit likelihoods in reported experiments; can be applied in settings where p(y|θ,d) is evaluable. Environments may have high variance priors/posteriors where vanilla NMC struggles.",
            "environment_complexity": "Benchmarks in paper: A/B test (θ dim=2, y dim=10) and Preference; complexity depends on M (inner samples) and learned q_v dimension.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "In EIG estimation benchmarks VNMC had much lower bias and variance than plain NMC under fixed budgets (Table 2): e.g., for A/B test hat_mu_VNMC bias^2 = 3.44e-3 and var = 3.38e-3 versus NMC bias^2 = 4.70e0 and var = 3.47e-1. VNMC continues to improve (does not plateau) after initial training as M and N are increased, converging to true EIG as M→∞.",
            "performance_without_adaptation": null,
            "sample_efficiency": "More sample-efficient than vanilla NMC because learned q_v produces lower-variance importance weights; theoretical two-stage cost is T = O(KL + NM) where small KL for training and NM refinement with M ∝ √N yields asymptotic rate O((NM)^{-1/3}) for bias-removal stage. Empirically much lower MSE under fixed compute budgets (Table 2).",
            "exploration_exploitation_tradeoff": "EIG-driven; VNMC's proposal reduces variance in EIG estimates enabling better exploration of design space under fixed compute. No explicit additional exploration heuristic beyond EIG maximization.",
            "comparison_methods": "Compared against NMC, hat_mu_post, hat_mu_marg, Laplace, LFIRE, DV in benchmarks.",
            "key_results": "VNMC bridges variational speed and NMC consistency: fast variational training yields good proposals that dramatically reduce bias/variance at practical budgets, and increasing inner sample count M recovers asymptotic unbiasedness. Empirically outperforms NMC by large margins on benchmark EIG estimation tasks.",
            "limitations_or_failures": "Requires an explicit likelihood for the importance weights (p(y,θ)/q_v); asymptotic unbiasedness requires increasing M (inner samples), which increases computational cost and reintroduces NMC-like scaling; effectiveness depends on quality of trained proposal q_v.",
            "uuid": "e1148.3",
            "source_info": {
                "paper_title": "Variational Bayesian Optimal Experimental Design",
                "publication_date_yy_mm": "2019-03"
            }
        },
        {
            "name_short": "Mixed-effects adaptive human study",
            "name_full": "Adaptive mixed-effects psychology experiment (online Mechanical Turk)",
            "brief_description": "An end-to-end adaptive experiment where VBOED (using the marginal+likelihood estimator hat_mu_{m+ell}) selected face-stimulus designs online for human participants to maximize information about fixed effects while treating individual differences as nuisance random effects.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "BOED system using hat_mu_{m+ell} in online human experiment",
            "agent_description": "Online pipeline: present stimulus to participant, observe response y, update model (mixed effects posterior over θ with nuisance ψ), train/maintain q_m and q_ell approximations (marginal+likelihood) for implicit likelihoods, compute EIG estimates and select next stimulus via Bayesian optimization; repeated across 36 possible designs and 8 participants.",
            "adaptive_design_method": "Information-gain maximization (EIG) using marginal+likelihood variational estimator (suitable for implicit-likelihood mixed-effects model)",
            "adaptation_strategy_description": "At each trial uses current data to update posterior over fixed effects θ (marginalizing nuisance ψ via sampling), trains q_m and q_ell through stochastic gradient ascent on the bounding objective, and selects the next design that maximizes the learned EIG surrogate via Bayesian optimization. The pipeline runs online between subject responses.",
            "environment_name": "Mixed-effects regression model for human psychophysics (8 participants, 36 possible designs)",
            "environment_characteristics": "Partially observable latent fixed effects θ and participant-specific random effects ψ (nuisance); implicit likelihood due to nuisance integration; censored sigmoid observation model; heteroskedastic noise and non-Gaussian observation transform.",
            "environment_complexity": "36 discrete designs (image-pairs formed from 6 feature levels -&gt; design matrix dim 6), 8 participants (random effects per participant), θ modeled as 6-dim fixed-effects vector; implicit likelihood requires sampling over nuisance variables; online, real-time constraints for design selection.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "BOED with hat_mu_{m+ell} led to a more certain posterior (lower entropy) than random design in the online human experiment (Figure 3). The paper reports qualitative and plotted reductions in posterior entropy over trials demonstrating improved learning speed; exact numeric trajectory shown in figure.",
            "performance_without_adaptation": "Random design baseline: produced higher posterior entropy and slower parameter concentration (Figure 3 indicates BOED obtains lower entropy posterior trajectories than random).",
            "sample_efficiency": "Adaptive BOED concentrated posterior with fewer trials than random; demonstrated real-time feasibility for an online experiment with per-trial updates. (No single-number sample count reported; see figure for trial-wise entropy curves.)",
            "exploration_exploitation_tradeoff": "EIG selection naturally balances exploration/exploitation by selecting trials expected to provide maximum posterior-entropy reduction given current posterior over θ and sampled nuisance ψ.",
            "comparison_methods": "Compared against random design baseline in the online human experiment for efficacy; EIG estimator choice justified by benchmark results in Table 2.",
            "key_results": "Demonstrated that variational EIG estimators (specifically marginal+likelihood) are practical and robust enough for real-time adaptive experiments with humans and implicit likelihoods, yielding more informative data and faster posterior concentration than random designs.",
            "limitations_or_failures": "Real-time requirement constrains complexity of variational training; estimator bias possible if variational families are misspecified; marginal+likelihood is not a formal bound on EIG in general (but error can be bounded and the method performed well empirically).",
            "uuid": "e1148.4",
            "source_info": {
                "paper_title": "Variational Bayesian Optimal Experimental Design",
                "publication_date_yy_mm": "2019-03"
            }
        },
        {
            "name_short": "CES revealed-preference simulation",
            "name_full": "Adaptive design for Constant Elasticity of Substitution (CES) revealed-preference model",
            "brief_description": "A simulated revealed-preference experiment where BOED using hat_mu_marg sought designs in d∈[0,100]^6 to efficiently identify an agent's utility parameters (ρ, α, u); compared BOED vs random and NMC-based BOED.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "BOED system using hat_mu_marg for CES agent inference",
            "agent_description": "Simulates agent responses under a CES utility model with latent parameters θ=(ρ, α, u); trains q_m(y|d) to approximate p(y|d), uses Bayesian optimization over d to maximize estimated EIG and selects designs adaptively to reveal agent preferences.",
            "adaptive_design_method": "Information-gain maximization (EIG) with variational marginal estimator",
            "adaptation_strategy_description": "After each simulated response updates posterior over θ, retrains/uses q_m to estimate EIG for candidate designs and selects the maximal-EIG design via Bayesian optimization; repeated sequentially to concentrate posterior on true θ.",
            "environment_name": "CES revealed-preference simulation (synthetic agent)",
            "environment_characteristics": "Stochastic, partially observable responses determined by agent utility under CES model; observation noise and potential censoring; design space continuous and high-dimensional (6-D), responses lower-dimensional relative to θ in this setup.",
            "environment_complexity": "Design d ∈ [0,100]^6; latent θ includes scalar ρ, vector α, and scalar u; experiments simulate many candidate designs and iteratively update posterior; complexity arises from multi-dimensional design and latent space.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "BOED with hat_mu_marg reduced posterior entropy and RMSE of posterior estimates for (ρ, α, u) faster than random design and BOED with NMC (Figure 4); random design made almost no progress, and NMC-based BOED struggled early when the prior/posterior variance was large.",
            "performance_without_adaptation": "Random design baseline: essentially no inroads into learning problem across same iterations (qualitative, Figure 4).",
            "sample_efficiency": "BOED produced significantly faster concentration of posterior per simulated trial compared to baselines (no single numeric sample-count threshold reported; see trial-wise entropy and RMSE plots).",
            "exploration_exploitation_tradeoff": "EIG criterion picks designs that are maximally informative about θ (explicitly encourages exploration that reduces epistemic uncertainty); Bayesian optimization manages exploration over design space under noisy EIG estimates.",
            "comparison_methods": "Random design; BOED with NMC (vanilla nested MC) as baseline.",
            "key_results": "Demonstrated that marginal variational estimator enabled informative design selection in a challenging continuous 6D design space and outperformed NMC and random baselines in terms of posterior entropy reduction and RMSE over sequential trials.",
            "limitations_or_failures": "NMC-based BOED struggled in the early iterations under high prior variance; quality of q_m approximation is critical—misspecification would bias EIG estimates and degrade design selection.",
            "uuid": "e1148.5",
            "source_info": {
                "paper_title": "Variational Bayesian Optimal Experimental Design",
                "publication_date_yy_mm": "2019-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "A tutorial on adaptive design optimization",
            "rating": 2,
            "sanitized_title": "a_tutorial_on_adaptive_design_optimization"
        },
        {
            "paper_title": "Sequential optimal design of neurophysiology experiments",
            "rating": 2,
            "sanitized_title": "sequential_optimal_design_of_neurophysiology_experiments"
        },
        {
            "paper_title": "Efficient Bayesian experimental design for implicit models",
            "rating": 2,
            "sanitized_title": "efficient_bayesian_experimental_design_for_implicit_models"
        },
        {
            "paper_title": "Efficient dynamic discovery of high-value information with partial VAE",
            "rating": 1,
            "sanitized_title": "efficient_dynamic_discovery_of_highvalue_information_with_partial_vae"
        },
        {
            "paper_title": "Bayesian inference and online experimental design for mapping neural microcircuits",
            "rating": 2,
            "sanitized_title": "bayesian_inference_and_online_experimental_design_for_mapping_neural_microcircuits"
        }
    ],
    "cost": 0.02205175,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Variational Bayesian Optimal Experimental Design</h1>
<p>Adam Foster ${ }^{\dagger *}$ Martin Jankowiak ${ }^{\ddagger}$ Eli Bingham ${ }^{\ddagger}$ Paul Horsfall ${ }^{\ddagger}$<br>Yee Whye Teh ${ }^{\dagger}$ Tom Rainforth ${ }^{\dagger}$ Noah Goodman ${ }^{\ddagger \S}$<br>${ }^{\dagger}$ Department of Statistics, University of Oxford, Oxford, UK<br>${ }^{\ddagger}$ Uber AI Labs, Uber Technologies Inc., San Francisco, CA, USA<br>${ }^{\S}$ Stanford University, Stanford, CA, USA<br>adam.foster@stats.ox.ac.uk</p>
<h4>Abstract</h4>
<p>Bayesian optimal experimental design (BOED) is a principled framework for making efficient use of limited experimental resources. Unfortunately, its applicability is hampered by the difficulty of obtaining accurate estimates of the expected information gain (EIG) of an experiment. To address this, we introduce several classes of fast EIG estimators by building on ideas from amortized variational inference. We show theoretically and empirically that these estimators can provide significant gains in speed and accuracy over previous approaches. We further demonstrate the practicality of our approach on a number of end-to-end experiments.</p>
<h2>1 Introduction</h2>
<p>Tasks as seemingly diverse as designing a study to elucidate human cognition, selecting the next query point in an active learning loop, and designing online feedback surveys all constitute the same underlying problem: designing an experiment to maximize the information gathered. Bayesian optimal experimental design (BOED) forms a powerful mathematical abstraction for tackling such problems [8, 23, 37, 43] and has been successfully applied in numerous settings, including psychology [30], Bayesian optimization [16], active learning [15], bioinformatics [42], and neuroscience [38].
In the BOED framework, we construct a predictive model $p(y \mid \theta, d)$ for possible experimental outcomes $y$, given a design $d$ and a particular value of the parameters of interest $\theta$. We then choose the design that optimizes the expected information gain (EIG) in $\theta$ from running the experiment,</p>
<p>$$
\operatorname{EIG}(d) \triangleq \mathbb{E}_{p(y \mid d)}[H[p(\theta)]-H[p(\theta \mid y, d)]]
$$</p>
<p>where $H[\cdot]$ represents the entropy and $p(\theta \mid y, d) \propto p(\theta) p(y \mid \theta, d)$ is the posterior resulting from running the experiment with design $d$ and observing outcome $y$. In other words, we seek the design that, in expectation over possible experimental outcomes, most reduces the entropy of the posterior over our target latent variables. If the predictive model is correct, this forms a design strategy that is (one-step) optimal from an information-theoretic viewpoint [24, 37].
The BOED framework is particularly powerful in sequential contexts, where it allows the results of previous experiments to be used in guiding the designs for future experiments. For example, as we ask a participant a series of questions in a psychology trial, we can use the information gathered from previous responses to ask more pertinent questions in the future, that will, in turn, return more information. This ability to design experiments that are self-adaptive can substantially increase their efficiency: fewer iterations are required to uncover the same level of information.
In practice, however, the BOED approach is often hampered by the difficulty of obtaining fast and high-quality estimates of the EIG: due to the intractability of the posterior $p(\theta \mid y, d)$, it constitutes</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>a nested expectation problem and so conventional Monte Carlo (MC) estimation methods cannot be applied [33]. Moreover, existing methods for tackling nested expectations have, in general, far inferior convergence rates than those for conventional expectations [22, 30, 32]. For example, nested MC (NMC) can only achieve, at best, a rate of $\mathcal{O}\left(T^{-1/3}\right)$ in the total computational cost $T$ [33], compared with $\mathcal{O}\left(T^{-1/2}\right)$ for conventional MC.</p>
<p>To address this, we propose a variational BOED approach that sidesteps the double intractability of the EIG in a principled manner and yields estimators with convergence rates in line with those for conventional estimation problems. To this end, we introduce four efficient and widely applicable variational estimators for the EIG. The different methods each present distinct advantages. For example, two allow training with implicit likelihood models, while one allows for asymptotic consistency even when the variational family does not contain the target distribution.</p>
<p>We theoretically confirm the advantages of our estimators, showing that they all have a convergence rate of $\mathcal{O}\left(T^{-1/2}\right)$ when the variational family contains the target distribution. We further verify their practical utility using a number of experiment design problems inspired by applications from science and industry, showing that they provide significant empirical gains in EIG estimation over previous methods and that these gains lead, in turn, to improved end-to-end performance.</p>
<p>To maximize the space of potential applications and users for our estimators, we provide a general-purpose implementation of them in the probabilistic programming system Pyro [5], exploiting Pyro’s first-class support for neural networks and variational methods.</p>
<h2>2 Background</h2>
<p>The BOED framework is a model-based approach for choosing an experiment design $d$ in a manner that optimizes the information gained about some parameters of interest $\theta$ from the outcome $y$ of the experiment. For instance, we may wish to choose the question $d$ in a psychology trial to maximize the information gained about an underlying psychological property of the participant $\theta$ from their answer $y$ to the question. In general, we adopt a Bayesian modelling framework with a prior $p(\theta)$ and a predictive model $p(y|\theta,d)$. The information gained about $\theta$ from running experiment $d$ and observing $y$ is the reduction in entropy from the prior to the posterior:</p>
<p>$\text{IG}(y,d)=H[p(\theta)]-H[p(\theta|y,d)].$ (2)</p>
<p>At the point of choosing $d$, however, we are uncertain about the outcome. Thus, in order to define a metric to assess the utility of the design $d$ we take the expectation of $\text{IG}(y,d)$ under the marginal distribution over outcomes $p(y|d)=\mathbb{E}_{p(\theta)}[p(y|\theta,d)]$ as per (1). We can further rearrange this as</p>
<p>$\text{EIG}(d)=\mathbb{E}<em p_y_theta_d_="p(y,\theta|d)">{p(y,\theta|d)}\left[\log\frac{p(\theta|y,d)}{p(\theta)}\right]=\mathbb{E}</em>\right]$ (3)}\left[\log\frac{p(y,\theta|d)}{p(\theta)p(y|d)}\right]=\mathbb{E}_{p(y,\theta|d)}\left[\log\frac{p(y|\theta,d)}{p(y|d)</p>
<p>with the result that the EIG can also be interpreted as the mutual information between $\theta$ and $y$ given $d$, or the epistemic uncertainty in $y$ averaged over the prior $p(\theta)$. The Bayesian optimal design is defined as $d^{*}\triangleq\arg\max_{d \in \mathcal{D}} \operatorname{EIG}(d)$, where $\mathcal{D}$ is the set of permissible designs.</p>
<p>Computing the EIG is challenging since neither $p(\theta|y,d)$ or $p(y|d)$ can, in general, be found in closed form. Consequently, the integrand is intractable and conventional MC methods are not applicable. One common way of getting around this is to employ a nested MC (NMC) estimator [30, 43]</p>
<p>$\hat{\mu}<em n="1">{\text{NMC}}(d) \triangleq \frac{1}{N} \sum</em>, d) . \quad$ (4)}^{N} \log \frac{p\left(y_{n} \mid \theta_{n, 0}, d\right)}{\frac{1}{M} \sum_{m=1}^{M} p\left(y_{n} \mid \theta_{n, m}, d\right)} \quad \text { where } \quad \theta_{n, m} \stackrel{\text { i.i.d. }}{\sim} p(\theta), y_{n} \sim p(y \mid \theta=\theta_{n, 0</p>
<p>Rainforth et al. [33] showed that this estimator, which has a total computational cost $T=\mathcal{O}(N M)$, is consistent in the limit $N, M \rightarrow \infty$ with RMSE convergence rate $\mathcal{O}\left(N^{-1 / 2}+M^{-1}\right)$, and that it is asymptotically optimal to set $M \propto \sqrt{N}$, yielding an overall rate of $\mathcal{O}\left(T^{-1 / 3}\right)$.</p>
<p>Given a base EIG estimator, a variety of different methods can be used for the subsequent optimization over designs, including some specifically developed for BOED [1, 29, 32]. In our experiments, we</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>will adopt Bayesian optimization [39], due to its sample efficiency, robustness to multi-modality, and ability to deal naturally with noisy objective evaluations. However, we emphasize that our focus is on the base EIG estimator and that our estimators can be used more generally with different optimizers.</p>
<p>The static design setting we have implicitly assumed thus far in our discussion can be generalized to sequential contexts, in which we design $T$ experiments $d_{1}, \ldots, d_{T}$ with outcomes $y_{1}, \ldots, y_{T}$. We assume experiment outcomes are conditionally independent given the latent variables and designs, i.e.</p>
<p>$$
p\left(y_{1: T}, \theta \mid d_{1: T}\right)=p(\theta) \prod_{t=1}^{T} p\left(y_{t} \mid \theta, d_{t}\right)
$$</p>
<p>Having conducted experiments $1, \ldots, t-1$, we can design $d_{t}$ by incorporating data in the standard Bayesian fashion: at experiment iteration $t$, we replace the prior $p(\theta)$ in (3) with $p\left(\theta \mid d_{1: t-1}, y_{1: t-1}\right)$, the posterior conditional on the first $t-1$ designs and outcomes. We can thus conduct an adaptive sequential experiment in which we optimize the choice of the design $d_{t}$ at each iteration.</p>
<h1>3 Variational Estimators</h1>
<p>Though consistent, the convergence rate of the NMC estimator is prohibitively slow for many practical problems. As such, EIG estimation often becomes the bottleneck for BOED, particularly in sequential experiments where the BOED calculations must be fast enough to operate in real-time.</p>
<p>In this section we show how ideas from amortized variational inference [10, 17, 34, 40] can be used to sidestep the double intractability of the EIG, yielding estimators with much faster convergence rates thereby alleviating the EIG bottleneck. A key insight for realizing why such fundamental gains can be made is that the NMC estimator is inefficient because a separate estimate of the integrand in (3) is made for each $y_{n}$. The variational approaches we introduce instead look to directly learn a functional approximation-for example, an approximation of $y \mapsto p(y \mid d)$ —and then evaluate this approximation at multiple points to estimate the integral, thereby allowing information to be shared across different values of $y$. If $M$ evaluations are made in learning the approximation, the total computational cost is now $T=\mathcal{O}(N+M)$, yielding substantially improved convergence rates.</p>
<p>Variational posterior $\hat{\mu}<em _post="{post" _text="\text">{\text {post }}$ Our first approach, which we refer to as the variational posterior estimator $\hat{\mu}</em>(\theta \mid y, d)$ to the posterior $p(\theta \mid y, d)$ and then using this to estimate the EIG:}}$, is based on learning an amortized approximation $q_{p</p>
<p>$$
\operatorname{EIG}(d) \approx \mathcal{L}<em _mid="\mid" _theta="\theta" d_="d)" p_y_="p(y,">{\text {post }}(d) \triangleq \mathbb{E}</em>}\left[\log \frac{q_{p}(\theta \mid y, d)}{p(\theta)}\right] \approx \hat{\mu<em n="1">{\text {post }}(d) \triangleq \frac{1}{N} \sum</em>
$$}^{N} \log \frac{q_{p}\left(\theta_{n} \mid y_{n}, d\right)}{p\left(\theta_{n}\right)</p>
<p>where $y_{n}, \theta_{n} \stackrel{\text { i.i.d. }}{\sim} p(y, \theta \mid d)$ and $\hat{\mu}<em _post="{post" _text="\text">{\text {post }}(d)$ is a MC estimator of $\mathcal{L}</em>(d)$. We draw samples of $p(y, \theta \mid d)$ by sampling $\theta \sim p(\theta)$ and then $y \mid \theta \sim p(y \mid \theta, d)$. We can think of this approach as amortizing the cost of the inner expectation, instead of running inference separately for each $y$.
To learn a suitable $q_{p}(\theta \mid y, d)$, we show in Appendix A that $\mathcal{L}}<em _post="{post" _text="\text">{\text {post }}(d)$ forms a variational lower bound $\operatorname{EIG}(d) \geq \mathcal{L}</em>(\theta \mid y, d)=p(\theta \mid y, d)$. Barber and Agakov [3] used this bound to estimate mutual information in the context of transmission over noisy channels, but the connection to experiment design has not previously been made.
This result means we can learn $q_{p}(\theta \mid y, d)$ by introducing a family of variational distributions $q_{p}(\theta \mid y, d, \phi)$ parameterized by $\phi$ and then maximizing the bound with respect to $\phi$ :}}(d)$ that is tight if and only if $q_{p</p>
<p>$$
\phi^{<em>}=\underset{\phi}{\arg \max } \mathbb{E}<em p="p">{p(y, \theta \mid d)}\left[\log \frac{q</em>\left(d ; \phi^{}(\theta \mid y, d, \phi)}{p(\theta)}\right], \quad \operatorname{EIG}(d) \approx \mathcal{L}_{\text {post }</em>}\right)
$$</p>
<p>Provided that we can generate samples from the model, this maximization can be performed using stochastic gradient methods [35] and the unbiased gradient estimator</p>
<p>$$
\nabla_{\phi} \mathcal{L}<em i="1">{\text {post }}(d ; \phi) \approx \frac{1}{S} \sum</em> p(y, \theta \mid d)
$$}^{S} \nabla_{\phi} \log q_{p}\left(\theta_{i} \mid y_{i}, d, \phi\right) \quad \text { where } \quad y_{i}, \theta_{i} \stackrel{\text { i.i.d. }}{\sim</p>
<p>and we note that no reparameterization is required as $p(y, \theta \mid d)$ is independent of $\phi$. After $K$ gradient steps we obtain variational parameters $\phi_{K}$ that approximate $\phi^{*}$, which we use to compute</p>
<p>a corresponding EIG estimator by constructing a MC estimator for $\mathcal{L}<em p="p">{\text {post }}(d ; \phi)$ as per (6) with $q</em>}\left(\theta_{n} \mid y_{n}, d\right)=q_{p}\left(\theta_{n} \mid y_{n}, d, \phi_{K}\right)$. Interestingly, the tightness of $\mathcal{L<em _mid="\mid" d_="d)" p_y="p(y">{\text {post }}(d)$ turns out to be equal to the expected forward KL divergence ${ }^{3} \mathbb{E}</em>(\theta \mid y, d, \phi))]$ so we can view this approach as learning an amortized proposal by minimizing this expected KL divergence.}[\operatorname{KL}(p(\theta \mid y, d) | q_{p</p>
<p>Variational marginal $\hat{\mu}<em m="m">{\text {marg }}$ In some scenarios, $\theta$ may be high-dimensional, making it difficult to train a good variational posterior approximation. An alternative approach that can be attractive in such cases is to instead learn an approximation $q</em>(y \mid d)$ to the marginal density $p(y \mid d)$ and substitute this into the final form of the EIG in (3). As shown in Appendix A, this yields an upper bound</p>
<p>$$
\operatorname{EIG}(d) \leq \mathcal{U}<em _mid="\mid" _theta="\theta" d_="d)" p_y_="p(y,">{\text {marg }}(d) \triangleq \mathbb{E}</em>}\left[\log \frac{p(y \mid \theta, d)}{q_{m}(y \mid d)}\right] \approx \hat{\mu<em n="1">{\text {marg }}(d) \triangleq \frac{1}{N} \sum</em>
$$}^{N} \log \frac{p\left(y_{n} \mid \theta_{n}, d\right)}{q_{m}\left(y_{n} \mid d\right)</p>
<p>where again $y_{n}, \theta_{n} \stackrel{\text { i.i.d. }}{=} p(y, \theta \mid d)$ and the bound is tight when $q_{m}(y \mid d)=p(y \mid d)$. Analogously to $\hat{\mu}<em m="m">{\text {post }}$, we can learn $q</em>}(y \mid d)$ by introducing a variational family $q_{m}(y \mid d, \phi)$ and then performing stochastic gradient descent to minimize $\mathcal{U<em _post="{post" _text="\text">{\text {marg }}(d, \phi)$. As with $\hat{\mu}</em>$, this bound was studied in a mutual information context [31], but it has not been utilized for BOED before.}</p>
<p>Variational NMC $\hat{\mu}<em _post="{post" _text="\text">{\text {VNMC }}$ As we will show in Section 4, $\hat{\mu}</em>}}$ and $\hat{\mu<em _VNMC="{VNMC" _text="\text">{\text {marg }}$ can provide substantially faster convergence rates than NMC. However, this comes at the cost of converging towards a biased estimate if the variational family does not contain the target distribution. To address this, we propose another EIG estimator, $\hat{\mu}</em>$
We can think of the NMC estimator as approximating $p(y \mid d)$ using $M$ samples from the prior. At a high-level, $\hat{\mu}}}$, which allows one to trade-off resources between the fast learning of a biased estimator permitted by variational approaches, and the ability of NMC to eliminate this bias. ${ }^{4<em v="v">{\text {VNMC }}$ is based around learning a proposal $q</em>(\theta \mid y, d)$ and then using samples from this proposal to make an importance sampling estimate of $p(y \mid d)$, potentially requiring far fewer samples than NMC. Formally, it is based around a bound that can be arbitrarily tightened, namely</p>
<p>$$
\operatorname{EIG}(d) \leq \mathbb{E}\left[\log p\left(y \mid \theta_{0}, d\right)-\log \frac{1}{L} \sum_{\ell=1}^{L} \frac{p\left(y, \theta_{\ell} \mid d\right)}{q_{v}\left(\theta_{\ell} \mid y, d\right)}\right] \triangleq \mathcal{U}_{\mathrm{VNMC}}(d, L)
$$</p>
<p>where the expectation is taken over $y, \theta_{0: L} \sim p\left(y, \theta_{0} \mid d\right) \prod_{\ell=1}^{L} q_{v}\left(\theta_{\ell} \mid y, d\right)$, which corresponds to one sample $y, \theta_{0}$ from the model and $L$ samples from the approximate posterior conditioned on $y$. To the best of our knowledge, this bound has not previously been studied in the literature. As with $\hat{\mu}<em _marg="{marg" _text="\text">{\text {post }}$ and $\hat{\mu}</em>}}$, we can minimize this bound to train a variational approximation $q_{v}(\theta \mid y, d, \phi)$. Important features of $\mathcal{U<em v="v">{\mathrm{VNMC}}(d, L)$ are summarized in the following lemma; see Appendix A for the proof.
Lemma 1. For any given model $p(\theta) p(y \mid \theta, d)$ and valid $q</em>(\theta \mid y, d)$,</p>
<ol>
<li>$\operatorname{EIG}(d)=\lim <em _VNMC="{VNMC" _text="\text">{L \rightarrow \infty} \mathcal{U}</em>}}(d, L) \leq \mathcal{U<em 2="2">{\text {VNMC }}\left(d, L</em>}\right) \leq \mathcal{U<em 1="1">{\text {VNMC }}\left(d, L</em> \geq 1$,}\right) \quad \forall L_{2} \geq L_{1</li>
<li>$\mathcal{U}<em v="v">{\text {VNMC }}(d, L)=\operatorname{EIG}(d) \quad \forall L \geq 1 \quad$ if $\quad q</em>(\theta \mid y, d)=p(\theta \mid y, d) \quad \forall y, \theta$,</li>
<li>$\mathcal{U}<em _mid="\mid" d_="d)" p_y="p(y">{\text {VNMC }}(d, L)-\operatorname{EIG}(d)=\mathbb{E}</em> \mid y, d\right)\right)\right]$}\left[\operatorname{KL}\left(\prod_{\ell=1}^{L} q_{v}\left(\theta_{\ell} \mid y, d\right)\left|\frac{1}{L} \sum_{\ell=1}^{L} p\left(\theta_{\ell} \mid y, d\right) \prod_{k \neq \ell} q_{v}\left(\theta_{k</li>
</ol>
<p>Like the previous bounds, the VNMC bound is tight when $q_{v}(\theta \mid y, d)=p(\theta \mid y, d)$. Importantly, the bound is also tight as $L \rightarrow \infty$, even for imperfect $q_{v}$. This means we can obtain asymptotically unbiased EIG estimates even when the true posterior is not contained in the variational family.
Specifically, we first train $\phi$ using $K$ steps of stochastic gradient on $\mathcal{U}<em _VNMC="{VNMC" _text="\text">{\text {VNMC }}(d, L)$ with some fixed $L$. To form a final EIG estimator, however, we use a MC estimator of $\mathcal{U}</em>$ fixed}}(d, M)$ where typically $M \gg L$. This final estimator is a NMC estimator that is consistent as $N, M \rightarrow \infty$ with $\phi_{K</p>
<p>$$
\hat{\mu}<em n="1">{\mathrm{VNMC}}(d) \triangleq \frac{1}{N} \sum</em>\right)
$$}^{N}\left(\log p\left(y_{n} \mid \theta_{n, 0}, d\right)-\log \frac{1}{M} \sum_{m=1}^{M} \frac{p\left(y_{n}, \theta_{n, m} \mid d\right)}{q_{v}\left(\theta_{n, m} \mid y_{n}, d, \phi_{K}\right)</p>
<p>where $\theta_{n, 0} \stackrel{\text { i.i.d. }}{=} p(\theta), y_{n} \sim p\left(y \mid \theta=\theta_{n, 0}, d\right)$ and $\theta_{n, m} \sim q_{v}\left(\theta \mid y=y_{n}, d, \phi_{K}\right)$. In practice, performance is greatly enhanced when the proposal $q_{v}$ is a good, if inexact, approximation to the posterior. This significantly improves upon traditional $\hat{\mu}<em v="v">{\mathrm{NMC}}$, which sets $q</em>(\theta \mid y, d)=p(\theta)$ in (11).</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Implicit likelihood and $\hat{\mu}<em _mid="\mid" _theta_="\theta)" p_psi="p(\psi">{\mathbf{m}+\ell}$ So far we have assumed that we can evaluate $p(y \mid \theta, d)$ pointwise. However, many models of interest have implicit likelihoods from which we can draw samples, but not evaluate directly. For example, models with nuisance latent variables $\psi$ (such as a random effect models) are implicit likelihood models because $p(y \mid \theta, d)=\mathbb{E}</em>[p(y \mid \theta, \psi, d)]$ is intractable, but can still be straightforwardly sampled from.
In this setting, $\hat{\mu}<em _marg="{marg" _text="\text">{\text {post }}$ is applicable without modification because it only requires samples from $p(y \mid \theta, d)$ and not evaluations of this density. Although $\hat{\mu}</em>(y \mid \theta, d)$ for the likelihood. We then form the approximation}}$ is not directly applicable in this setting, it can be modified to accommodate implicit likelihoods. Specifically, we can utilize two approximate densities: $q_{m}(y \mid d)$ for the marginal and $q_{\ell</p>
<p>$$
\operatorname{EIG}(d) \approx \mathcal{I}<em _mid="\mid" _theta="\theta" d_="d)" p_y_="p(y,">{\mathrm{m}+\ell}(d) \triangleq \mathbb{E}</em>}\left[\log \frac{q_{\ell}(y \mid \theta, d)}{q_{m}(y \mid d)}\right] \approx \hat{\mu<em n="1">{\mathrm{m}+\ell}(d) \triangleq \frac{1}{N} \sum</em>
$$}^{N} \log \frac{q_{\ell}\left(y_{n} \mid \theta_{n}, d\right)}{q_{m}\left(y_{n} \mid d\right)</p>
<p>Unlike the previous three cases, $\mathcal{I}<em m="m">{\mathrm{m}+\ell}(d)$ is not a bound on $\operatorname{EIG}(d)$, meaning it is not immediately clear how to train $q</em>}(y \mid d)$ and $q_{\ell}(y \mid \theta, d)$ to achieve an accurate EIG estimator. The following lemma shows that we can bound the EIG estimation error of $\mathcal{I<em m="m">{\mathrm{m}+\ell}$. The proof is in Appendix A.
Lemma 2. For any given model $p(\theta) p(y \mid \theta, d)$ and valid $q</em>(y \mid \theta, d)$, we have}(y \mid d)$ and $q_{\ell</p>
<p>$$
\left|\mathcal{I}<em _mid="\mid" _theta="\theta" d_="d)" p_y_="p(y,">{\mathrm{m}+\ell}(d)-\operatorname{EIG}(d)\right| \leq-\mathbb{E}</em>(y \mid \theta, d)\right]+C
$$}\left[\log q_{m}(y \mid d)+\log q_{\ell</p>
<p>where $C=-H[p(y \mid d)]-\mathbb{E}<em m="m">{p(\theta)}[H(p(y \mid \theta, d)]$ does not depend on $q</em>(y \mid \theta, d)=p(y \mid \theta, d)$ for almost all $y, \theta$.}$ or $q_{\ell}$. Further, the RHS of (13) is 0 if and only if $q_{m}(y \mid d)=p(y \mid d)$ and $q_{\ell</p>
<p>This lemma implies that we can learn $q_{m}(y \mid d)$ and $q_{\ell}(y \mid \theta, d)$ by maximizing $\mathbb{E}<em m="m">{p(y, \theta \mid d)}\left[\log q</em>}(y \mid d)+\right.$ $\log q_{\ell}(y \mid \theta, d)]$ using stochastic gradient ascent, and substituting these learned approximations into (12) for the final EIG estimator. To the best of our knowledge, this approach has not previously been considered in the literature. We note that, in general, $q_{m}$ and $q_{\ell}$ are learned separately and there need not be any weight sharing between them. See Appendix A. 4 for a discussion of the case when we couple $q_{m}$ and $q_{\ell}$ so that $q_{m}(y \mid d)=\mathbb{E<em _ell="\ell">{p(\theta)}\left[q</em>(y \mid \theta, d)\right]$.</p>
<p>Using estimators for sequential BOED In sequential settings, we also need to consider the implications of replacing $p(\theta)$ in the EIG with $p\left(\theta \mid d_{1: t-1}, y_{1: t-1}\right)$. At first sight, it appears that, while $\hat{\mu}<em _mathrm_m="\mathrm{m">{\text {marg }}$ and $\hat{\mu}</em>}+\ell}$ only require samples from $p\left(\theta \mid d_{1: t-1}, y_{1: t-1}\right)$, $\hat{\mu<em _mathrm_VNMC="\mathrm{VNMC">{\text {post }}$ and $\hat{\mu}</em>\right)$. Substituting this into the integrand of (6) gives}}$ also require its density to be evaluated, a potentially severe limitation. Fortunately, we can, in fact, avoid evaluating this posterior density. We note that, from (5), we have $p\left(\theta \mid y_{1: t-1}, d_{1: t-1}\right)=$ $p(\theta) \prod_{i=1}^{t-1} p\left(y_{i} \mid \theta, d_{i}\right) / p\left(y_{1: t-1} \mid d_{1: t-1</p>
<p>$$
\mathcal{L}<em t="t">{\text {post }}\left(d</em>}\right)=\mathbb{E<em 1:="1:" t-1="t-1">{p\left(\theta \mid y</em>\right)
$$}, d_{1: t-1}\right) p\left(y_{t} \mid \theta, d_{t}\right)}\left[\log \frac{q_{p}\left(\theta \mid y_{t}, d_{t}\right)}{p(\theta) \prod_{i=1}^{t-1} p\left(y_{i} \mid \theta, d_{i}\right)}\right]+\log p\left(y_{1: t-1} \mid d_{1: t-1</p>
<p>where $p(\theta) \prod_{i=1}^{t-1} p\left(y_{i} \mid \theta, d_{i}\right)$ can be evaluated exactly and the additive constant $\log p\left(y_{1: t-1} \mid d_{1: t-1}\right)$ does not depend on the new design $d_{t}, \theta$, or any of the variational parameters, and so can be safely ignored. Making the same substitution in (11) shows that we can also estimate $\mathcal{U}<em t="t">{\mathrm{VNMC}}\left(d</em>\right)$, approximate or exact, is compatible with all our approaches.}, L\right)$ up to a constant, which can then be similarly ignored. As such, any inference scheme for sampling $p\left(\theta \mid d_{1: t-1}, y_{1: t-1</p>
<p>Selecting an estimator Having proposed four estimators, we briefly discuss how to choose between them in practice. For reference, a summary of our estimators is given in Table 1, along with several baseline approaches. First, $\hat{\mu}<em _mathrm_m="\mathrm{m">{\text {marg }}$ and $\hat{\mu}</em>}+\ell}$ rely on approximating a distribution over $y$; $\hat{\mu<em _mathrm_VNMC="\mathrm{VNMC">{\text {post }}$ and $\hat{\mu}</em>}}$ approximate distributions over $\theta$. We may prefer the former two estimators if $\operatorname{dim}(y) \ll \operatorname{dim}(\theta)$ as it leaves us with a simpler density estimation problem, and vice versa. Second, $\hat{\mu<em _mathrm_VNMC="\mathrm{VNMC">{\text {marg }}$ and $\hat{\mu}</em>$ require an}</p>
<p>Table 1: Summary of EIG estimators. Baseline methods are explained in Section 5.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Implicit</th>
<th style="text-align: center;">Bound</th>
<th style="text-align: center;">Consistent</th>
<th style="text-align: center;">Eq.</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\hat{\mu}_{\text {post }}$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">Lower</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">(6)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\hat{\mu}_{\text {marg }}$</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">Upper</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">(9)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\hat{\mu}_{\text {VNMC }}$</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">Upper</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">(11)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\hat{\mu}_{\mathrm{m}+\ell}$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">(12)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\hat{\mu}_{\text {NMC }}$</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">Upper</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">(4)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\hat{\mu}_{\text {laplace }}$</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">(75)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\hat{\mu}_{\text {LPRE }}$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">(76)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\hat{\mu}_{\text {DV }}$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">Lower</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">(77)</td>
</tr>
</tbody>
</table>
<p>explicit likelihood whereas $\hat{\mu}<em _mathrm_m="\mathrm{m">{\text {post }}$ and $\hat{\mu}</em>}+\ell}$ do not. If an explicit likelihood is available, it typically makes sense to use it-one would never use $\hat{\mu<em _marg="{marg" _text="\text">{\mathrm{m}+\ell}$ over $\hat{\mu}</em>}}$ for example. Finally, if the variational families do not contain the target densities, $\hat{\mu<em _mathrm_VNMC="\mathrm{VNMC">{\mathrm{VNMC}}$ is the only method guaranteed to converge to the true $\operatorname{EIG}(d)$ in the limit as the computational budget increases. So we might prefer $\hat{\mu}</em>$ when computation time and cost are not constrained.}</p>
<h1>4 Convergence rates</h1>
<p>We now investigate the convergence of our estimators. We start by breaking the overall error down into three terms: I) variance in MC estimation of the bound; II) the gap between the bound and the tightest bound possible given the variational family; and III) the gap between the tightest possible bound and $\operatorname{EIG}(d)$. With variational EIG approximation $\mathcal{B}(d) \in\left{\mathcal{L}<em _marg="{marg" _text="\text">{\text {post }}(d), \mathcal{U}</em>}}(d), \mathcal{U<em _mathrm_m="\mathrm{m">{\mathrm{VNMC}}(d, L), \mathcal{I}</em>\right)$ we have, by the triangle inequality,}+\ell}(d)\right}$, optimal variational parameters $\phi^{*}$, learned variational parameters $\phi_{K}$ after $K$ stochastic gradient iterations, and MC estimator $\hat{\mu}\left(d, \phi_{K</p>
<p>$$
\left|\hat{\mu}\left(d, \phi_{K}\right)-\operatorname{EIG}(d)\right|<em K="K">{2} \leq \underbrace{\left|\hat{\mu}\left(d, \phi</em>\right)\right|}\right)-\mathcal{B}\left(d, \phi_{K<em _mathrm_I="\mathrm{I">{2}}</em>\left(d, \phi^{}}+\underbrace{\left|\mathcal{B}\left(d, \phi_{K}\right)-\mathcal{B<em>}\right)\right|<em _mathrm_II="\mathrm{II">{2}}</em>\left(d, \phi^{}}+\underbrace{\left|\mathcal{B</em>}\right)-\operatorname{EIG}(d)\right|}_{\mathrm{III}}
$$</p>
<p>where we have used the notation $|X|<em _mathrm_VNMC="\mathrm{VNMC">{2} \triangleq \sqrt{\mathbb{E}\left[X^{2}\right]}$ to denote the $L^{2}$ norm of a random variable.
By the weak law of large numbers, term I scales as $N^{-1 / 2}$ and can thus be arbitrarily reduced by taking more MC samples. Provided that our stochastic gradient scheme converges, term II can be reduced by increasing the number of stochastic gradient steps $K$. Term III, however, is a constant that can only be reduced by expanding the variational family (or increasing $L$ for $\hat{\mu}</em>(N+K)$.
Theorem 1. Let $\mathcal{X}$ be a measurable space and $\Phi$ be a convex subset of a finite dimensional inner product space. Let $X_{1}, X_{2}, \ldots$ be i.i.d. random variables taking values in $\mathcal{X}$ and $f: \mathcal{X} \times \Phi \rightarrow \mathbb{R}$ be a measurable function. Let}}$ ). Each approximation $\mathcal{B}(d)$ thus converges to a biased estimate of the $\operatorname{EIG}(d)$, namely $\mathcal{B}\left(d, \phi^{*}\right)$. As established by the following Theorem, if we set $N \propto K$, the rate of convergence to this biased estimate is $\mathcal{O}\left(T^{-1 / 2}\right)$, where $T$ represents the total computational cost, with $T=\mathcal{O</p>
<p>$$
\mu(\phi) \triangleq \mathbb{E}\left[f\left(X_{1}, \phi\right)\right] \approx \hat{\mu}<em n="1">{N}(\phi) \triangleq \frac{1}{N} \sum</em>, \phi\right)
$$}^{N} f\left(X_{n</p>
<p>and suppose that $\sup <em 1="1">{\phi \in \Phi}\left|f\left(X</em>, \phi\right)\right|<em _Phi="\Phi" _in="\in" _phi="\phi">{2}&lt;\infty$. Then $\sup </em>}\left|\hat{\mu<em 2="2">{N}(\phi)-\mu(\phi)\right|</em>\right)$. Suppose further that Assumption 1 in Appendix B holds and that $\phi^{}=\mathcal{O}\left(N^{-1 / 2<em>}$ is the unique minimizer of $\mu$. After $K$ iterations of the Polyak-Ruppert averaged stochastic gradient descent algorithm of [28] with gradient estimator $\nabla_{\phi} f\left(X_{t}, \phi\right)$, we have $\left|\mu\left(\phi_{K}\right)-\mu\left(\phi^{</em>}\right)\right|_{2}=\mathcal{O}\left(K^{-1 / 2}\right)$ and, combining with the first result,</p>
<p>$$
\left|\hat{\mu}<em K="K">{N}\left(\phi</em> N \propto K
$$}\right)-\mu\left(\phi^{*}\right)\right|_{2}=\mathcal{O}\left(N^{-1 / 2}+K^{-1 / 2}\right)=\mathcal{O}\left(T^{-1 / 2}\right) \text { if </p>
<p>The proof relies on standard results from MC and stochastic optimization theory; see Appendix B. We note that the assumptions required for the latter, though standard in the literature, are strong. In practice, $\phi$ can converge to a local optimum $\phi^{\dagger}$, rather than the global optimum $\phi^{<em>}$, introducing an additional asymptotic bias $\left|\mathcal{B}\left(d, \phi^{\dagger}\right)-\mathcal{B}\left(d, \phi^{</em>}\right)\right|$ into term III.
Theorem 1 can be applied directly to $\hat{\mu}<em _post="{post" _text="\text">{\text {marg }},-\hat{\mu}</em>}}$, and $\hat{\mu<em _marg="{marg" _text="\text">{\text {VNMC }}$ (with fixed $M=L$ ), showing that they converge respectively to $\mathcal{U}</em>\left(d, \phi^{}<em>}\right),-\mathcal{L}_{\text {post }}\left(d, \phi^{</em>}\right)$, and $\mathcal{U}<em 2="2">{\mathrm{VNMC}}\left(d, L, \phi^{<em>}\right)$ at a rate $=\mathcal{O}\left(T^{-1 / 2}\right)$ if $N \propto K$ and the assumptions are satisfied. For $\hat{\mu}<em _mathrm_VNMC="\mathrm{VNMC">{\mathrm{m}+\ell}$, we combine Theorem 1 and Lemma 2 to obtain the same $\mathcal{O}\left(T^{-1 / 2}\right)$ convergence rates; see the supplementary material for further details.
The key property of $\hat{\mu}</em>}}$ is that we need not set $M=L$ and can remove the asymptotic bias by increasing $M$ with $N$. We begin by training $\phi$ with a fixed value of $L$, decreasing the error term $\left|\mathcal{U<em K="K">{\mathrm{VNMC}}\left(d, L, \phi</em>\left(d, L, \phi^{}\right)-\mathcal{U}_{\mathrm{VNMC}</em>}\right)\right|</em>}$ at the fast rate $\mathcal{O}\left(K^{-1 / 2}\right)$ until $\left|\mathcal{U<em _mathrm_VNMC="\mathrm{VNMC">{\mathrm{VNMC}}\left(d, L, \phi^{*}\right)-\operatorname{EIG}(d)\right|$ becomes the dominant error term. At this point, we start to increase $N, M$. Using the NMC convergence results discussed in Sec. 2, if we set $M \propto \sqrt{N}$, then $\hat{\mu}</em>}}$ converges to $\operatorname{EIG}(d)$ at a rate $\mathcal{O}\left((N M)^{-1 / 3}\right)$. Note that the total cost of the $\hat{\mu<em p_theta_="p(\theta)">{\mathrm{VNMC}}$ estimator is $T=\mathcal{O}(K L+N M)$, where typically $M \gg L$. The first stage, costing $K L$, is fast variational training of an amortized importance sampling proposal for $p(y \mid d)=\mathbb{E}</em>[p(y \mid \theta, d)]$. The second stage, costing $N M$, is slower refinement to remove the asymptotic bias using the learned proposal in an NMC estimator.</p>
<p>Table 2: Bias squared and variance from 5 runs, averaged over designs, of EIG estimators applied to four benchmarks. We use - to denote that a method does not apply and $*$ when it is superseded by other methods. Bold indicates the estimator with the lowest empirical mean squared error.</p>
<table>
<thead>
<tr>
<th></th>
<th>A/B test</th>
<th></th>
<th>Preference</th>
<th></th>
<th>Mixed effects</th>
<th></th>
<th>Extrapolation</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>$\operatorname{Bias}^{2}$</td>
<td>Var</td>
<td>$\operatorname{Bias}^{2}$</td>
<td>Var</td>
<td>$\operatorname{Bias}^{2}$</td>
<td>Var</td>
<td>$\operatorname{Bias}^{2}$</td>
<td>Var</td>
</tr>
<tr>
<td>$\widehat{\mu}_{\text {post }}$</td>
<td>$1.33 \times 10^{-2}$</td>
<td>$7.15 \times 10^{-3}$</td>
<td>$4.26 \times 10^{-2}$</td>
<td>$8.53 \times 10^{-3}$</td>
<td>$2.34 \times 10^{-3}$</td>
<td>$2.92 \times 10^{-3}$</td>
<td>$1.24 \times 10^{-4}$</td>
<td>$5.16 \times 10^{-5}$</td>
</tr>
<tr>
<td>$\widehat{\mu}_{\text {marg }}$</td>
<td>$7.45 \times 10^{-2}$</td>
<td>$6.41 \times 10^{-3}$</td>
<td>$\mathbf{1 . 1 0} \times \mathbf{1 0}^{-\mathbf{3}}$</td>
<td>$\mathbf{1 . 9 9} \times \mathbf{1 0}^{-\mathbf{3}}$</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>$\widehat{\mu}_{\text {VNMC }}$</td>
<td>$3.44 \times 10^{-3}$</td>
<td>$3.38 \times 10^{-3}$</td>
<td>$4.17 \times 10^{-3}$</td>
<td>$9.04 \times 10^{-3}$</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>$\widehat{\mu}_{\text {m-t-f }}$</td>
<td>$*$</td>
<td>$*$</td>
<td>$*$</td>
<td>$*$</td>
<td>$\mathbf{3 . 0 6} \times \mathbf{1 0}^{-\mathbf{3}}$</td>
<td>$\mathbf{5 . 9 4} \times \mathbf{1 0}^{-\mathbf{5}}$</td>
<td>$\mathbf{6 . 9 0} \times \mathbf{1 0}^{-\mathbf{6}}$</td>
<td>$\mathbf{1 . 8 4} \times \mathbf{1 0}^{-\mathbf{5}}$</td>
</tr>
<tr>
<td>$\widehat{\mu}_{\text {NMC }}$</td>
<td>$4.70 \times 10^{0}$</td>
<td>$3.47 \times 10^{-1}$</td>
<td>$7.60 \times 10^{-2}$</td>
<td>$8.36 \times 10^{-2}$</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>$\widehat{\mu}_{\text {laplace }}$</td>
<td>$\mathbf{1 . 9 2} \times \mathbf{1 0}^{-\mathbf{4}}$</td>
<td>$\mathbf{1 . 4 7} \times \mathbf{1 0}^{-\mathbf{3}}$</td>
<td>$8.42 \times 10^{-2}$</td>
<td>$9.70 \times 10^{-2}$</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>$\widehat{\mu}_{\text {LFIRE }}$</td>
<td>$2.29 \times 10^{0}$</td>
<td>$6.20 \times 10^{-1}$</td>
<td>$1.30 \times 10^{-1}$</td>
<td>$1.41 \times 10^{-2}$</td>
<td>$1.41 \times 10^{-1}$</td>
<td>$6.67 \times 10^{-2}$</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>$\widehat{\mu}_{\text {DV }}$</td>
<td>$4.34 \times 10^{0}$</td>
<td>$8.85 \times 10^{-1}$</td>
<td>$9.23 \times 10^{-2}$</td>
<td>$8.07 \times 10^{-3}$</td>
<td>$9.10 \times 10^{-3}$</td>
<td>$5.56 \times 10^{-4}$</td>
<td>$7.84 \times 10^{-6}$</td>
<td>$4.11 \times 10^{-5}$</td>
</tr>
</tbody>
</table>
<p>One can think of the standard NMC approach as a special case of $\hat{\mu}_{\text {VNMC }}$ in which we naively choose $p(\theta)$ as the proposal. That is, standard NMC skips the first stage and hence does not benefit from the improved convergence rate of learning an amortized proposal. It typically requires a much higher total cost to achieve the same accuracy as VNMC.</p>
<h1>5 Related work</h1>
<p>We briefly discuss alternative approaches to EIG estimation for BOED that will form our baselines for empirical comparisons. The Nested Monte Carlo (NMC) baseline was introduced in Sec. 2. Another established approach is to use a Laplace approximation to the posterior [22, 25]; this approach is fast but is limited to continuous variables and can exhibit large bias. Kleinegesse and Gutmann [18] recently suggested an implicit likelihood approach based on the Likelihood-Free Inference by Ratio Estimation (LFIRE) method of Thomas et al. [41]. We also consider a method based on the Donsker-Varadhan (DV) representation of the KL divergence [11] as used by Belghazi et al. [4] for mutual information estimation. Though not previously considered in BOED, we include it as a baseline for illustrative purposes. For a full discussion of the DV bound and a number of other variational bounds used in deep learning, we refer to the recent work of Poole et al. [31]. For further discussion of related work, see Appendix C.</p>
<h2>6 Experiments</h2>
<h3>6.1 EIG estimation accuracy</h3>
<p>We begin by benchmarking our EIG estimators against the aforementioned baselines. We consider four experiment design scenarios inspired by applications of Bayesian data analysis in science and industry. First, A/B testing is used across marketing and design [6, 19] to study population traits. Here, the design is the choice of the A and B group sizes and the Bayesian model is a Gaussian linear model. Second, revealed preference [36] is used in economics to understand consumer behaviour. We consider an experiment design setting in which we aim to learn the underlying utility function of an economic agent by presenting them with a proposal (such as offering them a price for a commodity) and observing their revealed preference. Third, fixed effects and random effects (nuisance variables) are combined in mixed effects models [14, 20]. We consider an example inspired by item-response theory [13] in psychology. We seek information only about the fixed effects, making this an implicit likelihood problem. Finally, we consider an experiment where labelled data from one region of design space must be used to predict labels in a target region by extrapolation [27]. In summary, we have two models with explicit likelihoods (A/B testing, preference) and two that are implicit (mixed effects, extrapolation). Full details of each model are presented in Appendix D.</p>
<p>For each scenario, we estimated the EIG across a grid of designs with a fixed computational budget for each estimator and calculated the true EIG analytically or with brute force computation as appropriate; see Table 2 for the results. Whilst the Laplace method, unsurprisingly, performed best for the Gaussian linear model where its approximation becomes exact, we see that our methods are otherwise more accurate. All our methods outperformed NMC.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Convergence of RMSE for $\hat{\mu}<em _marg="{marg" _text="\text">{\text {post }}$ and $\hat{\mu}</em>$. (a) Convergence in number of MC samples $N$ with a fixed number $K$ of gradient updates of the variational parameters. (b) Convergence in time when increasing $K$ and with $N$ fixed. (c) Convergence in time when setting $N=K$ and increasing both (dashed lines represent theoretical rates). (d) Final RMSE with $N+K=5000$ fixed, for different $K$. Each graph shows the mean with shading representing $\pm 1$ std. err. from 100 trials.}</p>
<h1>6.2 Convergence rates</h1>
<p>We now investigate the empirical convergence characteristics of our estimators. Throughout, we consider a single design point from the A/B test example. We start by examining the convergence of $\hat{\mu}<em _marg="{marg" _text="\text">{\text {post }}$ and $\hat{\mu}</em>$ as we allocate the computational budget in different ways.
We first consider the convergence in $N$ after a fixed number of $K$ updates to the variational parameters. As shown in Figure 1a, the RMSE initially decreases as we increase $N$, before plateauing due to the bias in the estimator. We also see that $\hat{\mu}}<em _marg="{marg" _text="\text">{\text {post }}$ substantially outperforms $\hat{\mu}</em>}}$. We next consider the convergence as a function of wall-clock time when $N$ is held fixed and we increase $K$. We see in Figure 1b that, as expected, the errors decrease with time and that when a small value of $N=5$ is taken, we again see a plateauing effect, with the variance of the final MC estimator now becoming the limiting factor. In Figure 1c we take $N=K$ and increase both, obtaining the predicted convergence rate $\mathcal{O}\left(T^{-1 / 2}\right)$ (shown by the dashed lines). We conjecture that the better performance of $\hat{\mu<em _VNMC="{VNMC" _text="\text">{\text {post }}$ is likely due to $\theta$ being lower dimensional $(\operatorname{dim}=2)$ than $y(\operatorname{dim}=10)$. In Figure 1d, we instead fix $T=N+K$ to investigate the optimal trade-off between optimization and MC error: it appears the range of $K / T$ between 0.5 and 0.9 gives the lowest RMSE.
Finally, we show how $\hat{\mu}</em>}}$ can improve over NMC by using an improved variational proposal for estimating $p(y \mid d)$. In Figure 2, we plot the EIG estimates obtained by first running $K$ steps of stochastic gradient with $L=1$ to learn $q_{v}(\theta \mid y, d)$, before increasing $M$ and $N$. We see that spending some of our time budget training $q_{v}(\theta \mid y, d)$ leads to noticeable improvements in the estimation, but also that it is important to increase $N$ and $M$. Rather than plateauing like $\hat{\mu<em _marg="{marg" _text="\text">{\text {post }}$ and $\hat{\mu}</em>\right)$ rate.}}, \hat{\mu}_{\text {VNMC }}$ continues to improve after the initial training period as, albeit at a slower $O\left(T^{-1 / 3</p>
<h3>6.3 End-to-end sequential experiments</h3>
<p>We now demonstrate the utility of our methods for designing sequential experiments. First, we demonstrate that our variational estimators are sufficiently robust and fast to be used for adaptive experiments with a class of models that are of practical importance in many scientific disciplines. To this end, we run an adaptive psychology experiment with human participants recruited from Amazon Mechanical Turk to study how humans respond to features of stylized faces. To account for fixed effects-those common across the population-as well as individual variations that we treat as nuisance variables, we use the mixed effects regression model introduced in Sec. 6.1. See Appendix D for full details of the experiment.
To estimate the EIG for different designs, we use $\hat{\mu}_{\mathrm{m}+\ell}$, since it yields the best performance on our mixed effects model benchmark (see Table 2). Our EIG estimator is integrated into a system that</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 4: Evolution of the posterior in the sequential CES experiment. (a) Total entropy of a meanfield variational approximation of the posterior. (b)(c)(d) The RMSE of the posterior approximations of $\rho$, $\boldsymbol{\alpha}$ and $u$ as compared to the true values used to simulate agent responses. Note the scale of the vertical axis is logarithmic. All plots show the mean and $\pm 1$ std. err. from 10 independent runs.
presents participants with a stimulus, receives their response, learns an updated model, and designs the next stimulus, all online. Despite the relative simplicity of the design problem (with 36 possible designs) using BOED with $\hat{\mu}<em _marg="{marg" _text="\text">{\mathrm{m}+\ell}$ leads to a more certain (i.e. lower entropy) posterior than random design; see Figure 3.
Second, we consider a more challenging scenario in which a random design strategy gleans very little. We compare random design against two BOED strategies: $\hat{\mu}</em>}}$ and $\hat{\mu<em _marg="{marg" _text="\text">{\text {NMC }}$. Building on the revealed preference example in Sec. 6.1, we consider an experiment to infer an agent's utility function which we model using the Constant Elasticity of Substitution (CES) model [2] with latent variables $\rho, \boldsymbol{\alpha}, u$. We seek designs for which the agent's response will be informative about $\theta=(\rho, \boldsymbol{\alpha}, u)$. See Appendix D for full details. We estimate the EIG using $\hat{\mu}</em>\right)$, the prior at iteration $t$, is high variance. Our method selects informative designs throughout.}}$ because the dimension of $y$ is smaller than that of $\theta$, and select designs $d \in[0,100]^{6}$ using Bayesian optimization. To investigate parameter recovery we simulate agent responses from the model with fixed values of $\rho, \boldsymbol{\alpha}, u$. Figure 4 shows that using BOED with our marginal estimator reduces posterior entropy and concentrates more quickly on the true parameter values than both baselines. Random design makes no inroads into the learning problem, while BOED based on NMC particularly struggles at the outset when $p\left(\theta \mid d_{1: t-1}, y_{1: t-1</p>
<h1>7 Discussion</h1>
<p>We have developed efficient EIG estimators that are applicable to a wide range of experimental design problems. By tackling the double intractability of the EIG in a principled manner, they provide substantially improved convergence rates relative to previous approaches, and our experiments show that these theoretical advantages translate into significant practical gains. Our estimators are wellsuited to modern deep probabilistic programming languages and we have provided an implementation in Pyro. We note that the interplay between variational and MC methods in EIG estimation is not directly analogous to those in standard inference settings because the NMC EIG estimator is itself inherently biased. Our $\hat{\mu}_{\text {VNMC }}$ estimator allows one to play off the advantages of these approaches, namely the fast learning of variational approaches and asymptotic consistency of NMC.</p>
<h1>Acknowledgements</h1>
<p>We gratefully acknowledge research funding from Uber AI Labs. MJ would like to thank Paul Szerlip for help generating the sprites used in the Mechanical Turk experiment. AF would like to thank Patrick Rebeschini, Dominic Richards and Emile Mathieu for their help and support. AF gratefully acknowledges funding from EPSRC grant no. EP/N509711/1. YWT's and TR's research leading to these results has received funding from the European Research Council under the European Union's Seventh Framework Programme (FP7/2007-2013) ERC grant agreement no. 617071.</p>
<h2>References</h2>
<p>[1] Billy Amzal, Frédéric Y Bois, Eric Parent, and Christian P Robert. Bayesian-optimal design via interacting particle systems. Journal of the American Statistical association, 101(474):773-785, 2006.
[2] Kenneth J Arrow, Hollis B Chenery, Bagicha S Minhas, and Robert M Solow. Capital-labor substitution and economic efficiency. The review of Economics and Statistics, pages 225-250, 1961.
[3] David Barber and Felix Agakov. The IM algorithm: a variational approach to information maximization. Advances in Neural Information Processing Systems, 16:201-208, 2003.
[4] Ishmael Belghazi, Sai Rajeswar, Aristide Baratin, R Devon Hjelm, and Aaron Courville. MINE: mutual information neural estimation. arXiv preprint arXiv:1801.04062, 2018.
[5] Eli Bingham, Jonathan P Chen, Martin Jankowiak, Fritz Obermeyer, Neeraj Pradhan, Theofanis Karaletsos, Rohit Singh, Paul Szerlip, Paul Horsfall, and Noah D Goodman. Pyro: Deep universal probabilistic programming. The Journal of Machine Learning Research, 20(1): 973-978, 2019.
[6] George EP Box, J Stuart Hunter, and William G Hunter. Statistics for experimenters. In Wiley Series in Probability and Statistics. Wiley Hoboken, NJ, 2005.
[7] Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders. arXiv preprint arXiv:1509.00519, 2015.
[8] Kathryn Chaloner and Isabella Verdinelli. Bayesian experimental design: A review. Statistical Science, pages 273-304, 1995.
[9] Alex R Cook, Gavin J Gibson, and Christopher A Gilligan. Optimal observation times in experimental epidemic processes. Biometrics, 64(3):860-868, 2008.
[10] Peter Dayan, Geoffrey E Hinton, Radford M Neal, and Richard S Zemel. The Helmholtz machine. Neural computation, 7(5):889-904, 1995.
[11] Monroe D Donsker and SR Srinivasa Varadhan. Asymptotic evaluation of certain Markov process expectations for large time. Communications on Pure and Applied Mathematics, 28(1): $1-47,1975$.
[12] Sylvain Ehrenfeld. Some experimental design problems in attribute life testing. Journal of the American Statistical Association, 57(299):668-679, 1962.
[13] Susan E Embretson and Steven P Reise. Item response theory. Psychology Press, 2013.
[14] Andrew Gelman, Hal S Stern, John B Carlin, David B Dunson, Aki Vehtari, and Donald B Rubin. Bayesian data analysis. Chapman and Hall/CRC, 2013.
[15] Daniel Golovin, Andreas Krause, and Debajyoti Ray. Near-optimal bayesian active learning with noisy observations. In Advances in Neural Information Processing Systems, pages 766-774, 2010.</p>
<p>[16] José Miguel Hernández-Lobato, Matthew W Hoffman, and Zoubin Ghahramani. Predictive entropy search for efficient global optimization of black-box functions. In Advances in neural information processing systems, pages 918-926, 2014.
[17] Diederik P Kingma and Max Welling. Auto-encoding variational Bayes. In ICLR, 2014.
[18] Steven Kleinegesse and Michael Gutmann. Efficient Bayesian experimental design for implicit models. arXiv preprint arXiv:1810.09912, 2018.
[19] Ron Kohavi, Roger Longbotham, Dan Sommerfield, and Randal M Henne. Controlled experiments on the web: survey and practical guide. Data mining and knowledge discovery, 18(1): $140-181,2009$.
[20] John Kruschke. Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press, 2014.
[21] Tuan Anh Le, Maximilian Igl, Tom Rainforth, Tom Jin, and Frank Wood. Auto-encoding sequential monte carlo. arXiv preprint arXiv:1705.10306, 2017.
[22] Jeremy Lewi, Robert Butera, and Liam Paninski. Sequential optimal design of neurophysiology experiments. Neural Computation, 21(3):619-687, 2009.
[23] Dennis V Lindley. On a measure of the information provided by an experiment. The Annals of Mathematical Statistics, pages 986-1005, 1956.
[24] Dennis V Lindley. Bayesian statistics, a review, volume 2. SIAM, 1972.
[25] Quan Long, Marco Scavino, Raúl Tempone, and Suojin Wang. Fast estimation of expected information gains for Bayesian experimental designs based on Laplace approximations. Computer Methods in Applied Mechanics and Engineering, 259:24-39, 2013.
[26] Chao Ma, Sebastian Tschiatschek, Konstantina Palla, Jose Miguel Hernandez Lobato, Sebastian Nowozin, and Cheng Zhang. EDDI: Efficient dynamic discovery of high-value information with partial VAE. arXiv preprint arXiv:1809.11142, 2018.
[27] David JC MacKay. Information-based objective functions for active data selection. Neural computation, 4(4):590-604, 1992.
[28] Eric Moulines and Francis R Bach. Non-asymptotic analysis of stochastic approximation algorithms for machine learning. In Advances in Neural Information Processing Systems, pages $451-459,2011$.
[29] Peter Müller. Simulation based optimal design. Handbook of Statistics, 25:509-518, 2005.
[30] Jay I Myung, Daniel R Cavagnaro, and Mark A Pitt. A tutorial on adaptive design optimization. Journal of mathematical psychology, 57(3-4):53-67, 2013.
[31] Ben Poole, Sherjil Ozair, Aäron van den Oord, Alexander A Alemi, and George Tucker. On variational lower bounds of mutual information. NeurIPS Workshop on Bayesian Deep Learning, 2018.
[32] Tom Rainforth. Automating Inference, Learning, and Design using Probabilistic Programming. PhD thesis, University of Oxford, 2017.
[33] Tom Rainforth, Robert Cornish, Hongseok Yang, Andrew Warrington, and Frank Wood. On nesting Monte Carlo estimators. In International Conference on Machine Learning, pages $4264-4273,2018$.
[34] Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. In Proceedings of the 31st International Conference on Machine Learning, volume 32, pages 1278-1286, 2014.
[35] Herbert Robbins and Sutton Monro. A stochastic approximation method. The annals of mathematical statistics, pages 400-407, 1951.</p>
<p>[36] Paul A Samuelson. Consumption theory in terms of revealed preference. Economica, 15(60): 243-253, 1948.
[37] Paola Sebastiani and Henry P Wynn. Maximum entropy sampling and optimal Bayesian experimental design. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 62(1), 2000.
[38] Ben Shababo, Brooks Paige, Ari Pakman, and Liam Paninski. Bayesian inference and online experimental design for mapping neural microcircuits. In Advances in Neural Information Processing Systems, pages 1304-1312, 2013.
[39] Jasper Snoek, Hugo Larochelle, and Ryan P Adams. Practical Bayesian optimization of machine learning algorithms. In Advances in neural information processing systems, pages 2951-2959, 2012.
[40] Andreas Stuhlmüller, Jacob Taylor, and Noah Goodman. Learning stochastic inverses. In Advances in neural information processing systems, pages 3048-3056, 2013.
[41] Owen Thomas, Ritabrata Dutta, Jukka Corander, Samuel Kaski, and Michael U Gutmann. Likelihood-free inference by ratio estimation. arXiv preprint arXiv:1611.10242, 2016.
[42] Joep Vanlier, Christian A Tiemann, Peter AJ Hilbers, and Natal AW van Riel. A Bayesian approach to targeted experiment design. Bioinformatics, 28(8):1136-1142, 2012.
[43] Benjamin T Vincent and Tom Rainforth. The DARC toolbox: automated, flexible, and efficient delayed and risky choice experiments using bayesian adaptive design. 2017.</p>
<h1>A Details for variational estimators</h1>
<p>The proofs in A. 1 and A. 2 are included for completeness.</p>
<h2>A. 1 Variational posterior $\hat{\mu}_{\text {post }}$</h2>
<p>We require valid approximations $q_{p}(\theta \mid y, d)$ to have the same support as $p(\theta \mid y, d)$. Recall</p>
<p>$$
\mathcal{L}<em _mid="\mid" _theta="\theta" d_="d)" p_y_="p(y,">{\text {post }}(d)=\mathbb{E}</em>\right]
$$}\left[\log \frac{q_{p}(\theta \mid y, d)}{p(\theta)</p>
<p>and</p>
<p>$$
\operatorname{EIG}(d)=\mathbb{E}_{p(y, \theta \mid d)}\left[\log \frac{p(\theta \mid y, d)}{p(\theta)}\right]
$$</p>
<p>We aim to show $\operatorname{EIG}(d) \geq \mathcal{L}_{\text {post }}(d)$. Following [3], we have</p>
<p>$$
\begin{aligned}
\operatorname{EIG}(d)-\mathcal{L}<em _mid="\mid" _theta="\theta" d_="d)" p_y_="p(y,">{\text {post }}(d) &amp; =\mathbb{E}</em>\right] \
&amp; =\mathbb{E}}\left[\log \frac{p(\theta \mid y, d)}{p(\theta)}-\log \frac{q_{p}(\theta \mid y, d)}{p(\theta)<em p="p">{p(y, \theta \mid d)}\left[\log \frac{p(\theta \mid y, d) p(\theta)}{p(\theta) q</em>\right] \
&amp; =\mathbb{E}}(\theta \mid y, d)<em _mid="\mid" d_="d)" p_theta="p(\theta" y_="y,">{p(y \mid d)}\left[\mathbb{E}</em>\right]\right] \
&amp; =\mathbb{E}}\left[\log \frac{p(\theta \mid y, d)}{q_{p}(\theta \mid y, d)<em p="p">{p(y \mid d)}\left[\operatorname{KL}\left(p(\theta \mid y, d) | q</em>(\theta \mid y, d)\right)\right] \
&amp; \geq 0
\end{aligned}
$$</p>
<p>To further prove that the bound is tight, we note that the penultimate term $\mathbb{E}<em p="p">{p(y \mid d)}[\operatorname{KL}\left(p(\theta \mid y, d) | q</em>(\theta \mid y, d)=p(\theta \mid y, d)$ for almost all $y, \theta$.}(\theta \mid y, d)\right)]$ equals 0 if and only if $\operatorname{KL}\left(p(\theta \mid y, d) | q_{p}(\theta \mid y, d)\right)=0$ for almost all $y$ (i.e. the union of all $y$ for which this does not hold has measure zero). The occurs if and only if $q_{p</p>
<h2>A. 2 Variational marginal $\hat{\mu}_{\text {marg }}$</h2>
<p>We now demonstrate that $\mathcal{U}<em _post="{post" _text="\text">{\text {marg }}(d)$ is an upper bound on $\operatorname{EIG}(d)$. Proceeding in the same manner as for $\hat{\mu}</em>$, we find}</p>
<p>$$
\begin{aligned}
\mathcal{U}<em _mid="\mid" _theta="\theta" d_="d)" p_y_="p(y,">{\text {marg }}(d)-\operatorname{EIG}(d) &amp; =\mathbb{E}</em>\right] \
&amp; =\mathbb{E}}\left[\log \frac{p(y \mid \theta, d)}{q_{m}(y \mid d)}-\log \frac{p(y \mid \theta, d)}{p(y \mid d)<em m="m">{p(y, \theta \mid d)}\left[\log \frac{p(y \mid \theta, d) p(y \mid d)}{q</em>\right] \
&amp; =\mathbb{E}}(y \mid d) p(y \mid \theta, d)<em m="m">{p(y \mid d)}\left[\log \frac{p(y \mid d)}{q</em>\right] \
&amp; =\operatorname{KL}\left(p(y \mid d) | q_{m}(y \mid d)\right) \
&amp; \geq 0
\end{aligned}
$$}(y \mid d)</p>
<p>Again, the bound is tight if and only if $q_{m}(y \mid d)=p(y \mid d)$ almost everywhere.</p>
<h2>A. 3 Variational NMC $\hat{\mu}_{\text {VNMC }}$</h2>
<p>We now prove Lemma 1 from the main paper, duplicating the Lemma itself below for convenience.
Lemma 1. For any given model $p(\theta) p(y \mid \theta, d)$ and valid $q_{v}(\theta \mid y, d)$,</p>
<ol>
<li>$\operatorname{EIG}(d)=\lim <em _VNMC="{VNMC" _text="\text">{L \rightarrow \infty} \mathcal{U}</em>}}(d, L) \leq \mathcal{U<em 2="2">{\text {VNMC }}\left(d, L</em>}\right) \leq \mathcal{U<em 1="1">{\text {VNMC }}\left(d, L</em> \geq 1$,}\right) \quad \forall L_{2} \geq L_{1</li>
<li>$\mathcal{U}<em v="v">{\text {VNMC }}(d, L)=\operatorname{EIG}(d) \quad \forall L \geq 1 \quad$ if $\quad q</em>(\theta \mid y, d)=p(\theta \mid y, d) \quad \forall y, \theta$,</li>
<li>$\mathcal{U}<em _mid="\mid" d_="d)" p_y="p(y">{\text {VNMC }}(d, L)-\operatorname{EIG}(d)=\mathbb{E}</em> \mid y, d\right)\right)\right]$}\left[\operatorname{KL}\left(\prod_{\ell=1}^{L} q_{v}\left(\theta_{\ell} \mid y, d\right) | \frac{1}{L} \sum_{\ell=1}^{L} p\left(\theta_{\ell} \mid y, d\right) \prod_{k \neq \ell} q_{v}\left(\theta_{k</li>
</ol>
<p>Proof. Starting with proving the first result in lemma, we first recall the definition of $\mathcal{U}_{\mathrm{VNMC}}(d, L)$ itself,</p>
<p>$$
\mathcal{U}<em 0="0">{\mathrm{VNMC}}(d, L)=\mathbb{E}\left[\log p\left(y \mid \theta</em>\right]
$$}, d\right)-\log \frac{1}{L} \sum_{\ell=1}^{L} \frac{p\left(y, \theta_{\ell} \mid d\right)}{q_{v}\left(\theta_{\ell} \mid y, d\right)</p>
<p>where the expectation is taken over $y, \theta_{0: L} \sim p\left(y, \theta_{0} \mid d\right) \prod_{\ell=1}^{L} q_{v}\left(\theta_{\ell} \mid y, d\right)$. We consider positive integers $L_{2} \geq L_{1}$. We let $\delta=\mathcal{U}<em 1="1">{\mathrm{VNMC}}\left(d, L</em>}\right)-\mathcal{U<em 2="2">{\mathrm{VNMC}}\left(d, L</em>\right)$. Then,</p>
<p>$$
\delta=\mathbb{E}\left[\log \frac{1}{L_{2}} \sum_{\ell=1}^{L_{2}} \frac{p\left(y, \theta_{\ell} \mid d\right)}{q_{v}\left(\theta_{\ell} \mid y, d\right)}\right]-\mathbb{E}\left[\log \frac{1}{L_{1}} \sum_{\ell=1}^{L_{1}} \frac{p\left(y, \theta_{\ell} \mid d\right)}{q_{v}\left(\theta_{\ell} \mid y, d\right)}\right]
$$</p>
<p>We now proceed as in [7]. Let $I_{1}, \ldots, I_{L_{1}}$ be distinct indices drawn uniformly from $1, \ldots, L_{2}$. Then,</p>
<p>$$
\frac{1}{L_{2}} \sum_{\ell=1}^{L_{2}} \frac{p\left(y, \theta_{\ell}\right)}{q_{v}\left(\theta_{\ell} \mid y, d\right)}=\mathbb{E}<em 1="1">{I</em>\right]
$$}, \ldots, I_{L_{1}}}\left[\frac{1}{L_{1}} \sum_{j=1}^{L_{1}} \frac{p\left(y, \theta_{I_{j}}\right)}{q_{v}\left(\theta_{I_{j}} \mid y, d\right)</p>
<p>So</p>
<p>$$
\delta=\mathbb{E}\left[\log \left(\mathbb{E}<em 1:="1:" L__1="L_{1">{I</em>\right]
$$}}}\left[\frac{1}{L_{1}} \sum_{j=1}^{L_{1}} \frac{p\left(y, \theta_{I_{j}}\right)}{q_{v}\left(\theta_{I_{j}} \mid y, d\right)}\right]\right)\right]-\mathbb{E}\left[\log \frac{1}{L_{1}} \sum_{\ell=1}^{L_{1}} \frac{p\left(y, \theta_{\ell} \mid d\right)}{q_{v}\left(\theta_{\ell} \mid y, d\right)</p>
<p>then by Jensen's Inequality</p>
<p>$$
\begin{aligned}
\delta &amp; \geq \mathbb{E}\left[\mathbb{E}<em 1:="1:" L__1="L_{1">{I</em>\right] \
&amp; \geq \mathbb{E}\left[\log \frac{1}{L_{1}} \sum_{\ell=1}^{L_{1}} \frac{p\left(y, \theta_{\ell} \mid d\right)}{q_{v}\left(\theta_{\ell} \mid y, d\right)}\right]-\mathbb{E}\left[\log \frac{1}{L_{1}} \sum_{\ell=1}^{L_{1}} \frac{p\left(y, \theta_{\ell} \mid d\right)}{q_{v}\left(\theta_{\ell} \mid y, d\right)}\right] \
&amp; \geq 0
\end{aligned}
$$}}}\left[\log \left(\frac{1}{L_{1}} \sum_{j=1}^{L_{1}} \frac{p\left(y, \theta_{I_{j}}\right)}{q_{v}\left(\theta_{I_{j}} \mid y, d\right)}\right)\right]\right]-\mathbb{E}\left[\log \frac{1}{L_{1}} \sum_{\ell=1}^{L_{1}} \frac{p\left(y, \theta_{\ell} \mid d\right)}{q_{v}\left(\theta_{\ell} \mid y, d\right)</p>
<p>where we have used that $\theta_{I_{1}}, \ldots, \theta_{I_{L_{1}}} \stackrel{d}{=} \theta_{1}, \ldots, \theta_{L_{1}}$. This shows that $\mathcal{U}<em 1="1">{\mathrm{VNMC}}\left(d, L</em>}\right) \geq \mathcal{U<em 2="2">{\mathrm{VNMC}}\left(d, L</em>\right)$. For the limit $\lim <em _mathrm_VNMC="\mathrm{VNMC">{L \rightarrow \infty} \mathcal{U}</em>(d, L)$ we first fix some $y$ for which $p(y \mid d)&gt;0$ and consider}</p>
<p>$$
\mathcal{U}<em 0="0">{\mathrm{VNMC}}(d, L, y)=\mathbb{E}\left[\log p\left(y \mid \theta</em>\right]
$$}, d\right)-\log \frac{1}{L} \sum_{\ell=1}^{L} \frac{p\left(y, \theta_{\ell} \mid d\right)}{q_{v}\left(\theta_{\ell} \mid y, d\right)</p>
<p>with the expectation taken over $p\left(\theta_{0} \mid y, d\right) \prod_{\ell=1}^{L} q_{v}\left(\theta_{\ell} \mid y, d\right)$. Since $p(y, \theta \mid d) / q_{v}(\theta \mid y, d)$ is bounded by assumption, the Strong Law of Large Numbers implies that, in limit of large $L$,</p>
<p>$$
\frac{1}{L} \sum_{\ell=1}^{L} \frac{p\left(y, \theta_{\ell} \mid d\right)}{q_{v}\left(\theta_{\ell} \mid y, d\right)} \rightarrow p(y \mid d) \text { a.s. }
$$</p>
<p>Furthermore, using the same argument as before, $\mathcal{U}<em 1="1">{\mathrm{VNMC}}\left(d, L</em>}, y\right) \geq \mathcal{U<em 2="2">{\mathrm{VNMC}}\left(d, L</em>$. Thus the Bounded Convergence Theorem implies}, y\right)$ whenever $L_{2} \geq L_{1</p>
<p>$$
\mathcal{U}<em p_left_theta__0="p\left(\theta_{0">{\mathrm{VNMC}}(d, L, y) \downarrow \mathbb{E}</em> L \rightarrow \infty
$$} \mid y, d\right)}\left[\log p\left(y \mid \theta_{0}, d\right)-\log p(y \mid d)\right] \text { as </p>
<p>so, taking expectations of $p(y \mid d)$, by the Monotone Convergence Theorem</p>
<p>$$
\mathcal{U}<em _theta__0="\theta_{0" p_left_y_="p\left(y,">{\mathrm{VNMC}}(d, L) \downarrow \mathbb{E}</em> L \rightarrow \infty
$$} \mid d\right)}\left[\log p\left(y \mid \theta_{0}, d\right)-\log p(y \mid d)\right]=\operatorname{EIG}(d) \text { as </p>
<p>For the second result, we simply note that</p>
<p>$$
\frac{p(y, \theta \mid d)}{p(\theta \mid y, d)}=\frac{p(y, \theta \mid d)}{\frac{p(y, \theta \mid d)}{p(y \mid d)}}=p(y \mid d)
$$</p>
<p>Finally, for the third result, we proceed as in [21]. We have</p>
<p>$$
\mathcal{U}<em _ell="1">{\mathrm{VNMC}}(d, L)-\operatorname{EIG}(d)=\mathbb{E}\left[\log p(y \mid d)-\log \frac{1}{L} \sum</em>\right]
$$}^{l} \frac{p\left(y, \theta_{\ell} \mid d\right)}{q_{v}\left(\theta_{\ell} \mid y, d\right)</p>
<p>where the expectation is over $p\left(y, \theta_{0} \mid d\right) \prod_{\ell=1}^{L} q_{v}\left(\theta_{\ell} \mid y, d\right)$.
Then</p>
<p>$$
\begin{aligned}
\mathcal{U}<em _ell="1">{\mathrm{VNMC}}(d, L)-\operatorname{EIG}(d) &amp; =\mathbb{E}\left[-\log \frac{1}{L} \sum</em>\right] \
&amp; =\mathbb{E}\left[\log \frac{\prod_{\ell=1}^{L} q_{v}\left(\theta_{\ell} \mid y, d\right)}{\frac{1}{L} \sum_{\ell=1}^{L} p\left(\theta_{\ell} \mid y, d\right) \prod_{k \neq \ell} q_{v}\left(\theta_{k} \mid y, d\right)}\right] \
&amp; =\mathbb{E}\left[\log \frac{\prod_{\ell=1}^{L} q_{v}\left(\theta_{\ell} \mid y, d\right)}{P\left(\theta_{1: L} \mid y, d\right)}\right] \
&amp; =\mathbb{E}}^{L} \frac{p\left(\theta_{\ell} \mid y, d\right)}{q_{v}\left(\theta_{\ell} \mid y, d\right)<em _ell="1">{p(y \mid d)}\left[\operatorname{KL}\left(\prod</em> \mid y, d\right)\right)\right]
\end{aligned}
$$}^{L} q_{v}\left(\theta_{\ell} \mid y, d\right) | P\left(\theta_{1: L</p>
<p>where $P\left(\theta_{1: L} \mid y, d\right)=\frac{1}{L} \sum_{\ell=1}^{L} p\left(\theta_{\ell} \mid y, d\right) \prod_{k \neq \ell} q_{v}\left(\theta_{k} \mid y, d\right)$.</p>
<h1>A. 4 Variational marginal + likelihood $\hat{\mu}_{\mathbf{m}+\ell}$</h1>
<p>We now prove Lemma 2 from the main paper, duplicating the Lemma itself below for convenience.
Lemma 2. For any given model $p(\theta) p(y \mid \theta, d)$ and valid $q_{m}(y \mid d)$ and $q_{\ell}(y \mid \theta, d)$, we have</p>
<p>$$
\left|\mathcal{I}<em _mid="\mid" _theta="\theta" d_="d)" p_y_="p(y,">{\mathfrak{m}+\ell}(d)-\operatorname{EIG}(d)\right| \leq-\mathbb{E}</em>(y \mid \theta, d)\right]+C
$$}\left[\log q_{m}(y \mid d)+\log q_{\ell</p>
<p>where $C=-H[p(y \mid d)]-\mathbb{E}<em m="m">{p(\theta)}[H(p(y \mid \theta, d)]$ does not depend on $q</em>(y \mid \theta, d)=p(y \mid \theta, d)$ for almost all $y, \theta$.}$ or $q_{\ell}$. Further, the RHS of (13) is 0 if and only if $q_{m}(y \mid d)=p(y \mid d)$ and $q_{\ell</p>
<p>Proof. We aim to bound $\left|\mathcal{I}<em _mathfrak_m="\mathfrak{m">{\mathfrak{m}+\ell}(d)-\operatorname{EIG}(d)\right|$. Let $\delta=\mathcal{I}</em>(d)$. We have}+\ell}(d)-\operatorname{EIG</p>
<p>$$
\begin{aligned}
\delta &amp; =\mathbb{E}<em _ell="\ell">{p(y, \theta \mid d)}\left[\log \frac{q</em>}(y \mid \theta, d)}{q_{m}(y \mid d)}\right]-\mathbb{E<em _mid="\mid" _theta="\theta" d_="d)" p_y_="p(y,">{p(y, \theta \mid d)}\left[\log \frac{p(y \mid \theta, d)}{p(y \mid d)}\right] \
&amp; =\mathbb{E}</em>\right] \
&amp; =\mathbb{E}}\left[\log \frac{q_{\ell}(y \mid \theta, d)}{q_{m}(y \mid d)}-\log \frac{p(y \mid \theta, d)}{p(y \mid d)<em _ell="\ell">{p(y, \theta \mid d)}\left[\log \frac{q</em>\right] \
&amp; =-\mathbb{E}}(y \mid \theta, d)}{q_{m}(y \mid d)}-\log \frac{p(y \mid \theta, d)}{q_{m}(y \mid d)}+\log \frac{p(y \mid \theta, d)}{q_{m}(y \mid d)}-\log \frac{p(y \mid \theta, d)}{p(y \mid d)<em m="m">{p(y, \theta \mid d)}\left[\log \frac{q</em>}(y \mid d) p(y \mid \theta, d)}{q_{\ell}(y \mid \theta, d) q_{m}(y \mid d)}\right]+\mathbb{E<em m="m">{p(y, \theta \mid d)}\left[\log \frac{p(y \mid \theta, d) p(y \mid d)}{q</em>\right] \
&amp; =-\mathbb{E}}(y \mid d) p(y \mid \theta, d)<em _mid="\mid" _theta_="\theta," d_="d)" p_y="p(y">{p(\theta)}\left[\mathbb{E}</em>}\left[\log \frac{p(y \mid \theta, d)}{q_{\ell}(y \mid \theta, d)}\right]\right]+\mathbb{E<em m="m">{p(y \mid d)}\left[\log \frac{p(y \mid d)}{q</em>\right] \
&amp; =-\mathbb{E}}(y \mid d)<em _ell="\ell">{p(\theta)}[\operatorname{KL}\left(p(y \mid \theta, d) | q</em>(y \mid d)\right)
\end{aligned}
$$}(y \mid \theta, d)\right)]+\operatorname{KL}\left(p(y \mid d) | q_{m</p>
<p>So, by the triangle inequality</p>
<p>$$
|\delta| \leq \mathbb{E}<em _ell="\ell">{p(\theta)}[\operatorname{KL}\left(p(y \mid \theta, d) | q</em>(y \mid d)\right)
$$}(y \mid \theta, d)\right)]+\operatorname{KL}\left(p(y \mid d) | q_{m</p>
<p>We can rewrite the RHS using the following relation</p>
<p>$$
\begin{aligned}
\operatorname{KL}(p(x) | q(x)) &amp; =\mathbb{E}<em p_x_="p(x)">{p(x)}\left[\log \frac{p(x)}{q(x)}\right] \
&amp; =\mathbb{E}</em>}[\log p(x)]-\mathbb{E<em p_x_="p(x)">{p(x)}[\log q(x)] \
&amp; =-H[p(x)]-\mathbb{E}</em>[\log q(x)]
\end{aligned}
$$</p>
<p>This gives us</p>
<p>$$
\begin{aligned}
|\delta| &amp; \leq \mathbb{E}<em _mid="\mid" _theta="\theta" d_="d)" p_y_="p(y,">{p(\theta)}[-H\left(p(y \mid \theta, d)\right]-\mathbb{E}</em>}\left[\log q_{\ell}(y \mid \theta, d)\right]-H[p(y \mid d)]-\mathbb{E<em m="m">{p(y, \mid d)}\left[\log q</em>(y \mid d)\right] \
&amp; \leq-\mathbb{E}<em m="m">{p(y, \theta \mid d)}\left[\log q</em>[H(p(y \mid \theta, d)]
\end{aligned}
$$}(y \mid d)+\log q_{\ell}(y \mid \theta, d)\right]-H[p(y \mid d)]-\mathbb{E}_{p(\theta)</p>
<p>as required.
Finally, from (51) we see that the error bound is tight if and only if both KL-divergences are 0 if and only if $q_{\ell}(y \mid \theta, d)=p(y \mid \theta, d)$ and $q_{m}(y \mid d)=p(y \mid d)$ for almost all $y, \theta$.</p>
<p>We conclude with an additional observation. Suppose that we set $q_{m}(y \mid d)=\mathbb{E}<em _ell="\ell">{p(\theta)}[q</em>}(y \mid \theta, d)]$. This could be possible for instance when $\theta$ takes finitely many values. In this case, $\mathcal{I<em m="m">{\mathrm{m}+\ell}(d)$ is actually a lower bound on $\operatorname{EIG}(d)$. This is in contrast to the general case when $q</em>$ are learned separately, in which it is neither an upper nor a lower bound.
To show that $\mathcal{I}}$ and $q_{\ell<em m="m">{\mathrm{m}+\ell}(d)$ is a lower bound when $q</em>}(y \mid d)=\mathbb{E<em _ell="\ell">{p(\theta)}\left[q</em>(y \mid \theta, d)\right]$, we begin with the Donsker-Varadhan bound [11]</p>
<p>$$
\operatorname{EIG}(d) \geq \mathbb{E}<em _mid="\mid" d_="d)" p_theta_="p(\theta)" p_y="p(y">{p(y, \theta \mid d)}[T(y, \theta)]-\log \left(\mathbb{E}</em>\right]\right)
$$}\left[e^{T(y, \theta)</p>
<p>Substituting $T(y, \theta)=\log \left(q_{\ell}(y \mid \theta, d) / q_{m}(y \mid d)\right)$ we have</p>
<p>$$
\begin{aligned}
\operatorname{EIG}(d) &amp; \left.\geq \mathbb{E}<em _ell="\ell">{p(y, \theta \mid d)}\left[\log \frac{q</em>}(y \mid \theta, d)}{q_{m}(y \mid d)}\right]-\log \left(\mathbb{E<em _ell="\ell">{p(\theta) p(y \mid d)}\left[\frac{q</em>\right]\right)\right. \
&amp; \left.\geq \mathcal{I}}(y \mid \theta, d)}{q_{m}(y \mid d)<em _mid="\mid" d_="d)" p_y="p(y">{\mathrm{m}+\ell}(d)-\log \left(\mathbb{E}</em>}\left[\mathbb{E<em _ell="\ell">{p(\theta)}\left{\frac{q</em>\right}\right]\right)\right. \
&amp; \left.\geq \mathcal{I}}(y \mid \theta, d)}{q_{m}(y \mid d)<em _mid="\mid" d_="d)" p_y="p(y">{\mathrm{m}+\ell}(d)-\log \left(\mathbb{E}</em>}\left[\frac{\mathbb{E<em _ell="\ell">{p(\theta)}\left{q</em>\right]\right)\right. \
&amp; \left.\geq \mathcal{I}}(y \mid \theta, d)\right}}{q_{m}(y \mid d)<em _mid="\mid" d_="d)" p_y="p(y">{\mathrm{m}+\ell}(d)-\log \left(\mathbb{E}</em>\right]\right)\right. \
&amp; \geq \mathcal{I}_{\mathrm{m}+\ell}(d)
\end{aligned}
$$}\left[\frac{q_{m}(y \mid d)}{q_{m}(y \mid d)</p>
<h1>B Details for convergence rates</h1>
<p>We now provide the details for Theorem 1. Key to proving the aspect of the Theorem relating to the convergence of the variational parameter $\phi_{K}$ to $\phi^{*}$ is Assumption 1. Points 1-5 correspond to assumptions H2', H3, H4, H6, and H7 of [28]; our proof will rely heavily on theirs. We note that also that our measurability assumption made in the Theorem itself means that their assumption H1 is automatically satisfied.
Assumption 1. Assume:</p>
<ol>
<li>The function $\phi \mapsto f(X, \phi)$ is almost surely convex in its second argument and differentiable with Lipschitz continuous gradient, i.e. $\forall \phi_{1}, \phi_{2} \in \Phi$ :</li>
</ol>
<p>$$
\mathbb{E}\left(\left|\nabla f\left(X, \phi_{1}\right)-\nabla f\left(X, \phi_{2}\right)\right|^{2}\right) \leq C\left|\phi_{1}-\phi_{2}\right|
$$</p>
<p>with probability 1 for some $C$.
2. The function $f$ is $\nu$-strongly convex; that is, for all $\phi_{1}, \phi_{2} \in \Phi$ :</p>
<p>$$
\begin{aligned}
f\left(X, \phi_{1}\right) \geq f\left(X, \phi_{2}\right) &amp; +\nabla f\left(X, \phi_{2}\right)^{T}\left(\phi_{1}-\phi_{2}\right) \
&amp; +\frac{\nu}{2}\left|\phi_{1}-\phi_{2}\right|^{2}
\end{aligned}
$$</p>
<ol>
<li>There exists $\sigma&gt;0$ such that $\mathbb{E}\left[\left|\nabla f\left(X, \phi^{*}\right)\right|^{2}\right) \leq \sigma^{2}$</li>
<li>The function $\phi \mapsto f(X, \phi)$ is almost surely twice differentiable with Lipschitz continuous Hessian $H f$, i.e. $\forall \phi_{1}, \phi_{2} \in \Phi$ :</li>
</ol>
<p>$$
\mathbb{E}\left(\left|(H f)\left(X, \phi_{1}\right)-(H f)\left(X, \phi_{2}\right)\right|\right) \leq C^{\prime}\left|\phi_{1}-\phi_{2}\right|
$$</p>
<ol>
<li>There exists $\tau&gt;0$ such that $\mathbb{E}\left[\left|\nabla f\left(X, \phi^{<em>}\right)\right|^{4}\right] \leq \tau^{4}$ and there exists a positive definite operator $\Sigma$ such that $\mathbb{E}\left[\nabla f\left(X, \phi^{</em>}\right) \otimes \nabla f\left(X, \phi^{*}\right)\right] \preccurlyeq \Sigma$</li>
<li>The function $\mu$ is Lipschitz continuous</li>
</ol>
<p>It should be noted that, though relatively standard, these assumptions are also quite strong, particularly the assumption of strong convexity of $f$, and may well not hold in practice. In short, the stochastic gradient scheme used in optimizing the bounds may only converge toward a local optimum of</p>
<p>the bound $\phi^{\dagger}$, rather than the global optimum $\phi^{*}$. When this happens the behavior and rates of convergence will generally be the same, but the error breakdown will become</p>
<p>$$
\begin{aligned}
&amp; \left|\hat{\mu}\left(d, \phi_{K}\right)-\operatorname{EIG}(d)\right|<em K="K">{2} \
&amp; \leq\left|\hat{\mu}\left(d, \phi</em>\right)\right|}\right)-\mathcal{B}\left(d, \phi_{K<em K="K">{2} \
&amp;+\left|\mathcal{B}\left(d, \phi</em> \
&amp;+\left|\mathcal{B}\left(d, \phi^{\dagger}\right)-\operatorname{EIG}(d)\right|
\end{aligned}
$$}\right)-\mathcal{B}\left(d, \phi^{\dagger}\right)\right|_{2</p>
<p>where</p>
<p>$$
\left|\mathcal{B}\left(d, \phi^{\dagger}\right)-\operatorname{EIG}(d)\right| \geq\left|\mathcal{B}\left(d, \phi^{*}\right)-\operatorname{EIG}(d)\right|
$$</p>
<p>We now present our proof for the result, repeating the Theorem itself for convenience.
Theorem 1. Let $\mathcal{X}$ be a measurable space and $\Phi$ be a convex subset of a finite dimensional inner product space. Let $X_{1}, X_{2}, \ldots$ be i.i.d. random variables taking values in $\mathcal{X}$ and $f: \mathcal{X} \times \Phi \rightarrow \mathbb{R}$ be a measurable function. Let</p>
<p>$$
\mu(\phi) \triangleq \mathbb{E}\left[f\left(X_{1}, \phi\right)\right] \approx \hat{\mu}<em n="1">{N}(\phi) \triangleq \frac{1}{N} \sum</em>, \phi\right)
$$}^{N} f\left(X_{n</p>
<p>and suppose that $\sup <em 1="1">{\phi \in \Phi}\left|f\left(X</em>, \phi\right)\right|<em _Phi="\Phi" _in="\in" _phi="\phi">{2}&lt;\infty$. Then $\sup </em>}\left|\hat{\mu<em 2="2">{N}(\phi)-\mu(\phi)\right|</em>\right)$. Suppose further that Assumption 1 in Appendix B holds and that $\phi^{}=\mathcal{O}\left(N^{-1 / 2<em>}$ is the unique minimizer of $\mu$. After $K$ iterations of the Polyak-Ruppert averaged stochastic gradient descent algorithm of [28] with gradient estimator $\nabla_{\phi} f\left(X_{t}, \phi\right)$, we have $\left|\mu\left(\phi_{K}\right)-\mu\left(\phi^{</em>}\right)\right|_{2}=\mathcal{O}\left(K^{-1 / 2}\right)$ and, combining with the first result,</p>
<p>$$
\left|\hat{\mu}<em K="K">{N}\left(\phi</em> N \propto K
$$}\right)-\mu\left(\phi^{*}\right)\right|_{2}=\mathcal{O}\left(N^{-1 / 2}+K^{-1 / 2}\right)=\mathcal{O}\left(T^{-1 / 2}\right) \text { if </p>
<h1>Proof of Theorem 1</h1>
<p>Proof. We begin by establishing the uniform convergence of $\hat{\mu}<em n="n">{N}(\phi)$ to $\mu(\phi)$, for which we simply use the $L^{2}$ weak law of large numbers. Specifically, we let $Y</em>}=f\left(X_{n}, \phi\right)$ and $\varepsilon_{N}(\phi)=\left|\hat{\mu<em 2="2">{N}(\phi)-\right.$ $\mu(\phi) |</em>$, then</p>
<p>$$
\begin{aligned}
\varepsilon_{N}^{2}(\phi) &amp; =\mathbb{E}\left(\left[\frac{1}{N} \sum_{n=1}^{N}\left(Y_{n}-\mathbb{E} Y_{n}\right)\right]^{2}\right) \
&amp; =\mathbb{E}\left(\frac{1}{N^{2}} \sum_{n=1}^{N}\left(Y_{n}-\mathbb{E} Y_{n}\right)^{2}\right) \
&amp; =\frac{1}{N^{2}} \cdot N \operatorname{Var}\left(Y_{n}\right) \
&amp; \leq \frac{1}{N} \sup <em 1="1">{\phi \in \Phi}\left|f\left(X</em>
\end{aligned}
$$}, \phi\right)\right|_{2}^{2</p>
<p>which is bounded by assumption. Thus</p>
<p>$$
\sup <em N="N">{\phi \in \Phi} \varepsilon</em>\right)
$$}(\phi)=\mathcal{O}\left(N^{-1 / 2</p>
<p>as required.
We turn now to the stochastic gradient descent convergence. We begin by applying Theorem 3 of [28] using points 1-5 of Assumption 1 to give</p>
<p>$$
\left|\phi_{K}-\phi^{*}\right|_{2}=\mathcal{O}\left(K^{-1 / 2}\right)
$$</p>
<p>and (see [28] page 4)</p>
<p>$$
\mathbb{E} \mu\left(\phi_{K}\right)-\mu\left(\phi^{*}\right)=\mathcal{O}\left(K^{-1 / 2}\right)
$$</p>
<p>To establish $L^{2}$ convergence of the function values, it remains to control the variance of $\mu\left(\phi_{K}\right)$. We now invoke point 6 of Assumption 1 to see that, for some constant $B$ (namely the Lipschitz constant for $\mu$ ),</p>
<p>$$
\operatorname{Var}\left[\mu\left(\phi_{K}\right)\right]=\mathbb{E}\left[\left(\mu\left(\phi_{K}\right)-\mathbb{E}\left[\mu\left(\phi_{K}\right)\right]\right)^{2}\right]
$$</p>
<p>$$
\begin{aligned}
&amp; \leq \mathbb{E}\left[\left(\mu\left(\phi_{K}\right)-\mu\left(\mathbb{E} \phi_{K}\right)\right)^{2}\right] \
&amp; \leq B^{2} \mathbb{E}\left[\left(\phi_{t}-\mathbb{E} \phi_{t}\right)^{2}\right] \
&amp; \leq B^{2}\left|\phi_{K}-\phi^{*}\right|_{2}^{2}
\end{aligned}
$$</p>
<p>By (69) we conclude $\sqrt{\operatorname{Var}\left[\mu\left(\phi_{K}\right)\right]}=\mathcal{O}\left(K^{-1 / 2}\right)$. Thus $\mu\left(\phi_{K}\right)$ converges in $L^{2}$ at the required rate. Finally, if $\epsilon_{K}=\left|\hat{\mu}<em K="K">{K}\left(\phi</em>$ then}\right)-\mu\left(\phi^{*}\right)\right|_{2</p>
<p>$$
\begin{aligned}
\epsilon_{K} &amp; \leq\left|\hat{\mu}<em K="K">{K}\left(\phi</em>\right)\right|}\right)-\mu\left(\phi_{K<em K="K">{2}+\left|\mu</em>\right)\right|}\left(\phi_{K}\right)-\mu\left(\phi^{*<em K="K">{2} \
&amp; \leq\left|\hat{\mu}</em>\right)\right|}\left(\phi_{K}\right)-\mu\left(\phi_{K<em _Phi="\Phi" _in="\in" _phi="\phi">{2}+\sup </em>}\left|\hat{\mu<em 2="2">{K}(\phi)-\mu(\phi)\right|</em> \
&amp; =\mathcal{O}\left(N^{-1 / 2}+K^{-1 / 2}\right) \
&amp; =\mathcal{O}\left(T^{-1 / 2}\right)
\end{aligned}
$$</p>
<p>as required.
Finally, we discuss the necessary extensions for $\mathcal{I}<em _mathrm_m="\mathrm{m">{\mathrm{m}+\ell}$. The assumptions of the Theorem are subtly different in this case. Specifically, we require Assumption 1 to hold for the integrand of $\mathcal{F}$ rather than the integrand of $\mathcal{I}</em>}+\ell}$, where $\mathcal{F}(d, \phi)=-\mathbb{E}\left[\log q_{m}(y \mid d)+\log q_{\ell}(y \mid \theta, d)\right]+C$ is the loss function that we use to train $\phi$, and require $\mathcal{I<em 2="2">{\mathrm{m}+\ell}$ to be Lipschitz continuous in $\phi$.
The Monte Carlo error is no different in this setting. However, $\phi^{<em>}$ is optimal with respect to $\mathcal{F}(d, \phi)$ rather than $\mathcal{I}<em _mathrm_m="\mathrm{m">{\mathrm{m}+\ell}$ and the asymptotic bias term is $\left|\mathcal{I}</em>\left(d, \phi^{}+\ell</em>}\right)-\operatorname{EIG}(d)\right| \leq \mathcal{F}\left(d, \phi^{<em>}\right)$ by Lemma 2. For the optimization term, we have from equation (69) that $\left|\phi_{K}-\phi^{</em>}\right|</em>}=\mathcal{O}\left(K^{-1 / 2}\right)$. Then by the Lipschitz assumption on $\mathcal{I<em _mathrm_m="\mathrm{m">{\mathrm{m}+\ell}$, we have $\left|\mathcal{I}</em>}+\ell}\left(d, \phi_{k}\right)-\mathcal{I<em 2="2">{\mathrm{m}+\ell}\left(d, \phi^{*}\right)\right|</em>\right)$. The rest of the proof now goes through as above.}=\mathcal{O}\left(K^{-1 / 2</p>
<h1>C Related work</h1>
<p>In this section, we provide a more detailed discussion of existing techniques for EIG estimation to complement Sec. 5 in the main text.
One established approach is to use a Laplace approximation to the posterior to make fast approximations of EIG [22, 25]</p>
<p>$$
\hat{\mu}<em n="1">{\text {laplace }}(d) \triangleq \frac{1}{N} \sum</em>, d\right)\right]]
$$}^{N}[H[p(\theta)]-H\left[q\left(\theta \mid y_{n</p>
<p>where $q\left(\theta \mid y_{n}, d\right)$ is a Laplace approximation to $p\left(\theta \mid y_{n}, d\right)$ that is computed once for each $y_{n} \sim$ $p(y \mid d)$.
Kleinegesse and Gutmann [18] recently suggested an implicit likelihood approach that directly approximates the ratio $r(d, \theta, y)=p(y \mid \theta, d) / p(y \mid d)$ using samples from $p(y \mid \theta, d)$ and $p(y \mid d)$ and the Likelihood-Free Inference by Ratio Estimation (LFIRE) method suggested by [41], which is itself based around logistic regression. This yields the estimator</p>
<p>$$
\hat{\mu}<em n="1">{\mathrm{LFIRE}}(d) \triangleq \frac{1}{N} \sum</em>\right)
$$}^{N} \log \hat{r}\left(d, \theta_{n}, y_{n</p>
<p>where $\log \hat{r}\left(d, \theta_{n}, y_{n}\right)$ is estimated separately for each pairs of samples $y_{n}, \theta_{n}$.
In principal one could also exploit the equivalence between EIG and MI and use other existing MI estimation methods, a number of which were recently summarized by [31]. Of particular note, Belghazi et al. [4] use a bound on MI in the context of generative adversarial neural network training that is based on the Donsker-Varadhan (DV) representation of the KL divergence [11]. Specifically, they introduce a parametrized approximation $T(y, \theta \mid d, \phi)$ to $\log \frac{p(y, \theta \mid d)}{p(\theta) p(y \mid d)}$ and then optimize the lower bound</p>
<p>$$
\mathcal{L}<em _mid="\mid" _theta="\theta" d_="d)" p_y_="p(y,">{\mathrm{DV}}(d) \triangleq \mathbb{E}</em>\right]\right)
$$}[T(y, \theta \mid d, \phi)]-\log \left(\mathbb{E}_{p(\theta) p(y \mid d)}\left[e^{T(y, \theta \mid d, \phi)</p>
<p>The estimator $\hat{\mu}<em _post="{post" _text="\text">{\mathrm{DV}}$ is then produced in an analogous manner to $\hat{\mu}</em>$.}</p>
<p>The EIG has been applied by a number of authors in specific contexts. For instance, the EIG has been used to formulate acquisition functions in Bayesian optimization [16]. More recently, Ma et al. [26] used an EIG-type objective to select features rather than designs for a partial VAE model. The EIG estimation exploits the model structure of the partial VAE. Additionally, and in contrast to this paper, approximations learned using the ELBO are used rather than approximations that are trained using variational objectives that are directly tied to EIG estimation. For further discussion on the implications of using the ELBO (i.e. the reverse KL divergence) in EIG estimation settings, see Appendix G.</p>
<p>As mentioned previously, mutual information bounds are of interest in traditional signal processing [3] and of increasing interest in the deep learning community [31]-although to the best of our knowledge they have not been applied to BOED before. Interestingly, it is lower bounds that are of primary importance in the deep learning setting because of the interplay between MI estimation and the subsequent gradient-based optimization over parameters. This is in contrast to this work, in which we maximize EIG over designs using Bayesian optimization-allowing the use of estimators such as $\hat{\mu}_{\mathrm{m}+\ell}$ that are not, in expectation, bounds.</p>
<h1>D Experiment details</h1>
<p>Computing All experiments were run on a machine with 32818560 kB memory, $8 \operatorname{Intel}(\mathrm{R})$ Core(TM) i7-6700 CPU @ 3.40 GHz processors, running Fedora 28, Python 3.6.8, Pytorch 1.1.0. To reproduce the results presented in the paper, see https://github.com/ae-foster/pyro/tree/vboed-reproduce. The methods in this paper form part of Pyro's OED support, the documentation for which is provided at http://docs.pyro.ai/en/stable/contrib.oed.html.</p>
<h2>D. 1 EIG estimation accuracy</h2>
<p>A/B test We consider a classical A/B test, commonly used in marketing and design applications. Here the experiment design is the choice of group sizes: $n$ participants are split between groups A and B of size $n_{A}$ and $n-n_{A}$, respectively. For each participant we measure a continuous response $y$. We consider a linear data analysis model</p>
<p>$$
\theta \sim N\left(0, \Sigma_{\theta}\right) \quad y \mid \theta, d \sim N\left(X_{d} \theta, I\right)
$$</p>
<p>where $X_{d}$ is the $n \times 2$ design matrix with $(10)$ for the first $n_{A}$ rows and $(01)$ for the remainder.
In this example we set the number of participants to be $n=10$ with 11 designs $\left(n_{A}=0, \ldots, 10\right)$ and the prior covariance matrix to be</p>
<p>$$
\Sigma_{\theta}=\left(\begin{array}{cc}
10^{2} &amp; 0 \
0 &amp; 1.82^{2}
\end{array}\right)
$$</p>
<p>We chose families of variational distributions that include the true posterior (or true marginal). For the amortised posterior, we set $\phi=\left(A, \Sigma_{\mathrm{p}}\right)$ with $\phi$ trained separately for each $d$ and let</p>
<p>$$
q_{p}(\theta \mid y, d, \phi) \sim N\left(A y, \Sigma_{\mathrm{p}}\right)
$$</p>
<p>where $A$ is a $10 \times 2$ matrix and $\Sigma_{\mathrm{p}}$ is positive definite. For the marginal, we simply take $\phi=\left(\mu_{\mathrm{m}}, \Sigma_{\mathrm{m}}\right)$ and</p>
<p>$$
q_{m}(y \mid d, \phi) \sim N\left(\mu_{\mathrm{m}}, \Sigma_{\mathrm{m}}\right)
$$</p>
<p>For NMC and Laplace, no variational families need to be specified.
For LFIRE, we used a parametrization $\phi=(b, \delta, \Lambda)$ and used the ratio estimate</p>
<p>$$
\log \hat{r}(y \mid \theta, d, \phi)=b-(y-\delta)^{T} \Lambda(y-\delta)
$$</p>
<p>where $\Lambda$ is positive definite. This form was chosen to mimic the approximation made by the posterior method, and so reduce the effect of architecture on performance.
For DV, we used a similar critic, namely we set $\phi=(A, \Lambda)$ and</p>
<p>$$
T(y, \theta \mid d, \phi)=-(\theta-A y)^{T} \Lambda(\theta-A y)
$$</p>
<p>where $\Lambda$ is positive definite.
The ground truth $\operatorname{EIG}(d)$ was computed analytically. In Table 2, each estimator was allowed 10 seconds computation.</p>
<p>Preference We consider searching for an agent's utility indifference point, using responses that are both censored and corrupted with non-uniform noise. Let $d \in \mathbb{R}$ and</p>
<p>$$
\begin{aligned}
\theta &amp; \sim N\left(\mu_{\theta}, \sigma_{\theta}^{2}\right) \
\eta \mid \theta, d &amp; \sim N\left(d-\theta, \sigma_{\eta}^{2}(1+|d|)^{2}\right) \
y &amp; =f(\eta)
\end{aligned}
$$</p>
<p>where</p>
<p>$$
\begin{aligned}
f: \mathbb{R} &amp; \rightarrow[\epsilon, 1-\epsilon] \
x &amp; \mapsto\left{\begin{array}{ll}
\epsilon &amp; \text { if } x \leq \operatorname{logit}(\epsilon) \
1-\epsilon &amp; \text { if } x \geq \operatorname{logit}(1-\epsilon) \
\frac{1}{1-e^{-\epsilon}} &amp; \text { otherwise }
\end{array}\right.
\end{aligned}
$$</p>
<p>and $\operatorname{logit}(p)=\log p-\log (1-p)$.
For this example we set $\mu_{\theta}=-20, \sigma_{\theta}=20$ and $\sigma_{\eta}=1$. We took designs on a linearly spaced grid in $[-80,80]$. For the variational family for the posterior, we took $\phi=\left(w, \sigma, \mu_{0}, \sigma_{0}, \mu_{1}, \sigma_{1}\right)$ and then</p>
<p>$$
\begin{aligned}
q_{p}(\theta \mid y, d, \phi) &amp; \sim N\left(\mu_{\mathrm{p}}, \sigma_{\mathrm{p}}^{2}\right) \quad \text { where } \quad \hat{\eta}=d-\operatorname{logit}(y) \
\mu_{\mathrm{p}} &amp; =w \hat{\eta}+(1-w) \mu_{\theta}+\mu_{0} \mathbf{1}<em 1="1">{{y=\epsilon}}+\mu</em>} \mathbf{1<em _mathrm_p="\mathrm{p">{{y=1-\epsilon}} \
\sigma</em>}}^{2} &amp; =\sigma^{2}+\sigma_{0}^{2} \mathbf{1<em 1="1">{{y=\epsilon}}+\sigma</em>
\end{aligned}
$$}^{2} \mathbf{1}_{{y=1-\epsilon}</p>
<p>For the marginal, we simply took $\phi=\left(\mu_{\mathrm{m}}, \sigma_{\mathrm{m}}\right)$ and</p>
<p>$$
q_{m}(y \mid d, \phi) \sim f # N\left(\mu_{\mathrm{m}}, \sigma_{\mathrm{m}}^{2}\right)
$$</p>
<p>where # denotes the push-forward measure. We note that this variational family contains the true marginal.</p>
<p>For LFIRE, we used the parametrization $\phi=\left(b, b_{0}, b_{1}, \delta, \lambda\right)$ with ratio estimate</p>
<p>$$
\begin{aligned}
\hat{\eta} &amp; =d-\operatorname{logit}(y) \
\log \hat{r}(y \mid \theta, d, \phi) &amp; =b-\lambda(\hat{\eta}-\delta)^{2}+b_{0} \mathbf{1}<em 1="1">{{y=\epsilon}}+b</em>
\end{aligned}
$$} \mathbf{1}_{{y=1-\epsilon}</p>
<p>For DV, the critic had parametrization $\phi=\left(b_{0}, b_{1}, \delta_{i}, \delta_{0}, \delta_{1}, \lambda_{i}, \lambda_{0}, \lambda_{1}\right)$ and we set</p>
<p>$$
\begin{aligned}
\hat{\eta} &amp; =d-\operatorname{logit}(y) \
\lambda &amp; =\lambda_{i}+\lambda_{0} \mathbf{1}<em 1="1">{{y=\epsilon}}+\lambda</em>} \mathbf{1<em i="i">{{y=1-\epsilon}} \
\delta &amp; =\delta</em>}+\delta_{0} \mathbf{1<em 1="1">{{y=\epsilon}}+\delta</em>} \mathbf{1<em 0="0">{{y=1-\epsilon}} \
T(y, \theta \mid d, \phi) &amp; =-\lambda(\hat{\eta}-\delta)^{2}+b</em>} \mathbf{1<em 1="1">{{y=\epsilon}}+b</em>
\end{aligned}
$$} \mathbf{1}_{{y=1-\epsilon}</p>
<p>Both these forms were chosen to minimize the differences between the functional forms used for different methods.
The ground truth $\operatorname{EIG}(d)$ was computed by running the marginal method, which is statistically consistent for this example because the true marginal is contained in the variational family, to convergence. The posterior and Laplace methods are both asymptotically biased (see Figure 5) and in this case both make the same (Gaussian) distributional assumption. The posterior method, however, produces better EIG estimates. For the benchmarking results in Table 2, 10 seconds computation was allowed.</p>
<p>Mixed Effects Regression We consider BOED for a mixed effects regression model with a nonlinear linking function that will also serve as the basis for the adaptive experiment we run in Sec. 6.3. This class of models is commonly used for analyzing data in a variety of scientific disciplines, where including nuisance variables can be a critical component of the model. In our adaptive experiment, the nuisance variables-i.e. the random effects-are used to account for the variability of individual human participants. Because of the presence of nuisance variables these implicit likelihood models represent a significant challenge for BOED.
We begin by describing the experiment set-up. Participants were presented with a question of the form seen in Figure 6 with the possible images shown in Figure 7. There were two image feature</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 5: EIG curves for the Preference example, with estimators run until variance is negligible and iterates of $\phi$ are stable to highlight the asymptotic bias.
dimensions with 3 levels each. A single image $i$ could therefore be represented as a $1 \times 6$ matrix $X_{i}$ with two entries 1 and the rest 0 . With the left image $i_{1}$ and right image $i_{2}$, the question was represented as $X_{d}=X_{i_{1}}-X_{i_{2}}$ encoding the assumed left-right symmetry. We then considered a model for the $i$ th participant</p>
<p>$$
\begin{aligned}
\theta &amp; \sim N\left(0, \Sigma_{\theta}\right) \
\sigma_{\psi}^{-2} &amp; \sim \Gamma\left(\alpha_{\psi}, \beta_{\psi}\right) \
\psi_{i} \mid \sigma_{\psi} &amp; \sim N\left(0, \sigma_{\psi}^{2} I_{6}\right) \
\sigma_{k}^{-2} &amp; \sim \Gamma\left(\alpha_{k}, \beta_{k}\right) \
\log k_{i} \mid \sigma_{k} &amp; \sim N\left(0, \sigma_{k}^{2}\right) \
\eta \mid \theta, \psi_{i}, k_{i}, d &amp; \sim N\left(k_{i}\left(X_{d} \theta+X_{d} \psi_{i}\right), \sigma_{\eta}^{2}\right) \
y &amp; =f(\eta)
\end{aligned}
$$</p>
<p>where $f$ is the censored sigmoid defined in (86) and $i \in{1, \ldots, 8}$ as there were 8 different participants.
The actual prior values of the parameters used were</p>
<p>$$
\begin{aligned}
&amp; \Sigma_{\theta}=100 I_{6} \quad \sigma_{\eta}=10 \
&amp; \alpha_{\psi}=\beta_{\psi}=\alpha_{k}=\beta_{k}=2
\end{aligned}
$$</p>
<p>We begin by discussing the variational families used to estimate the EIG.
For the posterior estimator of EIG, we took $\phi=\left(A, \Sigma_{\mathrm{p}}\right)$ and</p>
<p>$$
\begin{aligned}
\hat{\eta} &amp; =\operatorname{logit}(y) \
q_{p}(\theta \mid y, d, \phi) &amp; \sim N\left(A \hat{\eta}, \Sigma_{\mathrm{p}}\right)
\end{aligned}
$$</p>
<p>For the marginal + likelihood estimator, we set $\phi=\left(\mu_{\mathrm{m}}, \sigma_{\mathrm{m}}, \mu_{\ell}, \sigma_{\ell}, \xi\right)$ and took</p>
<p>$$
\begin{aligned}
q_{m}(y \mid d, \phi) &amp; \sim f # N\left(\mu_{\mathrm{m}}, \sigma_{\mathrm{m}}^{2}\right) \
q_{\ell}(y \mid \theta, d, \phi) &amp; \sim f # N\left(e^{\xi} X_{d} \theta+\mu_{\ell}, \sigma_{\ell}^{2}\right)
\end{aligned}
$$</p>
<p>For LFIRE, we used $\phi=(b, \delta, \lambda)$ and then took</p>
<p>$$
\begin{aligned}
\hat{\eta} &amp; =\operatorname{logit}(y) \
\log \hat{r}(y \mid \theta, d, \phi) &amp; =b-\lambda(\hat{\eta}-\delta)^{2}
\end{aligned}
$$</p>
<p>For DV, we used $\phi=(\lambda, \xi)$ and</p>
<p>$$
\begin{aligned}
\hat{\eta} &amp; =\operatorname{logit}(y) \
T(y, \theta \mid d, \phi) &amp; =-\lambda\left(\hat{\eta}-e^{\xi} X_{d} \theta\right)^{2}
\end{aligned}
$$</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ See Appendix A for a proof. A comparison with the reverse KL divergence can be found in Appendix G.
${ }^{4}$ In Appendix F, we describe a method using $q_{m}(y \mid d)$ as a control variate that can also eliminate this bias and lower the variance of NMC, requiring additional assumptions about the model and variational family.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>