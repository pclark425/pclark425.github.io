<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-474 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-474</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-474</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-269605155</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2405.03524v3.pdf" target="_blank">E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE</a></p>
                <p><strong>Paper Abstract:</strong> Advancements in Artificial Intelligence (AI) and deep neural networks have driven significant progress in vision and text processing. However, achieving human-like reasoning and interpretability in AI systems remains a substantial challenge. The Neural-Symbolic paradigm, which integrates neural networks with symbolic systems, presents a promising pathway toward more interpretable AI. Within this paradigm, Knowledge Graphs (KG) are crucial, offering a structured and dynamic method for representing knowledge through interconnected entities and relationships, typically as triples (subject, predicate, object). This paper explores recent advancements in neural-symbolic integration based on KG, examining how it supports integration in three categories: enhancing the reasoning and interpretability of neural networks with symbolic knowledge (Symbol for Neural), refining the completeness and accuracy of symbolic systems via neural network methodologies (Neural for Symbol), and facilitating their combined application in Hybrid Neural-Symbolic Integration. It highlights current trends and proposes future research directions in Neural-Symbolic AI.</p>
                <p><strong>Cost:</strong> 0.023</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e474.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e474.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CogQA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cognitive Graph QA</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid QA system that combines a pretrained transformer (BERT) as a fast perception module with a graph neural network operating over a dynamically constructed cognitive graph to perform multi-hop question answering across large document collections.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cognitive graph for multi-hop reading comprehension at scale.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CogQA (Cognitive Graph QA)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CogQA builds a dynamic 'cognitive graph' from entities and answer candidates extracted by a BERT-based reader (System 1). The graph is iteratively expanded (frontier nodes) and then analyzed by a GNN (System 2) to perform multi-hop logical reasoning; the two components form an iterative feedback loop where GNN outputs and graph structure guide further BERT extraction until termination criteria are met.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Dynamic cognitive graph / knowledge-graph-like structure (entities and edges representing relationships and candidate-answer links); graph is explicitly represented as nodes and edges (KG-like).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>BERT (transformer) for text/entity extraction and initial retrieval (System 1) and a Graph Neural Network (GNN) for logical reasoning over the cognitive graph (System 2).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular iterative pipeline with cyclic feedback: BERT extracts candidates and seeds the graph, the graph (symbolic structure) is updated and passed to a GNN for reasoning; GNN outputs inform whether to continue extraction. Integration is via explicit graph construction, message passing in GNN, and iterative addition of nodes/edges rather than a single end-to-end differentiable module.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables multi-hop reasoning across disparate documents, produces an explicit interpretable graph trace of reasoning (answer provenance), achieves iterative refinement leading to improved answer discovery that neither BERT-alone (lack of multi-hop symbolic chaining) nor GNN-alone (lack of robust textual extraction) can provide on document-scale QA.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Multi-hop question answering over large document collections / multi-document reading comprehension.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Iterative graph construction and explicit symbolic structure improve cross-document multi-hop generalization and adaptability to questions requiring chaining; robustness depends on quality of initial entity extraction and graph expansion policy.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High — cognitive graph provides explicit nodes and edges supporting interpretable reasoning traces and answer justification (graph-based provenance).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Relies on accurate entity/mention extraction by BERT; iterative expansion can be computationally expensive; stopping/termination criteria and error propagation from extraction to graph reasoning are potential failure modes; KG incompleteness or noisy extractions degrade performance.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Dual-process (System 1/System 2) cognitive analogy: fast perceptual module (BERT) coupled with a deliberative symbolic reasoning module (GNN over cognitive graph) performing complementary roles.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e474.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e474.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>JointGT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>JointGT (Graph-Text Joint Representation Learning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A joint graph-text representation learning model for KG-to-text generation that preserves graph structure inside Transformer layers and uses new pretraining tasks to align graph and text embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Jointgt: Graphtext joint representation learning for text generation from knowledge graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>JointGT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>JointGT injects structure-aware semantic aggregation modules into each Transformer encoder layer to preserve KG structure while encoding; it uses three pre-training objectives (graph-enhanced text reconstruction, text-enhanced graph reconstruction, and graph-text embedding alignment via optimal transport) to align symbolic graph representations with textual representations.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Input knowledge graph (KG) represented as structured triples/graphs (RDF-like structures); symbolic graph structure is explicitly modeled and preserved during encoding.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Transformer encoder/decoder architecture (textual Transformer) with structure-aware aggregation modules (neural).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Hybrid integration inside Transformer layers using structure-aware semantic aggregation; pretraining objectives explicitly align graph and text embeddings (including optimal transport to minimize embedding transport cost), enabling iterative alignment during training — effectively a joint representation learning (neural) with symbolic structure preserved and used in loss functions.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Improved graph-to-text fidelity and coherence, better graph-text alignment enabling generation that respects graph structure and relations; capability to reconstruct graph and text from each other showing bidirectional grounding between symbolic KG and neural language representations.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Knowledge-graph-to-text generation (KG-to-text generation tasks/benchmarks).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Joint pretraining across graph and text improves alignment and may generalize better to graph-to-text generation in domains where KG structure matters; explicit alignment reduces distributional mismatch between graph and text modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Improved traceability of which graph structures influenced generated text via structure-aware modules and alignment objectives; preserves symbolic structure making some outputs explainable in terms of original graph triples.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Scalability to very large KGs may be limited; requires careful design of pretraining tasks and computational resources for optimal transport alignment; potential sensitivity to noisy/incomplete KGs.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Graph-text alignment via optimal transport and structure-aware aggregation — principle that explicit symbolic structure plus neural representation alignment yields better grounded text generation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e474.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e474.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HGNN-EA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Heterogeneous GNN for Entity Alignment (HGNN-EA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An entity alignment approach that uses heterogeneous graph neural networks and an iterative fusion method to align entities across different knowledge graphs by jointly modeling entity and relation types.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Iterative fusion method based on heterogeneous graph neural network for entity alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>HGNN-EA</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>HGNN-EA models different node types (entities, relations) with a heterogeneous GNN and applies iterative fusion to refine semantic representations and alignment decisions; the system iteratively optimizes inter-graph information exchange using attention mechanisms to improve semantic and structural alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Two or more knowledge graphs (KGs) with explicit entities, relations and attributes that serve as symbolic declarative inputs (entity identity and relation structure).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Heterogeneous Graph Neural Network (HGNN) / Graph Attention Networks (GAT) used to compute and iteratively refine embeddings and alignment scores (neural).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Iterative fusion: symbolic KG structures are embedded and processed by HGNN; iterative rounds of attention-based message passing and fusion refine cross-graph alignment, mixing symbolic distance-based measures with learned neural embeddings and iterative optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Progressive refinement of alignment decisions through iterative fusion yields better capture of cross-graph semantics and structure than single-pass embedding approaches; improved robustness to heterogeneity in schema and relation types.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Entity alignment across heterogeneous knowledge graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Iterative refinement allows better transfer across graphs with differing distributions and relation sets; can handle heterogeneity by combining structural signals and learned embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Partial — distance-based alignment and attention coefficients give interpretable signals about which nodes/relations influenced alignment, but learned embeddings are less directly interpretable.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Potential scalability concerns for very large graphs; quality depends on available attribute/structural signals; noisy or sparse relations reduce alignment accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Iterative fusion principle: repeated interaction between symbolic structure and learned neural representations yields improved alignment via progressive refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e474.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e474.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KIG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge-Fusion-Based Iterative Graph Structure Learning Framework (KIG)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An iterative framework that fuses multiple knowledge views to build and refine graph structures for implicit sentiment recognition using GCNs and multi-view fusion.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Knowledge-fusion-based iterative graph structure learning framework for implicit sentiment identification.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>KIG</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>KIG constructs initial graph structures by fusing several knowledge sources (co-occurrence statistics, cosine similarity, syntactic dependency trees) and iteratively refines the adjacency matrix and node embeddings using GCNs in a loop that alternates structure learning and representation learning.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Initial symbolic/knowledge-derived adjacency matrices from multiple sources (co-occurrence graphs, syntactic dependency graphs, semantic-similarity graphs) representing declarative structural priors.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Graph Convolutional Networks (GCNs) and iterative neural updates to node embeddings and adjacency weights.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Iterative graph structure learning: multi-view fusion creates initial symbolic structures which are then refined by back-and-forth updates between learned GCN embeddings and adjacency structure adjustments (an alternating optimization loop rather than purely end-to-end single-shot training).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Learns improved graph topology tailored to task (implicit sentiment) that neither fixed symbolic graphs nor pure GCNs on single-view graphs achieve; more expressive node representations and better sentiment capture through multi-view fusion and iterative refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Implicit sentiment identification (text sentiment analysis).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Iterative refinement enables adaptation of graph topology to domain-specific signals, improving robustness to domain shifts compared to fixed-graph approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Some interpretability via the evolving adjacency matrices and the explicit multi-view sources; however, learned modifications may be less transparent.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Quality depends on initial multi-view knowledge; noisy or conflicting views can mislead structure learning; iterative process adds computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Multi-view fusion + iterative structure learning: declarative priors guide initialization while neural updates refine topology and features in a complementary loop.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e474.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e474.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>QA-GNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>QA-GNN (Question Answering with GNNs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A model that combines pretrained language models with graph neural networks by forming a joint graph of question context and KG entities and using relevance scoring and GNN-based joint reasoning to answer questions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Qa-gnn: Reasoning with language models and knowledge graphs for question answering.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>QA-GNN</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>QA-GNN encodes the QA context using a pretrained language model, constructs a joint graph combining context nodes and KG nodes, computes relevance scores for KG nodes w.r.t. the context, and performs iterative GNN reasoning (attention-weighted) over the joint graph to infer answers.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Knowledge Graph (KG) with explicit entities and relations serving as symbolic knowledge to ground answers.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Pretrained language model encoder (textual neural network) and a Graph Neural Network (GNN/GAT) for graph-based reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Early fusion into a joint graph: contextual text nodes and KG nodes are connected; relevance scoring (via neural encoders) weights KG nodes, and attention-based GNN updates propagate information across the combined structure allowing joint reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Joint reasoning leverages both contextual textual cues and explicit KG relations, enabling inference that requires combining unstructured text understanding with structured multi-hop KG paths; improved accuracy on KG-grounded QA compared to text-only or KG-only baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Question answering over knowledge graphs with textual context (KG-grounded QA).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Combining context and KG enables better handling of questions that require grounding and multi-hop inference; generalization depends on entity linking quality and KG coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Relevance scores and attention weights provide interpretable signals about which KG nodes and edges influenced the answer; joint graph structure enables provenance tracing.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Requires accurate entity linking; noisy KG nodes or missing relations reduce efficacy; computational cost for joint graph construction on large KGs.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Joint graph representation + attention-weighted message passing: combining distributional textual representations with symbolic KG structure for grounded reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e474.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e474.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PullNet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PullNet (Iterative Retrieval Network)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-domain QA architecture that iteratively expands a question-specific subgraph by 'pulling' relevant KB facts and textual documents guided by a GCN classifier, integrating KB and text for reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Pullnet: Open domain question answering with iterative retrieval on knowledge bases and text.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PullNet</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PullNet starts from entities directly related to a question, iteratively scores subgraph nodes with a GCN to select top-k expansion candidates, retrieves additional KB facts and documents ('pull' operation), augments the subgraph, and repeats until a sufficient subgraph for answering is built; final reasoning is performed over the assembled heterogeneous subgraph.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Knowledge base (KB / KG) facts represented as nodes and edges and textual documents indexed as nodes in a heterogeneous graph (symbolic factual structure).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Graph Convolutional Network (GCN) used to score nodes and guide iterative retrieval and classifier components for node selection; retrieval procedures are procedural/neural-guided.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Iterative retrieval loop where neural GCN scoring drives symbolic KB/text expansion; hybridization occurs via dynamic heterogeneous subgraph construction and neural-guided expansion rather than a static end-to-end differentiable merge.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Dynamically constructed, question-specific heterogeneous subgraphs that fuse symbolic KB facts and textual evidence enable efficient multi-hop reasoning without exhaustive traversal, improving answer coverage and precision relative to single-source approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Open-domain question answering combining knowledge bases and text.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Iterative retrieval adapts subgraph size and content per question, improving applicability to diverse queries and better handling long-range dependencies across KB and text.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Constructed subgraph and selected expansion steps provide interpretable retrieval and reasoning chains; node selection probabilities give insight into which facts were used.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Iterative retrieval cost; dependency on retrieval quality and selection thresholds; potential to miss relevant facts if early iterations omit key seeds.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Neural-guided iterative retrieval: procedural selection of symbolic facts via learned scoring to build reasoning subgraphs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e474.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e474.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GRAFT-Net</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GRAFT-Net (Graph of Facts Relationships and Texts Network)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A heterogeneous graph neural model that fuses KG facts and textual data into one graph and uses GCN-style updates with attention and directed propagation to perform QA over combined sources.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Open domain question answering using early fusion of knowledge bases and text.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GRAFT-Net</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GRAFT-Net constructs a heterogeneous graph containing entity nodes and sentence/document nodes, updates entity representations by combining previous entity state, question representation, neighbor messages (relation-specific transforms) and mentions, and uses attention and directed propagation (personalized PageRank-inspired) to focus reasoning along relevant paths.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Knowledge graph (KB) facts represented as structured edges and entities; symbolic graph structure is explicit in the heterogeneous graph.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Graph Convolutional Network (GCN) style neural propagation with relation-specific transforms and attention mechanisms; feed-forward networks for updates.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Early fusion into one heterogeneous graph where textual nodes and KG nodes co-exist and neural propagation (GCN with attention and directed propagation) operates jointly on the fused structure; attention coefficients are computed using neural encoders tied to the question representation.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Ability to perform joint reasoning that leverages both textual evidence and KB facts, improved handling of noisy single-source inputs by cross-validating facts/text, and targeted propagation to maintain focus on question-relevant graph regions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Open-domain question answering combining knowledge bases and text.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Early fusion helps generalize across sources by combining complementary evidence; directed propagation maintains robustness on long-hop reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Attention weights and directed propagation seeds provide interpretable routing of information and identification of salient facts/sentences.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Construction and computation over large heterogeneous graphs can be costly; sensitive to noisy text mentions and incomplete KG coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Heterogeneous graph fusion: unify symbolic KB and textual evidence in one graph and use neural propagation with attention/directed mechanisms to simulate focused symbolic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e474.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e474.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>K-BERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>K-BERT (Knowledge-enabled BERT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method to inject knowledge graph triples into BERT by constructing a knowledge-rich sentence tree, using soft-position embeddings and a visibility matrix to mitigate heterogeneous embedding space and knowledge noise.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>K-bert: Enabling language representation with knowledge graph.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>K-BERT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>K-BERT augments input text by injecting related KG triples into a sentence tree structure, then feeds this augmented tree into BERT while using soft positional embeddings to preserve token order and a visibility matrix to mask irrelevant injected tokens during self-attention.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Knowledge Graph (KG) triples injected as branches in a knowledge-rich sentence tree (symbolic facts and relations).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>BERT (Transformer) as the neural language model that processes augmented input.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Data-level injection of symbolic KG into textual input (knowledge-rich sentence tree) plus architectural modifications: soft-position embeddings and a visibility matrix control which tokens attend to which, enabling partial integration of KG facts into Transformer attention computations.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables BERT to leverage explicit KG facts during contextual encoding, improving tasks requiring factual knowledge while reducing disruption to original text order and limiting knowledge noise via visibility masking.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Knowledge-enhanced NLP tasks where external KG facts improve understanding (general NLP benchmarks requiring factual grounding).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Embedding KG facts into context improves factual generalization for tasks where KG coverage aligns with the target domain; mitigates heterogeneous embedding mismatch.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Visibility matrix gives explicit control over which injected knowledge tokens influence each text token, improving interpretability of knowledge usage.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Potential knowledge noise if irrelevant triples injected; tree expansion increases input length and computational cost; depends on quality of KG linking.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Injection + visibility control: unify symbolic KG content with Transformer input while controlling attention flow to address heterogeneous embedding space (HES) and knowledge noise (KN).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e474.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e474.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KnowBERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>KnowBERT (Knowledge-Enhanced BERT with KAR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A knowledge-enhanced BERT variant that links mention spans to KB entities and recontextualizes text representations using a Knowledge Attention and Recontextualization (KAR) module to integrate entity knowledge into Transformer representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>KnowBERT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>KnowBERT identifies mention spans in text, uses an entity linker to map mentions to KB entities, forms mention-span and entity representations, and applies the Knowledge Attention and Recontextualization (KAR) mechanism (including mention-span self-attention and recontextualization steps) to infuse entity knowledge back into contextual token representations.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>External knowledge base / knowledge graph entities linked to text mentions (symbolic entity representations).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>BERT-style transformer with additional KAR modules (neural attention and recontextualization networks).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular augmentation inside BERT: entity linking produces symbolic entity identifiers which are embedded and integrated via KAR using attention mechanisms to recontextualize token embeddings with entity information during forward passes (neural attention over symbolic entity embeddings).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Improved contextual representations grounded in factual KB entities, better entity-aware language understanding, and higher factual consistency in downstream tasks compared to vanilla BERT.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Knowledge-grounded NLP tasks requiring entity-aware representations (e.g., entity typing, question answering).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Entity grounding improves performance on tasks requiring external factual knowledge and helps transfer to domains with entity-centric reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Entity linking steps and KAR attention weights provide interpretable links between tokens and KB entities, enabling tracing of which entity knowledge influenced token representations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Requires reliable mention detection and entity linking; incorporation of incorrect entity links can harm representations; scalability with very large KBs is a concern.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Knowledge Attention and Recontextualization: explicit linking of symbolic entity knowledge to neural contextual embeddings using attention provides a principled integration mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e474.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e474.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepProbLog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeepProbLog (Neural Probabilistic Logic Programming)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid framework that embeds neural predicate models into a probabilistic logic programming language (ProbLog) enabling end-to-end differentiable learning that combines perception (neural nets) with symbolic logical reasoning and probabilistic inference.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Deepproblog: Neural probabilistic logic programming.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DeepProbLog</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>DeepProbLog extends the ProbLog probabilistic logic programming framework by allowing neural network predicates (perception modules) to provide probabilistic truth values to logical atoms; the combined system performs probabilistic logical inference and supports gradient-based learning across neural and symbolic components.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>ProbLog probabilistic logic program (rules, facts, logical clauses) providing symbolic and probabilistic logical structure.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural networks used as learnable predicate models mapping perceptual inputs to probabilities that plug into logical inference.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Differentiable probabilistic logical inference where neural predicate outputs are treated as probabilistic facts in the logic program; learning performed end-to-end by backpropagating losses through the probabilistic inference mechanism into neural predicate parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Combines robust perception from neural nets with exact or probabilistic symbolic reasoning, enabling interpretable logical proofs that involve learned perceptual components; supports learning rules grounded in perception and constrained by logic.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Tasks requiring perception + logical reasoning (e.g., visual question answering with relational logic, tasks requiring symbolic constraints over neural predictions).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Symbolic rules enable compositional generalization and out-of-distribution logical generalization that purely neural models struggle with; benefits depend on expressivity of the logic program and quality of neural predicates.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High interpretability via logical proofs and rule traces; final answers can be explained by logical derivations where neural predicates provide perceptual grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Scaling probabilistic logical inference to very large programs/KBs can be computationally expensive; differentiable inference adds overhead; requires careful specification of symbolic rules and interfaces for neural predicates.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Probabilistic logic programming combined with differentiable neural predicates: symbolic constraints guide learning while neural modules provide perceptual grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e474.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e474.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RNNLogic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RNNLogic (Learning Logic Rules for KG Reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A differentiable approach that uses recurrent neural networks to learn logical reasoning patterns and rules for reasoning over knowledge graphs, yielding a neuralized rule-learning mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Rnnlogic: Learning logic rules for reasoning on knowledge graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>RNNLogic</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>RNNLogic learns sequences/functions that represent logical rules for KG reasoning by using recurrent neural networks to model rule composition and scoring; the learned rules can be applied for reasoning over KGs in a differentiable manner.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Logical rules (learned/parameterized) that represent symbolic inference patterns over KG relations; target is to capture logical compositions like relation chains.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Recurrent Neural Networks (RNNs) / differentiable neural modules that generate and score candidate logical rules or paths.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Differentiable rule induction: neural sequence models parameterize and score symbolic rule templates (or relation compositions) and learning is performed end-to-end to discover high-scoring logical rules for KG reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Ability to discover compositional symbolic rules from data enabling interpretable multi-hop inference; provides a bridge between black-box neural sequence models and explicit symbolic rule candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Knowledge graph reasoning / link prediction and rule-guided inference on KGs.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Learned symbolic-like rules support compositional generalization and can generalize to unseen combinations of relations better than pure embedding methods in some settings.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Learned rules give interpretable reasoning chains compared to opaque neural embeddings; rules can be inspected and validated.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Quality of discovered rules depends on search space and training signals; may struggle with noisy KGs or when exact symbolic regularities are weak.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Differentiable rule learning: neural sequence models parameterize symbolic rule discovery enabling gradient-based discovery of logical inference patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Deepproblog: Neural probabilistic logic programming. <em>(Rating: 2)</em></li>
                <li>Qa-gnn: Reasoning with language models and knowledge graphs for question answering. <em>(Rating: 2)</em></li>
                <li>Cognitive graph for multi-hop reading comprehension at scale. <em>(Rating: 2)</em></li>
                <li>Pullnet: Open domain question answering with iterative retrieval on knowledge bases and text. <em>(Rating: 2)</em></li>
                <li>Jointgt: Graphtext joint representation learning for text generation from knowledge graphs. <em>(Rating: 2)</em></li>
                <li>Open domain question answering using early fusion of knowledge bases and text. <em>(Rating: 2)</em></li>
                <li>Rnnlogic: Learning logic rules for reasoning on knowledge graphs. <em>(Rating: 1)</em></li>
                <li>K-bert: Enabling language representation with knowledge graph. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-474",
    "paper_id": "paper-269605155",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "CogQA",
            "name_full": "Cognitive Graph QA",
            "brief_description": "A hybrid QA system that combines a pretrained transformer (BERT) as a fast perception module with a graph neural network operating over a dynamically constructed cognitive graph to perform multi-hop question answering across large document collections.",
            "citation_title": "Cognitive graph for multi-hop reading comprehension at scale.",
            "mention_or_use": "mention",
            "system_name": "CogQA (Cognitive Graph QA)",
            "system_description": "CogQA builds a dynamic 'cognitive graph' from entities and answer candidates extracted by a BERT-based reader (System 1). The graph is iteratively expanded (frontier nodes) and then analyzed by a GNN (System 2) to perform multi-hop logical reasoning; the two components form an iterative feedback loop where GNN outputs and graph structure guide further BERT extraction until termination criteria are met.",
            "declarative_component": "Dynamic cognitive graph / knowledge-graph-like structure (entities and edges representing relationships and candidate-answer links); graph is explicitly represented as nodes and edges (KG-like).",
            "imperative_component": "BERT (transformer) for text/entity extraction and initial retrieval (System 1) and a Graph Neural Network (GNN) for logical reasoning over the cognitive graph (System 2).",
            "integration_method": "Modular iterative pipeline with cyclic feedback: BERT extracts candidates and seeds the graph, the graph (symbolic structure) is updated and passed to a GNN for reasoning; GNN outputs inform whether to continue extraction. Integration is via explicit graph construction, message passing in GNN, and iterative addition of nodes/edges rather than a single end-to-end differentiable module.",
            "emergent_properties": "Enables multi-hop reasoning across disparate documents, produces an explicit interpretable graph trace of reasoning (answer provenance), achieves iterative refinement leading to improved answer discovery that neither BERT-alone (lack of multi-hop symbolic chaining) nor GNN-alone (lack of robust textual extraction) can provide on document-scale QA.",
            "task_or_benchmark": "Multi-hop question answering over large document collections / multi-document reading comprehension.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Iterative graph construction and explicit symbolic structure improve cross-document multi-hop generalization and adaptability to questions requiring chaining; robustness depends on quality of initial entity extraction and graph expansion policy.",
            "interpretability_properties": "High — cognitive graph provides explicit nodes and edges supporting interpretable reasoning traces and answer justification (graph-based provenance).",
            "limitations_or_failures": "Relies on accurate entity/mention extraction by BERT; iterative expansion can be computationally expensive; stopping/termination criteria and error propagation from extraction to graph reasoning are potential failure modes; KG incompleteness or noisy extractions degrade performance.",
            "theoretical_framework": "Dual-process (System 1/System 2) cognitive analogy: fast perceptual module (BERT) coupled with a deliberative symbolic reasoning module (GNN over cognitive graph) performing complementary roles.",
            "uuid": "e474.0",
            "source_info": {
                "paper_title": "E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "JointGT",
            "name_full": "JointGT (Graph-Text Joint Representation Learning)",
            "brief_description": "A joint graph-text representation learning model for KG-to-text generation that preserves graph structure inside Transformer layers and uses new pretraining tasks to align graph and text embeddings.",
            "citation_title": "Jointgt: Graphtext joint representation learning for text generation from knowledge graphs.",
            "mention_or_use": "mention",
            "system_name": "JointGT",
            "system_description": "JointGT injects structure-aware semantic aggregation modules into each Transformer encoder layer to preserve KG structure while encoding; it uses three pre-training objectives (graph-enhanced text reconstruction, text-enhanced graph reconstruction, and graph-text embedding alignment via optimal transport) to align symbolic graph representations with textual representations.",
            "declarative_component": "Input knowledge graph (KG) represented as structured triples/graphs (RDF-like structures); symbolic graph structure is explicitly modeled and preserved during encoding.",
            "imperative_component": "Transformer encoder/decoder architecture (textual Transformer) with structure-aware aggregation modules (neural).",
            "integration_method": "Hybrid integration inside Transformer layers using structure-aware semantic aggregation; pretraining objectives explicitly align graph and text embeddings (including optimal transport to minimize embedding transport cost), enabling iterative alignment during training — effectively a joint representation learning (neural) with symbolic structure preserved and used in loss functions.",
            "emergent_properties": "Improved graph-to-text fidelity and coherence, better graph-text alignment enabling generation that respects graph structure and relations; capability to reconstruct graph and text from each other showing bidirectional grounding between symbolic KG and neural language representations.",
            "task_or_benchmark": "Knowledge-graph-to-text generation (KG-to-text generation tasks/benchmarks).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Joint pretraining across graph and text improves alignment and may generalize better to graph-to-text generation in domains where KG structure matters; explicit alignment reduces distributional mismatch between graph and text modalities.",
            "interpretability_properties": "Improved traceability of which graph structures influenced generated text via structure-aware modules and alignment objectives; preserves symbolic structure making some outputs explainable in terms of original graph triples.",
            "limitations_or_failures": "Scalability to very large KGs may be limited; requires careful design of pretraining tasks and computational resources for optimal transport alignment; potential sensitivity to noisy/incomplete KGs.",
            "theoretical_framework": "Graph-text alignment via optimal transport and structure-aware aggregation — principle that explicit symbolic structure plus neural representation alignment yields better grounded text generation.",
            "uuid": "e474.1",
            "source_info": {
                "paper_title": "E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "HGNN-EA",
            "name_full": "Heterogeneous GNN for Entity Alignment (HGNN-EA)",
            "brief_description": "An entity alignment approach that uses heterogeneous graph neural networks and an iterative fusion method to align entities across different knowledge graphs by jointly modeling entity and relation types.",
            "citation_title": "Iterative fusion method based on heterogeneous graph neural network for entity alignment.",
            "mention_or_use": "mention",
            "system_name": "HGNN-EA",
            "system_description": "HGNN-EA models different node types (entities, relations) with a heterogeneous GNN and applies iterative fusion to refine semantic representations and alignment decisions; the system iteratively optimizes inter-graph information exchange using attention mechanisms to improve semantic and structural alignment.",
            "declarative_component": "Two or more knowledge graphs (KGs) with explicit entities, relations and attributes that serve as symbolic declarative inputs (entity identity and relation structure).",
            "imperative_component": "Heterogeneous Graph Neural Network (HGNN) / Graph Attention Networks (GAT) used to compute and iteratively refine embeddings and alignment scores (neural).",
            "integration_method": "Iterative fusion: symbolic KG structures are embedded and processed by HGNN; iterative rounds of attention-based message passing and fusion refine cross-graph alignment, mixing symbolic distance-based measures with learned neural embeddings and iterative optimization.",
            "emergent_properties": "Progressive refinement of alignment decisions through iterative fusion yields better capture of cross-graph semantics and structure than single-pass embedding approaches; improved robustness to heterogeneity in schema and relation types.",
            "task_or_benchmark": "Entity alignment across heterogeneous knowledge graphs.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Iterative refinement allows better transfer across graphs with differing distributions and relation sets; can handle heterogeneity by combining structural signals and learned embeddings.",
            "interpretability_properties": "Partial — distance-based alignment and attention coefficients give interpretable signals about which nodes/relations influenced alignment, but learned embeddings are less directly interpretable.",
            "limitations_or_failures": "Potential scalability concerns for very large graphs; quality depends on available attribute/structural signals; noisy or sparse relations reduce alignment accuracy.",
            "theoretical_framework": "Iterative fusion principle: repeated interaction between symbolic structure and learned neural representations yields improved alignment via progressive refinement.",
            "uuid": "e474.2",
            "source_info": {
                "paper_title": "E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "KIG",
            "name_full": "Knowledge-Fusion-Based Iterative Graph Structure Learning Framework (KIG)",
            "brief_description": "An iterative framework that fuses multiple knowledge views to build and refine graph structures for implicit sentiment recognition using GCNs and multi-view fusion.",
            "citation_title": "Knowledge-fusion-based iterative graph structure learning framework for implicit sentiment identification.",
            "mention_or_use": "mention",
            "system_name": "KIG",
            "system_description": "KIG constructs initial graph structures by fusing several knowledge sources (co-occurrence statistics, cosine similarity, syntactic dependency trees) and iteratively refines the adjacency matrix and node embeddings using GCNs in a loop that alternates structure learning and representation learning.",
            "declarative_component": "Initial symbolic/knowledge-derived adjacency matrices from multiple sources (co-occurrence graphs, syntactic dependency graphs, semantic-similarity graphs) representing declarative structural priors.",
            "imperative_component": "Graph Convolutional Networks (GCNs) and iterative neural updates to node embeddings and adjacency weights.",
            "integration_method": "Iterative graph structure learning: multi-view fusion creates initial symbolic structures which are then refined by back-and-forth updates between learned GCN embeddings and adjacency structure adjustments (an alternating optimization loop rather than purely end-to-end single-shot training).",
            "emergent_properties": "Learns improved graph topology tailored to task (implicit sentiment) that neither fixed symbolic graphs nor pure GCNs on single-view graphs achieve; more expressive node representations and better sentiment capture through multi-view fusion and iterative refinement.",
            "task_or_benchmark": "Implicit sentiment identification (text sentiment analysis).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Iterative refinement enables adaptation of graph topology to domain-specific signals, improving robustness to domain shifts compared to fixed-graph approaches.",
            "interpretability_properties": "Some interpretability via the evolving adjacency matrices and the explicit multi-view sources; however, learned modifications may be less transparent.",
            "limitations_or_failures": "Quality depends on initial multi-view knowledge; noisy or conflicting views can mislead structure learning; iterative process adds computational cost.",
            "theoretical_framework": "Multi-view fusion + iterative structure learning: declarative priors guide initialization while neural updates refine topology and features in a complementary loop.",
            "uuid": "e474.3",
            "source_info": {
                "paper_title": "E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "QA-GNN",
            "name_full": "QA-GNN (Question Answering with GNNs)",
            "brief_description": "A model that combines pretrained language models with graph neural networks by forming a joint graph of question context and KG entities and using relevance scoring and GNN-based joint reasoning to answer questions.",
            "citation_title": "Qa-gnn: Reasoning with language models and knowledge graphs for question answering.",
            "mention_or_use": "mention",
            "system_name": "QA-GNN",
            "system_description": "QA-GNN encodes the QA context using a pretrained language model, constructs a joint graph combining context nodes and KG nodes, computes relevance scores for KG nodes w.r.t. the context, and performs iterative GNN reasoning (attention-weighted) over the joint graph to infer answers.",
            "declarative_component": "Knowledge Graph (KG) with explicit entities and relations serving as symbolic knowledge to ground answers.",
            "imperative_component": "Pretrained language model encoder (textual neural network) and a Graph Neural Network (GNN/GAT) for graph-based reasoning.",
            "integration_method": "Early fusion into a joint graph: contextual text nodes and KG nodes are connected; relevance scoring (via neural encoders) weights KG nodes, and attention-based GNN updates propagate information across the combined structure allowing joint reasoning.",
            "emergent_properties": "Joint reasoning leverages both contextual textual cues and explicit KG relations, enabling inference that requires combining unstructured text understanding with structured multi-hop KG paths; improved accuracy on KG-grounded QA compared to text-only or KG-only baselines.",
            "task_or_benchmark": "Question answering over knowledge graphs with textual context (KG-grounded QA).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Combining context and KG enables better handling of questions that require grounding and multi-hop inference; generalization depends on entity linking quality and KG coverage.",
            "interpretability_properties": "Relevance scores and attention weights provide interpretable signals about which KG nodes and edges influenced the answer; joint graph structure enables provenance tracing.",
            "limitations_or_failures": "Requires accurate entity linking; noisy KG nodes or missing relations reduce efficacy; computational cost for joint graph construction on large KGs.",
            "theoretical_framework": "Joint graph representation + attention-weighted message passing: combining distributional textual representations with symbolic KG structure for grounded reasoning.",
            "uuid": "e474.4",
            "source_info": {
                "paper_title": "E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "PullNet",
            "name_full": "PullNet (Iterative Retrieval Network)",
            "brief_description": "An open-domain QA architecture that iteratively expands a question-specific subgraph by 'pulling' relevant KB facts and textual documents guided by a GCN classifier, integrating KB and text for reasoning.",
            "citation_title": "Pullnet: Open domain question answering with iterative retrieval on knowledge bases and text.",
            "mention_or_use": "mention",
            "system_name": "PullNet",
            "system_description": "PullNet starts from entities directly related to a question, iteratively scores subgraph nodes with a GCN to select top-k expansion candidates, retrieves additional KB facts and documents ('pull' operation), augments the subgraph, and repeats until a sufficient subgraph for answering is built; final reasoning is performed over the assembled heterogeneous subgraph.",
            "declarative_component": "Knowledge base (KB / KG) facts represented as nodes and edges and textual documents indexed as nodes in a heterogeneous graph (symbolic factual structure).",
            "imperative_component": "Graph Convolutional Network (GCN) used to score nodes and guide iterative retrieval and classifier components for node selection; retrieval procedures are procedural/neural-guided.",
            "integration_method": "Iterative retrieval loop where neural GCN scoring drives symbolic KB/text expansion; hybridization occurs via dynamic heterogeneous subgraph construction and neural-guided expansion rather than a static end-to-end differentiable merge.",
            "emergent_properties": "Dynamically constructed, question-specific heterogeneous subgraphs that fuse symbolic KB facts and textual evidence enable efficient multi-hop reasoning without exhaustive traversal, improving answer coverage and precision relative to single-source approaches.",
            "task_or_benchmark": "Open-domain question answering combining knowledge bases and text.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Iterative retrieval adapts subgraph size and content per question, improving applicability to diverse queries and better handling long-range dependencies across KB and text.",
            "interpretability_properties": "Constructed subgraph and selected expansion steps provide interpretable retrieval and reasoning chains; node selection probabilities give insight into which facts were used.",
            "limitations_or_failures": "Iterative retrieval cost; dependency on retrieval quality and selection thresholds; potential to miss relevant facts if early iterations omit key seeds.",
            "theoretical_framework": "Neural-guided iterative retrieval: procedural selection of symbolic facts via learned scoring to build reasoning subgraphs.",
            "uuid": "e474.5",
            "source_info": {
                "paper_title": "E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "GRAFT-Net",
            "name_full": "GRAFT-Net (Graph of Facts Relationships and Texts Network)",
            "brief_description": "A heterogeneous graph neural model that fuses KG facts and textual data into one graph and uses GCN-style updates with attention and directed propagation to perform QA over combined sources.",
            "citation_title": "Open domain question answering using early fusion of knowledge bases and text.",
            "mention_or_use": "mention",
            "system_name": "GRAFT-Net",
            "system_description": "GRAFT-Net constructs a heterogeneous graph containing entity nodes and sentence/document nodes, updates entity representations by combining previous entity state, question representation, neighbor messages (relation-specific transforms) and mentions, and uses attention and directed propagation (personalized PageRank-inspired) to focus reasoning along relevant paths.",
            "declarative_component": "Knowledge graph (KB) facts represented as structured edges and entities; symbolic graph structure is explicit in the heterogeneous graph.",
            "imperative_component": "Graph Convolutional Network (GCN) style neural propagation with relation-specific transforms and attention mechanisms; feed-forward networks for updates.",
            "integration_method": "Early fusion into one heterogeneous graph where textual nodes and KG nodes co-exist and neural propagation (GCN with attention and directed propagation) operates jointly on the fused structure; attention coefficients are computed using neural encoders tied to the question representation.",
            "emergent_properties": "Ability to perform joint reasoning that leverages both textual evidence and KB facts, improved handling of noisy single-source inputs by cross-validating facts/text, and targeted propagation to maintain focus on question-relevant graph regions.",
            "task_or_benchmark": "Open-domain question answering combining knowledge bases and text.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Early fusion helps generalize across sources by combining complementary evidence; directed propagation maintains robustness on long-hop reasoning.",
            "interpretability_properties": "Attention weights and directed propagation seeds provide interpretable routing of information and identification of salient facts/sentences.",
            "limitations_or_failures": "Construction and computation over large heterogeneous graphs can be costly; sensitive to noisy text mentions and incomplete KG coverage.",
            "theoretical_framework": "Heterogeneous graph fusion: unify symbolic KB and textual evidence in one graph and use neural propagation with attention/directed mechanisms to simulate focused symbolic reasoning.",
            "uuid": "e474.6",
            "source_info": {
                "paper_title": "E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "K-BERT",
            "name_full": "K-BERT (Knowledge-enabled BERT)",
            "brief_description": "A method to inject knowledge graph triples into BERT by constructing a knowledge-rich sentence tree, using soft-position embeddings and a visibility matrix to mitigate heterogeneous embedding space and knowledge noise.",
            "citation_title": "K-bert: Enabling language representation with knowledge graph.",
            "mention_or_use": "mention",
            "system_name": "K-BERT",
            "system_description": "K-BERT augments input text by injecting related KG triples into a sentence tree structure, then feeds this augmented tree into BERT while using soft positional embeddings to preserve token order and a visibility matrix to mask irrelevant injected tokens during self-attention.",
            "declarative_component": "Knowledge Graph (KG) triples injected as branches in a knowledge-rich sentence tree (symbolic facts and relations).",
            "imperative_component": "BERT (Transformer) as the neural language model that processes augmented input.",
            "integration_method": "Data-level injection of symbolic KG into textual input (knowledge-rich sentence tree) plus architectural modifications: soft-position embeddings and a visibility matrix control which tokens attend to which, enabling partial integration of KG facts into Transformer attention computations.",
            "emergent_properties": "Enables BERT to leverage explicit KG facts during contextual encoding, improving tasks requiring factual knowledge while reducing disruption to original text order and limiting knowledge noise via visibility masking.",
            "task_or_benchmark": "Knowledge-enhanced NLP tasks where external KG facts improve understanding (general NLP benchmarks requiring factual grounding).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Embedding KG facts into context improves factual generalization for tasks where KG coverage aligns with the target domain; mitigates heterogeneous embedding mismatch.",
            "interpretability_properties": "Visibility matrix gives explicit control over which injected knowledge tokens influence each text token, improving interpretability of knowledge usage.",
            "limitations_or_failures": "Potential knowledge noise if irrelevant triples injected; tree expansion increases input length and computational cost; depends on quality of KG linking.",
            "theoretical_framework": "Injection + visibility control: unify symbolic KG content with Transformer input while controlling attention flow to address heterogeneous embedding space (HES) and knowledge noise (KN).",
            "uuid": "e474.7",
            "source_info": {
                "paper_title": "E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "KnowBERT",
            "name_full": "KnowBERT (Knowledge-Enhanced BERT with KAR)",
            "brief_description": "A knowledge-enhanced BERT variant that links mention spans to KB entities and recontextualizes text representations using a Knowledge Attention and Recontextualization (KAR) module to integrate entity knowledge into Transformer representations.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_name": "KnowBERT",
            "system_description": "KnowBERT identifies mention spans in text, uses an entity linker to map mentions to KB entities, forms mention-span and entity representations, and applies the Knowledge Attention and Recontextualization (KAR) mechanism (including mention-span self-attention and recontextualization steps) to infuse entity knowledge back into contextual token representations.",
            "declarative_component": "External knowledge base / knowledge graph entities linked to text mentions (symbolic entity representations).",
            "imperative_component": "BERT-style transformer with additional KAR modules (neural attention and recontextualization networks).",
            "integration_method": "Modular augmentation inside BERT: entity linking produces symbolic entity identifiers which are embedded and integrated via KAR using attention mechanisms to recontextualize token embeddings with entity information during forward passes (neural attention over symbolic entity embeddings).",
            "emergent_properties": "Improved contextual representations grounded in factual KB entities, better entity-aware language understanding, and higher factual consistency in downstream tasks compared to vanilla BERT.",
            "task_or_benchmark": "Knowledge-grounded NLP tasks requiring entity-aware representations (e.g., entity typing, question answering).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Entity grounding improves performance on tasks requiring external factual knowledge and helps transfer to domains with entity-centric reasoning.",
            "interpretability_properties": "Entity linking steps and KAR attention weights provide interpretable links between tokens and KB entities, enabling tracing of which entity knowledge influenced token representations.",
            "limitations_or_failures": "Requires reliable mention detection and entity linking; incorporation of incorrect entity links can harm representations; scalability with very large KBs is a concern.",
            "theoretical_framework": "Knowledge Attention and Recontextualization: explicit linking of symbolic entity knowledge to neural contextual embeddings using attention provides a principled integration mechanism.",
            "uuid": "e474.8",
            "source_info": {
                "paper_title": "E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "DeepProbLog",
            "name_full": "DeepProbLog (Neural Probabilistic Logic Programming)",
            "brief_description": "A hybrid framework that embeds neural predicate models into a probabilistic logic programming language (ProbLog) enabling end-to-end differentiable learning that combines perception (neural nets) with symbolic logical reasoning and probabilistic inference.",
            "citation_title": "Deepproblog: Neural probabilistic logic programming.",
            "mention_or_use": "mention",
            "system_name": "DeepProbLog",
            "system_description": "DeepProbLog extends the ProbLog probabilistic logic programming framework by allowing neural network predicates (perception modules) to provide probabilistic truth values to logical atoms; the combined system performs probabilistic logical inference and supports gradient-based learning across neural and symbolic components.",
            "declarative_component": "ProbLog probabilistic logic program (rules, facts, logical clauses) providing symbolic and probabilistic logical structure.",
            "imperative_component": "Neural networks used as learnable predicate models mapping perceptual inputs to probabilities that plug into logical inference.",
            "integration_method": "Differentiable probabilistic logical inference where neural predicate outputs are treated as probabilistic facts in the logic program; learning performed end-to-end by backpropagating losses through the probabilistic inference mechanism into neural predicate parameters.",
            "emergent_properties": "Combines robust perception from neural nets with exact or probabilistic symbolic reasoning, enabling interpretable logical proofs that involve learned perceptual components; supports learning rules grounded in perception and constrained by logic.",
            "task_or_benchmark": "Tasks requiring perception + logical reasoning (e.g., visual question answering with relational logic, tasks requiring symbolic constraints over neural predictions).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Symbolic rules enable compositional generalization and out-of-distribution logical generalization that purely neural models struggle with; benefits depend on expressivity of the logic program and quality of neural predicates.",
            "interpretability_properties": "High interpretability via logical proofs and rule traces; final answers can be explained by logical derivations where neural predicates provide perceptual grounding.",
            "limitations_or_failures": "Scaling probabilistic logical inference to very large programs/KBs can be computationally expensive; differentiable inference adds overhead; requires careful specification of symbolic rules and interfaces for neural predicates.",
            "theoretical_framework": "Probabilistic logic programming combined with differentiable neural predicates: symbolic constraints guide learning while neural modules provide perceptual grounding.",
            "uuid": "e474.9",
            "source_info": {
                "paper_title": "E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "RNNLogic",
            "name_full": "RNNLogic (Learning Logic Rules for KG Reasoning)",
            "brief_description": "A differentiable approach that uses recurrent neural networks to learn logical reasoning patterns and rules for reasoning over knowledge graphs, yielding a neuralized rule-learning mechanism.",
            "citation_title": "Rnnlogic: Learning logic rules for reasoning on knowledge graphs.",
            "mention_or_use": "mention",
            "system_name": "RNNLogic",
            "system_description": "RNNLogic learns sequences/functions that represent logical rules for KG reasoning by using recurrent neural networks to model rule composition and scoring; the learned rules can be applied for reasoning over KGs in a differentiable manner.",
            "declarative_component": "Logical rules (learned/parameterized) that represent symbolic inference patterns over KG relations; target is to capture logical compositions like relation chains.",
            "imperative_component": "Recurrent Neural Networks (RNNs) / differentiable neural modules that generate and score candidate logical rules or paths.",
            "integration_method": "Differentiable rule induction: neural sequence models parameterize and score symbolic rule templates (or relation compositions) and learning is performed end-to-end to discover high-scoring logical rules for KG reasoning.",
            "emergent_properties": "Ability to discover compositional symbolic rules from data enabling interpretable multi-hop inference; provides a bridge between black-box neural sequence models and explicit symbolic rule candidates.",
            "task_or_benchmark": "Knowledge graph reasoning / link prediction and rule-guided inference on KGs.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Learned symbolic-like rules support compositional generalization and can generalize to unseen combinations of relations better than pure embedding methods in some settings.",
            "interpretability_properties": "Learned rules give interpretable reasoning chains compared to opaque neural embeddings; rules can be inspected and validated.",
            "limitations_or_failures": "Quality of discovered rules depends on search space and training signals; may struggle with noisy KGs or when exact symbolic regularities are weak.",
            "theoretical_framework": "Differentiable rule learning: neural sequence models parameterize symbolic rule discovery enabling gradient-based discovery of logical inference patterns.",
            "uuid": "e474.10",
            "source_info": {
                "paper_title": "E XPLORING KNOWLEDGE GRAPH - BASED NEURAL - SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE",
                "publication_date_yy_mm": "2024-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Deepproblog: Neural probabilistic logic programming.",
            "rating": 2,
            "sanitized_title": "deepproblog_neural_probabilistic_logic_programming"
        },
        {
            "paper_title": "Qa-gnn: Reasoning with language models and knowledge graphs for question answering.",
            "rating": 2,
            "sanitized_title": "qagnn_reasoning_with_language_models_and_knowledge_graphs_for_question_answering"
        },
        {
            "paper_title": "Cognitive graph for multi-hop reading comprehension at scale.",
            "rating": 2,
            "sanitized_title": "cognitive_graph_for_multihop_reading_comprehension_at_scale"
        },
        {
            "paper_title": "Pullnet: Open domain question answering with iterative retrieval on knowledge bases and text.",
            "rating": 2,
            "sanitized_title": "pullnet_open_domain_question_answering_with_iterative_retrieval_on_knowledge_bases_and_text"
        },
        {
            "paper_title": "Jointgt: Graphtext joint representation learning for text generation from knowledge graphs.",
            "rating": 2,
            "sanitized_title": "jointgt_graphtext_joint_representation_learning_for_text_generation_from_knowledge_graphs"
        },
        {
            "paper_title": "Open domain question answering using early fusion of knowledge bases and text.",
            "rating": 2,
            "sanitized_title": "open_domain_question_answering_using_early_fusion_of_knowledge_bases_and_text"
        },
        {
            "paper_title": "Rnnlogic: Learning logic rules for reasoning on knowledge graphs.",
            "rating": 1,
            "sanitized_title": "rnnlogic_learning_logic_rules_for_reasoning_on_knowledge_graphs"
        },
        {
            "paper_title": "K-bert: Enabling language representation with knowledge graph.",
            "rating": 1,
            "sanitized_title": "kbert_enabling_language_representation_with_knowledge_graph"
        }
    ],
    "cost": 0.0229645,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>EXPLORING KNOWLEDGE GRAPH-BASED NEURAL-SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE
29 May 2024</p>
<p>Shenzhe Zhu 
Shengxiang Sun </p>
<p>University of Toronto Toronto
Canada</p>
<p>University of Toronto Toronto
Canada</p>
<p>EXPLORING KNOWLEDGE GRAPH-BASED NEURAL-SYMBOLIC SYSTEM FROM APPLICATION PERSPECTIVE
29 May 202437A2ED6C93AFDE4C65108C618E450946arXiv:2405.03524v4[cs.AI]
Advancements in Artificial Intelligence (AI) and deep neural networks have driven significant progress in vision and text processing.However, achieving human-like reasoning and interpretability in AI systems remains a substantial challenge.The Neural-Symbolic paradigm, which integrates neural networks with symbolic systems, presents a promising pathway toward more interpretable AI.Within this paradigm, Knowledge Graphs (KG) are crucial, offering a structured and dynamic method for representing knowledge through interconnected entities and relationships, typically as triples (subject, predicate, object).This paper explores recent advancements in neural-symbolic integration based on KG, examining how it supports integration in three categories: enhancing the reasoning and interpretability of neural networks with symbolic knowledge (Symbol for Neural), refining the completeness and accuracy of symbolic systems via neural network methodologies (Neural for Symbol), and facilitating their combined application in Hybrid Neural-Symbolic Integration.It highlights current trends and proposes future research directions in Neural-Symbolic AI.</p>
<p>Introduction</p>
<p>With the rapid advancement of deep learning, particularly in deep neural networks (DNNs) within Artificial Intelligence (AI), we have observed the emergence of groundbreaking methods.These innovations have obtained significant achievements in fields such as vision and text processing.For instance, models like EfficientNet [1], ResNet [2], and Vision Transformer [3] have demonstrated exceptional performance in tasks like image classification, target detection, and image segmentation.Similarly, the NLP domain has seen substantial strides with deep neural network-based pretrained language models, such as GPT-4 [4], Llama 2 [5], and BERT [6], setting new benchmarks in text comprehension and generation.Despite these successes, the opacity of deep neural network models, often referred to as the "Black Box" problem [7,8,9,10,11,12], has obtained considerable attention.This problem arises when it becomes challenging to trace and elucidate the reasoning behind a model's decision-making.This opacity stems from the model's intricate internal structure, which involves millions of parameters that adjust automatically during training to optimally represent the input data, thereby complicating the understanding of the model's decision-making process.Addressing this issue is vital for fostering user trust, ensuring system fairness and security, and advancing AI technology's integrity.</p>
<p>Various scientists and researchers have proposed solutions to the black-box problem, extending into the realm of Explainable AI (XAI) [13,14].Approaches like SHAP [15] and LIME [16] focus on feature attribution, aiming to clarify each input feature's contribution to the model's decision-making.Meanwhile, CAM [17] and Grad-CAM [18] utilize visualization techniques to demystify the model's internal mechanisms, aiding human understanding of how models process and interpret data.Additionally, SENN [19] adopts an Explanatory Embedded Modeling approach, enhancing explainability by integrating it into the model design phase, thereby creating a more transparent and logical model.</p>
<p>The field of model interpretability offers a vast array of research avenues, with some scientists recently try to explore the concept of integrating neural and symbolic systems to address the black-box problem [20,21,22,23,24,25,26].</p>
<p>System</p>
<p>Core Yoshua Bengio, an ACM Turing Award laureate, highlighted in his 2019 NeurIPS presentation the necessity for deep learning to evolve from System 1 to System 2 thinking [27].System 1 refers to the intuitive, fast, and unconscious cognitive processes that current deep learning [28] technologies excel in.In contrast, System 2 represents the logical, deliberate, and conscious cognitive processes, a hallmark of Symbolic artificial intelligence in the expert system stage [29,30,31].This stage employs explicit symbols and rules to emulate human logical reasoning.This concept of transition underpins the concept of neural-symbolic systems, aiming to marry the pattern recognition prowess of deep learning models with the structured knowledge representation and logical reasoning capabilities of symbolic logic systems, thereby offering efficient abilities in learning and generalization, and clear logic.(As shown in Table 1 shows the strengths and drawbacks of the neural and symbolic systems)</p>
<p>Knowledge graph (KG) [32], as an important member of symbolic logic, plays a crucial role in neural-symbolic integration.They are built on triples (subject, predicate, object) and form a graph structure that encapsulates real-world entities, concepts, and their interrelations.In neural symbolic systems, the KG not only serves as a repository of information but also acts as a bridge connecting symbolic logic and neural networks.It enriches the contextual information of the neural network and improves the decision-making and interpretability of the model, for example, in NLP tasks to help the network understand the relationship between words and entities.Meanwhile, symbolic reasoning relies on the logical rules and facts provided by the KG, which play an important role in both model training and reasoning.This idea of combining KG and neural symbolic integration enables us to build smarter, more reliable, and transparent AI systems.</p>
<p>The rest of this paper is organized as follows: Section 2 introduces the major classifications of neural-symbolic systems.Section 3 delves into several representative methods and models of neural-symbolic systems that incorporate KG.Section 4 discusses the future trends in the field.Finally, Section 5 concludes the paper.</p>
<p>In this paper, the term "neural system" primarily denotes deep neural networks [28].On the other hand, the "symbolic system" largely pertains to symbolic knowledge encapsulated within KG and related KG reasoning techniques.Additionally, in certain contexts, it may also encompass methods associated with symbolic reasoning.</p>
<p>Categorization of neural-symbolic systems</p>
<p>Delving into the categorization of neural-symbolic systems unveils three primary interaction models [33,34]: Symbol for Neural, Neural for Symbol, and Hybrid Neural-Symbolic Integration.Each category represents a distinct approach to integrating neural and symbolic components (see Figure 1).In this section, we will explore the definitions, and frameworks within these three taxonomies and how KG can be integrated into these systems.</p>
<p>Neural for symbol</p>
<p>"Neural for Symbol", also known as "Learning for Reasoning", focuses on utilizing the learning capabilities of neural networks for the enhancement and problem solving of traditional symbolic reasoning.In this paradigm, neural networks usually enhance symbolic systems by acceleration [35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58].Typically, "acceleration" refers to the use of neural networks to improve the speed and efficiency of symbolic systems in knowledge reasoning and processing complex data.For instance, Neural networks can optimize the search path [59] in KG reasoning by leveraging their advanced analytical capabilities.Figure 2 illustrates the architecture of this integrated approach.</p>
<p>Symbolic System</p>
<p>Neural Network</p>
<p>Guide</p>
<p>Enhance</p>
<p>Hybrid Integration</p>
<p>Figure 1: This diagram depicts three neural-symbolic system interactions: the orange curve for "Symbol for Neural", the pink for "Neural for Symbol", and the grey bidirectional line for "Hybrid neural-symbolic integration", highlighting their distinct collaborative dynamics.</p>
<p>Knoledge Graphs Symbolic Reasoning</p>
<p>Neural Networks
Inference Accelerating</p>
<p>Symbol for neural</p>
<p>In this context, "Symbol for Neural" [60,61,62,63,64,65,66,67,68,69,70,71,20,72,73,74,75,76,77,78,79,80,51,52,81,55,54,82,83,79,78,84,85,83,86,78,87,84,85], also known as "Reasoning for Learning", leverages symbolic systems like KG to furnish a prior knowledge and a logical framework, thereby guiding and shaping neural networks' learning processes.Symbolic knowledge encoded in KG provides a rich source of structured information that enables neural networks to enhance their interpretability and decision-making capabilities.Moreover, KG serves not merely as passive repositories but as active participants, infusing neural networks with domain-specific rules and facts to bolster their learning efficiency.For instance, in developing algorithms for a recommendation system on an online education platform, a KG can categorize courses by content, difficulty, and progression, directing the neural network to tailor learning paths for users, thus optimizing learning outcomes.Figure 3 illustrates the architecture and rationale of this integrated approach.</p>
<p>Hybrid neural-symbolic integration</p>
<p>"Hybrid neural-symbolic integration" [88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104] shows a more dynamic way of interaction.In this approach, neural networks and symbolic reasoning complement each other without being subordinate, working together to enhance the comprehension and inference capabilities of the AI system.In this system, neural networks first process input data (e.g., images, text, etc.), extracting features and converting them into intermediate representations.These representations are then passed to a symbolic system, which utilizes this data for logical reasoning and possibly combines it with existing KG to make decisions or generate new knowledge.The results of the reasoning are not only used for direct decision-making output but are also fed back to the neural network  to guide its further learning and parameter tuning, thus optimizing the performance of the overall system.Through this iterative feedback mechanism, the hybrid system can continuously optimize itself, and its components, the neural network and the symbolic system, can learn and adapt from each other's processing results.This collaborative process grants the hybrid system resilience and adaptability, allowing it to efficiently manage complex tasks with accuracy and interpretability.Figure 4 illustrates the architecture of this integrated approach.</p>
<p>Image, Text... 3 Methods based on knowledge graph</p>
<p>Neural Network Symbolic System Output
Enhance Adjust
In this section, we take an in-depth look at the three taxonomies of neural symbols introduced in Section 2, focusing on specific methods for applications.We aim to describe these representative approaches for combining neural symbols with KG techniques, demonstrating progress in several directions.In addition, Table 2 summarizes the relevant features of these representative methods.</p>
<p>Neural for symbol</p>
<p>Deep learning plays a pivotal role in enhancing KG-related applications.In the field of neural for symbol systems, networks significantly accelerate the efficiency of KG's symbolic reasoning.This integration can be categorized into two main categories based on their specific applications: recommender systems enhanced by KG [51,52,57,58], Q&amp;A systems enhanced by KG insights [53,54,55,56] These categories reflect the different ways in which neural networks promote the development of KG in various uses, enabling the building of faster and high-efficient computational models.</p>
<p>KG-based recommender systems</p>
<p>In the field of exploring KG-enhanced recommender systems, research has been divided into three main directions: pathbased approaches [106,107,108], embedding-based [109,81,110] approaches and propagation-based approaches [52,51] that we will introduce below.</p>
<p>Traditional KG recommendation systems like NFM [111], Wide&amp;Deep [112], and xDeepFM [113] struggle with non-linear relationships and high-order interactions.The Knowledge Graph Convolutional Network (KGCN) [51], leveraging the Graph Convolutional Network (GCN) [114,115] framework, addresses these challenges by capturing multi-hop relationships between entities through stacked graph convolutional layers and a weighted neighbor aggregation</p>
<p>Model</p>
<p>Application Categories KGCN [51] Recommender systems</p>
<p>Neural for symbol KGAT [52] CGAT [57] HRAN [58] VRN [53] Q&amp;A systems GRAFT-Net [54] PullNet [55] QA-GNN [56] SEKG-ZSL [86] Zero-shot and few-shot learning Symbol for neural ML-ZSL [83] DGP [78] GFL [87] K-BERT [84] Knowledge-enhanced LMs KnowBERT [105] CogQA [101] Q&amp;A systems Hybrid integration JointGT [102] KG-to-text HGNN-EA [103] Entity alignment KIG [104] Sentiment identification mechanism.Also, this methodology enhances the understanding of complex entity relationships and, by utilizing GCN's neighborhood sampling and parallel computation, significantly improves computational efficiency.</p>
<p>Neighborhood aggregation in KGCN updates node representations by utilizing neighbor features and capturing high-order user interests within the KG.It involves calculating and normalizing user relevance scores to weight neighboring entities, allowing the model to consider both direct and multi-hop neighbors, thus broadening its influence field and capturing complex entity dependencies.This approach is depicted in a two-layer receptive field illustration(see Figure 5), showcasing the multi-hop neighbor consideration.By incrementally constructing the network and employing negative sampling and gradient descent, KGCN refines entity representations.Additionally, domain sampling(uniformly sampling a fixed-sized set from each entity's neighbors)in each layer speeds up neighborhood information aggregation and propagation, enhancing the model's ability to quickly learn intricate patterns of entity interactions and relationships with fewer computational resources.</p>
<p>Similarly, Knowledge Graph Attention Network (KGAT) [52] works on complex network situations between items due to shared attributes or characteristics that traditional methods ignore.By leveraging the adaptive focusing of relevant node property of graph attention network [116], KGAT deeply mines the high-order relationships in the KG, significantly enhancing the model's understanding of the interrelationships between items, thereby improving the accuracy and relevance of recommendations.In addition to the basic collaborative KG embedding and prediction layers, the structure of KGAT specifically introduces an attention embedding propagation layer(see Figure 6).This layer efficiently captures high-order relationships by integrating recursive embedding propagation and attention mechanisms.The inclusion of an attention mechanism allows the model to differentiate the importance of different neighboring nodes (see Attention Coefficient π(h, r, t) below).Such a mechanism allows the neural network to focus more on more important nodes, thus improving the efficiency and accuracy of the recommender system.Firstly, recursive embedding propagation allows the model to gradually update the embedding representation of a node by considering the embedding information of the node and its neighbors, implemented through the equation 1, where e N h represents the aggregated embedding of node h's first-order neighborhood, e t is the embedding of the neighbor node t, and π(h, r, t) is the contribution weight of node t to h, reflecting the strength of the relationship between nodes.
e N h = (h,r,t)∈N h π(h, r, t)e t(1)
Subsequently, for the aforementioned attention coefficient π(h, r, t), we derive it with normalization using Equation 2:
π(h, r, t) = exp (W r e t ) ⊤ tanh(W r e h + e r ) (h,r ′ ,t ′ )∈N h exp ((W r ′ e t ′ ) ⊤ tanh(W r ′ e h + e r ′ ))(2)
where W r is the transformation matrix for relation r, e h and e t represent the embedding vectors for the head and tail entities, respectively, and e r is the embedding vector for relation r.Here, tanh is employed as the activation function to help the model capture complex nonlinear relationships between entities while maintaining the output within a stable range of values.After these steps, we aggregate the information to update the entity's representation, and the model could recursively extend this information aggregation to more distant neighbors through high-order propagation, allowing each node's embedding to capture a broader context and accelerating the information transfer process throughout the KG.</p>
<p>In recent years, along with the development of graph attention network technologies such as KGAT, we have witnessed the rise of technologies such as Contextualized Graph Attention Network(CGAT) [57] and Heterogeneous Relation Attention Networks(HRAN) [58], which further extend the application of graph attention networks in the field of KG reasoning.CGAT greatly enhances the performance of recommender systems by fusing local and non-local contextual information in the project KG.It utilizes a user-specific graph attention mechanism to aggregate neighborhood information in the KG, while taking into account the user's personalized preferences, enabling the model to provide customized recommendation services based on different users' attention to neighboring entities.HRAN, on the other hand, is designed for Heterogeneous KG Embedding (KGE), which operates at multiple semantic levels and hierarchically aggregates neighborhood features, while fully taking into account the information diversity of the KG.By introducing an innovative framework, HRAN uses an attention mechanism to determine the importance of different relational paths, enabling selective aggregation of information features.</p>
<p>KG-based Q&amp;A systems</p>
<p>KGs play a central role in the construction of contemporary Q&amp;A systems.By integrating and utilizing KGs, Q&amp;A systems can go beyond simple fact retrieval to achieve advanced question processing that requires in-depth semantic understanding and reasoning, while at the same time, we can leverage the learning capability of neural symbols to enhance the inference speed of KGs, thus significantly improving the response quality and user interaction experience.Past KG-driven Q&amp;A systems [117,118,119] faced two major challenges: first, it is difficult to utilize the structural information of the KG for complex multi-hop logical reasoning; second, it is difficult to accurately locate the topic entities mentioned in the question in the presence of various noises.To address these problems, Y Zhang et al. introduce the Variational Reasoning Network (VRN) [53], a model grounded in a probabilistic modeling framework.It leverages a deep learning architecture that resembles a propagation mechanism, specifically tailored for logic reasoning over KG.Also, this model incorporates the REINFORCE algorithm, complemented by a variance reduction technique, to optimize its performance and reliability in inference tasks.Specifically, VRN uses the probabilistic framework to handle uncertainty, consisting of two modules.The first one is the " Module for topic entity recognition ".In this module, we use a neural network model f ent (•) : q → R d that maps the problem to a high-dimensional vector space, thus capturing the problem context to identify and parse unique topic entities, rather than relying solely on pre-annotation or exact matching.The next one is the "Module for logic reasoning over KG".In this module, VRN uses the inference graph embedding architecture to solve the multi-hop problem and simplifies multi-step traversal in large KGs.It creates subgraphs that encapsulate all possible paths by performing topological ordering within a maximum number of hops of subject entities.It then learns the nonlinear embedding of these paths in the vector space.From there, it performs efficient reasoning on complex queries without the need for exhaustive graph traversal.Overall, this architecture avoids blind searches in large KG by combining probabilistic models with neural networks to predict potential inference paths.</p>
<p>Q&amp;A models are easy to encounter limitations due to their reliance on data extraction from a single source [120,121,122].The Graph of Facts Relationships and Texts Network (GRAFT-Net) [54] released by H Sun et al. transcends these limitations by fusing two different sources of information: KG and textual data, thus improving Q&amp;A performance.GRAFT-Net innovatively employs GCN to analyze heterogeneous graphs -a complex structure that combines both sources, encompassing learning the representation of different node types (entities and sentences) and their interconnections, thus allowing the neural network to deepen its understanding and reasoning about the interrelationships present in the composite graph.Figure 7 refers to the architecture of VRN.</p>
<p>Updating the heterogeneous graph constitutes a crucial phase in GRAFT-Net's training, where the refinement of entity nodes is pivotal.This update process employs a feed-forward network.Specifically, the update for an entity v is computed by amalgamating its previous state h
(l−1) v
, the question's representation h (l−1) q , and the collective states from neighboring entities N r (v).These are weighted by attention coefficients α v ′ r and modified by relation-specific transformations ψ r [114].Additionally, the update incorporates aggregated states from the entity's mentions across the
h (l) v = FFN           h (l−1) v h (l−1) q r v ′ ∈Nr(v) α v ′ r ψ r (h (l−1) v ′ ) (d,p)∈M (v) H (l−1) d,p          (3)
Following the update rules, we continue into two integral techniques employed in this study: the attention mechanism and the directed propagation technique.These methods are crucial for sharpening the model's focus on graph regions pivotal to the query at hand.Through the attention mechanism, where weights:
α rv = softmax x T r h (l−1) q = exp(x T r h (l−1) q ) k∈Nr(v) exp(x T k h (l−1) q ) (4)
reflect the congruence between relation vectors and the question representation, the model's information flow is channeled along edges deemed relevant.Simultaneously, the directed propagation technique, inspired by personalized PageRank [123], ensures targeted dissemination of embeddings from question-related seed nodes across pertinent graph paths, thereby maintaining the model's concentrated attention on essential areas of the graph.</p>
<p>Following the development of Graft-Net, the introduction of PullNet [55] by H. Sun's team marks a significant advancement in the field of Q&amp;A system.PullNet improves upon Graft-Net by introducing an iterative retrieval process.Instead of using fixed heuristics to construct a question-specific subgraph as in Graft-Net, PullNet employs a GCN to dynamically identify and expand relevant nodes in the subgraph.This method allows PullNet to efficiently gather pertinent information from both KBs and textual data, ensuring that the retrieved subgraph is comprehensive, and containing all the necessary information.Specifically, this iterative process begins with a basic subgraph containing only entities directly related to the problem.Subsequently, through a series of iterative steps, the system gradually expands this subgraph.In each iteration, PullNet uses GCN to assess the importance of each node in the subgraph and selects the k nodes most likely to help answer the question for expansion.This selection is based on the probability scores of each node, which are computed by the classification operation.For each selected node, PullNet performs a "pull" operation to retrieve new information related to these nodes, including facts from the knowledge base and documents from the corpus.The retrieved new information is then added to the subgraph, including not only the new nodes but also the edges connecting them.</p>
<p>With the rapid growth of pre-trained language models, many researchers have explored integrating them with KG for QA systems like QA-GNN [56].This model merges pre-trained language models and graph neural networks(GNN) [124] to enhance understanding of question-answering contexts and utilize KG effectively.Initially, QA-GNN interprets the context using a pre-trained model, then forms a joint graph with the KG.It assesses node relevance within the KG to the QA context using a scoring mechanism.Finally, the model applies GNNs and relevance scores for reasoning on the joint graph to predict answers.</p>
<p>The core innovations of QA-GNN are twofold.First, relevance scoring assesses the importance of each KG node in relation to the QA context(see Figure 9).This scoring informs the attention mechanism within the graph neural network, enhancing node representation updates.For example, with a QA context node z and a KG node v, the relevance score ρ v is computed using
ρ v = f head (f enc ([text(z); text(v)]))(5)
, where f enc is the encoder extracting text features and f head predicts the relevance score of node v to context z.Second is joint reasoning, where after forming the joint graph, the model uses a graph neural network with an attention mechanism to update node representations, iteratively updating the representations of the context and KG, thereby enabling reasoning.In this process, the graph attention network (GAT) [116] dynamically adjusts the weights of information transfer between nodes so that each node can update its own information based on its relevance score with neighboring nodes.Conclusion: Recommender systems and Q&amp;A systems, as the core applications combining KGs and neural networks, demonstrate a consensus on the choice of network models to utilize.First, these systems commonly adopt GNNs as their foundation, as they can resolve complex entity relationships and topological information directly on graph structures, providing a clear framework for efficiently processing KG data.For example, GCN-based [115] models such as KGCN [51] perform convolutional operations on the graph to deeply learn the interactions between nodes and highlight the learning of local connections.And GAT-based[116] models, such as KGAT [52] and QA-GNN [56], introduce the attention mechanism to improve the judgment of the importance of neighbors and achieve a detailed node representation.Second, multi-hop inference is a core technique in neural network-based KG reasoning, which plays an indispensable role in almost all KG applications.By performing multi-step logical reasoning in the KG, this approach can explore and reveal complex, multi-level relationships between data.In recommender systems, multi-hop reasoning helps the system to deeply understand the user's preferences and needs to achieve personalized recommendations, while in Q&amp;A systems, it enables the system to handle more complex queries and provide more accurate and insightful answers.Overall, all these models utilize the information and hierarchical relationships of graph structures to learn the representation of complex entities and relationships.Whether it is local structure capture in GCN, differential attention in GAT, or deep mining in multi-hop reasoning, they all demonstrate their ability to deal with complex and deep information, demonstrating their efficacy in intelligent applications.</p>
<p>Symbol for neural</p>
<p>The reasoning ability of the KG can be accelerated by neural networks, and at the same time, it can provide guidance and constraints for the learning process of neural networks through its rich structured information.This enhancement is reflected in the field of "symbol for neural", especially in two major application directions: KG-driven zero-shot and few-shot learning [83,86,78,87], and knowledge-enhanced pre-trained language model (LM) [84,85].These applications demonstrate how KG-based symbol grounding2 can uniquely enhance the functionality of neural networks, making network models more robust and interpretable.</p>
<p>KG-driven zero-shot and few-shot learning</p>
<p>Knowledge graph-based Zero-Shot Learning (ZSL) models [127,128,129] perform well in addressing application problems in the visual field, especially in image recognition and classification.These models can recognize categories that were unseen during training by introducing additional knowledge (e.g., relationships between entities), which enhances the generalization ability of the model.</p>
<p>The Zero-shot Learning via Semantic Embeddings and Knowledge Graphs(SEKG-ZSL) [86], a cutting-edge zero-shot learning framework for image classification, skillfully integrates semantic embeddings with KG, using them as inputs to GCN to train classifiers that recognize unseen categories.In this model, we utilize pre-trained text models (e.g., GloVe [130] or word2vec [131]) to extract semantic embedding vector representations of different categories in a high-dimensional space that capture the semantic properties of the corresponding categories.Meanwhile, the KG depicts the associations between categories graphically to aid model comprehension.In the graph structure, nodes represent different categories, and edges reveal the semantic relationships between categories.Then, the model processes these two types of knowledge inputs through the GCN to transfer and combine the information between different categories with the help of the associative relationships in the graph, thus developing a classifier that can generalize to unseen categories.In particular, it is noted that the KG sets constraints for the network's learning by utilizing the relationships between categories to guide the information transfer when training the classifier, and enhances its ability to learn and predict the unseen categories.Simply speaking, the KG plays the role of a map in the model, guiding the GCN to learn and infer along the correct semantic path.Overall, the SEKG-ZSL framework can effectively combine the semantic and visual information of categories to improve the accuracy and generalization ability of zero-sample learning.Typically, SEKG-ZSL performs well in dealing with zero-sample learning with single instance single label, but real-world scenarios such as image annotation usually involve a single image with multiple labels [132,133,134,135].For this reason, the Multi-label Zero-shot Learning(ML-ZSL) [83] method proposed by Lee C.W. et al. was developed to adapt to such problems.ML-ZSL achieves accurate prediction of unseen category labels by integrating structured KGs and effectively capturing the correlations among different labels.Its core lies in the information propagation mechanism, which is based on two key aspects: first, we need to construct a structured KG with nodes representing individual labels and update the node states through gated recurrent units (GRUs) [136] to simulate the information interactions and influences among labels and facilitate the propagation of information in the structured graph.Also, the updating process can be encapsulated by the following equation 6:
h (t) v = GRU Cell(u (t) v , h (t−1) v )(6)
This equation updates the state h (t) v of node v at time step t by combining the information u (t) v from neighboring nodes and the node's previous state h (t−1) v via a GRU cell.This mechanism facilitates the propagation and updating of information throughout the graph.Second, the propagation matrix is learned to provide a strategy for the flow of information through the graph.This process determines the propagation weights through a relational function, where the weights are set based on the semantic word embedding of the labels.This approach ensures that the model can make effective inferences based on learned semantic relations even when faced with unseen labels.In summary, by combining structured KG propagation and propagation matrix learning, ML-ZSL not only finely regulates the information flow (Specific representations of knowledge-guided neural networks), but also significantly improves the prediction accuracy of unseen labels while maintaining the correct relationships between labels.</p>
<p>Methods based on GCN for zero-shot learning have shown great potential.However, a major challenge for these approaches is the knowledge dilution caused by excessive Laplacian smoothing [137] in multilayer GCN architectures, which makes the feature representations too similar and thus reduces the model's prediction performance for new categories.To address this problem, M Kampffmeyer et al. introduced the Dense Graph Propagation (DGP) [78] method, which effectively avoids excessive information smoothing by establishing direct connections between nodes that are far away from each other in the KG, while optimizing information propagation by using distance-based weights between nodes.In specific terms, the module consists of a two-stage training procedure: the DGP is first trained to predict the weights of the last layer of the CNN for known categories, and then these predicted weights are applied to the CNN and fine-tuned to fit the new classifier.This approach not only enhances the prediction ability for unseen categories but also maintains the strong performance for known categories.</p>
<p>In addition to the zero-shot learning we previously discussed, few-shot learning also focuses on how to enable models to learn and generalize quickly in scenarios with scarce data.Within this framework, the Graph Few-shot Learning(GFL) [87] model employs its unique strategies to implement knowledge transfer, which migrates knowledge from the auxiliary graph to the target graph [138,139], thus helping to improve semi-supervised node classification in graphs.To be specific, GFL focuses on two types of relational structures at the node level (local perspective) and the graph level (global perspective) to facilitate knowledge transfer.First, at the node level, we aim to learn the associative structure among nodes of the same class.For this purpose, we introduce the Prototype Graph Neural Network (PGNN)3 [140], which constructs the relational structure R k from the sample set S k of each class k to learn the prototype representation c k of each class, thereby capturing the global relationships among nodes within the same category.And, this relational structure is typically based on metrics like k-hop common neighbors or topological distances.Also, the principle of prototype computation can be understood through the following equation 7:
c k = Pool (PGNN ϕ (R k , f θ (S k )))(7)
Here, Pool is a pooling operation (such as max pooling or average pooling) used to obtain a single prototype vector from the output of PGNN, f θ (S k ) represents the feature representation of all nodes in category k processed through a function with parameters θ, and PGNN ϕ denotes the PGNN model characterized by the parameter ϕ.Secondly, at the graph level, our goal is to learn the global information of a specific graph through the Hierarchical Graph Representation Gate and utilize this information to enhance the learning effectiveness of the network at the node level.This involves capturing the structural features of the graph at different levels and aggregating these features to form a comprehensive representation of the graph, and then adjusting the parameters ϕ of the graph neural network using a gating mechanism, enabling the model to capture and utilize global structural information at the graph level.</p>
<p>Knowledge-enhanced pre-trained language models</p>
<p>Pre-trained language models(PLMs) based on knowledge enhancement improve the understanding and generation of text by incorporating external knowledge, such as KG.These integration methods utilize the structured information in KG to enable the language model to not only process complex text more logically, but also to accurately reference and reason about specialized knowledge, thus making the output more reliable.</p>
<p>In the field of Natural Language Processing(NLP), although the Bidirectional Encoder Representations from Transformers model (BERT) [6] performs well on many tasks, there are still challenges when dealing with complex tasks that require deep knowledge and understanding.For this reason, researchers have explored the integration of structured KGs into BERT, aiming to provide the necessary external knowledge to enhance its comprehension and reasoning capabilities.Knowledge-enabled BERT(K-BERT) [84] and knowledge enhanced BERT(KnowBERT) [105] are two advanced models for integrating KGs to enhance BERT, which incorporates enriched knowledge into BERT through different approaches, with the same goal but different core implementation strategies.On the other hand, the proposed K-BERT [84] aims to solve the two main problems faced by language representation models based on knowledge injection: Heterogeneous Embedding Space (HES) and Knowledge Noise (KN).Firstly, to deal with the HES problem, K-BERT constructs a knowledge-rich sentence tree by directly integrating the KG information into the text, which realizes a unified representation of text and KG information in the same vector space, and effectively mitigates the HES problem.Secondly, to cope with the KN problem, K-BERT introduces soft-position embedding and a visible matrix mechanism.Soft positional embedding enables the model to integrate the injected knowledge while maintaining the text order without destroying the original text structure.Then, the visibility matrix controls the "visibility" of words to ensure that only relevant knowledge is computed, reducing the disturbance of irrelevant knowledge and mitigating the KN problem effectively.The visible matrix M is defined by the equation 8:
M ij = 0 if w i ↔ w j −∞ otherwise(8)
Here, w i and w j represent tokens within the sentence, and w i ↔ w j denotes that w i and w j are within the same branch of the knowledge-rich sentence tree and therefore can "see" each other.If they are not in the same branch, the value of −∞ could effectively mask out (i.e., makes invisible) the token w j when computing attention for w i , ensuring that only contextually relevant knowledge influences the representation of each token.</p>
<p>Conclusion:</p>
<p>In the paradigm of neural for symbol, KG has provided neural network learning with a wealth of structured knowledge and deep semantic and contextual information, serving as important guidance during the learning process.Faced with the challenge of scarce samples, the structured information from KGs significantly enhances the neural network's learning capabilities in complex language tasks.For instance, models such as SEKG-ZSL [86] and GFL [87] effectively learn through semantic embeddings and graph structure reasoning, even in situations with extremely limited samples.Moreover, in handling natural language processing (NLP) tasks, KGs provide the models with rich contextual information and precise factual knowledge that are difficult to obtain from traditional pre-training.This information directly enhances the models' understanding of complex queries and improves their ability to handle terms and concepts specific to certain fields.Additionally, it ensures the factual and logical consistency of the generated text, thereby enhancing the model's interpretability.</p>
<p>Hybrid neural-symbolic integration</p>
<p>Compared to the two previously mentioned categories, our hybrid integration model focuses more on processing the functions of neural networks and symbolic systems in parallel, allowing them to operate independently without interfering with each other.Through specific mechanisms, these two systems can share information and results.Typically, we expect this parallel operation to promote and grow with each other, forming a cyclic enhancement learning model: the output of each system can become part of the input of the other system, thus driving the iterative progress of the whole system.In addition, this learning model is also expected to apply to a wide range of application tasks, including Q&amp;A systems [101], KG-to-text [102], entity alignment [103] and sentiment identification [104], etc.</p>
<p>In Section 1, we discussed the concepts of System 1 and System 2 [27] from cognitive science.Based on these ideas, Ding M and his team combined the capabilities of BERT (acting as System 1) and GNN (acting as System 2) to develop the Cognitive Graph QA(CogQA) [101] model.This model employs a cognitive graph(KG-like structure) to mimic human dual-process cognition, aiming to address the complex challenges encountered when performing multi-hop question answering across large-scale document sets.CogQA constructs a dynamic cognitive graph that links information dispersed across multiple documents and iteratively mines and verifies potential answers.Specifically, apart from initializing the graph (creating starting nodes based on entities mentioned in the questions and marking them as "frontier nodes") and determining the termination conditions, each iteration of building the cognitive graph primarily involves three steps: First, relevant information, including potential answers and related entities, is extracted from the document set using BERT[6] (system 1); Second, based on the information provided by system 1, CogQA updates the cognitive graph by adding new nodes and edges, where new nodes include entities or answer candidates identified from the text, and edges represent logical relationships between entities.These new nodes are also marked as frontier nodes for use in the next iteration; Third, once the cognitive graph is updated, GNN(system 2) begins analyzing the logic and relationships between entities in depth and optimizing the structure of the cognitive graph.Importantly, after each iteration, CogQA assesses whether the cognitive graph is sufficiently comprehensive to answer the original question.If the information is deemed adequate, the model will predict the final answer based on the current cognitive graph.Otherwise, the model will continue iterating, further expanding, and refining the cognitive graph with each cycle until a satisfactory answer is found.The basic architecture and implementation of CogQA is shown in Figure 11 Ques Prev In the task of Knowledge Graph to Text Generation (KG-to-text) [142], existing models often ignore the structural information of the graph or lack pre-training tasks for accurately modeling graph-text alignment.To address these issues, a joint graph-text representation learning model called JointGT [102] is proposed.This model preserves the structure of the input graph by introducing structure-aware semantic aggregation modules in each Transformer layer of the encoder.In addition, the model designs three new pre-training tasks to explicitly enhance graph-text alignment, including graph-enhanced text reconstruction, text-enhanced graph reconstruction, and graph-text embedding alignment via optimal transport.It is worth noting that these pre-training tasks are performed iteratively to continuously optimize the performance of the model.In the graph-text embedding alignment task, it employs the optimal transport theory to minimize the cost between graph and text embedding, which is a typical iterative process.In this process, the model calculates the distance between the embedding vectors of the graph and the text and adjusts these embedding vectors by the optimal transport algorithm so that the transit cost is minimized.In this way, the model is better able to capture and learn the complex relationships between graphs and texts, thus generating more accurate and coherent texts.</p>
<p>Entity alignment is an important task in the field of KGs, aiming at identifying entities with the same or similar meanings in different KGs.Traditional approaches usually rely on extensive human involvement or simple embedding techniques, which may not be sufficient to capture the rich relationship and attribute information among entities.However, the HGNN-EA [103] model significantly improves the accuracy of entity alignment by employing Heterogeneous Graph Neural Networks (HGNNs) [143] to process entity and relationship data in the KG and using iterative fusion methods to enhance model training.In this model, different types of nodes (entities and relations) are modeled simultaneously and their semantic representations are strengthened through dynamic interactions during iterations.Each iteration optimizes the information exchange between nodes through Graph Attention Network (GAT) [125] to represent their semantic and structural associations more comprehensively.In addition, HGNN-EA applies a distance-based approach in entity alignment, which can accurately measure the semantic distances between entities in different KGs, and effectively identify pairs of entities with the same or similar meanings.</p>
<p>Implicit sentiment recognition, a common task in text analysis of the NLP field, faces challenges due to the lack of structural information and noise in predefined graph structures.To address these challenges, the Knowledge-Fusion-Based Iterative Graph Structure Learning Framework (KIG) [104] has been introduced.This innovative method aims to construct rich initial graph structures by integrating knowledge from multiple perspectives-including co-occurrence statistics, cosine similarity, and syntactic dependency trees-to more comprehensively capture the subtle expressions of sentiment within texts.The core mechanism of KIG lies in its iterative evolutionary graph learning process.In each iteration, KIG evaluates the effectiveness of the current graph structure and updates it based on the information learned, thereby achieving optimal node representations and graph topology.During the iterative process, KIG employs a multi-view fusion strategy, integrating graph structural perspectives from different information sources to form a comprehensive and expressive graph representation.For example, it considers both semantic similarity and syntactic structure to capture the textual sentiment tendencies more thoroughly.Moreover, each iteration involves refining the graph structure by adjusting the adjacency matrix and utilizing GCNs [114,115] to extract and merge node features, subsequently updating the node embedding.</p>
<p>Conclusion:</p>
<p>The four described models of Hybrid neural-symbolic integration, although applied in different domains, share a key feature -iterative learning mechanisms.Iterative learning significantly enhances the models' reasoning capabilities and data representation through a continuous cyclic process.For instance, in the HGNN-EA [103] and CogQA [101], iterative methods are used to progressively optimize the representation of nodes within KGs, thereby more accurately reflecting the complex relationships and attributes between entities.This iterative process not only improves the models' understanding of data structures but also refines the application of symbolic logic with each iteration, thereby increasing the accuracy and efficiency of problem-solving.Iterative learning also enhances the models' adaptability to new situations and their explanatory power, making them more flexible in practical applications.Through continual iterative updates, the models accumulate learning experiences, optimize their decision-making processes, and exhibit greater robustness and adaptability when confronted with unknown data or complex scenarios.</p>
<p>Future Trends &amp; Direction 4.1 Multimodal and multidomain learning</p>
<p>Multimodal and multidomain learning represents a significant trend in the field of deep learning [144,145,146,147,148], offering unprecedented opportunities but also presenting considerable challenges, particularly in terms of information fusion and domain adaptation.The challenge of information fusion primarily involves effectively integrating data from diverse modalities, such as text, images, and audio, which differ significantly in their forms and processing methods.By utilizing KG as a unified semantic framework, we can better align and integrate data from these varied modalities.The structured information within the KG provides essential context, facilitating the fusion of information from different sources, and thereby enhancing the overall understanding capabilities of the model.On the other hand, the issue of domain adaptation focuses on enabling models to operate across different domains while maintaining performance amidst variations in data distribution and characteristics across these domains.Employing a KG as a bridge for cross-domain data processing, and incorporating common knowledge and rules across domains, can significantly enhance the adaptability and generalization capabilities of models in new scenarios.</p>
<p>Reasoning efficiency</p>
<p>Improving reasoning efficiency is one of the challenges in achieving deep learning productization, especially in scenarios that require fast responses, such as mobile device applications, self-driving, and other real-time processing systems.These application scenarios typically require models to perform tasks quickly and accurately with limited computational resources.KGs may play a key role in this environment by providing neural network models with rich prior knowledge to optimize reasoning paths.More specifically, KGs can predefine the logical relationships and rules required during the inference process, allowing the model to directly perform some of the decisions and computations without the need for deep neural computation.The rules and known facts in the KG can be utilized for direct processing when performing reasoning tasks, thus reducing the reliance on data-driven reasoning.This approach reduces the amount of computation and also increases the speed of reasoning, making the model more efficient and practical in real applications.</p>
<p>Graph-integrated Transformer</p>
<p>Although graph neural networks (GNNs) [124] have demonstrated excellent capabilities in processing structured data, especially KGs, in practice, GNNs face challenges such as low computational efficiency, limited scalability, and lack of performance when dealing with large-scale datasets.The computational complexity of GNNs stems mainly from the sparseness and irregularity of graph data, which makes the optimization and acceleration of these models particularly difficult.Given these challenges, it is particularly promising to focus future research and applications on combining KGs with Transformer-based models [141], which, by their self-attentive mechanism, can efficiently process large-scale datasets and effectively capture long-distance dependencies, and especially excel in the processing of text and other continuous data streams.Specifically, by directly incorporating entities and relationships from the KG into the Transformer's self-attention mechanism, the knowledge-enhanced Transformer model can provide clear inference paths and logical proofs while maintaining efficient data processing.</p>
<p>Conclusion</p>
<p>In this paper, we explore how KG-based neural symbolic integration can be applied in three different categories.This research comprehensively demonstrates the potential of combining deep learning with KG reasoning, providing a theoretical foundation for the future development of more interpretable and efficient AI systems.The goal of this comprehensive approach is to bridge the gap between intuitive human reasoning and machine execution, thereby enhancing the utility and transparency of AI applications in multiple domains.</p>
<p>A Supplemental Material</p>
<p>A.1 Knowledge Graph</p>
<p>A knowledge graph(KG) is a structured representation of knowledge where entities, their attributes, and the relationships between them are organized into a graph-like structure.In mathematical terms, a KG can be represented as G = (V, E), where V represents the set of vertices or nodes corresponding to entities, and E represents the set of edges or relationships between these entities.Each relationship is often expressed as a triplet (subject, predicate, object), where the subject and object are entities and the predicate represents the relationship between them.Mathematically, this triplet can be denoted as (s, p, o).Each entity is associated with a set of properties or attributes, forming a vector space representation.Mathematically, this can be denoted as V i = {p 1 , p 2 , ..., p n }, where V i represents the ith entity and p 1 , p 2 , ..., p n represent its attributes.Relationships between entities are represented as directed edges connecting nodes in the graph.By leveraging graph theory and mathematical models, KGs enable the organization, retrieval, and analysis of complex information in a structured and interconnected manner, facilitating various applications such as semantic search, question answering, and knowledge discovery.</p>
<p>A.2 Graph neural networks</p>
<p>Graph Neural Networks (GNNs) [124] belong to a special class of neural networks that are designed to operate on data following the structure of a graph, in which there are entities or nodes, and relations or edges between them.That's pretty uncommon, actually.Unlike conventional neural networks, which can learn and reason from grid-like data, GNNs are quite able to get pattern recognition within data that's highly irregular and interconnected.GNNs iteratively update the representations of the nodes by allowing them to pool information from neighboring nodes, such that they can represent complex dependencies and patterns of the graph structure.This is the process, usually message passing between nodes, whereby each node aggregates information from its neighbors and changes its own representation based on the information.</p>
<p>A.2.1 Graph convolutional networks</p>
<p>Graph convolutional networks (GCNs) [115]are, in fact, convolutional neural networks (CNNs) that generalize the classical CNNs' convolutional operation from regular data domains to irregular ones, such as graphs.Being directly performed over the graph structure, convolutional operations in GCNs allow for the capturing of localized and global information in a principled manner over the corresponding adjacent nodes.Central to the idea of GCNs is the aggregation of feature information from the node's neighborhood, normally understood to mean the immediate neighbors, followed by updating the node representation with the gathered representation, and repeating this process several times over multiple layers.This is being done several times over a few layers to progressively learn more complex hierarchical representations of the graph data.</p>
<p>A.2.2 Graph attention networks</p>
<p>Graph Attention Networks (GATs) [116] are another type of graph neural network that applies attention mechanisms to allow the model to capture complex dependencies between different nodes in graph-structured data, within natural language processing.In traditional graph convolutional networks (GCNs), information from neighbors of nodes is uniformly aggregated, but the attention of GAT is dynamically computed for each pair of neighbor nodes and central node, which enabled our model to generalize the convolutional model by focusing more on the relevant neighbors of each node.This attention mechanism, in other words, allows the GATs to effectively learn the importance in light of their relevance to the target node, capturing differences in level that arise from the graph structure.</p>
<p>Figure 2 :
2
Figure 2: Neural for symbol</p>
<p>Figure 3 :
3
Figure 3: Symbol for neural</p>
<p>Figure 4 :
4
Figure 4: Hybrid neural-symbolic integration</p>
<p>Figure 5 :
5
Figure 5: A two-layer receptive field (green entities) of the blue entity in a KG</p>
<p>Figure 6 :
6
Figure 6: Attentive embedding propagation layer of KGAT</p>
<p>Figure 7 :
7
Figure 7: End-to-end architecture of the variational reasoning network (VRN) for question-answering with KG</p>
<p>Figure 8 :
8
Figure 8: Architecture of the QA-GNN for question-answering with KG</p>
<p>Figure 9 :
9
Figure 9: The basic architecture of training classifier by GCN with KG and semantic embedding</p>
<p>Figure 10 :
10
Figure 10: The Knowledge Attention and Recontextualization (KAR) component</p>
<p>Figure 11 :
11
Figure 11: Overview of CogQA implementation</p>
<p>Table 1 :
1
Comparison between neural system and symbolic system
methodAdvantageDisadvantageNeural SystemData patterns learningStrong representational capacityBlack box/Poor interpretabilityHandles complex patternsRelies on excessive dataSymbolic System Rule-based reasoningPrecise and logicalLess stableHighly interpretableLess flexible</p>
<p>Table 2 :
2
Overview of Models by Application and Category</p>
<p>Symbol grounding originates from cognitive science[126] and aims to connect abstract symbols to real-world physical entities. In the neural-symbolic field, it connects data to entities in a symbolic system, resulting in enhanced understanding and interpretability of the network.
Prototype Graph Neural Network (PGNN)[140] combines GNNs with prototype learning. By learning representative instances (prototypes) of key structures in a graph, GNN can more closely integrate the representation of the graph data with the representation of the associated prototypes, thus enhancing the interpretability of the representation in downstream tasks.
KnowBERT[105]introduces an innovative mechanism known as Knowledge Attention and Recontextualization (KAR), which adeptly bridges the gap between textual content and external knowledge bases.The essence of the KAR mechanism lies in its ability to identify entity mentions within the text and link them to corresponding entities in the knowledge base, thereby enriching the original contextual representation of the text.This process encompasses several critical steps: firstly, mention-span representation transforms potential entity mentions within the text into vectors of uniform dimensionality; secondly, an entity linker is employed to accurately align each mention with the most relevant entity in the knowledge base (symbol for neural); thirdly, by incorporating mention-span self-attention mechanism and through knowledge enhancement and recontextualization[141]steps, the selected entity information is effectively reintegrated into the textual representation, achieving a comprehensive integration of textual meaning and knowledge content.The basic architecture of KAR is shown in the following.
Efficientnet: Rethinking model scaling for convolutional neural networks. Mingxing Tan, Quoc Le, International conference on machine learning. PMLR2019</p>
<p>Resnest: Split-attention networks. Hang Zhang, Chongruo Wu, Zhongyue Zhang, Yi Zhu, Haibin Lin, Zhi Zhang, Yue Sun, Tong He, Jonas Mueller, Manmatha, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognition2022</p>
<p>An image is worth 16x16 words: Transformers for image recognition at scale. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, arXiv:2010.119292020arXiv preprint</p>
<p>Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, arXiv:2303.08774Shyamal Anadkat, et al. Gpt-4 technical report. 2023arXiv preprint</p>
<p>Llama 2: Open foundation and fine-tuned chat models. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, arXiv:2307.092882023arXiv preprint</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.048052018arXiv preprint</p>
<p>Interpretation of neural networks is fragile. Amirata Ghorbani, Abubakar Abid, James Zou, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence201933</p>
<p>Can we open the black box of ai?. Davide Castelvecchi, Nature News. 5387623202016</p>
<p>Explainable ai: A review of machine learning interpretability methods. Pantelis Linardatos, Vasilis Papastefanopoulos, Sotiris Kotsiantis, Entropy. 231182020</p>
<p>Interpretable machine learning. Lulu. com. Christoph Molnar, 2020</p>
<p>The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery. Zachary C Lipton, Queue. 1632018</p>
<p>Artificial neural networks: opening the black box. Judith E Dayhoff, James M Deleo, Cancer: Interdisciplinary International Journal of the American Cancer Society. 91S82001</p>
<p>Explainable artificial intelligence (xai): Concepts, taxonomies, opportunities and challenges toward responsible ai. Information fusion. Alejandro Barredo Arrieta, Natalia Díaz-Rodríguez, Javier Del Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador García, Sergio Gil-López, Daniel Molina, Richard Benjamins, 202058</p>
<p>Explainable machine learning practices: opening another black box for reliable medical ai. Emanuele Ratti, Mark Graves, AI and Ethics. 242022</p>
<p>A unified approach to interpreting model predictions. M Scott, Su-In Lundberg, Lee, 201730Advances in neural information processing systems</p>
<p>why should i trust you?" explaining the predictions of any classifier. Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin, Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. the 22nd ACM SIGKDD international conference on knowledge discovery and data mining2016</p>
<p>Learning deep features for discriminative localization. Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2016</p>
<p>Grad-cam: Visual explanations from deep networks via gradient-based localization. Michael Ramprasaath R Selvaraju, Abhishek Cogswell, Ramakrishna Das, Devi Vedantam, Dhruv Parikh, Batra, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer vision2017</p>
<p>Towards robust interpretability with self-explaining neural networks. David Alvarez, Melis , Tommi Jaakkola, Advances in neural information processing systems. 201831</p>
<p>Deep symbolic learning: Discovering symbols and rules from perceptions. Alessandro Daniele, Tommaso Campari, Sagar Malhotra, Luciano Serafini, arXiv:2208.115612022arXiv preprint</p>
<p>Explainable neural-symbolic learning (x-nesyl) methodology to fuse deep learning representations with expert knowledge graphs: The monumai cultural heritage use case. Natalia Díaz-Rodríguez, Alberto Lamas, Jules Sanchez, Gianni Franchi, Ivan Donadello, Siham Tabik, David Filliat, Policarpo Cruz, Rosana Montes, Francisco Herrera, Information Fusion. 792022</p>
<p>Adrien Bennetot, Jean-Luc Laurent, Raja Chatila, Natalia Díaz-Rodríguez, arXiv:1909.09065Towards explainable neuralsymbolic visual reasoning. 2019arXiv preprint</p>
<p>Looking inside the black-box: Logic-based explanations for neural networks. Joao Ferreira, Manuel De Sousa Ribeiro, Ricardo Gonçalves, Joao Leite, Proceedings of the international conference on principles of knowledge representation and reasoning. the international conference on principles of knowledge representation and reasoning202219</p>
<p>Greybox xai: A neural-symbolic learning framework to produce interpretable predictions for image classification. Adrien Bennetot, Gianni Franchi, Javier Del Ser, Raja Chatila, Natalia Diaz-Rodriguez, Knowledge-Based Systems. 2581099472022</p>
<p>Combining symbolic expressions and black-box function evaluations in neural programs. Forough Arabshahi, Sameer Singh, Animashree Anandkumar, arXiv:1801.043422018arXiv preprint</p>
<p>A symbolic-neural method for solving control problems. Sutton Suddarth, Holden, IEEE 1988 International Conference on Neural Networks. IEEE1988</p>
<p>Thinking, fast and slow. Daniel Kahneman, 2011macmillan</p>
<p>Deep learning. Yann Lecun, Yoshua Bengio, Geoffrey Hinton, nature. 52175532015</p>
<p>Connectionist ai, symbolic ai, and the brain. Paul Smolensky, Artificial Intelligence Review. 121987</p>
<p>Expert systems. C Joseph, Gary Giarratano, Riley, 1998PWS Publishing Co</p>
<p>Introduction to artificial intelligence and expert systems. Dan Patterson, 1990Prentice-Hall, Inc</p>
<p>Introduction: what is a knowledge graph? Knowledge graphs: Methodology, tools and selected use cases. Dieter Fensel, Umutcan Şimşek, Kevin Angele, Elwin Huaman, Elias Kärle, Oleksandra Panasiuk, Ioan Toma, Jürgen Umbrich, Alexander Wahler, Dieter Fensel, 2020</p>
<p>Connectionist-symbolic integration: From unified to hybrid approaches. Ron Sun, Frederic Alexandre, 2013Psychology Press</p>
<p>Hybrid neural systems: from simple coupling to fully integrated neural networks. Kenneth Mcgarry, Stefan Wermter, John Macintyre, Neural Computing Surveys. 211999</p>
<p>Integration of neural network-based symbolic regression in deep learning for scientific discovery. Samuel Kim, Peter Y Lu, Srijon Mukherjee, Michael Gilbert, Li Jing, Vladimir Čeperić, Marin Soljačić, IEEE transactions on neural networks and learning systems. 3292020</p>
<p>Chains of reasoning over entities, relations, and text using recurrent neural networks. Rajarshi Das, Arvind Neelakantan, David Belanger, Andrew Mccallum, arXiv:1607.014262016arXiv preprint</p>
<p>Deeppath: A reinforcement learning method for knowledge graph reasoning. Wenhan Xiong, Thien Hoang, William Yang, Wang , arXiv:1707.066902017arXiv preprint</p>
<p>Reinforced anytime bottom up rule learning for knowledge graph completion. Christian Meilicke, Melisachew Wudage Chekol, Manuel Fink, Heiner Stuckenschmidt, arXiv:2004.044122020arXiv preprint</p>
<p>Wenhu Chen, Wenhan Xiong, Xifeng Yan, William Wang, arXiv:1803.06581Variational knowledge graph reasoning. 2018arXiv preprint</p>
<p>Random walk inference and learning in a large scale knowledge base. Ni Lao, Tom Mitchell, William Cohen, Proceedings of the 2011 conference on empirical methods in natural language processing. the 2011 conference on empirical methods in natural language processing2011</p>
<p>Compositional vector space models for knowledge base completion. Arvind Neelakantan, Benjamin Roth, Andrew Mccallum, arXiv:1504.066622015arXiv preprint</p>
<p>Multi-hop knowledge graph reasoning with reward shaping. Xi Victoria, Lin , Richard Socher, Caiming Xiong, arXiv:1808.105682018arXiv preprint</p>
<p>Neural bellman-ford networks: A general graph neural network framework for link prediction. Zhaocheng Zhu, Zuobai Zhang, Louis-Pascal Xhonneux, Jian Tang, Advances in Neural Information Processing Systems. 342021</p>
<p>Inductive relation prediction by subgraph reasoning. Komal Teru, Etienne Denis, Will Hamilton, International Conference on Machine Learning. PMLR2020</p>
<p>William W Cohen, arXiv:1605.06523Tensorlog: A differentiable deductive database. 2016arXiv preprint</p>
<p>Differentiable learning of logical rules for knowledge base reasoning. Fan Yang, Zhilin Yang, William W Cohen, 201730Advances in neural information processing systems</p>
<p>Learn to explain efficiently via neural logic inductive learning. Yuan Yang, Le Song, arXiv:1910.024812019arXiv preprint</p>
<p>Rnnlogic: Learning logic rules for reasoning on knowledge graphs. Meng Qu, Junkun Chen, Louis-Pascal Xhonneux, Yoshua Bengio, Jian Tang, arXiv:2010.040292020arXiv preprint</p>
<p>Efficient probabilistic logic reasoning with graph neural networks. Yuyu Zhang, Xinshi Chen, Yuan Yang, Arun Ramamurthy, Bo Li, Yuan Qi, Le Song, arXiv:2001.118502020arXiv preprint</p>
<p>Probabilistic logic neural networks for reasoning. Meng Qu, Jian Tang, Advances in neural information processing systems. 201932</p>
<p>Knowledge graph convolutional networks for recommender systems. Hongwei Wang, Miao Zhao, Xing Xie, Wenjie Li, Minyi Guo, The world wide web conference. 2019</p>
<p>Kgat: Knowledge graph attention network for recommendation. Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, Tat-Seng Chua, Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining. the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining2019</p>
<p>Variational reasoning for question answering with knowledge graph. Yuyu Zhang, Hanjun Dai, Zornitsa Kozareva, Alexander Smola, Le Song, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence201832</p>
<p>Open domain question answering using early fusion of knowledge bases and text. Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn Mazaitis, Ruslan Salakhutdinov, William W Cohen, arXiv:1809.007822018arXiv preprint</p>
<p>Pullnet: Open domain question answering with iterative retrieval on knowledge bases and text. Haitian Sun, Tania Bedrax-Weiss, William W Cohen, arXiv:1904.095372019arXiv preprint</p>
<p>Qa-gnn: Reasoning with language models and knowledge graphs for question answering. Michihiro Yasunaga, Hongyu Ren, Antoine Bosselut, Percy Liang, Jure Leskovec, arXiv:2104.063782021arXiv preprint</p>
<p>Contextualized graph attention network for recommendation with item knowledge graph. Yong Liu, Susen Yang, Yonghui Xu, Chunyan Miao, Min Wu, Juyong Zhang, IEEE Transactions on knowledge and data engineering. 3512021</p>
<p>Learning knowledge graph embedding with heterogeneous relation attention networks. Zhifei Li, Hai Liu, Zhaoli Zhang, Tingting Liu, Neal N Xiong, IEEE Transactions on Neural Networks and Learning Systems. 3382021</p>
<p>Jing Zhang, Bo Chen, Lingxi Zhang, Xirui Ke, and Haipeng Ding. Neural, symbolic and neural-symbolic reasoning on knowledge graphs. AI Open. 20212</p>
<p>Jointly embedding knowledge graphs and logical rules. Shu Guo, Quan Wang, Lihong Wang, Bin Wang, Li Guo, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Jian Su, Kevin Duh, Xavier Carreras, the 2016 Conference on Empirical Methods in Natural Language ProcessingAustin, TexasAssociation for Computational LinguisticsNovember 2016</p>
<p>Knowledge graph embedding with iterative guidance from soft rules. Shu Guo, Quan Wang, Lihong Wang, Bin Wang, Li Guo, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence201832</p>
<p>Iteratively learning embeddings and rules for knowledge graph reasoning. Wen Zhang, Bibek Paudel, Liang Wang, Jiaoyan Chen, Hai Zhu, Wei Zhang, Abraham Bernstein, Huajun Chen, The world wide web conference. 2019</p>
<p>Logic tensor networks for semantic image interpretation. Ivan Donadello, Luciano Serafini, Artur D'avila Garcez, arXiv:1705.089682017arXiv preprint</p>
<p>Danqi Chen, Richard Socher, Christopher D Manning, Andrew Y Ng, arXiv:1301.3618Learning new facts from knowledge bases with neural tensor networks and semantic word vectors. 2013arXiv preprint</p>
<p>Luciano Serafini, Artur D'avila Garcez, arXiv:1606.04422Logic tensor networks: Deep learning and logical reasoning from data and knowledge. 2016arXiv preprint</p>
<p>A semantic loss function for deep learning with symbolic knowledge. Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, Guy Broeck, International conference on machine learning. PMLR2018</p>
<p>Discovering symbolic models from deep learning with inductive biases. Miles Cranmer, Alvaro Sanchez Gonzalez, Peter Battaglia, Rui Xu, Kyle Cranmer, David Spergel, Shirley Ho, Advances in neural information processing systems. 332020</p>
<p>Improving neural networks by preventing co-adaptation of feature detectors. Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, Ruslan R Salakhutdinov, arXiv:1207.05802012arXiv preprint</p>
<p>Ripplenet: Propagating user preferences on the knowledge graph for recommender systems. Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing Xie, Minyi Guo, Proceedings of the 27th ACM international conference on information and knowledge management. the 27th ACM international conference on information and knowledge management2018</p>
<p>Cazsl: Zero-shot regression for pushing models by generalizing through context. Wenyu Zhang, Skyler Seto, Devesh K Jha, 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE2020</p>
<p>Augmenting deep neural networks with symbolic educational knowledge: Towards trustworthy and interpretable ai for education. Danial Hooshyar, Roger Azevedo, Yeongwook Yang, Machine Learning and Knowledge Extraction. 612024</p>
<p>A neuro-vector-symbolic architecture for solving raven's progressive matrices. Michael Hersche, Mustafa Zeqiri, Luca Benini, Abu Sebastian, Abbas Rahimi, Nature Machine Intelligence. 542023</p>
<p>Embedding symbolic knowledge into deep networks. Yaqi Xie, Ziwei Xu, Mohan S Kankanhalli, Kuldeep S Meel, Harold Soh, Advances in neural information processing systems. 201932</p>
<p>Embedding symbolic temporal knowledge into deep sequential models. Yaqi Xie, Fan Zhou, Harold Soh, 2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE2021</p>
<p>Harnessing deep neural networks with logic rules. Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, Eric Xing, arXiv:1603.063182016arXiv preprint</p>
<p>Lsfsl: Leveraging shape information in few-shot learning. Deepan Chakravarthi Padmanabhan, Shruthi Gowda, Elahe Arani, Bahram Zonooz, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2023</p>
<p>Semantic-based regularization for learning and inference. Michelangelo Diligenti, Marco Gori, Claudio Sacca, Artificial Intelligence. 2442017</p>
<p>Rethinking knowledge graph propagation for zero-shot learning. Michael Kampffmeyer, Yinbo Chen, Xiaodan Liang, Hao Wang, Yujia Zhang, Eric P Xing, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognition2019</p>
<p>Knowledge graph transfer network for few-shot recognition. Riquan Chen, Tianshui Chen, Xiaolu Hui, Hefeng Wu, Guanbin Li, Liang Lin, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence202034</p>
<p>Se-cnn: convolution neural network acceleration via symbolic value prediction. Yuan Yao, IEEE Journal on Emerging and Selected Topics in Circuits and Systems. 1312023</p>
<p>Collaborative knowledge base embedding for recommender systems. Fuzheng Zhang, Nicholas Jing Yuan, Defu Lian, Xing Xie, Wei-Ying Ma, Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. the 22nd ACM SIGKDD international conference on knowledge discovery and data mining2016</p>
<p>Improving multi-hop question answering over knowledge graphs using knowledge base embeddings. Apoorv Saxena, Aditay Tripathi, Partha Talukdar, Proceedings of the 58th annual meeting of the association for computational linguistics. the 58th annual meeting of the association for computational linguistics2020</p>
<p>Multi-label zero-shot learning with structured knowledge graphs. Chung-Wei Lee, Wei Fang, Chih-Kuan Yeh, Yu-Chiang Frank, Wang , Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2018</p>
<p>K-bert: Enabling language representation with knowledge graph. Weijie Liu, Peng Zhou, Zhe Zhao, Zhiruo Wang, Qi Ju, Haotang Deng, Ping Wang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202034</p>
<p>Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, Qun Liu, arXiv:1905.07129Ernie: Enhanced language representation with informative entities. 2019arXiv preprint</p>
<p>Zero-shot recognition via semantic embeddings and knowledge graphs. Xiaolong Wang, Yufei Ye, Abhinav Gupta, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2018</p>
<p>Graph few-shot learning via knowledge transfer. Huaxiu Yao, Chuxu Zhang, Ying Wei, Meng Jiang, Suhang Wang, Junzhou Huang, Nitesh Chawla, Zhenhui Li, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence202034</p>
<p>Deepproblog: Neural probabilistic logic programming. Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, Luc De, Raedt , Advances in neural information processing systems. 201831</p>
<p>Abductive learning: towards bridging machine learning and logical reasoning. Zhi-Hua Zhou, Science China. Information Sciences. 627761012019</p>
<p>Bridging machine learning and logical reasoning by abductive learning. Wang-Zhou Dai, Qiuling Xu, Yang Yu, Zhi-Hua Zhou, Advances in Neural Information Processing Systems. 201932</p>
<p>Fast abductive learning by similarity-based consistency optimization. Yu-Xuan Huang, Wang-Zhou Dai, Le-Wen Cai, Stephen H Muggleton, Yuan Jiang, Advances in Neural Information Processing Systems. 202134</p>
<p>A hybrid learning model of abductive reasoning. Jiajie Todd R Johnson, Hongbin Zhang, Wang, Connectionist-Symbolic Integration. Psychology Press2013</p>
<p>Abductive learning with ground knowledge base. Le-Wen Cai, Wang-Zhou Dai, Yu-Xuan Huang, Yu-Feng Li, Stephen H Muggleton, Yuan Jiang, IJCAI. 2021</p>
<p>Weakly supervised neural symbolic learning for cognitive tasks. Jidong Tian, Yitian Li, Wenqing Chen, Liqiang Xiao, Hao He, Yaohui Jin, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202236</p>
<p>Grounding symbols in the analog world with neural nets: A hybrid model. Stevan Harnad, Psychology. 122001</p>
<p>Sc-net: a hybrid connectionist, symbolic system. G Steve, Lawrence O Romaniuk, Hall, Information sciences. 7131993</p>
<p>Opencog ns: a deeply-interactive hybrid neural-symbolic cognitive architecture designed for global/local memory synergy. Ben Goertzel, Deborah Duong, AAAI Fall Symposium Series. 2009. 2009</p>
<p>Neural-symbolic integration: A compositional perspective. Efthymia Tsamoura, Timothy Hospedales, Loizos Michael, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence202135</p>
<p>Neuro-symbolic computation for xai: Towards a unified model. Giuseppe Pisano, Giovanni Ciatto, Roberta Calegari, Andrea Omicini, CEUR WORKSHOP PROCEEDINGS. 20202706Sun SITE Central Europe, RWTH Aachen University</p>
<p>Senticnet 7: A commonsense-based neurosymbolic ai framework for explainable sentiment analysis. Erik Cambria, Qian Liu, Sergio Decherchi, Frank Xing, Kenneth Kwok, Proceedings of the Thirteenth Language Resources and Evaluation Conference. the Thirteenth Language Resources and Evaluation Conference2022</p>
<p>Cognitive graph for multi-hop reading comprehension at scale. Ming Ding, Chang Zhou, Qibin Chen, Hongxia Yang, Jie Tang, arXiv:1905.054602019arXiv preprint</p>
<p>Jointgt: Graphtext joint representation learning for text generation from knowledge graphs. Pei Ke, Haozhe Ji, Yu Ran, Xin Cui, Liwei Wang, Linfeng Song, Xiaoyan Zhu, Minlie Huang, arXiv:2106.105022021arXiv preprint</p>
<p>Iterative fusion method based on heterogeneous graph neural network for entity alignment. Zirui Zhang, Fanfang Meng, Yuanhui Meng, Xiaoxia Liu, Benhui Chen, 2023 International Joint Conference on Neural Networks (IJCNN). IEEE2023</p>
<p>Knowledge-fusion-based iterative graph structure learning framework for implicit sentiment identification. Yuxia Zhao, Mahpirat Mamat, Alimjan Aysa, Kurban Ubul, Sensors. 231462572023</p>
<p>Mark Matthew E Peters, Robert L Neumann, I V Logan, Roy Schwartz, Vidur Joshi, Sameer Singh, Noah A Smith, arXiv:1909.04164Knowledge enhanced contextual word representations. 2019arXiv preprint</p>
<p>Personalized entity recommendation: A heterogeneous information network approach. Xiao Yu, Xiang Ren, Yizhou Sun, Quanquan Gu, Bradley Sturt, Urvashi Khandelwal, Brandon Norick, Jiawei Han, Proceedings of the 7th ACM international conference on Web search and data mining. the 7th ACM international conference on Web search and data mining2014</p>
<p>Meta-graph based recommendation fusion over heterogeneous information networks. Huan Zhao, Quanming Yao, Jianda Li, Yangqiu Song, Dik Lun, Lee , Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. the 23rd ACM SIGKDD international conference on knowledge discovery and data mining2017</p>
<p>Heterogeneous information network embedding for recommendation. Chuan Shi, Binbin Hu, Wayne Xin Zhao, Philip Yu, IEEE transactions on knowledge and data engineering. 3122018</p>
<p>Dkn: Deep knowledge-aware network for news recommendation. Hongwei Wang, Fuzheng Zhang, Xing Xie, Minyi Guo, Proceedings of the 2018 world wide web conference. the 2018 world wide web conference2018</p>
<p>Shine: Signed heterogeneous information network embedding for sentiment link prediction. Hongwei Wang, Fuzheng Zhang, Min Hou, Xing Xie, Minyi Guo, Qi Liu, Proceedings of the eleventh ACM international conference on web search and data mining. the eleventh ACM international conference on web search and data mining2018</p>
<p>Neural factorization machines for sparse predictive analytics. Xiangnan He, Tat-Seng Chua, Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval. the 40th International ACM SIGIR conference on Research and Development in Information Retrieval2017</p>
<p>Wide &amp; deep learning for recommender systems. Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, Proceedings of the 1st workshop on deep learning for recommender systems. the 1st workshop on deep learning for recommender systems2016</p>
<p>Xing Xie, and Guangzhong Sun. xdeepfm: Combining explicit and implicit feature interactions for recommender systems. Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining. the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining2018</p>
<p>Modeling relational data with graph convolutional networks. Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den, Ivan Berg, Max Titov, Welling, The semantic web: 15th international conference. Heraklion, Crete, GreeceSpringer2018. June 3-7, 2018. 201815</p>
<p>Semi-supervised classification with graph convolutional networks. N Thomas, Max Kipf, Welling, arXiv:1609.029072016arXiv preprint</p>
<p>Graph attention networks. Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, Yoshua Bengio, stat. 1050202017</p>
<p>Keyvalue memory networks for directly reading documents. Alexander Miller, Adam Fisch, Jesse Dodge, Amir-Hossein, Antoine Karimi, Jason Bordes, Weston, arXiv:1606.031262016arXiv preprint</p>
<p>. Jason Weston, Sumit Chopra, Antoine Bordes, arXiv:1410.39162014Memory networks. arXiv preprint</p>
<p>Gated graph sequence neural networks. Yujia Li, Daniel Tarlow, Marc Brockschmidt, Richard Zemel, arXiv:1511.054932015arXiv preprint</p>
<p>Neural domain adaptation for biomedical question answering. Georg Wiese, Dirk Weissenborn, Mariana Neves, arXiv:1706.036102017arXiv preprint</p>
<p>Simple and effective semi-supervised question answering. Bhuwan Dhingra, Danish Pruthi, Dheeraj Rajagopal, arXiv:1804.007202018arXiv preprint</p>
<p>Distant supervision for relation extraction with an incomplete knowledge base. Bonan Min, Ralph Grishman, Li Wan, Chang Wang, David Gondek, Proceedings of the 2013 Conference of the North American Chapter. the 2013 Conference of the North American ChapterHuman Language Technologies2013</p>
<p>The anatomy of a large-scale hypertextual web search engine. Computer networks and ISDN systems. Sergey Brin, Lawrence Page, 199830</p>
<p>The graph neural network model. Franco Scarselli, Marco Gori, Chung Ah, Markus Tsoi, Gabriele Hagenbuchner, Monfardini, 200820</p>
<p>Graph attention networks. Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, Yoshua Bengio, arXiv:1710.109032017arXiv preprint</p>
<p>The symbol grounding problem. Stevan Harnad, Physica D: Nonlinear Phenomena. 421-31990</p>
<p>Zero-data learning of new tasks. Hugo Larochelle, Dumitru Erhan, Yoshua Bengio, AAAI. 200813</p>
<p>Zero-shot learning through crossmodal transfer. Richard Socher, Milind Ganjoo, Christopher D Manning, Andrew Ng, Advances in neural information processing systems. 262013</p>
<p>Latent embeddings for zero-shot classification. Yongqin Xian, Zeynep Akata, Gaurav Sharma, Quynh Nguyen, Matthias Hein, Bernt Schiele, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2016</p>
<p>Glove: Global vectors for word representation. Jeffrey Pennington, Richard Socher, Christopher D Manning, Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). the 2014 conference on empirical methods in natural language processing (EMNLP)2014</p>
<p>Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean, arXiv:1301.3781Efficient estimation of word representations in vector space. 2013arXiv preprint</p>
<p>Large-scale multi-label text classification-revisiting neural networks. Jinseok Nam, Jungi Kim, Eneldo Loza Mencía, Iryna Gurevych, Johannes Fürnkranz, Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014. Nancy, FranceSpringerSeptember 15-19, 2014. 2014Proceedings, Part II 14</p>
<p>Yunchao Wei, Wei Xia, Junshi Huang, Bingbing Ni, Jian Dong, Yao Zhao, Shuicheng Yan, Cnn, arXiv:1406.5726Single-label to multi-label. 2014arXiv preprint</p>
<p>Cnn-rnn: A unified framework for multi-label image classification. Jiang Wang, Yi Yang, Junhua Mao, Zhiheng Huang, Chang Huang, Wei Xu, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2016</p>
<p>Learning deep latent space for multi-label classification. Chih-Kuan Yeh, Wei-Chieh Wu, Wei-Jen Ko, Yu-Chiang Frank, Wang , Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence201731</p>
<p>Learning phrase representations using rnn encoder-decoder for statistical machine translation. Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio, arXiv:1406.10782014arXiv preprint</p>
<p>Edge detection in images using marr-hildreth filtering techniques. SmithJr, Marks, Lange, SheriffJr, Neale, Journal of neuroscience methods. 2611988</p>
<p>Weisfeiler-lehman graph kernels. Nino Shervashidze, Pascal Schweitzer, Erik , Jan Van Leeuwen, Kurt Mehlhorn, Karsten M Borgwardt, Journal of Machine Learning Research. 1292011</p>
<p>Deltacon: A principled massive-graph similarity function. Danai Koutra, Joshua T Vogelstein, Christos Faloutsos, Proceedings of the 2013 SIAM international conference on data mining. the 2013 SIAM international conference on data miningSIAM2013</p>
<p>Protgnn: Towards self-explaining graph neural networks. Zaixi Zhang, Qi Liu, Hao Wang, Chengqiang Lu, Cheekong Lee, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202236</p>
<p>Attention is all you need. Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin, 201730</p>
<p>The webnlg challenge: Generating text from rdf data. Claire Gardent, Anastasia Shimorina, Shashi Narayan, Laura Perez-Beltrachini, Proceedings of the 10th international conference on natural language generation. the 10th international conference on natural language generation2017</p>
<p>Heterogeneous graph neural network. Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, Nitesh V Chawla, Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining. the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining2019</p>
<p>Multimodal knowledge graph for deep learning papers and code. Dmitriy Amar Viswanathan Kannan, Ioannis Fradkin, Tugba Akrotirianakis, Arquimedes Kulahcioglu, Aditi Canedo, Shih-Yuan Roy, Malawade Yu, Mohammad Arnav, Al Abdullah, Faruque, Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management. the 29th ACM International Conference on Information &amp; Knowledge Management2020</p>
<p>Hybrid transformer with multi-level fusion for multimodal knowledge graph completion. Xiang Chen, Ningyu Zhang, Lei Li, Shumin Deng, Chuanqi Tan, Changliang Xu, Fei Huang, Luo Si, Huajun Chen, Proceedings of the 45th international ACM SIGIR conference on research and development in information retrieval. the 45th international ACM SIGIR conference on research and development in information retrieval2022</p>
<p>A multimodal translation-based approach for knowledge graph representation learning. Hatem Mousselly-Sergieh, Teresa Botschen, Iryna Gurevych, Stefan Roth, Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics. the Seventh Joint Conference on Lexical and Computational Semantics2018</p>
<p>Multi-modal knowledge graphs for recommender systems. Rui Sun, Xuezhi Cao, Yan Zhao, Junchen Wan, Kun Zhou, Fuzheng Zhang, Zhongyuan Wang, Kai Zheng, Proceedings of the 29th ACM international conference on information &amp; knowledge management. the 29th ACM international conference on information &amp; knowledge management2020</p>
<p>Multi-modal knowledge graph construction and application: A survey. Xiangru Zhu, Zhixu Li, Xiaodan Wang, Xueyao Jiang, Penglei Sun, Xuwu Wang, Yanghua Xiao, Nicholas Jing Yuan, IEEE Transactions on Knowledge and Data Engineering. 2022</p>            </div>
        </div>

    </div>
</body>
</html>