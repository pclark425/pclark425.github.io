<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2298 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2298</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2298</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-58576290</p>
                <p><strong>Paper Title:</strong> Application of machine learning in rheumatic disease research</p>
                <p><strong>Paper Abstract:</strong> Over the past decade, there has been a paradigm shift in how clinical data are collected, processed and utilized. Machine learning and artificial intelligence, fueled by breakthroughs in high-performance computing, data availability and algorithmic innovations, are paving the way to effective analyses of large, multi-dimensional collections of patient histories, laboratory results, treatments, and outcomes. In the new era of machine learning and predictive analytics, the impact on clinical decision-making in all clinical areas, including rheumatology, will be unprecedented. Here we provide a critical review of the machine-learning methods currently used in the analysis of clinical data, the advantages and limitations of these methods, and how they can be leveraged within the field of rheumatology.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2298.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2298.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RA_synovial_subtyping_SVM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Support Vector Machine applied to synovial histologic and RNA-seq driven rheumatoid arthritis subtyping</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Integration of synovial histologic features and RNA-sequencing to identify molecular/histologic RA subtypes via unsupervised clustering followed by an SVM classifier to map histology to genomic subgroups.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Identification of three rheumatoid arthritis disease subtypes by machine learning integration of synovial histologic features and RNA sequencing data.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Rheumatology / rheumatoid arthritis; molecular and histologic patient stratification</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Detect biologically and clinically meaningful synovial tissue subtypes (high-inflammatory, low-inflammatory, mixed) using gene expression and histology to enable better characterization of RA heterogeneity and potential links to clinical parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Limited/small for the analyzed set: histologic features from 129 synovial samples (123 RA, 6 OA) and gene-expression (the 500 most variable genes) from 45 synovial samples (39 RA, 6 OA). Labeled by domain experts for histology; genomic data labeled by clustering results. Data quality not ideal for large-scale generalization; no independent genomic validation dataset reported.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Multimodal: structured tabular histologic feature counts/scores and high-dimensional gene-expression vectors (RNA-seq-derived features); relatively low sample count with high feature dimensionality.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High dimensionality and heterogeneity (many gene features vs few samples), non-linear relationships between molecular profiles and histology, risk of overfitting due to small sample size and mixed disease types (RA and OA).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging application within RA research; established clinical/histologic measures exist but molecular subtyping in RA is still developing with limited large-scale validation.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium to high — interpretation is important (linking histologic patterns to clinical measures and biology), so explainability and validation are needed rather than opaque black-box outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>k-means clustering (unsupervised) + Support Vector Machine (supervised classification)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Unsupervised k-means clustering on the most variable genes to identify three genomic subgroups; principal component analysis used to validate clustering structure; a leave-one-out cross-validated SVM classifier trained on histologic features to predict genomic subtype labels (SVM aimed to separate classes with maximal margin). Details such as SVM kernel type and hyperparameters were not fully specified in the review summary.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Unsupervised learning (clustering) followed by supervised learning (SVM classification)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate for subgroup discovery and mapping histology to molecular labels; however, constrained by small sample sizes and mixed-case samples (RA and OA) which limit generalizability. Requires larger, independent datasets for broader applicability.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Classifier AUC for separating high-inflammatory subtype: 0.88; for low-inflammatory subtype: 0.71. (Reported in the cited study.)</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Qualitatively useful — histologic subtypes correlated with clinical features (ESR, CRP, autoantibodies). But the study is vulnerable to overfitting and limited by small sample size and lack of independent validation for genomic clustering.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Potential to enable histology-based proxies for molecular subtypes (practical for clinical pathology), improving patient stratification and tailoring therapies; impact contingent on external validation and larger cohorts.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Not directly compared to other classifiers in the review; authors noted potential overfitting of SVM and recommended more detailed method reporting and independent validation.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Integration of multimodal data (histology + RNA-seq), domain expert labeling of histologic features, and use of cross-validation; limitations include small sample size, mixed RA/OA samples, and incomplete reporting of classifier hyperparameters.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Combining unsupervised gene-expression clustering with supervised histology-based SVM classification can reveal clinically meaningful RA synovial subtypes, but small, heterogeneous datasets and limited validation constrain reliability and generalizability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Application of machine learning in rheumatic disease research', 'publication_date_yy_mm': '2019-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2298.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2298.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RA_mortality_RSF</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Random Survival Forest for prediction of mortality in rheumatoid arthritis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Non-parametric ensemble method (random survival forest) applied to time-to-event mortality prediction in RA using clinical and demographic features, externally validated across independent cohorts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Development and validation of a multivariate predictive model for rheumatoid arthritis mortality using a machine learning approach.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Rheumatology / prognosis modelling of rheumatoid arthritis mortality</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict mortality risk (time-to-event) in RA patients using demographic and clinical variables, addressing potential violation of Cox proportional hazards assumptions and capturing non-linear interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Moderate/adequate: two independent cohorts used — HCSC-RAC training cohort with 1,461 patients and PEARL validation cohort with 280 patients; data were structured clinical/demographic variables and longitudinal outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular clinical and demographic data (clinical variables, lab summaries); time-to-event (survival) data.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate: involves non-linear relationships and potential interactions among many clinical features; survival analysis increases complexity relative to plain classification/regression.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Relatively mature in terms of clinical data availability and existing models (e.g., Cox models), but ML survival forests are a more recent approach for this domain.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — prognostic models used for clinical risk stratification require interpretability to identify key risk factors; RSF provides variable importance metrics but is less mechanistic than explicit statistical models.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Random Survival Forest (RSF)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>An ensemble of decision trees adapted for censored time-to-event data using bootstrap aggregation (bagging); multiple runs (100 runs) with many trees per run (1,000 trees) to stabilize estimates; variable importance measures derived to identify key predictors (age at diagnosis, median ESR, number of hospital admissions).</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning — ensemble methods for survival analysis</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Well-suited: RSF handles non-linearities and interactions and does not assume proportional hazards; applicable to survival data with censoring and moderate sample sizes. Requires adequate sample size for stable tree ensembles.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported prediction error: 0.187 (training cohort) and 0.233 (validation cohort). Important predictors matched those from prior Cox model analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Qualitatively effective — performed reasonably with external validation and produced interpretable variable importance consistent with prior knowledge; advantages over Cox when proportional hazards assumption may be violated.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Enables improved, flexible prognostic modeling in RA potentially informing clinical decision-making and risk stratification; external validation increases translational potential.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared conceptually to Cox proportional hazards models; RSF highlighted as attractive alternative when proportional hazards assumptions are violated, and importance measures aligned with Cox model findings.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large enough training cohort, use of an independent validation cohort, ensemble averaging to reduce variance, and selection of relevant clinical predictors contributed to robust performance.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>RSF can effectively model non-linear, interacting predictors in survival tasks for RA and, when externally validated, offer practical prognostic performance with variable-importance outputs that align with clinical knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Application of machine learning in rheumatic disease research', 'publication_date_yy_mm': '2019-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2298.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2298.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DCNN_transfer_TB</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep Convolutional Neural Networks with transfer learning for chest radiograph tuberculosis classification</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of deep convolutional neural networks (AlexNet and GoogLeNet) pretrained on ImageNet (transfer learning) to classify pulmonary tuberculosis from chest X-rays with high AUC.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Medical imaging / infectious disease radiology (pulmonary tuberculosis detection)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Automatically detect pulmonary tuberculosis from standard chest radiographs using image-based deep learning to support diagnostic screening.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Moderate — the study leveraged chest radiograph datasets, but the review specifies limited clinical dataset context; transfer learning employed because target dataset size was small relative to model complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Unstructured image data (2D chest radiographs) suitable for convolutional neural networks; images may be labeled (tuberculosis vs normal).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High in feature representation (complex visual patterns), but lower in label space (binary classification); requires handling of intra-class variability, imaging artifacts, and limited labeled examples.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Imaging diagnostics is mature; application of deep learning is emerging but rapidly advancing with established best practices (transfer learning common).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low to medium — clinical deployment benefits from explainability, but high raw predictive performance (sensitivity/specificity) is often primary; visualization tools can aid interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Deep Convolutional Neural Networks (AlexNet, GoogLeNet) with transfer learning</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Pretrained AlexNet and GoogLeNet models (trained on ImageNet) were fine-tuned on chest radiograph data (transfer learning) to leverage learned low- and mid-level image features; training adapted to smaller radiograph dataset to prevent overfitting; evaluation used AUC metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning — deep learning with transfer learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable: transfer learning allowed use of powerful DCNN architectures despite limited domain-specific image data; suitable for image classification tasks in clinical radiology.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported AUC of 0.99 for tuberculosis vs normal classification using DCNN transfer learning (as cited in the review).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Extremely high reported discriminative performance in this task; transfer learning from ImageNet proved effective at capturing informative imaging features for TB detection despite domain differences.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High — could enable automated triage/screening in settings with limited radiologist availability, speed up diagnosis, and reduce workload; generalizable approach for other imaging tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared implicitly to training from scratch (which would be data-hungry) — transfer learning preferred when target dataset is small; DCNNs outperform many classical image-processing pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Use of large-scale pretraining (ImageNet), selection of proven DCNN architectures, and appropriate fine-tuning on domain images; transfer learning mitigates small-target-dataset limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Transfer learning with pretrained deep convolutional networks can achieve near-perfect classification on certain medical imaging tasks even with limited labeled domain data, provided domain-relevant fine-tuning and careful evaluation are performed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Application of machine learning in rheumatic disease research', 'publication_date_yy_mm': '2019-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2298.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2298.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AKI_GBM_prediction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gradient Boosting Machine for inpatient acute kidney injury prediction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Application of a gradient boosting machine to predict inpatient acute kidney injury (AKI) using clinical and laboratory features over a very large number of hospital admissions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The development of a machine learning inpatient acute kidney injury prediction model</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Nephrology / clinical risk prediction for acute kidney injury in hospitalized patients</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Early prediction of inpatient AKI to enable preventative interventions by modeling risk from routine clinical and laboratory measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Abundant: study used 121,158 admissions (large-scale electronic health record data) with 36 clinical and laboratory features; data are structured but can be noisy and heterogeneous.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular EHR data and time-indexed clinical/lab measurements; large sample size but potential missingness and heterogeneity across records.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate-to-high: temporal dynamics (labs over time), many interacting features, class imbalance (AKI events rarer than non-events), and need to handle missing/inconsistent EHR data.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature in terms of clinical measurement availability; ML approaches for AKI prediction are emergent and have demonstrated promise across large datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — clinicians require interpretable risk drivers for actionability; black-box predictions might be useful for alerts but require explainability for trust.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Gradient Boosting Machine (GBM)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>An ensemble of decision-tree based learners trained sequentially to correct predecessor errors (gradient boosting), using clinical and lab features; suited to tabular data and handling non-linearities and interactions; details on hyperparameters were not given in the review summary.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning — ensemble boosting methods</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable given large structured EHR dataset; GBM handles heterogeneous tabular features and learns complex relationships without strong parametric assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Described as successful in development of a predictive model for inpatient AKI on a very large dataset, but specific performance metrics are not reported in the review's summary.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Significant — early AKI prediction could reduce morbidity through earlier interventions, improve patient safety, and decrease length-of-stay/costs if integrated into clinical workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Not detailed in the review; GBM commonly outperforms single-tree methods and logistic regression on similar tabular clinical tasks, but explicit comparisons were not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Very large sample size, rich feature set, and method suitability for tabular clinical data; challenges include data quality, missingness, and deployment/integration into clinical systems.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Gradient boosting is a practical, effective approach for large-scale EHR-based risk prediction tasks (like AKI) owing to its ability to model non-linear interactions in structured clinical data, but performance depends critically on data quality and clinical integration.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Application of machine learning in rheumatic disease research', 'publication_date_yy_mm': '2019-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2298.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2298.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IBD_RF_prediction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Random Forests for prediction of hospitalization and corticosteroid use in inflammatory bowel disease</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Random forest models applied to predict hospitalization and outpatient corticosteroid use in a large IBD patient cohort using clinical and laboratory features.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Predicting hospitalization and outpatient corticosteroid use in inflammatory bowel disease patients using machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Gastroenterology / inflammatory bowel disease management and risk prediction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict near-term adverse outcomes (hospitalization and corticosteroid use) to guide management decisions in IBD patients.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Large: dataset comprised 20,368 patients with over 30 clinical and laboratory features; data likely labeled for outcomes of interest; EHR-derived data with potential heterogeneity.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular clinical and laboratory features extracted from EHRs; possibly temporal but used as aggregated features in the model.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate: multiple interacting clinical features and event imbalances; requires handling missing data and variable measurement intervals.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Clinical domain mature; ML application is becoming established for outcome prediction in chronic disease management.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — clinicians require understanding of risk drivers to act; random forests provide variable importance but are less interpretable than simple models.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Random Forest</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Bagged ensemble of decision trees trained on bootstrapped samples with random feature selection at splits; robust to overfitting and able to capture non-linear interactions among features; used to predict binary/conditional outcomes in EHR data.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning — ensemble tree methods</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate for tabular clinical prediction tasks with many features and potential non-linearities; benefits from large cohort size.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Reported as a successful application to predict clinical outcomes in a sizable dataset, though the review did not include specific performance metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Potential to assist in proactive care management, reduce unplanned hospitalizations, and tailor outpatient interventions if integrated into clinical workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Not explicitly described in the review; random forests often compared favorably to single-model baselines, but details absent here.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large labeled cohort, diverse feature set, and an algorithm robust to noisy EHR data; caveats include EHR data quality and need for external validation and calibration.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Random forests are a practical, robust choice for EHR-derived outcome prediction in chronic disease cohorts, leveraging large patient numbers to learn non-linear risk patterns though model interpretability and data quality remain important constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Application of machine learning in rheumatic disease research', 'publication_date_yy_mm': '2019-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2298.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2298.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ML_in_Rheumatology_review</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Review of Machine Learning applications in rheumatic disease research (this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A critical review summarizing ML/AI methods used in clinical data analysis relevant to rheumatology, discussing advantages, limitations, data issues, and illustrative domain applications.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Rheumatology broadly (diagnosis, prognostics, subgroup discovery, imaging, multi-omics integration)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Survey and synthesis of how ML methods can address heterogeneity, high-dimensional multi-omics and imaging data, prediction of outcomes, and patient stratification in rheumatic diseases.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Varies by task: can range from scarce (small synovial RNA-seq cohorts) to abundant (large EHR/claims datasets); review emphasizes common issues: heterogeneity, missingness, labeling inconsistencies, and need for quality control.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Multimodal — structured EHR/clinical/laboratory tabular data, unstructured text (EMRs), high-dimensional molecular data (gene expression), and imaging (histology, radiography); often high-dimensional and heterogeneous.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: clinical heterogeneity, multi-scale features (molecular to clinical), non-linear interactions, longitudinal/time-to-event outcomes, and potentially high-dimensional low-sample-size regimes in omics.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mixed — clinical rheumatology is established, but molecular stratification and ML-driven precision medicine are emerging and require more standardized data and external validation.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium to high — interpretability often required for clinical acceptance and mechanistic insight; review stresses that ML results must be contextualized with biological/clinical understanding.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Various: supervised (logistic/linear regression, SVM, random forests, gradient boosting, RSF), unsupervised (k-means, hierarchical clustering, PCA, t-SNE), deep learning (DCNN), transfer learning, ensemble methods, feature selection (LASSO, Elastic Net)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>The review outlines method families, typical preprocessing (imputation, normalization, feature engineering), training/validation frameworks (train/validation/test splits, cross-validation), hyperparameter tuning, ensembling to reduce variance, and transfer learning for imaging with small datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised, unsupervised, deep learning, transfer learning, ensemble methods (review covers multiple categories)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable across many rheumatology tasks (subgrouping, prognosis, imaging diagnosis, multi-omics integration) but contingent on representative, sufficiently large, and high-quality datasets and appropriate validation; regulatory, privacy, and deployment challenges noted.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Review reports promising results in several illustrative cases (e.g., high AUCs in imaging transfer learning, RSF prognostic models with external validation), but emphasizes pitfalls: overfitting, data quality, lack of reproducibility when randomness and hyperparameters are not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High — potential to transform diagnostics, prognostics, patient stratification, and drug discovery in rheumatology, but realization requires interdisciplinary collaboration, data standardization, and rigorous validation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>The review contrasts ML's prediction-focused, hypothesis-free approaches with traditional statistics' inference-focused, parsimonious models; suggests using ML when generalization and pattern discovery in high-dimensional data are priority, but cautions integration with established statistical guidelines.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Representative, labeled, and high-quality datasets; aggressive quality control and preprocessing; appropriate model selection and validation (external cohorts when possible); reporting reproducibility details (tools, seeds, hyperparameters); interdisciplinary teams combining domain and ML expertise.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>ML methods can extract clinically and biologically meaningful patterns from heterogeneous, high-dimensional rheumatology data, but their effectiveness depends critically on data quality, adequate sample size, careful validation, and interpretability for clinical adoption.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Application of machine learning in rheumatic disease research', 'publication_date_yy_mm': '2019-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Identification of three rheumatoid arthritis disease subtypes by machine learning integration of synovial histologic features and RNA sequencing data. <em>(Rating: 2)</em></li>
                <li>Development and validation of a multivariate predictive model for rheumatoid arthritis mortality using a machine learning approach. <em>(Rating: 2)</em></li>
                <li>Deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks. <em>(Rating: 2)</em></li>
                <li>The development of a machine learning inpatient acute kidney injury prediction model <em>(Rating: 2)</em></li>
                <li>Predicting hospitalization and outpatient corticosteroid use in inflammatory bowel disease patients using machine learning <em>(Rating: 1)</em></li>
                <li>Short-term prediction of mortality in patients with systemic lupus erythematosus: classification of outcomes using random forests <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2298",
    "paper_id": "paper-58576290",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "RA_synovial_subtyping_SVM",
            "name_full": "Support Vector Machine applied to synovial histologic and RNA-seq driven rheumatoid arthritis subtyping",
            "brief_description": "Integration of synovial histologic features and RNA-sequencing to identify molecular/histologic RA subtypes via unsupervised clustering followed by an SVM classifier to map histology to genomic subgroups.",
            "citation_title": "Identification of three rheumatoid arthritis disease subtypes by machine learning integration of synovial histologic features and RNA sequencing data.",
            "mention_or_use": "use",
            "scientific_problem_domain": "Rheumatology / rheumatoid arthritis; molecular and histologic patient stratification",
            "problem_description": "Detect biologically and clinically meaningful synovial tissue subtypes (high-inflammatory, low-inflammatory, mixed) using gene expression and histology to enable better characterization of RA heterogeneity and potential links to clinical parameters.",
            "data_availability": "Limited/small for the analyzed set: histologic features from 129 synovial samples (123 RA, 6 OA) and gene-expression (the 500 most variable genes) from 45 synovial samples (39 RA, 6 OA). Labeled by domain experts for histology; genomic data labeled by clustering results. Data quality not ideal for large-scale generalization; no independent genomic validation dataset reported.",
            "data_structure": "Multimodal: structured tabular histologic feature counts/scores and high-dimensional gene-expression vectors (RNA-seq-derived features); relatively low sample count with high feature dimensionality.",
            "problem_complexity": "High dimensionality and heterogeneity (many gene features vs few samples), non-linear relationships between molecular profiles and histology, risk of overfitting due to small sample size and mixed disease types (RA and OA).",
            "domain_maturity": "Emerging application within RA research; established clinical/histologic measures exist but molecular subtyping in RA is still developing with limited large-scale validation.",
            "mechanistic_understanding_requirements": "Medium to high — interpretation is important (linking histologic patterns to clinical measures and biology), so explainability and validation are needed rather than opaque black-box outputs.",
            "ai_methodology_name": "k-means clustering (unsupervised) + Support Vector Machine (supervised classification)",
            "ai_methodology_description": "Unsupervised k-means clustering on the most variable genes to identify three genomic subgroups; principal component analysis used to validate clustering structure; a leave-one-out cross-validated SVM classifier trained on histologic features to predict genomic subtype labels (SVM aimed to separate classes with maximal margin). Details such as SVM kernel type and hyperparameters were not fully specified in the review summary.",
            "ai_methodology_category": "Unsupervised learning (clustering) followed by supervised learning (SVM classification)",
            "applicability": "Appropriate for subgroup discovery and mapping histology to molecular labels; however, constrained by small sample sizes and mixed-case samples (RA and OA) which limit generalizability. Requires larger, independent datasets for broader applicability.",
            "effectiveness_quantitative": "Classifier AUC for separating high-inflammatory subtype: 0.88; for low-inflammatory subtype: 0.71. (Reported in the cited study.)",
            "effectiveness_qualitative": "Qualitatively useful — histologic subtypes correlated with clinical features (ESR, CRP, autoantibodies). But the study is vulnerable to overfitting and limited by small sample size and lack of independent validation for genomic clustering.",
            "impact_potential": "Potential to enable histology-based proxies for molecular subtypes (practical for clinical pathology), improving patient stratification and tailoring therapies; impact contingent on external validation and larger cohorts.",
            "comparison_to_alternatives": "Not directly compared to other classifiers in the review; authors noted potential overfitting of SVM and recommended more detailed method reporting and independent validation.",
            "success_factors": "Integration of multimodal data (histology + RNA-seq), domain expert labeling of histologic features, and use of cross-validation; limitations include small sample size, mixed RA/OA samples, and incomplete reporting of classifier hyperparameters.",
            "key_insight": "Combining unsupervised gene-expression clustering with supervised histology-based SVM classification can reveal clinically meaningful RA synovial subtypes, but small, heterogeneous datasets and limited validation constrain reliability and generalizability.",
            "uuid": "e2298.0",
            "source_info": {
                "paper_title": "Application of machine learning in rheumatic disease research",
                "publication_date_yy_mm": "2019-07"
            }
        },
        {
            "name_short": "RA_mortality_RSF",
            "name_full": "Random Survival Forest for prediction of mortality in rheumatoid arthritis",
            "brief_description": "Non-parametric ensemble method (random survival forest) applied to time-to-event mortality prediction in RA using clinical and demographic features, externally validated across independent cohorts.",
            "citation_title": "Development and validation of a multivariate predictive model for rheumatoid arthritis mortality using a machine learning approach.",
            "mention_or_use": "use",
            "scientific_problem_domain": "Rheumatology / prognosis modelling of rheumatoid arthritis mortality",
            "problem_description": "Predict mortality risk (time-to-event) in RA patients using demographic and clinical variables, addressing potential violation of Cox proportional hazards assumptions and capturing non-linear interactions.",
            "data_availability": "Moderate/adequate: two independent cohorts used — HCSC-RAC training cohort with 1,461 patients and PEARL validation cohort with 280 patients; data were structured clinical/demographic variables and longitudinal outcomes.",
            "data_structure": "Structured tabular clinical and demographic data (clinical variables, lab summaries); time-to-event (survival) data.",
            "problem_complexity": "Moderate: involves non-linear relationships and potential interactions among many clinical features; survival analysis increases complexity relative to plain classification/regression.",
            "domain_maturity": "Relatively mature in terms of clinical data availability and existing models (e.g., Cox models), but ML survival forests are a more recent approach for this domain.",
            "mechanistic_understanding_requirements": "Medium — prognostic models used for clinical risk stratification require interpretability to identify key risk factors; RSF provides variable importance metrics but is less mechanistic than explicit statistical models.",
            "ai_methodology_name": "Random Survival Forest (RSF)",
            "ai_methodology_description": "An ensemble of decision trees adapted for censored time-to-event data using bootstrap aggregation (bagging); multiple runs (100 runs) with many trees per run (1,000 trees) to stabilize estimates; variable importance measures derived to identify key predictors (age at diagnosis, median ESR, number of hospital admissions).",
            "ai_methodology_category": "Supervised learning — ensemble methods for survival analysis",
            "applicability": "Well-suited: RSF handles non-linearities and interactions and does not assume proportional hazards; applicable to survival data with censoring and moderate sample sizes. Requires adequate sample size for stable tree ensembles.",
            "effectiveness_quantitative": "Reported prediction error: 0.187 (training cohort) and 0.233 (validation cohort). Important predictors matched those from prior Cox model analyses.",
            "effectiveness_qualitative": "Qualitatively effective — performed reasonably with external validation and produced interpretable variable importance consistent with prior knowledge; advantages over Cox when proportional hazards assumption may be violated.",
            "impact_potential": "Enables improved, flexible prognostic modeling in RA potentially informing clinical decision-making and risk stratification; external validation increases translational potential.",
            "comparison_to_alternatives": "Compared conceptually to Cox proportional hazards models; RSF highlighted as attractive alternative when proportional hazards assumptions are violated, and importance measures aligned with Cox model findings.",
            "success_factors": "Large enough training cohort, use of an independent validation cohort, ensemble averaging to reduce variance, and selection of relevant clinical predictors contributed to robust performance.",
            "key_insight": "RSF can effectively model non-linear, interacting predictors in survival tasks for RA and, when externally validated, offer practical prognostic performance with variable-importance outputs that align with clinical knowledge.",
            "uuid": "e2298.1",
            "source_info": {
                "paper_title": "Application of machine learning in rheumatic disease research",
                "publication_date_yy_mm": "2019-07"
            }
        },
        {
            "name_short": "DCNN_transfer_TB",
            "name_full": "Deep Convolutional Neural Networks with transfer learning for chest radiograph tuberculosis classification",
            "brief_description": "Use of deep convolutional neural networks (AlexNet and GoogLeNet) pretrained on ImageNet (transfer learning) to classify pulmonary tuberculosis from chest X-rays with high AUC.",
            "citation_title": "Deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks.",
            "mention_or_use": "use",
            "scientific_problem_domain": "Medical imaging / infectious disease radiology (pulmonary tuberculosis detection)",
            "problem_description": "Automatically detect pulmonary tuberculosis from standard chest radiographs using image-based deep learning to support diagnostic screening.",
            "data_availability": "Moderate — the study leveraged chest radiograph datasets, but the review specifies limited clinical dataset context; transfer learning employed because target dataset size was small relative to model complexity.",
            "data_structure": "Unstructured image data (2D chest radiographs) suitable for convolutional neural networks; images may be labeled (tuberculosis vs normal).",
            "problem_complexity": "High in feature representation (complex visual patterns), but lower in label space (binary classification); requires handling of intra-class variability, imaging artifacts, and limited labeled examples.",
            "domain_maturity": "Imaging diagnostics is mature; application of deep learning is emerging but rapidly advancing with established best practices (transfer learning common).",
            "mechanistic_understanding_requirements": "Low to medium — clinical deployment benefits from explainability, but high raw predictive performance (sensitivity/specificity) is often primary; visualization tools can aid interpretation.",
            "ai_methodology_name": "Deep Convolutional Neural Networks (AlexNet, GoogLeNet) with transfer learning",
            "ai_methodology_description": "Pretrained AlexNet and GoogLeNet models (trained on ImageNet) were fine-tuned on chest radiograph data (transfer learning) to leverage learned low- and mid-level image features; training adapted to smaller radiograph dataset to prevent overfitting; evaluation used AUC metrics.",
            "ai_methodology_category": "Supervised learning — deep learning with transfer learning",
            "applicability": "Highly applicable: transfer learning allowed use of powerful DCNN architectures despite limited domain-specific image data; suitable for image classification tasks in clinical radiology.",
            "effectiveness_quantitative": "Reported AUC of 0.99 for tuberculosis vs normal classification using DCNN transfer learning (as cited in the review).",
            "effectiveness_qualitative": "Extremely high reported discriminative performance in this task; transfer learning from ImageNet proved effective at capturing informative imaging features for TB detection despite domain differences.",
            "impact_potential": "High — could enable automated triage/screening in settings with limited radiologist availability, speed up diagnosis, and reduce workload; generalizable approach for other imaging tasks.",
            "comparison_to_alternatives": "Compared implicitly to training from scratch (which would be data-hungry) — transfer learning preferred when target dataset is small; DCNNs outperform many classical image-processing pipelines.",
            "success_factors": "Use of large-scale pretraining (ImageNet), selection of proven DCNN architectures, and appropriate fine-tuning on domain images; transfer learning mitigates small-target-dataset limitations.",
            "key_insight": "Transfer learning with pretrained deep convolutional networks can achieve near-perfect classification on certain medical imaging tasks even with limited labeled domain data, provided domain-relevant fine-tuning and careful evaluation are performed.",
            "uuid": "e2298.2",
            "source_info": {
                "paper_title": "Application of machine learning in rheumatic disease research",
                "publication_date_yy_mm": "2019-07"
            }
        },
        {
            "name_short": "AKI_GBM_prediction",
            "name_full": "Gradient Boosting Machine for inpatient acute kidney injury prediction",
            "brief_description": "Application of a gradient boosting machine to predict inpatient acute kidney injury (AKI) using clinical and laboratory features over a very large number of hospital admissions.",
            "citation_title": "The development of a machine learning inpatient acute kidney injury prediction model",
            "mention_or_use": "use",
            "scientific_problem_domain": "Nephrology / clinical risk prediction for acute kidney injury in hospitalized patients",
            "problem_description": "Early prediction of inpatient AKI to enable preventative interventions by modeling risk from routine clinical and laboratory measurements.",
            "data_availability": "Abundant: study used 121,158 admissions (large-scale electronic health record data) with 36 clinical and laboratory features; data are structured but can be noisy and heterogeneous.",
            "data_structure": "Structured tabular EHR data and time-indexed clinical/lab measurements; large sample size but potential missingness and heterogeneity across records.",
            "problem_complexity": "Moderate-to-high: temporal dynamics (labs over time), many interacting features, class imbalance (AKI events rarer than non-events), and need to handle missing/inconsistent EHR data.",
            "domain_maturity": "Mature in terms of clinical measurement availability; ML approaches for AKI prediction are emergent and have demonstrated promise across large datasets.",
            "mechanistic_understanding_requirements": "Medium — clinicians require interpretable risk drivers for actionability; black-box predictions might be useful for alerts but require explainability for trust.",
            "ai_methodology_name": "Gradient Boosting Machine (GBM)",
            "ai_methodology_description": "An ensemble of decision-tree based learners trained sequentially to correct predecessor errors (gradient boosting), using clinical and lab features; suited to tabular data and handling non-linearities and interactions; details on hyperparameters were not given in the review summary.",
            "ai_methodology_category": "Supervised learning — ensemble boosting methods",
            "applicability": "Highly applicable given large structured EHR dataset; GBM handles heterogeneous tabular features and learns complex relationships without strong parametric assumptions.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Described as successful in development of a predictive model for inpatient AKI on a very large dataset, but specific performance metrics are not reported in the review's summary.",
            "impact_potential": "Significant — early AKI prediction could reduce morbidity through earlier interventions, improve patient safety, and decrease length-of-stay/costs if integrated into clinical workflows.",
            "comparison_to_alternatives": "Not detailed in the review; GBM commonly outperforms single-tree methods and logistic regression on similar tabular clinical tasks, but explicit comparisons were not provided here.",
            "success_factors": "Very large sample size, rich feature set, and method suitability for tabular clinical data; challenges include data quality, missingness, and deployment/integration into clinical systems.",
            "key_insight": "Gradient boosting is a practical, effective approach for large-scale EHR-based risk prediction tasks (like AKI) owing to its ability to model non-linear interactions in structured clinical data, but performance depends critically on data quality and clinical integration.",
            "uuid": "e2298.3",
            "source_info": {
                "paper_title": "Application of machine learning in rheumatic disease research",
                "publication_date_yy_mm": "2019-07"
            }
        },
        {
            "name_short": "IBD_RF_prediction",
            "name_full": "Random Forests for prediction of hospitalization and corticosteroid use in inflammatory bowel disease",
            "brief_description": "Random forest models applied to predict hospitalization and outpatient corticosteroid use in a large IBD patient cohort using clinical and laboratory features.",
            "citation_title": "Predicting hospitalization and outpatient corticosteroid use in inflammatory bowel disease patients using machine learning",
            "mention_or_use": "use",
            "scientific_problem_domain": "Gastroenterology / inflammatory bowel disease management and risk prediction",
            "problem_description": "Predict near-term adverse outcomes (hospitalization and corticosteroid use) to guide management decisions in IBD patients.",
            "data_availability": "Large: dataset comprised 20,368 patients with over 30 clinical and laboratory features; data likely labeled for outcomes of interest; EHR-derived data with potential heterogeneity.",
            "data_structure": "Structured tabular clinical and laboratory features extracted from EHRs; possibly temporal but used as aggregated features in the model.",
            "problem_complexity": "Moderate: multiple interacting clinical features and event imbalances; requires handling missing data and variable measurement intervals.",
            "domain_maturity": "Clinical domain mature; ML application is becoming established for outcome prediction in chronic disease management.",
            "mechanistic_understanding_requirements": "Medium — clinicians require understanding of risk drivers to act; random forests provide variable importance but are less interpretable than simple models.",
            "ai_methodology_name": "Random Forest",
            "ai_methodology_description": "Bagged ensemble of decision trees trained on bootstrapped samples with random feature selection at splits; robust to overfitting and able to capture non-linear interactions among features; used to predict binary/conditional outcomes in EHR data.",
            "ai_methodology_category": "Supervised learning — ensemble tree methods",
            "applicability": "Appropriate for tabular clinical prediction tasks with many features and potential non-linearities; benefits from large cohort size.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Reported as a successful application to predict clinical outcomes in a sizable dataset, though the review did not include specific performance metrics.",
            "impact_potential": "Potential to assist in proactive care management, reduce unplanned hospitalizations, and tailor outpatient interventions if integrated into clinical workflows.",
            "comparison_to_alternatives": "Not explicitly described in the review; random forests often compared favorably to single-model baselines, but details absent here.",
            "success_factors": "Large labeled cohort, diverse feature set, and an algorithm robust to noisy EHR data; caveats include EHR data quality and need for external validation and calibration.",
            "key_insight": "Random forests are a practical, robust choice for EHR-derived outcome prediction in chronic disease cohorts, leveraging large patient numbers to learn non-linear risk patterns though model interpretability and data quality remain important constraints.",
            "uuid": "e2298.4",
            "source_info": {
                "paper_title": "Application of machine learning in rheumatic disease research",
                "publication_date_yy_mm": "2019-07"
            }
        },
        {
            "name_short": "ML_in_Rheumatology_review",
            "name_full": "Review of Machine Learning applications in rheumatic disease research (this paper)",
            "brief_description": "A critical review summarizing ML/AI methods used in clinical data analysis relevant to rheumatology, discussing advantages, limitations, data issues, and illustrative domain applications.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "Rheumatology broadly (diagnosis, prognostics, subgroup discovery, imaging, multi-omics integration)",
            "problem_description": "Survey and synthesis of how ML methods can address heterogeneity, high-dimensional multi-omics and imaging data, prediction of outcomes, and patient stratification in rheumatic diseases.",
            "data_availability": "Varies by task: can range from scarce (small synovial RNA-seq cohorts) to abundant (large EHR/claims datasets); review emphasizes common issues: heterogeneity, missingness, labeling inconsistencies, and need for quality control.",
            "data_structure": "Multimodal — structured EHR/clinical/laboratory tabular data, unstructured text (EMRs), high-dimensional molecular data (gene expression), and imaging (histology, radiography); often high-dimensional and heterogeneous.",
            "problem_complexity": "High: clinical heterogeneity, multi-scale features (molecular to clinical), non-linear interactions, longitudinal/time-to-event outcomes, and potentially high-dimensional low-sample-size regimes in omics.",
            "domain_maturity": "Mixed — clinical rheumatology is established, but molecular stratification and ML-driven precision medicine are emerging and require more standardized data and external validation.",
            "mechanistic_understanding_requirements": "Medium to high — interpretability often required for clinical acceptance and mechanistic insight; review stresses that ML results must be contextualized with biological/clinical understanding.",
            "ai_methodology_name": "Various: supervised (logistic/linear regression, SVM, random forests, gradient boosting, RSF), unsupervised (k-means, hierarchical clustering, PCA, t-SNE), deep learning (DCNN), transfer learning, ensemble methods, feature selection (LASSO, Elastic Net)",
            "ai_methodology_description": "The review outlines method families, typical preprocessing (imputation, normalization, feature engineering), training/validation frameworks (train/validation/test splits, cross-validation), hyperparameter tuning, ensembling to reduce variance, and transfer learning for imaging with small datasets.",
            "ai_methodology_category": "Supervised, unsupervised, deep learning, transfer learning, ensemble methods (review covers multiple categories)",
            "applicability": "Applicable across many rheumatology tasks (subgrouping, prognosis, imaging diagnosis, multi-omics integration) but contingent on representative, sufficiently large, and high-quality datasets and appropriate validation; regulatory, privacy, and deployment challenges noted.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Review reports promising results in several illustrative cases (e.g., high AUCs in imaging transfer learning, RSF prognostic models with external validation), but emphasizes pitfalls: overfitting, data quality, lack of reproducibility when randomness and hyperparameters are not reported.",
            "impact_potential": "High — potential to transform diagnostics, prognostics, patient stratification, and drug discovery in rheumatology, but realization requires interdisciplinary collaboration, data standardization, and rigorous validation.",
            "comparison_to_alternatives": "The review contrasts ML's prediction-focused, hypothesis-free approaches with traditional statistics' inference-focused, parsimonious models; suggests using ML when generalization and pattern discovery in high-dimensional data are priority, but cautions integration with established statistical guidelines.",
            "success_factors": "Representative, labeled, and high-quality datasets; aggressive quality control and preprocessing; appropriate model selection and validation (external cohorts when possible); reporting reproducibility details (tools, seeds, hyperparameters); interdisciplinary teams combining domain and ML expertise.",
            "key_insight": "ML methods can extract clinically and biologically meaningful patterns from heterogeneous, high-dimensional rheumatology data, but their effectiveness depends critically on data quality, adequate sample size, careful validation, and interpretability for clinical adoption.",
            "uuid": "e2298.5",
            "source_info": {
                "paper_title": "Application of machine learning in rheumatic disease research",
                "publication_date_yy_mm": "2019-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Identification of three rheumatoid arthritis disease subtypes by machine learning integration of synovial histologic features and RNA sequencing data.",
            "rating": 2,
            "sanitized_title": "identification_of_three_rheumatoid_arthritis_disease_subtypes_by_machine_learning_integration_of_synovial_histologic_features_and_rna_sequencing_data"
        },
        {
            "paper_title": "Development and validation of a multivariate predictive model for rheumatoid arthritis mortality using a machine learning approach.",
            "rating": 2,
            "sanitized_title": "development_and_validation_of_a_multivariate_predictive_model_for_rheumatoid_arthritis_mortality_using_a_machine_learning_approach"
        },
        {
            "paper_title": "Deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks.",
            "rating": 2,
            "sanitized_title": "deep_learning_at_chest_radiography_automated_classification_of_pulmonary_tuberculosis_by_using_convolutional_neural_networks"
        },
        {
            "paper_title": "The development of a machine learning inpatient acute kidney injury prediction model",
            "rating": 2,
            "sanitized_title": "the_development_of_a_machine_learning_inpatient_acute_kidney_injury_prediction_model"
        },
        {
            "paper_title": "Predicting hospitalization and outpatient corticosteroid use in inflammatory bowel disease patients using machine learning",
            "rating": 1,
            "sanitized_title": "predicting_hospitalization_and_outpatient_corticosteroid_use_in_inflammatory_bowel_disease_patients_using_machine_learning"
        },
        {
            "paper_title": "Short-term prediction of mortality in patients with systemic lupus erythematosus: classification of outcomes using random forests",
            "rating": 1,
            "sanitized_title": "shortterm_prediction_of_mortality_in_patients_with_systemic_lupus_erythematosus_classification_of_outcomes_using_random_forests"
        }
    ],
    "cost": 0.01751975,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Application of machine learning in rheumatic disease research</p>
<p>M.D.Ki-Jo Kim 
Ki-Jo Kim 
Division of Rheumatology
Department of Internal Medicine
College of Medicine
The Catholic University of Korea
SeoulKorea</p>
<p>Ilias Tagkopoulos 
Department of Computer Science</p>
<p>Genome Center
Division of Rheumatology
Department of Internal Medicine
College of Medicine, St. Vincent's Hospital
University of California
DavisCAUSA</p>
<p>The Catholic University of Korea
93 Jungbu-daero, Paldal-gu16247SuwonKorea</p>
<p>Application of machine learning in rheumatic disease research
10.3904/kjim.2018.349Received : September 23, 2018 Accepted : November 18, 2018 Correspondence toREVIEW Korean J Intern Med 2019;34:708-722RheumatologyMachine learningPrediction
Over the past decade, there has been a paradigm shift in how clinical data are collected, processed and utilized. Machine learning and artificial intelligence, fueled by breakthroughs in high-performance computing, data availability and algorithmic innovations, are paving the way to effective analyses of large, multi-dimensional collections of patient histories, laboratory results, treatments, and outcomes. In the new era of machine learning and predictive analytics, the impact on clinical decision-making in all clinical areas, including rheumatology, will be unprecedented. Here we provide a critical review of the machine-learning methods currently used in the analysis of clinical data, the advantages and limitations of these methods, and how they can be leveraged within the field of rheumatology.</p>
<p>INTRODUCTION</p>
<p>Machine learning (ML) is a field of computer science that aims to create predictive models from data. It makes use of algorithms, methods and processes to uncover latent associations within the data and to create descriptive, predictive or prescriptive tools that exploit those associations [1]. It is often related to data mining [2], pattern recognition [3], artificial intelligence (AI) [4], and deep learning (DL) [5]. Although there are no clear definitions or boundaries among these areas and they often overlap, it is generally agreed that DL is a more recent sub-field of ML that uses computationally intensive algorithms and big data [6] to capture complex relationships within the data. Using multi-layered artificial neural networks, DL has dramatically improved the state-of-the-art in a variety of applications, including speech and visual object recognition, machine translation, natural language processing, and text automation [5,7]. Similarly, AI is broader than ML in that it uses the latter as a prediction engine feeding decision support and recommendation systems that are more than the sum of their parts. AI has been around for more than 70 years, born out of our appreciation and admiration of the power and inner workings of human intelligence [8]. Moreover, ML and AI are already part of our everyday lives, as they underlie our web searches [9], e-mail anti-spam filters [10], hotel and airline bookings [11], language translators [12], targeted advertising [13], and many other services [14]. Lately, ML and AI have captured the world's imagination in applications involving various complex games, with one of the most celebratwww.kjim.org https://doi.org/10.3904/kjim.2018.349 ed cases being the GO match held in 2016 between Sedol Lee, one of the top GO players in the world, and the computer program AlphaGo [5]. Fig. 1 provides a grouping of the different fields related to ML and AI.</p>
<p>The concept of ML dates to the 1940s but its development since the 1990s has been rapidly accelerated by the confluence of four key factors: the digitalization and storage of a massive amount of high-dimensional data at low cost; the development of general and graphic processors with high computational power; breakthroughs in ML algorithms that have significantly improved performance and minimized errors; and the free availability of open-source tools, codes, and models. In a clinical setting, ML and AI tools can help physicians ton understand a disease better and more accurately evaluate patients' status based on high-throughput molecular and imaging techniques, which at the same time reveal the complexity and heterogeneity of the disease [15][16][17]. Nonetheless, equal to the promise of ML/AI are the potential dangers that may arise if too much trust is placed in automated diagnosis and decision tools. As a cautionary tale, the concordance between IBM's Wat-son for Oncology [18] and an expert board of oncologists was highly variable, with a range of 17.8% to 97.9% depending on the tumor type, stage, hospital, and country [19]. Moreover, in recent news, the tool reportedly recommended unsafe cancer treatment plans [20]. Therefore, a thorough understanding and judicious approaches to ML are required to ensure its reasonable use in research and clinical practice. This is especially apparent given the complex nature of medicine, which involves the interactive combination of clinical and biological features in disease manifestation and diagnosis; a continuous inflow of new medical tools and drugs; socio-economic factors, such as the permission to treat that must be obtained from insurance companies; drug regulation and release by the regulatory agencies of the various countries; and ethical issues dealing with the use of electronic medical records (EMRs  gan involvement. Complex interactions between a multitude of environmental and genetic factors affect disease development and progression [21,22]. In view of their heterogeneity, most rheumatic diseases are not defined as a single entity but as a single group according to established classification criteria [21,22]. Previous risk-prediction models for disease development and outcome based on population-wide databases work well on average, but in terms of precision medicine many of the diagnostic and management needs of patients with rheumatic diseases are still unmet [23,24]. In this setting, ML can suggest effective solutions for the unsettled issues arising from complex and heterogeneous diseases such as rheumatic diseases [16]. ML applications in multi-omics datasets were examined in detail in a series of recent reviews [7,[25][26][27][28][29], and the superb performance of DL in image analysis has been the focus of recent papers [30][31][32][33]. Here we review the core principles and processes of ML that are applicable to clinical medicine as well as the current use of ML in research on rheumatic diseases. Our aim is to help clinicians and rheumatologists to understand better the basics of ML and its relevant research applications.</p>
<p>THE BASICS OF MACHINE LEARNING</p>
<p>Differences from traditional statistical models</p>
<p>There are substantial differences between ML and traditional statistics. First, ML concentrates on the task of "prediction," by using general-purpose learning algorithms to find patterns in often rich and unwieldy data. By contrast, statistical methods have a long-standing focus on inference, which is achieved through the creation and fitting of a project-specific probability model [34]. Second, most ML techniques are hypothesis-free, as their aim is to reconstruct associations within the data, whereas traditional statistics usually rely on specific assumptions and hypotheses, often those stemming from the model that has generated the data [35]. Third, the toolsets used to evaluate the generalization errors of an ML model (receiver-operating characteristic curves, cross-validation, among others) are generally different from those of traditional statistical techniques, which mostly rely on a calculation of the p value to reject a null hypothesis [34,36,37]. Fourth, traditional statistical modeling is generally fitted to produce the simplest, most parsimonious model and yields a result that is easy to understand and interpret. However, clinical and biological factors are usually not independent of each other and their associations may be non-linear. ML approaches, however, consider all possible interactions between variables according to multi-dimensional non-linear patterns, irrespective of the degree of complexity, while aggressively seeking to capture as many informative and interesting features as possible. Nonetheless, by the same token, this can produce a complicated and sophisticated model that is not easy to understand or interpret. Fifth, it is often the case that the results of clinical studies are not consistent across studies, due to differences in the characteristics of the study population, the sample size or the measured variables (number, scale, and method). This is partly because traditional models seek a goodness of fit in a set of study samples. By contrast, the fundamental goal of ML is to generalize beyond the examples in the training set. Generalization is feasible because the models derive from a much larger dataset, are then validated in an independent dataset and further tuned to obtain the best performance [38,39].</p>
<p>Types of machine learning</p>
<p>There are many types of ML algorithms, as shown in Fig. 2. One of the most widely used categorizations separates them into three classes: supervised, unsupervised, and reinforcement learning.</p>
<p>Supervised learning</p>
<p>Supervised learning searches for the relationship between a set of features (input variables) and one or more known outcomes (output classes or labels) and then derives a function that predicts the output value for a set of unlabeled input values based on an acceptable degree of fidelity [17,36,37]. For supervised learning to work, the training data should have the correct input-output pairs, which should be labeled by experts. Supervised learning includes both classification, where the task is to predict the group or class to which a new sample should be assigned (hence the output is a discrete variable), and regression, where the value of a continuous variable for a new sample must be estimated. can predict the treatment response in patients with RA treated with a specific therapy, researchers can apply a supervised learning algorithm to a dataset in which each patient record contains the set of clinical features of interest and a label specifying the degree of disease responsiveness (e.g., "good," "moderate," "no" response, in conformity with the EULAR response criteria) [40]. Supervised learning algorithms include logistic and linear regression, naïve Bayesian classifiers, decision trees and random forests, support vector machines (SVMs), k-nearest neighbors, and neural networks [17,36,37].</p>
<p>Unsupervised learning</p>
<p>Unsupervised learning is a sub-field of ML that attempts to identify the structure in the data without the need for a training set, classes, or labels [17,36,37]. In the medical field, an example would be to identify hidden subsets of patients with similar clinical or molecular characteristics as described in the data. For example, patients with diffuse-type systemic sclerosis can be further categorized as having inflammatory, fibroproliferative, or normal-like disease based on their skin's molecular signature [41,42]. The significance of this additional grouping can be further evaluated by determining correlations with clinical features and performance in subsequent supervised learning tasks.</p>
<p>Unsupervised learning algorithms include clustering methods such as hierarchical or k-means clustering, principal component analysis, t-distributed stochastic neighbor embedding (t-SNE), non-negative matrix factorization, and latent class analysis [17,36,37,43].</p>
<p>Reinforcement learning</p>
<p>Reinforcement learning is an area of ML that is based on behavioral psychology, namely, how software agents take actions in a particular environment to maximize the cumulative reward [39]. The best example is game theory and the above-mentioned AlphaGo, which places a stone at a specific position on the board at a certain point in the game to maximize the winning rate [44]. A similar method was also used to select the best initial time for second-line therapy in patients with non-small cell lung cancer [45]. However, although it has great potential, reinforcement learning is not often applied to clinical settings, as it needs rigorously defined clinical states, observations (vitals, lab results, among others), and actions (treatment) and rewards, which are quite difficult to define and are sometimes unknown.</p>
<p>Transfer learning</p>
<p>Transfer learning is the improvement of the learning of a new task through the transfer of knowledge from a related task that has already been learned [46]. The assumption is that a model pre-trained in a dataset that has some similarities with the final dataset, i.e., the one that will ultimately be used for training, will perform better and be trained faster than if the model is exposed only to the latter. The two conditions under which this assumption holds true are: (1) the final dataset is much smaller than what is dictated by both the task at hand and the complexity of the model and (2) the pre-training dataset and the final dataset have some commonalities that are informative for that task. For example, assume that a model is to be trained to recognize black swans in images but only a few dozen images of swans of any kind are available; hence, the dataset is sufficient to train only the simplest of neural networks.</p>
<p>In an alternative approach, large datasets comprising hundreds of thousands of images of birds in general can be substituted to pre-train the classifier to recognize birds. This pre-trained "bird" classifier can then be taught, using the key informative features of a bird (feathers, wings, beak, etc.), to recognize black swans from other items, including other birds. In a more relevant study for clinicians, Lakhani and Sundaram [47] adopted two famous deep convolutional neural network (DCNN) models for image classification, AlexNet [48] and GoogLeNet [49], pretrained on ImageNet [50], to differentiate pulmonary tuberculosis from the normal condition on a simple chest radiograph. DL with a DCNN accurately classified tuberculosis with an area under the curve (AUC) of 0.99.</p>
<p>SALIENT POINTS TO CONSIDER WHEN RUN-NING MACHINE LEARNING</p>
<p>Medical or healthcare data can be presented in a table consisting of two components: rows of samples (observations or instances) and columns of features (variables or attributes). A schematic diagram of a supervised ML process is provided in Fig. 3. In data science, a programmed machine or model type is called a "learner." In the following we discuss several points that should be kept in mind when ML is used.</p>
<p>Data quantity, quality, and their control</p>
<p>In ML, the data are of high dimensionality and the sample size is large, so-called Big Data. An exploration of each subgroup of the data can reveal hidden structures by extracting important common features across many subgroups even when there are large individual variations. This is not feasible when the sample size is small because outliers may be mistakenly identified [51]. However, Big Data, a term applicable to EMRs, are inevitably characterized by certain weaknesses [51][52][53].</p>
<p>High dimensionality brings noise accumulation, spurious correlations, and incidental endogeneity [51]. In  addition, because the massive samples in Big Data are typically aggregated from multiple sources at different times using different technologies, issues of heterogeneity, experimental variation, and statistical bias arise. Medical data are no exception, as there are clear differences between the formats used in EMRs, laboratory instruments, scales, assay reagents, and laboratory data notation methods. Furthermore, clinical and laboratory elements are often recorded incompletely or according to the preference of the particular doctor and therefore differently. In fact, the accuracy, completeness and comparability of EMR data were shown to vary from element to element by 10% to 90% [54]. The same disease code may be differently defined depending on the updated criteria, and coding errors inevitably occur because for the most part humans perform the recording. According to the Korean National Health Insurance claims database, true RA made up 91.4% of the total RA disease codes based on the RA identification algorithm [55]. Hence, to handle these challenges, aggressive quality control is needed [56], including data cleansing and refining techniques, such as error correction, removal of outliers, missing data interpolation, normalization, standardization, and de-batching. However, these processes rely on expert human judgment. Since even complex and sophisticated algorithms will not produce good results if the quality of the input data is poor, refinement of input data to improve their quality will provide better results even if the algorithm is less than optimal [37,57]. As has often been noted: "garbage in, garbage out" [58].</p>
<p>Data preprocessing</p>
<p>Raw data are usually not in a structure that is convenient for researchers to work with and not organized enough to be ready for ML. Data preprocessing refers to any transformation of the data before a learning algorithm is applied. It includes example finding and resolving inconsistencies; imputation of missing values; identifying, removing, or replacing outliers; discretizing numerical data or generating numerical dummy variables for categorical data; dimensionality reduction; feature extraction/selection; and feature scaling (normalization, standardization or Box-Cox transformation) [59]. Of these, feature scaling through standardization (or Z-score normalization) is an important preprocessing step for many ML algorithms. Predictor variables with ranges of different orders of magnitude can exert a disproportionate influence on the results. In other words, in the context of an algorithm, predictor variables with a greater range of scale may dominate. The scaling of feature values implicitly ensures equal weights of all features in their representation and should be the applied preprocessing approach in ML algorithms such as linear regression, SVM, and k-nearest neighbors [37].</p>
<p>Training, validation, and test datasets</p>
<p>For ML, the data are usually split into training, validation, and test datasets. The training dataset is the data sample used to fit the model. The validation dataset is the data sample used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters; it is regarded as a part of the training set. The test dataset is the data sample used to provide an unbiased evaluation of the fit that the final model achieved with the training dataset [36,37,60]. If the categorical variables are unbalanced, stratified sampling is favored. When a large amount of data is available, each set of samples can be set aside. However, if the number of samples is insufficient, removing data reduces the amount available for training. This can be mitigated by the use of resampling methods such as cross-validation and bootstrapping [60,61]. In general, a repeated 10-fold cross validation is recommended because of the low bias and variance properties of the performance estimate and the relatively low computational cost [37].</p>
<p>Bias-variance trade-off and overfitting</p>
<p>ML methods are often hindered by bias-variance trade-offs when a high-dimensional dataset with an inadequate number of samples is to be fitted [36,37,61]. Bias is the training error of the model; that is, the difference between the prediction value and the actual value. Models with a high bias tend to underfit, by applying a simpler model to describe a dataset of higher complexity. For example, if the goal is to capture the half-life relationship of protein degradation, a known non-linear process with exponential decay, the use of a linear model will not result in accurate prediction of protein levels at any time point, no matter how many training samples make up the dataset. By contrast, vari-ance expresses the sensitivity of the model to small perturbations in the input. A model of high variance will provide substantially different answers (output values) for small changes in the input, because of overfitting of its parameters to the training dataset at hand [61]. This prevents generalizations (and thus the ability of the model to perform well) to other datasets never seen by the model, i.e., those it has not been trained on. In general, variance increases and bias decreases with increasing model complexity [36,62].</p>
<p>Many ML algorithms are susceptible to overfitting because they have a strong propensity to fit the model to the dataset and minimize the loss function as much as possible. Because the goal of ML is to make the model generalizable from learning the training data, and not to obtain the best model well-fitted for the training data, proper measures should be taken depending on the type of algorithm. The most popular solutions for overfitting are training with more data of high-quality and the least amount of noise, cross-validation, early stopping, pruning (remove features), regularization, and ensembling [36,37,61,63]. The appropriate combination should be selected depending on the purpose of the study, the characteristics and size of the dataset, and the learner type.</p>
<p>Feature engineering and selection</p>
<p>Since features describe the sample's characteristics, more features imply a better understanding of the sample. However, in predictive modeling, too many features can impede learning because some may be irrelevant to the target of interest, less important than others or redundant in the context of other features. A "curse of dimensionality" occurs when the dimensionality of the data increases and the sparsity of the data increases [61]. It is statistically advantageous to estimate fewer parameters. In addition, researchers usually want to know the key informative features obtained with a simple model rather than work with a complex model that uses a large number of features to predict the outcome. In truth, processes that make the refined data amenable to learning, such as data cleaning, preprocessing, feature engineering and selection, are more essential than running a learner. However, this is a daunting task because it is manually tailored by domain experts in a time-consuming process [61]. Feature engineering is the process of transforming raw data such that the revised features better represent the problem that is of interest to the predictive model, resulting in improved model performance on new data. An example is to transform the counts of tender and/or swollen joints and the erythrocyte sedimentation rate (ESR) into a single formulated feature, Disease Activity Score (DAS28)-ESR, which better assesses disease activity in patients with RA. Feature selection is the process of selecting a subset of relevant features while pruning less-relevant features for use in model construction. There are three methods in feature selection algorithms: filter methods, wrapper methods, and embedded methods [37,64,65]. Filter methods involve the assignment of a score to each feature using a statistical measure followed by selection of high-ranked features based on the score. Filtering uses a preprocessing step and includes correlation coefficient scores, the pseudo-R 2 statistic and information gain. Wrapper methods evaluate multiple models using procedures that add and/or remove predictors to find the optimal combination that maximizes model performance. An example is the recursive feature elimination algorithm. Embedded methods perform variable selection in the process of training and are usually specific to certain learning machines. The most common type of embedded feature-selection method is the regularization method found in LASSO, Elastic Net, and Ridge regression. The features selected from the methods do not necessarily have a causal relationship with the target label, but simply provide critical information for use in predictive model construction.</p>
<p>Limitations of machine learning</p>
<p>ML has become ubiquitous and indispensable for solving complex problems in most sciences [16]. It can present novel findings or reveal previously hidden but important features that have been missed or overlooked in conventional studies using traditional statistics. However, those features might also be irrelevant, nonsensical, counterposed to the framework of current medical knowledge, or even cause confusion. This is because the results returned by ML are based solely on the input data. ML does not call the input data into question or explain why the results were obtained or their underlying mechanism. In the event of unexpect- ed results, the data should be re-investigated to determine whether human or technical errors have created biases, followed by careful interpretation and validation in the context of the disease.</p>
<p>ML models are fairly dependent on the data they are trained on or are called upon to analyze, and no model, regardless of its sophistication, can create a useful analysis from low-quality data [61,66]. As data are a product made in the past and represent existing knowledge, ML models are valid within the same framework of that knowledge and their performance will degrade if they are not regularly updated using new, emerging data. In the case of a supervised classifier, a common problem is that the classes that make up the target label are not represented equally. An imbalanced distribution of class sizes across samples favors learning weighted to the larger class size such that the trained model then preferably assigns a major class label to new instances thereof while ignoring or misclassifying minority samples, which, although they rarely occur, might be very important. Several methods have been devised to handle the imbalanced class issue [67,68].</p>
<p>Because the optimal algorithm, i.e., the one that best fits the data of interest, cannot be known beforehand, a reasonable strategy is to sequentially test simple and widely known learners before moving on to those that are more sophisticated and distinct. In some ML learners, hyperparameters should be tuned by exhaustively searching through a manually specified subset of the hyperparameter space of a learning algorithm [69].</p>
<p>Randomness is an inherit characteristic of ML applications [70], appearing in data collections, observation orders, weight assignments, and resampling, among others. To create stable, robust models with reproducible results, detailed information on the type and version of the computational tools, learners' parameters, hyperparameters and random seed number used should always be reported [71].</p>
<p>ILLUSTRATIVE EXAMPLES OF MACHINE LEARNING</p>
<p>Several representative clinical studies in which ML methods were used in the area of internal medicine are summarized in Table 1 [72][73][74][75][76][77][78][79][80][81][82][83][84][85][86]. In the study of rheu-matic diseases, ML has been employed only recently, but two of those studies are particularly noteworthy. In the first, Orange et al. [87] reported the identification of three distinct synovial subtypes based on the synovial gene signatures of patients with RA. These labels were used to design a histologic scoring algorithm in which the histologic scores correlated with clinical parameters such as ESR, C-reactive protein (CRP) level, and autoantibody titer [87]. The authors selected 14 histologic features from 129 synovial samples (123 RA and six osteoarthritis [OA] patients) and the 500 most variably expressed genes in 45 synovial samples (from 39 RA and six OA patients). Gene-expression-driven subgrouping was explored by k-means clustering, in which n objects are partitioned into k clusters, with each object belonging to the cluster with the nearest mean [88]. Clustering was most robust at 3 and this subgrouping was validated by principal component analysis, but not in an independent dataset. Three subgroups comprising high-inflammatory, low-inflammatory, and mixed subtypes, were designated based on their gene patterns and enriched ontology. The aim of the study was to determine the synchrony between synovial histologic features and genomic subtype, thereby yielding a convenient histology-based approach to characterization of synovial tissue. To this end, a leave-one-out cross-validation SVM classifier was implemented. The aim of an SVM is to find a decision hyperplane that separates data points of different classes with a maximal margin (i.e., the maximal distance to the nearest training data points) [89]. The model's performance in separating both the high and the low inflammatory subtypes from the other subtypes was relatively good (AUCs of 0.88 and 0.71, respectively). It should be noted that histologic subtypes are closely associated with clinical features, as significant increases in ESR, CRP levels, rheumatoid factor titer, and anti-cyclic citrullinated protein (CCP) titer in patients with high inflammatory scores were detected. However, this model might succumb to overfitting because SVM is vulnerable to overfitting [89,90], the sample size was too small (only 45 samples) and the model was not validated using an independent dataset. Moreover, the data samples were a mixture of RA and OA samples and there were no normal controls. SVM is an unsupervised ML with an efficient performance achieved using the kernel trick and the tuning of hy- perparameters. A better approach would be to specify the details of the model (kernel type, parameters, and hyperparameters) during method selection, to guarantee the reliability and reproducibility of the model. In the second, Lezcano-Valverde et al. [91] developed and validated a random survival forest (RSF) prediction model of mortality in RA patients based on demographic and clinically related variables. RSF, an extension of random forest for time-to-event data, is a non-parametric method that generates multiple decision trees using a bagging method [92,93]. Bagging, an abbreviation for bootstrap aggregation, is a simple and powerful ensemble method that fits multiple predictive models on random subsets of the original dataset and aggregates their individual predictions by either voting or averaging [94]. It is commonly used to reduce variance and avoid overfitting. RSF is an attractive alternative to the Cox proportional hazards model when the proportional hazards assumption is violated [93,95]. Lezcano-Valverde et al. [91] used two independent cohorts as the training and validation datasets: the RA cohort from the Hospital Clínico San Carlos (HCSC-RAC), consisting of 1,461 patients, and the 280 RA patients from the Hospital Universitario de La Princesa Early Arthritis Register Longitudinal (PEARL) study. Each model was run 100 times using 1,000 trees per run. The prediction error was 0.187 in the training cohort and 0.233 in the validation cohort. Important variables with a higher predictive capacity were age at diagnosis, median ESR and number of hospital admissions. These variables were consistent with those obtained in a previous result using a Cox proportional hazards model [96]. The strengths of the approach described in that study were external validation using an independent RA cohort and the absence of a restrictive assumption, which traditional Cox proportional hazards model rely on. RSF has also been used to analyze the mortality risk in patients with systemic lupus erythematosus [97] and in those with juvenile idiopathic inflammatory myopathies [98].</p>
<p>CONCLUSIONS</p>
<p>ML algorithms can accommodate diverse configurations of data, specify context weighting, and identify informative patterns that enable subgrouping or predictive modeling from every interaction of variables available for the assessment of diagnostic and prognostic elements. Extensive, in-depth applications of ML in biomedical science are increasing in number, and interesting results in the area of precision medicine have been obtained. However, several challenges must still be overcome. First, ML works only if the training data are representative of the problem to be solved, include informative features and are of sufficient quantity to train the model at hand. This can be difficult to achieve for both technical and real-world reasons. Second, privacy is a major concern in the collection of sensitive clinical data, which might limit the aggregation of all necessary information. Moreover, some data are expensive to acquire, reported in different formats and obtained using different methods and technologies. Third, because text-based medical records can be incoherent, distracted, and contain technical errors [52,53], expert human judgement is needed to review the data, detect any errors or problems and determine the clinical significance of any findings [35,99]. Finally, a consensus should be reached on how to integrate and coordinate ML results with previously established LASSO, least absolute shrinkage and selection operator; NKI, Netherlands Cancer Institute; VGH, Gancouver General Hospital. guidelines or recommendations that were based on traditional statistics. ML and AI will change the clinical landscape as we know it. From clinical decision support tools and personalized recommendation systems to the discovery of novel drugs and treatments, AI is poised to propel our world to unprecedented levels of automation, personalized service and accelerated R&amp;D cycles. Close collaboration and interdisciplinary teamwork between clinicians, biomedical informatics scientists, ML experts, and administrative stakeholders are a prerequisite to the achievement of satisfactory solutions amenable to a variety of clinical applications.</p>
<p>Figure 1 .
1An overview of fields related to learning from data. AI, artificial intelligence. 710 www.kjim.org https://doi.org/10.3904/kjim.</p>
<p>For example, to determine whether a set of clinical features www.kjim.org https://doi.org/10.3904/kjim.2018.349</p>
<p>Figure 2 .
2Overview of categorical types and different machine-learning algorithms. AI, artificial intelligence. https://doi.org/10.3904/kjim.</p>
<p>Figure 3 .
3Workflow to develop a supervised machine-learning-based predictive model. www.kjim.org https://doi.org/10.3904/kjim.2018.349</p>
<p>). Rheumatic diseases, including rheumatoid arthritis (RA), systemic lupus erythematosus, Sjögren's syndrome, systemic sclerosis, idiopathic inflammatory myositis, and the systemic vasculitides, are chronic autoimmune inflammatory disorders with multi-or-Clustering </p>
<p>Classification </p>
<p>Regression </p>
<p>Reinforcement learning </p>
<p>Active learning </p>
<p>Transfer learning </p>
<p>Natural language processing </p>
<p>Decision support systems </p>
<p>Computer vision </p>
<p>AI </p>
<p>Expressway </p>
<p>Artificial intelligence </p>
<p>Machine learning </p>
<p>ƒ(χ) </p>
<p>Deep learning </p>
<p>Computer 
science 
Statistics </p>
<p>Inference </p>
<p>Sampling </p>
<p>Distributions </p>
<p>Probability </p>
<p>Bayesian methods </p>
<p>Algorithms </p>
<p>Complexity </p>
<p>Databases </p>
<p>Big data </p>
<p>High performance computing </p>
<p>www.kjim.org https://doi.org/10.3904/kjim.2018.349</p>
<p>Table 1. Representative clinical studies using machine learning methods in internal medicine Table 1. Continued 718 www.kjim.org https://doi.org/10.3904/kjim.2018.349 The Korean Journal of Internal Medicine Vol. 34, No. 4, July 2019The Korean Journal of Internal Medicine Vol. 34, No. 4, July 2019 </p>
<p>Area 
Title </p>
<p>Machine 
learning 
category </p>
<p>Machine learning 
methods 
Input data 
Reference </p>
<p>Cardiology 
Identifying important 
risk factors for survival 
in patient with systolic 
heart failure using 
random survival forests </p>
<p>Supervised 
Random survival 
forest </p>
<p>39 Clinical variables 
2,231 Adult patients with 
systolic heart failure </p>
<p>[72] </p>
<p>Cardiology 
Use of hundreds of 
electrocardiographic 
biomarkers for 
prediction of mortality in 
postmenopausal women: 
the Women's Health 
Initiative </p>
<p>Supervised 
Random survival 
forest </p>
<p>477 Electrocardiographic 
findings 
33,144 Postmenopausal women </p>
<p>[73] </p>
<p>Cardiology 
Phenomapping for novel 
classification of heart 
failure with preserved 
ejection fraction </p>
<p>Unsupervised Agglomerative 
hierarchical 
clustering </p>
<p>67 Clinical and 
echocardiographic parameters 
420 Patients with heart failure 
with preserved ejection 
fraction </p>
<p>[74] </p>
<p>Cardiology 
Machine learning for 
prediction of all-cause 
mortality in patients 
with suspected coronary 
artery disease: a 5-year 
multicentre prospective 
registry analysis </p>
<p>Supervised 
Logit-boost 
model </p>
<p>44 Coronary computed 
tomographic angiography 
variables and 25 clinical 
variables 
10,030 Patients with suspected 
coronary artery disease </p>
<p>[75] </p>
<p>Pulmonology 
Unsupervised learning 
technique identifies 
bronchiectasis 
phenotypes with distinct 
clinical characteristics </p>
<p>Unsupervised Hierarchical 
clustering </p>
<p>78 Selected features from 
clinical, radiographic, and 
functional parameters 
148 Patients with bronchiectasis </p>
<p>[76] </p>
<p>Gastroenterology Predicting hospitalization 
and outpatient 
corticosteroid use in 
inflammatory bowel 
disease patients using 
machine learning </p>
<p>Supervised 
Random forest 
Over 30 clinical and laboratory 
features 
20,368 Patients with 
inflammatory bowel disease </p>
<p>[77] </p>
<p>Nephrology 
The development of 
a machine learning 
inpatient acute kidney 
injury prediction model </p>
<p>Supervised 
Gradient boosting 
machine </p>
<p>36 Clinical and laboratory 
features 
121,158 Admissions </p>
<p>[78] </p>
<p>Nephrology 
Using machine learning 
algorithms to predict 
risk for development of 
calciphylaxis in patients 
with chronic kidney 
disease </p>
<p>Supervised 
LASSO logistic 
regression 
Random forest </p>
<p>9,288 Clinical and laboratory 
features 
401 Patients with chronic 
kidney disease </p>
<p>[79] 
www.kjim.org </p>
<p>https://doi.org/10.3904/kjim.2018.349 </p>
<p>Area 
Title </p>
<p>Machine 
learning 
category </p>
<p>Machine learning 
methods 
Input data 
Reference </p>
<p>Endocrinology 
A predictive metabolic 
signature for the 
transition from 
gestational diabetes 
mellitus to type 2 
diabetes </p>
<p>Supervised 
Decision tree (J48) 
Naïve Bayes 
classifier </p>
<p>110 Blood metabolites 
1,035 Women with gestational 
diabetes </p>
<p>[80] </p>
<p>Endocrinology 
Predictive models to 
assess risk of type 2 
diabetes, hypertension 
and comorbidity: 
machine-learning 
algorithms and 
validation using national 
health data from Kuwait. 
A cohort study </p>
<p>Supervised 
Logistic 
regression 
k-Nearest 
neighbors 
Support vector 
machines 
Multifactor 
dimensionality 
reduction </p>
<p>13,647,408 Variables in medical 
records 
300,489 Hospital visitors </p>
<p>[81] </p>
<p>Oncology 
Systematic analysis of 
breast cancer morphology 
uncovers stromal features 
associated with survival </p>
<p>Supervised 
LASSO logistic 
regression </p>
<p>6,642 Image features from 
H&amp;E-stained histological 
images 
Two independent sets of 
patients with breast cancer: 
NKI (248 patients) and VGH 
(328 patients) </p>
<p>[82] </p>
<p>Oncology 
Development of a 
prognostic model for 
breast cancer survival 
in an open challenge 
environment </p>
<p>Supervised 
Unsupervised </p>
<p>Attractor 
metagenes 
analysis 
Generalized 
boosted 
regression 
k-Nearest 
neighbors </p>
<p>Clinical, survival information 
and 12 molecular features 
1,981 Patients with breast 
cancer </p>
<p>[83] </p>
<p>Oncology 
Predicting non-small cell 
lung cancer prognosis 
by fully automated 
microscopic pathology 
image features </p>
<p>Supervised 
Naïve Bayes 
classifiers 
Support vector 
machines 
Random forest </p>
<p>9,879 Image features 
2,186 H&amp;E stained whole-slide 
histopathology images, which 
were obtained from 515 lung 
adenocarcinoma patients 
and 502 lung squamous cell 
carcinoma patients. </p>
<p>[84] </p>
<p>Hematology 
Prediction of allogeneic 
hematopoietic stem-
cell transplantation 
mortality 100 days after 
transplantation using 
a machine learning 
algorithm: a European 
group for blood and 
marrow transplantation 
acute leukemia working 
party retrospective data 
mining study </p>
<p>Supervised 
Alternating 
decision tree </p>
<p>18 Clinical features 
28,236 Adult hematopoietic 
stem cell transplantation 
recipients who were affected by 
acute leukemia </p>
<p>[85] </p>
<p>Table 1 .
1Continued www.kjim.org https://doi.org/10.3904/kjim.2018.349
www.kjim.org https://doi.org/10.3904/kjim.2018.349 The Korean Journal of Internal Medicine Vol. 34, No. 4, July 2019
Conflict of interestNo potential conflict of interest relevant to this article was reported.
Some studies in machine learning using the game of checkers. A L Samuel, IBM J Res Dev. 3Samuel AL. Some studies in machine learning using the game of checkers. IBM J Res Dev 1959;3:210-229.</p>
<p>I H Witten, E Frank, M A Hall, C J Pal, Data Mining: Practical Machine Learning Tools and Techniques. 4th edWitten IH, Frank E, Hall MA, Pal CJ. Data Mining: Prac- tical Machine Learning Tools and Techniques. 4th ed.</p>
<p>. ( Cambridge, Ma, Elsevier ScienceCambridge (MA): Elsevier Science, 2016.</p>
<p>Pattern recognition and machine learning. N M Nasrabadi, J Electron Imaging. 1649901Nasrabadi NM. Pattern recognition and machine learn- ing. J Electron Imaging 2007;16:049901.</p>
<p>Machine Learning: An Artificial Intelligence Approach. R S Michalski, J G Carbonell, T M Mitchell, Berlin (DEMichalski RS, Carbonell JG, Mitchell TM. Machine Learning: An Artificial Intelligence Approach. Berlin (DE):</p>
<p>Deep learning. Y Lecun, Y Bengio, G Hinton, Nature. 521LeCun Y, Bengio Y, Hinton G. Deep learning. Nature 2015;521:436-444.</p>
<p>Deep learning applications and challenges in big data analytics. M M Najafabadi, F Villanustre, T M Khoshgoftaar, N Seliya, R Wald, E Muharemagic, J Big Data. 21Najafabadi MM, Villanustre F, Khoshgoftaar TM, Seliya N, Wald R, Muharemagic E. Deep learning applications and challenges in big data analytics. J Big Data 2015;2:1.</p>
<p>Opportunities and obstacles for deep learning in biology and medicine. T Ching, D S Himmelstein, B K Beaulieu-Jones, J R Soc Interface. 15Ching T, Himmelstein DS, Beaulieu-Jones BK, et al. Op- portunities and obstacles for deep learning in biology and medicine. J R Soc Interface 2018;15:20170387.</p>
<p>Artificial intelligence in medicine. P Hamet, J Tremblay, Metabolism. 69Hamet P, Tremblay J. Artificial intelligence in medicine. Metabolism 2017;69S:S36-S40.</p>
<p>A machine learning architecture for optimizing web search engines. AAAI Workshop on Internet Based Information Systems. J Boyan, D Freitag, T Joachims, Portland, ORBoyan J, Freitag D, Joachims T. A machine learning archi- tecture for optimizing web search engines. AAAI Work- shop on Internet Based Information Systems; 1996 May 10; Portland, OR.</p>
<p>A review of machine learning approaches to spam filtering. T S Guzella, W M Caminhas, Expert Syst Appl. 36Guzella TS, Caminhas WM. A review of machine learn- ing approaches to spam filtering. Expert Syst Appl 2009; 36:10206-10222.</p>
<p>To buy or not to buy: mining airfare data to minimize ticket purchase price. O Etzioni, R Tuchinda, C A Knoblock, A Yates, Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining. the ninth ACM SIGKDD international conference on Knowledge discovery and data miningEtzioni O, Tuchinda R, Knoblock CA, Yates A. To buy or not to buy: mining airfare data to minimize ticket pur- chase price. Proceedings of the ninth ACM SIGKDD in- ternational conference on Knowledge discovery and data mining; 2003 Aug 24-27;</p>
<p>. Dc New Washington, York, ACMNYWashington, DC. New York (NY): ACM, 2003: 119-128.</p>
<p>Neural machine translation by jointly learning to align and translate. D Bahdanau, K Cho, Y Bengio, International Conference on Learning Representations. Bahdanau D, Cho K, Bengio Y. Neural machine transla- tion by jointly learning to align and translate. Interna- tional Conference on Learning Representations 2015; 2015 May 7-9; San Diego, CA.</p>
<p>Machine learning for targeted display advertising: transfer learning in action. C Perlich, B Dalessandro, T Raeder, O Stitelman, F Provost, Mach Learn. 95Perlich C, Dalessandro B, Raeder T, Stitelman O, Provost F. Machine learning for targeted display advertising: trans- fer learning in action. Mach Learn 2014;95:103-127.</p>
<p>Artificial Neural Networks in Real-Life Applications. Hershey (PA): Idea Group Pub. J R Rabunal, J Dorrado, Rabunal JR, Dorrado J. Artificial Neural Networks in Re- al-Life Applications. Hershey (PA): Idea Group Pub., 2006.</p>
<p>Artificial intelligence in precision cardiovascular medicine. C Krittanawong, H Zhang, Z Wang, M Aydar, T Kitai, J Am Coll Cardiol. 69Krittanawong C, Zhang H, Wang Z, Aydar M, Kitai T. Arti- ficial intelligence in precision cardiovascular medicine. J Am Coll Cardiol 2017;69:2657-2664.</p>
<p>Predicting the future: big data, machine learning, and clinical medicine. Z Obermeyer, E J Emanuel, N Engl J Med. 375Obermeyer Z, Emanuel EJ. Predicting the future: big data, machine learning, and clinical medicine. N Engl J Med 2016;375:1216-1219.</p>
<p>Big data and data science in critical care. L N Sanchez-Pinto, Y Luo, M M Churpek, Chest. 154Sanchez-Pinto LN, Luo Y, Churpek MM. Big data and data science in critical care. Chest 2018;154:1239-1248.</p>
<p>A new era of oncology through artificial intelligence. A Curioni-Fontecedro, ESMO Open. 2198Curioni-Fontecedro A. A new era of oncology through artificial intelligence. ESMO Open 2017;2:e000198.</p>
<p>Concepts, characteristics, and clinical validation of IBM Watson for oncology. Y S Choi, Hanyang Med Rev. 37Choi YS. Concepts, characteristics, and clinical valida- tion of IBM Watson for oncology. Hanyang Med Rev 2017;37:49-60.</p>
<p>IBM's Watson supercomputer recommended 'unsafe and incorrect' cancer treatments, internal documents show. C Ross, I Swetlitz, InternetRoss C, Swetlitz I. IBM's Watson supercomputer recom- mended 'unsafe and incorrect' cancer treatments, inter- nal documents show [Internet].</p>
<p>( Boston, Ma, STAT, c2018 [. Boston (MA): STAT, c2018 [cited 2018 Nov 14]. Available from: https://www.statnews. com/2018/07/25/ibm-watson-recommended-unsafe-in- correct-treatments/.</p>
<p>Clinical aspects of autoimmune rheumatic diseases. F Goldblatt, O Neill, S G , Lancet. 382Goldblatt F, O'Neill SG. Clinical aspects of autoimmune rheumatic diseases. Lancet 2013;382:797-808.</p>
<p>. J S Smolen, D Aletaha, I B Mcinnes, Lancet. 388Rheumatoid arthritisSmolen JS, Aletaha D, McInnes IB. Rheumatoid arthritis. Lancet 2016;388:2023-2038.</p>
<p>International consensus: what else can we do to improve diagnosis and therapeutic strategies in patients affected by autoimmune rheumatic diseases (rheumatoid arthritis, spondyloarthritides, systemic sclerosis, systemic lupus erythematosus, antiphospholipid syndrome and Sjogren's 720 www. R Giacomelli, A Afeltra, A Alunno, 10.3904/kjim.2018.349Giacomelli R, Afeltra A, Alunno A, et al. International consensus: what else can we do to improve diagnosis and therapeutic strategies in patients affected by auto- immune rheumatic diseases (rheumatoid arthritis, spon- dyloarthritides, systemic sclerosis, systemic lupus ery- thematosus, antiphospholipid syndrome and Sjogren's 720 www.kjim.org https://doi.org/10.3904/kjim.2018.349</p>
<p>syndrome)? The unmet needs and the clinical grey zone in autoimmune disease management. The Korean Journal of Internal Medicine. 344Autoimmun RevThe Korean Journal of Internal Medicine Vol. 34, No. 4, July 2019 syndrome)? The unmet needs and the clinical grey zone in autoimmune disease management. Autoimmun Rev 2017;16:911-924.</p>
<p>The unmet need in rheumatology: reports from the targeted therapies meeting. K L Winthrop, V Strand, D Van Der Heijde, Clin Immunol. 186Winthrop KL, Strand V, van der Heijde D, et al. The un- met need in rheumatology: reports from the targeted therapies meeting 2017. Clin Immunol 2018;186:87-93.</p>
<p>Machine learning in bioinformatics. P Larranaga, B Calvo, R Santana, Brief Bioinform. 7Larranaga P, Calvo B, Santana R, et al. Machine learning in bioinformatics. Brief Bioinform 2006;7:86-112.</p>
<p>Machine learning applications in genetics and genomics. M W Libbrecht, W S Noble, Nat Rev Genet. 16Libbrecht MW, Noble WS. Machine learning applications in genetics and genomics. Nat Rev Genet 2015;16:321-332.</p>
<p>From systems biology to P4 medicine: applications in respiratory medicine. G Noell, R Faner, A Agusti, Eur Respir Rev. 27170110Noell G, Faner R, Agusti A. From systems biology to P4 medicine: applications in respiratory medicine. Eur Re- spir Rev 2018;27:170110.</p>
<p>Data integration and predictive modeling methods for multi-omics datasets. M Kim, I Tagkopoulos, Mol Omics. 14Kim M, Tagkopoulos I. Data integration and predictive modeling methods for multi-omics datasets. Mol Omics 2018;14:8-25.</p>
<p>Deep learning in biomedicine. M Wainberg, D Merico, A Delong, B J Frey, Nat Biotechnol. 36Wainberg M, Merico D, Delong A, Frey BJ. Deep learning in biomedicine. Nat Biotechnol 2018;36:829-838.</p>
<p>Deep learning: a primer for radiologists. G Chartrand, P M Cheng, E Vorontsov, Radiographics. 37Chartrand G, Cheng PM, Vorontsov E, et al. Deep learn- ing: a primer for radiologists. Radiographics 2017;37:2113- 2131.</p>
<p>Deep learning in medical imaging: general overview. J G Lee, S Jun, Y W Cho, Korean J Radiol. 18Lee JG, Jun S, Cho YW, et al. Deep learning in medical imaging: general overview. Korean J Radiol 2017;18:570- 584.</p>
<p>Data analysis strategies in medical imaging. C Parmar, J D Barry, A Hosny, J Quackenbush, Hjwl Aerts, Clin Cancer Res. 24Parmar C, Barry JD, Hosny A, Quackenbush J, Aerts HJWL. Data analysis strategies in medical imaging. Clin Cancer Res 2018;24:3492-3499.</p>
<p>Deep learning in medical image analysis. D Shen, G Wu, H I Suk, Annu Rev Biomed Eng. 19Shen D, Wu G, Suk HI. Deep learning in medical image analysis. Annu Rev Biomed Eng 2017;19:221-248.</p>
<p>Statistics versus machine learning. D Bzdok, N Altman, M Krzywinski, Nat Methods. 15Bzdok D, Altman N, Krzywinski M. Statistics versus ma- chine learning. Nat Methods 2018;15:233-234.</p>
<p>Machine learning in medicine: a primer for physicians. A K Waljee, P D Higgins, Am J Gastroenterol. 105Waljee AK, Higgins PD. Machine learning in medicine: a primer for physicians. Am J Gastroenterol 2010;105:1224- 1226.</p>
<p>An Introduction to Statistical Learning: With Applications in R. G James, D Witten, T Hastie, R Tibshirani, SpringerNew York (NY; New YorkJames G, Witten D, Hastie T, Tibshirani R. An Introduc- tion to Statistical Learning: With Applications in R. New York (NY): Springer New York, 2013.</p>
<p>Applied Predictive Modeling. M Kuhn, K Johnson, SpringerNew York (NY; New YorkKuhn M, Johnson K. Applied Predictive Modeling. New York (NY): Springer New York, 2013.</p>
<p>eDoctor: machine learning and the future of medicine. G S Handelman, H K Kok, R V Chandra, A H Razavi, M J Lee, H Asadi, J Intern Med. 284Handelman GS, Kok HK, Chandra RV, Razavi AH, Lee MJ, Asadi H. eDoctor: machine learning and the future of medicine. J Intern Med 2018;284:603-619.</p>
<p>Sengupta PP. Machine learning in cardiovascular medicine: are we there yet?. K Shameer, K W Johnson, B S Glicksberg, J T Dudley, Heart. 104Shameer K, Johnson KW, Glicksberg BS, Dudley JT, Sen- gupta PP. Machine learning in cardiovascular medicine: are we there yet? Heart 2018;104:1156-1164.</p>
<p>Development and validation of the European League Against Rheumatism response criteria for rheumatoid arthritis. Comparison with the preliminary American College of Rheumatology and the World Health Organization/International League Against Rheumatism Criteria. A M Van Gestel, M L Prevoo, M A Van &apos;t Hof, M H Van Rijswijk, L B Van De Putte, P L Van Riel, Arthritis Rheum. 39van Gestel AM, Prevoo ML, van 't Hof MA, van Rijswijk MH, van de Putte LB, van Riel PL. Development and validation of the European League Against Rheumatism response criteria for rheumatoid arthritis. Comparison with the preliminary American College of Rheumatology and the World Health Organization/International League Against Rheumatism Criteria. Arthritis Rheum 1996;39:34- 40.</p>
<p>Molecular subsets in the gene expression signatures of scleroderma skin. A Milano, S A Pendergrass, J L Sargent, PLoS One. 32696Milano A, Pendergrass SA, Sargent JL, et al. Molecular subsets in the gene expression signatures of scleroderma skin. PLoS One 2008;3:e2696.</p>
<p>Intrinsic gene expression subsets of diffuse cutaneous systemic sclerosis are stable in serial skin biopsies. S A Pendergrass, R Lemaire, I P Francis, J M Mahoney, R Lafyatis, M L Whitfield, J Invest Dermatol. 132Pendergrass SA, Lemaire R, Francis IP, Mahoney JM, Lafyatis R, Whitfield ML. Intrinsic gene expression sub- sets of diffuse cutaneous systemic sclerosis are stable in serial skin biopsies. J Invest Dermatol 2012;132:1363-1373.</p>
<p>Latent class models for clustering: A comparison with K-means. J Magidson, J Vermunt, Can J Mark Res. 20Magidson J, Vermunt J. Latent class models for clustering: A comparison with K-means. Can J Mark Res 2002;20:36- 43.</p>
<p>Mastering the game of Go with deep neural networks and tree search. D Silver, A Huang, C J Maddison, Nature. 529Silver D, Huang A, Maddison CJ, et al. Mastering the game of Go with deep neural networks and tree search. Nature 2016;529:484-489.</p>
<p>Reinforcement learning strategies for clinical trials in nonsmall cell lung cancer. Y Zhao, D Zeng, M A Socinski, M R Kosorok, Biometrics. 67Zhao Y, Zeng D, Socinski MA, Kosorok MR. Reinforce- ment learning strategies for clinical trials in nonsmall cell lung cancer. Biometrics 2011;67:1422-1433.</p>
<p>Transfer learning. L Torrey, J Shavlik, Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques. Olivas ESHershey, PAIGI GlobalTorrey L, Shavlik J. Transfer learning. In: Olivas ES, ed. Handbook of Research on Machine Learning Applica- tions and Trends: Algorithms, Methods, and Techniques. Hershey, PA: IGI Global, 2010:242-264.</p>
<p>Deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks. P Lakhani, B Sundaram, Radiology. 284Lakhani P, Sundaram B. Deep learning at chest radiog- raphy: automated classification of pulmonary tubercu- losis by using convolutional neural networks. Radiology 2017;284:574-582.</p>
<p>Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems 25. A Krizhevsky, I Sutskever, G E Hinton, Krizhevsky A, Sutskever I, Hinton GE. Imagenet classifi- cation with deep convolutional neural networks. Advanc- es in neural information processing systems 25; 2012 Dec 3-6;</p>
<p>. Nv Red Lake Tahoe, Hook, Curran AssociatesNYLake Tahoe, NV. Red Hook (NY): Curran Associates, 2012: 1097-1105.</p>
<p>Delving deep into rectifiers: surpassing human-level performance on imagenet classification. K He, X Zhang, S Ren, J Sun, Proceedings of the 2015 IEEE International Conference on Computer Vision. the 2015 IEEE International Conference on Computer VisionHe K, Zhang X, Ren S, Sun J. Delving deep into rectifi- ers: surpassing human-level performance on imagenet classification. Proceedings of the 2015 IEEE International Conference on Computer Vision; 2015 Dec 7-13;</p>
<p>Imagenet: a large-scale hierarchical image database. J Deng, W Dong, R Socher, L J Li, K Li, L Fei-Fei, IEEE Conference on Computer Vision and Pattern Recognition. Deng J, Dong W, Socher R, Li LJ, Li K, Fei-Fei L. Imagen- et: a large-scale hierarchical image database. 2009 IEEE Conference on Computer Vision and Pattern Recogni- tion; 2009 Jun 20-25;</p>
<p>. F L Miami, Piscataway, IEEEMiami, FL. Piscataway (NJ): IEEE, 2009: 248-255.</p>
<p>. 10.3904/kjim.2018.349www.kjim.org https://doi.org/10.3904/kjim.2018.349</p>
<p>Challenges of big data analysis. J Fan, F Han, H Liu, Natl Sci Rev. 1Fan J, Han F, Liu H. Challenges of big data analysis. Natl Sci Rev 2014;1:293-314.</p>
<p>The electronic medical record in 2016: advantages and disadvantages. J S Alpert, Digit Med. 2Alpert JS. The electronic medical record in 2016: advan- tages and disadvantages. Digit Med 2016;2:48-51.</p>
<p>Benefits and drawbacks of electronic health record systems. N Menachemi, T H Collum, Risk Manag Healthc Policy. 4Menachemi N, Collum TH. Benefits and drawbacks of electronic health record systems. Risk Manag Healthc Policy 2011;4:47-55.</p>
<p>Review: electronic health records and the reliability and validity of quality measures. A review of the literature. K S Chan, J B Fowles, J P Weiner, Med Care Res Rev. 67Chan KS, Fowles JB, Weiner JP. Review: electronic health records and the reliability and validity of quality measures. A review of the literature. Med Care Res Rev 2010;67:503- 527.</p>
<p>Development of an algorithm for identifying rheumatoid arthritis in the Korean National Health Insurance claims database. S K Cho, Y K Sung, C B Choi, J M Kwon, E K Lee, S C Bae, Rheumatol Int. 33Cho SK, Sung YK, Choi CB, Kwon JM, Lee EK, Bae SC. Development of an algorithm for identifying rheumatoid arthritis in the Korean National Health Insurance claims database. Rheumatol Int 2013;33:2985-2992.</p>
<p>If your data is bad, your machine learning tools are useless. T C Redman, InternetRedman TC. If your data is bad, your machine learning tools are useless [Internet].</p>
<p>. ( Boston, Ma, Harvard Business PublishingBoston (MA): Harvard Busi- ness Publishing, c2018 [cited 2018 Nov 15]. Available from: https://hbr.org/2018/04/if-your-data-is-bad-your-ma- chine-learning-tools-are-useless.</p>
<p>Learning from Data: Concepts, Theory, and Methods. V S Cherkassky, F M Mulier, WileyHoboken (NJ2nd ed.Cherkassky VS, Mulier FM. Learning from Data: Con- cepts, Theory, and Methods. 2nd ed. Hoboken (NJ): Wiley, 2007.</p>
<p>Data quality: "Garbage in-garbage out. M F Kilkenny, K M Robinson, Health Inf Manag. 47Kilkenny MF, Robinson KM. Data quality: "Garbage in-garbage out". Health Inf Manag 2018;47:103-105.</p>
<p>Data preprocessing for supervised leaning. S B Kotsiantis, D Kanellopoulos, P E Pintelas, Int J Comput Electr Autom Control Inf Eng. 1Kotsiantis SB, Kanellopoulos D, Pintelas PE. Data pre- processing for supervised leaning. Int J Comput Electr Autom Control Inf Eng 2006;1:111-117.</p>
<p>A study of cross-validation and bootstrap for accuracy estimation and model selection. R Kohavi, Proceedings of the 14th international joint conference on Artificial intelligence. the 14th international joint conference on Artificial intelligence2Kohavi R. A study of cross-validation and bootstrap for accuracy estimation and model selection. Proceedings of the 14th international joint conference on Artificial intelligence volume 2; 1995 Aug 20-25;</p>
<p>. Q C Montreal, Mateo, Morgan Kaufmann Publishers IncCAMontreal, QC. San Mateo (CA): Morgan Kaufmann Publishers Inc., 1995: 1137- 1143.</p>
<p>A few useful things to know about machine learning. P Domingos, Commun ACM. 55Domingos P. A few useful things to know about machine learning. Commun ACM 2012;55:78-87.</p>
<p>Points of significance: model selection and overfitting. J Lever, M Krzywinski, N Altman, Nat Methods. 13Lever J, Krzywinski M, Altman N. Points of significance: model selection and overfitting. Nat Methods 2016;13:703- 704.</p>
<p>The problem of overfitting. D M Hawkins, J Chem Inf Comput Sci. 44Hawkins DM. The problem of overfitting. J Chem Inf Comput Sci 2004;44:1-12.</p>
<p>An introduction to variable and feature selection. I Guyon, A Elisseeff, J Mach Learn Res. 3Guyon I, Elisseeff A. An introduction to variable and fea- ture selection. J Mach Learn Res 2003;3:1157-1182.</p>
<p>A review of feature selection techniques in bioinformatics. Y Saeys, I Inza, P Larranaga, Bioinformatics. 23Saeys Y, Inza I, Larranaga P. A review of feature selection techniques in bioinformatics. Bioinformatics 2007;23: 2507-2517.</p>
<p>Scaling to very very large corpora for natural language disambiguation. M Banko, E Brill, Proceedings of the 39th Annual Meeting on Association for Computational Linguistics. the 39th Annual Meeting on Association for Computational LinguisticsBanko M, Brill E. Scaling to very very large corpora for natural language disambiguation. Proceedings of the 39th Annual Meeting on Association for Computational Linguistics; 2001 Jul 6-11;</p>
<p>. France Toulouse, Morgan Kaufmann PublishersSan Francisco (CAToulouse, France. San Francisco (CA): Morgan Kaufmann Publishers, 2001: 26-33.</p>
<p>Class imbalance problem in data mining: review. R Longadge, S Dongre, L Malik, Int J Comput Sci Netw. 2Longadge R, Dongre S, Malik L. Class imbalance problem in data mining: review. Int J Comput Sci Netw 2013;2:83- 87.</p>
<p>The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets. T Saito, M Rehmsmeier, PLoS One. 10118432Saito T, Rehmsmeier M. The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets. PLoS One 2015;10:e0118432.</p>
<p>Hyperparameter search in machine learning. M Claesen, De Moor, B , Int J Comput Sci Netw. 4Claesen M, De Moor B. Hyperparameter search in ma- chine learning. Int J Comput Sci Netw 2015;4:1-5. https:// arxiv.org/abs/1502.02127.</p>
<p>A lot of randomness is hiding in accuracy. A Ben-David, Eng Appl Artif Intell. 20Ben-David A. A lot of randomness is hiding in accuracy. Eng Appl Artif Intell 2007;20:875-885.</p>
<p>Tools and techniques for computational reproducibility. S R Piccolo, M B Frampton, Gigascience. 530Piccolo SR, Frampton MB. Tools and techniques for com- putational reproducibility. Gigascience 2016;5:30.</p>
<p>Identifying important risk factors for survival in patient with systolic heart failure using random survival forests. E Hsich, E Z Gorodeski, E H Blackstone, H Ishwaran, M S Lauer, Circ Cardiovasc Qual Outcomes. 4Hsich E, Gorodeski EZ, Blackstone EH, Ishwaran H, Lau- er MS. Identifying important risk factors for survival in patient with systolic heart failure using random survival forests. Circ Cardiovasc Qual Outcomes 2011;4:39-45.</p>
<p>Use of hundreds of electrocardiographic biomarkers for prediction of mortality in postmenopausal women: the Women's Health Initiative. E Z Gorodeski, H Ishwaran, U B Kogalur, Circ Cardiovasc Qual Outcomes. 4Gorodeski EZ, Ishwaran H, Kogalur UB, et al. Use of hundreds of electrocardiographic biomarkers for predic- tion of mortality in postmenopausal women: the Wom- en's Health Initiative. Circ Cardiovasc Qual Outcomes 2011;4:521-532.</p>
<p>Phenomapping for novel classification of heart failure with preserved ejection fraction. S J Shah, D H Katz, S Selvaraj, Circulation. 131Shah SJ, Katz DH, Selvaraj S, et al. Phenomapping for novel classification of heart failure with preserved ejec- tion fraction. Circulation 2015;131:269-279.</p>
<p>Machine learning for prediction of all-cause mortality in patients with suspected coronary artery disease: a 5-year multicentre prospective registry analysis. M Motwani, D Dey, D S Berman, Eur Heart J. 38Motwani M, Dey D, Berman DS, et al. Machine learning for prediction of all-cause mortality in patients with sus- pected coronary artery disease: a 5-year multicentre pro- spective registry analysis. Eur Heart J 2017;38:500-507.</p>
<p>Unsupervised learning technique identifies bronchiectasis phenotypes with distinct clinical characteristics. W J Guan, M Jiang, Y H Gao, Int J Tuberc Lung Dis. 20Guan WJ, Jiang M, Gao YH, et al. Unsupervised learning technique identifies bronchiectasis phenotypes with distinct clinical characteristics. Int J Tuberc Lung Dis 2016;20:402-410.</p>
<p>Predicting hospitalization and outpatient corticosteroid use in inflammatory bowel disease patients using machine learning. A K Waljee, R Lipson, W L Wiitala, Inflamm Bowel Dis. 24Waljee AK, Lipson R, Wiitala WL, et al. Predicting hos- pitalization and outpatient corticosteroid use in inflam- matory bowel disease patients using machine learning. Inflamm Bowel Dis 2017;24:45-53.</p>
<p>The development of a machine learning inpatient acute kidney injury prediction model. J L Koyner, K A Carey, D P Edelson, M M Churpek, Crit Care Med. 46Koyner JL, Carey KA, Edelson DP, Churpek MM. The de- velopment of a machine learning inpatient acute kidney injury prediction model. Crit Care Med 2018;46:1070-1077.</p>
<p>. 10.3904/kjim.2018.349www.kjim.org https://doi.org/10.3904/kjim.2018.349</p>
<p>. The Korean Journal of Internal Medicine. 344The Korean Journal of Internal Medicine Vol. 34, No. 4, July 2019</p>
<p>Using machine learning algorithms to predict risk for development of calciphylaxis in patients with chronic kidney disease. R S Kleiman, E R Larose, J C Badger, Kleiman RS, LaRose ER, Badger JC, et al. Using machine learning algorithms to predict risk for development of calciphylaxis in patients with chronic kidney disease.</p>
<p>. AMIA Jt Summits Transl Sci Proc. 2017AMIA Jt Summits Transl Sci Proc 2018;2017:139-146.</p>
<p>A predictive metabolic signature for the transition from gestational diabetes mellitus to type 2 diabetes. A Allalou, A Nalla, K J Prentice, Diabetes. 65Allalou A, Nalla A, Prentice KJ, et al. A predictive metabol- ic signature for the transition from gestational diabetes mellitus to type 2 diabetes. Diabetes 2016;65:2529-2539.</p>
<p>Predictive models to assess risk of type 2 diabetes, hypertension and comorbidity: machine-learning algorithms and validation using national health data from Kuwait. A cohort study. B Farran, A M Channanath, K Behbehani, T A Thanaraj, BMJ Open. 32457Farran B, Channanath AM, Behbehani K, Thanaraj TA. Predictive models to assess risk of type 2 diabetes, hyper- tension and comorbidity: machine-learning algorithms and validation using national health data from Kuwait. A cohort study. BMJ Open 2013;3:e002457.</p>
<p>Systematic analysis of breast cancer morphology uncovers stromal features associated with survival. A H Beck, A R Sangoi, S Leung, Sci Transl Med. 3Beck AH, Sangoi AR, Leung S, et al. Systematic analysis of breast cancer morphology uncovers stromal features associated with survival. Sci Transl Med 2011;3:108ra113.</p>
<p>Development of a prognostic model for breast cancer survival in an open challenge environment. W Y Cheng, Ou Yang, T H Anastassiou, D , Sci Transl Med. 5Cheng WY, Ou Yang TH, Anastassiou D. Development of a prognostic model for breast cancer survival in an open challenge environment. Sci Transl Med 2013;5:181ra50.</p>
<p>Predicting non-small cell lung cancer prognosis by fully automated microscopic pathology image features. K H Yu, C Zhang, G J Berry, Nat Commun. 712474Yu KH, Zhang C, Berry GJ, et al. Predicting non-small cell lung cancer prognosis by fully automated microscopic pathology image features. Nat Commun 2016;7:12474.</p>
<p>Prediction of allogeneic hematopoietic stem-cell transplantation mortality 100 days after transplantation using a machine learning algorithm: a European group for blood and marrow transplantation acute leukemia working party retrospective data mining study. R Shouval, M Labopin, O Bondi, J Clin Oncol. 33Shouval R, Labopin M, Bondi O, et al. Prediction of allo- geneic hematopoietic stem-cell transplantation mortality 100 days after transplantation using a machine learning algorithm: a European group for blood and marrow transplantation acute leukemia working party retrospec- tive data mining study. J Clin Oncol 2015;33:3144-3151.</p>
<p>Dermatologist-level classification of skin cancer with deep neural networks. A Esteva, B Kuprel, R A Novoa, Nature. 542Esteva A, Kuprel B, Novoa RA, et al. Dermatologist-level classification of skin cancer with deep neural networks. Nature 2017;542:115-118.</p>
<p>Identification of three rheumatoid arthritis disease subtypes by machine learning integration of synovial histologic features and RNA sequencing data. D E Orange, P Agius, E F Dicarlo, Arthritis Rheumatol. 70Orange DE, Agius P, DiCarlo EF, et al. Identification of three rheumatoid arthritis disease subtypes by machine learning integration of synovial histologic features and RNA sequencing data. Arthritis Rheumatol 2018;70:690- 701.</p>
<p>An efficient k-means clustering algorithm: analysis and implementation. T Kanungo, D M Mount, N S Netanyahu, C D Piatko, R Silverman, A Y Wu, IEEE Trans Pattern Anal Mach Intell. 24Kanungo T, Mount DM, Netanyahu NS, Piatko CD, Silver- man R, Wu AY. An efficient k-means clustering algorithm: analysis and implementation. IEEE Trans Pattern Anal Mach Intell 2002;24:881-892.</p>
<p>What is a support vector machine?. W S Noble, Nat Biotechnol. 24Noble WS. What is a support vector machine? Nat Bio- technol 2006;24:1565-1567.</p>
<p>Overcome support vector machine diagnosis overfitting. H Han, X Jiang, Cancer Inform. 131SupplHan H, Jiang X. Overcome support vector machine diag- nosis overfitting. Cancer Inform 2014;13(Suppl 1):145-158.</p>
<p>Development and validation of a multivariate predictive model for rheumatoid arthritis mortality using a machine learning approach. J M Lezcano-Valverde, F Salazar, L Leon, Sci Rep. 710189Lezcano-Valverde JM, Salazar F, Leon L, et al. Develop- ment and validation of a multivariate predictive model for rheumatoid arthritis mortality using a machine learn- ing approach. Sci Rep 2017;7:10189.</p>
<p>Random survival forests. H Ishwaran, U B Kogalur, E H Blackstone, M S Lauer, Ann Appl Stat. 2Ishwaran H, Kogalur UB, Blackstone EH, Lauer MS. Ran- dom survival forests. Ann Appl Stat 2008;2:841-860.</p>
<p>ggRandomForests: exploring random forest survival. J Ehrlinger, InternetEhrlinger J. ggRandomForests: exploring random forest survival [Internet].</p>
<p>. Arxiv, ArXiv, 2016 [cited 2018 Nov 15].</p>
<p>Ensemble methods: bagging and random forests. N Altman, M Krzywinski, Nat Methods. 14Altman N, Krzywinski M. Ensemble methods: bagging and random forests. Nat Methods 2017;14:933-934.</p>
<p>A comparison of the conditional inference survival forest model to random survival forests based on a simulation study as well as on two applications with time-to-event data. J B Nasejje, H Mwambi, K Dheda, M Lesosky, BMC Med Res Methodol. 17115Nasejje JB, Mwambi H, Dheda K, Lesosky M. A compari- son of the conditional inference survival forest model to random survival forests based on a simulation study as well as on two applications with time-to-event data. BMC Med Res Methodol 2017;17:115.</p>
<p>Influence of demographic and clinical factors on the mortality rate of a rheumatoid arthritis cohort: a 20-year survival study. L Abasolo, J Ivorra-Cortes, Leon L Jover, J A Fernandez-Gutierrez, B Rodriguez-Rodriguez, L , Abasolo L, Ivorra-Cortes J, Leon L, Jover JA, Fernan- dez-Gutierrez B, Rodriguez-Rodriguez L. Influence of demographic and clinical factors on the mortality rate of a rheumatoid arthritis cohort: a 20-year survival study.</p>
<p>. Semin Arthritis Rheum. 45Semin Arthritis Rheum 2016;45:533-538.</p>
<p>Short-term prediction of mortality in patients with systemic lupus erythematosus: classification of outcomes using random forests. M M Ward, S Pajevic, J Dreyfuss, J D Malley, Arthritis Rheum. 55Ward MM, Pajevic S, Dreyfuss J, Malley JD. Short-term prediction of mortality in patients with systemic lupus erythematosus: classification of outcomes using random forests. Arthritis Rheum 2006;55:74-80.</p>
<p>Early illness features associated with mortality in the juvenile idiopathic inflammatory myopathies. A M Huber, G Mamyrova, P A Lachenbruch, Arthritis Care Res (Hoboken). 66Huber AM, Mamyrova G, Lachenbruch PA, et al. Early illness features associated with mortality in the juvenile idiopathic inflammatory myopathies. Arthritis Care Res (Hoboken) 2014;66:732-740.</p>
<p>Data glitches are hazardous to your health. Sci Am. 30910Data glitches are hazardous to your health. Sci Am 2013;309:10.</p>            </div>
        </div>

    </div>
</body>
</html>