<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1132 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1132</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1132</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-25.html">extraction-schema-25</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-251041074</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2108.08062v2.pdf" target="_blank">Concurrent Active Learning in Autonomous Airborne Source Search: Dual Control for Exploration and Exploitation</a></p>
                <p><strong>Paper Abstract:</strong> A concurrent learning framework is developed for source search in an unknown environment using autonomous platforms equipped with onboard sensors. Distinct from the existing solutions that require significant computational power for Bayesian estimation and path planning, the proposed solution is computationally affordable for onboard processors. A new concept of concurrent learning using multiple parallel estimators is proposed to learn the operational environment and quantify estimation uncertainty. The search agent is empowered with the dual capability of exploiting current-estimated parameters to track the source and probing the environment to reduce the impacts of uncertainty, namely Concurrent Learning based Dual Control for Exploration and Exploitation (CL-DCEE). In this setting, the control action not only minimizes the tracking error between future agent's position and estimated source location, but also the uncertainty of predicted estimation. More importantly, the rigorous proven properties, such as the convergence of CL-DCEE algorithm, are established under mild assumptions on noises, and the impact of noises on the search performance is examined. Simulation results are provided to validate the effectiveness of the proposed CL-DCEE algorithm. Compared with the information-theoretic approach, CL-DCEE not only guarantees convergence, but produces better search performance and consumes much less computational time.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1132.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1132.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CL-DCEE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Concurrent Learning based Dual Control for Exploration and Exploitation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An onboard-capable active learning search algorithm that combines an ensemble of parallel gradient-based estimators with a dual-control path planner that trades off exploitation (moving to where high concentration is predicted) and exploration (moving to reduce predicted estimator uncertainty). Proven convergence under mild noise assumptions and evaluated in simulation and real dispersion data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>CL-DCEE</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An ensemble (N parallel) of gradient-based source-parameter estimators (memory-based regression using recent q samples) whose predicted measurement mean and ensemble variance are used in a gradient-based path planner. Key components: (1) N concurrent estimators Θ_i updated by gradient descent on least-squares f(Θ_i,p), (2) ensemble aggregation to compute nominal estimate and predicted measurement variance P_{k+1|k}, (3) one-step-ahead myopic cost J(u_k) = (M0 - z_k+1|k)^2 + P_{k+1|k}, and (4) gradient-descent control update u_k = -δ ∇_p y + ∇_p P.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Active learning via dual control / ensemble-based uncertainty reduction (variance minimization) combined with exploitation of predicted mean (concentration maximization).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>At each step the agent computes predicted measurement mean z_{k+1|k} (exploitation) and predicted variance P_{k+1|k} from the N estimators at candidate next positions. The control input u_k is chosen by minimizing J = (M0 - predicted_mean)^2 + predicted_variance, implemented via gradient descent. Estimators are updated by memory-based gradient descent using the most recent q samples; ensemble spread quantifies uncertainty and drives exploratory probing to reduce variance.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Autonomous airborne source search (isotropic plume ATDM simulations and a real recirculating-channel fluorescein dye dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Partially observable and stochastic: continuous 3D state and action space, additive Gaussian sensor noise, intermittent non-detection (dropouts, modelled like Poisson/non-detection events), unknown source and environmental parameters (source position s, release rate q, wind speed u_s, wind direction ρ_s, diffusivity ζ_s1, lifetime ζ_s2), local turbulence and time-varying dispersion in experimental data.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Search area 100 m × 100 m × 1 m; continuous position (p_k ∈ R^3); continuous admissible control U (step size ∈ [1 m, 4 m], velocity 2 m/s); sampling period 10 s per measurement; measurement budget 180, flight budget 2000 s in simulation; experimental dataset: 340 frames (49×98 pixels) with rapidly time-varying fields.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Converged to bounded estimation MSE in simulation (~1000 s of operation). Steady-state agent-source distances (mean) for ensemble sizes N = 5, 10, 50, 100, 200, 1000 were approximately 35.96 m, 20.28 m, 2.80 m, 2.36 m, 2.22 m, and 1.61 m respectively. Computational cost for 200 trial runs: CL-DCEE total times ≈ {N=5: 21.8 s, 10: 23.1 s, 50: 24.3 s, 100: 26.3 s, 200: 30.5 s, 1000: 56.8 s} versus Entrotaxis ≈ 2940.4 s (same 200 trials) — i.e., CL-DCEE consumed <~1% of Entrotaxis compute for typical N≤100.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>High relative sample efficiency: convergence of estimator MSE and approach-to-source observed by ~1000 s (≈100 samples assuming 10 s/sample). CL-DCEE updates estimators every sample and converges faster than the benchmark Entrotaxis in simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Built into the cost J(u) = (M0 - predicted_mean)^2 + P_pred; the first term enforces exploitation by steering to where high concentration is predicted, the second term enforces exploration by steering to positions that reduce predicted ensemble variance. No hand-tuned scalar tradeoff weight is required—the terms arise naturally from the one-step-ahead prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Entrotaxis (information-theoretic IPP implemented with particle filter), prior DCEE (particle-filter-based dual control), Chemotaxis (reactive gradient-based), pure exploitation variant (P term removed, not numerically reported).</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>1) CL-DCEE provides a practical myopic dual-control active learning method with theoretical convergence guarantees (Theorems 1 and 2) under bounded unbiased noises and persistent-excitation-like conditions. 2) Multi-estimator ensemble quantifies uncertainty cheaply (far fewer estimators than particle filters) and enables a variance-driven exploration term. 3) In simulations CL-DCEE attains much lower computational cost (≈100x reduction) and competitive or better source-approach performance when sensor noise is unbiased and environment known; tens of estimators (N≥50) suffice for good performance. 4) In a real, highly time-varying dispersion dataset, CL-DCEE successfully locates the source despite many non-detections by leveraging the ensemble.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Performance degrades under biased/noisy non-detection events (intermittent dropouts) especially with small ensemble sizes (N=5,10) due to accumulated biased measurements; requires sufficient ensemble size and persistent excitation (use of q past samples) to guarantee estimator convergence; relies on accuracy of the ATDM model (model bias can affect performance); algorithm is myopic (one-step-ahead) and multi-step lookahead is left for future work.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concurrent Active Learning in Autonomous Airborne Source Search: Dual Control for Exploration and Exploitation', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1132.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1132.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Entrotaxis</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Entrotaxis (information-theoretic informative path planning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An information-theoretic active search strategy that chooses agent motions to maximize expected information gain (minimize posterior entropy/variance) using a particle-filter-based inference engine; used in this paper as the primary benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Entrotaxis as a strategy for autonomous search and source reconstruction in turbulent conditions</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Entrotaxis</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Information-theoretic informative path planner: uses particle filtering (in experiments here: 10,000 particles) to represent posterior over source parameters and selects next moves from a discretised action set by maximising expected entropy reduction or other information measures; in the experiments action set U = {8 cardinal/diagonal directions} with fixed step size 2 m.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Information gain maximization / entropy-based active learning (informative path planning).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Uses a particle-filter posterior to predict expected information gain for candidate next moves and selects the action expected to reduce posterior uncertainty the most (pure exploration objective).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Autonomous airborne source search (same isotropic-plume simulations and experimental dispersion dataset used as CL-DCEE comparison)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Partially observable, stochastic dispersion with sensor noise and non-detection events; continuous-space plume but Entrotaxis uses discretised candidate moves and particle-filter belief; unknown source and environmental parameters estimated via particle filter.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Same spatial domain (100 m × 100 m × 1 m); particle filter used with 10,000 particles; discrete action set of 8 directions with fixed 2 m step size; sampling every 10 s in simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Provides robust posterior estimation and strong resilience to sensor dropouts and unknown environment parameters, but requires many measurements to update particle filter (slow acquisition). In experiments here Entrotaxis's computation for 200 trials was ≈2940.4 s (much larger than CL-DCEE). It tends to keep the agent farther from the true source (qualitatively large steady-state agent-source distance) while achieving acceptable estimator MSE eventually.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Lower sample efficiency in these experiments: requires many measurements (and many particles) to update the posterior and achieve estimator accuracy; acquisition continues until flight termination under limited budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Primarily pure exploration (information-theoretic): aims to reduce estimator posterior uncertainty rather than explicitly steering the agent to the currently-believed maximum concentration; this can lead to probing informative regions instead of exploiting the current estimate.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>CL-DCEE (ensemble dual-control) and Chemotaxis; baseline in the paper for informative-path planning.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>Entrotaxis is computationally expensive (particle filter with many particles and sampling-based planning) but robust to sensor dropouts and unknown environmental parameters; because it focuses on exploration it can maintain larger distance to the true source even when estimate is accurate; not suitable for onboard implementation on low-power processors without simplification.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Very heavy computational burden (particle filters + optimisation); discrete and limited feasible action set reduces flexibility; typically executed offboard in prior work; no rigorous convergence analysis provided in prior studies (as noted by the authors).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concurrent Active Learning in Autonomous Airborne Source Search: Dual Control for Exploration and Exploitation', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1132.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1132.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DCEE (prior)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dual Control for Exploration and Exploitation (prior formulation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A previously-introduced dual-control framework that formalizes autonomous search as a control problem balancing exploration (information acquisition) and exploitation (moving towards believed source), typically implemented with particle filters and model predictive planning; cited as motivation and contrasted with CL-DCEE.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dual control for exploitation and exploration (DCEE) in autonomous search</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>DCEE (prior work)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Dual-control framework combining particle-filter based Bayesian estimation of source/environment parameters and control strategies that attempt to balance exploration and exploitation (often implemented via model predictive control or information-theoretic objectives).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Dual control with particle-filter Bayesian inference and informative planning (information-theoretic components / model-predictive control).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Evaluates candidate control sequences by predicting their effect on future posteriors using particle filters and optimises expected information gain vs task objective, but requires costly nested inference-in-optimization loops.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Autonomous airborne source search (motivating prior work and conceptual predecessor to CL-DCEE)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Partially observable, stochastic plume dispersion; unknown parameters; typically noisy sensors and discrete candidate actions in prior implementations.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Prior implementations used discretised action sets and heavy particle-filtering; computational costs restricted onboard deployment and continuous action flexibility.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Reported to have good empirical performance in experiments but high computational cost; the prior DCEE required remote/offboard computation in earlier studies and lacked rigorous convergence proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Explicitly attempts to balance exploration and exploitation via dual control; often implemented through information-theoretic objectives or MPC formulations that include uncertainty terms.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>CL-DCEE (this paper argues CL-DCEE reduces computational cost and provides theoretical convergence), Entrotaxis, particle-filter IPP methods.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>DCEE provides a principled dual-control view but in prior work relied on particle filters and optimisation which induced high computational cost and lacked formal convergence guarantees; motivated CL-DCEE which replaces particle filters with an ensemble and gradient-based planning to enable onboard use and provable convergence.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>High computational cost due to nested Bayesian inference during planning; limited feasible action sets in implementations; no rigorous theoretical convergence analysis in prior DCEE publications (as cited).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concurrent Active Learning in Autonomous Airborne Source Search: Dual Control for Exploration and Exploitation', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Dual control for exploitation and exploration (DCEE) in autonomous search <em>(Rating: 2)</em></li>
                <li>Entrotaxis as a strategy for autonomous search and source reconstruction in turbulent conditions <em>(Rating: 2)</em></li>
                <li>Infotaxis as a strategy for searching without gradients <em>(Rating: 2)</em></li>
                <li>Simple and scalable predictive uncertainty estimation using deep ensembles <em>(Rating: 2)</em></li>
                <li>Planning to be surprised: Optimal bayesian exploration in dynamic environments <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1132",
    "paper_id": "paper-251041074",
    "extraction_schema_id": "extraction-schema-25",
    "extracted_data": [
        {
            "name_short": "CL-DCEE",
            "name_full": "Concurrent Learning based Dual Control for Exploration and Exploitation",
            "brief_description": "An onboard-capable active learning search algorithm that combines an ensemble of parallel gradient-based estimators with a dual-control path planner that trades off exploitation (moving to where high concentration is predicted) and exploration (moving to reduce predicted estimator uncertainty). Proven convergence under mild noise assumptions and evaluated in simulation and real dispersion data.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "CL-DCEE",
            "agent_description": "An ensemble (N parallel) of gradient-based source-parameter estimators (memory-based regression using recent q samples) whose predicted measurement mean and ensemble variance are used in a gradient-based path planner. Key components: (1) N concurrent estimators Θ_i updated by gradient descent on least-squares f(Θ_i,p), (2) ensemble aggregation to compute nominal estimate and predicted measurement variance P_{k+1|k}, (3) one-step-ahead myopic cost J(u_k) = (M0 - z_k+1|k)^2 + P_{k+1|k}, and (4) gradient-descent control update u_k = -δ ∇_p y + ∇_p P.",
            "adaptive_design_method": "Active learning via dual control / ensemble-based uncertainty reduction (variance minimization) combined with exploitation of predicted mean (concentration maximization).",
            "adaptation_strategy_description": "At each step the agent computes predicted measurement mean z_{k+1|k} (exploitation) and predicted variance P_{k+1|k} from the N estimators at candidate next positions. The control input u_k is chosen by minimizing J = (M0 - predicted_mean)^2 + predicted_variance, implemented via gradient descent. Estimators are updated by memory-based gradient descent using the most recent q samples; ensemble spread quantifies uncertainty and drives exploratory probing to reduce variance.",
            "environment_name": "Autonomous airborne source search (isotropic plume ATDM simulations and a real recirculating-channel fluorescein dye dataset)",
            "environment_characteristics": "Partially observable and stochastic: continuous 3D state and action space, additive Gaussian sensor noise, intermittent non-detection (dropouts, modelled like Poisson/non-detection events), unknown source and environmental parameters (source position s, release rate q, wind speed u_s, wind direction ρ_s, diffusivity ζ_s1, lifetime ζ_s2), local turbulence and time-varying dispersion in experimental data.",
            "environment_complexity": "Search area 100 m × 100 m × 1 m; continuous position (p_k ∈ R^3); continuous admissible control U (step size ∈ [1 m, 4 m], velocity 2 m/s); sampling period 10 s per measurement; measurement budget 180, flight budget 2000 s in simulation; experimental dataset: 340 frames (49×98 pixels) with rapidly time-varying fields.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Converged to bounded estimation MSE in simulation (~1000 s of operation). Steady-state agent-source distances (mean) for ensemble sizes N = 5, 10, 50, 100, 200, 1000 were approximately 35.96 m, 20.28 m, 2.80 m, 2.36 m, 2.22 m, and 1.61 m respectively. Computational cost for 200 trial runs: CL-DCEE total times ≈ {N=5: 21.8 s, 10: 23.1 s, 50: 24.3 s, 100: 26.3 s, 200: 30.5 s, 1000: 56.8 s} versus Entrotaxis ≈ 2940.4 s (same 200 trials) — i.e., CL-DCEE consumed &lt;~1% of Entrotaxis compute for typical N≤100.",
            "performance_without_adaptation": null,
            "sample_efficiency": "High relative sample efficiency: convergence of estimator MSE and approach-to-source observed by ~1000 s (≈100 samples assuming 10 s/sample). CL-DCEE updates estimators every sample and converges faster than the benchmark Entrotaxis in simulations.",
            "exploration_exploitation_tradeoff": "Built into the cost J(u) = (M0 - predicted_mean)^2 + P_pred; the first term enforces exploitation by steering to where high concentration is predicted, the second term enforces exploration by steering to positions that reduce predicted ensemble variance. No hand-tuned scalar tradeoff weight is required—the terms arise naturally from the one-step-ahead prediction.",
            "comparison_methods": "Entrotaxis (information-theoretic IPP implemented with particle filter), prior DCEE (particle-filter-based dual control), Chemotaxis (reactive gradient-based), pure exploitation variant (P term removed, not numerically reported).",
            "key_results": "1) CL-DCEE provides a practical myopic dual-control active learning method with theoretical convergence guarantees (Theorems 1 and 2) under bounded unbiased noises and persistent-excitation-like conditions. 2) Multi-estimator ensemble quantifies uncertainty cheaply (far fewer estimators than particle filters) and enables a variance-driven exploration term. 3) In simulations CL-DCEE attains much lower computational cost (≈100x reduction) and competitive or better source-approach performance when sensor noise is unbiased and environment known; tens of estimators (N≥50) suffice for good performance. 4) In a real, highly time-varying dispersion dataset, CL-DCEE successfully locates the source despite many non-detections by leveraging the ensemble.",
            "limitations_or_failures": "Performance degrades under biased/noisy non-detection events (intermittent dropouts) especially with small ensemble sizes (N=5,10) due to accumulated biased measurements; requires sufficient ensemble size and persistent excitation (use of q past samples) to guarantee estimator convergence; relies on accuracy of the ATDM model (model bias can affect performance); algorithm is myopic (one-step-ahead) and multi-step lookahead is left for future work.",
            "uuid": "e1132.0",
            "source_info": {
                "paper_title": "Concurrent Active Learning in Autonomous Airborne Source Search: Dual Control for Exploration and Exploitation",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Entrotaxis",
            "name_full": "Entrotaxis (information-theoretic informative path planning)",
            "brief_description": "An information-theoretic active search strategy that chooses agent motions to maximize expected information gain (minimize posterior entropy/variance) using a particle-filter-based inference engine; used in this paper as the primary benchmark.",
            "citation_title": "Entrotaxis as a strategy for autonomous search and source reconstruction in turbulent conditions",
            "mention_or_use": "use",
            "agent_name": "Entrotaxis",
            "agent_description": "Information-theoretic informative path planner: uses particle filtering (in experiments here: 10,000 particles) to represent posterior over source parameters and selects next moves from a discretised action set by maximising expected entropy reduction or other information measures; in the experiments action set U = {8 cardinal/diagonal directions} with fixed step size 2 m.",
            "adaptive_design_method": "Information gain maximization / entropy-based active learning (informative path planning).",
            "adaptation_strategy_description": "Uses a particle-filter posterior to predict expected information gain for candidate next moves and selects the action expected to reduce posterior uncertainty the most (pure exploration objective).",
            "environment_name": "Autonomous airborne source search (same isotropic-plume simulations and experimental dispersion dataset used as CL-DCEE comparison)",
            "environment_characteristics": "Partially observable, stochastic dispersion with sensor noise and non-detection events; continuous-space plume but Entrotaxis uses discretised candidate moves and particle-filter belief; unknown source and environmental parameters estimated via particle filter.",
            "environment_complexity": "Same spatial domain (100 m × 100 m × 1 m); particle filter used with 10,000 particles; discrete action set of 8 directions with fixed 2 m step size; sampling every 10 s in simulations.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Provides robust posterior estimation and strong resilience to sensor dropouts and unknown environment parameters, but requires many measurements to update particle filter (slow acquisition). In experiments here Entrotaxis's computation for 200 trials was ≈2940.4 s (much larger than CL-DCEE). It tends to keep the agent farther from the true source (qualitatively large steady-state agent-source distance) while achieving acceptable estimator MSE eventually.",
            "performance_without_adaptation": null,
            "sample_efficiency": "Lower sample efficiency in these experiments: requires many measurements (and many particles) to update the posterior and achieve estimator accuracy; acquisition continues until flight termination under limited budgets.",
            "exploration_exploitation_tradeoff": "Primarily pure exploration (information-theoretic): aims to reduce estimator posterior uncertainty rather than explicitly steering the agent to the currently-believed maximum concentration; this can lead to probing informative regions instead of exploiting the current estimate.",
            "comparison_methods": "CL-DCEE (ensemble dual-control) and Chemotaxis; baseline in the paper for informative-path planning.",
            "key_results": "Entrotaxis is computationally expensive (particle filter with many particles and sampling-based planning) but robust to sensor dropouts and unknown environmental parameters; because it focuses on exploration it can maintain larger distance to the true source even when estimate is accurate; not suitable for onboard implementation on low-power processors without simplification.",
            "limitations_or_failures": "Very heavy computational burden (particle filters + optimisation); discrete and limited feasible action set reduces flexibility; typically executed offboard in prior work; no rigorous convergence analysis provided in prior studies (as noted by the authors).",
            "uuid": "e1132.1",
            "source_info": {
                "paper_title": "Concurrent Active Learning in Autonomous Airborne Source Search: Dual Control for Exploration and Exploitation",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "DCEE (prior)",
            "name_full": "Dual Control for Exploration and Exploitation (prior formulation)",
            "brief_description": "A previously-introduced dual-control framework that formalizes autonomous search as a control problem balancing exploration (information acquisition) and exploitation (moving towards believed source), typically implemented with particle filters and model predictive planning; cited as motivation and contrasted with CL-DCEE.",
            "citation_title": "Dual control for exploitation and exploration (DCEE) in autonomous search",
            "mention_or_use": "mention",
            "agent_name": "DCEE (prior work)",
            "agent_description": "Dual-control framework combining particle-filter based Bayesian estimation of source/environment parameters and control strategies that attempt to balance exploration and exploitation (often implemented via model predictive control or information-theoretic objectives).",
            "adaptive_design_method": "Dual control with particle-filter Bayesian inference and informative planning (information-theoretic components / model-predictive control).",
            "adaptation_strategy_description": "Evaluates candidate control sequences by predicting their effect on future posteriors using particle filters and optimises expected information gain vs task objective, but requires costly nested inference-in-optimization loops.",
            "environment_name": "Autonomous airborne source search (motivating prior work and conceptual predecessor to CL-DCEE)",
            "environment_characteristics": "Partially observable, stochastic plume dispersion; unknown parameters; typically noisy sensors and discrete candidate actions in prior implementations.",
            "environment_complexity": "Prior implementations used discretised action sets and heavy particle-filtering; computational costs restricted onboard deployment and continuous action flexibility.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Reported to have good empirical performance in experiments but high computational cost; the prior DCEE required remote/offboard computation in earlier studies and lacked rigorous convergence proofs.",
            "performance_without_adaptation": null,
            "sample_efficiency": null,
            "exploration_exploitation_tradeoff": "Explicitly attempts to balance exploration and exploitation via dual control; often implemented through information-theoretic objectives or MPC formulations that include uncertainty terms.",
            "comparison_methods": "CL-DCEE (this paper argues CL-DCEE reduces computational cost and provides theoretical convergence), Entrotaxis, particle-filter IPP methods.",
            "key_results": "DCEE provides a principled dual-control view but in prior work relied on particle filters and optimisation which induced high computational cost and lacked formal convergence guarantees; motivated CL-DCEE which replaces particle filters with an ensemble and gradient-based planning to enable onboard use and provable convergence.",
            "limitations_or_failures": "High computational cost due to nested Bayesian inference during planning; limited feasible action sets in implementations; no rigorous theoretical convergence analysis in prior DCEE publications (as cited).",
            "uuid": "e1132.2",
            "source_info": {
                "paper_title": "Concurrent Active Learning in Autonomous Airborne Source Search: Dual Control for Exploration and Exploitation",
                "publication_date_yy_mm": "2023-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Dual control for exploitation and exploration (DCEE) in autonomous search",
            "rating": 2,
            "sanitized_title": "dual_control_for_exploitation_and_exploration_dcee_in_autonomous_search"
        },
        {
            "paper_title": "Entrotaxis as a strategy for autonomous search and source reconstruction in turbulent conditions",
            "rating": 2,
            "sanitized_title": "entrotaxis_as_a_strategy_for_autonomous_search_and_source_reconstruction_in_turbulent_conditions"
        },
        {
            "paper_title": "Infotaxis as a strategy for searching without gradients",
            "rating": 2,
            "sanitized_title": "infotaxis_as_a_strategy_for_searching_without_gradients"
        },
        {
            "paper_title": "Simple and scalable predictive uncertainty estimation using deep ensembles",
            "rating": 2,
            "sanitized_title": "simple_and_scalable_predictive_uncertainty_estimation_using_deep_ensembles"
        },
        {
            "paper_title": "Planning to be surprised: Optimal bayesian exploration in dynamic environments",
            "rating": 1,
            "sanitized_title": "planning_to_be_surprised_optimal_bayesian_exploration_in_dynamic_environments"
        }
    ],
    "cost": 0.01589625,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Concurrent Active Learning in Autonomous Airborne Source Search: Dual Control for Exploration and Exploitation
24 Jul 2022</p>
<p>Member, IEEEZhongguo Li 
Department of Aeronautical and Automotive Engineering
Loughborough University
LE11 3TULoughboroughU.K</p>
<p>Fellow, IEEEWen-Hua Chen w.chen@lboro.ac.uk 
Department of Aeronautical and Automotive Engineering
Loughborough University
LE11 3TULoughboroughU.K</p>
<p>Senior Member, IEEEJun Yang j.yang3@lboro.ac.uk 
Department of Aeronautical and Automotive Engineering
Loughborough University
LE11 3TULoughboroughU.K</p>
<p>Concurrent Active Learning in Autonomous Airborne Source Search: Dual Control for Exploration and Exploitation
24 Jul 2022460068ED0D840A0119BEF6BF647C419FarXiv:2108.08062v2[eess.SY]Autonomous searchoptimisation and learningdual controlexploration and exploitationpath planningsource search and estimation
In this paper, a concurrent learning framework is developed for source search in an unknown environment using autonomous platforms equipped with onboard sensors.Distinct from the existing solutions that require significant computational power for Bayesian estimation and path planning, the proposed solution is computationally affordable for onboard processors.A new concept of concurrent learning using multiple parallel estimators is proposed to learn the operational environment and quantify estimation uncertainty.The search agent is empowered with dual capability of exploiting current estimated parameters to track the source and probing the environment to reduce the impacts of uncertainty, namely Concurrent Learning based Dual Control for Exploration and Exploitation (CL-DCEE).In this setting, the control action not only minimises the tracking error between future agent's position and estimated source location, but also the uncertainty of predicted estimation.More importantly, the rigorous proven properties such as the convergence of CL-DCEE algorithm are established under mild assumptions on noises, and the impact of noises on the search performance is examined.Simulation results are provided to validate the effectiveness of the proposed CL-DCEE algorithm.Compared with the information-theoretic approach, CL-DCEE not only guarantees convergence, but produces better search performance and consumes much less computational time.</p>
<p>I. INTRODUCTION</p>
<p>P UBLIC concern towards safety and health issues has been significantly exacerbated during the past few decades, due to rapid industrial development and increasing risks of terrorism.Identifying sources of airborne release (including chemical, biological, radiological and nuclear (CBRN) materials) is one of the most important tasks in disaster management and environment protection [1].In the early literature, source term estimation (STE) is mainly supported by onsite measurement using static sensor networks that are deployed beforehand in some specific areas of potential risks [1][2][3][4].This type of strategy is very costly, and only feasible for high-risk industry, e.g.nuclear power plants [5].Recently, significant research efforts have been dedicated to the development of dynamic estimation of airborne release assisted by mobile platforms, for example, autonomous ground robots [6][7][8][9] and unmanned aerial vehicles (UAVs) [10][11][12].Compared with conventional static methods, autonomous search is much more flexible and cost-effective in emergent accident management.Comprehensive surveys of recent progress on source localisation using autonomous vehicles have been reported in several review papers [1,13,14].</p>
<p>There are various methods dealing with this problem [1,7].Among them, informative path planning (IPP) becomes increasingly popular, e.g.Infotaxis [8] and Entrotaxis [15].Vergassola et al. [8] proposed an informative search approach, referred as Infotaxis, by which the agent moves to the next position that is expected to minimise uncertainties of the posterior distribution.Hutchinson et al. [15] developed Entrotaxis algorithm that steers the agent to search over the most uncertain area in the next movement.More recently, some advanced versions of the above algorithms have been developed aiming to improve their robustness, search speed and accuracy in more complex search environment, including Infotaxis II [16], Entrotaxis-jump [17] and hybrid of Infotaxis and Entrotaxis [18].Zhao et al. [17] proposed an Entrotaxisjump algorithm for source search in large-scale road networks with intermittent jumps to traverse obstacles [17].In [18], a number of hybrid strategies combining Infotaxis and Entrotaxis are proposed in the random obstructed environment with forbidden search areas.Essentially, information-theoretic approaches aim to reduce uncertainties of estimated source location and unknown environment parameters.Therefore, the reward function, which the agent targets to maximise while making its next movement, is defined according to the information gain using some informative measures [19], for example, entropy, Kullback-Leibler divergence and variance.</p>
<p>Apart from information-theoretic methods, another main branch for source seeking is the optimisation approach.Stochastic extremum seeking is employed to direct a nonholonomic unicycle towards the maximum of an unknown signal field [20].A simultaneous perturbation stochastic approximation approach (SPSA) is developed to approach a minimiser of a source signal for environment with and without obstacles [21], which can be traced back to the early work in [22].An adaptive gradient climbing method is designed for cooperative mobile sensors to seek the optimiser of environmental field in [23].It is worth mentioning that convergence guarantees of those algorithms have been well-studied by leveraging advanced control and stochastic approximation techniques.In those learning based control approaches, the unknown parameters of the environment are passively updated.In Bayesian framework developed in [24], optimal trajectory planning uses the current estimate to plan the future trajectory in order to maximise cumulative probability of detection or minimise mean time of detection.In fact, the control actions of aforementioned works are designed based on the principle of certainty equivalence by treating the current estimation of the environment as the true parameters.As a result, estimation uncertainty is not explicitly taken into account when the search agent makes next movement.</p>
<p>Recently, Chen et al. [7] have reformulated the autonomous search problem from a control-theoretic perspective, referred as Dual Control for Exploration and Exploitation (DCEE).The ultimate goal of autonomous search is to design a control strategy that can navigate the agent to an unknown release in an unknown environment, which is a well-posed goaloriented control problem.Distinct from traditional control settings where operational systems are manipulated by following predefined references or setpoints, the autonomous search problem does not have such a given reference or path that can directly lead the agent to the source.Instead, the agent is required to explore the operational environment to learn the source parameters, and at the same time exploit its belief to move towards the source.From the perspective of dual control, information-theoretic approach is a pure exploration strategy aiming at collecting information from unknown environment while model predictive control (MPC) is a pure exploitation approach targeting at making full use of current uncertain estimation.This novel dual control framework achieves a natural balance between the two objectives, and has demonstrated superior performance in real experiments compared with MPC and IPP.</p>
<p>Although DCEE offers a conceptually promising framework in autonomous search, similar to all the existing informationtheoretic approaches, currently it still suffers from two drawbacks: computational burden and no rigorous analysis of its properties such as stability and convergence.IPP and DCEE approaches demand massive computational burden imposed by nonlinear particle filters and optimisation based path planning [15,25,26].More specifically, the Bayesian inference engine is involved in the optimisation loop for informative path planning since the influence of the control action on the predicted posterior of the estimated source and environment parameters is evaluated at each iteration.Consequently, the search algorithm is restricted to be a set of certain moving directions with a fixed step size, and currently carried out remotely in a control centre, rather than onboard on the mobile robot in the existing experimental studies [6,7,10,27].This significantly restricts their practical applications in autonomous search in a wide area or an extreme environment.Hence, less computationally demanding alternatives are needed so that online computation can be achieved by portable processors on mobile platforms.To the best of our knowledge, currently there are quite limited proven properties of IPP autonomous search strategies.This was actually a main motivation of formulating it from a control-theoretic approach in [7] since it enables to get access to rich knowledge and tools available in control theory.No rigorous analysis on convergence is provided but mainly illus-trated through extensive simulation and experimental studies.In IPP and DCEE, the agent's movement (path planning) and source estimation (environment acquisition) are strongly coupled: the agent takes actions according to the current estimation of source parameters and the estimators update their knowledge by using the concentration collected at agent's new position determined by path planning.This coupling, together with noisy measurement, environment turbulence, complicated particle filtering and optimisation involved in implementation of the search strategy, makes the rigorous analysis of theoretic properties of these search strategies quite challenging.Those two critical limitations motivate this study.</p>
<p>In this paper, inspired by the concept of DCEE, we propose a concurrent learning based DCEE scheme with multiple estimators that encompasses dual effects: driving the agent to the believed location by exploiting current estimation, and reducing uncertainties by exploring the unknown operational environment, which is referred as Concurrent Learning based Dual Control for Exploration and Exploitation (CL-DCEE) for the sake of simplicity.The underlying principle of the concurrent learning scheme advocated in this paper is distinct from the classic dual control in handling the two intricate coupling elements of the system and the environment.Existing dual control approaches impose a probing effect on the system itself, for example, state estimation in stochastic control [28,29] and parameter estimation in adaptive control [30,31].On the other hand, the dual effect introduced in our formulation is used to explore the operational environment, as our objective is to acquire a better understanding of the unknown environment such that the agent is able to approach the true source location.</p>
<p>To address the two challenges of computational burden and proven properties, two approaches are proposed in this paper.Instead of implementing computationally demanding particle filtering, an efficient multi-estimator scheme is proposed for source and environment learning.The number of estimators used in CL-DCEE is much smaller than that of particles required for Bayesian filters in information-theoretic algorithms.These estimators run in parallel from a set of randomly started initial estimates.There are several fundamental incentives promoting us to employ multiple concurrent estimators.First, compared with employing a single estimator, this multi-estimator approach provides a means to quantify uncertainty associated with source estimators, which is of great importance to empower the search agent with dual capability of exploration and exploitation.Secondly, it significantly improves performance and robustness over a single estimator.The performance of a single estimator (such as an observer or learning machine) is often severely influenced by the initialisation and setting of the individual estimator, for example, state estimation [32], disturbance observer [33] and parameter adaptation [34].To our knowledge, there is few result on multi-estimator assisted control algorithms.Devising multiple parallel estimators for the source parameters is conducive to eliminating undesirable behaviour caused by random initialisation of an individual, and also it allows us to take advantage of a priori probability density function (PDF) of source parameters.To further reduce the computational load, effective gradient-based optimisation algorithms are utilised to replace the complicated path planning process in the existing methods.It is shown that by combining these two techniques, we are able to reduce the computational load by 100 times while significantly increasing the admissible control set.Most importantly, we establish theoretical guarantee of convergence of the CL-DCEE algorithm, and analyse the steady-state performance of the estimation and search by directly linking them with sensor and environment characters.</p>
<p>In summary, the key contributions of this paper are enumerated as follows.</p>
<p>1) A concurrent active learning algorithm with multiple environment estimators is developed, which achieves a balanced trade-off between exploitation of believed source location and exploration of uncertain environment, that is, simultaneously navigating the agent to the source and reducing the impacts of uncertainties associated with the acquired environment knowledge.</p>
<p>2) The convergence of the proposed autonomous search algorithm, CL-DCEE, is rigorously established under sensor and control noises, by leveraging a memory based stochastic approximation and a gradient based path planning strategy.</p>
<p>3) The proposed CL-DCEE provides a computationally efficient solution for autonomous search of airborne source release.Simulation and experiment results are provided to demonstrate the performance of the proposed method in comparison with information-theoretic approaches.Our solution shows superior performance with significant reduction in computational time.The remainder of this paper is organised as follows.In Section II, we formulate the autonomous search problem and develop feasible value functions for the path planning and estimation.In Section III, CL-DCEE algorithm is proposed by deploying multiple environment estimators.Section IV provides simulation results and detailed discussions in comparison with existing approaches.Experimental study using a real dataset is presented in Section V. Section VI concludes this paper.</p>
<p>II. PROBLEM FORMULATION A. Agent Modelling</p>
<p>The searching agent is considered as a fully autonomous vehicle, for example, a mobile robot or a UAV, which is equipped with chemical/biological sensors.We assume that the agent has been devised with a low-level controller that can steer the agent to the desired position directed by highlevel decision-making process.Therefore, the dynamics of the search agent can be simplified as
p k+1 = p k + u k + w k(1)
where p k = [p k,x , p k,y , p k,z ] T ∈ Ω ⊆ R 3 denotes the position of the searching agent at current step k with Ω being a convex and compact searching space, u k ∈ U ⊆ R 3 is the control action with U being the admissible set of actions, and w k is the control error.It is worth mentioning that in this paper the admissible set U can be continuous, which is distinct from the existing results in [6,7,10] where the search is restricted to certain directions with a fixed step size.</p>
<p>B. Dispersion Modelling</p>
<p>Atmospheric transport and dispersion model (ATDM), governing the spatial-temporal diffusion of the pollutant materials, is utilised to predict the concentration in space and time, given the parameters of a release.In this paper, we denote true source parameters as Θ s = [s T , q] T ∈ R 4 with s = [s x , s y , s z ] T ∈ R 3 being the position of the source and q ∈ R + representing a positive release rate.The dispersion model is given by
M (p k , Θ s ) = q 4πζ s1 ||p k − s exp − p k − s ζ × exp − (p k,x − s x ) u s cos ρ s 2ζ s1 × exp − (p k,y − s y ) u s sin ρ s 2ζ s1(2)
where environmental parameters include the wind speed u s , wind direction ρ s , diffusivity ζ s1 , the particle lifetime ζ s2 , and
a composite coefficient ζ = ζs1ζs2 1+(u 2 s ζs2)/(4ζs1) .</p>
<p>C. Sensor Modelling</p>
<p>Information collection in autonomous search of an airborne release is mainly from onboard chemical/biological sensors.As the search agent moves to a new position, concentration measurement will be taken.The agent is required to remain at current position for a short period to obtain a reliable reading, referred as the sampling time.It is likely that the sensors fail to detect any meaningful readings.Sensors deployed on mobile platforms are usually low-price portable devices whose performances are seriously constrained by limited power supply and local turbulence.As summarised in [11], there are several scenarios that may cause a non-detection event: 1) there is no chemical material present in the current position, or present but out of the detection range of the sensor; 2) the source is present in the position but the detector fails to receive any material due to intermittent turbulence; 3) the concentration is below a pre-specified threshold, and is thus classified as a non-detection event.</p>
<p>In summary, the sensor reading can be modelled as
z(p k ) = M (p k , Θ s ) + v k , D = 1 vk , D = 0 (3)
where M is the true chemical concentration, D denotes either a detection event D = 1 or a non-detection event D = 0, and v k and vk represent additive Gaussian noises imposed on the sensor readings.The probability distribution of D is a random process, usually characterised by Poission distribution.</p>
<p>For theoretical analysis, we assume that the sensor can always receive concentration with additive white noises.In simulation and experiment, we will test the performance of the proposed algorithm with and without sensor dropouts.</p>
<p>D. Objective Function Construction</p>
<p>The dispersion model in ( 2) is referred as an isotropic plume (IP) model [8].There are many other commonlyused dispersion models, such as Gaussian plume (GP) and computational fluid dynamics (CFD) [35].Nevertheless, the model can be understood as a concentration function that possesses the highest value at the release centre and decreases monotonically as the increase of the distance to the centre (in terms of expectation).Thus, it can be used to formulate an optimisation objective for the autonomous agent, by taking the position p k as the optimisation variable.Following the convention in optimisation theory, the objective function is defined as
g (p k , Θ k ) = (M 0 − M (p k , Θ k )) 2(4)
where M 0 is a predefined upper bound of the concentration measurement.It is clear that the optimal solution of ( 4) is
p * k = s, where M (p * k , Θ s ) is maximised.
To estimate the source location s and release rate q based on available measurements, we may define an additional value function taking the source term as the decision variable.Least square methods can serve for this purpose, given by
f (Θ i , p i ) = [M(p i , Θ i ) − z(p i )] 2(5)
where z(p i ) denotes the measured concentration at agent position p i , ∀i = 1, . . ., k.</p>
<p>III. CONCURRENT LEARNING FOR DUAL CONTROL WITH EXPLORATION AND EXPLOITATION A. Framework of Concurrent Learning with Dual Effects</p>
<p>Suppose that the search agent aims to minimise the objective function defined in (4) at each step.Then, it will move to the position where the maximum concentration measurement is expected based on the current belief of the source, i.e. its estimate Θ k .This type of method can be understood as a pure exploitation strategy, which aims to make full use of the current estimation of the source parameters Θ k .If the source estimators were perfect without any noisy disturbances or uncertainties, then exploiting the trustworthy estimator would accelerate the speed of finding the source and its associated parameters.Nonetheless, the operational environment is often uncertain, and perfect estimation is never available.This motivates the development of active learning methods to autonomously explore the unknown environment so as to construct more accurate estimators.</p>
<p>The dual control framework for autonomous source search and estimation was firstly introduced by Chen et al. [7] recently.The goal is to drive the agent towards the believed position of a release and in the meanwhile reduce uncertainty associated with the estimation of the target position.Generally speaking, uncertainty is often measured in a stochastic sense for probability density function of a variable.In [15], particle filters are utilised to estimate the source parameters and the uncertainty associated with the estimated source target.However, it requires a large number of particles to support the Bayesian inference engine, which incurs heavy computational burden.Quantifying the uncertainty is of great importance, as demonstrated in our previous works [6,7,11,15].To alleviate this problem, we thus introduce a set of N source term estimators and they are initialised according to the prior knowledge of the source parameters.It is worth emphasising that the number of estimators N is much smaller than that of particles in Bayesian filters as shown later.</p>
<p>The concentration information collected up to time step k is denoted by Z k := {z (p 1 ) , z (p 2 ) , . . ., z (p k )}.Let Θ i k be the source term estimation of the ith estimator at the kth measurement, and Θk := 1 N N i=1 Θ i k as the nominal estimation, i.e. the mean, of the source parameters.The posterior distribution of source estimation can be represented by ρ k|k := p (Θ|Z k ) at time k.When the search agent moves to a new position directed by the control input u k , the hypothetical posterior distribution of source estimation will be updated as ρk+1|k := p Θ|Z k+1|k where Z k+1|k = {Z k , ẑk+1|k }, and consequently the future belief of concentration can be regarded as a random variable conditional on u k , denoted as ẑk+1|k ∼ p ẑk+1|k |u k .As a result, the control input u k will not only affect the future concentration measurement at agent's new position but also affect the belief of future measurement distribution.</p>
<p>Motivated by the above discussion, the control input u k should be designed to navigate the agent to the position where the predicted posterior of the measurement ẑk+1|k is close to the predefined threshold M 0 .Therefore, the conditional cost function can be formulated as
min u k ∈U J(u k ) = min u k ∈U E Θ E ẑk+1|k M 0 − ẑk+1|k 2 |Z k+1|k (6a) subject to p k+1|k = p k + u k + w k . (6b)
The physical interpretation is, based on all the available information including priors and available measurements, we would like the robot moving to a place where the predicted maximum concentration is located.This mechanism is behind Chemotaxis, a widely adopted search strategy in nature from bacteria to human being [36].We show that the control action u k , obtained from the optimisation problem in (6), implicitly carries dual effects.We define zk+1|k as the nominal predicted concentration of the future virtual measurements, i.e. the mean of p ẑk+1|k |u k , written as
zk+1|k := E ẑk+1|k |Z k+1|k .(7)
Based on the definition of zk+1|k , we can further define zk+1|k = ẑk+1|k − zk+1|k .Therefore, the objective function can be reformulated as
J(u k ) = E Θ,ẑ k+1|k M 0 − zk+1|k − zk+1|k 2 |Z k+1|k .
(8) Expanding ( 8) leads to
J (u k ) =E M 0 − zk+1|k 2 |Z k+1|k − 2E zk+1|k M 0 − zk+1|k |Z k+1|k + E z2 k+1|k |Z k+1|k .(9)
Since M 0 and zk+1|k are deterministic variables and E zk+1|k = 0, it follows that
J (u k ) = E M 0 − zk+1|k 2 |Z k+1|k + E z2 k+1|k |Z k+1|k . (10) In case of N estimators, we have zk+1|k = 1 N N i=1
ẑi k+1|k , with ẑi k+1|k being the predicted measurement at agent's future position p k+1|k based on the ith source estimator Θ i k .Then, the optimisation problem for CL-DCEE can be formulated as
min u k ∈U J(u k ) = min u k ∈U M 0 − zk+1|k 2 + P k+1|k(11a)P k+1|k := 1 N N i=1 (ẑ i k+1|k − zk+1|k ) 2(11b)p k+1|k = p k + u k + w k . (11c)
Remark 1: According to the definition of P k+1|k in (11b), it is clear that P k+1|k is the predicted variance of ẑi k+1|k , ∀i = 1, . . ., N, given that each estimator has a uniform weight of 1/N .The value function in (11a) consists of two parts: the first part exploits current information by navigating the agent towards the believed position of higher concentration, and the second part aims to gather more information by reducing the variance of future virtual measurements.In short, exploitation drives the agent to the position where high concentration is expected by minimising (M 0 − zk+1|k ) 2 , while the exploration effect makes the agent search over some position that can reduce the predicted variance of the concentration by minimising P k+1|k .The first term in (11a) is closely related to the exploitation objective (4) by navigating the agent to higher concentration field.Because the estimators are updated according to the least square function in (5), the second term in (11a) is determined by the updating mechanism of the estimators.</p>
<p>Remark 2: Recently, how to balance between exploration and exploitation has aroused extensive discussions and arguments in many areas, in particular artificial intelligence, optimisation and decision-making [7,28].In some cases, artificial weights are introduced on purpose to impose both effects [28].From the above formulation process of our framework, a natural balance between the two effects is derived from a physically meaningful cost function.Accordingly, our framework eliminates the requirement for choosing trade-off weights.</p>
<p>To obtain the variance P k+1|k , we resort to the classical principle of predicting variance estimation in extended Kalman filters [37], which can be formulated as
P k+1|k = P k|k F T k+1 F k+1 F i k+1 = ∂M p k , Θ i k ∂p(12)
where
P k|k = 1 N N i=1 (z i k − zk ) 2 denotes current variance of estimated measurement, z i k = M p k , Θ i k , zk = 1 N N i=1 z i k and F k+1 = col[F 1 k+1 , . . . , F N k+1 ].
In (12), p k+1|k is future position of the agent, which will serve as the optimisation variable in the CL-DCEE algorithm.Now, we can present the gradient-based optimisation algorithm for the source term estimation and path planning.For notational convenience, we will use
y(p k , Θ k ) = (M 0 − zk+1|k ) 2(13)
to denote the first term in the dual objective (11a).Inspired by the memory based regression parameter estimation methods [38], the N source estimators can be updated according to
Θ i k+1 = Θ i k − k t=k−q+1 η t ∇Θ f (Θ i k , p t ), ∀i = 1, 2, . . . , N(14)
where q is a positive integer denoting the number of past measurement used at the kth iteration.The path planning is given by
p k+1 = p k + u k + w k u k = −δ k ∇ p y (p k , Θ k ) + ∇ p P k+1|k(15)
where η t , δ k are constant step sizes to be designed, and Θ k represents the collection of all N estimators.Note that ∇ p y (p k , Θ k ) and ∇ p P k+1|k are pure predictions without measurement noises.Basically, algorithms ( 14) and ( 15) use gradient descent method to ensure that the agent moves towards the believed position of a release and the source estimators converge to the true parameters that minimise the least square function in (5).</p>
<p>The approximated gradients of the least square function ( 5) can be written as
∇Θ f (Θ i k , p k ) = ∇ Θ f (Θ i k , p k ) + µ k (16)
where µ k denotes the gradient noises, which can be regarded as a source of perturbation to the true gradient caused by the sensory noises.</p>
<p>For convergence analysis, some basic assumptions on the gradient and control noises are introduced in the following.</p>
<p>Assumption 1: The noise µ k in ( 16) satisfies the following properties:
E [µ k ] = 0 (17) E µ k 2 ≤ 2(18)
where is a positive constant.The position control error has similar properties:
E [w k ] = 0 (19) E w k 2 ≤ ρ 2 (20)
where ρ is a positive constant.Remark 3: Assumption 1 implies that the noises have zero mean and bounded variance.As a result, the noises are unbiased.The noise variance is assumed to be bounded as in (18) and (20).There are a number of reasons for the use of noisy variables.First, in real experiment, the position where measurement is collected might not be exactly the same position as p k .Possible causes are the error in the positioning system such as GPS for outdoor operation or SLAM (Simultaneous Localisation and Mapping) for indoor operation, or control errors in the lower loop.The autonomous search scheme acts as a higher level path planning and it passes the path or way points to a lower level controller to follow which may have control error due to disturbance and other reasons (e.g.local turbulence for a UAV operation).Second, the concentration measurements collected are strongly subject to sensor noises and uncertainties.In this paper, we deploy additive white noise term to quantify those impacts, and we will analyse how the agent will behave under uncertain information.</p>
<p>In summary, the implementation structure of CL-DCEE can been encapsulated in Algorithm 1.The key feature of our algorithm is the adoption of dual effects for exploitation and exploration.Multiple estimators have been developed for source term construction, which provides an effective tool for quantifying information uncertainty.In order to reduce future variance of the measurement, we need to predict future concentration by using current parameters of ATDM, based on which the exploration objective P k+1|k can be formulated as a function of optimisation variable p k+1|k .</p>
<p>Algorithm 1 Implementation structure of CL-DCEE Initialisation:</p>
<ol>
<li>
<p>specify the number of estimators N 2. conduct a number of q initial samples (p i , z(p i )) indexed by i = −q + 1, −q + 2, . . ., 0 3. initialise the agent's position p 0 and the initial guess of the source parameter Θ i 0 for all i = 1, 2, . . ., N Iteration:</p>
</li>
<li>
<p>set k := k + 1 5. collect the concentration reading from the sensor at position p k 6. for i = 1 : N update the estimated source terms by
Θ i k = Θ i k−1 − k t=k−q+1 η t ∇Θ f (Θ i k−1 , p t ) end for 7. calculate current estimation variance P k|k = 1 N N i=1 (z i k − zk ) 2 8. predict future variance as a function of p k+1|k F i k+1 = ∂M(p k+1|k ,Θ i k ) ∂p p k+1|k ,Θ i k P k+1|k = P k|k F T k+1 F k+1 9.
update the next movement for the agent by
u k = −δ k ∇ p y (p k , Θ k ) + ∇ p P k+1|k p k+1 = p k + u k + w k End if termination condition is satisfied or iteration budget is approached.
Remark 4: There is an important difference between the traditional gradient-based search methods such as in Chemotaxis and the proposed CL-DCEE algorithm in this study.In the early works (e.g.[39,40]), mobile robots are equipped with sensors that directly collect the local gradients of concentration, and utilise the measured gradients to plan their next movement.Clearly, this type of search suffers severely from sensor errors and turbulent fluctuations, since the next movement is purely determined by instantaneous gradient measurements.In our framework, the search agent measures local concentration value, and uses all the available information, including priors and available measurements, to learn the source parameters.Based on the acquired knowledge of source, the search agent uses model evaluated gradients to plan its next movement.This learning process lasts over the entire period of search, and therefore an instant sample, subject to noise and turbulence, will not cause considerable interruption to the path planning.Combining with the multiestimator scheme, the robustness of CL-DCEE algorithm is significantly improved, and is able to achieve comparable search performance as information-theoretic methods with less computational load, which will be demonstrated later through theoretical and simulation studies.</p>
</li>
</ol>
<p>B. Convergence Analysis</p>
<p>In this subsection, we will show that the path planning algorithm (15) in conjunction with multiple source estimators (14) will lead the agent to a small neighbourhood of the source location s.</p>
<p>Theorem 1: Under Assumption 1, all N source estimators in ( 14) converge to a neighbourhood of the true position of the release s from a random initialisation set if the learning rate η t of each estimator is chosen such that
Γ i k = I 4 − k t=k−q+1 η t T i k (t) 2(21)satisfies 0 &lt; Γ i k &lt; 1, where T i k (t) := 1 0 ∇ 2 Θ f (Θ s + τ Θi k , p t )dτ.
Moreover, the expected mean-square-errors (MSE), E Θ i k − Θ s 2 , ∀i = 1, . . ., N , converge at a geometric rate to a bounded neighbourhood of zero, given by
lim k→∞ E Θ i k − Θ s 2 ≤ sup j∈[1,∞) ( j t=j−q+1 η 2 t 2 ) 1 − sup j∈[1,∞) (Γ i j )
.</p>
<p>Proof: It follows from ( 14) and ( 16) that
Θ i k+1 = Θ i k − k t=k−q+1 η t ∇ Θ f (Θ i k , p t ) + µ t(23)
Now, let Θi k = Θ i k − Θ s denote the error of the agent's estimation relative to source parameters.Then, substituting Θk into (23) results in the error dynamics as
Θi k+1 = Θi k − k t=k−q+1 η t ∇ Θ f Θ i k , p t + µ t .(24)
To relate the gradient term with Θi k , we resort to the mean value theorem [41].For a twice-differentiable function H(x) : R m → R, the following relation holds, for any
a, b ∈ R m , ∇ x H(b) =∇ x H(a) + 1 0 ∇ 2 x H[a + τ (b − a)]dτ (b − a).(25)
Therefore, applying the above theorem leads to
∇ Θ f Θ i k , p t =∇ Θ f (Θ s , p t ) + 1 0 ∇ 2 Θ f (Θ s + τ Θi k , p t )dτ Θi k (26)
Let us denote
T i k (t) := 1 0 ∇ 2 Θ f (Θ s + τ Θi k , p t )dτ.(27)
Consequently, substituting ( 27) and ( 26) into (24) yields
Θi k+1 = I 4 − k t=k−q+1 η t T i k (t) Θi k − k t=k−q+1 η t µ t (28)
where ∇ Θ f (Θ s , p t ) = 0 has been used.Taking the square of the Euclidean norm of the error dynamics (28) gives
Θi k+1 2 = I 4 − k t=k−q+1 η t T i k (t) Θi k − k t=k−q+1 η t µ t 2 = I 4 − k t=k−q+1 η t T i k (t) Θi k 2 + k t=k−q+1 η 2 t µ t 2 − 2 (I 4 − k t=k−q+1 η t T i k (t)) Θi k T k t=k−q+1 η t µ t . (29) Let Q i k := E Θi k 2
denote the expected mean-square-error of the variable Θk .Then, taking the expectation of ( 29) results in
Q i k+1 ≤ I 4 − k t=k−q+1 η t T i k (t) 2 Q i k + k t=k−q+1 η 2 t 2 − 2 E (I 4 − k t=k−q+1 η t T i k (t)) Θi k T k t=k−q+1 η t µ t = I 4 − k t=k−q+1 η t T i k (t) 2 Q i k + k t=k−q+1 η 2 t 2(30
) where conditions of the gradient noise in Assumption 1 have been utilised, i.e., µ t is white noise independent of Θ i k with bounded variance.To guarantee the convergence of the estimators, it is required that
Γ i k = I 4 − k t=k−q+1 η t T i k (t) 2(31)
within unit circle.Then, we have
lim k→∞ Q i k ≤ sup j∈[1,∞) ( j t=j−q+1 η 2 t 2 ) 1 − sup j∈[1,∞) (Γ i j )(32)
where lim k→∞ ( k j=1 Γ i j )Q i 0 = 0 has been applied.In view of (30), it can be concluded that the estimator MSE converges to a small neighbourhood of zero at a geometric rate, given by O(sup j∈[1,∞) Γ i j ).This completes the proof.Remark 5: To ensure that Γ i k in ( 21) is within unit circle, it is sufficient to require k t=k−q+1 T i k (t) &gt; 0 for a positive integer q under small learning rate η t &gt; 0. This is a commonlyused condition of persistent excitation in adaptive control and system identification [38,42].In essence, at each iteration k, not only current data sample (p k , z(p k )) is utilised for updating the environment parameter Θ k+1 but also past q − 1 step measurements (p j , z(p j )) for j ∈ {k − q + 1, . . ., k − 1} are used.This type of technique is motivated by the memory regressor extension, see [38], to relax the requirement of persistent excitation for each single sample.</p>
<p>Remark 6: The proposed parameter adaption algorithm in (14) encompasses two special cases commonly-used in existing literature: stochastic gradient approximation (q = 1) and full batch approximation (q = k).It is worth noting that increasing the iteration length q can enhance the robustness and accuracy of the adaption algorithm as the excitation effect will be more significant, but may also incur additional computational load [43].</p>
<p>Remark 7: Different from existing filtering techniques, like extended Kalman filter and Gaussian mixture filter, which usually rely on process models and stochastic properties of process noises to quantify the level of estimation uncertainty, the proposed concurrent learning method in this paper uses a hybrid approach that combines both model-based and modelfree techniques.The model-based parallel estimators essentially yield a distribution of the estimation at each iteration.A model-free approach is used to calculate the mean of the estimation and its variance based on the distribution of the estimations yielded by these parallel estimators.Recently, this hybrid model-based and model-free approach has been proven to be very successful and promising via extensive simulation and experimental studies [44,45] in machine learning community.It takes the advantage of the model-based approaches in sampling efficiency but alleviates its inherited model biased error using a model-free ensemble.However, there is no rigorous result for the ensemble approach in machine learning community despite its widely perceived success.Inspired by its success in machine learning, we propose a hybrid parameter estimation approach consisting of N parallel gradient based estimators and an ensemble process.This approach not only significantly increases the robustness of the parameter estimation particularly in the presence of intermittent sensor measurement but also provides a reliable way to quantify the level of uncertainty of the current estimation, which is important in realising the DCEE concept.In Theorem 1, we prove its global convergence of the estimation for our specific application by leveraging a memory based estimation method.</p>
<p>Theorem 1 shows the convergence of the estimators, i.e., the estimator will eventually converge using feasible path planning methods, but the optimality is not guaranteed.Convergence of source estimation can be achieved as long as the agent keeps collecting information that fulfils the conditions specified in Theorem 1.In a real search problem, the search environment is complex and there is limited time/sampling budget, and therefore the search agent has to actively plan its path to quickly approach the source.</p>
<p>Although the path planning and environment acquisition are coupled, it has been shown that under Assumption 1 source estimators can converge to true parameters when measurement samples k → ∞.This important property allows us to employ the well-known separation principle for the convergence analysis of the overall algorithm.Such an analytical principle has been widely used to establish the stability of disturbance observer based control (DOBC) [32,46], where design of the controller is separated from design of the observer.In addition, we will further analyse the composite search performance (steady-state performance) in relation to the noise characters.</p>
<p>Theorem 2: Consider a dispersion described by ATDM (2) and the measurement errors and disturbances satisfy Assumption 1.Let η t satisfy the condition specified in Theorem 1.If the step size δ k is designed such that
0 &lt; 2 I 3 − δ k L k 2 &lt; 1 (33)
where L k := 1 0 ∇ 2 p y(s + τ pk , Θ k )dτ , then the search agent converges to a bounded neighbourhood of the source location using the proposed CL-DCEE in Algorithm 1.Moreover, the steady-state MSE bound between agent and true source is given by
lim k→∞ E p k − s 2 ≤ ν2 + 2 1 − sup j∈[1,∞) (2 I 3 − δ j L j 2 )
(34) where ν &gt; 0 denotes the upper bound of the gradient norm of the estimators' variance ∇ p P k+1|k .Proof: According to the path update law (15), we have
p k+1 = p k − δ k ∇ p y (p k , Θ k ) + ∇ p P k+1|k + w k (35)
Denote pk = p k −s as the error of the agent's position relative to the source position.Consequently, the error dynamics of pk can be written as
pk+1 = pk − δ k ∇ p y (p k , Θ k ) − δ k ∇ p P k+1|k + w k . (36)
Following a similar argument as in Theorem 1, we have
pk+1 = (I 3 − δ k L k ) pk − δ k ∇ p P k+1|k + w k (37)
where
L k := 1 0 ∇ 2 p y(s + τ pk , Θ k )dτ.(38)
Then, taking the square of the Euclidean norm for both sides of the error dynamics (37) leads to
pk+1 2 = (I 3 − δ k L k ) pk − δ k ∇ p P k+1|k + w k 2 = (I 3 − δ k L k ) pk 2 + δ 2 k ∇ p P k+1|k 2 + w k 2 + 2[(I 3 − δ k L k ) pk ] T w k − 2δ k ∇ T p P k+1|k w k − 2δ k [(I 3 − δ k L k ) pk ] T ∇ p P k+1|k .
(39) Let P k := E pk 2 denote the expected mean-square-error between the agent's position and the source location.Taking the expectation of (39) and further applying the noise conditions in (19) and ( 20), we have
P k+1 ≤ I 3 − δ k L k 2 P k + E[δ 2 k ∇ p P k+1|k 2 ] + ρ 2 + E[2[(I 3 − δ k L k ) pk ] T w k ] − E[2δ k ∇ T p P k+1|k w k ] − E[2δ k [(I 3 − δ k L k ) pk ] T ∇ p P k+1|k ] ≤2 I 3 − δ k L k 2 P k + ρ 2 + 2δ 2 k ∇ p P k+1|k 2 (40)
where the following three relationships have been applied to derive the second inequality,
E[2[(I 3 − δ k L k ) pk ] T w k ] = 0 E[2δ k ∇ T p P k+1|k w k ] = 0 E[2δ k [(I 3 − δ k L k ) pk ] T ∇ p P k+1|k ] ≤ δ k ∇ p P k+1|k 2 + E (I 3 − δ k L k ) pk 2 = δ 2 k ∇ p P k+1|k 2 + I 3 − δ k L k 2 P k .(41)
In view of the definition of P k+1|k , it is known that the last term in (40), 2δ 2 k ∇ p P k+1|k 2 , is a measure of the variance of the estimator error that is upper bounded by
E Θi k 2 ≤ max Θi 0 2 , sup j∈[1,∞) ( j t=j−q+1 η 2 t 2 ) 1 − sup j∈[1,∞) (Γ i j )(42
) where Θ0</p>
<p>2 is the initial estimation error of the estimators.Note that the ATDM is a smooth function with respect to the source estimators Θ i k , and thus F k+1 is bounded for bounded Θ i k , as in (42).Therefore, we can always find an upper bound ν2 &gt; 0 such that ∇ p P k+1|k 2 ≤ ν2 .Thus,
P k+1 ≤ (2 I 3 − δ k L k 2 )P k + ν2 + 2 . (43)
If we choose δ k such that (2
I 3 − δ k L k 2
) is within unit circle, then the convergence of ( 43) is guaranteed.Now, we analyse the steady-state search performance.It follows from ( 43) that
lim k→∞ E p k − s 2 ≤ ν2 + 2 1 − sup j∈[1,∞) (2 I 3 − δ j L j 2 ) (44) where lim k→∞ k j=1 (2 I 3 −δ j L j
2 )P 0 = 0 has been applied.Similarly, it can be obtained from (43) that the agent converges to a bounded mean-square-error in (44) at a geometric rate, given by O(sup j∈[1,∞) (2
I 3 − δ j L j2
)).This completes the performance analysis.</p>
<p>Remark 8: There is a significant difference between the existing dual control formulation and our framework in this paper.Previous studies introduce the exploration effect on the system for purposes of state or parameter estimation [28,30,31], while in our work the probing effect is used to explore the environment (in this case, learn the source location and release rate).This crucial distinction allows us to learn the unknown environment by reducing estimation uncertainty.Compared with our previous work in [7], there are several distinctions in this paper.a) The problem formulation is different.The formulation in ( 10) is a concentration-driven optimisation problem, whereas [7] uses a position-driven mechanism (see equation ( 5) in [7]).This subtle distinction leads to different search behaviours and analytical procedures.From the traditional search strategies point of view, one relates to Chemotaxis while the previous one to Infotaxis [1].b) DCEE [7] uses particle filters for the source term estimation and also for posterior estimation, which is quite computationally expensive.We moved away form this framework to reduce computational burden to make autonomous algorithms easily implemented on mobile sensor platforms that normally have limited computational resources.Motivated by ensemble aggregating in machine learning community [44,45], a concurrent learning mechanism for the estimation process is proposed using a multi-estimator ensemble approach.It is shown that this learning based control method is much more computationally efficient.c) The feasible action set Ω in this paper can be continuous, whereas in [7] only a limited number of feasible actions can be chosen.Limited discretised actions in [7] may heavily influence the flexibility of the search agent and restrict the potential of dual control.d) In this work, we provide a complete theoretical analysis of the modified dual control algorithm using gradient descent.There is no theoretic analysis of convergence property of DCEE in [7].In fact, so far there is no formal analysis and theoretic proof for any IPP based search algorithms including DCEE, which is even more complicated due to the involvement of dual affect.</p>
<p>Remark 9: If we remove the second term P k+1|k in the path planning objective in (11a), then our algorithm reduces to the pure exploitation strategy, which solely relies on the current estimators of the source parameters.It should be emphasised that the learning process of pure exploitation is passive or accidental, since source parameters are updated when the agent makes full use of current belief.In Algorithm 1, the probing effect is included in the value function, by which the agent can actively or deliberately learn the environment.In this sense, our CL-DCEE framework is closely related to active learning in MPC [7,28,47].Generally speaking, dual control of exploration and exploitation in an uncertain environment belongs to a much wider class of machine learning problems, in particular, reinforcement learning [48][49][50].</p>
<p>IV. SIMULATION STUDY</p>
<p>In this section, simulation results will be provided to validate the effectiveness of the proposed algorithms.Since Entrotaxis [15] has demonstrated better performance compared with other existing methods, we will use Entrotaxis as a benchmark for the simulation study.It is worth noting that those informative path planing approaches require a significant amount of computational power due to the implementation of the nonlinear Bayesian filtering and the sampling search based path planning structure.</p>
<p>An autonomous UAV is utilised to search an open bounded space where a single source release is present.The area of interest is Ω = 100m × 100m × 1m.For the first experiment in Section IV-A, environmental parameters are known: the wind speed u s = 4m/s, wind direction ρ s = 1.5π rad, diffusivity ζ s1 = 1, the particle lifetime ζ s2 = 20.For the second case in Section IV-B, the source and environmental parameters are all considered to be unknown.The operational parameters of the UAV are listed in Table I.In order to achieve stable sensor measurement, the UAV will take 10s to collect one concentration sample.The maximum sampling and flight time budgets are bounded.Searching process will be terminated when the maximum budgets are reached.True source parameters and prior knowledge used by the agent are summarised in Table I, where U (•) denotes uniform distribution, and N (•) represents normal distribution.</p>
<p>The algorithm structure of Entrotaxis is presented in [15], which is composed of an inference engine and a path planner.The number of particles for the inference engine is set as 10, 000, and feasible directions are U = {↑, ↓, ←, →, , , , } with a fixed step size 2m.For the proposed method in this paper, we implement the CL-DCEE framework in Algorithm 1 with six different sets of environment estimators, N = 5, 10, 50, 100, 200 and 1, 000, respectively.Different from Entrotaxis and DCEE, the step size of movement can be any value in the range of [1m, 4m], and the direction of movement can be arbitrary by taking advantage of low computational load of CL-DCEE.The learning rates are set as η k = 5 and δ k = 4. Since one step stochastic approximation generates satisfactory estimation performance with high efficiency, the memory integer q is set as 1.The initial conditions of estimators are randomly chosen in accordance with the prior knowledge in Table I.It should be noted that measurement signals from sensors are converted in dB scale.When implementing the proposed algorithms, the gradients are normalised to keep agent's movement within a meaningful range.</p>
<p>A. Unbiased Sensor Noises in Partially Unknown Environment</p>
<p>In this subsection, the sensor measurement noises are set as additive Gaussian white noises.We assume that there is no non-detection event, which means the sensor can always obtain concentration values buried in noises.Each algorithm has been repeated for 200 times with the same configurations.</p>
<p>The obtained mean-square-errors of the CL-DCEE and Entrotaxis algorithms are displayed in Fig. 1.MSE evaluates the performance of the source estimators, calculated by E(s k −s) 2 .It is clear that all algorithms can gradually achieve acceptable estimation of the source position within limited budgets.Uniform distribution of the source location has been applied in the initialisation process, as it is assumed that there is no prior information regarding source position.As a result, the initial guess of the source position is around the centre of the search space.In general, Entrotaxis requires a large number of measurements to update its particle filter, which leads to a slow acquisition rate of source estimation.The acquisition process continues until the flight is terminated at the maximum measurement budget.On the other hand, our proposed algorithms allow quick update of the source estimators by using instantaneous measurements.CL-DCEE algorithm converges to bounded MSE at approximately 1, 000s.This property is helpful to conducting emergent identification of the source parameters.Apart from the estimation accuracy, it is also desired that the search agent can move to the source position, so as to closely monitor the status of the release or take further remedy actions.In Fig. 2, the distance between the agent and the source is displayed.A noticeable phenomenon is that agent's position using Entrotaxis is quite far from the source position.The proposed CL-DCEE in this paper can keep the agent in the neighbourhood of the true source, and the steadystate distances are around 35.96m, 20.28m, 2.80m, 2.36m, 2.22m and 1.61m, for N = 5, 10, 50, 100, 200 and 1, 000, respectively.Illustrative examples of search paths of CL-DCEE with N = 10 and N = 100 have been demonstrated in Figs.3a and 3b.</p>
<p>To show the influence of the number of estimators, we have presented the average performance using different values of N , as shown in Fig. 4. Initially, increasing N can significantly enhance the performance in terms of estimators' MSE and the agent distance to the source (N ranging from 5 to 50).For N ≥ 50, increasing N is no longer able to provide much performance improvement (N ranging from 50 to 1, 000).Therefore, the proposed CL-DCEE framework does not require a large number of estimators, and tens of them will be sufficient for autonomous search problem.It also implies that the number of estimators for the ensemble approach should be properly selected to balance estimation performance and computational complexity.</p>
<p>Entrotaxis aims to minimise the estimation error of source parameters, and it does not necessarily imply that the agent has to move close to the source position.Correspondingly, there is a substantial distance between the agent and the source, even though the estimated source position has been fairly satisfactory.A representative search path using Entrotaxis has been presented in Fig. 3c.In essence, Entrotaxis and other informative path planning methods utilise pure exploration strategy [7], which drives the agent to the most informative position in order to reduce information uncertainties.As can be seen from Fig. 3c, the agent ignores the current estimation of the source position but probes the uncertain areas around the estimated source.This consequently leads to large errors between the agent and the source.An important advantage of the proposed methods in this paper is the computational efficiency.For clear comparison, we have summarised time consumed by different algorithms, as shown in Table II.The simulations are carried out using Matlab with a processor of 2.8 GHz Quad-Core Intel Core i7.It can be seen that our algorithm is much faster than Entrotaxis.It only consumes less than 1% of the time for Entrotaxis (N ≤ 100).As a result, CL-DCEE also occupies much less memory storage since the number of estimators is much smaller.This is a very important and advantageous feature because processors used on mobile platforms are usually lower-price portable chips that cannot offer intensive computational power or large memory.</p>
<p>B. Unknown Environment with Sensor Non-detection Events</p>
<p>In this subsection, operational environment is also assumed to be unknown.Consequently, this necessitates estimating a full list of parameters of ATDM, i.e.Θ s = s T , q, ρ s , u s , ζ s1 , ζ s2</p>
<p>T .One of the most significant challenges in autonomous search of airborne release sources is intermittent sensor reading.Due to ultra low concentration, limited resolution of onboard sensors and local turbulence (possibly caused by the movement of sensor platforms or local airflow), there is a quite significant rate of undetection events.Because of sensor dropouts, the noises are no longer unbiased, and consequently the performance of proposed algorithms will be degraded.As mentioned in Remark 7, the proposed multi-estimator approach is in fact a hybrid method that combines the advantages of both model-based and model-free techniques.Consequently, it is able to cope with nonlinear and non-Gaussian filter problems.The performance of the CL-DCEE algorithm is satisfactory under intermittent sensor dropouts as shown via the simulation results.</p>
<p>We have run each algorithm for 200 times with random sensor dropouts.Table III shows time consumed by running difference settings for 200 trials.Although there are more uncertainties in the sensor and environment, the computational   loads of those algorithms are similar.Fig. 5 shows the MSE of source estimation.It is noticeable that the informationtheoretic method exhibits quite strong resilience to the sensor dropouts and environment uncertainties.In Fig. 6, distance between the agent and the true source is displayed.Compared with previous results in Fig. 2, it is clear that the performance of our method has been influenced by the sensor dropouts and unknown environment, whereas Entrotaxis provides similar result as before.Nevertheless, all algorithms with different number of estimators can gradually navigate the agent move close to the source position.Noticeably, the estimation performance of the CL-DCEE algorithm is degraded in the later period of search, in particular, for N = 5 and 10.This behaviour is probably due to the presence of non-detection events, which leads to biased measurement information.As the estimation process continues, such a biased measurement is gradually accumulated and worsens the search performance.The overall search performance and robustness to sensor dropouts are significantly enhanced by increasing the number of estimators.</p>
<p>By the simulation comparison, it can be concluded that the information-theoretic algorithm is computationally intensive, but it demonstrates strong robustness to sensor dropouts and   unknown environment.On the other hand, the proposed algorithm in this paper is much cheap to evaluate, but more sensitive to sensor performance and uncertainties.By comparing the obtained results in Sections IV-A and IV-B, we notice that knowing the environment can significantly enhance the performance of CL-DCEE algorithm, but has quite limited contribution for Entrotaxis.In general, our algorithm is expected to produce more accurate estimation under good sensor performance and less uncertain environment.When the number of unknown parameters in the model increases, it becomes more challenging in theory to satisfy the persistent excitation condition as discussed in Remarks 5 and 6.</p>
<p>V. EXPERIMENTAL STUDY</p>
<p>In this section, we test the proposed CL-DCEE algorithm using a real experimental dataset collected by COANDA Research &amp; Development Corporation using a large recirculating water channel [16].Fluorescein dye was released at a constant rate from a narrow tube, and concentration data was collected over the entire search domain.More detailed descriptions of the experiment settings can be found in [15,16].The dataset is composed of a total number of 340 sequential frames, where each of them consists of 49 × 98 pixels.This is a quite challenging dataset for autonomous search due to rapid changes of the dispersion field.In Fig. 7, four consecutive samples are depicted, which are collected at a sampling rate 10/23s.During a very short period of time, the dispersion field changes very fast.As a result, conventional reactive search approaches, like Chemotaxis, cannot obtain reliable sensor readings, and usually yield poor search performance.Estimation of the source parameters becomes essential in this type of challenging search scenarios.As discussed in Remark 7, the accuracy of model-based filtering techniques, like extended and unscented Kalman filter, are heavily influenced by the accuracy of the model and the assumed stochastic properties.In autonomous search, the models used in experiments, e.g., isotropic plume, may be quite different from the real dispersion field.Therefore, the hybrid ensemble strategy is beneficial for real-time computation of estimation variance since it inherits the advantages from both model-free and model-based techniques.</p>
<p>Fig. 8 shows a representative search path using CL-DCEE algorithm.Most of the time, the sensor cannot receive any readings (i.e.undetected events) due to low concentration when the agent is far from the source.Until the 70th iteration, the first meaningful reading is collected, as shown in the black dot in the third plot of Fig. 8. Fortunately, the estimators are able to update their estimates using zero measurements, because no measurement means that the source is less likely in the area.During the later period of searching, sensor can often obtain reliable readings as the concentration is high.Both estimators and the search agent converge to the source location, and the search mission is successfully completed as shown in the last plot of Fig. 8.</p>
<p>VI. CONCLUSION</p>
<p>This paper has developed a computationally efficient solution for autonomous search of an airborne release with proven properties like convergence.A new learning framework, inspired by dual control for exploration and exploitation (DCEE), has been formulated to solve this goal-oriented control problem in an unknown environment with an unknown target.Gradient-based optimisation algorithms have been proposed to estimate the source parameters, and to plan next movement by formulating suitable value functions.Theoretical guarantee for convergence and steady-state performance are analysed under measurement noises and uncertain turbulence.From the simulation and experimental studies, the effectiveness of the proposed solution has been validated.It has been demonstrated that our algorithm achieves superior performance comparing with informative path planning, and it also consumes much less computation time.</p>
<p>One fundamental motivation for developing computationally efficient estimation approaches is to avoid prohibitive computational cost involved in predicting the future posteriors under a possible control action.In fact, the current setting  in this paper is a myopic search strategy with one-stepahead prediction.Previous work on multi-stage path planing is mainly based on certainty equivalence without considering future uncertainty, but it can provide better search trajectory by increasing the look ahead depth [24].Active learning based non-myopic search has been recently pioneered in [51] for machine learning and data mining problems.As discussed in [7], multi-stage dual control will be beneficial for enhancing search performance and robustness of autonomous search problem, but existing approaches are too computationally expensive to be implemented for multi-step DCEE.By employing the multiestimator based approach developed in this paper, this will facilitate multi-stage DCEE so fully realise the potential of DCEE, which is a promising direction for future research.</p>
<p>Fig. 1 :
1
Fig. 1: Mean-square-error between the estimated and true source positions.</p>
<p>Fig. 2 :
2
Fig. 2: Distance between agent's position and the true source.</p>
<p>Fig. 3 :
3
Fig. 3: Representative runs of different algorithms: (a) CL-DCEE with N = 10, (b) CL-DCEE with N = 100, (c) Entrotaxis.Red lines are the paths of the UAV, the green dots represent the estimated source position, and the black dots represent the true source position.</p>
<p>Fig. 4 :
4
Fig. 4: Performance of CL-DCEE algorithm with different number of estimators.</p>
<p>Fig. 5 :
5
Fig.5: Mean-square-error between estimated and true source positions with unknown environment and sensor dropouts.</p>
<p>Fig. 6 :
6
Fig. 6: Distance between agent's position and the true source with unknown environment and sensor dropouts.</p>
<p>Fig. 7 :
7
Fig. 7: Concentration map of a dispersion field at different time frames where local turbulence changes the distribution dramatically from time to time.The sub-figures are taken at 1, 2, 3 and 4 sample instances, respectively.The grey-scale shade depicts the instantaneous concentration.</p>
<p>Fig. 8 :
8
Fig. 8: Representative search path of CL-DCEE on real dataset using an ensemble of 100 estimators.The sub-figures are taken at 1, 30, 80 and 146 sample instances, respectively.Red lines are the paths of the search agent, red cross denotes agent's current position, the green dots represent the estimated source position, and the black dots represent non-zero measurements.</p>
<p>Wen-Hua Chen (M'00-SM'06-F'17)  holds a Chair in Autonomous Vehicles with the Department of Aeronautical and Automotive Engineering, Loughborough University, Loughborough, U.K., where he is leading the Centre of Autonomous Systems.He has a considerable experience in control, signal processing and artificial intelligence and their applications in robots, aerospace, and automotive systems.He joined the Department of Aeronautical and Automotive Engineering, Loughborough University, in 2000 after having held a research position and then a Lecturer in control engineering with the Centre for Systems and Control, University of Glasgow, Scotland.Recently he was awarded a 5 years Established Career Fellowship by the UK Engineering and Physical Sciences Research Council.He is a Chartered Engineer, a Fellow of IEEE, the Institution of Mechanical Engineers and the Institution of Engineering and Technology, U.K.He has authored or coauthored near 300 papers and 2 books.Jun Yang (Senior Member, IEEE) received the B.Sc. degree from the Department of Automatic Control, Northeastern University, Shenyang, China, in 2006, and the Ph.D. degree in control theory and control engineering from the School of Automation, Southeast University, Nanjing, China, in 2011.He is currently a Senior Lecturer with the Department of Aeronautical and Automotive Engineering at Loughborough University.He is an IET Fellow.He received the ICI prize for best paper of Transactions of the Institute of Measurement and Control in 2016 and Premium Award for best paper of IET Control Theory and Applications in 2017.His current research interests include disturbance estimation and compensation, advanced control theory, and its application to electric machines, mechatronic systems and robotics.</p>
<p>TABLE I :
I
Operational parameters and source knowledge.
UAVSource PriorMeasurement budget 180--Flight budget2, 000s--Velocity2m/s--Maximum step size4m--Start position[2, 2, 1]--x position-80mU (x min , xmax)y position-80mU (y min , ymax)z position-1mU (z min , zmax)Release rate-10g/sN (11, 2)</p>
<p>TABLE II :
II
Time consumed by running different algorithms for 200 trials.
CL-DCEEEntrotaxisEstimators/Particles510501002001,00010,000Time (second)21.8 23.1 24.3 26.3 30.556.82940.4</p>
<p>TABLE III :
III
Time consumed by running different algorithms for 200 trials with unknown environment and sensor dropouts.
CL-DCEEEntrotaxisEstimators/Particles510501002001,00010,000Time (second)19.7 21.3 27.6 28.2 35.553.62877.9
This work was supported by the UK Engineering and Physical Sciences Research Council (EPSRC) Established Career Fellowship "Goal-Oriented Control Systems: Disturbance, Uncertainty and Constraints" under the grant number EP/T005734/1.
A review of source term estimation methods for atmospheric dispersion events using static or mobile sensors. M Hutchinson, H Oh, W.-H Chen, Information Fusion. 362017</p>
<p>Source function estimate by means of variational data assimilation applied to the ETEX-I tracer experiment. L Robertson, J Langner, Atmospheric Environment. 32241998</p>
<p>Inverse modelling methods for identifying unknown releases in emergency scenarios: An overview. S K Singh, M Sharan, J.-P Issartel, International Journal of Environment and Pollution. 201557</p>
<p>Source estimation methods for atmospheric dispersion. K Shankar Rao, Atmospheric Environment. 41332007</p>
<p>A review of ground-based robotic systems for the characterization of nuclear environments. I Tsitsimpelis, C J Taylor, B Lennox, M J Joyce, Progress in Nuclear Energy. 1112019</p>
<p>Informationbased search for an atmospheric release using a mobile robot: Algorithm and experiments. M Hutchinson, C Liu, W.-H Chen, IEEE Transactions on Control Systems Technology. 2762018</p>
<p>Dual control for exploitation and exploration (DCEE) in autonomous search. W.-H Chen, C Rhodes, C Liu, Automatica. 1331098512021</p>
<p>Infotaxis as a strategy for searching without gradients. M Vergassola, E Villermaux, B I Shraiman, Nature. 44571262007</p>
<p>Chemical plume source localization. S Pang, J A Farrell, IEEE Transactions on Systems, Man, and Cybernetics. 3652006Part B (Cybernetics)</p>
<p>Unmanned aerial vehicle-based hazardous materials response: Information-theoretic hazardous source search and reconstruction. M Hutchinson, C Liu, P Thomas, W.-H Chen, IEEE Robotics &amp; Automation Magazine. 2019</p>
<p>Source term estimation of a hazardous airborne release using an unmanned aerial vehicle. M Hutchinson, C Liu, W.-H Chen, Journal of Field Robotics. 3642019</p>
<p>Optimal path following for small fixed-wing UAVs under wind disturbances. J Yang, C Liu, M Coombes, Y Yan, W.-H Chen, IEEE Transactions on Control Systems Technology. 2932020</p>
<p>Odor source localization algorithms on mobile robots: A review and future outlook. X.-X Chen, J Huang, Robotics and Autonomous Systems. 1122019</p>
<p>An overview of small unmanned aerial vehicles for air quality measurements: Present applications and future prospectives. T F Villa, F Gonzalez, B Miljievic, Z D Ristovski, L Morawska, Sensors. 16710722016</p>
<p>Entrotaxis as a strategy for autonomous search and source reconstruction in turbulent conditions. M Hutchinson, H Oh, W.-H Chen, Information Fusion. 422018</p>
<p>A study of cognitive strategies for an autonomous search. B Ristic, A Skvortsov, A Gunatilaka, Information Fusion. 282016</p>
<p>Entrotaxis-jump as a hybrid search algorithm for seeking an unknown emission source in a large-scale area with road network constraint. Y Zhao, B Chen, Z Zhu, F Chen, Y Wang, D Ma, Expert Systems with Applications. 1571134842020</p>
<p>Searching the diffusive source in an unknown obstructed environment by cognitive strategies with forbidden areas. Y Zhao, B Chen, Z Zhu, F Chen, Y Wang, Y Ji, Building and Environment. 1861073492020</p>
<p>Planning to be surprised: Optimal bayesian exploration in dynamic environments. Y Sun, F Gomez, J Schmidhuber, International Conference on Artificial General Intelligence. Springer2011Conference Proceedings</p>
<p>Stochastic source seeking for nonholonomic unicycle. S.-J Liu, M Krstic, Automatica. 4692010</p>
<p>Stochastic source seeking for mobile robots in obstacle environments via the SPSA method. E Ramirez-Llanos, S Martinez, IEEE Transactions on Automatic Control. 6442018</p>
<p>Multivariate stochastic approximation using a simultaneous perturbation gradient approximation. J C Spall, IEEE Transactions on Automatic Control. 3731992</p>
<p>Cooperative control of mobile sensor networks: Adaptive gradient climbing in a distributed environment. P Ogren, E Fiorelli, N E Leonard, IEEE Transactions on Automatic control. 4982004</p>
<p>Optimal search for a lost target in a bayesian world. F Bourgault, T Furukawa, H F Durrant-Whyte, Conference Proceedings. Field and Service Robotics. Springer2003</p>
<p>Odor source localization using a mobile robot in outdoor airflow environments with a particle filter algorithm. J.-G Li, Q.-H Meng, Y Wang, M Zeng, Autonomous Robots. 3032011</p>
<p>Beyond the Kalman filter: Particle Filters for Tracking Applications. B Ristic, S Arulampalam, N Gordon, 2003Artech House</p>
<p>Autonomous search of an airborne release in urban environments using informed tree planning. C Rhodes, C Liu, P Westoby, W.-H Chen, arXiv:2109.035422021arXiv preprint</p>
<p>Stochastic model predictive control with active uncertainty learning: A survey on dual control. A Mesbah, Annual Reviews in Control. 452018</p>
<p>Approximating explicit model predictive control using constrained neural networks. S Chen, K Saulnier, N Atanasov, D D Lee, V Kumar, G J Pappas, M Morari, Annual American Control Conference (ACC). </p>
<p>Conference Proceedings. 2018</p>
<p>Dual adaptive dynamic control of mobile robots using neural networks. M K Bugeja, S G Fabri, L Camilleri, IEEE Transactions on Systems, Man, and Cybernetics. 3912008Part B (Cybernetics)</p>
<p>Survey of adaptive dual control methods. N M Filatov, H Unbehauen, IEE Proceedings-Control Theory and Applications. 2000147</p>
<p>Generalized extended state observer based control for systems with mismatched uncertainties. S Li, J Yang, W.-H Chen, X Chen, IEEE Transactions on Industrial Electronics. 59122011</p>
<p>Disturbanceobserver-based control and related methods: An overview. W.-H Chen, J Yang, L Guo, S Li, IEEE Transactions on Industrial Electronics. 6322015</p>
<p>A parameter estimation perspective of continuous time model reference adaptive control. G C Goodwin, D Q Mayne, Automatica. 2311987</p>
<p>A review of dispersion modelling and its application to the dispersion of particles: An overview of different dispersion models available. N S Holmes, L Morawska, Atmospheric Environment. 40302006</p>
<p>Chemotaxis. J B Stock, M Baker, Encyclopedia of Microbiology. Elsevier Inc2009</p>
<p>An Introduction to the Kalman Filter. G Welch, G Bishop, 1995Chapel Hill, NC, USA</p>
<p>On modified parameter estimators for identification and adaptive control. a unified framework and some new schemes. R Ortega, V Nikiforov, D Gerasimov, Annual Reviews in Control. 2020</p>
<p>Bacterium-inspired robots for environmental monitoring. A Dhariwal, G S Sukhatme, A A Requicha, IEEE International Conference on Robotics and Automation. IEEE2004Conference Proceedings</p>
<p>A robotic system to locate hazardous chemical leaks. R A Russell, D Thiel, R Deveza, A Mackay-Sim, Proceedings of IEEE International Conference on Robotics and Automation. IEEE International Conference on Robotics and AutomationIEEE1995Conference Proceedings</p>
<p>W Rudin, Principles of Mathematical Analysis. New York, NY, USAMcGraw-hill19763rd ed</p>
<p>Adaptive extremum seeking control of nonlinear dynamic systems with parametric uncertainties. M Guay, T Zhang, Automatica. 3972003</p>
<p>Performance analysis of multiinnovation gradient type identification methods. F Ding, T Chen, Automatica. 4312007</p>
<p>Deep reinforcement learning in a handful of trials using probabilistic dynamics models. K Chua, R Calandra, R Mcallister, S Levine, arXiv:1805.121142018arXiv preprint</p>
<p>Simple and scalable predictive uncertainty estimation using deep ensembles. B Lakshminarayanan, A Pritzel, C Blundell, Advances in Neural Information Processing Systems. 201730</p>
<p>Disturbance observer based control for nonlinear systems. W.-H Chen, IEEE/ASME Transactions on Mechatronics. 942004</p>
<p>Dual effect, certainty equivalence, and separation in stochastic control. Y Bar-Shalom, E Tse, IEEE Transactions on Automatic Control. 1951974</p>
<p>A general safety framework for learning-based control in uncertain robotic systems. J F Fisac, A K Akametalu, M N Zeilinger, S Kaynama, J Gillula, C J Tomlin, IEEE Transactions on Automatic Control. 6472018</p>
<p>Learning Q-network for active information acquisition. H Jeong, B Schlotfeldt, H Hassani, M Morari, D D Lee, G J Pappas, arXiv:1910.107542019arXiv preprint</p>
<p>MRAC-RL: A framework for on-line policy adaptation under parametric model uncertainty. A Guha, A Annaswamy, arXiv:2011.105622020arXiv preprint</p>
<p>Zhongguo Li (Member, IEEE) received the B.Eng. and Ph.D. degrees in electrical and electronic engineering from the University of Manchester. S Jiang, G Malkomes, G Converse, A Shofner, B Moseley, R Garnett, International Conference on Machine Learning. PMLR. Manchester, U.K.; Loughborough, U.K.2017. 2017 and 2021Loughborough UniversityHis research interests include optimisation and decision-making for advanced control. agent systems, and their applications in autonomous vehicles</p>            </div>
        </div>

    </div>
</body>
</html>