<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3643 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3643</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3643</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-88.html">extraction-schema-88</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to estimate the probability or likelihood of future scientific discoveries or real-world events, including methods, results, and comparisons.</div>
                <p><strong>Paper ID:</strong> paper-270357773</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.04446v1.pdf" target="_blank">Can Language Models Use Forecasting Strategies?</a></p>
                <p><strong>Paper Abstract:</strong> Advances in deep learning systems have allowed large models to match or surpass human accuracy on a number of skills such as image classification, basic programming, and standardized test taking. As the performance of the most capable models begin to saturate on tasks where humans already achieve high accuracy, it becomes necessary to benchmark models on increasingly complex abilities. One such task is forecasting the future outcome of events. In this work we describe experiments using a novel dataset of real world events and associated human predictions, an evaluation metric to measure forecasting ability, and the accuracy of a number of different LLM based forecasting designs on the provided dataset. Additionally, we analyze the performance of the LLM forecasters against human predictions and find that models still struggle to make accurate predictions about the future. Our follow-up experiments indicate this is likely due to models' tendency to guess that most events are unlikely to occur (which tends to be true for many prediction datasets, but does not reflect actual forecasting abilities). We reflect on next steps for developing a systematic and reliable approach to studying LLM forecasting.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3643.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3643.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to estimate the probability or likelihood of future scientific discoveries or real-world events, including methods, results, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PaLM 2 Forecaster</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PaLM 2 (backbone) forecasting experiments</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>This paper uses PaLM 2 (pre-trained transformer with pretraining cutoff July 2022) as the backbone LLM to estimate probabilities for binary real-world events drawn from an internal prediction market (GleanGen). Multiple prompting strategies (basic direct prompt, 'forecaster' prompt, breakdown, base-rates, both-sides, synthetic crowd/personas, and a news-grounded pipeline) were evaluated and compared to human market forecasts using Brier score variants.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PaLM 2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A large pre-trained transformer language model (PaLM 2) whose pretraining ended in July 2022 (used without additional fine-tuning in these experiments); exact parameter count/architecture details are not provided in the paper beyond being a modern PaLM-series model.</td>
                        </tr>
                        <tr>
                            <td><strong>prediction_task</strong></td>
                            <td>Forecast binary outcomes of real-world events (will condition be true by expiry date?) from the GleanGen internal prediction market (categories: Technology Industry, Finance, Covid-19, Misc.), evaluated on Validation (351 events) and Test (341 events) splits.</td>
                        </tr>
                        <tr>
                            <td><strong>method_of_probability_estimation</strong></td>
                            <td>Direct natural-language prompting to output a probability (0–1) with multiple strategy variants: Basic direct prompt; 'Forecaster' prompt adapted from prior work; Breakdown into subevents; Base-rate elicitation; Both-sides pros/cons; Crowd via multiple personas generated from the same base model; News-grounded pipeline querying NYT and Hacker News and summarizing headlines; variants with and without chain-of-thought/rationale; probability extraction via post-processing LLM that reads the model output and emits a floating-point probability; sampling eight low-temperature generations and averaging as the final probability. The paper also discusses alternative extraction approaches (token-prob enumeration and training an output layer) but did not use them as the primary method.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_benchmark</strong></td>
                            <td>GleanGen prediction market dataset — internal Google prediction market with event definitions, creation/resolution/expiry dates, and human market probability spreads over time; Validation (351 events) and Test (341 events); each event has many human trades (median ~100 predictions/event). Events were filtered to exclude internal-only items so remaining categories are public (Covid-19, Finance, Technology Industry, Misc.).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Primary metric: Brier score (mean squared error between predicted probability and outcome). Also introduced a Weighted Brier Score that averages the Brier for events that resolved true and false to correct label imbalance. Reported unweighted Brier scores on Validation: Human = 0.1334; PaLM 2 Basic = 0.1221; Forecaster baseline = 0.1483; Breakdown = 0.1895; Base Rates = 0.1562; Both Sides = 0.1553; Crowd = 0.1706; News API = 0.1235. Table 3 reports average predicted probabilities and Brier: Average probability (Human) = 0.3280, (Basic) = 0.2529, (1 - Reversed) = 0.3965; Brier (Human) = 0.1334, (Basic) = 0.1221, (1 - Reversed) = 0.1814. Weighted Brier analysis (values not fully enumerated in text) shows humans outperform all LLM methods when positives and negatives are equally weighted.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>On unweighted Brier, the simplest PaLM 2 basic prompt outperformed the human GleanGen market (Basic 0.1221 vs Human 0.1334), and the News-API pipeline performed close to the basic prompt (0.1235). However, when using the Weighted Brier Score to correct for the dataset's skew toward negative outcomes, the human baseline outperformed all LLM prompting strategies. More complex human-inspired prompting strategies (breakdown, base rates, both-sides, persona crowding) failed to improve and in many cases worsened performance relative to the Basic prompt. The authors compare qualitatively to concurrent work that achieves improved performance via ensembling and fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Key issues reported: (1) dataset label imbalance (majority 'No' outcomes) interacts with model tendency to output low probabilities, producing apparently good unweighted Brier scores (a negativity bias confound); (2) PaLM 2 pretraining cutoff constraints required to ensure events were not in training data, limiting the choice of SOTA models; (3) prompting that elicits rationales raises average predicted probabilities (worsening unweighted Brier on a negatively-skewed dataset); (4) model probability outputs are not guaranteed calibrated and token-prob approaches or learned output heads pose their own problems; (5) inability to update model pretraining in-flight (external news can be added but pretraining remains stale); (6) uncertainty about published cutoff dates for other models complicates comparative studies.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_findings</strong></td>
                            <td>The paper's main findings are (a) a very simple direct prompt to PaLM 2 produced the best unweighted Brier score among LLM strategies and even beat the human market on that metric, (b) more elaborate human-inspired strategies (breakdown, base-rates, both-sides, persona crowds, news-grounding) did not consistently improve performance and often performed worse, (c) analysis revealed a negativity bias in PaLM 2 (model tends to assign low probabilities), which combined with the dataset's many negative outcomes explains the apparent superiority of the Basic prompt; using a Weighted Brier Score that balances positive and negative outcomes shows humans outperform LLMs, (d) ensembling and fine-tuning (reported in other work) are promising directions not explored here, and (e) the Weighted Brier Score is useful to detect distributional confounds in forecasting evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can Language Models Use Forecasting Strategies?', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3643.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3643.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to estimate the probability or likelihood of future scientific discoveries or real-world events, including methods, results, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Halawi et al. 2024</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Approaching human-level forecasting with language models.</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced concurrent work reporting that ensembles of pre-trained and fine-tuned LLMs can approach or exceed human crowd forecasting accuracy; they achieved high accuracy by ensembling multiple pre-trained models and models fine-tuned to produce calibrated predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Approaching human-level forecasting with language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Ensembles of pre-trained and fine-tuned LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Described in the referenced work as combinations of multiple LLMs including fine-tuned variants; exact architectures/details are given in that paper (not reproduced here).</td>
                        </tr>
                        <tr>
                            <td><strong>prediction_task</strong></td>
                            <td>Forecasting real-world events from forecasting tournaments/markets.</td>
                        </tr>
                        <tr>
                            <td><strong>method_of_probability_estimation</strong></td>
                            <td>Ensembling predictions across multiple models and including models fine-tuned for forecasting; calibration/fine-tuning to improve probabilistic outputs (as summarized in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_benchmark</strong></td>
                            <td>Forecasting tournament datasets (referenced work); not the primary dataset of this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported in the cited work as approaching human crowd accuracy; this paper cites the claim qualitatively and does not re-report numeric metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>Cited as achieving human-level or better performance by combining ensembling and fine-tuning—presented here as a contrast to the present paper's observation that prompting alone (without fine-tuning/ensembling) is insufficient.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>The paper notes that Halawi et al.'s improvements rely on model fine-tuning and ensembling, approaches separate from the zero/few-shot prompting strategies evaluated in the current paper.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_findings</strong></td>
                            <td>Ensembling and targeted fine-tuning can materially improve LLM forecasting performance, per the referenced study; mentioned as a promising direction relative to the prompting-focused experiments in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can Language Models Use Forecasting Strategies?', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3643.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3643.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to estimate the probability or likelihood of future scientific discoveries or real-world events, including methods, results, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Schoenegger et al. 2023</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large language model prediction capabilities: Evidence from a real-world forecasting tournament.</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced prior study that evaluated ChatGPT-like models on forecasting tournament questions and found out-of-the-box performance to be poor, barely above random guessing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Large language model prediction capabilities: Evidence from a real-world forecasting tournament.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT (out-of-the-box)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A pre-trained conversational LLM evaluated without fine-tuning on forecasting tournament questions (as summarized by this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>prediction_task</strong></td>
                            <td>Forecasting questions from a popular prediction market / forecasting tournament.</td>
                        </tr>
                        <tr>
                            <td><strong>method_of_probability_estimation</strong></td>
                            <td>Out-of-the-box prompting / direct question answering (no fine-tuning or ensembling reported here).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_benchmark</strong></td>
                            <td>A public forecasting tournament dataset (cited work); authors of this paper note the dataset may be included in LLM pretraining in older cases.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Summarized as 'performed poorly out-of-the-box, barely outperforming random guessing' in the present paper; exact numbers are in the cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>Compared unfavorably to human forecasters and to methods that use ensembling/fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Out-of-the-box LLMs may be contained or contaminated by training data or lacking calibration; performance was poor without additional methodologic adjustments (ensembling/fine-tuning).</td>
                        </tr>
                        <tr>
                            <td><strong>notable_findings</strong></td>
                            <td>Out-of-the-box conversational LLMs may not reliably forecast real-world events without additional method interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can Language Models Use Forecasting Strategies?', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3643.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3643.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to estimate the probability or likelihood of future scientific discoveries or real-world events, including methods, results, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Schoenegger et al. 2024</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Wisdom of the silicon crowd: LLM ensemble prediction capabilities match human crowd accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced concurrent work finding that ensembling predictions from many LLMs improves forecasting performance and can rival the accuracy of human crowds.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Wisdom of the silicon crowd: Llm ensemble prediction capabilities match human crowd accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLM ensembles</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>An ensemble of many LLMs (distinct models) used to produce aggregated probabilistic forecasts; details are in the cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>prediction_task</strong></td>
                            <td>Forecasting real-world events and matching human crowd accuracy through aggregated model predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>method_of_probability_estimation</strong></td>
                            <td>Ensembling / averaging predictions across multiple distinct LLMs to create a synthetic 'silicon crowd'.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_benchmark</strong></td>
                            <td>Forecasting tournament / real-world forecasting datasets used in that referenced study.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported by the cited study to reach performance comparable to human crowds; the present paper cites this qualitatively and does not re-report numeric metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>Presented as evidence that ensemble approaches materially improve results relative to single-model prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Ensembling requires multiple models and/or model checkpoints and may be more computationally expensive; referenced as a contrasting method to the single-model prompting strategies tried here.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_findings</strong></td>
                            <td>Aggregating many LLM forecasts (ensembling) can rival human crowd accuracy, per the referenced work.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can Language Models Use Forecasting Strategies?', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3643.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3643.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to estimate the probability or likelihood of future scientific discoveries or real-world events, including methods, results, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Zou et al. dataset</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Forecasting future world events with neural networks (dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced prior dataset of forecasting tournament questions intended as a benchmark; authors note older datasets of this kind may be contained in modern LLM pretraining and thus be less useful for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Forecasting future world events with neural networks.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>prediction_task</strong></td>
                            <td>Benchmark of forecasting tournament questions for model evaluation (dataset-level resource).</td>
                        </tr>
                        <tr>
                            <td><strong>method_of_probability_estimation</strong></td>
                            <td>Dataset intended for use by forecasting models; the referenced paper used neural networks for prediction (details in that work).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_benchmark</strong></td>
                            <td>A dataset of forecasting tournament questions (cited work); the present paper notes the dataset is several years old and likely present in modern LLM pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not reported here; metrics and results are in the cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>Mentioned as background and as potentially obsolete for modern LLM evaluation due to contamination by pretraining data.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Older public forecasting datasets may appear in model pretraining corpora, invalidating held-out evaluation assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_findings</strong></td>
                            <td>Serves as prior benchmark work; cited caution that benchmark freshness and pretraining contamination are critical when evaluating forecasting ability of modern LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can Language Models Use Forecasting Strategies?', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Approaching human-level forecasting with language models. <em>(Rating: 2)</em></li>
                <li>Large language model prediction capabilities: Evidence from a real-world forecasting tournament. <em>(Rating: 2)</em></li>
                <li>Wisdom of the silicon crowd: Llm ensemble prediction capabilities match human crowd accuracy. <em>(Rating: 2)</em></li>
                <li>Forecasting future world events with neural networks. <em>(Rating: 2)</em></li>
                <li>Ai-augmented predictions. <em>(Rating: 1)</em></li>
                <li>Large language model prediction capabilities: Evidence from a real-world forecasting tournament. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3643",
    "paper_id": "paper-270357773",
    "extraction_schema_id": "extraction-schema-88",
    "extracted_data": [
        {
            "name_short": "PaLM 2 Forecaster",
            "name_full": "PaLM 2 (backbone) forecasting experiments",
            "brief_description": "This paper uses PaLM 2 (pre-trained transformer with pretraining cutoff July 2022) as the backbone LLM to estimate probabilities for binary real-world events drawn from an internal prediction market (GleanGen). Multiple prompting strategies (basic direct prompt, 'forecaster' prompt, breakdown, base-rates, both-sides, synthetic crowd/personas, and a news-grounded pipeline) were evaluated and compared to human market forecasts using Brier score variants.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "PaLM 2",
            "model_description": "A large pre-trained transformer language model (PaLM 2) whose pretraining ended in July 2022 (used without additional fine-tuning in these experiments); exact parameter count/architecture details are not provided in the paper beyond being a modern PaLM-series model.",
            "prediction_task": "Forecast binary outcomes of real-world events (will condition be true by expiry date?) from the GleanGen internal prediction market (categories: Technology Industry, Finance, Covid-19, Misc.), evaluated on Validation (351 events) and Test (341 events) splits.",
            "method_of_probability_estimation": "Direct natural-language prompting to output a probability (0–1) with multiple strategy variants: Basic direct prompt; 'Forecaster' prompt adapted from prior work; Breakdown into subevents; Base-rate elicitation; Both-sides pros/cons; Crowd via multiple personas generated from the same base model; News-grounded pipeline querying NYT and Hacker News and summarizing headlines; variants with and without chain-of-thought/rationale; probability extraction via post-processing LLM that reads the model output and emits a floating-point probability; sampling eight low-temperature generations and averaging as the final probability. The paper also discusses alternative extraction approaches (token-prob enumeration and training an output layer) but did not use them as the primary method.",
            "dataset_or_benchmark": "GleanGen prediction market dataset — internal Google prediction market with event definitions, creation/resolution/expiry dates, and human market probability spreads over time; Validation (351 events) and Test (341 events); each event has many human trades (median ~100 predictions/event). Events were filtered to exclude internal-only items so remaining categories are public (Covid-19, Finance, Technology Industry, Misc.).",
            "performance_metrics": "Primary metric: Brier score (mean squared error between predicted probability and outcome). Also introduced a Weighted Brier Score that averages the Brier for events that resolved true and false to correct label imbalance. Reported unweighted Brier scores on Validation: Human = 0.1334; PaLM 2 Basic = 0.1221; Forecaster baseline = 0.1483; Breakdown = 0.1895; Base Rates = 0.1562; Both Sides = 0.1553; Crowd = 0.1706; News API = 0.1235. Table 3 reports average predicted probabilities and Brier: Average probability (Human) = 0.3280, (Basic) = 0.2529, (1 - Reversed) = 0.3965; Brier (Human) = 0.1334, (Basic) = 0.1221, (1 - Reversed) = 0.1814. Weighted Brier analysis (values not fully enumerated in text) shows humans outperform all LLM methods when positives and negatives are equally weighted.",
            "comparison_to_baselines": "On unweighted Brier, the simplest PaLM 2 basic prompt outperformed the human GleanGen market (Basic 0.1221 vs Human 0.1334), and the News-API pipeline performed close to the basic prompt (0.1235). However, when using the Weighted Brier Score to correct for the dataset's skew toward negative outcomes, the human baseline outperformed all LLM prompting strategies. More complex human-inspired prompting strategies (breakdown, base rates, both-sides, persona crowding) failed to improve and in many cases worsened performance relative to the Basic prompt. The authors compare qualitatively to concurrent work that achieves improved performance via ensembling and fine-tuning.",
            "limitations_or_challenges": "Key issues reported: (1) dataset label imbalance (majority 'No' outcomes) interacts with model tendency to output low probabilities, producing apparently good unweighted Brier scores (a negativity bias confound); (2) PaLM 2 pretraining cutoff constraints required to ensure events were not in training data, limiting the choice of SOTA models; (3) prompting that elicits rationales raises average predicted probabilities (worsening unweighted Brier on a negatively-skewed dataset); (4) model probability outputs are not guaranteed calibrated and token-prob approaches or learned output heads pose their own problems; (5) inability to update model pretraining in-flight (external news can be added but pretraining remains stale); (6) uncertainty about published cutoff dates for other models complicates comparative studies.",
            "notable_findings": "The paper's main findings are (a) a very simple direct prompt to PaLM 2 produced the best unweighted Brier score among LLM strategies and even beat the human market on that metric, (b) more elaborate human-inspired strategies (breakdown, base-rates, both-sides, persona crowds, news-grounding) did not consistently improve performance and often performed worse, (c) analysis revealed a negativity bias in PaLM 2 (model tends to assign low probabilities), which combined with the dataset's many negative outcomes explains the apparent superiority of the Basic prompt; using a Weighted Brier Score that balances positive and negative outcomes shows humans outperform LLMs, (d) ensembling and fine-tuning (reported in other work) are promising directions not explored here, and (e) the Weighted Brier Score is useful to detect distributional confounds in forecasting evaluations.",
            "uuid": "e3643.0",
            "source_info": {
                "paper_title": "Can Language Models Use Forecasting Strategies?",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Halawi et al. 2024",
            "name_full": "Approaching human-level forecasting with language models.",
            "brief_description": "Referenced concurrent work reporting that ensembles of pre-trained and fine-tuned LLMs can approach or exceed human crowd forecasting accuracy; they achieved high accuracy by ensembling multiple pre-trained models and models fine-tuned to produce calibrated predictions.",
            "citation_title": "Approaching human-level forecasting with language models.",
            "mention_or_use": "mention",
            "model_name": "Ensembles of pre-trained and fine-tuned LLMs",
            "model_description": "Described in the referenced work as combinations of multiple LLMs including fine-tuned variants; exact architectures/details are given in that paper (not reproduced here).",
            "prediction_task": "Forecasting real-world events from forecasting tournaments/markets.",
            "method_of_probability_estimation": "Ensembling predictions across multiple models and including models fine-tuned for forecasting; calibration/fine-tuning to improve probabilistic outputs (as summarized in this paper).",
            "dataset_or_benchmark": "Forecasting tournament datasets (referenced work); not the primary dataset of this paper.",
            "performance_metrics": "Reported in the cited work as approaching human crowd accuracy; this paper cites the claim qualitatively and does not re-report numeric metrics.",
            "comparison_to_baselines": "Cited as achieving human-level or better performance by combining ensembling and fine-tuning—presented here as a contrast to the present paper's observation that prompting alone (without fine-tuning/ensembling) is insufficient.",
            "limitations_or_challenges": "The paper notes that Halawi et al.'s improvements rely on model fine-tuning and ensembling, approaches separate from the zero/few-shot prompting strategies evaluated in the current paper.",
            "notable_findings": "Ensembling and targeted fine-tuning can materially improve LLM forecasting performance, per the referenced study; mentioned as a promising direction relative to the prompting-focused experiments in this paper.",
            "uuid": "e3643.1",
            "source_info": {
                "paper_title": "Can Language Models Use Forecasting Strategies?",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Schoenegger et al. 2023",
            "name_full": "Large language model prediction capabilities: Evidence from a real-world forecasting tournament.",
            "brief_description": "Referenced prior study that evaluated ChatGPT-like models on forecasting tournament questions and found out-of-the-box performance to be poor, barely above random guessing.",
            "citation_title": "Large language model prediction capabilities: Evidence from a real-world forecasting tournament.",
            "mention_or_use": "mention",
            "model_name": "ChatGPT (out-of-the-box)",
            "model_description": "A pre-trained conversational LLM evaluated without fine-tuning on forecasting tournament questions (as summarized by this paper).",
            "prediction_task": "Forecasting questions from a popular prediction market / forecasting tournament.",
            "method_of_probability_estimation": "Out-of-the-box prompting / direct question answering (no fine-tuning or ensembling reported here).",
            "dataset_or_benchmark": "A public forecasting tournament dataset (cited work); authors of this paper note the dataset may be included in LLM pretraining in older cases.",
            "performance_metrics": "Summarized as 'performed poorly out-of-the-box, barely outperforming random guessing' in the present paper; exact numbers are in the cited work.",
            "comparison_to_baselines": "Compared unfavorably to human forecasters and to methods that use ensembling/fine-tuning.",
            "limitations_or_challenges": "Out-of-the-box LLMs may be contained or contaminated by training data or lacking calibration; performance was poor without additional methodologic adjustments (ensembling/fine-tuning).",
            "notable_findings": "Out-of-the-box conversational LLMs may not reliably forecast real-world events without additional method interventions.",
            "uuid": "e3643.2",
            "source_info": {
                "paper_title": "Can Language Models Use Forecasting Strategies?",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Schoenegger et al. 2024",
            "name_full": "Wisdom of the silicon crowd: LLM ensemble prediction capabilities match human crowd accuracy.",
            "brief_description": "Referenced concurrent work finding that ensembling predictions from many LLMs improves forecasting performance and can rival the accuracy of human crowds.",
            "citation_title": "Wisdom of the silicon crowd: Llm ensemble prediction capabilities match human crowd accuracy.",
            "mention_or_use": "mention",
            "model_name": "LLM ensembles",
            "model_description": "An ensemble of many LLMs (distinct models) used to produce aggregated probabilistic forecasts; details are in the cited work.",
            "prediction_task": "Forecasting real-world events and matching human crowd accuracy through aggregated model predictions.",
            "method_of_probability_estimation": "Ensembling / averaging predictions across multiple distinct LLMs to create a synthetic 'silicon crowd'.",
            "dataset_or_benchmark": "Forecasting tournament / real-world forecasting datasets used in that referenced study.",
            "performance_metrics": "Reported by the cited study to reach performance comparable to human crowds; the present paper cites this qualitatively and does not re-report numeric metrics.",
            "comparison_to_baselines": "Presented as evidence that ensemble approaches materially improve results relative to single-model prompting.",
            "limitations_or_challenges": "Ensembling requires multiple models and/or model checkpoints and may be more computationally expensive; referenced as a contrasting method to the single-model prompting strategies tried here.",
            "notable_findings": "Aggregating many LLM forecasts (ensembling) can rival human crowd accuracy, per the referenced work.",
            "uuid": "e3643.3",
            "source_info": {
                "paper_title": "Can Language Models Use Forecasting Strategies?",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Zou et al. dataset",
            "name_full": "Forecasting future world events with neural networks (dataset)",
            "brief_description": "Referenced prior dataset of forecasting tournament questions intended as a benchmark; authors note older datasets of this kind may be contained in modern LLM pretraining and thus be less useful for evaluation.",
            "citation_title": "Forecasting future world events with neural networks.",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "prediction_task": "Benchmark of forecasting tournament questions for model evaluation (dataset-level resource).",
            "method_of_probability_estimation": "Dataset intended for use by forecasting models; the referenced paper used neural networks for prediction (details in that work).",
            "dataset_or_benchmark": "A dataset of forecasting tournament questions (cited work); the present paper notes the dataset is several years old and likely present in modern LLM pretraining.",
            "performance_metrics": "Not reported here; metrics and results are in the cited work.",
            "comparison_to_baselines": "Mentioned as background and as potentially obsolete for modern LLM evaluation due to contamination by pretraining data.",
            "limitations_or_challenges": "Older public forecasting datasets may appear in model pretraining corpora, invalidating held-out evaluation assumptions.",
            "notable_findings": "Serves as prior benchmark work; cited caution that benchmark freshness and pretraining contamination are critical when evaluating forecasting ability of modern LLMs.",
            "uuid": "e3643.4",
            "source_info": {
                "paper_title": "Can Language Models Use Forecasting Strategies?",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Approaching human-level forecasting with language models.",
            "rating": 2,
            "sanitized_title": "approaching_humanlevel_forecasting_with_language_models"
        },
        {
            "paper_title": "Large language model prediction capabilities: Evidence from a real-world forecasting tournament.",
            "rating": 2,
            "sanitized_title": "large_language_model_prediction_capabilities_evidence_from_a_realworld_forecasting_tournament"
        },
        {
            "paper_title": "Wisdom of the silicon crowd: Llm ensemble prediction capabilities match human crowd accuracy.",
            "rating": 2,
            "sanitized_title": "wisdom_of_the_silicon_crowd_llm_ensemble_prediction_capabilities_match_human_crowd_accuracy"
        },
        {
            "paper_title": "Forecasting future world events with neural networks.",
            "rating": 2,
            "sanitized_title": "forecasting_future_world_events_with_neural_networks"
        },
        {
            "paper_title": "Ai-augmented predictions.",
            "rating": 1,
            "sanitized_title": "aiaugmented_predictions"
        },
        {
            "paper_title": "Large language model prediction capabilities: Evidence from a real-world forecasting tournament.",
            "rating": 1,
            "sanitized_title": "large_language_model_prediction_capabilities_evidence_from_a_realworld_forecasting_tournament"
        }
    ],
    "cost": 0.0167425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Can Language Models Use Forecasting Strategies?
6 Jun 2024</p>
<p>Sarah Pratt spratt3@uw.edu 
University of Washington</p>
<p>Seth Blumberg 
University of Washington</p>
<p>Pietro Kreitlon Carolino 
University of Washington</p>
<p>Meredith Ringel Morris 
University of Washington</p>
<p>Google 
University of Washington</p>
<p>Google Deepmind 
University of Washington</p>
<p>Can Language Models Use Forecasting Strategies?
6 Jun 2024B3DAE1810A6BF8F0AEC6EEE9842DCA73arXiv:2406.04446v1[cs.LG]
Advances in deep learning systems have allowed large models to match or surpass human accuracy on a number of skills such as image classification, basic programming, and standardized test taking.As the performance of the most capable models begin to saturate on tasks where humans already achieve high accuracy, it becomes necessary to benchmark models on increasingly complex abilities.One such task is forecasting the future outcome of events.In this work we describe experiments using a novel dataset of real world events and associated human predictions, an evaluation metric to measure forecasting ability, and the accuracy of a number of different LLM based forecasting designs on the provided dataset.Additionally, we analyze the performance of the LLM forecasters against human predictions and find that models still struggle to make accurate predictions about the future.Our follow-up experiments indicate this is likely due to models' tendency to guess that most events are unlikely to occur (which tends to be true for many prediction datasets, but does not reflect actual forecasting abilities).We reflect on next steps for developing a systematic and reliable approach to studying LLM forecasting.</p>
<p>Introduction</p>
<p>Throughout history, people have attempted to synthesize information about the past in order to make accurate predictions about the future.Many careers from political pundit to meteorologist are focused primarily on being able to forecast the outcome of future events better than the average person.However, despite the importance and prevalence of these predictions, measuring the accuracy of predictions after the fact is harder than it may first appear.Language around predictions is often vague and subjective.If a political pundit states that a politician "could get elected" and then they win, the political pundit could claim to have been correct.However, if they lose, the pundit could similarly claim to have been correct by including the word "could," demonstrating their skepticism all along.Similarly, it is not always clear what is an official prediction versus an off-hand speculation.This vague nature makes it difficult to retrospectively measure the accuracy of forecasts, even after the outcome is known.Without the ability to measure performance it is difficult to improve, as we cannot empirically know which strategies yield accurate predictions and which do not.</p>
<p>To remedy this, Mellers et al. [11] studied the performance of individuals when forecasts were made in a controlled setting, specifically a forecasting tournament.This study, sponsored by the U.S. intelligence community, aimed to measure the performance of various individuals and strategies to concretely understand how to make effective predictions.A number of events were collected by the tournament organizers.Forecasters made predictions on the likelihood of these events taking place from 0 to 1 and then were scored by the accuracy of their predictions.Mellers et al. [11] and later Tetlock et al. [17] found that indeed some participants consistently outperformed their peers in accuracy and certain strategies seemed correlated with an ability to correctly predict if events would occur.</p>
<p>In this paper, we study whether Large Language Models (LLMs) can meet or even exceed human performance on forecasting tasks.We first describe a novel dataset of prediction events and associated human forecasts, and discuss the tradeoffs of various approaches for implementing and measuring LLM forecasting abilities.We then present results from instructing an LLM to use several "superforecasting" [17] strategies known to improve human forecasters' performance, ultimately finding that our LLM superforecasting approaches do not consistently outperform our human baseline.We then conduct further analyses to explore why LLMs do not yet consistently outperform humans on this task, and discuss a path forward for LLM forecasting research.</p>
<p>Related Work</p>
<p>Human Forecasting: The inspiration for examining the ability of LLMs to make predictions about events in the future comes directly from prior work examining humans' ability to make effective predictions about the future.Mellers et al. [11] examine the performance of different participants over the course of multiple forecasting tournaments.In these tournaments, a dataset of events is created and participants must make predictions on the likelihood of these event occurring.Participants are scored based on how far away their prediction was from the true outcome.Mellers et al. [11] found that not only were some individuals consistently much more accurate, but they were able to find different strategies that correlated with more successful predictions; Tetlock has also described successful strategies of "superforecasters" [17] .We take inspiration from these works when crafting prompts for our LLM-based forecasters.</p>
<p>LLMs for Time Series Forecasting: Forecasting real world events is a specific instance of future prediction.One area of study for LLM future prediction is time series data.For time series data, LLMs are given a sequence of data points and must continue the sequence with one or several predictions into future data points, rather than making a single prediction on a single defined event.Time series forecasting is well-suited to a number of applications and LLMs have been explored in making time series predictions for traffic patterns [10], stock fluctuations [21], and future retail data [1].</p>
<p>Additionally, prior work has explored multiple methods to adapt LLMs to time series data.Chang et al. [6] finetune pre-trained LLMs on seven different time series tasks.Xue et al. [22] examine a zero-shot model as well as a pre-trained model, adapting the time series data into a natural language prompt so that the pre-trained model may understand this data in-context.Finally, Gruver et al. [7] examine LLMs for time series prediction in a purely zero-shot setting.They find that LLMs are able to make predictions even without first transforming the data into a natural language question, but rather framing the prediction as a next token completion.Additionally, they find that a number of factors affect zero-shot ability of LLMs, such as how the tokenizer parses the input.While these works all focus on using LLMs to make predictions about the future, they focus on producing the next values in a series of observations, which differs substantially from the task of single event prediction.</p>
<p>LLMs for Forecasting Real World Events: In addition to predicting the future in the format of time series prediction, prior work has examined how to automate predictions for single real world events, such as those in a forecasting tournament.Zou et al. [23] present a dataset of questions taken directly from a forecasting tournament to act as a benchmark for future automated forecasting models; however, this dataset, being several years old, is likely contained within the pretraining of most modern LLMs, rendering it obsolete.</p>
<p>In recent months, a number of studies performed concurrently with the work described in this paper have examined if LLMs are capable of performing similarly to humans on the difficult task of predicting the future.Schoenegger et al.(2023) [13] found that ChatGPT performed poorly out-ofthe-box when making predictions on events from a popular prediction market, barely outperforming random guessing.Halawi et al. [8] found that LLMs could perform similarly to human crowds and even outperform them in certain situations.They achieved this high accuracy by ensembling the predictions of pre-trained LLMs as well as LLMs that had been fine-tuned to generate accurate predictions.Finally, Schoenegger et al.(2024) [15] similarly found that ensembling the prediction of many LLMs improves performance over a single LLM prediction and rivals the performance of a crowd of human forecasters.</p>
<p>We build on this previous work by examining the effectiveness of specific strategies shown to be effective in humans when applied to LLM forecasters and identifying a propensity toward negative predictions as a model confound.Specifically, we examine works which study human forecasting [11,17], translate the proposed forecasting strategies into LLM prompts, and then compare these approaches to human performance as well as simpler LLM baselines.In the Discussion, we reflect on potential causes of similarities and differences between our findings and those of concurrent LLM forecasting studies such as [13,8,15], and identify opportunities for methods to support uniform and replicable approaches to benchmarking LLM forecasting abilities.</p>
<p>Dataset</p>
<p>Constructing a dataset and measuring the forecasting performance of models presents a number of unique challenges.Most tasks used to benchmark LLMs are static: the information necessary to complete the task, the data points included in the dataset, and the performance of the baseline, are all constant in time.For example, consider a binary classification task such as sentiment classification.The number of examples which can be included in this dataset does not need to vary from year to year; the information needed to achieve good performance on this task remains consistent between years; and human performance on this task is likely to remain nearly identical no matter what year it is evaluated, providing a consistent baseline to understand the abilities of any given model.Now consider the task of forecasting.In order to measure its forecasting performance, a model must be evaluated on a set of questions about events that are in "its future" but in "our past".For instance, asking a modern-day model who will win a presidential election in 2012 tells us nothing about its ability to predict future events -this information is simply in the model's pre-training data.On the other hand, we can't ask it who will win an election in 2052, since we won't know if its answer is right or wrong.Thus the model must be evaluated on events that already resolved in the real world, but only after the model was trained.</p>
<p>Next, consider the information needed to make a 'good' prediction for an event.In a given week, it may be very difficult to predict the outcome with any confidence; however, the next week the information may change and the result of that event may become obvious (consider the case of predicting a presidential primary winner -if several candidates drop out of the contest after a poor debate performance, thus narrowing the field, the task of predicting the winner becomes substantially easier after the debate than beforehand).Therefore the information that should be incorporated into the prediction changes with time.Finally, the baseline performance is similarly dynamic.Just as new information may suddenly clarify the outcome for a model, it may also greatly influence human performance.In order to understand if a model has high performance, it is valuable to compare it to human performance at that same point in time (i.e., being equivalently "up to date" in their knowledge of relevant events).</p>
<p>Therefore in order to construct a dataset and measure human and model performance on this dataset, we must define how to do this in this setting of constantly changing data.In this section we detail how we establish consistent metrics for ever-changing data and models.</p>
<p>Data</p>
<p>In order to measure forecasting performance we must first obtain a large set of events for which models may make predictions.Additionally, for each of these models it is valuable to have human predictions in order to provide a baseline for model accuracy.We satisfy both of these requirements with data from GleanGen.GleanGen is a prediction market where more than 2,000 Google employees trade a virtual 'currency' based on the likelihood that an event will take place (this 'currency' has no monetary value, but is used to incentivize market participation via gamification mechanisms such as leaderboards).Prediction markets have been shown to lead to high accuracy predictions as they provide financial (or in this case, reputational) incentive for correct predictions and take advantage of the wisdom of the crowds rather than relying on the forecasts of a single individual [19].</p>
<p>Event Descriptions.The GleanGen prediction market data consists of of (1) events and their descriptions and (2) human predictions.Each event is defined by a number of different fields, as depicted in Figure 2. Events are given a unique name that roughly describes the topic of the event.The event itself is defined by the condition, which is a binary event that can either occur or not occur.This condition is phrased to eliminate as much ambiguity as possible.For example, if a condition is phrased as "Company X has a successful first quarter" or "AI reached human level capabilities," this can lead to clashing definitions over "successful" or "human level," as these terms can be subjective.Therefore events are phrased to rely on objective metrics such as "Company X sees a net profit in the first quarter" or "AI achieved y% on benchmark z."In addition to the condition, the event contains an expiration date, so all conditions are phrased as "Condition takes place by date X."This makes it possible for events to resolve negatively.Without an expiration date, an event such as "AI reached human level capabilities" can never resolve in the negative as it can always be argued that this event just has not happened yet.</p>
<p>In addition to the condition and expiration date, each event has a creation date, which is when human forecasters were able to begin to make predictions.There is also a resolution date, which is when the event is resolved 'true' or 'false.'Note that this can coincide with the expiration date but can also be different.For example, if the event is "Company X gets a new CEO by date Y," then the resolution date can either be whichever day a new CEO is named or the date when the event expires.For resolved events, there is a field indicating if it resolved as True or False.Each event is tagged with a category specifying the general topic of the event.</p>
<p>GleanGen is framed as a prediction market rather than a forecasting tournament.Rather than make direct numerical predictions, forecasters on GleanGen make trades to try to maximize their total "currency."If a user believes the probability of an event is lower than the market, they can make a trade based on this belief.If they outperform the market, they gain "currency," moving up on the leaderboard.A detailed explanation of the mechanics of prediction markets can be found in Section 4 of Hanson et al. [9].Thus, for each event, GleanGen provides a range of probabilities that represent the market's belief about its likelihood.This range can change over time as the market shifts based on new information.See Figure 2 in the appendix for a visualization of the human predictions for a given event.</p>
<p>Dataset Cleaning and Filtering</p>
<p>We remove any events that have not yet resolved.Additionally, we filter based on event category; of the nine categories, five relate to events that are internal to Google.We remove these since LLMs would have an unfair disadvantage at answering these types of questions, since public models are not trained on internal corporate data relevant to forecasting intra-company topics.This leaves events in four categories (Covid-19, Finance, Technology Industry, and Miscellaneous).With these remaining events, we create a Validation set and a Test set, balancing so they have a similar number of events resolved in each month.Appendix F provides examples of events that resolve positively and negatively in each topic category.</p>
<p>After completing this filtering, we are left with 351 events in our Validation set, and 341 events in the Test set; each split includes predictions from more than 1,000 humans with a median of about 100 predictions per event.We present all experiments on the Validation set and then use our Test set to ensure our observations generalize to a different distribution of events, which we present in Appendix B. The distribution of predictions, resolution, category, and number of events over time is shown in Figure 3 in the Appendix C, and additional statistics are given in Table 4 and Table 5 in Appendix A. The majority of events resolve 'No.'Many of the events resolved at the end of 2022; this is due to many events being phrased as "Will X happen in 2022."</p>
<p>Evaluation Metric</p>
<p>Brier Score.Given the constantly shifting set of events and baseline human predictions, it is crucial to carefully define our evaluation metric.Following previous works that examine forecasting abilities in humans [11] and LLMs [8,13,15] we measure the accuracy of forecasts using Mean Squared Error, generally referred to as Brier Score when used to measure forecasting performance.Specifically, we measure performance using the formula:
BrierScore = 1 N N t=1 (f t − o t ) 2
Where f t ∈ [0, 1] and represent the predicted likelihood of the event, while o t is either 0 if the event did not occur or 1 if if it did.Thus the Brier Score is between 0 (for a perfect prediction) and 1 (for a maximally incorrect prediction).Additionally, we introduce the Weighted Brier Score, a metric designed to counteract the inherently uneven nature of the collected dataset.The large majority of events in the prediction market resolve negatively.This means that biases that push the models/humans to predict lower values often lead to a higher Brier Score.The Weighted Brier Score separately calculates the Brier Score of events that resolved positively and events that resolved negatively and then averages the two, creating a post-hoc balancing of these types of events.</p>
<p>Prediction Market Spread.To calculate the Brier Score, each event must have a forecast from 0 to 1.However, the human forecasts for each event takes place for a range of time and comes as a spread of events with a lower and upper bound.To convert this to a single value for each day, we take the mean of the upper and lower bounds and assign this as the human prediction for that day.</p>
<p>Prediction Through Time.Another challenge with comparing to human baselines comes from the fact that human predictions (and relevant information for both the humans and the model) change over time.Even after averaging the bounds we are still left with different human predictions for each day.There are several ways to utilize these predictions as a baseline.</p>
<p>One option is to set a single date and take predictions from that date for both the human predictions and the LLM forecaster.The crucial thing to consider for this strategy is to pick a date such that the model and the humans have similar amounts of information.That is, if we select the date August 1, 2022, and pull human predictions from that date, it is an unfair comparison if the LLM has been trained up to October 1, 2023, and the LLM predictions are able to take advantage of much more up-to-date information that the human predictions (even if all the events in the data set resolve after October 1, 2023).Therefore the best way to implement this strategy is to set the date as slightly after the model's knowledge cut-off so that human predictions are able to condition on at least as much information as the model's predictions.The benefit to this strategy is that all predictions are made with equally up-to-date information for each event and the humans and the model are using equally up-to-date information.The disadvantage for this strategy is that all predictions are made for the event which were active on a single day given the information that was present on a single day.This poses a risk that observations about these predictions may not generalize to predictions made for events during another time period.Events for that day could be particularly easy or difficult.</p>
<p>Another option is to take multiple predictions throughout time for both the humans and the model, as in Hawali et al. [8].For each event, they make predictions about the likelihood of the event at various points between when the event began and when the event was resolved.When using external information for their LLM forecaster (such as news articles), they provide the LLM with external information up until each date that they predict.This has the advantages of considering information and events throughout multiple points in time.However, while it is possible to change the external information that is fed into the LLM, it is not possible to on-the-fly update its pre-training information.That means that for some predictions, the LLM will have very up-to-date pre-training data compared to the human baseline, and for some predictions, the LLM may be months out of date compared to the information that the humans were able to use to make their forecasts.</p>
<p>In this work, we aim to examine how well LLMs are able to forecast events given that they are trained with as up-to-date information as possible (though in-filling recent world events to an out-of-date LLM remains an interesting research direction).To this end, we select the former option as our method of measuring the Brier score for both humans and LLMs.We begin our events in August 2022 (our model's pre-training data ends in July 2022 [16]); we then compare the accuracy of the LLM predictions to the forecasts of humans on date X for the same set of events.This controls for the difference in knowledge between the humans and LLMs as much as possible.</p>
<p>Methods</p>
<p>Backbone Model Selection.To build a forecasting agent, we begin with a large pre-trained language model.While most tasks are best tackled by the most recent, most capable models, such models pose problems for evaluating a forecasting agent.To evaluate the model, we need a collection of events for which we know the outcome but the model does not; that is, we must be able to guarantee that the resolution of the event is not contained in the pre-training data.For this, we need a model whose pre-training ended far enough back in time such that a large number of events have resolved since that time.Aiming to balance model capability with training cut-off date, we select PaLM 2 [3] as our backbone language model, which ended its pre-training in July 2022 [16].</p>
<p>Input format.For all of the following LLM forecasting approaches, we input the events to the LLM forecaster as a natural language input (i.e., a text prompt).We extract the information from each field in the GleanGen events and additionally include a short description of the field when necessary.We also include the date for which our model is making predictions, which we set as August 1, 2022.There are 78 events which are active for this date in the Val set (meaning that the events have begun by this date but has not yet resolved).As detailed below, we experiment with different forecasting approaches by include various other instructions which are also formatted in natural language, building on the basic event description as given below:</p>
<p>"You will make a prediction on the event called [EVENT NAME] The event will be true if the following condition is satisfied: Output format As our final output, the model must produce a value between 0 and 1 that represents the probability of the event occurring, which the model generates in text.This can then be postprocessed to extract the value from the text and evaluated.Additional details on this process can be found in Appendix D.</p>
<p>Examined Forecasting Strategies.In order to build an LLM forecaster, we draw inspiration from previous tactics that are known to improve humans' ability to predict events accurately.Prior research in human forecasting has shown that certain methods of examining and researching an event often yield higher performance [11,17].We design a number of LLM forecasters in which the LLM processing the event uses these known strategies.The strategies we examine are as follows:</p>
<p>Breakdown.Many events are difficult to predict as they actually require a series of things to occur.For example, in order for someone to become President of the U.S. they must decide to run for president, win their party's primary, win the election, and stay in good health during the entire process.Therefore, one strategy that is recommended for making accurate predictions is to break all events down into these sub-events and consider the likelihood of each of individually, using these sub-event predictions to inform the prediction of the target event.</p>
<p>Base Rates.The philosophy behind base rates it to use the frequency of similar past events to predict future events.For example, to know the likelihood of a major hurricane, one should examine the frequency of hurricanes in the past.Then the final prediction should be an adjustment of this initial forecast, or "base rate."One hypothesis for why this strategy is more effective is that people may afford too much weight to the specifics of the situation [4].Using the past occurrences forces people to at least begin with an initial prediction that does not take the specifics of a certain situation into account at all, but rather uses similar prior events as proxy, mitigating this bias.</p>
<p>Both Sides.This strategy states that it is valuable to examine the factors which may increase the likelihood of an event taking place and those which would decrease the likelihood, even in the case where one outcome seems almost certain.Making an argument for both perspectives may allow the forecaster to uncover valuable pieces of information which may have been overlooked if the forecaster was only building evidence for one perspective.</p>
<p>Crowd.Prior work has found that groups of high performance forecasters are able to make more accurate predictions than individual forecasters [11].Towards this end, we examine the strategy of averaging the predictions of multiple different LLM personas.This differs from prior work using synthetic crowds [15] for forecasting as we implement the crowd using one base pre-trained model and many personas, rather than many models each with the same persona.The method of generating these personas for each event is given in Appendix E. use external news sources to first query a database of headlines (specifically, The New York Times and Hacker News).We then incorporate these headlines into the model's prediction, allowing the model to ground its predictions in external knowledge sources.</p>
<p>News</p>
<p>Baselines.In addition to human performance, we utilize two simple LLM baselines to understand the out-of-the-box performance of pre-trained models on the task of forecasting.Both of these baselines are composed of a single prompt which instructs the model to generate a prediction.For the first baseline, which we denote the 'Basic Baseline', we simply provide the model with the details of the event and prompt it to generate a prediction.For 'Forecaster Baseline', we provide the model with the prompt proposed in [13].However, neither of these baselines utilize any sophisticated forecasting strategies, but rather rely on a single prompt.</p>
<p>Design Approach.For each strategy, our workflow chains [20] various LLM based modules in which each module is instructed to complete a step in the current strategy.The output of the module is then processed and used as input for the next module.The final module receives the output of previous generations to produce a prediction.We visualize this workflow for the News API strategy in Figure 5.The workflows and prompts for all strategies and baselines are given in Appendix E.</p>
<p>Results</p>
<p>Table 1 presents the Brier Score of our human data from GleanGen, two LLM baselines, LLM-based forecasters using the strategies enumerated in Section 4. The results in Table 1, are surprising in two ways.First, the most basic strategy outperforms the human prediction market baseline.This is unexpected as prediction markets are known to produce high accuracy forecasts.Thus, it is unexpected that such a simple prompt would outperform this strong human baseline.</p>
<p>The second surprising observation in Table 1 is that none of the more complex forecasting strategies outperform the most basic baseline.Breaking down the problem into smaller subparts, examining base rates, considering the factors which may contribute to each outcome, generating predictions from multiple personas, and using external news sources all lead to a worse Brier Score than the most basic strategy of using a single prompt.Even using a single prompt which is slightly more complex as in [13] leads to significantly worse performance.Thus, not only does a single basic prompt outperform humans, but also all examined forecasting strategies when applied to the same base model.This same observation applies to the test set as given in Table 6 in Appendix B.</p>
<p>Negativity Bias Hypothesis and Analysis</p>
<p>We hypothesize that the reason for the high performance of the simplest LLM baseline as well as the relatively worse behavior of all other prompting approaches is due to the underlying biases of the model, specifically the tendency of the model to predict low probabilities of events in the most basic prompt setting.The large majority of events resolved negatively (this is likely to be a property of most prediction market and/or forecasting tournament datasets, since events must be phrased very</p>
<p>Events which resolve as False Events which resolve as True</p>
<p>Figure 1: Predictions for events in the Validation set with and without the model first producing a rationale.When prompted to produce a rationale, the model predicts a consistently higher probability.This underlying bias of the model to produce a low probability when no rationale is required (paired with the skewed distribution towards events that do not occur) may explain why the simplest baseline outperforms all other strategies.Figure 6 in Appendix G shows this figure at a larger scale.</p>
<p>specifically to make them meaningful as measurable predictions, thereby decreasing the likelihood that their conditions will be satisfied).This means that a model which naturally tends to assign a low probability to events occurring may have high performance without a real ability to succeed at the task.We propose that the high accuracy of the most basic model is due to its underlying distribution, not its forecasting ability.We further explore this theory through three follow-on analyses, below.</p>
<p>Weighted Brier Score.We introduce the Weighted Brier Score in order to better measure the performance of individual models and remove the positive bias associated with low probabilities.We separately compute the Brier Score for the events which do occur and which do not occur and then average these values.This approach accounts for the uneven distribution of events via a post-hoc re-weighting.The results for this metric are found in Table 2. Using this metric, the human baseline outperforms all LLM methods.Additionally, we can see that the Brier scores for the events which resolve as Yes are significantly higher than the Brier scores for events which resolve as No, indicating better performance for negatively resolving events.While this is also the case for the human baseline, the effect is less extreme, supporting our theory that improvements over human baselines of LLM forecasters may be due to their tendency to produce lower forecasts than the prediction market.</p>
<p>Predictions with and without Rationales.Additionally, we examine the theory that the most basic LLM model produces the best Brier Score because other interventions raise the average prediction value, which is associated with worse performance when most of the events resolve negatively.To do this, we generate predictions on a set of events twice.Once we used our basic baseline (which we call 'Just Answer') and the second time we instruct the model to first provide a rationale and then answer, which we refer to as 'Answer + Rationale'.The results of this experiment are shown in Figure 1.In line with our hypothesis, the probabilities from the 'Just Answer' setting are much lower than those of our 'Answer + Rationale' setting.This validates the theory that prompting the model to utilize forecasting strategies leads to a worse accuracy not because the model becomes worse at forecasting, but because the overall probabilities increase.</p>
<p>Reversed Events.To further understand the bias of the base model, we evaluate the models on the reverse of all the events.That is, we reword the events so that they describe the opposite outcome.If the event is "Candidate A becomes president," then we would reverse the event so it is "Candidate A does not become president."We then subtract this prediction from 1 to get a forecast for the likelihood of the original event (as the probability of the event occurring is the same as 1 minus the probability of the event not occurring).Table 3 shows the results of this experiment.As expected, the average probability produced by the LLM forecaster is much lower than that of the human prediction market.However, when predictions are made of reversed events and then subtracted from 1, the average prediction is significantly higher than in the Basic condition.This suggests that the model makes low predictions on the probability of the event taking place as well as low predictions of the probability not taking place, since logically Basic and 1 -Reversed should be equal.In other words, we would expect the model's probability that an event will take place and the model's probability that an event will not take place to add to 1; however, they add to well below 1, indicating the model has a bias towards predicting low probabilities.</p>
<p>Human Basic 1 -Reversed Average Probability 0.3280 0.2529 0.3965 Brier Score 0.1334 0.1221 0.1814 Table 3: Given a completely unbiased model, the basic baseline should give the same value for the event and (1 -the reversed event).However, (1 -reversed) is significantly higher.This means that while the sum of the probability for the event and the reversed event should add to 1, it adds to well below 1, suggesting the model may have a bias toward low probabilities.</p>
<p>Discussion</p>
<p>We ultimately find that none of the examined forecasting strategies were able to improve over the most basic baseline of simply prompting the model to make a prediction on the event.This is inline with concurrent studies [8,13], which found that pre-trained language models were not able to perform well out-of-the-box on the task of event forecasting.However, our findings differ from these studies in that our baseline was able to perform similarly to our human prediction market.Hawali et al. [8] were able to approach human accuracy only through fine-tuning the pre-trained mondels.We conjecture that our relatively high accuracy for our most basic approach is due to underlying biases toward low probabilities in the model, and the predominance of negative outcomes in our dataset; our introduction of the Weighted Brier Score analysis revealed this insight, suggesting that such analysis may be useful in future works for revealing whether a particular study of LLM forecasting performance may be a fluke of model biases and probability distributions.</p>
<p>One limitation of this work (and of LLM forecasting studies more generally) is the need to use models slightly behind the state-of-the-art in order to be certain of the end-of-pre-training date, and to ensure that date precedes the resolution of events in the dataset.Many SOTA models do not publicize details of their training data [3,2], including the pre-training cutoff date (we had to engage in personal correspondence with model engineers to obtain this information for this research [16], an obstacle that might limit participation in research of this type to those with insider connections).In fact, models may state incorrect cut-off dates of their own models, as seen in Figure 4 in Appendix C. We strongly urge model developers to include cutoff dates in model cards [12] to facilitate future studies in this domain.Future work in developing benchmark datasets of human predictions for events beyond the training date of today's SOTA models, combined with developers' sharing accurate model pre-training cutoffs, will support future research using more capable models which have been developed since the release of PaLM 2 [3].</p>
<p>Additionally, just as we have seen groups of humans outperform the predictions of any individual human in the task of forecasting [19,11], LLMs may prove to be the most effective working in collaboration with human forecasters.Though initial work has begun to address this direction by studying ensembles of distinct models working together [14], we believe there is still much to be explored in combining the skill sets of humans and LLMs.Finally, we believe there is more to explore in translating human strategies to LLM forecasting including combining multiple strategies, employing strategies on more capable models, and experimenting with various ways to translating these stratigies into LLM-based methods.</p>
<p>Conclusion</p>
<p>This paper adds to the body of knowledge on designing LLM forecasters by studying the performance of prompting strategies based on human superforecasting approaches [17] as compared to human performance in the GleanGen marketplace.Our analysis reflects on the complexities of dataset and model selection and experimental designs for a task where performance is sensitive to the information available to a human or model at a particular point in time.We introduced the Weighted Brier Score analysis, which revealed that the apparent success of our Basic forecaster was likely a result of PaLM 2's bias toward predicting low probabilities.We hope this research provides a foundation for continued exploration into how LLMs can be used as powerful tools to understand the future.Each event contains a description of the event, as well as a specific condition that must be met for the event to resolve as true.Events are binary: the condition is either met by the specified expiration date, or it is not.Additionally, there are human predictions for each event.These predictions come in the form of a range of probabilities over time.From the time the event is created to the expiration date of the event, market participants may update their beliefs based on constantly changing information.Additionally, the human predictions are in the form of a prediction market, meaning that there is a spread of human predictions rather than just a single value.A larger spread can be interpreted as more uncertainty.</p>
<p>Appendices A Dataset Statistics</p>
<p>C Additional Figures</p>
<p>Example Event Definition</p>
<p>Resolve Yes vs No Category of Event</p>
<p>Number of events on a given date Figure 3: Breakdown of event types in Validation set.The majority of events resolve 'No,' meaning the that condition of the event did not take place by the expiration date.The events are distributed over four categories: Technology Industry, Finance, Covid-19, and Misc.Additionally, the number of events that are active for a given date vary significantly, with the peak occurring just before the end of 2022.</p>
<p>Figure 4: Example of unclear model cut-off date.When ChatGPT is first asked its cut-off date, it states it is September 2021.It then will not answer a question about 2022.However, when directly asked a question about 2022 in a new chat window, the model is able to correctly answer.These chats both took place on November 8, 2023.This strongly suggests that the model is in fact trained on data after its stated cut-off date.This uncertainly makes analysing a model's forecasting ability challenging.</p>
<p>Module 1:</p>
<p>Get Search Queries Event data is input into the first module which is instructed to extract two to three keywords for each event (e.g., for the event "Tesla L3 Autonomy (3): Tesla reaches L3 autonomy (driving required only when prompted)", this module extracts the words 'Tesla', 'Autonomy', and 'Driving' ).These search terms are then used to retrieve articles from The New York Times and Hacker News APIs.The articles that are retrieved are then post-processed by an LLM module which is instructed to remove unrelated headlines and summarize the relevant information returned by the News APIs.Finally, the predictor module uses these summaries as well as the details of the event to make a final prediction.Prompts and pipelines for all forecasting strategies are given in Appendix E D Extracting Probability from LLM Generating a Probability in Natural Language In order to extract a probability from the LLM, we generated a response using standard next token prediction.We then post-process the output, using an additional LLM which was instructed to read through the output and emit only the probability value as a floating point value.We found this to be the most straight-forward method and allowed the most flexibility when experiment with different forecasting strategies.However, we also considered the following two alternative methods.</p>
<ol>
<li>
<p>Alternative 1 is to extract a probability of an event is to examine the probability of each token in a selected set of values (i.e. the token for '5%', '10%', etc).This will guarantee that the model is always producing a probability.However, model probabilities can be poorly calibrated and model distributions often do not correlate with a true level of confidence.Additionally, this method also suffers from the fact that some tokens may be favored simply because they occur more frequently in the training data and not because they are a more accurate measure of the model's internal prediction (consider 10% versus 11%; the former is a more common completion than the latter).</p>
</li>
<li>
<p>Alternative 2 is to not use the token outputs at all and train an additional layer on top of the final representation of the model to output a numerical probability.Like the previous option, this suffers from the issue that model probabilities don't always correlate to true confidence values.Additionally, with this option it is difficult to understand how text based interventions such as in-context learning [5] or chain-of-thought [18] affect the final probability.</p>
</li>
</ol>
<p>Averaging outputs.Rather than generate a single prediction, we instead generate eight different predictions and then take the mean as the final prediction.This makes the model slightly more robust to any small changes that may occur in the output due to small but semantically insignificant changes to the input.In practice, we set the temperature very low (0.01) and then sample eight predictions.This means that if the model is confident in a given value, the predictions are likely to all be similar, but if the model gives equal probability to many different potential outcomes then the model will likely sample and then average a variety of these outputs.</p>
<p>E Prompts and Workflows for Forecasting Strategies</p>
<p>In this Appendix, we provide the prompt templates for each of our LLM forecaster approaches.</p>
<p>Note that "[Forecaster Text]" in below prompts refers from the following prompt from [13]:</p>
<p>In this chat, you are a superforecaster that has a strong track record of accurate forecasts of the future.As an experienced forecaster, you evaluate past data and trends carefully and aim to predict future events as accurately as you can, even though you cannot know the answer.This means you put probabilities on outcomes that you are uncertain about (ranging from 0 to 100%).When the outcome is continuous, you give me 25th interquartile ranges.You also quickly outline your rationale.In your rationales, you carefully consider the reasons for and against your probability estimate, you will make use of comparison classes of similar events and probabilities and take into account base rates and past events as well as other forecasts and predictions."You will also consider different perspectives."</p>
<p>Basic:</p>
<p>Predict the likelihood of the following event by the given date.</p>
<p>You will make a prediction on the event called Base Rate:</p>
<p>You are trying to forecast if an event will take place in the future.For example, if the event is 'A member of the house of representatives steps down before the end of their term' the question might be 'How many times in the past 100 years has a member of the house of representatives stepped down before the end of their term.'If the event is 'Joe Biden dies in the next year' the question might be 'How likely is it than an 80 year old dies in the next year?'If the event is 'Company X has a profit of Y in 2022' the question might be 'What was the companies profits in each of the last 5 years?' Pose a question about the frequency of similar events that will act as a base rate for this event: Both Sides:</p>
<p>Positive Prompt:</p>
<p>You are part of a team trying to figure out in an event is likely to take place.You are tasked with detailing all evidence that the event will happen.Describe everything we must consider that may make the event more likely to take place.This includes specific facts about the event that your team should consider, as well as sequences of events that may make the event more likely.For example, consider the event: Kamala Harris become president in 2024.You may want to mention her current role as vice president, as well as the possibility that Joe Biden may die or be too ill to run.Additionally, make use of base rates of similar situations.Using the above example this may include information such as the average 80 year old has about a 7% chance of dying in the next year.Write a paragraph which you will share your your team detailing the evidence that may increase the likelihood of the event taking place.</p>
<p>You will be generating the supporting evidence for the event called [name] The event will be true if the following condition is satisfied: [condition] This condition must be satisfied by [expiry] Currently the date is [today], so the event must happen within the next [number of days] days.</p>
<p>Here is additional information about this event:</p>
<p>[description] Please give all the evidence that the condition will happen by [expiry].</p>
<p>Return [pros]</p>
<p>Negative Prompt:</p>
<p>You are part of a team trying to figure out in an event is likely to take place.You are tasked with detailing all evidence that the event will not happen.Describe everything we must consider that may make the event less likely to take place.This includes specific facts about the event that your team should consider, as well as sequences of events that may make the event more less.For example, consider the event: Kamala Harris become president in 2024.You may want to mention that Joe Biden has only served one term.You may also want to mention her lack of popularity, so that even if Joe Biden does not run, she may not be chosen as the nominee.Additionally, make use of base rates of similar situations.Using the same example, this may include information such as only 5 presidents have chosen not to run for a second term.Write a paragraph which you will share your your team detailing the evidence that may decrease the likelihood of the event taking place.</p>
<p>You will generating the evidence that suggests the following event does not take place: [name] The event will be true if the following condition is satisfied Sequences:</p>
<p>You are a forecaster tasked with generating all the different possible sequences of events that would cause an event to NOT happen.</p>
<p>[EVENT] Kamala Harris is the Democratic Nominee for 2024</p>
<p>Crowd:</p>
<p>You must ask an expert to make a prediction on a single event.Your job is to decide which expert you would like to ask.For example, if you were to pick an expert to predict if SpaceX will land on Mars, you may choose to ask an aerospace engineer.You must pick an expert to make a prediction on if the following event will take place: You are [job].Using your expertise, you will make a prediction on the likelihood of an event taking place.Using your background knowledge, consider past events, and use this to inform your prediction about the future.</p>
<p>You will make a prediction on the event called [name] The event will be true if the following condition is satisfied: [condition] This condition must be satisfied by [expiry] Currently the date is [today] Here is additional information about this event: [description]</p>
<p>Now talk through your rationale.Begin by discussing you own expertise.Next talk through the specific details about the event.You will give two probabilities.First, output the probability, between 0 and 1, that [condition] will happen ever.Then, output the probability, between 0 and 1, that [condition] will happen between [today] and [expiry], so in the next [number of days] days.'</p>
<p>External News:</p>
<p>You are summarizing an event into just the main words involved, in order to best search for the event in a search engine.You may name people, places, events or anything else.For example, the main entities involved in SpaceX lands human on Mars, would be: You are examining some newspaper headlines to try to predict if an event will take place.Read through the headlines and remove any which are totally irrelevant to the given topic.Additionally, remove headlines if they are identical to an existing headline.
SpaceX</p>
<p>[Hackernews headlines]</p>
<p>You are interested any headlines that could lead to the event or indicate that it will not happen: [name] Keep any headlines that might indicate that the event will take place.Additionally, keep any headlines that might indicate that the event will not take place.Remove irrelevant and duplicate headlines.If none of the headlines are very relevant, output NONE.</p>
<p>Return [filtered Hackernews headlines]</p>
<p>You are examining some newspaper headlines to try to gather information about an event.Many of the headlines contain irrelevant information, but some headlines may contain valuable pieces of information.Read through the headlines and look for information which directly relates to the event you are studying.</p>
<p>Then return a list of all relevant information extracted from the headlines.You may return entire headlines, small pieces of headlines, or paraphrased headlines.For example, you may be looking through headlines that that contain evidence about if Kamala Harris will be the next president.</p>
<p>Figure 2 :
2
Figure2: Example event from GleanGen.Each event contains a description of the event, as well as a specific condition that must be met for the event to resolve as true.Events are binary: the condition is either met by the specified expiration date, or it is not.Additionally, there are human predictions for each event.These predictions come in the form of a range of probabilities over time.From the time the event is created to the expiration date of the event, market participants may update their beliefs based on constantly changing information.Additionally, the human predictions are in the form of a prediction market, meaning that there is a spread of human predictions rather than just a single value.A larger spread can be interpreted as more uncertainty.</p>
<p>Figure 5 :
5
Figure5: Schematic for single forecasting strategy.Event data is input into the first module which is instructed to extract two to three keywords for each event (e.g., for the event "Tesla L3 Autonomy (3): Tesla reaches L3 autonomy (driving required only when prompted)", this module extracts the words 'Tesla', 'Autonomy', and 'Driving' ).These search terms are then used to retrieve articles from The New York Times and Hacker News APIs.The articles that are retrieved are then post-processed by an LLM module which is instructed to remove unrelated headlines and summarize the relevant information returned by the News APIs.Finally, the predictor module uses these summaries as well as the details of the event to make a final prediction.Prompts and pipelines for all forecasting strategies are given in Appendix E</p>
<p>[condition].Here is additional information on the event: [description].Who would you like to ask?I choose to talk to return[job]</p>
<p>Mars the main entities involved in Kamala Harris Wins Democratic Nomination are: Kamala Harris Democratic Nomination What are the primary entities involved in this event: [name] ([condition])?Give [number of terms] terms: Return [search terms] [Hackernews headlines] = query-HackerNews-API([search terms]) [NYT headlines] = query-NYT-API([search terms])</p>
<p>If a headline says 'Headline 1 -2023-01-01: Kamala Harris states in press conference on Tuesday that she accepts nomination and looks forward to leading the Country' you may return '2023-01-01: Kamala Harris says she accepts nomination.You are looking for information about if the following event will take place: [name] ([condition]).Here are the headlines you have access to: [HEADLINES]:" [NYT headlines] Please pull all information from the headlines that may directly increase or decrease the likelihood of the event: [name] ([condition]).Ignore any headlines that do not directly contain information about the exact event: [name] ([condition]).If none of the headline are very relevant, output NONE.return [filtered NYT headlines] Read through each of the headlines and paraphrase each one as it relates to predicting the likelihood of the following event: [name] ([condition]).Include the date of the headline at the beginning.Do not include any interpretation of the headlines, only paraphrasing.[filtered NYT headlines] Return [summarized NYT headlines] F Example Events from GleanGen In this Appendix, we provide examples of events from each of the four analyzed categories (Covid-19, Finance, Technology Industry, and Misc.) in the GleanGen dataset.These include two negatively resolving examples (Resolution: Condition Not Met) and two positive examples (Resolution: Condition Met).</p>
<p>Figure 6 :
6
Figure 6: Larger scale version of Figure 1. Figure demonstrates that predicted probabilities are consistently higher when the model is prompted to first produce a rationale.Events which ultimately resolve as True are below the green line and events which resolve as False are above the green line.</p>
<p>Table 1 :
1
Brier score for human forecasters versus LLM based-forecasters on Validation set.Lower is better.Full prompts for these strategies are given in Appendix E.
Human Basic Forecaster Breakdown Base Rates Both Sides Crowd News API0.1334 0.12210.14830.18950.15620.15530.17060.1235HumanBasicForecasterBreakdownBase RatesBoth SidesCrowdNews APIResolve Yes0.25920.34070.33340.23780.45450.34060.21760.3353Resolve No0.09010.05030.08600.17280.05340.09140.15440.0546Weighted0.17460.19550.20970.20530.25400.21590.18600.1950
API. Finally, prior work has shown that thorough research is vital for humans to make accurate predictions on a variety of topics.Without a proper knowledge background it is nearly impossible to fully understand the underlying factors at play.Using this as inspiration, we examine methods which</p>
<p>Table 2 :
2
Weighted Brier Score for human forecasters versus LLM-based forecasters on Validation set.Lower is better.When weighting events that resolve positively and negatively the same, the human baseline performs the strongest.The Basic baseline only performs well for events that resolve negatively.The weighted score analysis suggests that the strong performance of the Basic model in Table1may have been a result of the model's bias to predict low probabilities combined with the high frequency of negatively resolving events in the dataset.</p>
<p>Table 4 :
4
Number of predictions or 'trades' made on each event in our examined prediction market.
Total Mean Median Max MinVal 77135 219.811228152Test 66361 194.610021964Total Events Resolve 'No' Resolve 'Yes' Industry Finance Covid-19 MiscVal3512111401296944109Test341223118122695298</p>
<p>Table 5 :
5
Break down of resolutions and categories of dataset
B Test Set ResultsHuman Basic Forecaster Breakdown Base Rates Both Sides Expert News API0.1413 0.10620.12060.18150.12330.14370.16110.1138</p>
<p>Table 6 :
6
Brier score for human forecasters versus LLM based-forecasters on Test set.Lower is better.Full prompts for these strategies given in Appendix E.</p>
<p>[name].The event will be true if the following condition is satisfied: [condition] This condition must be satisfied by [expiry] Currently the date is [today], so the event must happen within the next [number of days] days.
Here is additional information about this event: [description]Here is a prediction, between 0 and 100%, for if [condition] happens by [expiry]Forecaster:[Forecaster Text]Predict the likelihood of the following event by the given date.You will make a prediction on the event called [name].The event will be true if the following condition is satisfied: [condition]This condition must be satisfied by [expiry]Currently the date is [today], so the event must happen within the next [number of days] days.Here is additional information about this event: [description]Here is a prediction, between 0 and 100%, for if [condition] happens by [expiry]</p>
<dl>
<dt>You are trying to forecast if an event will take place in the future:[condition].Answer the following question: [base rate question] Give your response as a complete sentence.Predict the likelihood of the following event by the given date.You will make a prediction on the event called [name].The event will be true if the following condition is satisfied: [condition] This condition must be satisfied by [expiry] Currently the date is [today], so the event must happen within the next [number of days] days.Here is additional information about this event: [description] Here a base rate for this event: [base rate] Here is a prediction, between 0 and 100%, for if [condition] happens by[expiry]</dt>
<dt>[name] -[condition]. "Return [base rate question]Return [base rate][Forecaster Text]</dt>
<dd>
<p>[condition].This condition must be satisfied by [expiry] Currently the date is [today], so the event must happen within the next [number of days] days.Here is additional information about this event: [description] Please give all the evidence that the condition will not happen by [expiry] or at all.
Return [cons][Forecaster Text]Predict the likelihood of the following event by the given date.
You will make a prediction on the event called [name].The event will be true if the following condition is satisfied: [condition] This condition must be satisfied by [expiry] Currently the date is [today], so the event must happen within the next [number of days] days.Here is additional information about this event: [description]Here is argument for why the event may come true: [pros] Here is argument for why the event may not come true: [cons] Here is a prediction, between 0 and 100%, for if [condition] happens by[expiry]</p>
</dd>
</dl>
<p>You will make a prediction on the event called [name] The event will be true if the following condition is satisfied: [condition] This condition must be satisfied by [expiry] Currently the date is [today] Here is additional information about this event: [description]Now talk through your rationale, including all possible sequences that may lead to this event.Please take into account that to resolve as true, the event must happen in the next [number of days] days.After considering all the information, output a final probability between 0 and 1 for if the event [condition], will happen between [today] and [expiry].
[Forecaster Text][OPPOSITE] Kamala Harris is not the Democratic Nominee for 2024[END]Here are a number sequences that may lead to this event happening:[EVENT] A human sets foot on Mars by 2030-01-01 Potential Sequence [i] :[OPPOSITE] A human does not set foot on Mars by 2030-01-01 [Positive Sequence i][END]Here are a number sequences that may lead to this event not happening:[EVENT] [condition] Potential Sequence [i]:Return [Opposite Event] [Negative Sequence i]</p>
<p>Mahdi Abolghasemi, Odkhishig Ganbold, Kristian Rotaru, arXiv:2312.06941Humans vs large language models: Judgmental forecasting in an era of advanced ai. 2023arXiv preprint</p>
<p>Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, arXiv:2303.08774Shyamal Anadkat, et al. Gpt-4 technical report. 2023arXiv preprint</p>
<p>. Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, arXiv:2305.104032023Palm 2 technical report. arXiv preprint</p>
<p>The base-rate fallacy in probability judgments. Maya Bar, - Hillel, Acta Psychologica. 4431980</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033</p>
<p>Llm4ts: Aligning pre-trained llms as data-efficient time-series forecasters. Ching Chang, Wei-Yao Wang, Wen-Chih Peng, Tien-Fu Chen, 2024</p>
<p>Large language models are zero-shot time series forecasters. Nate Gruver, Marc Finzi, Shikai Qiu, Andrew G Wilson, Advances in Neural Information Processing Systems. 202436</p>
<p>Approaching human-level forecasting with language models. Danny Halawi, Fred Zhang, Chen Yueh-Han, Jacob Steinhardt, arXiv:2402.185632024arXiv preprint</p>
<p>Shall we vote on values, but bet on beliefs. Robin Hanson, Journal of Political Philosophy. 2122013</p>
<p>Chenxi Liu, Sun Yang, Qianxiong Xu, Zhishuai Li, Cheng Long, Ziyue Li, Rui Zhao, arXiv:2401.10134Spatial-temporal large language model for traffic prediction. 2024arXiv preprint</p>
<p>Identifying and cultivating superforecasters as a method of improving probabilistic predictions. Barbara Mellers, Eric Stone, Terry Murray, Angela Minster, Nick Rohrbaugh, Michael Bishop, Eva Chen, Joshua Baker, Yuan Hou, Michael Horowitz, Perspectives on Psychological Science. 1032015</p>
<p>Model cards for model reporting. Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, Timnit Gebru, Proceedings of the conference on fairness, accountability, and transparency. the conference on fairness, accountability, and transparency2019</p>
<p>Large language model prediction capabilities: Evidence from a real-world forecasting tournament. Philipp Schoenegger, Peter S Park, arXiv:2310.130142023arXiv preprint</p>
<p>Ai-augmented predictions. Philipp Schoenegger, Peter S Park, Ezra Karger, Philip E Tetlock, arXiv:2402.07862Llm assistants improve human forecasting accuracy. 2024arXiv preprint</p>
<p>Philipp Schoenegger, Indre Tuminauskaite, Peter S Park, Philip E Tetlock, arXiv:2402.19379Wisdom of the silicon crowd: Llm ensemble prediction capabilities match human crowd accuracy. 2024arXiv preprint</p>
<p>. Siamak Shakeri, 2023Private Communication</p>
<p>Superforecasting: The art and science of prediction. E Philip, Dan Tetlock, Gardner, 2016Random House</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in neural information processing systems. 202235</p>
<p>Prediction markets. Justin Wolfers, Eric Zitzewitz, Journal of economic perspectives. 1822004</p>
<p>Ai chains: Transparent and controllable human-ai interaction by chaining large language model prompts. Tongshuang Wu, Michael Terry, Carrie Jun Cai, Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems, CHI '22. the 2022 CHI Conference on Human Factors in Computing Systems, CHI '22New York, NY, USAAssociation for Computing Machinery2022</p>
<p>The wall street neophyte: A zero-shot analysis of chatgpt over multimodal stock movement prediction challenges. Qianqian Xie, Weiguang Han, Yanzhao Lai, Min Peng, Jimin Huang, arXiv:2304.053512023arXiv preprint</p>
<p>Promptcast: A new prompt-based learning paradigm for time series forecasting. Hao Xue, Flora D Salim, IEEE Transactions on Knowledge and Data Engineering. 2023</p>
<p>Forecasting future world events with neural networks. Andy Zou, Tristan Xiao, Ryan Jia, Joe Kwon, Mantas Mazeika, Richard Li, Dawn Song, Jacob Steinhardt, Owain Evans, Dan Hendrycks, Advances in Neural Information Processing Systems. 202235</p>
<p>You are a forecaster tasked with generating all the different possible sequences of events that would cause an event to happen. </p>
<p>. Joe Biden dies in office. </p>
<p>Musk claimed a human setting foot on Mars was achievable in 6 years, and 4 years if we get lucky. The Starship rocket that Musk envisions would deliver this vision has made excellent progress recently. [QUESTIONS] Will the event 'A human sets foot on Mars' happen by 2030-01-01?. EXPIRY DATE] 2030-01-01Dec 8, 2020Kamala Harris is selected as Democratic Nominee OUTCOME ACHIEVED: Kamala Harris is the Democratic Nominee for 2024 END [EVENT] A human sets foot on Mars [CURRENT DATE. ADDITIONAL INFORMATION. POTENTIAL INCITING EVENTS] None [PATH TO POSITIVE OUTCOME</p>
<p>SpaceX lands a human on Mars OUTCOME ACHIEVED: A human sets foot on Mars. PATH TO POSITIVE OUTCOME</p>
<p>NASA lands a human on Mars OUTCOME ACHIEVED: A human sets foot on Mars. PATH TO POSITIVE OUTCOME</p>
<p>A non-US country lands a human on Mars OUTCOME ACHIEVED: A human sets foot on Mars. CURRENT DATE] [today] [EXPIRY DATE] [expiry] [ADDITIONAL INFORMATION] [description] [QUESTIONS] Will the event '[condition. POTENTIAL INCITING EVENTS. Positive Sequences] You are a forecaster tasked with generating all the different possible sequences of events that would cause an event to NOT happen</p>
<p>QUESTIONS] Will the event 'Kamala Harris is the Democratic Nominee for 2024' NOT happen by 2024-11-5? [POTENTIAL INHIBITING EVENTS] Joe biden decides to run for a second term. PATH TO NEGATIVE OUTCOME</p>
<p>Joe Biden is selected as the Democratic Nominee OUTCOME NOT ACHIEVED: Kamala Harris is NOT the Democratic Nominee for. 2024PATH TO NEGATIVE OUTCOME</p>
<p>. Joe Biden dies in office. </p>
<p>Another democrat, such as Gavin Newsom, is selected as the democratic nominee OUTCOME NOT ACHIEVED: Kamala Harris is NOT the Democratic Nominee for. 2024PATH TO NEGATIVE OUTCOME</p>
<p>Another democrat, such as Gavin Newsom, is selected as the democratic nominee OUTCOME NOT ACHIEVED: Kamala Harris is NOT the Democratic Nominee for. 2024PATH TO NEGATIVE OUTCOME</p>
<p>Musk claimed a human setting foot on Mars was achievable in 6 years, and 4 years if we get lucky. The Starship rocket that Musk envisions would deliver this vision has made excellent progress recently. [QUESTIONS] Will the event 'A human sets foot on Mars. by 2030-01-01 [CURRENT DATE] 2022-8-1 [EXPIRY DATE] 2030-01-01Dec 8, 2020Kamala Harris does not run forA human sets foot on Mars by 2030-01-01 [EVENT OPPOSITE] A human does not foot on Mars. NOT happen by 2030-01-01? [POTENTIAL INHIBITING EVENTS] None [PATH TO NEGATIVE OUTCOME</p>
<p>SpaceX lands a human on Mars after 2030-01-01 OUTCOME NOT ACHIEVED: A human does NOT set foot on Mars by 2030-01-01. PATH TO NEGATIVE OUTCOME</p>
<p>by 2030-01-01 END [EVENT] [condition] by [expiry] [EVENT OPPOSITE]SpaceX decides to cancel the project to land a human on Mars OUTCOME NOT ACHIEVED: A human does NOT set foot on Mars. Here are recent headlines from the New York Times on the topic. summarized NYT headlines] Based on all the information available to you how likely do you think it is that this event has takes place by [expiry]? Give your explanation and probability</p>            </div>
        </div>

    </div>
</body>
</html>