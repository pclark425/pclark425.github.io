<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2244 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2244</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2244</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-61.html">extraction-schema-61</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems, models, or agents that use task-specific, adaptive, or dynamically allocated representations versus uniform representations, including performance comparisons, computational efficiency, and generalization results.</div>
                <p><strong>Paper ID:</strong> paper-281676353</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2509.24495v1.pdf" target="_blank">Neuroplasticity-inspired dynamic ANNs for multi-task demand forecasting</a></p>
                <p><strong>Paper Abstract:</strong> This paper introduces a novel approach to Dynamic Artificial Neural Networks (D-ANNs) for multi-task demand forecasting called Neuroplastic Multi-Task Network (NMT-Net). Unlike conventional methods focusing on inference-time dynamics or computational efficiency, our proposed method enables structural adaptability of the computational graph during training, inspired by neuroplasticity as seen in biological systems. Each new task triggers a dynamic network adaptation, including similarity-based task identification and selective training of candidate ANN heads, which are then assessed and integrated into the model based on their performance. We evaluated our framework using three real-world multi-task demand forecasting datasets from Kaggle. We demonstrated its superior performance and consistency, achieving lower RMSE and standard deviation compared to traditional baselines and state-of-the-art multi-task learning methods. NMT-Net offers a scalable, adaptable solution for multi-task and continual learning in time series prediction. The complete code for NMT-Net is available from our GitHub repository.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2244.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2244.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems, models, or agents that use task-specific, adaptive, or dynamically allocated representations versus uniform representations, including performance comparisons, computational efficiency, and generalization results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NMT-Net</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neuroplastic Multi-Task Network (NMT-Net)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuroplasticity-inspired dynamic artificial neural network that adapts its computational graph during training by creating, evaluating, and selectively integrating task-specific heads based on similarity to previously learned tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>NMT-Net (Dynamic ANN / D-ANN)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Shared backbone MLP with categorical embeddings and sequential MLP blocks; maintains a dictionary of regression heads and dynamically instantiates temporary heads for a new task from either general pretrained weights or a head of the most similar prior task, then selects and retains the better head based on evaluation loss (RMSE). Designed for multi-task / continual time-series regression.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_task_aligned_abstraction</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>abstraction_mechanism</strong></td>
                            <td>Dynamic multi-head architecture: similarity-based task identification + temporary head instantiation (from either general pretrained weights or a similar-task head) + head selection and selective integration (task-specific heads over a shared backbone).</td>
                        </tr>
                        <tr>
                            <td><strong>is_dynamic_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Multi-task demand forecasting (time-series regression) evaluated on three Kaggle datasets: Demand Forecasting (DF), Store Item Demand Forecasting (SIDF subset), Product Demand Forecast (PDF).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_task_aligned</strong></td>
                            <td>Reported in Table 1. Per-dataset D-ANN (ours) results (RMSE, mean (σ); min (σ); max (σ)): DF: mean 16.10 (0.21), min 3.25 (0.40), max 30.33 (1.01). SIDF: mean 6.66 (0.17), min 3.22 (0.21), max 10.09 (0.53). PDF: mean 573.5 (11.97), min 4.52 (0.01), max 1893 (11.07). The paper emphasizes lower mean RMSE and much lower standard deviation compared to baselines and other multi-task methods.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_uniform_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>computational_efficiency_task_aligned</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_efficiency_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_generalization_results</strong></td>
                            <td>Authors claim the method can be used for inference with previously unseen tasks due to data-focused similarity search and pretraining, but such experiments are explicitly stated to be out-of-scope and not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>multi_task_performance</strong></td>
                            <td>Demonstrated improved multi-task performance: NMT-Net achieved the best mean RMSE on DF and SIDF and competitive results on PDF; it also produced substantially lower run-to-run standard deviation (consistency) than baselines and SOTA multi-task methods (see Table 1). The method groups tasks via similarity and re-uses heads, producing an average of ~4 tasks per head in ablation experiments (SIM methods other than RAND).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_constrained_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_finding_summary</strong></td>
                            <td>Dynamic, task-aligned head allocation via similarity and temporary head training reduces mean RMSE and dramatically reduces variance across runs compared to static baselines and other multi-task grouping/clustering methods on demand forecasting tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory</strong></td>
                            <td>supports</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory_explanation</strong></td>
                            <td>The empirical results show that allocating task-specific heads (task-aligned abstractions) and dynamically adapting which heads are used yields better accuracy and much greater consistency than static/uniform baselines and several multi-task algorithms, supporting the Task-Aligned Abstraction Principle.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2244.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2244.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems, models, or agents that use task-specific, adaptive, or dynamically allocated representations versus uniform representations, including performance comparisons, computational efficiency, and generalization results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Task Grouping (TAG)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A task-grouping method for multi-task learning that partitions tasks into groups so that models share parameters within groups rather than uniformly across all tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Efficiently identifying task groupings for multi-task learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>TAG (task grouping)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A deep-learning based task-grouping approach that identifies groups of similar tasks and trains shared models or branches per group to capture group-specific patterns while leveraging shared information across tasks in a group.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_task_aligned_abstraction</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>abstraction_mechanism</strong></td>
                            <td>Task grouping / grouped parameter sharing (tasks are partitioned into groups and parameters are shared within groups rather than uniformly across all tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>is_dynamic_or_adaptive</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Multi-task demand forecasting (DF, SIDF, PDF datasets used in this paper's experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_task_aligned</strong></td>
                            <td>Reported in Table 1. TAG results (RMSE, mean (σ); min (σ); max (σ)): DF: mean 19.12 (3.33), min 8.09 (2.09), max 53.35 (6.39). SIDF: mean 6.64 (1.28), min 3.33 (1.36), max 14.24 (1.42). PDF: mean 858.2 (78.12), min 26.76 (45.47), max 2253 (167.2).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_uniform_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>computational_efficiency_task_aligned</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_efficiency_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_generalization_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>multi_task_performance</strong></td>
                            <td>Per Table 1, TAG produced competitive results (especially on SIDF) but typically worse mean RMSE and higher variability than NMT-Net; shows grouping tasks can help but static grouping here was outperformed by dynamic head allocation.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_constrained_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_finding_summary</strong></td>
                            <td>Static task grouping improves multi-task performance compared to many baselines, but dynamic task-aligned head allocation (NMT-Net) achieves lower average error and much lower variance in these datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory</strong></td>
                            <td>supports</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory_explanation</strong></td>
                            <td>TAG's grouping-based sharing demonstrates that allocating non-uniform, group-specific parameters helps multi-task learning, consistent with the Task-Aligned Abstraction Principle, though dynamic allocation (NMT-Net) gave stronger empirical gains here.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2244.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2244.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems, models, or agents that use task-specific, adaptive, or dynamically allocated representations versus uniform representations, including performance comparisons, computational efficiency, and generalization results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MTL-cluster</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MTL-cluster (Clustered multi-task learning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A clustered multi-task learning method that groups tasks via clustering and learns models per cluster to capture cluster-specific task structure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Clustered multi-task learning: A convex formulation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MTL-cluster</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Approach that clusters tasks and learns shared parameters within clusters, enabling task-specific adaptations at the cluster level rather than using a uniform representation for all tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_task_aligned_abstraction</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>abstraction_mechanism</strong></td>
                            <td>Task clustering with clustered parameter sharing (cluster-level task-aligned representations).</td>
                        </tr>
                        <tr>
                            <td><strong>is_dynamic_or_adaptive</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Multi-task demand forecasting (DF, SIDF, PDF datasets in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_task_aligned</strong></td>
                            <td>Reported in Table 1. MTL-cluster results (RMSE, mean (σ); min (σ); max (σ)): DF: mean 18.48 (3.81), min 8.72 (2.11), max 69.19 (7.92). SIDF: mean 11.51 (2.92), min 6.48 (2.17), max 15.50 (2.66). PDF: mean 1653 (431.9), min 7.78 (3.34), max 1992 (24.27).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_uniform_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>computational_efficiency_task_aligned</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_efficiency_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_generalization_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>multi_task_performance</strong></td>
                            <td>Clustered multi-task learning improved over some shallow multi-task baselines but was generally outperformed by NMT-Net in mean RMSE and consistency on DF and SIDF datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_constrained_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_finding_summary</strong></td>
                            <td>Task clustering provides task-aligned parameter sharing that helps multi-task learning, but dynamic, per-task head allocation (NMT-Net) yielded better accuracy and much lower variance in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory</strong></td>
                            <td>supports</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory_explanation</strong></td>
                            <td>Clustering tasks into groups and learning per-cluster parameters demonstrates benefits of non-uniform representations, consistent with the Task-Aligned Abstraction Principle; however, static clustering was less effective than dynamic allocation in the reported results.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2244.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2244.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems, models, or agents that use task-specific, adaptive, or dynamically allocated representations versus uniform representations, including performance comparisons, computational efficiency, and generalization results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MTL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-Level Lasso (MTL; sparse multi-task regression)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A shallow multi-task regression method using structured sparsity (multi-level lasso) to learn shared relevant features across tasks instead of uniform representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Multi-level lasso for sparse multi-task regression</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Multi-Level Lasso (MTL)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Sparsity-regularized multi-task regression that enforces shared, sparse feature selection across tasks (structured regularization to obtain shared, task-aligned features).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_task_aligned_abstraction</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>abstraction_mechanism</strong></td>
                            <td>Structured sparsity (joint feature selection) to create task-aligned representations.</td>
                        </tr>
                        <tr>
                            <td><strong>is_dynamic_or_adaptive</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Multi-task regression for demand forecasting (DF, SIDF, PDF datasets used in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_task_aligned</strong></td>
                            <td>Reported in Table 1. MTL results (RMSE, mean (σ)): DF: mean 61.68 (4.03). SIDF: mean 33.45 (1.94). PDF: mean 3833 (609.3).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_uniform_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>computational_efficiency_task_aligned</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_efficiency_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_generalization_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>multi_task_performance</strong></td>
                            <td>In these experiments, the structured sparse multi-task regression performed worse than many other methods (including dynamic NMT-Net), indicating dataset- and method-specific limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_constrained_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_finding_summary</strong></td>
                            <td>Structured sparse multi-task regression (MTL) did not match the accuracy or consistency of the dynamic, task-aligned head allocation approach in these datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory_explanation</strong></td>
                            <td>While MTL embodies task-aligned representations via sparse shared features, its poorer empirical performance here suggests that not all task-aligned mechanisms are equally effective; thus evidence is mixed.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2244.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2244.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems, models, or agents that use task-specific, adaptive, or dynamically allocated representations versus uniform representations, including performance comparisons, computational efficiency, and generalization results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MTWR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-task Wasserstein Regularized Regression (MTWR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A shallow multi-task regression method that uses Wasserstein regularization to encourage structured sharing across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Wasserstein regularization for sparse multi-task regression</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MTWR</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Multi-task regression with Wasserstein-based regularization to control and encourage useful sharing between tasks instead of uniform parameter sharing.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_task_aligned_abstraction</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>abstraction_mechanism</strong></td>
                            <td>Regularization-based shared feature learning (Wasserstein regularization) for structured task-aligned representations.</td>
                        </tr>
                        <tr>
                            <td><strong>is_dynamic_or_adaptive</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Multi-task regression / demand forecasting (DF, SIDF, PDF in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_task_aligned</strong></td>
                            <td>Reported in Table 1. MTWR results (RMSE, mean (σ)): DF: mean 45.58 (7.07). SIDF: mean 12.17 (5.26). PDF: mean 3383 (294.1).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_uniform_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>computational_efficiency_task_aligned</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_efficiency_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_generalization_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>multi_task_performance</strong></td>
                            <td>MTWR showed variable performance across datasets and was outperformed by NMT-Net on DF and SIDF in mean RMSE.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_constrained_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_finding_summary</strong></td>
                            <td>Regularization-based multi-task sharing can help, but here was weaker than dynamic head allocation for these forecasting tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory_explanation</strong></td>
                            <td>MTWR embodies non-uniform sharing via regularization, supporting the principle in concept, but performance here was dataset-dependent and weaker than dynamic allocation methods.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2244.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2244.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems, models, or agents that use task-specific, adaptive, or dynamically allocated representations versus uniform representations, including performance comparisons, computational efficiency, and generalization results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dynamic inference graph methods</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sample/Temporal/Spatial-wise Dynamic Inference Graph Methods (early exiting, layer skipping, dynamic parameters)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of methods that adapt the inference computation graph per input (e.g., early exiting, layer skipping, dynamic parameters) primarily to reduce computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Dynamic inference graph methods (early exiting, layer skipping, dynamic parameters)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Techniques that adapt the inference-time computational graph on a per-sample basis to reduce redundant computation; discussed in related work as commonly used approaches for D-ANNs focused on efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_task_aligned_abstraction</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>abstraction_mechanism</strong></td>
                            <td>Adaptive inference graph (early exit, layer skipping, dynamic parameters) that allocates compute non-uniformly across inputs (sample/adaptive-level).</td>
                        </tr>
                        <tr>
                            <td><strong>is_dynamic_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Computer vision and text processing examples mentioned in related work (general-purpose).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_task_aligned</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_uniform_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_efficiency_task_aligned</strong></td>
                            <td>Discussed qualitatively as methods primarily aimed at reducing computational cost; no FLOPs/inference time reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_efficiency_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_generalization_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>multi_task_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>resource_constrained_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_finding_summary</strong></td>
                            <td>Mentioned as prevailing dynamic NN approaches focused on inference-time adaptation and computational efficiency rather than multi-task performance improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory</strong></td>
                            <td>supports</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory_explanation</strong></td>
                            <td>These adaptive inference techniques show that non-uniform resource allocation can be beneficial (primarily for efficiency), aligning with the idea that uniform representations are not always optimal.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2244.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2244.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems, models, or agents that use task-specific, adaptive, or dynamically allocated representations versus uniform representations, including performance comparisons, computational efficiency, and generalization results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DyNet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DyNet (dynamic neural network toolkit)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework for dynamic declaration and implementation of neural networks that enables runtime changes to computational graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dynet: The dynamic neural network toolkit</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DyNet (framework)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A neural network toolkit designed for dynamic declaration and execution of computational graphs (graph can be changed per example or during runtime), cited as prior art for dynamic graph capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_task_aligned_abstraction</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>abstraction_mechanism</strong></td>
                            <td>Framework-level dynamic computational graph declaration (enables dynamic networks but does not prescribe a task-alignment method).</td>
                        </tr>
                        <tr>
                            <td><strong>is_dynamic_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General neural network research and applications; mentioned in context of dynamic graph declaration.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_task_aligned</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_uniform_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_efficiency_task_aligned</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_efficiency_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_generalization_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>multi_task_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>resource_constrained_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_finding_summary</strong></td>
                            <td>Referenced as an example of prior tooling that enables dynamic computational graphs; authors note prior work used such frameworks mostly for efficiency purposes rather than to improve multi-task performance as they propose.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory</strong></td>
                            <td>neutral</td>
                        </tr>
                        <tr>
                            <td><strong>supports_or_challenges_theory_explanation</strong></td>
                            <td>DyNet enables dynamic graphs but the paper treats it as tooling rather than evidence for task-aligned abstractions improving multi-task generalization.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Efficiently identifying task groupings for multi-task learning <em>(Rating: 2)</em></li>
                <li>Dynet: The dynamic neural network toolkit <em>(Rating: 2)</em></li>
                <li>Dynamic neural networks: A survey <em>(Rating: 2)</em></li>
                <li>Clustered multi-task learning: A convex formulation <em>(Rating: 2)</em></li>
                <li>Wasserstein regularization for sparse multi-task regression <em>(Rating: 1)</em></li>
                <li>Multi-level lasso for sparse multi-task regression <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2244",
    "paper_id": "paper-281676353",
    "extraction_schema_id": "extraction-schema-61",
    "extracted_data": [
        {
            "name_short": "NMT-Net",
            "name_full": "Neuroplastic Multi-Task Network (NMT-Net)",
            "brief_description": "A neuroplasticity-inspired dynamic artificial neural network that adapts its computational graph during training by creating, evaluating, and selectively integrating task-specific heads based on similarity to previously learned tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "NMT-Net (Dynamic ANN / D-ANN)",
            "model_description": "Shared backbone MLP with categorical embeddings and sequential MLP blocks; maintains a dictionary of regression heads and dynamically instantiates temporary heads for a new task from either general pretrained weights or a head of the most similar prior task, then selects and retains the better head based on evaluation loss (RMSE). Designed for multi-task / continual time-series regression.",
            "model_size": null,
            "uses_task_aligned_abstraction": true,
            "abstraction_mechanism": "Dynamic multi-head architecture: similarity-based task identification + temporary head instantiation (from either general pretrained weights or a similar-task head) + head selection and selective integration (task-specific heads over a shared backbone).",
            "is_dynamic_or_adaptive": true,
            "task_domain": "Multi-task demand forecasting (time-series regression) evaluated on three Kaggle datasets: Demand Forecasting (DF), Store Item Demand Forecasting (SIDF subset), Product Demand Forecast (PDF).",
            "performance_task_aligned": "Reported in Table 1. Per-dataset D-ANN (ours) results (RMSE, mean (σ); min (σ); max (σ)): DF: mean 16.10 (0.21), min 3.25 (0.40), max 30.33 (1.01). SIDF: mean 6.66 (0.17), min 3.22 (0.21), max 10.09 (0.53). PDF: mean 573.5 (11.97), min 4.52 (0.01), max 1893 (11.07). The paper emphasizes lower mean RMSE and much lower standard deviation compared to baselines and other multi-task methods.",
            "performance_uniform_baseline": null,
            "has_direct_comparison": true,
            "computational_efficiency_task_aligned": null,
            "computational_efficiency_baseline": null,
            "sample_efficiency_results": null,
            "transfer_generalization_results": "Authors claim the method can be used for inference with previously unseen tasks due to data-focused similarity search and pretraining, but such experiments are explicitly stated to be out-of-scope and not reported.",
            "interpretability_results": null,
            "multi_task_performance": "Demonstrated improved multi-task performance: NMT-Net achieved the best mean RMSE on DF and SIDF and competitive results on PDF; it also produced substantially lower run-to-run standard deviation (consistency) than baselines and SOTA multi-task methods (see Table 1). The method groups tasks via similarity and re-uses heads, producing an average of ~4 tasks per head in ablation experiments (SIM methods other than RAND).",
            "resource_constrained_results": null,
            "key_finding_summary": "Dynamic, task-aligned head allocation via similarity and temporary head training reduces mean RMSE and dramatically reduces variance across runs compared to static baselines and other multi-task grouping/clustering methods on demand forecasting tasks.",
            "supports_or_challenges_theory": "supports",
            "supports_or_challenges_theory_explanation": "The empirical results show that allocating task-specific heads (task-aligned abstractions) and dynamically adapting which heads are used yields better accuracy and much greater consistency than static/uniform baselines and several multi-task algorithms, supporting the Task-Aligned Abstraction Principle.",
            "uuid": "e2244.0"
        },
        {
            "name_short": "TAG",
            "name_full": "Task Grouping (TAG)",
            "brief_description": "A task-grouping method for multi-task learning that partitions tasks into groups so that models share parameters within groups rather than uniformly across all tasks.",
            "citation_title": "Efficiently identifying task groupings for multi-task learning",
            "mention_or_use": "use",
            "model_name": "TAG (task grouping)",
            "model_description": "A deep-learning based task-grouping approach that identifies groups of similar tasks and trains shared models or branches per group to capture group-specific patterns while leveraging shared information across tasks in a group.",
            "model_size": null,
            "uses_task_aligned_abstraction": true,
            "abstraction_mechanism": "Task grouping / grouped parameter sharing (tasks are partitioned into groups and parameters are shared within groups rather than uniformly across all tasks).",
            "is_dynamic_or_adaptive": false,
            "task_domain": "Multi-task demand forecasting (DF, SIDF, PDF datasets used in this paper's experiments).",
            "performance_task_aligned": "Reported in Table 1. TAG results (RMSE, mean (σ); min (σ); max (σ)): DF: mean 19.12 (3.33), min 8.09 (2.09), max 53.35 (6.39). SIDF: mean 6.64 (1.28), min 3.33 (1.36), max 14.24 (1.42). PDF: mean 858.2 (78.12), min 26.76 (45.47), max 2253 (167.2).",
            "performance_uniform_baseline": null,
            "has_direct_comparison": true,
            "computational_efficiency_task_aligned": null,
            "computational_efficiency_baseline": null,
            "sample_efficiency_results": null,
            "transfer_generalization_results": null,
            "interpretability_results": null,
            "multi_task_performance": "Per Table 1, TAG produced competitive results (especially on SIDF) but typically worse mean RMSE and higher variability than NMT-Net; shows grouping tasks can help but static grouping here was outperformed by dynamic head allocation.",
            "resource_constrained_results": null,
            "key_finding_summary": "Static task grouping improves multi-task performance compared to many baselines, but dynamic task-aligned head allocation (NMT-Net) achieves lower average error and much lower variance in these datasets.",
            "supports_or_challenges_theory": "supports",
            "supports_or_challenges_theory_explanation": "TAG's grouping-based sharing demonstrates that allocating non-uniform, group-specific parameters helps multi-task learning, consistent with the Task-Aligned Abstraction Principle, though dynamic allocation (NMT-Net) gave stronger empirical gains here.",
            "uuid": "e2244.1"
        },
        {
            "name_short": "MTL-cluster",
            "name_full": "MTL-cluster (Clustered multi-task learning)",
            "brief_description": "A clustered multi-task learning method that groups tasks via clustering and learns models per cluster to capture cluster-specific task structure.",
            "citation_title": "Clustered multi-task learning: A convex formulation",
            "mention_or_use": "use",
            "model_name": "MTL-cluster",
            "model_description": "Approach that clusters tasks and learns shared parameters within clusters, enabling task-specific adaptations at the cluster level rather than using a uniform representation for all tasks.",
            "model_size": null,
            "uses_task_aligned_abstraction": true,
            "abstraction_mechanism": "Task clustering with clustered parameter sharing (cluster-level task-aligned representations).",
            "is_dynamic_or_adaptive": false,
            "task_domain": "Multi-task demand forecasting (DF, SIDF, PDF datasets in this paper).",
            "performance_task_aligned": "Reported in Table 1. MTL-cluster results (RMSE, mean (σ); min (σ); max (σ)): DF: mean 18.48 (3.81), min 8.72 (2.11), max 69.19 (7.92). SIDF: mean 11.51 (2.92), min 6.48 (2.17), max 15.50 (2.66). PDF: mean 1653 (431.9), min 7.78 (3.34), max 1992 (24.27).",
            "performance_uniform_baseline": null,
            "has_direct_comparison": true,
            "computational_efficiency_task_aligned": null,
            "computational_efficiency_baseline": null,
            "sample_efficiency_results": null,
            "transfer_generalization_results": null,
            "interpretability_results": null,
            "multi_task_performance": "Clustered multi-task learning improved over some shallow multi-task baselines but was generally outperformed by NMT-Net in mean RMSE and consistency on DF and SIDF datasets.",
            "resource_constrained_results": null,
            "key_finding_summary": "Task clustering provides task-aligned parameter sharing that helps multi-task learning, but dynamic, per-task head allocation (NMT-Net) yielded better accuracy and much lower variance in these experiments.",
            "supports_or_challenges_theory": "supports",
            "supports_or_challenges_theory_explanation": "Clustering tasks into groups and learning per-cluster parameters demonstrates benefits of non-uniform representations, consistent with the Task-Aligned Abstraction Principle; however, static clustering was less effective than dynamic allocation in the reported results.",
            "uuid": "e2244.2"
        },
        {
            "name_short": "MTL",
            "name_full": "Multi-Level Lasso (MTL; sparse multi-task regression)",
            "brief_description": "A shallow multi-task regression method using structured sparsity (multi-level lasso) to learn shared relevant features across tasks instead of uniform representations.",
            "citation_title": "Multi-level lasso for sparse multi-task regression",
            "mention_or_use": "use",
            "model_name": "Multi-Level Lasso (MTL)",
            "model_description": "Sparsity-regularized multi-task regression that enforces shared, sparse feature selection across tasks (structured regularization to obtain shared, task-aligned features).",
            "model_size": null,
            "uses_task_aligned_abstraction": true,
            "abstraction_mechanism": "Structured sparsity (joint feature selection) to create task-aligned representations.",
            "is_dynamic_or_adaptive": false,
            "task_domain": "Multi-task regression for demand forecasting (DF, SIDF, PDF datasets used in this paper).",
            "performance_task_aligned": "Reported in Table 1. MTL results (RMSE, mean (σ)): DF: mean 61.68 (4.03). SIDF: mean 33.45 (1.94). PDF: mean 3833 (609.3).",
            "performance_uniform_baseline": null,
            "has_direct_comparison": true,
            "computational_efficiency_task_aligned": null,
            "computational_efficiency_baseline": null,
            "sample_efficiency_results": null,
            "transfer_generalization_results": null,
            "interpretability_results": null,
            "multi_task_performance": "In these experiments, the structured sparse multi-task regression performed worse than many other methods (including dynamic NMT-Net), indicating dataset- and method-specific limitations.",
            "resource_constrained_results": null,
            "key_finding_summary": "Structured sparse multi-task regression (MTL) did not match the accuracy or consistency of the dynamic, task-aligned head allocation approach in these datasets.",
            "supports_or_challenges_theory": "mixed",
            "supports_or_challenges_theory_explanation": "While MTL embodies task-aligned representations via sparse shared features, its poorer empirical performance here suggests that not all task-aligned mechanisms are equally effective; thus evidence is mixed.",
            "uuid": "e2244.3"
        },
        {
            "name_short": "MTWR",
            "name_full": "Multi-task Wasserstein Regularized Regression (MTWR)",
            "brief_description": "A shallow multi-task regression method that uses Wasserstein regularization to encourage structured sharing across tasks.",
            "citation_title": "Wasserstein regularization for sparse multi-task regression",
            "mention_or_use": "use",
            "model_name": "MTWR",
            "model_description": "Multi-task regression with Wasserstein-based regularization to control and encourage useful sharing between tasks instead of uniform parameter sharing.",
            "model_size": null,
            "uses_task_aligned_abstraction": true,
            "abstraction_mechanism": "Regularization-based shared feature learning (Wasserstein regularization) for structured task-aligned representations.",
            "is_dynamic_or_adaptive": false,
            "task_domain": "Multi-task regression / demand forecasting (DF, SIDF, PDF in this paper).",
            "performance_task_aligned": "Reported in Table 1. MTWR results (RMSE, mean (σ)): DF: mean 45.58 (7.07). SIDF: mean 12.17 (5.26). PDF: mean 3383 (294.1).",
            "performance_uniform_baseline": null,
            "has_direct_comparison": true,
            "computational_efficiency_task_aligned": null,
            "computational_efficiency_baseline": null,
            "sample_efficiency_results": null,
            "transfer_generalization_results": null,
            "interpretability_results": null,
            "multi_task_performance": "MTWR showed variable performance across datasets and was outperformed by NMT-Net on DF and SIDF in mean RMSE.",
            "resource_constrained_results": null,
            "key_finding_summary": "Regularization-based multi-task sharing can help, but here was weaker than dynamic head allocation for these forecasting tasks.",
            "supports_or_challenges_theory": "mixed",
            "supports_or_challenges_theory_explanation": "MTWR embodies non-uniform sharing via regularization, supporting the principle in concept, but performance here was dataset-dependent and weaker than dynamic allocation methods.",
            "uuid": "e2244.4"
        },
        {
            "name_short": "Dynamic inference graph methods",
            "name_full": "Sample/Temporal/Spatial-wise Dynamic Inference Graph Methods (early exiting, layer skipping, dynamic parameters)",
            "brief_description": "A class of methods that adapt the inference computation graph per input (e.g., early exiting, layer skipping, dynamic parameters) primarily to reduce computational cost.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "Dynamic inference graph methods (early exiting, layer skipping, dynamic parameters)",
            "model_description": "Techniques that adapt the inference-time computational graph on a per-sample basis to reduce redundant computation; discussed in related work as commonly used approaches for D-ANNs focused on efficiency.",
            "model_size": null,
            "uses_task_aligned_abstraction": true,
            "abstraction_mechanism": "Adaptive inference graph (early exit, layer skipping, dynamic parameters) that allocates compute non-uniformly across inputs (sample/adaptive-level).",
            "is_dynamic_or_adaptive": true,
            "task_domain": "Computer vision and text processing examples mentioned in related work (general-purpose).",
            "performance_task_aligned": null,
            "performance_uniform_baseline": null,
            "has_direct_comparison": null,
            "computational_efficiency_task_aligned": "Discussed qualitatively as methods primarily aimed at reducing computational cost; no FLOPs/inference time reported in this paper.",
            "computational_efficiency_baseline": null,
            "sample_efficiency_results": null,
            "transfer_generalization_results": null,
            "interpretability_results": null,
            "multi_task_performance": null,
            "resource_constrained_results": null,
            "key_finding_summary": "Mentioned as prevailing dynamic NN approaches focused on inference-time adaptation and computational efficiency rather than multi-task performance improvements.",
            "supports_or_challenges_theory": "supports",
            "supports_or_challenges_theory_explanation": "These adaptive inference techniques show that non-uniform resource allocation can be beneficial (primarily for efficiency), aligning with the idea that uniform representations are not always optimal.",
            "uuid": "e2244.5"
        },
        {
            "name_short": "DyNet",
            "name_full": "DyNet (dynamic neural network toolkit)",
            "brief_description": "A framework for dynamic declaration and implementation of neural networks that enables runtime changes to computational graphs.",
            "citation_title": "Dynet: The dynamic neural network toolkit",
            "mention_or_use": "mention",
            "model_name": "DyNet (framework)",
            "model_description": "A neural network toolkit designed for dynamic declaration and execution of computational graphs (graph can be changed per example or during runtime), cited as prior art for dynamic graph capabilities.",
            "model_size": null,
            "uses_task_aligned_abstraction": null,
            "abstraction_mechanism": "Framework-level dynamic computational graph declaration (enables dynamic networks but does not prescribe a task-alignment method).",
            "is_dynamic_or_adaptive": true,
            "task_domain": "General neural network research and applications; mentioned in context of dynamic graph declaration.",
            "performance_task_aligned": null,
            "performance_uniform_baseline": null,
            "has_direct_comparison": null,
            "computational_efficiency_task_aligned": null,
            "computational_efficiency_baseline": null,
            "sample_efficiency_results": null,
            "transfer_generalization_results": null,
            "interpretability_results": null,
            "multi_task_performance": null,
            "resource_constrained_results": null,
            "key_finding_summary": "Referenced as an example of prior tooling that enables dynamic computational graphs; authors note prior work used such frameworks mostly for efficiency purposes rather than to improve multi-task performance as they propose.",
            "supports_or_challenges_theory": "neutral",
            "supports_or_challenges_theory_explanation": "DyNet enables dynamic graphs but the paper treats it as tooling rather than evidence for task-aligned abstractions improving multi-task generalization.",
            "uuid": "e2244.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Efficiently identifying task groupings for multi-task learning",
            "rating": 2
        },
        {
            "paper_title": "Dynet: The dynamic neural network toolkit",
            "rating": 2
        },
        {
            "paper_title": "Dynamic neural networks: A survey",
            "rating": 2
        },
        {
            "paper_title": "Clustered multi-task learning: A convex formulation",
            "rating": 2
        },
        {
            "paper_title": "Wasserstein regularization for sparse multi-task regression",
            "rating": 1
        },
        {
            "paper_title": "Multi-level lasso for sparse multi-task regression",
            "rating": 1
        }
    ],
    "cost": 0.020361249999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>NEUROPLASTICITY-INSPIRED DYNAMIC ANNS FOR MULTI-TASK DEMAND FORECASTING
September 30, 2025</p>
<p>Mateusz Żarski mzarski@iitis.pl 
Institute of Theoretical and Applied Informatics Polish Academy of Sciences Gliwice
Bałtycka 544-100Poland</p>
<p>Sławomir Nowaczyk slawomir.nowaczyk@hh.se 
School of Information Technology
Halmstad University Kristian IV:s väg 3
301 18HalmstadSweden</p>
<p>NEUROPLASTICITY-INSPIRED DYNAMIC ANNS FOR MULTI-TASK DEMAND FORECASTING
September 30, 20259F16315518A47E5D84B0EAE3546D6521arXiv:2509.24495v1[cs.AI]Dynamic Neural NetworksMulti task learningDemand forecastingNeuroplasticity
This paper introduces a novel approach to Dynamic Artificial Neural Networks (D-ANNs) for multitask demand forecasting called Neuroplastic Multi-Task Network (NMT-Net).Unlike conventional methods focusing on inference-time dynamics or computational efficiency, our proposed method enables structural adaptability of the computational graph during training, inspired by neuroplasticity as seen in biological systems.Each new task triggers a dynamic network adaptation, including similarity-based task identification and selective training of candidate ANN heads, which are then assessed and integrated into the model based on their performance.We evaluated our framework using three real-world multi-task demand forecasting datasets from Kaggle.We demonstrated its superior performance and consistency, achieving lower RMSE and standard deviation compared to traditional baselines and state-of-the-art multi-task learning methods.NMT-Net offers a scalable, adaptable solution for multi-task and continual learning in time series prediction.The complete code for NMT-Net is available from our GitHub repository[50].</p>
<p>Introduction</p>
<p>Although Dynamic Artificial Neural Networks (D-ANNs) are not an entirely new concept in the field of Artificial Intelligence (AI) [38], they have struggled to gain traction and become a cornerstone of the Deep Learning paradigm.Nevertheless, this promising branch of AI seems capable of redefining the field of neural algorithms in their scalability and multi-tasking capabilities [18].Somewhat surprisingly, recently defined dynamics of neural networks are usually limited to Sample-, Temporal-, or Spatial-wise Dynamics, where the networks' model itself is static, and dynamic behavior is provided with a dynamic inference graph [17] or adaptive features and layers used [14].Moreover, currently the primary focus of dynamic neural network development lies in reducing computational costs [1] rather than improving Artificial Neural Networks (ANNs) performance in a multi-task setup.This work proposes a novel approach to dynamic neural networks: Neuroplastic Multi-Task Network (NMT-Net).Our neural network model is dynamic with respect to the computational graph (and not the inference graph) in a multi-task, regression setup, resembling the phenomena of brain plasticity during task learning.With each new task, a neural network trained with our approach can update its computational graph by adding a new head to the graph to maximize its performance and simultaneously update the loss function according to this task.</p>
<p>We motivate our approach with a demand forecasting scenario.Predicting product demand across multiple product categories and sales locations inherently results in a high-dimensional forecasting problem.This rapidly becomes challenging if all data are merged into a single predictive model, neglecting crucial heterogeneity.The result is model underperformance due to conflicting signals and variance across diverse demand profiles, as each product-location combination may exhibit unique temporal patterns, distribution characteristics, and demand dynamics influenced by local factors.In contrast, naively treating each of these combinations as isolated tasks quickly becomes computationally infeasible while also ignoring valuable shared information, such as underlying demand drivers, market trends, or seasonal effects that manifest similarly across subsets of tasks.</p>
<p>A multi-task learning approach naturally addresses this tension by explicitly modeling shared structures through joint learning while still accommodating task-specific variations via dedicated parameters or adaptive mechanisms.Our work focuses on systematically leveraging shared latent representations to capture common predictive patterns while simultaneously preserving the ability to handle task-specific idiosyncrasies.However, finding the right balance between commonality and specificity is challenging, and D-ANNs appear to be the perfect tool for doing just that.We demonstrate robust performance improvements from NMT-Net in three regression problems using Kaggle public demand forecasting datasets.</p>
<p>The rest of the paper is organized as follows.Section 2 describes existing research and approaches related to D-ANNs.Section 3 provides a detailed description of our proposed NMT-Net method.Next, Sections 4 and 5 describe the experimental setup used to validate our approach and the results of the experiments that compare NMT-Net with baselines and state-of-the-art, respectively.Finally, in Section 6, we present our final remarks and discuss possible future research directions.</p>
<p>Related work</p>
<p>There are three main topics present in the research literature that are relevant for the NMT-Net method: Dynamic Neural Networks, Multi-task learning, and the task of Demand forecasting.</p>
<p>Dynamic Neural Networks</p>
<p>As mentioned in Section 1, the currently developed methods of implementing D-ANNs focus on Sample-, Temporal-, or Spatial-wise Network Dynamics.All these approaches remain similar due to the way the dynamics are implemented in the neural network model -based on dynamic inference graphs [17].These methods are used primarily to reduce the computational cost of neural networks using techniques such as early exiting, layer skipping, and dynamic parameters [42] etc., with the primary objective of reducing computational redundancy.They are used in tasks such as computer vision or text processing, where computational redundancy can play a significant role in the overall computational costs.</p>
<p>Other approaches to D-ANNs include the use of Tapped-Delay Neural Network (TDNN) and Nonlinear autoregressive with exogenous inputs Network (NARX) [11,3].In this setup, the NN model implements network dynamics by introducing time series delays of the input or adding additional feedback connections, similar to the Recurrent Neural Network (RNN) architecture.This approach was successfully implemented in time series analysis [2] and is closely related to the issue of demand forecasting.</p>
<p>Another approach to the problem of dynamic neural networks is to define computational and inference graphs during the network's training and implementation.DyNet [31] authors proposed a framework for dynamic declaration and implementation of NN models, as opposed to a two-step declaration and execution present in other Deep Learning frameworks (e.g., TensorFlow).However, with this approach, the goal was again to reduce the computational complexity of the neural network.Other approaches to improve the performance of the ANN architecture involve using neural architecture search (NAS) [29].These methods are used to automate the selection of a neural network architecture to best match the task it should perform -e.g., in computer vision [36].In this field, frameworks have also been developed to apply NAS algorithms effectively [22].</p>
<p>Multi-task learning</p>
<p>Multi-task learning aims to improve the performance and generalization of models and algorithms by simultaneously performing multiple tasks.Since its conception, it has been used for time-series prediction, multi-representation classification, sequential transfer [4,5], etc.In previous applications of multi-task learning, various methods of designing or training ANNs were used, including hierarchical and tree-structured models [47], task routing [9], and feature sharing [34], as well as other approaches like task relation or task decomposition [48].</p>
<p>Other multi-task learning methods that emerged recently include selective ANN branch sharing [16], knowledge distillation [28], and adaptive model merging without relying on the initial training data [43].One of the most explored algorithm groups in multi-task learning is the grouping and clustering of tasks in the training dataset.Within this set of algorithms, methods for efficient task identification [13,39], learning the task overlap [27], and task clustering [19,45] can be distinguished.Closely related to this group are also research papers considering dynamic task prioritization [15] and multi-objective optimization [37].</p>
<p>Similarly to D-ANNs, there are also specific programming frameworks for multi-task problems, like MALSAR [49].It is developed for the MATLAB programming language and provides the user with a set of algorithms and regularization methods for multi-task problems.</p>
<p>Demand forecasting</p>
<p>Demand forecasting is a practical task that focuses on production, distribution, and ordering strategies as well as planning.Traditional methods such as Autoregressive Integrated Moving Average (ARIMA) [12] and shallow learning models like Support Vector Machines [44] have been widely used for time series forecasting and remain in practical use to this day.However, these techniques often struggle to capture complex, nonlinear patterns in data, especially in multi-task setups.</p>
<p>Newer developments focus on the use of deep learning by leveraging ANN architectures that can model temporal dynamics within the time-series data, such as Long Short-Term Memory (LSTM) [6] and Gated Recurrent Unit (GRU) [40] models.Their popularity in this task is due to their ability to retain information over long sequences and manage temporal dependencies [20], with the use of transformer models increasing for the same reason [46].</p>
<p>Several studies have also explored hybrid approaches that combine ANNs with other machine learning techniques or numerical methods.For instance, models integrating Multi-Layer Perceptrons (MLPs) with autoregressive components have been investigated [8], alongside hybrid models such as MLP-Fourier [32] and MLP-SVM [26].Another notable direction in this research area involves incorporating trainable categorical embeddings within MLP architectures.These are particularly effective in scenarios involving highly differentiated products or when enhanced product categorization is required [10].</p>
<p>Summary and research gap</p>
<p>The topic of Dynamic Artificial Neural Networks has been explored from various perspectives, with most research primarily focusing on reducing computational complexity and improving the efficiency of time-series data processing.However, to the best of our knowledge, there are currently no effective methods for training ANNs with a dynamic computational graph.In the current work, we address this gap by proposing a novel approach tailored to a multi-task learning setup for demand forecasting.This enables dynamic adaptation of the ANN model's computational graph and dynamic task grouping as additional tasks are received during operation.With NMT-Net, we aim to expand the field of truly dynamic ANN models, inspired by brain plasticity phenomena in human and animal learning.</p>
<p>Method</p>
<p>This work proposes NMT-Net, a novel approach to Dynamic Artificial Neural Networks training in a multi-task setup, inspired by the mechanisms of neuroplasticity observed in the learning process of biological organisms [35,7].Similarly to biological mechanisms, our approach assumes the following way a neural network learns new skills (tasks) [41,25]:</p>
<ol>
<li>General neural structures are used for initial training on an unknown task 2. New, specialized neural structures are temporarily created during learning to achieve high performance in the given task 3. Acquired knowledge is transferred to another neural structure, either one responsible for similar previously learned tasks, or a unique structure fully responsible for the new task 4. The temporary neural structure used during task-specific learning is released and available for re-use in the future</li>
</ol>
<p>To replicate this biological phenomenon as closely as practically possible, our NMT-Net method uses three key mechanisms during the training of consecutive tasks:</p>
<p>• Similar task identification • Temporary head training • Head performance assessment and selection</p>
<p>Preliminaries and notations</p>
<p>Datasets used in this study contain multiple regression tasks in the form of time series regarding the issue of demand forecasting.For each task, the dataset comprises a sequence of timesteps consisting of univariate vectors of categorical (product and vendor IDs) and continuous variables (e.g., the demand in a given period).We divided our dataset into three subsets, while preserving the order of the datapoints:</p>
<p>• X pre -for initial pre-training phase of the model (obtaining initial model weights Θ 0 )</p>
<p>• X post -for multi-learning phase</p>
<p>• X eval -for model evaluation We used the ratio of 0.4 : 0.4 : 0.2.In cases where the pre-training phase was not applicable, we used combined data X train = X pre ∪ X post for model training.</p>
<p>Similar task identification</p>
<p>In our setup, any given task consists of multiple training datapoints (sliding windows), each of a fixed t number of time steps (lag).Task similarity identification is performed pairwise, between n datapoints of feature vectors of a new, upcoming task
X new = {x (t) 1 , x (t) 2 , . . . , x(t)
n } and a set of all tasks previously learned by the model X old = {X 1 , X 2 , . . ., X m }.As the number of datapoints can be unequal across the tasks, for the similarity comparison, we use an average update to compute the average feature vector X (t) for the whole set of datapoints for each task.</p>
<p>After obtaining average feature vector representations for the new task X m+1 , we use Root Mean Squared Error (RM SE) to compute a set of its pairwise task similarities against all average feature vector representations of the previously learned tasks X 1 , . . ., X m .Thus, the already trained task X sim most closely related to the incoming task X new is defined as:
X sim = arg min {RM SE(X new , X 1 ), RM SE(X new , X 2 ), ..., RM SE(X new , X m )}(1)</p>
<p>Temporary head training</p>
<p>Given the new task X new , and having selected the most similar, previously trained task X sim , we then train two new temporary ANN heads -one starting from an initial, general set of weights learned in the pre-training phase Θ 0 , and the second starting from the head trained using X sim data, Θ sim .The datasets used for the subsequent training of these two heads are as follows:
• Θ 0 is trained solely on X new data • Θ sim is trained on updated set of data: X updated = X sim ∪ X new
This phase aims to obtain the highest possible performing ANN head regarding the task at hand, X new .However, if an existing head is to be used, its existing knowledge must be preserved to avoid catastrophic forgetting.</p>
<p>In other words, NMT-Net heads are designed to be re-used and perform multiple tasks as long as doing so is beneficial to the overall performance of the model.Thus, the number of tasks the ANN model knows is typically much higher than the number of ANN heads.The dynamic aspect of temporal head training allows the model to optimize its performance in the scope of a multi-task or continual learning setup.</p>
<p>Head performance assessment</p>
<p>Given two temporary heads trained in the previous step, we assess their performance on the evaluation dataset for the new task X new_eval .With the regression objective, we use the training loss function L as an evaluation criterion (2) for both heads and select the better-performing one as the new ANN head for the X new task:
Θ new = Θ 0 , if L(Θ 0 (X new_eval )) &lt; L(Θ sim (X new_eval )) Θ sim , otherwise.(2)
Subsequently, the better-performing head is saved, and the lower-scoring one is removed, thus releasing it from memory.Lastly, after adding the new task to the known task set, the model can be further updated with additional tasks in a multi-task or continual learning setup.</p>
<p>For clarity, the complete process of dynamic task addition to the NMT-Net model during its training cycle is depicted in Figure 1 and formally defined in Algorithm 1.</p>
<p>Note that, unlike most contemporary approaches, NMT-Net does not use any hyperparameters to manage the training.This means that, apart from providing custom dataloaders and ANN architectures, our method is expected to work outof-the-box for any further experiments.Furthermore, due to data-focused similarity search and extensive pre-training, our method can also be used for inference with previously unseen tasks; however, such experiments are out of scope for the current work.We used three datasets related to the demand forecasting task for our experimental setup, which are publicly available at Kaggle.We used Demand Forecasting (DF) [33] dataset containing weekly sales from a three-year period, with multiple vendors and products, consisting of a total of 1155 tasks.The second dataset was a representative 10% of the vast Store Item Demand Forecasting Challenge (SIDF) [24] dataset, containing a total of 500 valid tasks based on vendor and product ID.Our last dataset was the Product Demand Forecast (PDF) [23] dataset, which we divided into 93 tasks with product code, category, and warehouse.As an error function, for all our experiments, we used RMSEnote that RMSE (unlike e.g.MSE) provides error in the same scale as the input data, so our results from Section 5 cannot be compared head-to-head across the datasets.</p>
<p>From the datasets tested, only the DF dataset contained additional information apart from the date, demand label, and categorical variables for product and vendor.Due to this, in order to remain consistent throughout our experiments, only categorical variables and demand labels were used for training.We also used a fixed number of lags for every experiment where applicable (with lag value 15).We ensured that with every datapoint in training, the following data M.Θ 0 .train(Xnew )</p>
<p>18:</p>
<p>if L(M.Θ sim ) &lt; L(M.Θ 0 ) then ▷ Assess temporary heads performance 19: end if 23: end while vector is preserved (in pre-training as well as single task training), totaling 17 elements in the input vector: input_vector = {vendor_id, product_id, damand 1 , demand 2 , ..., demand 15 }
X old [X sim ] ← X old [X sim ] ∪ X new ▷ Append
(3)</p>
<p>Implementation</p>
<p>In our implementation, we used a Linux-based operating system and Python 3.11 environment with an Intel Xeon W-2255 CPU, 128 GB RAM, and an Nvidia RTX 6000 with 24 GB VRAM.The libraries we used in our code included scikit-Learn and statsmodels for our shallow ML experiments, as well as PyTorch and PyTorch-Lightning for ANN experiments.Implementation of Algorithm 1 is available in our repository [50].</p>
<p>Baselines</p>
<p>Our baseline experiments used ARIMA, Decision Trees, and Random Forests.The models were selected due to their consistent and extensive use in practical demand forecasting.</p>
<p>Experiments on the Autoregressive Integrated Moving Average model were performed separately for each task to achieve the best performance.The data was considered as non-seasonal, with parameter grid search for all components of the model (AR (p), MA (q), and I (d)) resulting in a total of 135 models per task.Below are the ranges used for every parameter:</p>
<p>• p = {1, . . ., 15}, step = 1</p>
<p>• q = {1, . . ., 3}, step = 1
• d = {1, . . . , 3}, step = 1
Decision Trees and Random Forests experiments were also performed per task for consistency, with a set of grid-searched parameters for each algorithm run.The ranges of the parameters for DTs and RFs are listed below:</p>
<p>• maximum regressor depth: depth max = {4, . . ., 12}, step = 2</p>
<p>• maximum number of leaf nodes: leaf max = {10, 15, 20}</p>
<p>• maximum number of estimators (RFs only): est max = {100, 150, 200, 250}</p>
<p>Additional experiments regarding post-pruning of the trained Decision Trees were also performed; however, the RMSE metric tended to be much worse, and ultimately, these experiments were excluded from the summary.</p>
<p>Multi-task learning SotA</p>
<p>For our experiments covering the use of multi-tasking methods, we found four methods in recent literature against which we can compare NMT-Net.Two of them are multi-task regression models: Multi-Level Lasso (MTL) [30] and multi-task Wasserstein regularized regression (MTWR) [21], as shallow ML methods, as well as task grouping (TAG) [13] and task clustering (MTL-cluster) [45], as deep learning methods.</p>
<p>For our shallow ML experiments, we followed training recipes from the papers, with additional grid search over hyperparameters.For alpha parameters, we used a set alphas = {0.01,0.05, 0.1, 0.2, 0.5, 1}, and for the number of relevant joint features for task training, we used n f eatures = {3, . . ., 15} with step = 1.</p>
<p>For DL experiments, since the direct evaluation of different ANN model architectures suitable for the demand prediction task is outside the paper's scope, we used a simple MLP model with Cat2Vec categorical embedding for store and product IDs, along with a sequential model for past demands with a given lag.However, other ANN models, such as RNN or Transformer model architecture, can be used as a drop-in replacement for our NMT-Net method.</p>
<p>The ANN architecture consisted of two embedding layers performing categorical variables to 5-element vectors encoding, followed by concatenation with the rest of the input vector.Next, the sequential part of the network consisted of three MLP blocks: {Linear, ReLu, BatchN orm, Dropout} with hidden dimensions linear dim = {128, 256, 64} and constant dropout rate of 0.5.The head of the network was a single linear regression layer with a single neuron output for one-step forecasting.</p>
<p>For optimization, the AdamW optimizer was used with an initial learning rate of 0.01 for the first 100 pre-training epochs and 0.001 for 50 fine-tuning epochs.Learning rate was also scheduled with Reduce on Plateau scheduler and the rate of 0.8 for pre-training and 0.6 for fine-tuning, as well as 20 and 10 step patience, respectively.RMSE loss was used as the loss function, and the model was trained with a consistent batch size of 5 for every experiment performed.</p>
<p>Neuroplastic Multi-Task Network (NMT-Net)</p>
<p>In order to stay consistent with our multi-tasking experiments, the overall model architecture remained the same for D-ANN experiments, with the only differences resulting from the dynamic nature of the training and the dynamic, multi-head capabilities of the model.For multi-head capabilities, we changed the last regression layer to layer dictionary holding a set of regression layers along with their task-specific descriptions.This set is supplemented with additional regression layers during training, and pre-existing layers within it can also be fine-tuned during the training process with simultaneous optimizer update.The model also stores information on head-to-task relations.</p>
<p>For consistency with other MLP experiments, we also left the training process unchanged.Our optimizer, loss function, learning rates, and scheduler are the same as described in Subsection 4.4.</p>
<p>Results</p>
<p>This section describes the experiments we performed with our chosen methods.The sections below provide a detailed description of each group of experiments, with methods, training recipes, and training parameters used.A summary of all performed experiments is included in Tab. 1.Note that the experiments were performed using a random seed and with at least five runs for every method.In the summary, we also include the standard deviation value (σ) for the results obtained.</p>
<p>In this section, in Tab. 1, we present the results of all the methods we tested.They are divided into three test datasets, and the primary measure we used is RMSE.We have also included in the table the standard deviation (σ) of the results obtained in the five randomized seed experiments.Later, in Subsection 5.1, we also include an ablation study, different similarity measurements, and additional information on head performance and task-to-head distribution.</p>
<p>As can be seen in the results, for the mean RMSE, our method outperformed other approaches in DF and SIDF datasets, while being close to the best-performing task grouping approach in SIDF dataset.Similarly, for minimum RMSE, our method again performed the best in two out of three datasets, with decision trees and random forests scoring better on PDF dataset.For maximum RMSE scores, the Dynamic ANNs outperformed all other methods, significantly lowering the score across all the datasets.Our method excelled the most in terms of the standard deviation of the experiments, having it lower mostly by an order of magnitude compared to other approaches, meaning that it remained the most consistent method across all the experiments.</p>
<p>In</p>
<p>Additional experiments</p>
<p>In this subsection, we cover additional experiments performed on the X eval part of the DF dataset.For all the additional experiments performed, we remained consistent with the training recipe described in Section 4.4, and at least five training runs were done for each experiment.</p>
<p>We performed an ablation study to assess the method of selecting the most similar, previously learned task to the task at hand, and also verified if the similarity calculation increases the model's performance at all.For the study, we selected four cases with varying similarity measurements:</p>
<p>• Random (RAND) -the task for fine-tuning is selected randomly from the X old set</p>
<p>• Median Absolute Error (MedAE)</p>
<p>• Mean Gamma Deviance (MGD)</p>
<p>• Root Mean Squared Error (RMSE) -as in the experiments performed in Section 5</p>
<p>In Tab. 2 we present the results of the ablation study.As can be seen in the results, using RMSE as a similarity metric still resulted in obtaining the best mean and minimum RMSE score, while obtaining a slightly lower maximum score.However, using two other metrics may result in obtaining a lower standard deviation across the scores obtained.As could be expected, using randomly selected model heads for fine-tuning resulted in a deterioration of the RMSE score, indicating that the model will benefit from jointly training the most similar tasks.For our next experiments, we dive deeper into the process of training the models to assess how well each SIM function behaves as the task number increases.In order to do so, we evaluated the performance and characteristics of heads added during the training for each of the similarity metrics.We specified three additional characteristics that we measured during the course of multi-task training:</p>
<p>• Total head count</p>
<p>• The number of tasks performed by a single head</p>
<p>• The performance of heads across the added tasks In Fig. 3, we present the additional models' characteristics for every SIM method we tested.For the first column -the total number of models' heads, it can be seen that all three SIM methods (MedAE, MGD, and RMSE) maintain similar head count for the given task number, while for the RAND method total head count is significantly higher, indicating that the tasks could not be grouped in a effective manner.</p>
<p>Figure 3: The results for the total number of models' heads, the number of tasks performed per head, and overall models' performance for the different SIM methods.</p>
<p>The same can be seen in the next column -the total number of tasks per head.In this column, we present the maximum and mean number of tasks per head in the network for all experiments performed.We omitted the minimum value, as the number is consistently 1 every time a new head is added.Once again, apart from the RAND method, the MedAE, MGD, and RMSE methods stay close to each other, with the average tasks per head being approximately 4. For the RAND method, a much lower task count per head can be observed, indicating that the tasks that were trained together did not significantly improve the performance of the model.</p>
<p>Lastly, in the third column, we show the overall model performance graphs as they changed during the addition of the tasks.The most significant difference can be seen in the maximum RMSE score across the SIM methods.While for the RAND method, the maximum RMSE started with the lowest value, the model then struggled to improve it for the whole course of training, meaning that the addition of new tasks did little to improve the overall performance.Similarly, the MedAE method also struggled to improve over time, and only with the addition of task 800 could it improve the performance.The best-performing methods were the MGD and RMSE, where, thanks to the similarity found in the task, they improved the worst-performing heads with tasks 168 and 73, respectively.It can also be noted that both the MGD and RMSE methods improved the worst-performing heads the most frequently -3 times, while the MedAE method could provide the improvement only once.</p>
<p>Conclusions and future work</p>
<p>In this work, we proposed a novel method for Dynamic Artificial Neural Networks aimed at enhancing multi-task and continual learning models by introducing structural adaptability to the neural architecture during training.Our method, inspired by neuroplasticity as seen in the task learning of biological organisms, allows for dynamically adapting the computational graph through task similarity assessment, temporary ANN head training, and selective head integration.Our approach proved to allow structural flexibility, significantly improving performance and consistency across various multi-task problems.We firmly believe that our method can also be applied to other multi-task domains, as well as to continual learning problems, including reinforcement learning setups.</p>
<p>Experimental results on three public datasets demonstrated that our method outperforms traditional models such as ARIMA, Decision Trees, and Random Forests, as well as modern multi-task learning strategies (task grouping and task clustering).In particular, our approach achieved the lowest RMSE and standard deviation across most experiments, indicating both accuracy and robustness.</p>
<p>With our promising results, several research paths are open for further investigation.As stated in Section 5, additional, dynamic hyperparameter tuning during the training process can further improve the performance of our method.We also see potential for integrating our method with other ANN architectures, such as RNNs, CNNs, and Transformer models, and testing our approach with different types of data and tasks.</p>
<p>Other future research opportunities we consider valid are employing our method for continual learning in the scope of reinforcement learning setups, as our method was inspired by reinforcement learning-type tasks in biological environments.Using our method on Atari, MuJoCo, or MiniHack environments could result in improvements of the current state-of-the-art models, and also allow us to compare our findings on datasets that are more widely used for the multi-task setups than the task of demand forecasting.</p>
<p>Lastly, with the core of our method tested and verified, we want to delve into more complex methods of integrating into ANNs' structural models during training.In this paper, we presented task-group-specific computational model dynamics focusing on the model's head layers.In our further work, we want to tackle the problem of modifying specific ANN layers in the global scope in order to achieve fully cross-model dynamic computational ANN graphs.</p>
<p>Figure 1 :
1
Figure 1: The process of dynamically adding a single task to the ANN model in a multi-task learning loop.</p>
<p>Fig. 2 ,
2
we also included three sample training curves for the datasets used.In the figure, a vertical blue line separates the 100-epoch pre-training phase from the 50-epoch fine-tuning, head-specific phase.The main, black vertical axis contains RMSE measurements during training, and the dotted cyan axis contains the current learning rate for the epoch, also indicating when Reduce on Plateau scheduler updated the learning rate.Also in the figure, two red dots indicate the lowest values for both training and testing errors, values of which are also shown in the Error min box in the graphs.It can be seen that, depending on the dataset, the model training behaved differently, with DF model acting the most predictably, where training error remained lower than testing error throughout the training process, and PDF model learning the most head-(task group) specific behavior in the fine-tuning phase.It can also be seen that for the SIDF model, the fine-tuning phase helped significantly in the head-specific training phase, lowering both training and testing errors.Given the learning curves collected from all the experiments and datasets, it can be speculated that additional management of learning rate, batch size, and the length of each training phase could further improve our results.</p>
<p>Figure 2 :
2
Figure 2: Sample training curves for the datasets tested.</p>
<p>Table 1 :
1
Results of experiments conducted on three test datasets
DatasetMethodmean (σ)RMSE min (σ)max (σ)ARIMA25.34 (4.35)3.43 (3.15)196.90 (7.22)DT28.98 (6.43)4.09 (3.11)360.56 (9.95)RF26.93 (5.55)3.32 (1.17)308.62 (9.21)MTL61.68 (4.03)56.65 (3.87)67.04 (5.17)DFMTWR45.58 (7.07)39.01 (4.22)56.65 (8.28)MTL-cluster18.48 (3.81)8.72 (2.11)69.19 (7.92)TAG19.12 (3.33)8.09 (2.09)53.35 (6.39)D-ANN (ours)16.10 (0.21)3.25 (0.40)30.33 (1.01)ARIMA12.43 (4.45)4.82 (6.36)23.61 (5.22)DT17.42 (7.27)5.45 (7.67)35.29 (7.78)RF17.40 (7.26)5.45 (7.22)35.30 (7.67)MTL33.45 (1.94)30.40 (1.21)35.62 (2.04)SIDFMTWR12.17 (5.26)8.60 (4.01)23.20 (5.56)MTL-cluster11.51 (2.92)6.48 (2.17)15.50 (2.66)TAG6.64 (1.28)3.33 (1.36)14.24 (1.42)D-ANN (ours)6.66 (0.17)3.22 (0.21)10.09 (0.53)ARIMA6232 (1640)3.36 (142.0)8217 (1822)DT7294 (1945)2.71 (157.0)10095 (1874)RF7288 (1945)2.71 (157.0)10095 (1874)MTL3833 (609.3)3715 (571.4)3888 (621.4)PDFMTWR3383 (294.1)3070 (266.6)3942 (301.5)MTL-cluster1653 (431.9)7.78 (3.34)1992 (24.27)TAG858.2 (78.12)26.76 (45.47)2253 (167.2)D-ANN (ours)573.5 (11.97)4.52 (0.01)1893 (11.07)</p>
<p>Table 2 :
2
Ablation experiments results
SIMRMSEMethodmean (σ)min (σ)max (σ)RAND18.04 (0.43)3.46 (0.23)29.76 (0.61)MedAE16.40 (0.31)4.52 (0.13)31.03 (1.42)MGD16.24 (0.16)3.80 (0.47)29.11 (0.57)RMSE16.10 (0.21)3.25 (0.40)30.33 (1.01)
Considering our findings from these additional experiments, it can be seen that using RMSE as the similarity measurement method yields the best results in multi-task scenarios. However, it is also worth noting that alternative methods to the ones presented (e.g. similarity based on the trained models' weights rather than task similarity) can also be valid. We also conclude that:1. Uncovering the task similarity can significantly improve the performance of the multi-task model.2. When grouped, similar tasks will improve the overall performance of the model.3.Using the different SIM methods has a notable impact on how well the tasks are grouped in the scope of both model size and performance.4. The rate of model performance improvements is two-way dependent on similarity measurements, as it matters for both task distribution across models' heads and the similarity of the upcoming task to the tasks already known by the model.
Our method and accompanying codebase, available on GitHub, offer a solid foundation for further development of dynamic, neuroplasticity-inspired architectures in multi-task learning scenarios.We hope this work encourages future research into biologically plausible and structurally adaptive AI systems, as we will pursue it onward.
Dynamic neural networks. ICML Workshop. 2022</p>
<p>Dynamic neural network modelling of soil moisture content for predictive irrigation scheduling. O Adeyemi, I Grove, S Peets, Y Domun, T Norton, 10.3390/s18103408Sensors. 18102018</p>
<p>A dynamic neural network model for predicting risk of zika in real time. M Akhtar, M U G Kraemer, L M Gardner, 10.1186/s12916-019-1389-3BMC Medicine. 2019</p>
<p>Algorithms and applications for multitask learning. R Caruana, ICML. 1996Citeseer</p>
<p>Multitask learning. R Caruana, 10.1023/A:1007379606734Machine Learning. 1997</p>
<p>Rnn / lstm with modified adam optimizer in deep learning approach for automobile spare parts demand forecasting. K K Chandriah, R Naraganahalli, 10.1007/s11042-021-10913-02021Multimedia Tools and Applications</p>
<p>Neuroplasticity and adult learning. S A Chen, A M Goodwill, Third international handbook of lifelong learning. Springer2022</p>
<p>Short-term water demand forecasting algorithm using ar model and mlp. G S Choi, C Yu, R M Jin, S K Yu, M G Chun, 10.5391/jkiis.2009.19.5.713Journal of Korean Institute of Intelligent Systems. 1952009</p>
<p>M Crawshaw, arXiv:2009.09796Multi-task learning with deep neural networks: A survey. 2020arXiv preprint</p>
<p>R Dholakia, R Randeria, R Dholakia, H Ashar, D Rana, 10.1007/978-3-030-38445-6_5Cognitive Demand Forecasting with Novel Features Using Word2Vec and Session of the Day. ChamSpringer International Publishing2020</p>
<p>Dynamic neural network architectures for on field stochastic calibration of indicative low cost air quality sensing systems. E Esposito, S De Vito, M Salvato, V Bright, R L Jones, O Popoola, Sensors and Actuators B: Chemical. 2312016</p>
<p>Forecasting of demand using arima model. J Fattah, L Ezzine, Z Aman, H E Moussami, A Lachhab, 10.1177/1847979018808673International Journal of Engineering Business Management. 1018479790188086732018</p>
<p>Efficiently identifying task groupings for multi-task learning. C Fifty, E Amid, Z Zhao, T Yu, R Anil, C Finn, M Ranzato, A Beygelzimer, Y Dauphin, P Liang, Vaughan, Advances in Neural Information Processing Systems. J W , Curran Associates, Inc202134</p>
<p>Dynamic neural network structure: A review for its theories and applications. J Guo, C P Chen, Z Liu, X Yang, IEEE Transactions on Neural Networks and Learning Systems. 2024</p>
<p>Dynamic task prioritization for multitask learning. M Guo, A Haque, D A Huang, S Yeung, L Fei-Fei, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)September 2018</p>
<p>Learning to branch for multi-task learning. P Guo, C Y Lee, D Ulbricht, PMLR (13-18Proceedings of the 37th International Conference on Machine Learning. Proceedings of Machine Learning Research. H D Iii, A Singh, the 37th International Conference on Machine Learning. Machine Learning ResearchJul 2020119</p>
<p>Dynamic neural networks: A survey. Y Han, G Huang, S Song, L Yang, H Wang, Y Wang, 2021</p>
<p>Dynamic neural networks: advantages and challenges. G Huang, National Science Review. 118e0882024</p>
<p>Clustered multi-task learning: A convex formulation. L Jacob, J P Vert, F Bach, Advances in Neural Information Processing Systems. D Koller, D Schuurmans, Y Bengio, L Bottou, Curran Associates, Inc200821</p>
<p>A novel lstm-gru-based hybrid approach for electrical products demand forecasting. A Jadli, E H B Lahmer, International Journal of Intelligent Engineering &amp; Systems. 1532022</p>
<p>Wasserstein regularization for sparse multi-task regression. H Janati, M Cuturi, A Gramfort, Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics. Proceedings of Machine Learning Research. K Chaudhuri, M Sugiyama, the Twenty-Second International Conference on Artificial Intelligence and Statistics. Machine Learning ResearchPMLR16-18 Apr 201989</p>
<p>Auto-keras: An efficient neural architecture search system. H Jin, Q Song, X Hu, 10.1145/3292500.3330648Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data MiningNew York, NY, USAAssociation for Computing Machinery201919</p>
<p>Product demand forecast. Kaggle, Aug 2017</p>
<p>Kaggle: Store item demand forecasting challenge. Jun 2018</p>
<p>Motor cortex is required for learning but not for executing a motor skill. R Kawai, T Markman, R Poddar, R Ko, A L Fantana, A K Dhawale, A R Kampff, B P Ölveczky, Neuron. 8632015</p>
<p>An improved demand forecasting model using deep learning approach and proposed decision integration strategy for supply chain. Z H Kilimci, A O Akyuz, M Uysal, S Akyokus, M O Uysal, B Atak Bulbul, M A Ekmis, 10.1155/2019/9067367Complexity. 2019190673672019</p>
<p>Learning task grouping and overlap in multi-task learning. A Kumar, H D Iii, 2012</p>
<p>Knowledge distillation for multi-task learning. W H Li, H Bilen, Computer Vision -ECCV 2020 Workshops. A Bartoli, A Fusiello, ChamSpringer International Publishing2020</p>
<p>A survey on evolutionary neural architecture search. Y Liu, Y Sun, B Xue, M Zhang, G G Yen, K C Tan, 10.1109/TNNLS.2021.3100554IEEE Transactions on Neural Networks and Learning Systems. 3422023</p>
<p>Multi-level lasso for sparse multi-task regression. A C Lozano, G Swirszcz, Proceedings of the 29th International Coference on International Conference on Machine Learning. the 29th International Coference on International Conference on Machine LearningOmnipress, Madison, WI, USA201212</p>
<p>G Neubig, C Dyer, Y Goldberg, A Matthews, W Ammar, A Anastasopoulos, M Ballesteros, D Chiang, D Clothiaux, T Cohn, arXiv:1701.03980Dynet: The dynamic neural network toolkit. 2017arXiv preprint</p>
<p>Hybrid water demand forecasting model associating artificial neural network with fourier series. F K Odan, L F R Reis, 10.1061/(ASCE)WR.1943-5452.0000177Journal of Water Resources Planning and Management. 13832012</p>
<p>Demand forecasting dataset. A V S Rao, Jul 2020</p>
<p>An overview of multi-task learning in. S Ruder, arXiv:1706.05098deep neural networks. 2017arXiv preprint</p>
<p>Learning in the fast lane: new insights into neuroplasticity. Y Sagi, I Tavor, S Hofstetter, S Tzur-Moryosef, T Blumenfeld-Katzir, Y Assaf, Neuron. 7362012</p>
<p>Automl: A systematic review on automated machine learning with neural architecture search. I Salehin, M S Islam, P Saha, S Noman, A Tuni, M M Hasan, M A Baten, 10.1016/j.jiixd.2023.10.002Journal of Information and Intelligence. 212024</p>
<p>Multi-task learning as multi-objective optimization. O Sener, V Koltun, S Bengio, H Wallach, H Larochelle, K Grauman, N Cesa-Bianchi, Advances in Neural Information Processing Systems. R Garnett, Curran Associates, Inc201831</p>
<p>A dynamic neural network approach to nonlinear process modeling. A M Shaw, Iii Doyle, F J Schwaber, J S , Computers &amp; chemical engineering. 2141997</p>
<p>Which tasks should be learned together in multi-task learning?. T Standley, A Zamir, D Chen, L Guibas, J Malik, S Savarese, PMLR (13-18Proceedings of the 37th International Conference on Machine Learning. Proceedings of Machine Learning Research. H D Iii, A Singh, the 37th International Conference on Machine Learning. Machine Learning ResearchJul 2020119</p>
<p>Magru: Multi-layer attention with gru for logistics warehousing demand prediction. R Tian, B Wang, C Wang, KSII Transactions on Internet &amp; Information Systems. 1832024</p>
<p>Expansion and renormalization of human brain structure during skill acquisition. E Wenger, C Brozzoli, U Lindenberger, M Lövdén, Trends in cognitive sciences. 21122017</p>
<p>C Xu, J Mcauley, arXiv:2202.07101A survey on dynamic neural networks for natural language processing. 2022arXiv preprint</p>
<p>Adamerging: Adaptive model merging for multi-task learning. E Yang, Z Wang, L Shen, S Liu, G Guo, X Wang, D Tao, 2024</p>
<p>Demand forecasting by using support vector machine. L Yue, Y Yafeng, G Junjun, T Chongli, 10.1109/ICNC.2007.324Third International Conference on Natural Computation (ICNC 2007). 20073</p>
<p>Balancing performance and scalability of demand forecasting ml models. M Żarski, S Nowaczyk, Advances in Intelligent Data Analysis. G Krempl, K Puolamäki, I Miliou, ChamSpringer Nature Switzerland2025XXIII</p>
<p>Intermittent demand forecasting with transformer neural networks. G P Zhang, Y Xia, M Xie, Annals of Operations Research. 33912024</p>
<p>An overview of multi-task learning. Y Zhang, Q Yang, National Science Review. 512018</p>
<p>A survey on multi-task learning. Y Zhang, Q Yang, IEEE transactions on knowledge and data engineering. 34122021</p>
<p>Malsar: Multi-task learning via structural regularization. J Zhou, J Chen, J Ye, Arizona State University. 212011</p>
<p>Multi_Forecasting. M Żarski, Jun 2025</p>            </div>
        </div>

    </div>
</body>
</html>