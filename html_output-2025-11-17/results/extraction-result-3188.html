<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3188 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3188</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3188</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-74.html">extraction-schema-74</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <p><strong>Paper ID:</strong> paper-a22f3398ea865426c89ee66f4824ec626e56a864</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/a22f3398ea865426c89ee66f4824ec626e56a864" target="_blank">RET-LLM: Towards a General Read-Write Memory for Large Language Models</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> RET-LLM is proposed, a novel framework that equips LLMs with a general write-read memory unit, allowing them to extract, store, and recall knowledge from the text as needed for task performance.</p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have significantly advanced the field of natural language processing (NLP) through their extensive parameters and comprehensive data utilization. However, existing LLMs lack a dedicated memory unit, limiting their ability to explicitly store and retrieve knowledge for various tasks. In this paper, we propose RET-LLM a novel framework that equips LLMs with a general write-read memory unit, allowing them to extract, store, and recall knowledge from the text as needed for task performance. Inspired by Davidsonian semantics theory, we extract and save knowledge in the form of triplets. The memory unit is designed to be scalable, aggregatable, updatable, and interpretable. Through qualitative evaluations, we demonstrate the superiority of our proposed framework over baseline approaches in question answering tasks. Moreover, our framework exhibits robust performance in handling temporal-based question answering tasks, showcasing its ability to effectively manage time-dependent information.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3188.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3188.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RET-LLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retentive Large Language Model (RET-LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A concept framework that augments an instruction-tuned LLM (Alpaca-7B, finetuned with LoRA) with an external, updatable read-write triplet memory accessed via text-based MEM_WRITE / MEM_READ API calls; memory stores <t1, relation, t3> triplets plus average LLM representations hashed into an LSH index for fuzzy retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>RET-LLM</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A system composed of (1) a controller, (2) a finetuned instruction-following LLM (Alpaca-7B finetuned with LoRA), and (3) an external triplet memory. The LLM is finetuned to generate explicit memory API calls (MEM_WRITE, MEM_READ) so the controller can store or retrieve triplets; retrieved triplets are appended to the LLM input to produce answers.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external read-write triplet memory (retrieval-augmented, vector-indexed)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Information is extracted as triplets <t1, relation, t3> and stored in a three-column table. For each text field the mean LLM representation h_AVG(t_i) is stored in an LSH index to allow fuzzy nearest-neighbor lookup when exact text matches are absent. The LLM issues textual API calls [MEM_WRITE {t1 >> t2 >> t3}] to write and [MEM_READ {...}] to query; the controller executes these calls, the memory returns all matching triplets (possibly multiple), and the LLM uses the returned triplets to generate final answers. Memory is updatable, aggregatable (can combine information across documents), and interpretable (triplet format).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Synthetic triplet-based question answering; temporal question answering (examples)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Finetuning/evaluation focused on (1) extracting relationships from statements into triplets, (2) answering triplet-derived QA queries (who/is-related-to/which-company etc.) possibly requiring aggregation across multiple stored triplets, and (3) demonstrating handling of time-dependent facts via modifiable memory entries.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>question answering</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Qualitative examples show RET-LLM can correctly answer questions using retrieved triplets from its external memory even when the base Alpaca-7B model (zero-shot, given the same context) produced incorrect answers; the external modifiable memory also enables updating temporal facts to obtain up-to-date answers.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>No quantitative/benchmarked evaluation reported (only qualitative examples); resource-limited finetuning setup (LoRA on a single A6000); planned future work to add detailed empirical evaluation and broader relation types; potential retrieval failures if LSH fails to find semantically-similar entries.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RET-LLM: Towards a General Read-Write Memory for Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3188.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3188.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative Agents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior (Park et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generative-agent framework that stores and dynamically retrieves a natural-language record of an agent's observations and reflections to drive simulated human-like behaviors; the memory component is part of the agent rather than an LLM-invoked external tool.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Generative Agents (Park et al. 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Framework of simulated agents that record experiences in natural language and retrieve them to plan behavior; an LLM is used as a planner, but the memory belongs to the agent architecture rather than being controlled directly by the LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>agent-internal episodic experience memory (natural-language memory log)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>The agent maintains a timeline of observations/reflections stored in natural language; retrieval and summarization of these entries inform future planning and behavior. The memory is an inherent component of the agent and not an externally-invoked tool by the LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Simulated interactive behavior tasks (generative agent scenarios)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Interactive simulation tasks where agents must plan and act like humans over extended interactions using stored experiences and reflections (long-horizon behavior modeling).</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>simulated behavior / planning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Park et al.'s architecture demonstrates rich emergent behaviors when agents maintain and use an experience memory; noted distinction: memory is agent-internal and the LLM lacks direct control over which specific content is stored/retrieved.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Memory is tied to the agent and not directly controlled by the LLM; potential issues in the specificity of stored content and how the LLM can influence stored memory.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RET-LLM: Towards a General Read-Write Memory for Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3188.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3188.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Memorizing Transformer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Memorizing Transformer</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transformer variant that extends attention to a persistent key-value memory storing representations extracted from transformer layers, enabling attention over much longer effective contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Memorizing transformers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Memorizing Transformer (Wu et al. 2022)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A transformer architecture that stores (key, value) pairs from internal layers in an external memory and retrieves relevant pairs to augment the current context during generation, enabling long-range memory beyond the usual context window.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external KV memory (architectural memory augmentation)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Extracts keys and values from transformer layers to build a memory store; during generation, nearest-neighbor retrieval of these KV entries is performed and added to the model's context to improve recall over long contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Long-context / memorization tasks (as in the Memorizing Transformer paper)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks that require remembering and attending to information from very long documents or previously seen data; main challenge is scaling attention to long histories.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>language modeling / long-context retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Prior work shows that storing KV pairs from transformer layers and retrieving them can improve the model's ability to handle long-range dependencies and memorization tasks; cited here as prior art differing from RET-LLM because it modifies the LLM architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Architectural changes required; memory scaling and integration complexity compared to RET-LLM's external-tool approach.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RET-LLM: Towards a General Read-Write Memory for Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3188.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3188.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Training LMs w/ Memory Augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Training language models with memory augmentation (Zhong et al., 2022)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Approach that trains LMs with an external memory augmentation to improve retrieval and use of external context; mentioned as related work contrasting with RET-LLM's triplet-storage proposal.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Training language models with memory augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Memory-augmented LMs (Zhong et al. 2022)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Language models trained to use an external memory store (often vector/document store) to retrieve context to condition generation.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented memory (document/vector store)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Stores encoded document representations and retrieves relevant documents based on query context to augment the model's input; often integrated during training to improve retrieval behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Contextual retrieval-augmented tasks (as in Zhong et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks requiring retrieval of supporting documents to improve generation accuracy (e.g., open-domain QA, long-document QA).</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>question answering / retrieval-augmented generation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Memory-augmentation during training can improve retrieval and generation when external context is needed; cited as prior art and contrasted with RET-LLM's triplet and LSH-based fuzzy retrieval approach.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Document-level storage can be less aggregatable or fine-grained than triplet storage; integration may require training-time changes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RET-LLM: Towards a General Read-Write Memory for Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3188.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3188.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Plug-in Knowledge Memory (Cheng et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Language model with plug-in knowldge memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced approach (Cheng et al.) that encodes documents and retrieves them to add to the context during generation; cited as related work that does document-level rather than triplet-level memory.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language model with plug-in knowldge memory</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Language model with plug-in knowledge memory (Cheng et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Method that encodes documents into a memory store and retrieves relevant documents based on the current context to augment the generative process.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external document memory / retrieval augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Encodes whole documents, saves encodings, and retrieves relevant documents to add to the LLM context for generation; contrasted with RET-LLM's extraction of fine-grained triplets.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Document retrieval-augmented generation tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks where retrieval of whole documents provides relevant context for generation or question answering.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>question answering / retrieval-augmented generation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Document-level retrieval can supply necessary context but may be less concise and aggregatable than triplet memory; cited as background.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Potential inefficiency in aggregating dispersed facts across multiple documents; less interpretable at a fine-grained fact level.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RET-LLM: Towards a General Read-Write Memory for Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3188.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3188.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MemLLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MemLLM: Finetuning LLMs to use an explicit read-write memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced follow-up work cited by the authors as the evolved and thoroughly evaluated version of the RET-LLM concept; focuses on finetuning LLMs to use an explicit read-write memory.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Memllm: Finetuning llms to use an explicit read-write memory</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MemLLM (Modarressi et al., 2024)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An evolved implementation of RET-LLM that reportedly includes thorough empirical evaluation; finetunes LLMs to use an explicit read-write memory (triplet-style read/write API), as cited by the current paper.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external read-write explicit memory (triplet-based)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Reportedly similar to RET-LLM's triplet memory and API-driven read/write interactions; cited as the subsequent, thoroughly evaluated system.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as the evolved and empirically-evaluated follow-up to RET-LLM (authors note this concept has since been evaluated in MemLLM).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RET-LLM: Towards a General Read-Write Memory for Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3188.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e3188.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Toolformer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Toolformer: Language models can teach themselves to use tools</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Method that trains LMs to generate API calls to external tools (e.g., calculators, search APIs) and use tool outputs to improve task performance; cited as related work teaching LLMs to use external tools.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Toolformer: Language models can teach themselves to use tools</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Toolformer (Schick et al. 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Approach where an LLM is taught to generate calls to external tools and incorporate tool outputs into generation; similar in spirit to RET-LLM's approach of teaching the LLM to call a memory API.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external tools via API (not a persistent memory store)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>The LLM learns to formulate API calls to tools during training; the controller executes tool calls and returns outputs which the LLM integrates into responses. Cited here because RET-LLM uses a similar text-API pattern for memory.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Tool-augmented generation tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks where external tool capabilities (calculation, search, etc.) are beneficial; main challenge is learning when and how to call tools and incorporate results.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>tool use / question answering</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Demonstrates that LLMs can be trained to autonomously call external tools; RET-LLM applies this idea to a more complex external memory tool.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Tool invocation correctness and deciding when to call tools remain challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RET-LLM: Towards a General Read-Write Memory for Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3188.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e3188.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Time-aware LMs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Time-aware language models as temporal knowledge bases</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Work curating temporally-annotated data and training LMs for improved temporal awareness, cited here in the context of temporal facts and memory/updatability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Time-aware language models as temporal knowledge bases</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Time-aware language models (Dhingra et al. 2022)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Approach that treats language models as temporal knowledge bases by curating temporally-annotated datasets and training models to be more temporally aware of facts.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>dataset annotation / temporal training (not explicit external memory)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Improves a model's temporal knowledge via temporally-annotated training data rather than a modifiable external memory; cited as related work addressing temporal information challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Temporal fact tasks / temporal knowledge benchmarks</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks that require awareness of time-dependent facts and changes (e.g., who is current president), challenging for static LM parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>question answering / temporal knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Temporal annotation and training can improve temporal awareness; RET-LLM offers an alternative by using an updatable external memory to handle changing facts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Temporal training does not provide an easy means to update facts post-training; memory-based approaches are complementary.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RET-LLM: Towards a General Read-Write Memory for Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Memllm: Finetuning llms to use an explicit read-write memory <em>(Rating: 2)</em></li>
                <li>Generative agents: Interactive simulacra of human behavior <em>(Rating: 2)</em></li>
                <li>Memorizing transformers <em>(Rating: 2)</em></li>
                <li>Training language models with memory augmentation <em>(Rating: 2)</em></li>
                <li>Toolformer: Language models can teach themselves to use tools <em>(Rating: 1)</em></li>
                <li>Time-aware language models as temporal knowledge bases <em>(Rating: 1)</em></li>
                <li>Language model with plug-in knowldge memory <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3188",
    "paper_id": "paper-a22f3398ea865426c89ee66f4824ec626e56a864",
    "extraction_schema_id": "extraction-schema-74",
    "extracted_data": [
        {
            "name_short": "RET-LLM",
            "name_full": "Retentive Large Language Model (RET-LLM)",
            "brief_description": "A concept framework that augments an instruction-tuned LLM (Alpaca-7B, finetuned with LoRA) with an external, updatable read-write triplet memory accessed via text-based MEM_WRITE / MEM_READ API calls; memory stores &lt;t1, relation, t3&gt; triplets plus average LLM representations hashed into an LSH index for fuzzy retrieval.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "RET-LLM",
            "agent_description": "A system composed of (1) a controller, (2) a finetuned instruction-following LLM (Alpaca-7B finetuned with LoRA), and (3) an external triplet memory. The LLM is finetuned to generate explicit memory API calls (MEM_WRITE, MEM_READ) so the controller can store or retrieve triplets; retrieved triplets are appended to the LLM input to produce answers.",
            "memory_used": true,
            "memory_type": "external read-write triplet memory (retrieval-augmented, vector-indexed)",
            "memory_mechanism_description": "Information is extracted as triplets &lt;t1, relation, t3&gt; and stored in a three-column table. For each text field the mean LLM representation h_AVG(t_i) is stored in an LSH index to allow fuzzy nearest-neighbor lookup when exact text matches are absent. The LLM issues textual API calls [MEM_WRITE {t1 &gt;&gt; t2 &gt;&gt; t3}] to write and [MEM_READ {...}] to query; the controller executes these calls, the memory returns all matching triplets (possibly multiple), and the LLM uses the returned triplets to generate final answers. Memory is updatable, aggregatable (can combine information across documents), and interpretable (triplet format).",
            "task_name": "Synthetic triplet-based question answering; temporal question answering (examples)",
            "task_description": "Finetuning/evaluation focused on (1) extracting relationships from statements into triplets, (2) answering triplet-derived QA queries (who/is-related-to/which-company etc.) possibly requiring aggregation across multiple stored triplets, and (3) demonstrating handling of time-dependent facts via modifiable memory entries.",
            "task_type": "question answering",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "key_findings": "Qualitative examples show RET-LLM can correctly answer questions using retrieved triplets from its external memory even when the base Alpaca-7B model (zero-shot, given the same context) produced incorrect answers; the external modifiable memory also enables updating temporal facts to obtain up-to-date answers.",
            "limitations_or_challenges": "No quantitative/benchmarked evaluation reported (only qualitative examples); resource-limited finetuning setup (LoRA on a single A6000); planned future work to add detailed empirical evaluation and broader relation types; potential retrieval failures if LSH fails to find semantically-similar entries.",
            "uuid": "e3188.0",
            "source_info": {
                "paper_title": "RET-LLM: Towards a General Read-Write Memory for Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Generative Agents",
            "name_full": "Generative agents: Interactive simulacra of human behavior (Park et al., 2023)",
            "brief_description": "A generative-agent framework that stores and dynamically retrieves a natural-language record of an agent's observations and reflections to drive simulated human-like behaviors; the memory component is part of the agent rather than an LLM-invoked external tool.",
            "citation_title": "Generative agents: Interactive simulacra of human behavior",
            "mention_or_use": "mention",
            "agent_name": "Generative Agents (Park et al. 2023)",
            "agent_description": "Framework of simulated agents that record experiences in natural language and retrieve them to plan behavior; an LLM is used as a planner, but the memory belongs to the agent architecture rather than being controlled directly by the LLM.",
            "memory_used": true,
            "memory_type": "agent-internal episodic experience memory (natural-language memory log)",
            "memory_mechanism_description": "The agent maintains a timeline of observations/reflections stored in natural language; retrieval and summarization of these entries inform future planning and behavior. The memory is an inherent component of the agent and not an externally-invoked tool by the LLM.",
            "task_name": "Simulated interactive behavior tasks (generative agent scenarios)",
            "task_description": "Interactive simulation tasks where agents must plan and act like humans over extended interactions using stored experiences and reflections (long-horizon behavior modeling).",
            "task_type": "simulated behavior / planning",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": false,
            "key_findings": "Park et al.'s architecture demonstrates rich emergent behaviors when agents maintain and use an experience memory; noted distinction: memory is agent-internal and the LLM lacks direct control over which specific content is stored/retrieved.",
            "limitations_or_challenges": "Memory is tied to the agent and not directly controlled by the LLM; potential issues in the specificity of stored content and how the LLM can influence stored memory.",
            "uuid": "e3188.1",
            "source_info": {
                "paper_title": "RET-LLM: Towards a General Read-Write Memory for Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Memorizing Transformer",
            "name_full": "Memorizing Transformer",
            "brief_description": "A transformer variant that extends attention to a persistent key-value memory storing representations extracted from transformer layers, enabling attention over much longer effective contexts.",
            "citation_title": "Memorizing transformers",
            "mention_or_use": "mention",
            "agent_name": "Memorizing Transformer (Wu et al. 2022)",
            "agent_description": "A transformer architecture that stores (key, value) pairs from internal layers in an external memory and retrieves relevant pairs to augment the current context during generation, enabling long-range memory beyond the usual context window.",
            "memory_used": true,
            "memory_type": "external KV memory (architectural memory augmentation)",
            "memory_mechanism_description": "Extracts keys and values from transformer layers to build a memory store; during generation, nearest-neighbor retrieval of these KV entries is performed and added to the model's context to improve recall over long contexts.",
            "task_name": "Long-context / memorization tasks (as in the Memorizing Transformer paper)",
            "task_description": "Tasks that require remembering and attending to information from very long documents or previously seen data; main challenge is scaling attention to long histories.",
            "task_type": "language modeling / long-context retrieval",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": false,
            "key_findings": "Prior work shows that storing KV pairs from transformer layers and retrieving them can improve the model's ability to handle long-range dependencies and memorization tasks; cited here as prior art differing from RET-LLM because it modifies the LLM architecture.",
            "limitations_or_challenges": "Architectural changes required; memory scaling and integration complexity compared to RET-LLM's external-tool approach.",
            "uuid": "e3188.2",
            "source_info": {
                "paper_title": "RET-LLM: Towards a General Read-Write Memory for Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Training LMs w/ Memory Augmentation",
            "name_full": "Training language models with memory augmentation (Zhong et al., 2022)",
            "brief_description": "Approach that trains LMs with an external memory augmentation to improve retrieval and use of external context; mentioned as related work contrasting with RET-LLM's triplet-storage proposal.",
            "citation_title": "Training language models with memory augmentation",
            "mention_or_use": "mention",
            "agent_name": "Memory-augmented LMs (Zhong et al. 2022)",
            "agent_description": "Language models trained to use an external memory store (often vector/document store) to retrieve context to condition generation.",
            "memory_used": true,
            "memory_type": "retrieval-augmented memory (document/vector store)",
            "memory_mechanism_description": "Stores encoded document representations and retrieves relevant documents based on query context to augment the model's input; often integrated during training to improve retrieval behaviors.",
            "task_name": "Contextual retrieval-augmented tasks (as in Zhong et al.)",
            "task_description": "Tasks requiring retrieval of supporting documents to improve generation accuracy (e.g., open-domain QA, long-document QA).",
            "task_type": "question answering / retrieval-augmented generation",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": false,
            "key_findings": "Memory-augmentation during training can improve retrieval and generation when external context is needed; cited as prior art and contrasted with RET-LLM's triplet and LSH-based fuzzy retrieval approach.",
            "limitations_or_challenges": "Document-level storage can be less aggregatable or fine-grained than triplet storage; integration may require training-time changes.",
            "uuid": "e3188.3",
            "source_info": {
                "paper_title": "RET-LLM: Towards a General Read-Write Memory for Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Plug-in Knowledge Memory (Cheng et al.)",
            "name_full": "Language model with plug-in knowldge memory",
            "brief_description": "A referenced approach (Cheng et al.) that encodes documents and retrieves them to add to the context during generation; cited as related work that does document-level rather than triplet-level memory.",
            "citation_title": "Language model with plug-in knowldge memory",
            "mention_or_use": "mention",
            "agent_name": "Language model with plug-in knowledge memory (Cheng et al.)",
            "agent_description": "Method that encodes documents into a memory store and retrieves relevant documents based on the current context to augment the generative process.",
            "memory_used": true,
            "memory_type": "external document memory / retrieval augmentation",
            "memory_mechanism_description": "Encodes whole documents, saves encodings, and retrieves relevant documents to add to the LLM context for generation; contrasted with RET-LLM's extraction of fine-grained triplets.",
            "task_name": "Document retrieval-augmented generation tasks",
            "task_description": "Tasks where retrieval of whole documents provides relevant context for generation or question answering.",
            "task_type": "question answering / retrieval-augmented generation",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": false,
            "key_findings": "Document-level retrieval can supply necessary context but may be less concise and aggregatable than triplet memory; cited as background.",
            "limitations_or_challenges": "Potential inefficiency in aggregating dispersed facts across multiple documents; less interpretable at a fine-grained fact level.",
            "uuid": "e3188.4",
            "source_info": {
                "paper_title": "RET-LLM: Towards a General Read-Write Memory for Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "MemLLM",
            "name_full": "MemLLM: Finetuning LLMs to use an explicit read-write memory",
            "brief_description": "A referenced follow-up work cited by the authors as the evolved and thoroughly evaluated version of the RET-LLM concept; focuses on finetuning LLMs to use an explicit read-write memory.",
            "citation_title": "Memllm: Finetuning llms to use an explicit read-write memory",
            "mention_or_use": "mention",
            "agent_name": "MemLLM (Modarressi et al., 2024)",
            "agent_description": "An evolved implementation of RET-LLM that reportedly includes thorough empirical evaluation; finetunes LLMs to use an explicit read-write memory (triplet-style read/write API), as cited by the current paper.",
            "memory_used": true,
            "memory_type": "external read-write explicit memory (triplet-based)",
            "memory_mechanism_description": "Reportedly similar to RET-LLM's triplet memory and API-driven read/write interactions; cited as the subsequent, thoroughly evaluated system.",
            "task_name": null,
            "task_description": null,
            "task_type": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": null,
            "key_findings": "Cited as the evolved and empirically-evaluated follow-up to RET-LLM (authors note this concept has since been evaluated in MemLLM).",
            "limitations_or_challenges": null,
            "uuid": "e3188.5",
            "source_info": {
                "paper_title": "RET-LLM: Towards a General Read-Write Memory for Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Toolformer",
            "name_full": "Toolformer: Language models can teach themselves to use tools",
            "brief_description": "Method that trains LMs to generate API calls to external tools (e.g., calculators, search APIs) and use tool outputs to improve task performance; cited as related work teaching LLMs to use external tools.",
            "citation_title": "Toolformer: Language models can teach themselves to use tools",
            "mention_or_use": "mention",
            "agent_name": "Toolformer (Schick et al. 2023)",
            "agent_description": "Approach where an LLM is taught to generate calls to external tools and incorporate tool outputs into generation; similar in spirit to RET-LLM's approach of teaching the LLM to call a memory API.",
            "memory_used": false,
            "memory_type": "external tools via API (not a persistent memory store)",
            "memory_mechanism_description": "The LLM learns to formulate API calls to tools during training; the controller executes tool calls and returns outputs which the LLM integrates into responses. Cited here because RET-LLM uses a similar text-API pattern for memory.",
            "task_name": "Tool-augmented generation tasks",
            "task_description": "Tasks where external tool capabilities (calculation, search, etc.) are beneficial; main challenge is learning when and how to call tools and incorporate results.",
            "task_type": "tool use / question answering",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": false,
            "key_findings": "Demonstrates that LLMs can be trained to autonomously call external tools; RET-LLM applies this idea to a more complex external memory tool.",
            "limitations_or_challenges": "Tool invocation correctness and deciding when to call tools remain challenges.",
            "uuid": "e3188.6",
            "source_info": {
                "paper_title": "RET-LLM: Towards a General Read-Write Memory for Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Time-aware LMs",
            "name_full": "Time-aware language models as temporal knowledge bases",
            "brief_description": "Work curating temporally-annotated data and training LMs for improved temporal awareness, cited here in the context of temporal facts and memory/updatability.",
            "citation_title": "Time-aware language models as temporal knowledge bases",
            "mention_or_use": "mention",
            "agent_name": "Time-aware language models (Dhingra et al. 2022)",
            "agent_description": "Approach that treats language models as temporal knowledge bases by curating temporally-annotated datasets and training models to be more temporally aware of facts.",
            "memory_used": null,
            "memory_type": "dataset annotation / temporal training (not explicit external memory)",
            "memory_mechanism_description": "Improves a model's temporal knowledge via temporally-annotated training data rather than a modifiable external memory; cited as related work addressing temporal information challenges.",
            "task_name": "Temporal fact tasks / temporal knowledge benchmarks",
            "task_description": "Tasks that require awareness of time-dependent facts and changes (e.g., who is current president), challenging for static LM parameters.",
            "task_type": "question answering / temporal knowledge",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": false,
            "key_findings": "Temporal annotation and training can improve temporal awareness; RET-LLM offers an alternative by using an updatable external memory to handle changing facts.",
            "limitations_or_challenges": "Temporal training does not provide an easy means to update facts post-training; memory-based approaches are complementary.",
            "uuid": "e3188.7",
            "source_info": {
                "paper_title": "RET-LLM: Towards a General Read-Write Memory for Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Memllm: Finetuning llms to use an explicit read-write memory",
            "rating": 2
        },
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior",
            "rating": 2
        },
        {
            "paper_title": "Memorizing transformers",
            "rating": 2
        },
        {
            "paper_title": "Training language models with memory augmentation",
            "rating": 2
        },
        {
            "paper_title": "Toolformer: Language models can teach themselves to use tools",
            "rating": 1
        },
        {
            "paper_title": "Time-aware language models as temporal knowledge bases",
            "rating": 1
        },
        {
            "paper_title": "Language model with plug-in knowldge memory",
            "rating": 1
        }
    ],
    "cost": 0.012709999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>RET-LLM: Towards a General Read-Write Memory for Large Language Models</h1>
<p>Note: This concept paper outlines an initial methodology, now evolved and thoroughly evaluated in MemLLM. ${ }^{\dagger}$<br>Ali Modarressi ${ }^{1,2 <em>}$ Ayyoob Imani ${ }^{1,2 </em>}$ Mohsen Fayyaz ${ }^{3}$ Hinrich Schtze ${ }^{1,2}$<br>${ }^{1}$ Center for Information and Language Processing, LMU Munich, Germany<br>${ }^{2}$ Munich Center for Machine Learning, Germany ${ }^{3}$ Microsoft, Berlin, Germany<br>{amodaresi, ayyoob}@cis.lmu.de</p>
<h4>Abstract</h4>
<p>Large language models (LLMs) have significantly advanced the field of natural language processing (NLP) through their extensive parameters and comprehensive data utilization. However, existing LLMs lack a dedicated memory unit, limiting their ability to explicitly store and retrieve knowledge for various tasks. In this paper, we propose RET-LLM a novel framework that equips LLMs with a general write-read memory unit, allowing them to extract, store, and recall knowledge from the text as needed for task performance. Inspired by Davidsonian semantics theory, we extract and save knowledge in the form of triplets. The memory unit is designed to be scalable, aggregatable, updatable, and interpretable. Through qualitative evaluations, we demonstrate the superiority of our proposed framework over baseline approaches in question answering tasks. Moreover, our framework exhibits robust performance in handling temporal-based question answering tasks, showcasing its ability to effectively manage time-dependent information.</p>
<h2>1 Introduction</h2>
<p>Large language models (LLMs) have significantly advanced the field of natural language processing (NLP) in recent years (Bubeck et al., 2023; Chowdhery et al., 2022; Touvron et al., 2023). With their vast parameter count and access to extensive data, LLMs have demonstrated remarkable accuracy across various tasks. However, current state-of-the-art LLMs lack a dedicated memory unit. Instead, they are trained to predict words based on context, encoding knowledge implicitly in their parameters, which differs from the ideal memory function.</p>
<p>An ideal memory unit should possess certain characteristics. Firstly, it should allow for read and</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: An overview of RET-LLM. A user could prompt with (A): an informative sentence and our approach stores potent information from it inside the memory or (B): a question where previously saved information should be utilized to generate a valid answer.
write operations, enabling the language model to interact with stored knowledge. Scalability is also crucial, as the memory unit should accommodate the consistently evolving nature of knowledge. Furthermore, the memory unit should not be limited to textual documents alone; it should be capable of acquiring knowledge from diverse sources such as database systems. Interpretabilty is desired, granting insight into the specific knowledge required by the LLM to solve a given task. Lastly, the information stored in the memory unit should be aggregatable, enabling the model to combine related information across multiple documents. For instance an LLM should be able to list all cities of a country mentioned in multiple documents.</p>
<p>Previous attempts to incorporate memory into LLMs have fallen short in capturing the complete range of memory characteristics. For example, (Zhong et al., 2022; Wu et al., 2022) and (Cheng et al.) degrade the memory as the ability to retrieve relevant documents for a given query context, and adding them to the context when generating answers. Park et al. (2023) merely stores and retrieves previous observations and reflections of a generative agent in a simulated environment.</p>
<p>To address these limitations, we introduce RETLLM, (Retentive LLM) a solution that endows</p>
<p>LLMs with a scalable, updatable, interpretable, and aggregatable memory module. Our proposal involves equipping language models with a memory module, which allows them to extract knowledge from text and save it for future reference. When faced with a task, the LLM can query the memory module for additional information to support its response. The memory module supports updates and can incorporate information from non-textual sources such as SQL and no-SQL databases and spreadsheets. Furthermore, it enables aggregation of various pieces of information related to a particular concept scattered in a huge document or within multiple documents.</p>
<p>Figure 1 shows the architecture of RET-LLM. It comprises three components: an LLM, a controller, and a memory unit. We employ Alpaca Taori et al. (2023), a recently released instruction-tuned language model (LLM), and design a fine-tuning process to enable it to acquire the following abilities: information extraction, information lookup, and fact-based answer generation.</p>
<p>Information extraction entails the identification and extraction of triplets in the form of <concept1, relationship, concept2> from informative sentences. The information lookup task involves querying the memory unit to acquire additional information concerning a given concept and its associated relationships when confronted with tasks necessitating further information. Lastly, fact-based answer generation involves generating a final answer based on the retrieved information. The triplet-based storage approach draws inspiration from the theoretical framework of Davidsonian semantics (Davidson, 1967), which provides a foundation for representing concepts described in sentences using a tripletlike structure of <event, subject, object>.</p>
<p>The memory module stores the triplets and their vector representations. During retrieval, it first searches for an exact match of the query text and resorts to a fuzzy search based on vector representations if no exact match is found. For efficient fuzzy search and retrieval, we employ LSH-based hashing of vector representations. The controller acts as an interface, automating interactions between users, the LLM, and the memory module, ensuring a seamless interaction experience with an intelligent chat system.</p>
<p>Our proposed approach offers several advantages over previous methods. It enables LLMs to explicitly store and retrieve knowledge, which is crucial
for real-world NLP applications. By incorporating explicit knowledge storage and retrieval, we gain better understanding of the workings of these models and the knowledge they rely on to solve tasks. The use of an external memory unit separate from the LLM ensures scalability and easy modification of stored information. The fuzzy search technique enables efficient retrieval of relevant information, even in the absence of exact matches. Storing information in triplets facilitates the generation of precise and comprehensive solutions, particularly when data aggregation is necessary. Lastly, the memory module allows for easy incorporation of information from diverse sources and accommodates changing facts over time.</p>
<p>Over a qualitative evaluation using question answering examples, we demonstrate cases where a comparable LLM such as Alpaca-7B fails to return a correct answer. We show that this shortcoming occurs while the model has access to all the information required for generating a valid answer. However, in our proposed approach after storing the extractable knowledge from the context, the RET-LLM shows its capability in answering a question without the need of reinputting the context. We also demonstrate that RET-LLM could handle temporal based QA examples. Since it is equipped with a modifiable memory which could handle temporal facts.</p>
<h2>2 Related Works</h2>
<p>Prior works in the field have explored incorporating relevant context into large language models (LLMs) by retrieving and adding relevant documents to the task's context. Zhong et al. (2022) propose training LLMs with memory augmentation by introducing trainable memory units that are optimized during the training process. Wu et al. (2022) presents the Memorizing Transformer, which can attend to longer documents during inference. This approach stores (Key, Value) pairs, extracted from a transformer layer, in a memory and retrieves relevant pairs to add them to the current context during generation. (Cheng et al.) encode each documents, save them, and retrieve relevant documents based on the current context. In contrast to these approaches, our method offers improved scalability as we do not modify the architecture of the LLM. Instead, we suggest extracting and saving information from documents, allowing for the aggregation of extracted information from multiple sources.</p>
<p>This enables us to provide more relevant and concise retrieved information that is closely aligned with the specific question being addressed.</p>
<p>Park et al. (2023) utilizes an LLM within a generative agent framework to facilitate the storage and dynamic retrieval of a comprehensive record of the agent's experiences using natural language. However, there exists a fundamental distinction between their architecture and ours. In Park's framework, the memory component is an inherent part of the agent itself, while the LLM serves as an external tool employed solely for planning the agent's behaviors. Consequently, the LLM lacks control over the specific content to be stored and retrieved within the agent's memory.</p>
<p>Dhingra et al. (2022) contribute to the field by curating a dataset specifically designed to differentiate between temporal and non-temporal facts. They propose training language models on temporally annotated data to enhance their temporal awareness. This work aligns with our research focus on addressing temporal information challenges. However, in our proposed solution, we address these challenges by introducing an updatable memory module.</p>
<p>Schick et al. (2023) present a methodology that empowers LLMs to leverage external tools by generating API calls to access additional functionalities, such as using a calculator for task execution. Our work shares similarities with their approach in terms of teaching the LLM to utilize an external tool. However, it should be noted that our focus lies on incorporating a more intricate and influential tool, namely the memory module, which has the potential to significantly impact the LLM's output.</p>
<h2>3 Approach</h2>
<p>We aim to design a RET-LLM where the user can perform two actions: (1): Provide one or a series of informative statements where the RET-LLM should be able to memorize the containing information. Previous methods perform this task by either training/fine-tuning the LLM over the provided document or creating a vector representation for the document and storing the representation. (2): Asking related questions which the RET-LLM would answer based on the stored memory. All these actions should function in a seamless setting where the user should only interact in natural language.</p>
<p>Our RET-LLM is constituted by three main com-
ponents: (1) Controller, (2): Fine-tuned LLM \&amp; (3): Memory. As shown in Figure 1, the controller moderates the flow of information between the user, the LLM and the memory. The LLM acts as a processing unit, where it receives the texts passed by the controller and figures where it needs to invoke a memory call or not. Since the LLM operates with text, inspired by Schick et al. (2023), we standardized the memory calls by implementing a text-based API schema. Therefore the LLM could generate memory API calls and the controller could apply the LLM API calls to the memory. In our setting, the memory stores data in triplets by using a three-columned table. This is based on the theoretical framework of Davidsonian semantics (Davidson, 1967), where concepts described in sentences could be stored in a structure of <first argument, relation, second argument>.</p>
<p>In the following we describe RET-LLM in more detail. The memory-API, how we finetune the LLM to become capable of these calls and the memory structure.</p>
<h3>3.1 Memory Structure</h3>
<p>Each triplet defines a relationship between two arguments with the following format: $\left\langle t_{1}, t_{2}, t_{3}\right\rangle$ where $t_{1}$ is the first argument, $t_{2}$ is the relation and $t_{3}$ is the second argument in the relationship. For instance in the sentence: "Mark Zuckerberg is the CEO of Meta Inc." the informative triplet that could be extracted is: (Mark Zuckerberg, CEO, Meta Inc.).</p>
<p>To store these triplets we use a three-columned table where each column is associated with each part of the triplet. Alongside saving the texts, we store the average representations so that the memory could also handle queries which have semantically similar words. If the memory module fails to find the exact text in the table, it checks for similar texts by comparing the vector representation of the query text with vector representations of text peices already stored in the dataset. Therefore for every $t_{i}$ the mean representation retrieved by the $\operatorname{LLM}\left(\boldsymbol{h}<em i="i">{A V G}\left(t</em>\right)\right)$ is stored in a Locality-Sensitive Hashing (LSH) table. The reason of utilizing LSH is to reduce the computation required for finding similar representations. Without a hash table for a given query representation, the distances to all of the stored representations should be computed which would be a computationally-expensive task.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" />
(a) Memory-Write scenario: (1) Controller passes the input to the LLM (2) which generates the appropiate memory write call. (3) The controller gives the data (and their average represntations) to the memory to be stored.
<img alt="img-2.jpeg" src="img-2.jpeg" />
(b) Memory-Read scenario: (1) Controller passes the question to the LLM (2) which generates the appropiate memory read call. (3) The controller apply the query on the memory with the given search terms from the LLM. (4) The memory returns the query results which are (5) forwarded back to the LLM. (6) The LLM generates the answer to the question using the query results and (7) the answer would be returned back to the user.</p>
<p>Figure 2: A visualization of the process in both read- and write-based inputs.</p>
<p>Handling Memory Queries. In a memory query, one or two of the triplet parameters should be provided as input:</p>
<p>$$
\mathcal{Q} \in\left{\left\langle q_{1}\right\rangle,\left\langle q_{2}\right\rangle,\left\langle q_{3}\right\rangle,\left\langle q_{1}, q_{2}\right\rangle,\left\langle q_{1}, q_{3}\right\rangle,\left\langle q_{2}, q_{3}\right\rangle\right}
$$</p>
<p>Where $q_{i}$ is the search term for the $i$-th parameter in the stored tuples. Before retrieving the query results, each search term is checked For a given $\mathcal{Q}$, first the memory checks whether the search terms $\left(q_{i}\right)$ have an exact match in the storage table. If $q_{i}$ does not exist in the stored terms, we use its average representation $\boldsymbol{h}<em i="i">{A V G}\left(q</em>}\right)$ and the LSH table for an alternative term $\left(\hat{q<em i="i">{i}\right)$ that has an exact match in out memory table. Possibly, the LSH table may not find an alternative term for the given representation, therefore the query would not have a result: $\mathcal{Q} \rightarrow \emptyset$. In any case (exact match or similar match), the query might have multiple matches in the data table $\left(q</em>\right)$. In this case all resulting triplets would be returned as the query output.}=t_{i</p>
<h3>3.2 Memory-API \&amp; Dataflow</h3>
<p>To enable communication between the memory and the LLM, we design an API schema for memory read and write functions. This API allows the controller to understand when the LLM is calling the memory and what parameters should be passed. Based on the triplets discussed in the previous section, the two memory calls are as the following:</p>
<ul>
<li>[MEM_WRITE $\left{t_{1} \gg t_{2} \gg t_{3}\right}$ ]: This structure is for storing a triplet $\left\langle t_{1}, t_{2}, t_{3}\right\rangle$. Depending on the prompt, multiple write calls could be sequentially generated by the LLM to store multiple triplets extracted from a text.</li>
<li>[MEM_READ $\left{_\right}<em -="-">{-} \gg</em>$ atleast one of them should be filled with the search terms. Based on the query results from the memory, one or a list of triplets could be returned as shown in the highlighted segment.}\right}:\left{t_{1} \gg t_{2} \gg t_{3}\right} ; \ldots$ ] : In a memory read, as shown in the API, there are three placeholders that based on $\mathcal{Q</li>
</ul>
<p>Figure 2 demonstrates how RET-LLM operates using the memory-API. Depending on the input given by the user, RET-LLM either have to read or write information from or to the memory. If the user prompt an informative statement (or ideally a full document), it would be memory write scenario. On the other hand, by having a question in the input, we consider this to be a memory read case. In both cases the user input is the first input to RET-LLM that is passed on to the LLM.</p>
<p>Based on the given input the LLM infers and generates the relevant API call. With a memory write case, after the API call is generated the controller detects it and invoke a memory storation function with the given parameters. The memory receives the data in a triplet format and stores it for future usage. If a memory read call is generated by the LLM, the controller also detects it and pauses the model's sequence generation for the memory retrieval. It uses the parameters given inside the read call as the query terms and passes them to the memory. The memory lists all stored triplets that feature the given search terms (or a semantically similar version of them according to $\S 3.1$ ) and return the results back to the controller. Using the API discussed in the beginning of this section, the read results are listed after the call so that the LLM could use them to produce a naturally sounded answer. After the answer is produced it is returned back to the user.</p>
<p>As the controller is in between of the user and the LLM, it could hide the whole memory-API schema. This would make the user feel an end-to-end simple language modeling experience without knowing the memory functionality behind the scene.</p>
<h3>3.3 Finetuning the LLM</h3>
<p>In this part we discuss how the LLM is finetuned to be capable of generating memory-API calls. In the end the LLM should be capable of detecting which type of memory call (read or write) it should provoke based on the input. As stated in Section 3.2, the LLM's input may have one of the two previously discussed structures depending on the memory function. Therefore the LLM should be able to generate and handle this API to store or read the relevant information. To this end, we develop a synthetic dataset to train the LLM. The synthetic task is to learn the relationships of the discussed people with the respective corporations. Based on the stored information, RET-LLM should be
capable of answering any questions regarding the people, the corporations or the relationships.</p>
<p>We use a set of firstname and lastnames to generate a synthetic population, called $\mathcal{P}$. Each person from this population per $\in \mathcal{P}$ could have only one relationship from the following list: $r e l \in \mathcal{R}={$ employment, manager, investor, founder, customer $}$ with an organization $\operatorname{org} \in$ $\mathcal{O}$. Where $\mathcal{O}$ is a set of corporation names. Hence, each triplet would be as: $(p e r, r e l, o r g)$. For instance: $\langle$ Dominick Alphonso, employment, BMW $\rangle .{ }^{1}$ Based on this triplet we can build three triplet-specific questions:</p>
<ul>
<li>$\mathcal{Q}=\langle$ per $\rangle$, e.g. "Who is Dominick Alphonso?"</li>
<li>$\mathcal{Q}=\langle$ per, org $\rangle$, e.g. "How Dominick Alphonso is related to BMW?"</li>
<li>$\mathcal{Q}=\langle$ per, rel $\rangle$, e.g. "Dominick Alphonso is employed by which company?"
and the answer to all above should be "Dominick Alphonso is employed by BMW.". Alongside these questions three other types of questions could be asked that could be relevant to multiple triplets:</li>
<li>$\mathcal{Q}=\langle r e l\rangle$, e.g. "Who are the employees?"</li>
<li>$\mathcal{Q}=\langle o r g\rangle$, e.g. "Who are related to BMW?"</li>
<li>$\mathcal{Q}=\langle r e l, o r g\rangle$, e.g. "Who are employed by BMW?"</li>
</ul>
<p>Unlike the first three, each of these questions could have multiple persons related to the answer. For each of these questions we expect the model answer the questions without any extra information (e.g. stating the corporation of employment when its not asked). To create a training data instance from these questions based on the memory-API, we use the templates stated in Table 1. During finetuning the Question, API query (with the MEM_READ command), API Response and the answer are concatenated as the data input for the LLM. However, the langauge modeling loss is only applied to the API query and Answer sections. Since these two segments are the text sequences that the LLM is expected to generate based on the other two segments (Question \&amp; API Response) that are provided by the controller.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th>Query Type</th>
<th>Question</th>
<th>API Query</th>
<th>API Response</th>
<th>Answer</th>
</tr>
</thead>
<tbody>
<tr>
<td>$\langle per\rangle$</td>
<td>Who is per?</td>
<td>${p e r * *\rangle$ :</td>
<td>${p e r * r e 1 * o r g}$</td>
<td>per is rel to org.</td>
</tr>
<tr>
<td>$\langle per,org\rangle$</td>
<td>How per is related to org?</td>
<td>${p e r * * o r g}$ :</td>
<td>${p e r * r e 1 * o r g}$</td>
<td>per is rel to org.</td>
</tr>
<tr>
<td>$\langle per,rel\rangle$</td>
<td>per is rel which company?</td>
<td>${p e r * r e 1 *\rangle$ :</td>
<td>${p e r * r e 1 * o r g}$</td>
<td>per is rel to org.</td>
</tr>
<tr>
<td>$\langle org\rangle$</td>
<td>Who are related to org?</td>
<td>${* * o r g}$ :</td>
<td>${\mathrm{per}<em 1="1">{1} * \mathrm{rel}</em>} * \mathrm{org}} ;\left{\mathrm{per<em 2="2">{2} * \mathrm{rel}</em>\right} ; \ldots$} * \mathrm{org</td>
<td>${\mathrm{per}<em 2="2">{1}, \mathrm{per}</em>, \ldots}$ is/are related to org.</td>
</tr>
<tr>
<td>$\langle rel\rangle$</td>
<td>Who are the rel?</td>
<td>${<em> \mathrm{rel} </em>\rangle$ :</td>
<td>$\left{\mathrm{per}<em 1="1">{1} * \mathrm{rel}<em>{</em>} \mathrm{org}</em>}\right} ;\left{\mathrm{per<em 2="2">{2} * \mathrm{rel}<em>{</em>} \mathrm{org}</em>\right} ; \ldots$</td>
<td>${\mathrm{per}<em 2="2">{1}, \mathrm{per}</em>, \ldots}$ is/are rel.</td>
</tr>
<tr>
<td>$\langle org, rel\rangle$</td>
<td>Who are rel org?</td>
<td>${* \mathrm{rel} * \mathrm{org}}$ :</td>
<td>$\left{\mathrm{per}<em 2="2">{1} * \mathrm{rel}<em>{</em>} \mathrm{org}\right} ;\left{\mathrm{per}</em>} * \mathrm{rel<em>{</em>} \mathrm{org}\right} ; \ldots$</td>
<td>$\left{\mathrm{per}<em 2="2">{1}, \mathrm{per}</em>, \ldots\right}$ is/are rel to org.</td>
</tr>
</tbody>
</table>
<p>Table 1: Memory read data examples for finetuning. The first three types of questions are based on a single triplet therefore the API response would be only one triplet. However the second three may have multiple relevant tiplets stored in the memory as shown in their API-Resonse. Thus, the answer should combine the triplets data into a single sentence. $\left[\mathrm{per}<em 2="2">{1}, \mathrm{per}</em>, \ldots\right]$ is the placeholder of the names written sequentially in a natural way. For instance: "Dirk Alosa, Ty Baumkirchner, and Vera Bayless"</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Triplet(s)</th>
<th style="text-align: left;">Statement</th>
<th style="text-align: left;">API Write Call(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">$\left[\left(\mathrm{per}<em 2="2">{1}, \mathrm{rel}, \mathrm{org}\right),\left(\mathrm{per}</em>\right), \ldots\right]$}, \mathrm{rel}, \mathrm{org</td>
<td style="text-align: left;">$\left[\mathrm{per}<em 2="2">{1}, \mathrm{per}</em>, \ldots\right]$ is/are rel to org.</td>
<td style="text-align: left;">$\left[\mathrm{MEM} _\right.$WRITE $\left(\mathrm{per}<em 1="1">{1} * \mathrm{rel}</em>} * \mathrm{org}\right) \mathrm{][MEM} _\right.$WRITE $\left(\mathrm{per<em 2="2">{2} * \mathrm{rel}</em> \ldots$} * \mathrm{org}\right) \mathrm{]</td>
</tr>
</tbody>
</table>
<p>Table 2: Memory write data example structure for finetuning.</p>
<p>As we also need informative examples where have MEM_WRITE calls, we use a similar strategy by using the population, organizations and relations that were previously defined $(\mathcal{P}, \mathcal{Q}, \mathcal{R})$. Based on the memory-API, in a memory write scenario the RET-LLM receives a sentence which here contains a relationship information and then the LLM should generate the corresponding memory write calls. In our dataset we opted to build examples where it states about multiple people whom have the same relationship with the same company: $\left(\mathrm{per}_{i}, \mathrm{rel}, \mathrm{org}\right)$. The template for the memory write data examples are shown in Table 2. Similar to the question-based examples, the statement and the API call are concatenated to form the full input sequence. Also the loss function is applied only to the API segment, since the first part is provided by the controller.</p>
<p>We opted to use the Instruction-following Alpaca-7B model (Taori et al., 2023) as a base model for our finetuning. To execute the training in a resource limited setup, we use low-rank adaptation (LoRA) (Hu et al., 2022). ${ }^{2}$ This parameter efficient measure allows us to finetune the base model on a single A6000 48GB GPU.</p>
<h2>4 Qualitative Results</h2>
<p>In this part, we present the internal process and final output on multiple evaluation examples. These examples were generated with the same procedure stated in $\S 3.3$. First to demonstrate the importance of our approach, we provide the same example to</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>our base model (Alpaca-7B) in a zero-shot setting. The input would be a short instruction for the task, the informative sentences from the example and in the end is the question. As shown in Figure 3, the zero-shot result from the instruction tuned model is clearly incorrect. While the model does have all the information in its context, its still produces an incorrect response.</p>
<p>In thie same example, the RET-LLM first stores the extracted triplets from the examples into the memory. After storing the extracted relationships, the RET-LLM could respond to the same question even without having the information in the input. With the help of the memory-API and the memory itself, the relevant triplet is found. The LLM manages to answer correctly after appending the query result to the memory call.</p>
<p>One potential use cases of our approach is in answering questions that have a temporal context. For example, the presidency of the United States undergoes a change every 4 to 8 years. A normal PLM model answers the question about the presidency based on its own training data. While model retraining or parameter editing has its own challenges, our approach could provide an easy and interpretable solution for this issue (Figure 4).</p>
<h2>5 Conclusion \&amp; Future Work</h2>
<p>In this work, we introduced a RET-LLM capable of storing information and retrieving it in further use. With a triplet based memory structure, information are stored in relationships between two arguments with a known relation. The memory could be utilized via a memory-API which is generated</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 3: An example that has an incorrect result in a zero-shot setting and a correct one in our approach. Note that in the zero-shot setting the model has direct access to the information required for answering the question in its input and still end up with an incorrect answer. However, in our approach each of the user prompts could be given to the RET-LLM in separately. Another example is mentioned in the appendix Figure 5.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 4: Asking a question which requires temporal context usually leads to an outdated answer as shown here with Alpaca. However, in our RET-LLM with the aid of a modifiable memory, these questions could be answered by simply providing a updated memory entry.</p>
<p>by a finetuned LLM. Using a controller, all components could communicate with each other and the user would interact with the controller being unbeknown of the behind process. We have shown that the LLM generates the proper API calls in some question answering examples without having the information in its input context. As this work is still under development, in our next revision we will add a more in-detail empirical evaluation, preferrably on a real dataset. We also seek to improve our finetuning method to a more generalized setting so that it could be capable of working with more types of informative relations.</p>
<h2>References</h2>
<p>Sbastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. 2023. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712.</p>
<p>Xin Cheng, Yankai Lin, Dongyan Zhao, and Rui Yan. Language model with plug-in knowldge memory.</p>
<p>Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. 2022. Palm: Scaling language modeling with pathways.</p>
<p>Donald Davidson. 1967. The logical form of action sentences, reprinted in d. davidson (1980) essays on actions and events.</p>
<p>Bhuwan Dhingra, Jeremy R. Cole, Julian Martin Eisenschlos, Daniel Gillick, Jacob Eisenstein, and William W. Cohen. 2022. Time-aware language models as temporal knowledge bases. Transactions of the Association for Computational Linguistics, 10:257273.</p>
<p>Edward J Hu, yelong shen, Phillip Wallis, Zeyuan AllenZhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations.</p>
<p>Ali Modarressi, Abdullatif Kksal, Ayyoob Imani, Mohsen Fayyaz, and Hinrich Schtze. 2024. Memllm: Finetuning llms to use an explicit read-write memory. arXiv preprint arXiv:2404.11672.</p>
<p>Joon Sung Park, Joseph C O'Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. 2023. Generative agents: Interactive simulacra of human behavior. arXiv preprint arXiv:2304.03442.</p>
<p>Timo Schick, Jane Dwivedi-Yu, Roberto Dess, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. Toolformer: Language models can teach themselves to use tools. arXiv preprint arXiv:2302.04761.</p>
<p>Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Stanford alpaca: An instruction-following llama model. https:// github.com/tatsu-lab/stanford_alpaca.</p>
<p>Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothe Lacroix, Baptiste Rozire, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. Llama: Open and efficient foundation language models.</p>
<p>Yuhuai Wu, Markus N Rabe, DeLesley Hutchins, and Christian Szegedy. 2022. Memorizing transformers. arXiv preprint arXiv:2203.08913.</p>
<p>Zexuan Zhong, Tao Lei, and Danqi Chen. 2022. Training language models with memory augmentation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 5657-5673, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.</p>
<h2>A Extra Evaluation Example</h2>
<h1>Evaluation Example #2 (Zero-Shot Setting - Alpaca-7B):</h1>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<h2>Evaluation Example #2:</h2>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 5: Another evaluation example that has an incorrect result in a zero-shot setting and a correct one in our approach.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ The code for finetuning a llama-based model using LoRA is available at: github.com/tloen/alpaca-lora&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>