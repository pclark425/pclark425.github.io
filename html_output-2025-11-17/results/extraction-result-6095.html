<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6095 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6095</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6095</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-121.html">extraction-schema-121</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, benchmarks, and results for evaluating LLM-generated scientific theories.</div>
                <p><strong>Paper ID:</strong> paper-bc7984bfcfae537dbe633eeeb8d69c42a994c724</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/bc7984bfcfae537dbe633eeeb8d69c42a994c724" target="_blank">ELLE: Efficient Lifelong Pre-training for Emerging Data</a></p>
                <p><strong>Paper Venue:</strong> Findings</p>
                <p><strong>Paper TL;DR:</strong> The proposed ELLE consists of function preserved model expansion, which flexibly expands an existing PLM’s width and depth to improve the efficiency of knowledge acquisition, and pre-trained domain prompts, which disentangle the versatile knowledge learned during pre-training and stimulate the proper knowledge for downstream tasks.</p>
                <p><strong>Paper Abstract:</strong> Current pre-trained language models (PLM) are typically trained with static data, ignoring that in real-world scenarios, streaming data of various sources may continuously grow. This requires PLMs to integrate the information from all the sources in a lifelong manner. Although this goal could be achieved by exhaustive pre-training on all the existing data, such a process is known to be computationally expensive. To this end, we propose ELLE, aiming at efficient lifelong pre-training for emerging data. Specifically, ELLE consists of (1) function preserved model expansion, which flexibly expands an existing PLM’s width and depth to improve the efficiency of knowledge acquisition; and (2) pre-trained domain prompts, which disentangle the versatile knowledge learned during pre-training and stimulate the proper knowledge for downstream tasks. We experiment ELLE with streaming data from 5 domains on BERT and GPT. The results show the superiority of ELLE over various lifelong learning baselines in both pre-training efficiency and downstream performances. The codes are publicly available at https://github.com/thunlp/ELLE.</p>
                <p><strong>Cost:</strong> 0.008</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6095",
    "paper_id": "paper-bc7984bfcfae537dbe633eeeb8d69c42a994c724",
    "extraction_schema_id": "extraction-schema-121",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00758925,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>ELLE: Efficient Lifelong Pre-training for Emerging Data</h1>
<p>Yujia Qin ${ }^{1,2,3 <em>}$, Jiajie Zhang ${ }^{1,2,3 </em>}$, Yankai Lin ${ }^{4}$, Zhiyuan Liu ${ }^{1,2,3,5,6}$, ${ }^{1}$ Peng Li ${ }^{7}$, Maosong Sun ${ }^{1,2,3,5,6,8 \dagger}$, Jie Zhou ${ }^{4}$<br>${ }^{1}$ Department of Computer Science and Technology, Tsinghua University, Beijing, China<br>${ }^{2}$ Beijing National Research Center for Information Science and Technology<br>${ }^{3}$ Institute for Artificial Intelligence, Tsinghua University, Beijing, China<br>${ }^{4}$ Pattern Recognition Center, WeChat AI, Tencent Inc.<br>${ }^{5}$ International Innovation Center of Tsinghua University, Shanghai, China<br>${ }^{6}$ Beijing Academy of Artificial Intelligence<br>${ }^{7}$ Institute for AI Industry Research (AIR), Tsinghua University, China.<br>${ }^{8}$ Jiangsu Collaborative Innovation Center for Language Ability, Xuzhou, China<br>{qyj20,jiajie-z19}@mails.tsinghua.edu.cn</p>
<h4>Abstract</h4>
<p>Current pre-trained language models (PLM) are typically trained with static data, ignoring that in real-world scenarios, streaming data of various sources may continuously grow. This requires PLMs to integrate the information from all the sources in a lifelong manner. Although this goal could be achieved by exhaustive pretraining on all the existing data, such a process is known to be computationally expensive. To this end, we propose ELLE, aiming at efficient lifelong pre-training for emerging data. Specifically, ELLE consists of (1) function preserved model expansion, which flexibly expands an existing PLM's width and depth to improve the efficiency of knowledge acquisition; and (2) pre-trained domain prompts, which disentangle the versatile knowledge learned during pretraining and stimulate the proper knowledge for downstream tasks. We experiment ELLE with streaming data from 5 domains on BERT and GPT. The results show the superiority of ELLE over various lifelong learning baselines in both pre-training efficiency and downstream performances. The codes are publicly available at https://github.com/thunlp/ELLE.</p>
<h2>1 Introduction</h2>
<p>Pre-trained language models (PLM) have broken the glass ceiling for various natural language processing (NLP) tasks (Radford et al., 2018; Devlin et al., 2019; Han et al., 2021). However, most of the existing PLMs are typically trained with a static snapshot of the web information, ignoring that in real-world scenarios, streaming data</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>from various sources may continuously grow, e.g., the gatherings of literary works (Zhu et al., 2015), news articles (Zellers et al., 2019) and science papers (Lo et al., 2020). In addition, the distribution of incoming data may also vary over time. This requires PLMs to continually integrate the information from all the sources to grasp the versatile structural and semantic knowledge comprehensively, so that PLMs could utilize the proper knowledge to boost the performance in various downstream tasks.</p>
<p>A simple yet effective way to integrate all the information is to pre-train PLMs on all the existing data exhaustively. However, such a process is computationally expensive (Schwartz et al., 2019), especially under the information explosion era when tremendous data is continually collected. This leaves us an important question: with limited computational resources, how can we efficiently adapt PLMs in a lifelong manner? We formulate it as the efficient lifelong pre-training problem. Similar to conventional lifelong learning, PLMs are expected to continually abosrb knowledge from emerging data, and in the meantime, mitigate the catastrophic forgetting (McCloskey and Cohen, 20p) on previously learned knowledge.</p>
<p>In addition, efficient lifelong pre-training poses two new challenges: (1) efficient knowledge growth. When the overall data scale accumulates to a certain magnitude, packing more knowledge into a fixed-sized PLM becomes increasingly hard, which significantly impacts the efficiency of PLM's knowledge growth. This is because larger PLMs show superior sample efficiency and training efficiency over their smaller counterparts (Kaplan et al., 2020; Li et al., 2020) due to overparameterization (Arora et al., 2018). That is, larger PLMs learn knowledge in a more efficient way. Therefore,</p>
<p>timely model expansions are essential for efficient knowledge growth; (2) proper knowledge stimulation. During pre-training, various knowledge from all domains is packed into PLMs hastily. However, a certain downstream task may largely require the knowledge from a specific domain. Thus it is essential for PLMs to disentangle different kinds of knowledge and properly stimulate the needed knowledge for each task.</p>
<p>In this paper, we propose ELLE, targeting at Efficient LifeLong pre-training for Emerging data. Specifically, (1) to facilitate the efficiency of knowledge growth, we propose the function preserved model expansion to flexibly expand an existing PLM's width and depth. In this way, we increase PLM's model size and thus improve its training efficiency. Before being adapted to a new domain, the expanded PLM performs a function recovering warmup to regain the functionality of the original PLM; (2) for proper knowledge stimulation, we pre-implant domain prompts during pre-training to prime the PLM which kind of knowledge it is learning. Therefore, versatile knowledge from multiple sources can be disentangled. During downstream fine-tuning, we could further utilize these implanted prompts and manipulate the PLM to stimulate the proper knowledge for a specific task.</p>
<p>To demonstrate the effectiveness of ELLE, we simulate the scenario where streaming data from 5 domains sequentially comes. We pre-train two typical PLMs (BERT and GPT) and expand their model sizes each time when the new data is available. We experiment when the number of parameters is sequentially grown from both 30 M to 125 M and 125 M to 355 M . The experimental results show the superiority of ELLE over multiple lifelong learning baselines in both pre-training efficiency and downstream task performances. In addition, we conduct sufficient experiments to verify the effectiveness of each component of ELLE. In general, we provide a promising research direction and hope this work could inspire more future attempts towards efficient lifelong pre-training.</p>
<h2>2 Related Work</h2>
<p>Lifelong Learning for PLMs. Lifelong learning aims at incrementally acquiring new knowledge, and in the meantime, mitigating the catastrophic forgetting issue. Numerous efforts have been spent towards this goal, including (1) memory-based methods (Rebuffi et al., 2017; Rolnick et al., 2019),
which perform experience replay with authentic data (de Masson d'Autume et al., 2019), automatically generated data (Sun et al., 2020), or previously computed gradients (Lopez-Paz and Ranzato, 2017) conserved in the memory, (2) consolidationbased methods (Kirkpatrick et al., 2017; Aljundi et al., 2018), which introduce additional regularization terms to consolidate the model parameters that are important to previous tasks, and (3) dynamic architecture methods (Rusu et al., 2016; Yoon et al., 2018), which fix trained network architectures in old tasks and dynamically grow branches for new tasks. Lifelong learning is also a hot topic for PLMs. Some target at domain adaptation through continual pre-training (Gururangan et al., 2020), parameter-efficient adapters (He et al., 2021) and sparse expert models (Gururangan et al., 2021). Others focus on the incremental acquisition of factual knowledge that changes over time (Dhingra et al., 2021; Jang et al., 2021). However, the existing works seldom consider our lifelong learning setting where streaming data from multiple sources is sequentially gathered. Recently, researchers have also conducted a series of empirical studies on the continual learning of PLMs (Wu et al., 2021; Jin et al., 2021).</p>
<p>Efficient Pre-training in NLP. Many attempts have been made towards improving the efficiency of pre-training, such as designing novel pretraining tasks (Clark et al., 2020), model architectures (Zhang and He, 2020), optimization algorithms (You et al., 2020) and parallel architectures (Shoeybi et al., 2019; Shazeer et al., 2018). Until recently, researchers propose to "back distill" the knowledge from existing PLMs to accelerate large PLMs' pre-training (Qin et al., 2021a). Another line of work proposes progressive training to dynamically expand an existing PLM's size through parameter recycling (Gong et al., 2019; Gu et al., 2021; Chen et al., 2021). However, these methods typically focus on training PLMs on one static corpus, and thus cannot be directly applied to our lifelong pre-training setting.</p>
<h2>3 Methodology</h2>
<h3>3.1 Preliminaries</h3>
<p>Background for PLM. A PLM $\mathcal{M}$ generally consists of an embedding layer and $L$ Transformer (Vaswani et al., 2017) layers. Given an input $\mathbf{x}$ consisting of a series of tokens, i.e.,</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Illustration of ELLE when adapting an existing PLM $\mathcal{M}<em i-1="i-1">{i-1}$ trained on previous data $\overline{\mathcal{D}}</em>}$ to a new corpus $\mathcal{D<em 1="1">{i}$. We also visualize the mechanism of width / depth expansion and pre-trained domain prompts.
$\mathbf{x}=\left{w</em>}, \ldots, w_{|\mathbf{x}|}\right}, \mathcal{M}$ first converts the input into embeddings $\left{\mathbf{h<em _mathbf_x="|\mathbf{x">{1}^{0}, \ldots, \mathbf{h}</em>}|}^{0}\right}$, which are sequentially processed by each Transformer layer into contextualized hidden representations $\mathbf{H}^{l}=$ $\left{\mathbf{h<em _mathbf_x="|\mathbf{x">{1}^{l}, \ldots, \mathbf{h}</em>\right}$, where $1 \leq l \leq L$.}|}^{l</p>
<p>Task Definition. Assume a stream of corpus $\overline{\mathcal{D}}<em N="N">{N}$ from $N$ domains (e.g., news articles, web content and literary works) is sequentially gathered, i.e., $\overline{\mathcal{D}}</em>}=\left{\mathcal{D<em N="N">{1}, \ldots, \mathcal{D}</em>}\right}$, where $\mathcal{D<em i="i">{i}=\left{\mathbf{x}</em>\right}}^{j<em 1="1">{j=1}^{|\mathcal{D}|}$. The whole training process can be partitioned into several stages. Initially, we have a PLM $\mathcal{M}</em>}$, which has been well trained on $\mathcal{D<em i="i">{1}$, and for the $i$-th stage ( $i&gt;1$ ), we obtain a new collection of data $\mathcal{D}</em>}$. Assume in this stage, we only have limited computational resources $\mathcal{R<em i-1="i-1">{i}$, our goal is to continually pretrain the existing PLM $\mathcal{M}</em>}$ to learn new knowledge on $\mathcal{D<em i="i">{i}$, and obtain a new PLM $\mathcal{M}</em>}$. Meanwhile, we expect the adapted PLM $\mathcal{M<em i-1="i-1">{i}$ should not forget the previously learned knowledge of $\overline{\mathcal{D}}</em>$.</p>
<p>Overall Framework. As illustrated in Figure 1, starting from $\mathcal{M}<em i-1="i-1">{i-1}$, which is trained on previous data $\overline{\mathcal{D}}</em>}$, we first expand $\mathcal{M<em i-1="i-1">{i-1}$ 's width and depth and construct an enlarged PLM $\mathcal{M}</em>}^{\mathrm{WD}}$ to improve its training efficiency. Then we perform function recovering warmup and train $\mathcal{M<em i-1="i-1">{i-1}^{\mathrm{WD}}$ to inherit the knowledge of $\mathcal{M}</em>}$ to obtain $\mathcal{M<em i="i">{i-1}^{\mathrm{WD} <em>}$. The above procedures are dubbed as function preserved model expansion (§ 3.2). After that, we continually pre-train $\mathcal{M}_{i-1}^{\mathrm{WD} </em>}$ to gain new knowledge on $\mathcal{D}</em>}$. To mitigate the catastrophic forgetting on the previously learned knowledge, we employ data-based memory replay on a subset of previously gathered data $\overline{\mathcal{D}<em 1="1">{i-1}^{e u b}=\left{\mathcal{D}</em>}^{e u b}, \ldots, \mathcal{D<em k="k">{i-1}^{e u b}\right}$ conserved in the memory, where $\mathcal{D}</em>$ $(1 \leq k \leq i-1)$ and $B$ is the constrained memory size for each domain. To help PLMs disentangle the knowledge during pre-training and also stimulate the needed knowledge for each downstream task, we implant domain prompts into PLMs during the whole training process (§ 3.3).}^{e u b}=\left{x_{k}^{1}, \ldots, x_{k}^{B}\right} \in \mathcal{D}_{k</p>
<h3>3.2 Function Preserved Model Expansion</h3>
<p>To accumulate knowledge more efficiently, each time when a new corpus $\mathcal{D}<em i-1="i-1">{i}$ comes, we expand both $\mathcal{M}</em>$ 's width and depth to attain the superior sample efficiency and fast convergence brought by larger model capacity (Li et al., 2020).</p>
<p>Width Expansion. For width expansion, we borrow the function preserving initialization (FPI) from Chen et al. (2021). For a brief introduction, FPI expands the matrices of all modules of a Transformer layer to arbitrary larger sizes and constructs an enlarged PLM $\mathcal{M}<em i-1="i-1">{i-1}^{\mathrm{W}} . \mathcal{M}</em>}^{\mathrm{W}}$ is initialized using the corresponding matrices of the original $\mathcal{M<em 1="1">{i-1}$ through parameter replication. For example, as visualized in Figure 1, the core principle of FPI is to divide the product of $o \times x</em>}$ into multiple partitions, e.g. $\frac{o}{2} \times x_{1}+\frac{o}{2} \times x_{1}$. Formally, FPI expands a matrix $\boldsymbol{W} \in \mathbb{R}^{h_{1} \times h_{2}}$ of $\mathcal{M<em 1="1">{i-1}$ to an enlarged matrix $\boldsymbol{W}^{\prime} \in \mathbb{R}^{\left(h</em>$ as follows:}+\Delta_{h_{1}}\right) \times h_{2}}$ of $\mathcal{M}_{i-1}^{\mathrm{W}</p>
<p>$$
\begin{aligned}
m(i) &amp; =\left{\begin{array}{lr}
i &amp; i \in\left[1, h_{1}\right] \
U\left(\left{1, \ldots, h_{1}\right}\right) &amp; i \in\left(h_{1}, h_{1}+\Delta_{h_{1}}\right]
\end{array}\right. \
C_{i} &amp; =\sum_{i^{\prime}=1}^{h_{1}+\Delta_{h_{1}}} \mathbb{1}\left(m\left(i^{\prime}\right)=m(i)\right) \
\boldsymbol{W}<em i="i">{(i, <em>}^{\prime} &amp; =\frac{1}{C_{i}} \cdot \boldsymbol{W}_{(m(i), </em>)}+\mathbb{1}\left(C</em>
\end{aligned}
$$}&gt;1\right) \cdot \boldsymbol{\delta}_{i</p>
<p>where $U(\cdot)$ denotes a uniform sampling function, $m(\cdot)$ denotes the mapping function between two matrices, $\mathbb{I}(\cdot)$ is an indicator function, $C_{i}$ counts how many partitions a specific neuron is splitted</p>
<p>and $\boldsymbol{\delta}<em 2="2">{i} \in \mathbb{R}^{h</em>}}$ is a random gaussian noise. FPI ensures that both $\mathcal{M<em i-1="i-1">{i-1}^{\mathrm{W}}$ and $\mathcal{M}</em>$ during initialization. These slight noises would break the symmetry after the replication and accelerate later pre-training.}$ have approximately the same functionality, i.e., both models have almost the same output given the same input. Besides function preservation, the initialized model could serve as a good starting point for further optimization. We refer readers to Chen et al. (2021) for more details about width expansion. Different from Chen et al. (2021), we additionally introduce random noises $\boldsymbol{\delta}_{i}$ into the newly copied parameters of $\boldsymbol{W}^{\prime</p>
<p>Depth Expansion. For depth expansion, previous works generally resort to stacking all the original PLM layers into $2 \times$ layers through parameter replication (Gong et al., 2019). Such initialization is demonstrated to improve training efficiency.</p>
<p>However, the above layer stacking method restricts the number of layers of the enlarged PLM $\mathcal{M}<em i-1="i-1">{i-1}^{\mathrm{D}}$ to be integer multiples of that of the original PLM $\mathcal{M}</em>}$, which is not flexible for practical uses. To improve the expansion flexibility so that $\mathcal{M<em i-1="i-1">{i-1}$ could be expanded with arbitrary number of layers, we propose a novel layer insertion method to construct a new PLM $\mathcal{M}</em>}^{\mathrm{D}}$ with $L+L^{\prime}$ layers, where $1 \leq L^{\prime} \leq L$. Specifically, we randomly select $L^{\prime}$ layers from $\mathcal{M<em i-1="i-1">{i-1}$, copy each layer's parameters and insert the replication layer right before / after the original layer. We found empirically that inserting the copied layer into other positions would cause a performance drop, and the reason is that it will violate the processing order of the original layer sequence and break the PLM's original functionality. At each expansion stage when new data comes, since different layers have different functionalities, we always choose those layers that have not been copied before to help PLMs develop in an all-around way, instead of just developing a certain kind of functionality. Since both width expansion and depth expansion are compatible with each other, we simultaneously expand both of them to construct an enlarged model $\mathcal{M}</em>$ 's knowledge contained in the parameters.}^{\mathrm{WD}}$, which inherits $\mathcal{M}_{i-1</p>
<p>Function Recovering Warmup. Since the above model expansion cannot ensure exact function preservation and inevitably results in functionality loss and performance drops, we pre-train the initialized PLM $\mathcal{M}<em i-1="i-1">{i-1}^{\mathrm{WD}}$ on the previous corpora $\overline{\mathcal{D}}</em>$ conserved in the memory to recover the lan-
guage abilities lost during model expansion, which is dubbed as function recovering warmup (FRW). After the warmup, we obtain $\mathcal{M}}^{\text {euk }<em i-1="i-1">{i-1}^{\mathrm{WD}}$, which successfully inherits the knowledge from $\mathcal{M}</em>$ and is also well-prepared for the next training stage.</p>
<h3>3.3 Pre-trained Domain Prompt</h3>
<p>Instead of training a separate model for each domain, we expect a single compact PLM to integrate the knowledge from all the sources. When confronted with a downstream task from a specific domain, the PLM needs to expose the proper knowledge learned during pre-training. To facilitate both knowledge acquisition during pre-training and knowledge exposure during fine-tuning, we resort to prompts as domain indicators and condition the PLM's behavior on these prompts. Soft prompts have been demonstrated excellent task indicators (Qin et al., 2021b) and have non-trivial transferability among tasks (Su et al., 2021).</p>
<p>Specifically, during pre-training, to disentangle the knowledge from different sources, we implant a soft prompt token into the input to prime the PLM which kind of knowledge it is learning. The prompt of domain $i$ is a tunable vector $\mathbf{p}<em i="i">{i}$. We prepend $\mathbf{p}</em>}$ before the original token embeddings $\mathbf{H}^{0}=$ $\left{\mathbf{h<em _mathbf_x="|\mathbf{x">{1}^{0}, \ldots, \mathbf{h}</em>}|}^{0}\right}$ for an input $\mathbf{x} \in \mathcal{D<em i="i">{i}$, resulting in the modified input $\mathbf{H}^{0 *}=\left{\mathbf{p}</em>} ; \mathbf{h<em _mathbf_x="|\mathbf{x">{1}^{0}, \ldots, \mathbf{h}</em>$ is optimized together with other parameters of the PLM during pre-training. During fine-tuning, when applying the PLM on a similar domain of data seen before, we could leverage the trained domain prompt and prepend it before the input of downstream data. In this way, we manually manipulate the PLM to stimulate the most relevant knowledge learned during pre-training.}|}^{0}\right}$, which is then processed by all the Transformer layers. Each $\mathbf{p}_{i</p>
<h2>4 Experiments</h2>
<h3>4.1 Experimental Setting</h3>
<p>Data Streams. We simulate the scenario where streaming data from 5 domains is gathered sequentially, i.e., the concatenation of WIKIPEDIA and BookCorpus (WB) (Zhu et al., 2015), News Articles (Ns) (Zellers et al., 2019), Amazon Reviews (Rev) (He and McAuley, 2016), Biomedical Papers (Bio) (Lo et al., 2020) and Computer Science Papers (CS) (Lo et al., 2020). For each corpus $\mathcal{D}<em i="i">{i}$, we roughly sample 3,400 M tokens, and the quantity for each $\mathcal{D}</em>$ $(1 \leq i \leq 5)$ is comparable to the pre-training data</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Domain</th>
<th style="text-align: center;">WB</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">NS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">REV</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">BIO</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">CS</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Metrics</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Growing from BERT $<em _L12_D768="{L12_D768" _text="\text">{\text {L6_D384 }}$ to BERT $</em>$}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Naive (Lower Bound)</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">8.03</td>
<td style="text-align: center;">5.54</td>
<td style="text-align: center;">13.52</td>
<td style="text-align: center;">21.42</td>
<td style="text-align: center;">13.86</td>
<td style="text-align: center;">17.67</td>
<td style="text-align: center;">9.93</td>
<td style="text-align: center;">9.81</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">EWC</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">8.09</td>
<td style="text-align: center;">5.65</td>
<td style="text-align: center;">13.40</td>
<td style="text-align: center;">20.98</td>
<td style="text-align: center;">13.92</td>
<td style="text-align: center;">17.75</td>
<td style="text-align: center;">9.94</td>
<td style="text-align: center;">9.82</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">MAS</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">8.08</td>
<td style="text-align: center;">5.65</td>
<td style="text-align: center;">13.44</td>
<td style="text-align: center;">21.17</td>
<td style="text-align: center;">13.87</td>
<td style="text-align: center;">17.67</td>
<td style="text-align: center;">9.91</td>
<td style="text-align: center;">9.75</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">A-GEM</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">8.82</td>
<td style="text-align: center;">6.72</td>
<td style="text-align: center;">13.31</td>
<td style="text-align: center;">20.06</td>
<td style="text-align: center;">14.73</td>
<td style="text-align: center;">18.89</td>
<td style="text-align: center;">10.56</td>
<td style="text-align: center;">10.58</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">ER</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">6.85</td>
<td style="text-align: center;">1.59</td>
<td style="text-align: center;">6.99</td>
<td style="text-align: center;">4.09</td>
<td style="text-align: center;">6.66</td>
<td style="text-align: center;">3.62</td>
<td style="text-align: center;">6.39</td>
<td style="text-align: center;">3.16</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Logit-KD</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">7.60</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">7.19</td>
<td style="text-align: center;">1.95</td>
<td style="text-align: center;">7.08</td>
<td style="text-align: center;">2.02</td>
<td style="text-align: center;">6.92</td>
<td style="text-align: center;">1.92</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">PNN</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">6.52</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">5.29</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">4.84</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">4.76</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">ELLE (ours)</td>
<td style="text-align: center;">7.92</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">5.62</td>
<td style="text-align: center;">$-0.20$</td>
<td style="text-align: center;">4.81</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">4.41</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">4.06</td>
<td style="text-align: center;">0.44</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Growing from BERT $<em _L24_D1024="{L24_D1024" _text="\text">{\text {L12_D768 }}$ to BERT $</em>$}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">ER</td>
<td style="text-align: center;">4.54</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">4.33</td>
<td style="text-align: center;">1.31</td>
<td style="text-align: center;">4.02</td>
<td style="text-align: center;">1.46</td>
<td style="text-align: center;">3.73</td>
<td style="text-align: center;">1.15</td>
<td style="text-align: center;">3.82</td>
<td style="text-align: center;">1.28</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">ELLE (ours)</td>
<td style="text-align: center;">4.52</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">3.89</td>
<td style="text-align: center;">0.47</td>
<td style="text-align: center;">3.61</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">3.66</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">3.29</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Growing from GPT $<em _L12_D768="{L12_D768" _text="\text">{\text {L6_D384 }}$ to GPT $</em>$}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Naive (Lower Bound)</td>
<td style="text-align: center;">46.54</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">52.91</td>
<td style="text-align: center;">37.96</td>
<td style="text-align: center;">81.28</td>
<td style="text-align: center;">177.22</td>
<td style="text-align: center;">94.44</td>
<td style="text-align: center;">160.51</td>
<td style="text-align: center;">60.64</td>
<td style="text-align: center;">80.48</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">MAS</td>
<td style="text-align: center;">46.54</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">53.12</td>
<td style="text-align: center;">38.44</td>
<td style="text-align: center;">81.23</td>
<td style="text-align: center;">177.20</td>
<td style="text-align: center;">93.21</td>
<td style="text-align: center;">157.93</td>
<td style="text-align: center;">60.62</td>
<td style="text-align: center;">80.28</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">ER</td>
<td style="text-align: center;">46.54</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">44.49</td>
<td style="text-align: center;">12.42</td>
<td style="text-align: center;">35.46</td>
<td style="text-align: center;">21.78</td>
<td style="text-align: center;">33.24</td>
<td style="text-align: center;">23.38</td>
<td style="text-align: center;">31.94</td>
<td style="text-align: center;">19.83</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Logit-KD</td>
<td style="text-align: center;">46.54</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">48.93</td>
<td style="text-align: center;">5.41</td>
<td style="text-align: center;">37.60</td>
<td style="text-align: center;">9.97</td>
<td style="text-align: center;">34.60</td>
<td style="text-align: center;">11.74</td>
<td style="text-align: center;">33.67</td>
<td style="text-align: center;">11.19</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">PNN</td>
<td style="text-align: center;">46.54</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">39.90</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">26.84</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">22.19</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">21.43</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">ELLE (ours)</td>
<td style="text-align: center;">46.50</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">36.84</td>
<td style="text-align: center;">2.25</td>
<td style="text-align: center;">25.60</td>
<td style="text-align: center;">4.38</td>
<td style="text-align: center;">22.29</td>
<td style="text-align: center;">5.88</td>
<td style="text-align: center;">20.49</td>
<td style="text-align: center;">4.31</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 1: Average perplexity (AP) and average increased perplexity $\left(\mathrm{AP}^{+}\right)$of PLMs trained by different lifelong learning methods with the same train wall time. PLMs are trained with streaming data from WB, NS, REV, BIO and CS domain sequentially. We evaluate the performance each time when PLMs finish training on one domain.
of BERT (Devlin et al., 2019). In addition, considering that in practice, the expense of storage is far cheaper than the computational resources for pre-training, we maintain a relatively large memory compared with conventional lifelong learning settings by randomly sampling 200 M tokens ( $\mathcal{D}<em i="i">{i}^{\text {sub }}$ ) for each corpus $\mathcal{D}</em>$.</p>
<p>Evaluated Models. We mainly follow the model architectures of BERT and GPT (Radford et al., 2018). We use byte-level BPE vocabulary to ensure there are few unknown tokens in each corpus. We experiment with the initial PLM $\mathcal{M}<em _L6_D384="{L6_D384" _text="\text">{1}$ of 6 layers and hidden size of 384 (around 30 M parameters, denoted as BERT $</em>}} / \mathrm{GPT<em 5="5">{\text {L6_D384 }}$ ), and linearly enlarge the PLM's number of parameters for 4 times, to the final PLM $\mathcal{M}</em>$ of 12 layers and hidden size of 768 (around 125 M parameters, denoted as BERT $<em _L12_D768="{L12_D768" _text="\text">{\text {L12_D768 }} / \mathrm{GPT}</em>$ ). We also experiment on a larger model size, i.e., growing the PLM from BERT $}<em _L24_D1024="{L24_D1024" _text="\text">{\text {L12_D768 }}(125 \mathrm{M})$ to BERT $</em>$ 's architecture are listed in appendix B. We also discuss the effect of expanded model size at each stage in appendix A.}}$ (355M). Details of each $\mathcal{M}_{i</p>
<p>Training Details. We train our model for 62, 500 steps for the first corpus. For the following domain $i(i&gt;1)$, after the model expansion, we perform function recovering warmup for 5,000 steps, then train the resulting PLM for 20,000 steps on the new data together with memory replay. Following</p>
<p>Chaudhry et al. (2019b), we jointly train PLMs on a mixture samples from both $\mathcal{D}<em i-1="i-1">{i}$ and $\overline{\mathcal{D}}</em>}^{s u b}$ in each batch, and the sampling ratio of $\mathcal{D<em i-1="i-1">{i}$ and $\overline{\mathcal{D}}</em>, 2015$ ) is chosen as the optimizer. All the experiments are conducted under the same environment of 8 V100 GPUs with a batch size of 2,048 . More training details of pre-training are left in appendix B. We also experiment with fewer computational budgets and memory budgets in appendix G, and find that within a reasonable range, both of the two factors would not significantly influence the performance of ELLE.}^{s u b}$ is set to $9: 1$ in every batch. Adam (Kingma and $\mathrm{Ba</p>
<p>Evaluation Metrics. We deem one algorithm to be more efficient if it could achieve the same performance with other methods utilizing fewer computations. For PLM, this is equivalent to achieving better performance using the same computations since pre-training with more computations almost always results in better performance (Clark et al., 2020). We evaluate the PLM's performance during both pre-training and downstream fine-tuning.</p>
<p>Specifically, for pre-training, we propose two metrics to evaluate how PLMs perform on the learned domains following Chaudhry et al. (2019a): (1) average perplexity (AP) and (2) average increased perplexity $\left(\mathrm{AP}^{+}\right)$. We record the train wall time (Li et al., 2020) during pre-training. For a model checkpoint at time step $T$ when learning the $j$-th domain, we measure the checkpoint's per-</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Average perplexity (AP) of different lifelong learning methods with BERTL6, D384 as the initial PLM. The trend curves for AP+ and other PLMs are left in appendix D.</p>
<p>plexity PPL<sub>T,i</sub> on the validation set of each domain i. Let PPL<sub>i,i</sub><sup>f</sup> be the perplexity on the i-th domain when the PLM finishes training on the i-th domain, the above metrics are calculated as follows:</p>
<p>$$
\begin{aligned}
AP &amp;= \exp\left(\frac{1}{j} \sum_{i=1}^{j} \log PPL_{T,i}\right), \
AP^+ &amp;= \frac{1}{j-1} \sum_{i=1}^{j-1} (PPL_{T,i} - PPL_{i,i}^{f}),
\end{aligned}
\tag{2}
$$</p>
<p>where AP measures the average performance on all the seen data {D<sub>1</sub>, . . . , D<sub>j</sub>}. Lower AP indicates the PLM generally learns more knowledge from existing domains; AP<sup>+</sup> measures the influence of current data D<sub>j</sub> on previous data D<sub>j−1</sub>. Lower AP<sup>+</sup> means PLMs forget less knowledge learned before.</p>
<p>To evaluate PLMs' performance in downstream tasks, for each domain, we select a representative task that is relatively stable, i.e., MNLI (Williams et al., 2018), HyperPartisan (Kiesel et al., 2019), Helpfullness (McAuley et al., 2015), ChemProt (Kringelum et al., 2016) and ACL-ARC (Jurgens et al., 2018) for WB, NS, REV, BIO and CS, respectively. Training details for fine-tuning are left in appendix C.</p>
<p><strong>Baselines.</strong> Keeping most of the experimental set-
tings the same, we choose the following baselines
for comparison: (1) <strong>Naive</strong>, which is a naive ex-
tension of Gururangan et al. (2020) to contin-
ually adapt PLMs for each domain and can be seen
as the lower bound; (2) <strong>EWC</strong> (Schwarz et al.,
2018), which adopts elastic weight consolidation
to add L<sub>2</sub> regularization on parameter changes; (3)
<strong>MAS</strong> (Aljundi et al., 2018), which estimates pa-
rameter importance via the gradients of the model</p>
<table>
<thead>
<tr>
<th>Domain</th>
<th>WB</th>
<th>NS</th>
<th>REV</th>
<th>BIO</th>
<th>CS</th>
<th>AVG</th>
</tr>
</thead>
<tbody>
<tr>
<td><em>Growing from BERTL6, D384 to BERTL12, D768</em></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Naive</td>
<td>77.2</td>
<td>72.8</td>
<td>60.6</td>
<td>77.1</td>
<td>64.8</td>
<td>70.5</td>
</tr>
<tr>
<td>EWC</td>
<td>77.4</td>
<td>72.8</td>
<td>61.6</td>
<td>77.5</td>
<td>59.6</td>
<td>69.8</td>
</tr>
<tr>
<td>MAS</td>
<td>77.1</td>
<td>73.7</td>
<td>60.7</td>
<td>77.5</td>
<td>68.2</td>
<td>71.5</td>
</tr>
<tr>
<td>A-GEM</td>
<td>76.6</td>
<td>71.4</td>
<td>61.5</td>
<td>76.9</td>
<td>67.5</td>
<td>70.8</td>
</tr>
<tr>
<td>ER</td>
<td>77.6</td>
<td>72.2</td>
<td>61.9</td>
<td>78.3</td>
<td>63.5</td>
<td>70.7</td>
</tr>
<tr>
<td>Logit-KD</td>
<td>77.2</td>
<td>69.5</td>
<td>63.9</td>
<td>76.8</td>
<td>58.9</td>
<td>69.2</td>
</tr>
<tr>
<td>PNN</td>
<td>76.0</td>
<td>76.3</td>
<td>68.0</td>
<td>79.5</td>
<td>65.2</td>
<td>73.0</td>
</tr>
<tr>
<td>ELLE</td>
<td><strong>83.2</strong></td>
<td><strong>81.8</strong></td>
<td><strong>68.5</strong></td>
<td><strong>82.9</strong></td>
<td><strong>72.7</strong></td>
<td><strong>77.8</strong></td>
</tr>
<tr>
<td><em>Growing from BERTL12, D768 to BERTL24, D1024</em></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ER</td>
<td>84.7</td>
<td>83.3</td>
<td>68.0</td>
<td>82.7</td>
<td>71.4</td>
<td>78.0</td>
</tr>
<tr>
<td>ELLE</td>
<td><strong>86.3</strong></td>
<td><strong>90.4</strong></td>
<td><strong>70.5</strong></td>
<td><strong>84.2</strong></td>
<td><strong>73.8</strong></td>
<td><strong>81.0</strong></td>
</tr>
</tbody>
</table>
<p>Table 2: Final downstream performance (F1) of BERT
on each domain after finishing pre-training on all do-
mains. Experiments of NS domain are repeated for 10
times with different seeds and others are repeated for
5 times. More detailed results at different pre-training
stages are illustrated in appendix C.</p>
<p>outputs; (4) <strong>ER</strong> (Chaudhry et al., 2019b), which
alleviates forgetting by jointly training models on a
mixture samples from new data D<sub>i</sub> and the memory
D<sub>i−1</sub><sup>sub</sup>. ELLE is based on ER and additionally intro-
duces the model expansion and pre-trained domain
prompts. For ER, we set the sampling ratio of D<sub>i</sub>
and D<sub>i−1</sub><sup>sub</sup> to be 9 : 1 in every batch same as ELLE;
(5) <strong>A-GEM</strong> (Chaudhry et al., 2019a), which con-
strains the new parameter gradients to make sure
that optimization directions do not conflict with
gradients on old domains; (6) <strong>Logit-KD</strong>, which
prevents forgetting by distilling knowledge from
the previous model M<sub>i−1</sub> using the old data in the
memory; (7) <strong>PNN</strong> (Rusu et al., 2016), which fixes
the old PLM M<sub>i−1</sub> to completely avoid knowledge
forgetting and grows new branches for learning new
knowledge. For a fair comparison, we control the
total train wall time of ELLE and all the baselines
to be the same at each training stage, so that each
method consumes the same computational costs.</p>
<p>4.2 Main Results</p>
<p>Table 1 summarizes the pre-training performance
each time when the PLM finishes training on a spe-
cific domain. Figure 2 depicts the trend of AP for
BERT w.r.t. train wall time, other trend curves are
illustrated in appendix D. We also report the final
downstream performance for discriminative PLMs
(BERT) on each domain after finishing the whole
pre-training in Table 2. The intermediate down-
stream performance each time when the PLM fin-
ishes training on one domain is left in appendix C.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Domain</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">WB</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">NS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">REV</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">BIO</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">CS</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">WE</td>
<td style="text-align: center;">DE</td>
<td style="text-align: center;">FRW</td>
<td style="text-align: center;">$\delta_{N}$</td>
<td style="text-align: center;">PT</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">6.85</td>
<td style="text-align: center;">1.59</td>
<td style="text-align: center;">6.99</td>
<td style="text-align: center;">4.09</td>
<td style="text-align: center;">6.66</td>
<td style="text-align: center;">3.62</td>
<td style="text-align: center;">6.39</td>
<td style="text-align: center;">3.16</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">6.23</td>
<td style="text-align: center;">0.78</td>
<td style="text-align: center;">5.34</td>
<td style="text-align: center;">1.42</td>
<td style="text-align: center;">4.98</td>
<td style="text-align: center;">1.20</td>
<td style="text-align: center;">4.48</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">5.81</td>
<td style="text-align: center;">0.03</td>
<td style="text-align: center;">5.49</td>
<td style="text-align: center;">1.43</td>
<td style="text-align: center;">5.16</td>
<td style="text-align: center;">1.32</td>
<td style="text-align: center;">4.79</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">5.78</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">4.91</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">4.49</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">4.13</td>
<td style="text-align: center;">0.52</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">5.79</td>
<td style="text-align: center;">0.09</td>
<td style="text-align: center;">5.09</td>
<td style="text-align: center;">1.13</td>
<td style="text-align: center;">4.58</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">4.22</td>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">5.69</td>
<td style="text-align: center;">$-0.13$</td>
<td style="text-align: center;">4.85</td>
<td style="text-align: center;">0.67</td>
<td style="text-align: center;">4.45</td>
<td style="text-align: center;">0.69</td>
<td style="text-align: center;">4.09</td>
<td style="text-align: center;">0.47</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">7.92</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">5.62</td>
<td style="text-align: center;">$-0.20$</td>
<td style="text-align: center;">4.81</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">4.41</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">4.06</td>
<td style="text-align: center;">0.44</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 3: AP and $\mathrm{AP}^{+}$of different combinations of strategies when growing $\mathrm{BERT}<em _mathrm_L="\mathrm{L">{\mathrm{L} 6 _\mathrm{D} 384}$ to $\mathrm{BERT}</em>$.} 12 _\mathrm{D} 768</p>
<p>Superiority of ELLE. (1) From the results in Table 1, we observe that, compared with all the baselines, ELLE achieves the lowest AP and satisfying $\mathrm{AP}^{+}$after finishing training on each domain. This demonstrates that, given limited computational resources, ELLE could acquire more knowledge and in the meantime, mitigate the knowledge forgetting problem. (2) We also observe from Figure 2 that the AP of ELLE descends the fastest, showing the superior training efficiency of ELLE over all baselines. (3) Besides, ELLE performs the best on all downstream tasks, indicating that the knowledge learned during pre-training could be properly stimulated and leveraged for each downstream task. (4) The superiority of ELLE is consistently observed on the larger model size, i.e., BERT ${ }<em _mathrm_L="\mathrm{L">{\mathrm{L} 24 _\mathrm{D} 1024}$ and other model architectures, i.e., GPT $</em>$. This shows that ELLE is agnostic to both the model size and the specific PLM model architecture chosen. We expect future work to apply ELLE on other PLM architectures and extremely large PLMs.} 12 _\mathrm{D} 768</p>
<p>Comparisons with Baselines. (1) First of all, consolidation-based methods (EWC and MAS) perform almost comparable with the naive baseline in either pre-training or downstream tasks. This means that parameter regularization may not be beneficial for PLMs' knowledge acquisition. (2) Among memory-based methods, gradient-based reaply (A-GEM) exhibits poorer performance in pre-training, on the contrary, data-based replay (ER and Logit-KD) achieve lower AP and $\mathrm{AP}^{+}$than the naive baseline, demonstrating that replaying real data points could more efficiently mitigate the knowledge forgetting problem. Meanwhile, all of the memory-based methods perform comparable or worse than the naive baseline in downstream performance. (3) PNN achieves significantly lower AP than non-progressive baselines, and is immune to knowledge forgetting $\left(\mathrm{AP}^{+}=0\right)$. It also performs better on the downstream tasks than other
baselines. This indicates that enlarging the network is an effective way for lifelong pre-training and also benefits downstream tasks.</p>
<h2>5 Analysis</h2>
<p>In this section, we conduct analyses to investigate the effect of ELLE's components. We follow the setting in $\S 4$ by choosing BERT $<em _mathrm_L="\mathrm{L">{\mathrm{L} 6 _\mathrm{D} 384}$ as the initial model and continually growing it to BERT $</em>$ are illustrated in appendix D.} 12 _\mathrm{D} 768}$. Specifically, we investigate the effect of (1) width expansion (WE), (2) depth expansion (DE), (3) function recovering warmup (FRW), (4) the random noises added into the newly constructed parameters during model expansion $\left(\delta_{N}\right)$ and (5) the pre-trained domain prompts (PT). We test ELLE under different combinations of the above components and compare the results. The experimental results of pre-training and downstream tasks are summarized in Table 3 and Table 4, respectively. Detailed trend curves for AP and $\mathrm{AP}^{+</p>
<p>Effect of Width / Depth Expansion. First, we compare the differences of conducting only width expansion (WE+FRW), only depth expansion (DE+FRW) and expansion on both width and depth (WE+DE+FRW) before function preserving warmup. For a fair comparison, we keep the total number of $\mathcal{M}_{i}$ 's increased parameters for the above three strategies almost the same at each stage $i$. The specific model architectures are listed in appendix F. The results show that: (1) compared with the non-expanding baseline, all these three strategies achieve better pre-training and downstream performance, showing that with the growth of model size, the sample efficiency and training efficiency are extensively increased. Therefore, PLMs could gain more knowledge with limited computational resources and perform better in downstream tasks; (2) compared with expanding only width or depth, expanding both of them is</p>
<p>| WE DE FRW $\delta_{N}$ PT |  |  |  | WB |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | </p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The visualization of the attention patterns of different attention heads in $\mathcal{M}<em i-1="i-1">1$ (BERT_L6_D384), $\mathcal{M}_2$ (BERT_L8_D512), $\mathcal{M}_3$ (BERT_L10_D640), $\mathcal{M}_4$ (BERT_L11_D708) and $\mathcal{M}_5$ (BERT_L12_D768) after finishing training on the new corpus $\mathcal{D}_i$. Note that in this figure, all the attention heads of a PLM $\mathcal{M}_i$ are expanded from all its ancestors ${\mathcal{M}_1, \ldots, \mathcal{M}</em>}$ in the same column. We observe similar attention patterns between the descendant PLM and the ancestor PLM, demonstrating the descendant PLM successfully preserves the functionality of its ancestors.</p>
<p>The descendant PLM (the expanded larger PLM) should have similar functionalities to the ancestor PLM (the original PLM before model expansion). We thus investigate such functionality similarity through the lens of attention patterns of each attention head in the Transformer layer.</p>
<p>Specifically, we visualize the attention patterns of a stream of PLMs ({$\mathcal{M}_1, \ldots, \mathcal{M}_5}$) trained by ELLE when growing from BERT_L6_D384 to BERT_L12_D768. We checkpoint each PLM $\mathcal{M}_i$ when it finishes training on the emerging data $\mathcal{D}_i$. We input the same data into these checkpoints to derive the attention patterns. The results are illustrated in Figure 3, from which we observe that the attention patterns of a head in a descendant PLM are surprisingly similar to those of its "ancestors", even if the descendant PLM is further trained on the new data and enlarged many times. This indicates that the expanded PLM by ELLE successfully inherits the knowledge from its "ancestor", and thus exhibits similar functionality to some extent.</p>
<h2>6 Conclusion</h2>
<p>In this paper, we present the efficient lifelong pretraining problem, which requires PLMs to continually integrate the information from emerging data efficiently. To achieve our goal, we propose ELLE and progressively expand PLMs to acquire knowledge efficiently and mitigate the knowledge forgetting. We also pre-implant domain prompts during pre-training and use them to stimulate the needed knowledge for downstream tasks. The experimental results show the superiority of ELLE over various lifelong learning baselines in both pre-training efficiency and downstream performances.</p>
<h2>Acknowledgments</h2>
<p>This work is supported by the National Key R&amp;D Program of China (No. 2020AAA0106502), NExT++ project from the National Research Foundation, Prime Minister's Office, Singapore under its IRC@Singapore Funding Initiative, Beijing Academy of Artificial Intelligence (BAAI), and International Innovation Center of Tsinghua University, Shanghai, China. This work is also supported by the Pattern Recognition Center, WeChat AI, Tencent Inc. Yujia Qin, Jiajie Zhang and Yankai Lin designed the methods and the experiments. Jiajie Zhang conducted the experiments. Yujia Qin, Jiajie Zhang and Yankai Lin wrote the paper. Zhiyuan Liu, Peng Li, Maosong Sun and Jie Zhou advised the project and participated in the discussion. The authors would like to thank Yichun Yin and Cheng Chen for their constructive advice.</p>
<h2>References</h2>
<p>Samira Abnar, Lisa Beinborn, Rochelle Choenni, and Willem Zuidema. 2019. Blackbox meets blackbox: Representational similarity and stability analysis of neural language models and brains. ArXiv preprint, abs/1906.01539.</p>
<p>Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny, Marcus Rohrbach, and Tinne Tuytelaars. 2018. Memory aware synapses: Learning what (not) to forget. In Proceedings of the European Conference on Computer Vision (ECCV).</p>
<p>Sanjeev Arora, Nadav Cohen, and Elad Hazan. 2018. On the optimization of deep networks: Implicit acceleration by overparameterization. In Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmässan, Stockholm, Sweden, July 10-15, 2018, volume 80 of Proceedings of Machine Learning Research, pages 244-253. PMLR.</p>
<p>Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus Rohrbach, and Mohamed Elhoseiny. 2019a. Efficient lifelong learning with A-GEM. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net.</p>
<p>Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan, Puneet K Dokania, Philip HS Torr, and Marc'Aurelio Ranzato. 2019b. On tiny episodic memories in continual learning. ArXiv preprint, abs/1902.10486.</p>
<p>Cheng Chen, Yichun Yin, Lifeng Shang, Xin Jiang, Yujia Qin, Fengyu Wang, Zhi Wang, Xiao Chen, Zhiyuan Liu, and Qun Liu. 2021. bert2bert: Towards reusable pretrained language models. ArXiv preprint, abs/2110.07143.</p>
<p>Kevin Clark, Minh-Thang Luong, Quoc V. Le, and Christopher D. Manning. 2020. ELECTRA: pretraining text encoders as discriminators rather than generators. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.</p>
<p>Cyprien de Masson d'Autume, Sebastian Ruder, Lingpeng Kong, and Dani Yogatama. 2019. Episodic memory in lifelong language learning. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 13122-13131.</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186, Minneapolis, Minnesota. Association for Computational Linguistics.</p>
<p>Bhuwan Dhingra, Jeremy R Cole, Julian Martin Eisenschlos, Daniel Gillick, Jacob Eisenstein, and William W Cohen. 2021. Time-aware language models as temporal knowledge bases. ArXiv preprint, abs/2106.15110.</p>
<p>Linyuan Gong, Di He, Zhuohan Li, Tao Qin, Liwei Wang, and Tie-Yan Liu. 2019. Efficient training of BERT by progressively stacking. In Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research, pages 2337-2346. PMLR.</p>
<p>Xiaotao Gu, Liyuan Liu, Hongkun Yu, Jing Li, Chen Chen, and Jiawei Han. 2021. On the transformer growth for progressive BERT training. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5174-5180, Online. Association for Computational Linguistics.</p>
<p>Suchin Gururangan, Mike Lewis, Ari Holtzman, Noah A Smith, and Luke Zettlemoyer. 2021. Demix layers: Disentangling domains for modular language modeling. ArXiv preprint, abs/2108.05036.</p>
<p>Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, and Noah A. Smith. 2020. Don't stop pretraining: Adapt language models to domains and tasks. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8342-8360, Online. Association for Computational Linguistics.</p>
<p>Xu Han, Zhengyan Zhang, Ning Ding, Yuxian Gu, Xiao Liu, Yuqi Huo, Jiezhong Qiu, Liang Zhang, Wentao Han, Minlie Huang, Qin Jin, Yanyan Lan, Yang Liu, Zhiyuan Liu, Zhiwu Lu, Xipeng Qiu, Ruihua Song, Jie Tang, Ji-Rong Wen, Jinhui Yuan, Wayne Xin Zhao, and Jun Zhu. 2021. Pre-trained models: Past, present and future. ArXiv preprint, abs/2106.07139.</p>
<p>Ruidan He, Linlin Liu, Hai Ye, Qingyu Tan, Bosheng Ding, Liying Cheng, Jiawei Low, Lidong Bing, and Luo Si. 2021. On the effectiveness of adapter-based tuning for pretrained language model adaptation. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 22082222, Online. Association for Computational Linguistics.</p>
<p>Ruining He and Julian J. McAuley. 2016. Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering. In Proceedings of the 25th International Conference on World Wide Web, WWW 2016, Montreal, Canada, April 11 - 15, 2016, pages 507-517. ACM.</p>
<p>Joel Jang, Seonghyeon Ye, Sohee Yang, Joongbo Shin, Janghoon Han, Gyeonghun Kim, Stanley Jungkyu</p>
<p>Choi, and Minjoon Seo. 2021. Towards continual knowledge learning of language models. ArXiv preprint, abs/2110.03215.</p>
<p>Xisen Jin, Dejiao Zhang, Henghui Zhu, Wei Xiao, Shang-Wen Li, Xiaokai Wei, Andrew Arnold, and Xiang Ren. 2021. Lifelong pretraining: Continually adapting language models to emerging corpora. ArXiv preprint, abs/2110.08534.</p>
<p>David Jurgens, Srijan Kumar, Raine Hoover, Dan McFarland, and Dan Jurafsky. 2018. Measuring the evolution of a scientific field through citation frames. Transactions of the Association for Computational Linguistics, 6:391-406.</p>
<p>Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language models. ArXiv preprint, abs/2001.08361.</p>
<p>Johannes Kiesel, Maria Mestre, Rishabh Shukla, Emmanuel Vincent, Payam Adineh, David Corney, Benno Stein, and Martin Potthast. 2019. SemEval2019 task 4: Hyperpartisan news detection. In Proceedings of the 13th International Workshop on Semantic Evaluation, pages 829-839, Minneapolis, Minnesota, USA. Association for Computational Linguistics.</p>
<p>Diederik P. Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.</p>
<p>James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. 2017. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114(13):3521-3526.</p>
<p>Jens Kringelum, Sonny Kim Kjaerulff, Søren Brunak, Ole Lund, Tudor I Oprea, and Olivier Taboureau. 2016. Chemprot-3.0: a global chemical biology diseases mapping. Database, 2016.</p>
<p>Zhuohan Li, Eric Wallace, Sheng Shen, Kevin Lin, Kurt Keutzer, Dan Klein, and Joey Gonzalez. 2020. Train big, then compress: Rethinking model size for efficient training and inference of transformers. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research, pages 5958-5968. PMLR.</p>
<p>Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, and Daniel Weld. 2020. S2ORC: The semantic scholar open research corpus. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4969-4983, Online. Association for Computational Linguistics.</p>
<p>David Lopez-Paz and Marc'Aurelio Ranzato. 2017. Gradient episodic memory for continual learning. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pages 6467-6476.</p>
<p>Julian J. McAuley, Christopher Targett, Qinfeng Shi, and Anton van den Hengel. 2015. Image-based recommendations on styles and substitutes. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, Santiago, Chile, August 9-13, 2015, pages 43-52. ACM.</p>
<p>Michael McCloskey and Neal J Cohen. 20p. Catastrophic interference in connectionist networks: The sequential learning problem. ArXiv preprint, abs/p.</p>
<p>Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. 2019. fairseq: A fast, extensible toolkit for sequence modeling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations), pages 48-53, Minneapolis, Minnesota. Association for Computational Linguistics.</p>
<p>Yujia Qin, Yankai Lin, Jing Yi, Jiajie Zhang, Xu Han, Zhengyan Zhang, Yusheng Su, Zhiyuan Liu, Peng Li, Maosong Sun, et al. 2021a. Knowledge inheritance for pre-trained language models. ArXiv preprint, abs/2105.13880.</p>
<p>Yujia Qin, Xiaozhi Wang, Yusheng Su, Yankai Lin, Ning Ding, Zhiyuan Liu, Juanzi Li, Lei Hou, Peng Li, Maosong Sun, et al. 2021b. Exploring lowdimensional intrinsic task subspace via prompt tuning. ArXiv preprint, abs/2110.07867.</p>
<p>Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Improving language understanding by generative pre-training.</p>
<p>Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H. Lampert. 2017. icarl: Incremental classifier and representation learning. In 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017, pages 5533-5542. IEEE Computer Society.</p>
<p>David Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy P. Lillicrap, and Gregory Wayne. 2019. Experience replay for continual learning. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 348-358.</p>
<p>Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. 2016. Progressive neural networks. ArXiv preprint, abs/1606.04671.</p>
<p>Roy Schwartz, Jesse Dodge, Noah A Smith, and Oren Etzioni. 2019. Green ai. ArXiv preprint, abs/1907.10597.</p>
<p>Jonathan Schwarz, Wojciech Czarnecki, Jelena Luketina, Agnieszka Grabska-Barwinska, Yee Whye Teh, Razvan Pascanu, and Raia Hadsell. 2018. Progress \&amp; compress: A scalable framework for continual learning. In Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmässan, Stockholm, Sweden, July 10-15, 2018, volume 80 of Proceedings of Machine Learning Research, pages 4535-4544. PMLR.</p>
<p>Noam Shazeer, Youlong Cheng, Niki Parmar, Dustin Tran, Ashish Vaswani, Penporn Koanantakool, Peter Hawkins, HyoukJoong Lee, Mingsheng Hong, Cliff Young, Ryan Sepassi, and Blake A. Hechtman. 2018. Mesh-tensorflow: Deep learning for supercomputers. In Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada, pages 10435-10444.</p>
<p>Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. 2019. Megatron-lm: Training multi-billion parameter language models using model parallelism. ArXiv preprint, abs/1909.08053.</p>
<p>Yusheng Su, Xiaozhi Wang, Yujia Qin, Chi-Min Chan, Yankai Lin, Zhiyuan Liu, Peng Li, Juanzi Li, Lei Hou, Maosong Sun, et al. 2021. On transferability of prompt tuning for natural language understanding. ArXiv preprint, abs/2111.06719.</p>
<p>Fan-Keng Sun, Cheng-Hao Ho, and Hung-Yi Lee. 2020. LAMOL: language modeling for lifelong language learning. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pages 5998-6008.</p>
<p>Adina Williams, Nikita Nangia, and Samuel Bowman. 2018. A broad-coverage challenge corpus for sentence understanding through inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1112-1122, New Orleans, Louisiana. Association for Computational Linguistics.</p>
<p>Tongtong Wu, Massimo Caccia, Zhuang Li, Yuan-Fang Li, Guilin Qi, and Gholamreza Haffari. 2021. Pretrained language model in continual learning: A comparative study. In International Conference on Learning Representations.</p>
<p>Jaehong Yoon, Eunho Yang, Jeongtae Lee, and Sung Ju Hwang. 2018. Lifelong learning with dynamically expandable networks. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings. OpenReview.net.</p>
<p>Yang You, Jing Li, Sashank J. Reddi, Jonathan Hseu, Sanjiv Kumar, Srinadh Bhojanapalli, Xiaodan Song, James Demmel, Kurt Keutzer, and Cho-Jui Hsieh. 2020. Large batch optimization for deep learning: Training BERT in 76 minutes. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.</p>
<p>Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, and Yejin Choi. 2019. Defending against neural fake news. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 9051-9062.</p>
<p>Minjia Zhang and Yuxiong He. 2020. Accelerating training of transformer-based language models with progressive layer dropping. ArXiv preprint, abs/2010.13369.</p>
<p>Yukun Zhu, Ryan Kiros, Richard S. Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and Sanja Fidler. 2015. Aligning books and movies: Towards story-like visual explanations by watching movies and reading books. In 2015 IEEE International Conference on Computer Vision, ICCV 2015, Santiago, Chile, December 7-13, 2015, pages 19-27. IEEE Computer Society.</p>
<h2>Appendices</h2>
<h2>A Additional Analysis on Function Preserved Model Expansion</h2>
<p>In addition to the analyses of function preserved model expansion conducted in our main paper, in this section, we further analyze the effect of (1) the expanded model size at each training stage and (2) the choice of copied layer during depth expansion. We experiment on the combination of WE+DE+FRW as mentioned in $\S 5$ and choose BERT $<em 1="1">{\text {L6_D384 }}$ as the initial PLM $\mathcal{M}</em>$. Other settings are kept the same as $\S 5$.</p>
<p>Effect of Expanded Model Size. In our main experiments, we assume that the data size of each emerging corpus is the same and linearly enlarge the model size when conducting model expansion. In this section, we explore the effect of expanded model size given limited computational resources. We conduct experiments on a stream of data from 3 domains, i.e., WB, Ns and Rev domain. We start from the initial PLM BERT $_{\text {L6_D384 }}$ and continually adapt it to new corpora. Under the same training environment, we control the computational costs (train wall time) of each domain to be 7200 seconds. We compare the performances when the PLM expands $0,2,4$, and 6 layers and heads for each domain, respectively. Note the PLMs expanded with a larger size would be trained with fewer steps to control the train wall time.</p>
<p>The results are shown in Table 6, from which we can conclude that the best performance is obtained when the model expands 2 layers and heads at each expansion stage, and expanding more or fewer parameters leads to a performance drop. The reasons are two-fold: (1) firstly, as mentioned before, expanding the model size improves the sample efficiency (Kaplan et al., 2020; Li et al., 2020), which is beneficial for PLMs' knowledge acquisition; (2) secondly, when increasing the expanded model size, the benefits from inheriting the knowledge of a small PLM would become less and less evident. To sum up, expanding with an intermediate size strikes the best trade-off between the above two reasons, and there may exist an optimal expanded size when performing model expansion.</p>
<p>Intuitively, the optimal expanded model size may be influenced by many factors, e.g., the computational budgets, the amount of emerging data, the PLM's model architecture, etc. And systematically analyzing the effects of all these factors is beyond
the scope of this paper, thus we expect future works to design algorithms to accurately estimate the optimal expanded size for model expansion.</p>
<p>Choice of Copied Layer. As mentioned in § 3.2, each time when we conduct width expansion, we choose those layers that have not been copied before. To demonstrate the benefit of this trick, we compare three expansion strategies: (1) always replicating those layers that have not been copied before (WE+DE+FRW); (2) always replicating the first layer (WE+DE first +FRW ) and (3) always replicating the last layer (WE+DE ${ }_{\text {last }}+$ FRW).</p>
<p>The results in Figure 4 show that AP and AP ${ }^{+}$ descend the fastest when we always replicate those layers that have not been copied before (i.e., WE+DE+FRW). This demonstrates that, since different layers have different functionalities, choosing those layers that have not been expanded before would help PLMs develop in an all-around way, instead of just developing a certain kind of functionality. Furthermore, we find empirically that when pre-training PLMs continually on multiple domains, if we always choose those layers that have not been expanded before at each depth expansion stage, then the final performance is not sensitive to choosing which layers to expand first.</p>
<h2>B Pre-training Hyper-parameters</h2>
<p>In Table 7, we list the architectures and the hyperparameters for the PLMs we pre-trained with ELLE in this paper, including the total number of trainable parameters ( $n_{\text {params }}$ ), the number of layers ( $n_{\text {layers }}$ ), the number of units in each bottleneck layer ( $d_{\text {model }}$ ), the number of attention heads ( $n_{\text {heads }}$ ), the inner hidden size of FFN layer ( $d_{\mathrm{FFN}}$ ), the learning rate (lr), the training steps of FRW (SF), the training steps of adaptation after FRW (STF) when learning the new corpus, the ratio of learning rate warmup (RW), and the total train wall time (TWT). We set the dropout rate for each model to 0.1 , weight decay to 0.01 and use linear learning rate decay for BERT and inverse square root decay for GPT. We adopt Adam (Kingma and Ba, 2015) as the optimizer. The hyper-parameters for the optimizer is set to $1 \times 10^{-6}, 0.9,0.98$ for $\epsilon, \beta_{1}, \beta_{2}$, respectively. We reset the optimizer and the learning rate scheduler each time when the PLM finishes FRW or the training on new corpus. All experiments are conducted under the same computation environment with 8 NVIDIA 32GB V100 GPUs. All the pre-training implementations are based on</p>
<table>
<thead>
<tr>
<th>Domain</th>
<th>WB</th>
<th></th>
<th>News</th>
<th></th>
<th>REVIEW</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Metrics</td>
<td>AP</td>
<td>AP $^{+}$</td>
<td>AP</td>
<td>AP $^{+}$</td>
<td>AP</td>
<td>AP $^{+}$</td>
</tr>
<tr>
<td>Expand 0 layers and heads per domain</td>
<td>$\mathbf{1 3 . 0 9}$</td>
<td>-</td>
<td>8.99</td>
<td>-0.49</td>
<td>8.24</td>
<td>2.80</td>
</tr>
<tr>
<td>Expand 2 layers and heads per domain</td>
<td>$\mathbf{1 3 . 0 9}$</td>
<td>-</td>
<td>$\mathbf{8 . 2 8}$</td>
<td>$\mathbf{- 1 . 4 4}$</td>
<td>$\mathbf{7 . 2 5}$</td>
<td>$\mathbf{1 . 1 1}$</td>
</tr>
<tr>
<td>Expand 4 layers and heads per domain</td>
<td>$\mathbf{1 3 . 0 9}$</td>
<td>-</td>
<td>8.62</td>
<td>-0.95</td>
<td>7.53</td>
<td>1.30</td>
</tr>
<tr>
<td>Expand 6 layers and heads per domain</td>
<td>$\mathbf{1 3 . 0 9}$</td>
<td>-</td>
<td>9.08</td>
<td>-0.24</td>
<td>7.92</td>
<td>1.49</td>
</tr>
</tbody>
</table>
<p>Table 6: AP and AP $^{+}$of PLMs trained with ELLE that expands $0,2,4$ and 6 layers and heads during model expansion, respectively. AP and AP $^{+}$are evaluated when each PLM finishes training on each domain.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: AP and AP $^{+}$of PLMs trained by ELLE using different depth expansion strategies: WE+DE+FRW, WE+DE first +FRW and WE+DE last +FRW w.r.t train wall time.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">$n_{\text {params }}$</th>
<th style="text-align: center;">$n_{\text {layers }}$</th>
<th style="text-align: center;">$d_{\text {model }}$</th>
<th style="text-align: center;">$n_{\text {heads }}$</th>
<th style="text-align: center;">$d_{\text {FFN }}$</th>
<th style="text-align: center;">lr</th>
<th style="text-align: center;">SF</th>
<th style="text-align: center;">STF</th>
<th style="text-align: center;">RW</th>
<th style="text-align: center;">TWT(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Growing from BERT $\mathrm{L}<em 12_="12," _mathrm_D="\mathrm{D">{1, \mathrm{~B}, \mathrm{D} 384}$ to BERT $\mathrm{L}</em>$} 768</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{1}$</td>
<td style="text-align: center;">30.3 M</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">384</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">1536</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">62.5 k</td>
<td style="text-align: center;">$8 \%$</td>
<td style="text-align: center;">$6.0 \times 10^{4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{2}$</td>
<td style="text-align: center;">51.5 M</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">2048</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
<td style="text-align: center;">5 k</td>
<td style="text-align: center;">20 k</td>
<td style="text-align: center;">$8 \%$</td>
<td style="text-align: center;">$2.4 \times 10^{4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{3}$</td>
<td style="text-align: center;">82.2 M</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">640</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">2560</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
<td style="text-align: center;">5 k</td>
<td style="text-align: center;">20 k</td>
<td style="text-align: center;">$8 \%$</td>
<td style="text-align: center;">$5.0 \times 10^{4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{4}$</td>
<td style="text-align: center;">102 M</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">704</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">2816</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
<td style="text-align: center;">5 k</td>
<td style="text-align: center;">20 k</td>
<td style="text-align: center;">$8 \%$</td>
<td style="text-align: center;">$5.8 \times 10^{4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{5}$</td>
<td style="text-align: center;">125 M</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
<td style="text-align: center;">5 k</td>
<td style="text-align: center;">20 k</td>
<td style="text-align: center;">$8 \%$</td>
<td style="text-align: center;">$6.8 \times 10^{4}$</td>
</tr>
<tr>
<td style="text-align: center;">Growing from BERT $<em 12_="12," _mathrm_D="\mathrm{D">{\mathrm{L} 12, \mathrm{D} 768}$ to BERT $\mathrm{L}</em>$} 1024</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{1}$</td>
<td style="text-align: center;">125 M</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">62.5 k</td>
<td style="text-align: center;">$8 \%$</td>
<td style="text-align: center;">$1.9 \times 10^{5}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{2}$</td>
<td style="text-align: center;">216 M</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">960</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">3840</td>
<td style="text-align: center;">$2.5 \times 10^{-4}$</td>
<td style="text-align: center;">1 k</td>
<td style="text-align: center;">20 k</td>
<td style="text-align: center;">$20 \%$</td>
<td style="text-align: center;">$6.5 \times 10^{4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{3}$</td>
<td style="text-align: center;">280 M</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">1024</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">4096</td>
<td style="text-align: center;">$2.5 \times 10^{-4}$</td>
<td style="text-align: center;">1 k</td>
<td style="text-align: center;">20 k</td>
<td style="text-align: center;">$20 \%$</td>
<td style="text-align: center;">$1.4 \times 10^{5}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{4}$</td>
<td style="text-align: center;">318 M</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">1024</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">4096</td>
<td style="text-align: center;">$2.5 \times 10^{-4}$</td>
<td style="text-align: center;">1 k</td>
<td style="text-align: center;">20 k</td>
<td style="text-align: center;">$20 \%$</td>
<td style="text-align: center;">$1.7 \times 10^{5}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{5}$</td>
<td style="text-align: center;">355 M</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">1024</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">4096</td>
<td style="text-align: center;">$2.5 \times 10^{-4}$</td>
<td style="text-align: center;">1 k</td>
<td style="text-align: center;">20 k</td>
<td style="text-align: center;">$20 \%$</td>
<td style="text-align: center;">$2.2 \times 10^{5}$</td>
</tr>
<tr>
<td style="text-align: center;">Growing from GPT $<em _mathrm_L="\mathrm{L">{\mathrm{L} 6, \mathrm{D} 384}$ to GPT $</em>$} 12, \mathrm{D} 768</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{1}$</td>
<td style="text-align: center;">29.9 M</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">384</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">1536</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">62.5 k</td>
<td style="text-align: center;">$16 \%$</td>
<td style="text-align: center;">$6.7 \times 10^{4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{2}$</td>
<td style="text-align: center;">51.0 M</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">2048</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
<td style="text-align: center;">5 k</td>
<td style="text-align: center;">20 k</td>
<td style="text-align: center;">$16 \%$</td>
<td style="text-align: center;">$3.9 \times 10^{4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{3}$</td>
<td style="text-align: center;">81.4 M</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">640</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">2560</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
<td style="text-align: center;">5 k</td>
<td style="text-align: center;">20 k</td>
<td style="text-align: center;">$16 \%$</td>
<td style="text-align: center;">$5.6 \times 10^{4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{4}$</td>
<td style="text-align: center;">101 M</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">704</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">2816</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
<td style="text-align: center;">5 k</td>
<td style="text-align: center;">20 k</td>
<td style="text-align: center;">$16 \%$</td>
<td style="text-align: center;">$6.8 \times 10^{4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{5}$</td>
<td style="text-align: center;">124 M</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
<td style="text-align: center;">5 k</td>
<td style="text-align: center;">20 k</td>
<td style="text-align: center;">$16 \%$</td>
<td style="text-align: center;">$7.8 \times 10^{4}$</td>
</tr>
</tbody>
</table>
<p>Table 7: Model architectures, learning rate (lr), steps of FRW (SF), steps of training after FRW (STF), the ratio of steps for learning rate warmup (for both FRW and pre-training) (RW), and train wall time (TWT) for all the models pre-trained with ELLE in this paper. We list the details when growing BERT $<em _mathrm_L="\mathrm{L">{\mathrm{L} 6, \mathrm{D} 384}$ to BERT $</em>$, BERT $} 12, \mathrm{D} 768<em _mathrm_L="\mathrm{L">{\mathrm{L} 12, \mathrm{D} 768}$ to BERT $</em>$ and GPT $} 24, \mathrm{D} 1024<em _mathrm_L="\mathrm{L">{\mathrm{L} 6, \mathrm{D} 384}$ to GPT $</em>$ seconds, respectively.
fairseq $^{1}$ (Ott et al., 2019) (MIT-license).} 12, \mathrm{D} 768}$, respectively. The total train wall time consumed by the above three settings is $2.57 \times 10^{5}$ seconds, $7.79 \times 10^{5}$ seconds, and $3.08 \times 10^{5</p>
<table>
<thead>
<tr>
<th>HyperParam</th>
<th>MNLI</th>
<th>HyperPartisan</th>
<th>Helpfulness</th>
<th>ChemProt</th>
<th>ACL-ARC</th>
</tr>
</thead>
<tbody>
<tr>
<td>Learning Rate</td>
<td>$1 \times 10^{-5}$</td>
<td>$2 \times 10^{-5}$</td>
<td>$2 \times 10^{-5}$</td>
<td>$2 \times 10^{-5}$</td>
<td>$2 \times 10^{-5}$</td>
</tr>
<tr>
<td>Batch Size</td>
<td>32</td>
<td>256</td>
<td>256</td>
<td>256</td>
<td>256</td>
</tr>
<tr>
<td>Weight Decay</td>
<td>0.1</td>
<td>0.1</td>
<td>0.1</td>
<td>0.1</td>
<td>0.1</td>
</tr>
<tr>
<td>Max Epochs</td>
<td>10</td>
<td>10</td>
<td>10</td>
<td>10</td>
<td>10</td>
</tr>
<tr>
<td>Learning Rate Decay</td>
<td>Linear</td>
<td>Linear</td>
<td>Linear</td>
<td>Linear</td>
<td>Linear</td>
</tr>
<tr>
<td>Warmup Ratio</td>
<td>0.06</td>
<td>0.06</td>
<td>0.06</td>
<td>0.06</td>
<td>0.06</td>
</tr>
</tbody>
</table>
<p>Table 8: Hyper-parameters for fine-tuning on downstream tasks of each domain. As mentioned in the main paper, for each domain, we select a representative task that is relatively stable, i.e., MNLI (Williams et al., 2018), HyperPartisan (Kiesel et al., 2019), Helpfullness (McAuley et al., 2015), ChemProt (Kringelum et al., 2016) and ACL-ARC (Jurgens et al., 2018) for WB, NS, REV, BIO and CS, respectively.</p>
<h2>C Implementation Details and Additional Experiments for Downstream Fine-tuning</h2>
<p>Implementation Details. Table 8 describes the hyper-parameters for fine-tuning PLMs on downstream tasks of each domain. The implementations of MNLI are based on fairseq $^{2}$ (Ott et al., 2019) (MIT-license). The implementations of Hy PERPartisAN, Helpfulness ChemProt, and ACL-ARC are based on (Gururangan et al., 2020) ${ }^{3}$.</p>
<p>Additional Experiments. Figure 5 visualizes the specific F1 on each downstream tasks and the average F1 of PLMs trained with Naive, A-GEM, EWC, MAS, ER, Logit-KD, PNN and ELLE after finishing training on each domain when we choose BERT $<em 1="1">{\text {L6_D384 }}$ as the initial PLM $\mathcal{M}</em>$. The average F1 when finishing training on the $i$-th domain is calculated as follows:</p>
<p>$$
\mathrm{F} 1_{a v g}^{i}=\frac{1}{N} \sum_{j=1}^{N} \mathrm{~F} 1_{\mathcal{M}_{i}}^{j}
$$</p>
<p>where $\mathrm{F} 1_{\mathcal{M}<em i="i">{i}}^{j}$ is the F 1 score of $\mathcal{M}</em>$ evaluated on the downstream task of the $j$-th domain. We also list the detailed numerical results for each task in Table 9, covering all PLMs trained by each lifelong learning method.</p>
<p>The results show that ELLE outperforms all the lifelong learning baselines after finishing training on each domain, demonstrating that ELLE could properly stimulate the learned knowledge during pre-training and boost the performance in downstream tasks.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>D Trend Curves for AP and AP ${ }^{+}$</h2>
<p>For the experiments in $\S 4$, the trend curves of average perplexity (AP) and average increased perplexity $\left(\mathrm{AP}^{+}\right)$w.r.t train wall time are shown in Figure 7 (growing from BERT $<em _L12_D768="{L12_D768" _text="\text">{\text {L6_D384 }}$ to BERT $</em>$ ), Figure 8 (growing from BERT $}<em _L24_D1024="{L24_D1024" _text="\text">{\text {L12_D768 }}$ to BERT $</em>$ ), and Figure 9 (growing from GPT $}<em _L12_D768="{L12_D768" _text="\text">{\text {L6_D384 }}$ to GPT $</em>$ of ELLE descend with the fastest speed, demonstrating that ELLE could acquire knowledge and mitigate the knowledge forgetting on previous domains more efficiently. Thus given limited computational resources, PLMs trained by ELLE could integrate more information from different domains.}}$ ). Each figure illustrates the performance of different lifelong learning methods. The above results reflect that, compared with all the baselines, AP and $\mathrm{AP}^{+</p>
<p>For the analysis in $\S 5$, we visualize the trend curves of AP and $\mathrm{AP}^{+}$when choosing different combinations of strategies. Specifically, we investigate (1) the effect of width / depth expansion in Figure 10 (comparing WE+FRW, DE+FRW and WE+DE+FRW); (2) the effect of function recovering warmup in Figure 11 (comparing WE+DE and WE+DE+FRW); (3) the effect of random noises added into the newly initialized parameters during model expansion in Figure 11 (comparing WE+DE+FRW and WE+DE+FRW+ $\delta_{N}$ ) and (4) the effect of pre-trained domain prompts in Figure 12 (comparing ELLE and ELLE-PT). All of the above results again demonstrate the effectiveness of ELLE's each component.</p>
<h2>E Representational Similarity of a Stream of PLMs</h2>
<p>We investigate the representational similarity (Abnar et al., 2019) of a descendant PLM and its ancestors. Representational similarity measures how similar two PLMs represent the data. Specifically,</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Specific and average F1 on downstream tasks of all domains of different lifelong learning methods. The initial PLM is chosen as BERT $<em _mathrm_L="\mathrm{L">{\text {L6_D384 }}$. The score is evaluated after each model finishes training on each domain.
we experiment on a stream of PLMs when growing $\mathrm{BERT}</em>} 6 _\mathrm{D} 384}$ to $\mathrm{BERT<em j="j">{\mathrm{L} 12 _\mathrm{D} 768}$. For a model $\mathcal{M}</em>}$ and its ancestor $\mathcal{M<em j="j">{i}(1 \leq i \leq j-1)$, we randomly sample $n$ [MASK] tokens from the raw corpus $\mathcal{D}</em>$, and get the probability distributions</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Domain</th>
<th style="text-align: center;">WB</th>
<th style="text-align: center;">Ns</th>
<th style="text-align: center;">REV</th>
<th style="text-align: center;">BIO</th>
<th style="text-align: center;">CS</th>
<th style="text-align: center;">AVG</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Naive</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{1}$</td>
<td style="text-align: center;">77.11</td>
<td style="text-align: center;">76.29</td>
<td style="text-align: center;">62.85</td>
<td style="text-align: center;">76.49</td>
<td style="text-align: center;">63.07</td>
<td style="text-align: center;">71.16</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{2}$</td>
<td style="text-align: center;">78.17</td>
<td style="text-align: center;">80.21</td>
<td style="text-align: center;">61.54</td>
<td style="text-align: center;">75.95</td>
<td style="text-align: center;">61.64</td>
<td style="text-align: center;">71.50</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{3}$</td>
<td style="text-align: center;">77.70</td>
<td style="text-align: center;">73.00</td>
<td style="text-align: center;">64.46</td>
<td style="text-align: center;">73.39</td>
<td style="text-align: center;">53.41</td>
<td style="text-align: center;">68.39</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{4}$</td>
<td style="text-align: center;">75.60</td>
<td style="text-align: center;">68.33</td>
<td style="text-align: center;">61.32</td>
<td style="text-align: center;">80.32</td>
<td style="text-align: center;">59.49</td>
<td style="text-align: center;">69.01</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{5}$</td>
<td style="text-align: center;">77.18</td>
<td style="text-align: center;">72.84</td>
<td style="text-align: center;">60.63</td>
<td style="text-align: center;">77.12</td>
<td style="text-align: center;">64.82</td>
<td style="text-align: center;">70.52</td>
</tr>
<tr>
<td style="text-align: center;">A-GEM</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{1}$</td>
<td style="text-align: center;">77.11</td>
<td style="text-align: center;">76.29</td>
<td style="text-align: center;">62.85</td>
<td style="text-align: center;">76.49</td>
<td style="text-align: center;">63.07</td>
<td style="text-align: center;">71.16</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{2}$</td>
<td style="text-align: center;">77.99</td>
<td style="text-align: center;">76.80</td>
<td style="text-align: center;">61.99</td>
<td style="text-align: center;">75.53</td>
<td style="text-align: center;">59.65</td>
<td style="text-align: center;">71.50</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{3}$</td>
<td style="text-align: center;">77.71</td>
<td style="text-align: center;">72.96</td>
<td style="text-align: center;">63.92</td>
<td style="text-align: center;">73.39</td>
<td style="text-align: center;">53.66</td>
<td style="text-align: center;">68.39</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{4}$</td>
<td style="text-align: center;">74.76</td>
<td style="text-align: center;">71.80</td>
<td style="text-align: center;">61.41</td>
<td style="text-align: center;">79.70</td>
<td style="text-align: center;">62.00</td>
<td style="text-align: center;">69.93</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{5}$</td>
<td style="text-align: center;">76.55</td>
<td style="text-align: center;">71.37</td>
<td style="text-align: center;">61.53</td>
<td style="text-align: center;">76.85</td>
<td style="text-align: center;">64.82</td>
<td style="text-align: center;">70.75</td>
</tr>
<tr>
<td style="text-align: center;">MAS</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{1}$</td>
<td style="text-align: center;">77.11</td>
<td style="text-align: center;">76.29</td>
<td style="text-align: center;">62.85</td>
<td style="text-align: center;">76.49</td>
<td style="text-align: center;">63.07</td>
<td style="text-align: center;">71.16</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{2}$</td>
<td style="text-align: center;">78.13</td>
<td style="text-align: center;">76.75</td>
<td style="text-align: center;">61.68</td>
<td style="text-align: center;">75.12</td>
<td style="text-align: center;">62.69</td>
<td style="text-align: center;">70.87</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{3}$</td>
<td style="text-align: center;">76.60</td>
<td style="text-align: center;">73.79</td>
<td style="text-align: center;">64.04</td>
<td style="text-align: center;">72.11</td>
<td style="text-align: center;">53.95</td>
<td style="text-align: center;">70.87</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{4}$</td>
<td style="text-align: center;">76.09</td>
<td style="text-align: center;">71.90</td>
<td style="text-align: center;">61.83</td>
<td style="text-align: center;">80.62</td>
<td style="text-align: center;">64.26</td>
<td style="text-align: center;">70.94</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{5}$</td>
<td style="text-align: center;">77.14</td>
<td style="text-align: center;">73.70</td>
<td style="text-align: center;">60.69</td>
<td style="text-align: center;">77.53</td>
<td style="text-align: center;">68.23</td>
<td style="text-align: center;">71.46</td>
</tr>
<tr>
<td style="text-align: center;">MAS</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{1}$</td>
<td style="text-align: center;">77.11</td>
<td style="text-align: center;">76.29</td>
<td style="text-align: center;">62.85</td>
<td style="text-align: center;">76.49</td>
<td style="text-align: center;">63.07</td>
<td style="text-align: center;">71.16</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{2}$</td>
<td style="text-align: center;">78.30</td>
<td style="text-align: center;">80.15</td>
<td style="text-align: center;">61.18</td>
<td style="text-align: center;">75.87</td>
<td style="text-align: center;">59.96</td>
<td style="text-align: center;">71.09</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{3}$</td>
<td style="text-align: center;">77. 11</td>
<td style="text-align: center;">72.26</td>
<td style="text-align: center;">64.41</td>
<td style="text-align: center;">72.37</td>
<td style="text-align: center;">52.07</td>
<td style="text-align: center;">67.64</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{4}$</td>
<td style="text-align: center;">76.21</td>
<td style="text-align: center;">73.21</td>
<td style="text-align: center;">61.34</td>
<td style="text-align: center;">80.81</td>
<td style="text-align: center;">62.33</td>
<td style="text-align: center;">70.78</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{5}$</td>
<td style="text-align: center;">77.41</td>
<td style="text-align: center;">72.79</td>
<td style="text-align: center;">61.62</td>
<td style="text-align: center;">77.49</td>
<td style="text-align: center;">59.62</td>
<td style="text-align: center;">69.79</td>
</tr>
<tr>
<td style="text-align: center;">ER</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{1}$</td>
<td style="text-align: center;">77.11</td>
<td style="text-align: center;">76.29</td>
<td style="text-align: center;">62.85</td>
<td style="text-align: center;">76.49</td>
<td style="text-align: center;">63.07</td>
<td style="text-align: center;">71.16</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{2}$</td>
<td style="text-align: center;">78.40</td>
<td style="text-align: center;">79.13</td>
<td style="text-align: center;">61.41</td>
<td style="text-align: center;">76.25</td>
<td style="text-align: center;">67.41</td>
<td style="text-align: center;">72.52</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{3}$</td>
<td style="text-align: center;">78.18</td>
<td style="text-align: center;">78.04</td>
<td style="text-align: center;">63.98</td>
<td style="text-align: center;">75.57</td>
<td style="text-align: center;">57.53</td>
<td style="text-align: center;">70.70</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{4}$</td>
<td style="text-align: center;">77.47</td>
<td style="text-align: center;">72.40</td>
<td style="text-align: center;">62.19</td>
<td style="text-align: center;">80.44</td>
<td style="text-align: center;">59.89</td>
<td style="text-align: center;">73.13</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{5}$</td>
<td style="text-align: center;">77.57</td>
<td style="text-align: center;">72.15</td>
<td style="text-align: center;">61.92</td>
<td style="text-align: center;">78.25</td>
<td style="text-align: center;">63.49</td>
<td style="text-align: center;">70.68</td>
</tr>
<tr>
<td style="text-align: center;">Logit-KD</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{1}$</td>
<td style="text-align: center;">77.11</td>
<td style="text-align: center;">79.29</td>
<td style="text-align: center;">62.85</td>
<td style="text-align: center;">76.49</td>
<td style="text-align: center;">64.07</td>
<td style="text-align: center;">71.16</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{2}$</td>
<td style="text-align: center;">76.33</td>
<td style="text-align: center;">69.77</td>
<td style="text-align: center;">63.14</td>
<td style="text-align: center;">75.21</td>
<td style="text-align: center;">59.19</td>
<td style="text-align: center;">68.73</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{3}$</td>
<td style="text-align: center;">76.63</td>
<td style="text-align: center;">71.32</td>
<td style="text-align: center;">64.97</td>
<td style="text-align: center;">74.46</td>
<td style="text-align: center;">55.91</td>
<td style="text-align: center;">68.66</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{4}$</td>
<td style="text-align: center;">76.84</td>
<td style="text-align: center;">69.12</td>
<td style="text-align: center;">64.30</td>
<td style="text-align: center;">76.96</td>
<td style="text-align: center;">59.11</td>
<td style="text-align: center;">69.27</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{5}$</td>
<td style="text-align: center;">77.21</td>
<td style="text-align: center;">69.48</td>
<td style="text-align: center;">63.86</td>
<td style="text-align: center;">76.82</td>
<td style="text-align: center;">58.87</td>
<td style="text-align: center;">69.25</td>
</tr>
<tr>
<td style="text-align: center;">PNN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{1}$</td>
<td style="text-align: center;">76.04</td>
<td style="text-align: center;">74.11</td>
<td style="text-align: center;">62.31</td>
<td style="text-align: center;">75.09</td>
<td style="text-align: center;">59.57</td>
<td style="text-align: center;">69.42</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{2}$</td>
<td style="text-align: center;">76.04</td>
<td style="text-align: center;">76.30</td>
<td style="text-align: center;">64.74</td>
<td style="text-align: center;">75.65</td>
<td style="text-align: center;">59.19</td>
<td style="text-align: center;">70.24</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{3}$</td>
<td style="text-align: center;">76.04</td>
<td style="text-align: center;">76.30</td>
<td style="text-align: center;">68.01</td>
<td style="text-align: center;">75.51</td>
<td style="text-align: center;">55.91</td>
<td style="text-align: center;">71.76</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{4}$</td>
<td style="text-align: center;">76.04</td>
<td style="text-align: center;">76.30</td>
<td style="text-align: center;">68.01</td>
<td style="text-align: center;">79.46</td>
<td style="text-align: center;">59.11</td>
<td style="text-align: center;">72.51</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{5}$</td>
<td style="text-align: center;">76.04</td>
<td style="text-align: center;">76.30</td>
<td style="text-align: center;">68.01</td>
<td style="text-align: center;">79.46</td>
<td style="text-align: center;">58.87</td>
<td style="text-align: center;">73.01</td>
</tr>
<tr>
<td style="text-align: center;">ELLE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{1}$</td>
<td style="text-align: center;">77.12</td>
<td style="text-align: center;">78.85</td>
<td style="text-align: center;">64.05</td>
<td style="text-align: center;">76.81</td>
<td style="text-align: center;">65.67</td>
<td style="text-align: center;">72.50</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{2}$</td>
<td style="text-align: center;">79.67</td>
<td style="text-align: center;">78.48</td>
<td style="text-align: center;">67.93</td>
<td style="text-align: center;">76.38</td>
<td style="text-align: center;">65.84</td>
<td style="text-align: center;">73.66</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{3}$</td>
<td style="text-align: center;">81.99</td>
<td style="text-align: center;">86.75</td>
<td style="text-align: center;">69.32</td>
<td style="text-align: center;">78.14</td>
<td style="text-align: center;">62.63</td>
<td style="text-align: center;">75.77</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{4}$</td>
<td style="text-align: center;">82.55</td>
<td style="text-align: center;">81.18</td>
<td style="text-align: center;">69.19</td>
<td style="text-align: center;">83.27</td>
<td style="text-align: center;">69.03</td>
<td style="text-align: center;">77.04</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{5}$</td>
<td style="text-align: center;">83.17</td>
<td style="text-align: center;">81.83</td>
<td style="text-align: center;">68.47</td>
<td style="text-align: center;">82.87</td>
<td style="text-align: center;">72.69</td>
<td style="text-align: center;">77.81</td>
</tr>
</tbody>
</table>
<p>Table 9: Specific and average F1 scores on downstream tasks from each domain after the PLM finishes training on each domain. We evaluate PLMs trained with different lifelong learning methods that choose BERT $<em 1="1">{\text {L6_D384 }}$ as the initial model $\mathcal{M}</em>$.
$\boldsymbol{p}<em k="k">{k}^{i}$ and $\boldsymbol{p}</em>}^{j}$ output by the LM head of $\mathcal{M<em j="j">{i}$ and $\mathcal{M}</em>}$, respectively for each [MASK] token $k$, where $1 \leq k \leq n$. We calculate the average representational similarity (ARS) between $\mathcal{M<em 1="1">{j}$ and all its ancestors $\left{\mathcal{M}</em>\right}$ as follows:}, \cdots, \mathcal{M}_{j-1</p>
<p>$$
\operatorname{ARS}<em i="1">{j}=\frac{-1}{(j-1) \times n} \sum</em>}^{j-1} \sum_{k=1}^{n} \mathrm{KL}\left(\boldsymbol{p<em k="k">{k}^{i}, \boldsymbol{p}</em>\right)
$$}^{j</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Domain</th>
<th style="text-align: center;">WB</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Ns</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">REV</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">BIO</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">CS</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Metrics</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;">AP</td>
<td style="text-align: center;">AP+</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Half train wall time</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">MAS</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">8.50</td>
<td style="text-align: center;">6.22</td>
<td style="text-align: center;">12.85</td>
<td style="text-align: center;">18.88</td>
<td style="text-align: center;">13.99</td>
<td style="text-align: center;">17.52</td>
<td style="text-align: center;">10.31</td>
<td style="text-align: center;">10.22</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">ER</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">7.12</td>
<td style="text-align: center;">1.98</td>
<td style="text-align: center;">7.11</td>
<td style="text-align: center;">4.14</td>
<td style="text-align: center;">6.83</td>
<td style="text-align: center;">3.77</td>
<td style="text-align: center;">6.53</td>
<td style="text-align: center;">3.78</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Logit-KD</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">7.72</td>
<td style="text-align: center;">1.12</td>
<td style="text-align: center;">7.27</td>
<td style="text-align: center;">1.94</td>
<td style="text-align: center;">7.17</td>
<td style="text-align: center;">2.08</td>
<td style="text-align: center;">7.06</td>
<td style="text-align: center;">1.99</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">PNN</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">6.75</td>
<td style="text-align: center;">$\mathbf{0 . 0 0}$</td>
<td style="text-align: center;">5.53</td>
<td style="text-align: center;">$\mathbf{0 . 0 0}$</td>
<td style="text-align: center;">5.09</td>
<td style="text-align: center;">$\mathbf{0 . 0 0}$</td>
<td style="text-align: center;">5.03</td>
<td style="text-align: center;">$\mathbf{0 . 0 0}$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">ELLE (ours)</td>
<td style="text-align: center;">$\mathbf{7 . 9 2}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$\mathbf{6 . 0 5}$</td>
<td style="text-align: center;">0.26</td>
<td style="text-align: center;">$\mathbf{5 . 2 1}$</td>
<td style="text-align: center;">1.04</td>
<td style="text-align: center;">$\mathbf{4 . 8 3}$</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">$\mathbf{4 . 4 2}$</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Smaller memory</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">MAS</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">8.08</td>
<td style="text-align: center;">5.65</td>
<td style="text-align: center;">13.44</td>
<td style="text-align: center;">21.17</td>
<td style="text-align: center;">13.87</td>
<td style="text-align: center;">17.67</td>
<td style="text-align: center;">9.91</td>
<td style="text-align: center;">9.75</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">ER</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">6.99</td>
<td style="text-align: center;">2.09</td>
<td style="text-align: center;">7.15</td>
<td style="text-align: center;">4.53</td>
<td style="text-align: center;">6.86</td>
<td style="text-align: center;">4.09</td>
<td style="text-align: center;">6.49</td>
<td style="text-align: center;">3.42</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Logit-KD</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">7.68</td>
<td style="text-align: center;">1.15</td>
<td style="text-align: center;">7.24</td>
<td style="text-align: center;">2.06</td>
<td style="text-align: center;">7.21</td>
<td style="text-align: center;">2.27</td>
<td style="text-align: center;">7.05</td>
<td style="text-align: center;">2.16</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">PNN</td>
<td style="text-align: center;">7.96</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">6.52</td>
<td style="text-align: center;">$\mathbf{0 . 0 0}$</td>
<td style="text-align: center;">5.29</td>
<td style="text-align: center;">$\mathbf{0 . 0 0}$</td>
<td style="text-align: center;">4.84</td>
<td style="text-align: center;">$\mathbf{0 . 0 0}$</td>
<td style="text-align: center;">4.76</td>
<td style="text-align: center;">$\mathbf{0 . 0 0}$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">ELLE (ours)</td>
<td style="text-align: center;">$\mathbf{7 . 9 2}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$\mathbf{5 . 8 5}$</td>
<td style="text-align: center;">0.39</td>
<td style="text-align: center;">$\mathbf{5 . 0 4}$</td>
<td style="text-align: center;">1.13</td>
<td style="text-align: center;">$\mathbf{4 . 5 8}$</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">$\mathbf{4 . 2 0}$</td>
<td style="text-align: center;">0.70</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Full train wall time \&amp; memory (the main results in § 4)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">ELLE (ours)</td>
<td style="text-align: center;">7.92</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">5.62</td>
<td style="text-align: center;">$-0.20$</td>
<td style="text-align: center;">4.81</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">4.41</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">4.06</td>
<td style="text-align: center;">0.44</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 10: Average perplexity (AP) and average increased perplexity ( $\mathrm{AP}^{+}$) of PLMs trained by different lifelong learning methods with half train wall time on $\mathrm{Ns}, \mathrm{Rev}, \mathrm{Bio}, \mathrm{CS}$ domains and smaller memory containing 34 M tokens for each domain. We evaluate the performance each time when PLMs finish training on one domain.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Average representational similarity (ARS) of a stream of PLMs comparing different lifelong learning algorithms. We choose BERT $<em 1="1">{\text {LS_D384 }}$ as the initial PLM $\mathcal{M}</em>$.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Domain</th>
<th style="text-align: left;">WB</th>
<th style="text-align: left;">Ns</th>
<th style="text-align: left;">REV</th>
<th style="text-align: left;">BIO</th>
<th style="text-align: left;">CS</th>
<th style="text-align: left;">AVG</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Half train wall time</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">MAS</td>
<td style="text-align: left;">76.7</td>
<td style="text-align: left;">72.3</td>
<td style="text-align: left;">61.6</td>
<td style="text-align: left;">77.4</td>
<td style="text-align: left;">64.3</td>
<td style="text-align: left;">70.5</td>
</tr>
<tr>
<td style="text-align: left;">ER</td>
<td style="text-align: left;">78.0</td>
<td style="text-align: left;">71.0</td>
<td style="text-align: left;">61.1</td>
<td style="text-align: left;">77.4</td>
<td style="text-align: left;">65.8</td>
<td style="text-align: left;">70.7</td>
</tr>
<tr>
<td style="text-align: left;">Logit-KD</td>
<td style="text-align: left;">77.0</td>
<td style="text-align: left;">72.6</td>
<td style="text-align: left;">63.8</td>
<td style="text-align: left;">76.2</td>
<td style="text-align: left;">58.4</td>
<td style="text-align: left;">69.6</td>
</tr>
<tr>
<td style="text-align: left;">PNN</td>
<td style="text-align: left;">76.0</td>
<td style="text-align: left;">55.9</td>
<td style="text-align: left;">62.6</td>
<td style="text-align: left;">53.1</td>
<td style="text-align: left;">28.0</td>
<td style="text-align: left;">55.1</td>
</tr>
<tr>
<td style="text-align: left;">ELLE</td>
<td style="text-align: left;">$\mathbf{8 2 . 0}$</td>
<td style="text-align: left;">$\mathbf{7 8 . 4}$</td>
<td style="text-align: left;">$\mathbf{6 8 . 7}$</td>
<td style="text-align: left;">$\mathbf{8 1 . 7}$</td>
<td style="text-align: left;">$\mathbf{7 4 . 0}$</td>
<td style="text-align: left;">$\mathbf{7 7 . 0}$</td>
</tr>
<tr>
<td style="text-align: left;">Smaller memory</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">MAS</td>
<td style="text-align: left;">77.1</td>
<td style="text-align: left;">73.7</td>
<td style="text-align: left;">60.7</td>
<td style="text-align: left;">77.5</td>
<td style="text-align: left;">68.2</td>
<td style="text-align: left;">71.5</td>
</tr>
<tr>
<td style="text-align: left;">ER</td>
<td style="text-align: left;">77.9</td>
<td style="text-align: left;">72.0</td>
<td style="text-align: left;">61.5</td>
<td style="text-align: left;">76.3</td>
<td style="text-align: left;">63.6</td>
<td style="text-align: left;">70.3</td>
</tr>
<tr>
<td style="text-align: left;">Logit-KD</td>
<td style="text-align: left;">77.0</td>
<td style="text-align: left;">73.1</td>
<td style="text-align: left;">63.3</td>
<td style="text-align: left;">75.9</td>
<td style="text-align: left;">57.4</td>
<td style="text-align: left;">69.3</td>
</tr>
<tr>
<td style="text-align: left;">PNN</td>
<td style="text-align: left;">76.0</td>
<td style="text-align: left;">64.9</td>
<td style="text-align: left;">64.2</td>
<td style="text-align: left;">55.1</td>
<td style="text-align: left;">30.5</td>
<td style="text-align: left;">58.1</td>
</tr>
<tr>
<td style="text-align: left;">ELLE</td>
<td style="text-align: left;">$\mathbf{8 2 . 9}$</td>
<td style="text-align: left;">$\mathbf{8 0 . 5}$</td>
<td style="text-align: left;">$\mathbf{6 8 . 9}$</td>
<td style="text-align: left;">$\mathbf{8 2 . 6}$</td>
<td style="text-align: left;">$\mathbf{7 4 . 2}$</td>
<td style="text-align: left;">$\mathbf{7 7 . 8}$</td>
</tr>
<tr>
<td style="text-align: left;">Full train wall time \&amp; memory (the main results in § 4)</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">ELLE</td>
<td style="text-align: left;">83.2</td>
<td style="text-align: left;">81.8</td>
<td style="text-align: left;">68.5</td>
<td style="text-align: left;">82.9</td>
<td style="text-align: left;">72.7</td>
<td style="text-align: left;">77.8</td>
</tr>
</tbody>
</table>
<p>Table 11: Final downstream performance (F1) of BERT on each domain after finishing pre-training on all domains with half train wall time on $\mathrm{Ns}, \mathrm{Rev}, \mathrm{Bio}, \mathrm{CS}$ domains and smaller memory containing 34 M tokens for each domain. Experiments of Ns domain are repeated for 10 times with different seeds and others are repeated for 5 times.
where KL denotes the Kullback-Leibler divergence between two probability distributions. Higher
$\mathrm{ARS}<em j="j">{j}$ means the representations of $\mathcal{M}</em>}$ and its ancestors are more similar. To some extent, $\mathrm{ARS<em j="j">{j}$ could reflect how much knowledge / functionality of the ancestors is preserved by $\mathcal{M}</em>$.</p>
<p>We compare ARS of PLMs trained by Naive, MAS, ER, Logit-KD and ELLE and illustrate the results in Figure 6, from which we observe that Logit-KD has the highest ARS. This is because the training objective of knowledge distillation in Logit-KD is highly correlated with ARS. In addition, ELLE takes second place. We also find that, with PLMs continually absorbing new knowledge, the ASR generally decreases.</p>
<h2>F Model Architectures for the Analysis of Model Expansion</h2>
<p>In Table 12, we list the model architectures of all the investigated PLMs when conducting analysis of model expansion in $\S 5$. Specifically, three strategies are investigated, including WE+FRW, DE+FRW and WE+DE+FRW. As mentioned in our main paper, for a fair comparison, we keep the total number of $\mathcal{M}_{i}$ 's increased parameters for the above three strategies almost the same at each stage $i$.</p>
<h2>G Performance of ELLE with Fewer Computational Budgets and Storage Budgets</h2>
<p>To investigate the performance of ELLE under limited (1) computational budgets and (2) storage budgets, in this section, we take an initial step to investigate the effect of (1) training resources (train</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">$n_{\text {params }}$</th>
<th style="text-align: center;">$n_{\text {layers }}$</th>
<th style="text-align: center;">$d_{\text {model }}$</th>
<th style="text-align: center;">$n_{\text {heads }}$</th>
<th style="text-align: center;">$d_{\text {PPN }}$</th>
<th style="text-align: center;">lr</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">WE + FRW</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{1}$</td>
<td style="text-align: center;">30.3 M</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">384</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">1536</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{2}$</td>
<td style="text-align: center;">53.6 M</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">576</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">2304</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{3}$</td>
<td style="text-align: center;">82.2 M</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{4}$</td>
<td style="text-align: center;">104 M</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">896</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">3584</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{5}$</td>
<td style="text-align: center;">129 M</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">1024</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">4096</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;">DE + FRW</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{1}$</td>
<td style="text-align: center;">30.3 M</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{2}$</td>
<td style="text-align: center;">51.6 M</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">$2.5 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{3}$</td>
<td style="text-align: center;">83.6 M</td>
<td style="text-align: center;">36</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">$2.5 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{4}$</td>
<td style="text-align: center;">105 M</td>
<td style="text-align: center;">48</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">$2.5 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{5}$</td>
<td style="text-align: center;">126 M</td>
<td style="text-align: center;">60</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">$2.5 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;">WE + DE + FRW</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{1}$</td>
<td style="text-align: center;">30.3 M</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">384</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">1536</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{2}$</td>
<td style="text-align: center;">51.5 M</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">2048</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{3}$</td>
<td style="text-align: center;">82.2 M</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">640</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">2560</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{4}$</td>
<td style="text-align: center;">102 M</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">704</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">2816</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{M}_{5}$</td>
<td style="text-align: center;">125 M</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">$5.0 \times 10^{-4}$</td>
</tr>
</tbody>
</table>
<p>Table 12: Model architectures the investigated PLMs of WE+FRW, DE+FRW, WE+DE+FRW. We keep the total number of $\mathcal{M}<em _mathrm_L="\mathrm{L">{i}$ 's increased parameters for the above three strategies almost the same at each stage $i$.
wall time) and (2) memory size for ELLE. Following the experimental setting in $\S 4$, we continually grow $\mathrm{BERT}</em>} 6 _\mathrm{D} 384}$ to $\mathrm{BERT<em i="i">{\mathrm{L} 12 _\mathrm{D} 768}$ on a stream of data from 5 domains. We test the performance of ELLE and a series of lifelong learning baselines (MAS, ER, Logit-KD and PNN), by (1) reducing the train wall time by half (for NS, REV, BIO and CS domain) and (2) randomly sample only 34 M tokens ( $1 \%$ of the full corpus) as the memory $\mathcal{D}</em>$ for each corpus $i$, compared with the memory size 200 M in $\S 4$.}^{\text {sub }</p>
<p>The experimental results for the above two settings are listed in Table 10 (pre-training) and Table 11 (fine-tuning), respectively. We also illustrate the trend curves of AP and $\mathrm{AP}^{+}$in Figure 13 and Figure 14. From the above results, we find that: (1) when given fewer computational budgets and storage budgets, ELLE still outperforms all the lifelong learning baselines in both pre-training and downstream performance, which demonstrates the superiority of ELLE; (2) for ELLE, when PLMs are trained with fewer computational budgets, we observe significant performance drops in both pre-training (higher AP and $\mathrm{AP}^{+}$) and downstream tasks (lower average F1). This shows that pre-training with fewer computations would harm PLMs' knowledge acquisition; (3) for ELLE, when there are fewer memory budgets, although we also observe slight performance drops in pretraining (higher AP and $\mathrm{AP}^{+}$), the performance in downstream tasks is generally not influenced, with the average F1 score keeping almost the same
(77.8). This shows the data-efficiency of PLMs, i.e., PLMs could easily recall the learned knowledge by reviewing small-scale data conserved in the memory (as few as $1 \%$ ). As mentioned before, considering that for pre-training, the expense of storage (e.g., hard disks) is far cheaper than the computational resources (e.g., GPUs), the storage space problem for memory seldom needs to be considered.</p>
<h2>H Details of Baselines</h2>
<p>We tried different hyper-parameters for baselines, including the regularization parameter $\lambda$ for EWC and MAS, and the memory size for A-GEM, to derive and report their best performance. Their AP and $\mathrm{AP}^{+}$curves are shown in Figure 15, 16 and 17. From the results we can see that none of these hyperparameters works well. For EWC and MAS, when the regularization parameter $\lambda$ is small, the pre-training performance is not obviously better than that of naive method. However, if we slightly increase $\lambda$, the performance would become worse than baseline. For A-GEM, the case with bigger memory also doesn't clearly outperform cases with smaller memory and naive case. Specially, we observed that during A-GEM pre-training, $99.9 \%$ of the inter-products of current gradient and replay gradient are positive, implying that pre-training on different domains is similar to each other to a large extent. This might indicate that EWC, MAS, and A-GEM cannot deal with the subtle difference of various domains.</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: AP and AP $^{+}$of different lifelong learning methods with BERT $<em _L6_D384="{L6_D384" _text="\text">{\text {L6_D384 }}$ as the initial PLM w.r.t train wall time. ELLE continually grows BERT $</em>$.
}}$ to BERT $_{\text {L12_D768 }<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: AP and AP $^{+}$of ELLE when growing BERT $<em _L24_D1024="{L24_D1024" _text="\text">{\text {L12_D768 }}$ to BERT $</em>$.
}<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 9: AP and AP $^{+}$of different lifelong learning methods with GPT $<em _L6_D384="{L6_D384" _text="\text">{\text {L6_D384 }}$ as the initial PLM w.r.t train wall time. ELLE continually grows GPT $</em>$.}}$ to GPT $_{\text {L12_D768 }</p>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Figure 10: AP and $\mathrm{AP}^{+}$of PLMs trained with different model expansion strategies: expanding width only (WE+FRW), expanding depth only (DE+FRW) and expanding width and depth together (WE+DE+FRW) w.r.t train wall time.
<img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<p>Figure 11: AP and $\mathrm{AP}^{+}$of PLMs trained by $\mathrm{WE}+\mathrm{DE}, \mathrm{WE}+\mathrm{DE}+\mathrm{FRW}, \mathrm{WE}+\mathrm{DE}+\mathrm{FRW}+\delta_{N}$ w.r.t train wall time.
<img alt="img-11.jpeg" src="img-11.jpeg" /></p>
<p>Figure 12: AP and $\mathrm{AP}^{+}$of PLMs trained by ELLE with and without domain prompts w.r.t train wall time.</p>
<p><img alt="img-12.jpeg" src="img-12.jpeg" /></p>
<p>Figure 13: AP and $\mathrm{AP}^{+}$of different lifelong learning methods with $\mathrm{BERT}<em _mathrm_L="\mathrm{L">{\mathrm{L6} _\mathrm{D} 384}$ as the initial model w.r.t train wall time. The train wall time on News, Review, Bio, CS domains is half of the original experiment in Section 4. ELLE continually grows $\mathrm{BERT}</em>$.
} 6 _\mathrm{D} 384}$ to $\mathrm{BERT}_{\mathrm{L} 12 _\mathrm{D} 768<img alt="img-13.jpeg" src="img-13.jpeg" /></p>
<p>Figure 14: AP and $\mathrm{AP}^{+}$of different lifelong learning methods with $\mathrm{BERT}<em i="i">{\mathrm{L} 6 _\mathrm{D} 384}$ as the initial model with smaller memory w.r.t train wall time. For domain $i$, we randomly sample only about 34 M tokens as memory $\mathcal{D}</em>}^{\text {sub }}$, which is $1 \%$ of training corpus $\mathcal{D<em _mathrm_L="\mathrm{L">{i}$. ELLE continually grows $\mathrm{BERT}</em>$.
} 6 _\mathrm{D} 384}$ to $\mathrm{BERT}_{\mathrm{L} 12 _\mathrm{D} 768<img alt="img-14.jpeg" src="img-14.jpeg" /></p>
<p>Figure 15: AP and $\mathrm{AP}^{+}$of EWC with $\mathrm{BERT}_{\mathrm{L} 6 _\mathrm{D} 384}$ as the initial model and with different regularization parameter $\lambda$ w.r.t train wall time.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ https://github.com/pytorch/fairseq
${ }^{2}$ https://github.com/pytorch/fairseq
${ }^{3}$ https://github.com/allenai/
dont-stop-pretraining&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>