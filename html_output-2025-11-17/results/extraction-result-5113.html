<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5113 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5113</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5113</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-107.html">extraction-schema-107</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <p><strong>Paper ID:</strong> paper-f977d79980ed2dfc7b2194fe680895e49b3b60a9</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/f977d79980ed2dfc7b2194fe680895e49b3b60a9" target="_blank">From LSAT: The Progress and Challenges of Complex Reasoning</a></p>
                <p><strong>Paper Venue:</strong> IEEE/ACM Transactions on Audio Speech and Language Processing</p>
                <p><strong>Paper TL;DR:</strong> This paper proposes a hybrid reasoning system to integrate these three tasks of the LSAT, including analytical reasoning, logical reasoning and reading comprehension, and sheds a light on the potential future directions, like unsupervised symbolic knowledge extraction, model interpretability, few-shot learning and comprehensive benchmark for complex reasoning.</p>
                <p><strong>Paper Abstract:</strong> Complex reasoning aims to draw a correct inference based on complex rules. As a hallmark of human intelligence, it involves a degree of explicit reading comprehension, interpretation of logical knowledge and complex rule application. In this paper, we take a step forward in complex reasoning by systematically studying the three challenging and domain-general tasks of the Law School Admission Test (LSAT), including analytical reasoning, logical reasoning and reading comprehension. We propose a hybrid reasoning system to integrate these three tasks and achieve impressive overall performance on the LSAT tests. The experimental results demonstrate that our system endows itself a certain complex reasoning ability, especially the fundamental reading comprehension and challenging logical reasoning capacities. Further analysis also shows the effectiveness of combining the pre-trained models with the task-specific reasoning module, and integrating symbolic knowledge into discrete interpretable reasoning steps in complex reasoning. We further shed a light on the potential future directions, like unsupervised symbolic knowledge extraction, model interpretability, few-shot learning and comprehensive benchmark for complex reasoning.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5113.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5113.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LReasoner</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Logic-driven Reasoner (LReasoner)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural-symbolic system that extracts elementary logical symbols and expressions from text, performs symbolic logical inference (contraposition and transitivity) to extend implicit logic, verbalizes the inferred expressions into natural language, and feeds the extended context into a pretrained transformer for answer selection; also uses logic-driven data augmentation with contrastive learning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LReasoner (with ALBERT / RoBERTa backbones)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A hybrid pipeline: (1) Logic Identification via constituency parsing to extract noun/gerund phrases as logical symbols and heuristics to form initial expressions with ¬ and →; (2) Logic Extension applying symbolic equivalence laws (contraposition and transitive law) to derive implicit expressions; (3) Logic Verbalization: template-based natural language generation of derived expressions; (4) use of a pretrained Transformer encoder (ALBERT or RoBERTa) to score candidate options given the extended context. Additionally, a logic-driven data augmentation procedure constructs logically-contrasting negative examples and trains with a contrastive loss alongside answer prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>LR-LSAT (Logical Reasoning subset of LSAT); also evaluated on ReClor and LogiQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple-choice logical reasoning questions sourced from LSAT (LR-LSAT) requiring extraction of propositional constituents and explicit logical inference (negations, implications, transitivity, contraposition). ReClor and LogiQA are similar standardized-exam derived benchmarks testing deeper logical reasoning over short passages.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Neural-symbolic pipeline: unsupervised heuristic logic identification (constituency parse + negation/conditional heuristics), symbolic logic extension using logical equivalence laws (contraposition and transitivity), verbalization of derived expressions into natural language and concatenation with original context as model input; plus logic-driven data augmentation (modify/delete/reverse/negate logical expressions to produce hard negatives) and contrastive learning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>On LR-LSAT: LReasoner_ALBERT Val 65.0% / Test 63.5%; LReasoner_RoBERTa Val 54.0% / Test 53.3%. Ablations: without Context Extension (w/o CE) LReasoner_ALBERT Val 63.4% / Test 61.6%; without Data Augmentation (w/o DA) Val 61.7% / Test 60.0%. On ReClor: LReasoner_ALBERT Val 73.2% / Test 70.7% (surpassing reported baseline ALBERT); LReasoner_RoBERTa Val 66.2% / Test 62.4%. On LogiQA: LReasoner_ALBERT Val 41.6% / Test 41.2%; LReasoner_RoBERTa Val 38.1% / Test 40.6%.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Logic identification is heuristic and imperfect: sampled recall for logical symbol identification ≈ 65.9% and for logical expression identification ≈ 48.9%, causing missed or noisy symbolic inputs; the approach struggles on question types requiring abstract flaw matching (e.g., 'Match flaws') and weakening (Weaken) questions (these types achieve ≈60% accuracy vs. >70% on other types); reliance on verbalization (natural-language encoding of symbolic facts) may be suboptimal versus directly encoding symbolic structure; unsupervised extraction errors and symbol ambiguity limit end-to-end robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>LReasoner substantially outperforms plain pretrained baselines on LR-LSAT (ALBERT baseline 57.9%/57.8% vs LReasoner_ALBERT 65.0%/63.5%) and improves over RoBERTa baseline; on ReClor LReasoner_ALBERT outperforms baseline ALBERT (70.2%/66.5% baseline → 73.2%/70.7%); on LogiQA modest gains observed. Authors report that LReasoner_ALBERT even surpasses human performance reported for ReClor (human 63.0% per table). Ablation shows both the context-extension module and data augmentation contribute meaningfully to gains.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Ablation: removing Context Extension (CE) drops LReasoner_ALBERT from Val 65.0%/Test 63.5% to Val 63.4%/Test 61.6%; removing Data Augmentation (DA) drops to Val 61.7%/Test 60.0%, indicating both components help. Logic identification evaluation on 50 sampled instances: symbol recall 65.9%, expression recall 48.9%. Error analysis: worst performance on 'Match flaws' and 'Weaken' categories (~60% accuracy) vs. >70% on many other categories.</td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>The system is reported and evaluated in this paper as the principal logical-reasoning improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From LSAT: The Progress and Challenges of Complex Reasoning', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5113.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5113.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ALBERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A parameter-reduced variant of BERT that shares parameters across layers and uses factorized embedding parameterization; used as a backbone encoder for several experiments and as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ALBERT: A lite bert for self-supervised learning of language representations</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ALBERT (pretrained transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pretrained Transformer-based encoder (BERT-family) with parameter-reduction techniques (cross-layer parameter sharing and factorized embedding parameterization) that enable training larger models with fewer parameters; used here as the backbone for baseline and as the encoder in LReasoner_ALBERT and in position-aware RC models.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>LR-LSAT (and ReClor, LogiQA as baselines)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple-choice logical reasoning benchmarks requiring inference over short passages and extraction of logical relations.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Fine-tuning ALBERT on LR-LSAT as baseline; also used as the encoder inside the LReasoner pipeline which receives extended context sentences produced by logic verbalization.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Baseline ALBERT on LR-LSAT: Val 57.9% / Test 57.8%. Within LReasoner_ALBERT (with logic modules) performance improved to Val 65.0% / Test 63.5%. On ReClor baseline ALBERT: Val 70.2% / Test 66.5%; on LogiQA baseline ALBERT: Val 38.9% / Test 37.6%.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>As a pure neural model, ALBERT alone relies on surface-level semantics and struggles to capture discrete logical structure compared to the logic-driven pipeline; performance improvements require explicit symbolic augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>ALBERT baseline is stronger than RoBERTa and BERT baselines on LR-LSAT; LReasoner built on ALBERT yields further gains, indicating benefit of symbolic augmentation when combined with a strong pretrained encoder.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Comparison rows in Table V show ALBERT baseline vs LReasoner_ALBERT and ablations for CE and DA demonstrating contributions of logic modules when ALBERT is the backbone.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From LSAT: The Progress and Challenges of Complex Reasoning', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5113.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5113.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RoBERTa</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RoBERTa: A Robustly Optimized BERT Pretraining Approach</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An improved BERT-style transformer pretraining recipe (longer training, dynamic masking, larger batches) used as a backbone and baseline in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>RoBERTa: A robustly optimized bert pretraining approach</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa (pretrained transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>BERT-family transformer pretrained with optimized hyperparameters and training regimes (e.g., dynamic masking); used as baseline and as the encoder in LReasoner_RoBERTa and other components like CGAR/NSAR extractors.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>LR-LSAT (and ReClor, LogiQA as baselines)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple-choice logical reasoning requiring propositional extraction and inference.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Fine-tuning RoBERTa as baseline; used as encoder within logic-driven pipeline (LReasoner_RoBERTa) where extended context is concatenated and fed to RoBERTa for scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Baseline RoBERTa on LR-LSAT: Val 49.2% / Test 49.6%. LReasoner_RoBERTa: Val 54.0% / Test 53.3%. On ReClor RoBERTa baseline: Val 62.6% / Test 55.6%; LReasoner_RoBERTa: Val 66.2% / Test 62.4%. On LogiQA RoBERTa baseline: Val 35.9% / Test 35.3%; LReasoner_RoBERTa: Val 38.1% / Test 40.6%.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>As with ALBERT, RoBERTa alone often captures surface semantics but fails to model discrete logical transformations without explicit symbolic augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>RoBERTa baseline is weaker than ALBERT on LR-LSAT; LReasoner_RoBERTa improves over RoBERTa but less than the ALBERT-backed LReasoner.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Table V shows LReasoner variants using RoBERTa vs ALBERT; gains from logic modules are observed with either backbone though absolute performance differs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From LSAT: The Progress and Challenges of Complex Reasoning', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5113.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5113.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The original bidirectional Transformer pretraining model used as a baseline in logical reasoning experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>BERT: Pre-training of deep bidirectional transformers for language understanding</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (pretrained transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Bidirectional Transformer encoder pretrained with masked language modeling and next-sentence prediction; used as a baseline model for LR-LSAT.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>LR-LSAT</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple-choice logical reasoning from LSAT requiring extraction and inference of propositional logic.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Fine-tuning BERT on LR-LSAT as a baseline to compare against more logic-aware methods.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Baseline BERT on LR-LSAT: Val 39.3% / Test 39.4%.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Poorer performance relative to RoBERTa/ALBERT baselines; lacks explicit mechanisms to capture discrete logic structures.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>Underperforms RoBERTa and ALBERT baselines; LReasoner variants (with symbolic modules) substantially outperform BERT baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Serves as a point of comparison in Table V; no ablation specific to BERT reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From LSAT: The Progress and Challenges of Complex Reasoning', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5113.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5113.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DAGN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DAGn: Discourse-Aware Graph Network for Logical Reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A discourse-aware graph neural network previously proposed for logical reasoning; used as a baseline comparison on ReClor and LogiQA benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dagn: Discourse-aware graph network for logical reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DAGN (Discourse-aware Graph Network)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A graph-based neural model that builds discourse/logic-aware graphs over passages and uses graph neural networks to perform logical reasoning; included in comparisons on ReClor and LogiQA.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>ReClor, LogiQA (and comparable logical reasoning benchmarks)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Standardized-exam derived logical reasoning multiple-choice QA requiring discourse-level and logical inference.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Graph construction over discourse elements and GNN-based reasoning to capture relations between propositions; used as a baseline in evaluation tables.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported in Table VI: On ReClor Val 65.8% / Test 58.3%; on LogiQA Val 36.9% / Test 39.3%.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Listed as baseline; paper does not deeply analyze DAGN failure modes but shows LReasoner variants outperform DAGN on these datasets when combined with logic-driven extension and strong pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>DAGN is outperformed by LReasoner_ALBERT on ReClor and LogiQA in reported experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>No ablation inside this paper; included only as a comparative baseline in results tables.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From LSAT: The Progress and Challenges of Complex Reasoning', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Logic-driven context extension and data augmentation for logical reasoning of text <em>(Rating: 2)</em></li>
                <li>Reclor: A reading comprehension dataset requiring logical reasoning <em>(Rating: 2)</em></li>
                <li>LogiQA: A challenge dataset for machine reading comprehension with logical reasoning <em>(Rating: 2)</em></li>
                <li>RoBERTa: A robustly optimized bert pretraining approach <em>(Rating: 1)</em></li>
                <li>ALBERT: A lite bert for self-supervised learning of language representations <em>(Rating: 1)</em></li>
                <li>BERT: Pre-training of deep bidirectional transformers for language understanding <em>(Rating: 1)</em></li>
                <li>Dagn: Discourse-aware graph network for logical reasoning <em>(Rating: 2)</em></li>
                <li>Neural Symbolic Reader: Scalable integration of distributed and symbolic representations for reading comprehension <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5113",
    "paper_id": "paper-f977d79980ed2dfc7b2194fe680895e49b3b60a9",
    "extraction_schema_id": "extraction-schema-107",
    "extracted_data": [
        {
            "name_short": "LReasoner",
            "name_full": "Logic-driven Reasoner (LReasoner)",
            "brief_description": "A neural-symbolic system that extracts elementary logical symbols and expressions from text, performs symbolic logical inference (contraposition and transitivity) to extend implicit logic, verbalizes the inferred expressions into natural language, and feeds the extended context into a pretrained transformer for answer selection; also uses logic-driven data augmentation with contrastive learning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LReasoner (with ALBERT / RoBERTa backbones)",
            "model_description": "A hybrid pipeline: (1) Logic Identification via constituency parsing to extract noun/gerund phrases as logical symbols and heuristics to form initial expressions with ¬ and →; (2) Logic Extension applying symbolic equivalence laws (contraposition and transitive law) to derive implicit expressions; (3) Logic Verbalization: template-based natural language generation of derived expressions; (4) use of a pretrained Transformer encoder (ALBERT or RoBERTa) to score candidate options given the extended context. Additionally, a logic-driven data augmentation procedure constructs logically-contrasting negative examples and trains with a contrastive loss alongside answer prediction.",
            "model_size": null,
            "logical_reasoning_task": "LR-LSAT (Logical Reasoning subset of LSAT); also evaluated on ReClor and LogiQA",
            "task_description": "Multiple-choice logical reasoning questions sourced from LSAT (LR-LSAT) requiring extraction of propositional constituents and explicit logical inference (negations, implications, transitivity, contraposition). ReClor and LogiQA are similar standardized-exam derived benchmarks testing deeper logical reasoning over short passages.",
            "method_or_approach": "Neural-symbolic pipeline: unsupervised heuristic logic identification (constituency parse + negation/conditional heuristics), symbolic logic extension using logical equivalence laws (contraposition and transitivity), verbalization of derived expressions into natural language and concatenation with original context as model input; plus logic-driven data augmentation (modify/delete/reverse/negate logical expressions to produce hard negatives) and contrastive learning.",
            "performance": "On LR-LSAT: LReasoner_ALBERT Val 65.0% / Test 63.5%; LReasoner_RoBERTa Val 54.0% / Test 53.3%. Ablations: without Context Extension (w/o CE) LReasoner_ALBERT Val 63.4% / Test 61.6%; without Data Augmentation (w/o DA) Val 61.7% / Test 60.0%. On ReClor: LReasoner_ALBERT Val 73.2% / Test 70.7% (surpassing reported baseline ALBERT); LReasoner_RoBERTa Val 66.2% / Test 62.4%. On LogiQA: LReasoner_ALBERT Val 41.6% / Test 41.2%; LReasoner_RoBERTa Val 38.1% / Test 40.6%.",
            "limitations_or_failure_cases": "Logic identification is heuristic and imperfect: sampled recall for logical symbol identification ≈ 65.9% and for logical expression identification ≈ 48.9%, causing missed or noisy symbolic inputs; the approach struggles on question types requiring abstract flaw matching (e.g., 'Match flaws') and weakening (Weaken) questions (these types achieve ≈60% accuracy vs. &gt;70% on other types); reliance on verbalization (natural-language encoding of symbolic facts) may be suboptimal versus directly encoding symbolic structure; unsupervised extraction errors and symbol ambiguity limit end-to-end robustness.",
            "comparison": "LReasoner substantially outperforms plain pretrained baselines on LR-LSAT (ALBERT baseline 57.9%/57.8% vs LReasoner_ALBERT 65.0%/63.5%) and improves over RoBERTa baseline; on ReClor LReasoner_ALBERT outperforms baseline ALBERT (70.2%/66.5% baseline → 73.2%/70.7%); on LogiQA modest gains observed. Authors report that LReasoner_ALBERT even surpasses human performance reported for ReClor (human 63.0% per table). Ablation shows both the context-extension module and data augmentation contribute meaningfully to gains.",
            "ablation_or_analysis_results": "Ablation: removing Context Extension (CE) drops LReasoner_ALBERT from Val 65.0%/Test 63.5% to Val 63.4%/Test 61.6%; removing Data Augmentation (DA) drops to Val 61.7%/Test 60.0%, indicating both components help. Logic identification evaluation on 50 sampled instances: symbol recall 65.9%, expression recall 48.9%. Error analysis: worst performance on 'Match flaws' and 'Weaken' categories (~60% accuracy) vs. &gt;70% on many other categories.",
            "notes": "The system is reported and evaluated in this paper as the principal logical-reasoning improvement.",
            "uuid": "e5113.0",
            "source_info": {
                "paper_title": "From LSAT: The Progress and Challenges of Complex Reasoning",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "ALBERT",
            "name_full": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations",
            "brief_description": "A parameter-reduced variant of BERT that shares parameters across layers and uses factorized embedding parameterization; used as a backbone encoder for several experiments and as a baseline.",
            "citation_title": "ALBERT: A lite bert for self-supervised learning of language representations",
            "mention_or_use": "use",
            "model_name": "ALBERT (pretrained transformer)",
            "model_description": "Pretrained Transformer-based encoder (BERT-family) with parameter-reduction techniques (cross-layer parameter sharing and factorized embedding parameterization) that enable training larger models with fewer parameters; used here as the backbone for baseline and as the encoder in LReasoner_ALBERT and in position-aware RC models.",
            "model_size": null,
            "logical_reasoning_task": "LR-LSAT (and ReClor, LogiQA as baselines)",
            "task_description": "Multiple-choice logical reasoning benchmarks requiring inference over short passages and extraction of logical relations.",
            "method_or_approach": "Fine-tuning ALBERT on LR-LSAT as baseline; also used as the encoder inside the LReasoner pipeline which receives extended context sentences produced by logic verbalization.",
            "performance": "Baseline ALBERT on LR-LSAT: Val 57.9% / Test 57.8%. Within LReasoner_ALBERT (with logic modules) performance improved to Val 65.0% / Test 63.5%. On ReClor baseline ALBERT: Val 70.2% / Test 66.5%; on LogiQA baseline ALBERT: Val 38.9% / Test 37.6%.",
            "limitations_or_failure_cases": "As a pure neural model, ALBERT alone relies on surface-level semantics and struggles to capture discrete logical structure compared to the logic-driven pipeline; performance improvements require explicit symbolic augmentation.",
            "comparison": "ALBERT baseline is stronger than RoBERTa and BERT baselines on LR-LSAT; LReasoner built on ALBERT yields further gains, indicating benefit of symbolic augmentation when combined with a strong pretrained encoder.",
            "ablation_or_analysis_results": "Comparison rows in Table V show ALBERT baseline vs LReasoner_ALBERT and ablations for CE and DA demonstrating contributions of logic modules when ALBERT is the backbone.",
            "uuid": "e5113.1",
            "source_info": {
                "paper_title": "From LSAT: The Progress and Challenges of Complex Reasoning",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "RoBERTa",
            "name_full": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
            "brief_description": "An improved BERT-style transformer pretraining recipe (longer training, dynamic masking, larger batches) used as a backbone and baseline in experiments.",
            "citation_title": "RoBERTa: A robustly optimized bert pretraining approach",
            "mention_or_use": "use",
            "model_name": "RoBERTa (pretrained transformer)",
            "model_description": "BERT-family transformer pretrained with optimized hyperparameters and training regimes (e.g., dynamic masking); used as baseline and as the encoder in LReasoner_RoBERTa and other components like CGAR/NSAR extractors.",
            "model_size": null,
            "logical_reasoning_task": "LR-LSAT (and ReClor, LogiQA as baselines)",
            "task_description": "Multiple-choice logical reasoning requiring propositional extraction and inference.",
            "method_or_approach": "Fine-tuning RoBERTa as baseline; used as encoder within logic-driven pipeline (LReasoner_RoBERTa) where extended context is concatenated and fed to RoBERTa for scoring.",
            "performance": "Baseline RoBERTa on LR-LSAT: Val 49.2% / Test 49.6%. LReasoner_RoBERTa: Val 54.0% / Test 53.3%. On ReClor RoBERTa baseline: Val 62.6% / Test 55.6%; LReasoner_RoBERTa: Val 66.2% / Test 62.4%. On LogiQA RoBERTa baseline: Val 35.9% / Test 35.3%; LReasoner_RoBERTa: Val 38.1% / Test 40.6%.",
            "limitations_or_failure_cases": "As with ALBERT, RoBERTa alone often captures surface semantics but fails to model discrete logical transformations without explicit symbolic augmentation.",
            "comparison": "RoBERTa baseline is weaker than ALBERT on LR-LSAT; LReasoner_RoBERTa improves over RoBERTa but less than the ALBERT-backed LReasoner.",
            "ablation_or_analysis_results": "Table V shows LReasoner variants using RoBERTa vs ALBERT; gains from logic modules are observed with either backbone though absolute performance differs.",
            "uuid": "e5113.2",
            "source_info": {
                "paper_title": "From LSAT: The Progress and Challenges of Complex Reasoning",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "BERT",
            "name_full": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "brief_description": "The original bidirectional Transformer pretraining model used as a baseline in logical reasoning experiments.",
            "citation_title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "mention_or_use": "use",
            "model_name": "BERT (pretrained transformer)",
            "model_description": "Bidirectional Transformer encoder pretrained with masked language modeling and next-sentence prediction; used as a baseline model for LR-LSAT.",
            "model_size": null,
            "logical_reasoning_task": "LR-LSAT",
            "task_description": "Multiple-choice logical reasoning from LSAT requiring extraction and inference of propositional logic.",
            "method_or_approach": "Fine-tuning BERT on LR-LSAT as a baseline to compare against more logic-aware methods.",
            "performance": "Baseline BERT on LR-LSAT: Val 39.3% / Test 39.4%.",
            "limitations_or_failure_cases": "Poorer performance relative to RoBERTa/ALBERT baselines; lacks explicit mechanisms to capture discrete logic structures.",
            "comparison": "Underperforms RoBERTa and ALBERT baselines; LReasoner variants (with symbolic modules) substantially outperform BERT baseline.",
            "ablation_or_analysis_results": "Serves as a point of comparison in Table V; no ablation specific to BERT reported.",
            "uuid": "e5113.3",
            "source_info": {
                "paper_title": "From LSAT: The Progress and Challenges of Complex Reasoning",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "DAGN",
            "name_full": "DAGn: Discourse-Aware Graph Network for Logical Reasoning",
            "brief_description": "A discourse-aware graph neural network previously proposed for logical reasoning; used as a baseline comparison on ReClor and LogiQA benchmarks.",
            "citation_title": "Dagn: Discourse-aware graph network for logical reasoning",
            "mention_or_use": "mention",
            "model_name": "DAGN (Discourse-aware Graph Network)",
            "model_description": "A graph-based neural model that builds discourse/logic-aware graphs over passages and uses graph neural networks to perform logical reasoning; included in comparisons on ReClor and LogiQA.",
            "model_size": null,
            "logical_reasoning_task": "ReClor, LogiQA (and comparable logical reasoning benchmarks)",
            "task_description": "Standardized-exam derived logical reasoning multiple-choice QA requiring discourse-level and logical inference.",
            "method_or_approach": "Graph construction over discourse elements and GNN-based reasoning to capture relations between propositions; used as a baseline in evaluation tables.",
            "performance": "Reported in Table VI: On ReClor Val 65.8% / Test 58.3%; on LogiQA Val 36.9% / Test 39.3%.",
            "limitations_or_failure_cases": "Listed as baseline; paper does not deeply analyze DAGN failure modes but shows LReasoner variants outperform DAGN on these datasets when combined with logic-driven extension and strong pretraining.",
            "comparison": "DAGN is outperformed by LReasoner_ALBERT on ReClor and LogiQA in reported experiments.",
            "ablation_or_analysis_results": "No ablation inside this paper; included only as a comparative baseline in results tables.",
            "uuid": "e5113.4",
            "source_info": {
                "paper_title": "From LSAT: The Progress and Challenges of Complex Reasoning",
                "publication_date_yy_mm": "2021-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Logic-driven context extension and data augmentation for logical reasoning of text",
            "rating": 2
        },
        {
            "paper_title": "Reclor: A reading comprehension dataset requiring logical reasoning",
            "rating": 2
        },
        {
            "paper_title": "LogiQA: A challenge dataset for machine reading comprehension with logical reasoning",
            "rating": 2
        },
        {
            "paper_title": "RoBERTa: A robustly optimized bert pretraining approach",
            "rating": 1
        },
        {
            "paper_title": "ALBERT: A lite bert for self-supervised learning of language representations",
            "rating": 1
        },
        {
            "paper_title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "rating": 1
        },
        {
            "paper_title": "Dagn: Discourse-aware graph network for logical reasoning",
            "rating": 2
        },
        {
            "paper_title": "Neural Symbolic Reader: Scalable integration of distributed and symbolic representations for reading comprehension",
            "rating": 1
        }
    ],
    "cost": 0.01641175,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>From LSAT: The Progress and Challenges of Complex Reasoning</h1>
<p>Siyuan Wang, Student Member, IEEE, Zhongkun Liu, Wanjun Zhong, Ming Zhou, Member, IEEE, Zhongyu Wei, Member, IEEE, Zhumin Chen, and Nan Duan, Member, IEEE,</p>
<h4>Abstract</h4>
<p>Complex reasoning aims to draw a correct inference based on complex rules. As a hallmark of human intelligence, it involves a degree of explicit reading comprehension, interpretation of logical knowledge and complex rule application. In this paper, we take a step forward in complex reasoning by systematically studying the three challenging and domain-general tasks of the Law School Admission Test (LSAT), including analytical reasoning, logical reasoning and reading comprehension. We propose a hybrid reasoning system to integrate these three tasks and achieve impressive overall performance on the LSAT tests. The experimental results demonstrate that our system endows itself a certain complex reasoning ability, especially the fundamental reading comprehension and challenging logical reasoning capacities. Further analysis also shows the effectiveness of combining the pre-trained models with the task-specific reasoning module, and integrating symbolic knowledge into discrete interpretable reasoning steps in complex reasoning. We further shed a light on the potential future directions, like unsupervised symbolic knowledge extraction, model interpretability, few-shot learning and comprehensive benchmark for complex reasoning.</p>
<p>Index Terms-LSAT, complex reasoning, analytical reasoning, logical reasoning, reading comprehension.</p>
<h2>I. INTRODUCTION</h2>
<p>COMPLEX reasoning aims to comprehend and analyze the given information, and apply complex rules to draw correct inference [1, 2]. As an essential ability for complex problem solving, it provides tremendous opportunities for many real-world scenarios, such as mathematical word problems, negotiation and argument, and medical diagnosis [3, 4, 5, 6]. In recent years, having a computer pass admission examinations is a hot AI challenge towards complex reasoning, which offers an objective and accurate measurement with a certain difficulty. Fujita et al. [7] design a system to sit the Japanese National Center Test for University Admissions. Gaokao, as the National College Entrance Examination of China, also</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>has been widely studied [8, 9]. Although encouraging results have been achieved in taking these real high-school exams, these works study domain-specific and limited complex reasoning capabilities. They cover different subjects and each is separately processed with subject-specific knowledge [10]. For example, the annotated formulas representing physics, mathematics and biology knowledge are usually assumed to be provided to solve corresponding problems [7, 11], while history and geography questions are primarily solved by retrieving relevant information supplemented by shallow reasoning to match the answer [12, 13].</p>
<p>To take a step towards a more challenging and domaingeneral complex reasoning ability, we focus on the Law School Admission Test (LSAT) ${ }^{1}$, which is one of the most difficult exams covering multiple domains. LSAT is a standardized test administered for prospective law school candidates worldwide, which mainly assesses their general complex reasoning skills, including analytical reasoning, logical reasoning, and reading comprehension capabilities in general domains. Correspondingly, the LSAT can be categorized into three tasks: (1) analytical reasoning (AR), measures the ability to analyze a scenario ruled by a set of constraints, and determine which option satisfies or conflicts with all the constraints. (2) logical reasoning (LR), a task that focuses on the logical analysis of texts and performing logical inference to deduce implications from asserted ones. (3) reading comprehension (RC), revolves around the ability to deeply understand long-form materials, and locate the relevant pieces to distinguishing what is the case by summarizing or comparing highly abstract concepts, such as attitudes and principles. Three examples of LSAT tasks are listed in Figure 1, which are all quite challenging and involve complex reasoning processes. Therefore, we aim to systematically explore the progress and challenges of complex reasoning, and take the real-world LSAT tasks which have been rarely explored [14] as a testbed.</p>
<p>Existing methods for complex reasoning can be summarized into three types, namely, symbolic models, neural models, and neural-symbolic models [15, 16]. Symbolic models identify the discrete symbols (like entities and logical functions) as basic reasoning units, and perform explicit inferences upon symbolic representations. With controllable and interpretable reasoning steps, yet they largely depend on expert-defined rules which are inflexible for different datasets and lack resilience against data noises [17]. Neural models mimic the neuron connections in the human brain to learn the semantics</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<table>
<thead>
<tr>
<th>[Example 1 - Analytical Reasoning]</th>
<th>[Example 2 - Logical Reasoning]</th>
<th>[Example 3 - Reading Comprehension]</th>
</tr>
</thead>
<tbody>
<tr>
<td>Context:</td>
<td>Context:</td>
<td>Context:</td>
</tr>
<tr>
<td>Seven directors -A, B, C, D, E, F, and G- serves on the X committee or the Y committee. Constraints</td>
<td>If you have no keyboarding skills at all, you will not be able to use a computer. And if you are not able to use a computer, you will not be able to write your essays using a word processing program.</td>
<td><P1>Is it necessary for defense lawyers to believe that the clients they defend are innocent of the charges against them? Some legal scholars hold that lawyers' sole obligation is to provide the best defense they are capable of..... <P1> <P2> But such a position overlooks the fact that the defense lawyer's <Mark1>obligation</Mark1> is twofold: to the defendant, certainly, but no less so to the court and, by extension, to society. ... whether the client is guilty but the lawyer sincerely believes the client may well be innocent, the lawyer should of course try to prove that the client is innocent.<P2> <P3> The lawyer's obligation to the court and to society also ultimately benefits the defendant ... Lawyers should not be mere mouthpieces for a defendant but instead advocates for the rights of the defendant given the facts of the case. <P3> Question: Which one of the following most accurately describes the author's attitude toward the twofold obligation introduced in lines 20-23?</td>
</tr>
<tr>
<td>If A serves on X, then B serves on Y. (C-1)</td>
<td></td>
<td>A. confident that it enables defense lawyers to balance their competing responsibilities to the court and to society.</td>
</tr>
<tr>
<td>If C serves on X, then D and E serve on Y. (C-2)</td>
<td></td>
<td>B. certain that it prevents defense lawyers from representing clients whom they know to be guilty.</td>
</tr>
<tr>
<td>F serves on a different committee with G. (C-3)</td>
<td></td>
<td>C. satisfied that it helps defense lawyers to uncover the relevant facts of a case</td>
</tr>
<tr>
<td>E serves on a different committee with A. (C-4)</td>
<td></td>
<td>D. pleased that it does not interfere with common defense strategies used by defense lawyers</td>
</tr>
<tr>
<td>If G serves on X, so does B. (C-5)</td>
<td></td>
<td>E. convinced that it does not represent a conflict of interest for defense lawyers</td>
</tr>
<tr>
<td>Question:</td>
<td></td>
<td></td>
</tr>
<tr>
<td>If D and F both serve on the X committee, (C-6)</td>
<td></td>
<td>Relevant Pieces:</td>
</tr>
<tr>
<td>then which one of the following could be true?</td>
<td></td>
<td>The lawyer's obligation to the court and to society also ultimately benefits the defendant.</td>
</tr>
<tr>
<td>A. A and C both serve on the X committee.</td>
<td></td>
<td></td>
</tr>
<tr>
<td>To(2, X)&amp; To(2, Y) conflict with C-6</td>
<td></td>
<td></td>
</tr>
<tr>
<td>B. A and E both serve on the Y committee.</td>
<td></td>
<td></td>
</tr>
<tr>
<td>To(3, Y)&amp; To(3, Y) conflict with C-6</td>
<td></td>
<td></td>
</tr>
<tr>
<td>C. B and G both serve on the X committee.</td>
<td></td>
<td></td>
</tr>
<tr>
<td>To(2, X)&amp; To(2, Y) conflict with C-6</td>
<td></td>
<td></td>
</tr>
<tr>
<td>D. C and E both serve on the Y committee.</td>
<td></td>
<td></td>
</tr>
<tr>
<td>To(2, Y)&amp; To(2, Y) conflicting all constraints</td>
<td></td>
<td></td>
</tr>
<tr>
<td>E. G and E both serve on the X committee.</td>
<td></td>
<td></td>
</tr>
<tr>
<td>To(2, X)&amp; To(2, Y) conflict with C-6</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Participants: Positions:</td>
<td></td>
<td></td>
</tr>
<tr>
<td>(A,B,C,D,E,F,G) (X committee, Y committee)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Constraints to Programs:</td>
<td></td>
<td></td>
</tr>
<tr>
<td>C-1: {fThen({To(A,X)},{To(B,Y)})}</td>
<td></td>
<td></td>
</tr>
<tr>
<td>C-2: {fThen({To(C,X)},{To(D,Y)})&amp;To(E,Y)})</td>
<td></td>
<td></td>
</tr>
<tr>
<td>C-3: Position of F = Position of G</td>
<td></td>
<td></td>
</tr>
<tr>
<td>C-4: Position of E = Position of A</td>
<td></td>
<td></td>
</tr>
<tr>
<td>C-5: {fThen({To(G,X)},{To(R,X)})}</td>
<td></td>
<td></td>
</tr>
<tr>
<td>C-6: To(2, X)&amp; To(7, X)</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Fig. 1: Three examples of LSAT tasks with the required reasoning processes. For AR, it needs to understand the knowledge of participants, positions, and constraints, and deduce the legitimate option. For LR, the elementary logical symbols and expressions need to be identified to logically infer the implicit expression. For RC, it requires locating the relevant pieces by the positional indicators and abstract the answer. The options in green mean the correct answers of three examples.</p>
<p>of data with continuous vectors and implicitly infer the answer, which are robust to the ambiguous and noisy data but short of interpretability. To achieve synergies among the advantages and circumvent the limitations of symbolism and connectionism, neural-symbolic models integrate both symbolic logic and continuous representation to reason out the answer [18].</p>
<p>From the above perspectives, we design a hybrid reasoning system for three LSAT tasks. For AR, we first propose a symbolic system [19] which designs rules to identify symbolic participants and constraints, and deterministically deduce the legitimate solutions. We then attempt a neural method utilizing a graph network for modeling constraints between participants. We also come up with a neural-symbolic model which neurally parses the textual constraints into programs and discretely executes the programs to reach the answer. For LR, we propose a neural-symbolic logic-driven system [20], which employs a symbolic module to extract logic from the texts and infer the entailed logic by logical laws, then utilizes a neural module to encode the inferred logic for answer prediction. For RC, we propose a neural Transformer-based approach with an external multi-head attention mechanism [21] and passage positional information for better understanding the interaction between context and question.</p>
<p>On the whole, our overall system integrating three tasks achieves an accuracy of 56.8% on the LSAT exams, which is comparable to the median for human test taker scores. Our systems for RC and LR even have a chance to be admitted to the top 30 and top 58 law schools, respectively. The results show the effectiveness of our systems for modeling complex reasoning abilities, notably the fundamental reading compre- hension and challenging logical reasoning capability. The overall illustration of our investigation on LSAT towards complex reasoning is shown in Figure 2. Through a systematical study of three LSAT tasks, we not only achieve great performance on LSAT, but also make some progress towards complex reasoning. We further investigate the emerging challenges and inspire potential future directions of complex reasoning. For example, automatically extracting symbolic knowledge in an unsupervised manner, few-shot complex reasoning, improving the interpretability of the neural reasoning system, and building a comprehensive benchmark, are all essential to be explored to promote complex reasoning research.</p>
<p>In the rest of the paper, we first list some related work of complex reasoning and corresponding advanced methods. We also preliminarily introduce the tasks, baseline models and datasets of LSAT in § II. Then we separately introduce the challenges, detailed methods, experimental results and further analysis for analytical reasoning, logical reasoning and reading comprehension tasks in § IV, § V and § VI, respectively. We further summarize our overall performance on LSAT, and discuss the major challenges and future directions in complex reasoning in § VII. We finally draw our conclusion in § VIII.</p>
<p>II. RELATED WORK</p>
<p>A. Taxonomy of Complex Reasoning</p>
<p>To encourage the progress of artificial intelligence systems towards deeper human-like comprehension and reasoning, there has been a surge in complex reasoning research in recent</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 2: The overall illustration of our investigation from LSAT towards complex reasoning.</p>
<p>years. We first investigate existing works on several major aspects of complex reasoning.</p>
<p><em>a) Logical Reasoning:</em> An increasing number of tasks and datasets have been introduced targeting logical reasoning. Natural Language Inference [22, 23, 24] aims to determine the entailment relationship between a hypothesis and a premise, which requires relatively simple logical reasoning ability at the sentence level. Several question answering datasets have been proposed for promoting logical reasoning ability, i.e., LogiQA [25], ReClor [14], which are sourced from public standardized exams. However, previous methods usually fail to model the discrete logical inference process explicitly. This work also dives into logical reasoning, and considers understanding the elementary logical structure and perform explicit logical inference to draw a logical conclusion.</p>
<p><em>b) Commonsense Reasoning:</em> Commonsense reasoning requires utilizing commonsense knowledge to reason out the answer, which attracts great concern of the research communities. Recently many benchmarks have been introduced to assess reasoning capabilities over different commonsense knowledge, such as domain-specific knowledge [26, 27, 28], general semantic knowledge [29] and inferential knowledge [30]. Current methods, however, are still not robust enough to be deployed in the open domain and ignore directly modeling commonsense through symbolic integration [31]. How to incorporate symbolic commonsense and reason over relevant knowledge will be substantially explored [32, 33].</p>
<p><em>c) Multi-Hop Reasoning:</em> Multi-hop reasoning is another widely studied complex reasoning task recently [34, 35, 36, 37], which requires reasoning across multiple pieces of sentences or documents to model multi-hop relationships to reach the answer. Conversational question answering tasks [38, 39] also involve multi-hop reasoning over multi-turn utterances. Constructing correct multi-hop reasoning chains (conversation flows) has been a key challenge for these tasks, and it is an essential research direction to effectively model multi-hop reasoning paths over multiple passages [40, 41].</p>
<p><em>d) Numerical Reasoning:</em> Numerical reasoning involves performing discrete arithmetic reasoning over quantities to solve mathematical word problems [42, 43, 44, 45], which is a fundamental and challenging task. Previous work translates the textual math word problem into an expression or an expression tree and utilizes arithmetic knowledge to solve it [43, 46, 47]. With weak supervision, how to improve the accuracy of generated expression trees is worth further study [48, 49].</p>
<h3><em>B. Advanced Methods of Complex Reasoning</em></h3>
<p>Advanced methods to solve complex reasoning problems, no matter what specific reasoning skill is required, can be summarized as following three types: symbolic models, neural models and neural-symbolic models [15, 16, 17].</p>
<p><em>a) Symbolic Models:</em> As complex reasoning requires discrete reasoning operations over reasoning units, most previous studies for complex reasoning are symbolic expert systems [50, 51, 52, 53]. They design a set of rules or templates to identify basic units for reasoning as symbols, such as the quantities and arithmetic signs for numerical reasoning [54, 55, 56], relevant triples and paths from knowledge graph for commonsense reasoning [57], etc. They then perform deterministic and explicit inferences upon discrete elementary units to predict the answer. The symbolic models provide sound readability and interpretability. However, it requires expert knowledge and tremendous human efforts in designing rules, which makes it inflexible to scale across different datasets and lack resilience against data noises. Moreover, the</p>
<p>finite and discrete symbolic representations are insufficient to depict all the intrinsic reasoning structures.
b) Neural Models: Neural models mimic the neuron connections in the human brain [58, 59] and apply neural networks to implicitly represent the abstracted semantics of input text and knowledge with continuous vectors, which are robust to the ambiguous and noisy data [60, 61]. For example, pretrained language models have achieved superior performance on many comprehensive tasks [62, 63, 64]. However, the decision process of neural models is always a black box, which makes the prediction lacks explainability and reliability. Whether the neural models show the reasoning ability or just capture the data bias to achieve high accuracy is also a question. Graph neural networks [65, 66] and neural module networks [67, 68] are also introduced to partly imitate the human reasoning process to make up interpretability. However, these methods still perform an implicit inference to reason out the answer without a clue as to why and how. Besides, neural models depend a lot on training data and are computationally expensive to train, and the performance will sharply decrease with limited data and resource.
c) Neural-Symbolic Models: To combine the advantages and circumvent the shortcomings of both symbolic and neural methods, neural-symbolic models which integrate symbolic logic and neural representation are widely studied [69, 70, 71, 72, 73]. Some work employs a neural module to parse the language into executable programs [74, 18] and deterministically executing the programs to find the answer in a symbolic module. For example, the neural-symbolic models for numerical reasoning translate the input texts into expressions through a neural generation model and then discretely execute the expressions [43, 46, 47]. Other work first designs rules to extract the reasoning units and explicitly conduct inference over them in a symbolic module. They then utilize a neural module to learn continuous vectors for symbolic representations to deal with the uncertainty of data [75, 76, 20]. Specifically, for commonsense and multi-hop reasoning, the symbolic module can be designed to identify relevant knowledge and multi-hop reasoning chain, respectively, and then encode them into the neural module to match the answer [77, 78, 79, 80]. However, how to generate high-quality programs under weak supervision and extract symbolic reasoning units in an unsupervised manner remains an elusive challenge.</p>
<h2>C. Examination-based Question Answering</h2>
<p>Recent years have witnessed an emerging trend in answering complex questions collected from human standardized examinations at a different level of education, which is more difficult and measurable. The Todai Robot project aims to create a system that can pass the Japanese National Center Test for University Admissions [7]. Aristo Challenge focused on solving the questions of Elementary School Science and Math Tests which is for 6-11 year olds [81]. A similar project studying the National College Entrance Examination of China (Gaokao) also has been launched [8, 9, 12]. These challenges deal with various subjects, like mathematics, biology, physics, geography, history, and drive the progress of AI systems towards complex problem solving and reasoning. However, these questions rely heavily on domain-specific expressions and knowledge like formulas in mathematics and physics, and quotes in Classical Chinese, which ignore the domaingeneral complex reasoning ability. Besides, the studies of these tasks have hit the bottleneck of commonsense-based reading comprehension and general intelligence, which fail to be admitted to key universities [82].</p>
<p>RACE dataset [83] is introduced to remove domain restrictions by collecting the general English exams for middle and high school Chinese students. However, around 70\% of questions are in the category of word matching, paraphrasing or single-sentence reasoning, which are relatively simple. LogiQA [25] collected from the National Civil Servants Examination of China and ReClor [14] from the Graduate Management Admission Tests and Law School Admission Tests both require deeper logical reasoning. In this paper, we not only examine the logical reasoning capability of LSAT, but also challenging analytical reasoning and complicated reading comprehension abilities to systematically explore complex reasoning.</p>
<h2>III. Preliminaries</h2>
<h2>A. Task Definition</h2>
<p>The LSAT problems are formulated as a multiple-choice question answering task, which is described as follows. Given a context $c$, a question $q$ together with five candidate options $o=o_{1}, o_{2}, o_{3}, o_{4}, o_{5}$, only one option is need to be predicted as the most plausible answer $o_{a}$.</p>
<h2>B. Baseline Model</h2>
<p>Pre-trained Transformer-based language models, i.e., BERT [62], RoBERTa [63] and ALBERT [64], achieve impressive performance on multiple-choice question answering, which can be employed as the baseline model of all LSAT tasks. Specifically, the context, the question and an option are concatenated as the input for encoding, which is formulated as $[C L S] c[S E P] q\left|\left|o_{i}[S E P]\right.\right.$ and $\left.\right|$ is the concatenation operator. Given five options, five concatenated sequences are constructed to be encoded. The representations of special token $[C L S]$ in five sequences are fed into a classification layer to get the probabilities of options as their scores, and the option with the highest score is selected as the answer. The models are fine-tuned with cross-entropy loss on the training set.</p>
<h2>C. Dataset</h2>
<p>The LSAT datasets are collected from previous exams from 1991 to 2016, including a total of 90 examinations. Each exam roughly contains 100 questions, among which $1 / 2$ are logical reasoning questions, $1 / 4$ are analytical reasoning questions and the rest $1 / 4$ are reading comprehension questions. For a small proportion of questions with only four options, we randomly select one of the wrong choices as a supplemental option for each instance. We name datasets of analytical reasoning, logical reasoning and reading comprehension tasks as AR-LSAT [19], LR-LSAT and RC-LSAT, respectively. Each</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Datasets</th>
<th style="text-align: left;">Statistics</th>
<th style="text-align: right;">Train</th>
<th style="text-align: right;">Val</th>
<th style="text-align: right;">Test</th>
<th style="text-align: right;">Total</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">AR-LSAT</td>
<td style="text-align: left;"># context</td>
<td style="text-align: right;">280</td>
<td style="text-align: right;">40</td>
<td style="text-align: right;">40</td>
<td style="text-align: right;">360</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"># question</td>
<td style="text-align: right;">1,630</td>
<td style="text-align: right;">231</td>
<td style="text-align: right;">230</td>
<td style="text-align: right;">2,091</td>
</tr>
<tr>
<td style="text-align: left;">LR-LSAT</td>
<td style="text-align: left;"># context</td>
<td style="text-align: right;">3,325</td>
<td style="text-align: right;">503</td>
<td style="text-align: right;">507</td>
<td style="text-align: right;">4,335</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"># question</td>
<td style="text-align: right;">3,529</td>
<td style="text-align: right;">506</td>
<td style="text-align: right;">510</td>
<td style="text-align: right;">4,545</td>
</tr>
<tr>
<td style="text-align: left;">RC-LSAT</td>
<td style="text-align: left;"># context</td>
<td style="text-align: right;">280</td>
<td style="text-align: right;">40</td>
<td style="text-align: right;">40</td>
<td style="text-align: right;">360</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"># question</td>
<td style="text-align: right;">1,880</td>
<td style="text-align: right;">270</td>
<td style="text-align: right;">269</td>
<td style="text-align: right;">2,419</td>
</tr>
</tbody>
</table>
<p>TABLE I: The detailed statistics of LSAT datasets. # context and # question are the numbers of contexts and questions in each split.
dataset is further split into training, validation and testing sets. The detailed statistics of each dataset are listed in Table I.</p>
<p>As collected from standardized examinations, these LSAT datasets are of high quality and difficulty for complex reasoning, and are accompanied by an accurate evaluation metric and relatively limited data size. The data sparsity makes these reasoning tasks more difficult to be solved by traditional datadriven approaches that purely learn data patterns from massive data. Therefore, the models with solid complex reasoning abilities need to be developed and decrease the dependency on the data size.</p>
<h2>IV. Analytical Reasoning</h2>
<h2>A. Challenges in Analytical Reasoning</h2>
<p>Analytical Reasoning aims to analyze a scenario involving a set of predefined constraints and perform deductive reasoning to draw correct solutions. As no previous work or benchmark dataset completely studies this challenging task, we introduce a new dataset, namely AR-LSAT [19], to foster research on this area. Most of the questions in AR-LSAT can be viewed as a constraint satisfaction problem [84], which needs to find legal assignments of positions to participants satisfying the given constraints. All participants, positions and constraints are described in the context. Take a look at the first example in Figure 1, two positions (i.e., X committee and Y committee) need to be assigned to seven directors (i.e., A, B, etc.) under a set of constraints. To solve such problems, the system requires understanding the game settings including the compositions of participants, the possible values of positions, and interpreting the logical meaning of the constraints descriptions. Then it involves conducting inference over constraints to deduce the answers.</p>
<p>The analytical reasoning problems are quite challenging. The situation descriptions in the context are diverse with no domain restriction. A more accurate and comprehensive understanding of the context is also required, because each piece of the context is significant in building the whole reasoning chain. Besides, the five options of a question tend to be similar to each other and the answer never explicitly appears in the context. Therefore, the AR task cannot be superficially solved by relevant information extraction and shallow contextual matching.</p>
<h2>B. Symbolic Model: ARM</h2>
<p>To explicitly model discrete analytical reasoning steps, we start with a symbolic model called Analytical Reasoning Machine (ARM) [19], which can answer the question by predefined rules and deterministic deduction. To solve questions like the first example in Figure1, we propose to perform a fourstage reasoning process: 1) extracting participants, positions, constraints from the context and question; 2) interpreting constraints into executable programs, i.e., a combination of logical functions; 3) generating a set of legitimate assignments by executing all programs; 4) selecting the most plausible option by matching the legitimate assignments. Next, we will introduce these steps in detail.</p>
<p>1) Arguments Extraction: We first extract participants, positions and constraints from the context to have a primary understanding of the problem. Specifically, we use a Named Entity Recognition model [85] to extract entities from the context and group them into participants and positions. Entities that appear together in the leading sentence of the context are recognized as participants or positions, where participants always appear before positions. We also identify constraints by judging whether a sentence restricts the assignments between participants and positions. As the example in Figure 1, seven participants (i.e., $A, B, C, D, E, F, G$ ) need to be assigned into two positions (i.e., $X$ committee and $Y$ committee). All sentences except the first are recognized as constraint descriptions.
2) Constraints Interpretation: We next interpret natural language constraints into executable programs based on three types of predefined functions, i.e., relational, counting and compositional functions. The relational function involves participants and positions as arguments and focuses on the relationship between them, e.g., "Before $(A, B)$ " means " $A$ must be in a lower-numbered position than $B$ " while "To $(A, X)$ " indicates "Participant $A$ is assigned to position $X$ ". The counting function describes the numerical and order constraints over participants, which take as arguments both participants and numbers. A compositional function takes two sets of relational or counting functions as arguments and formulates the relationship between them, like conditional (if-then) relationship. For example, the constraint "If A serves on the $X$, then $B$ serves on the $Y$ " can be expressed as "IfThen $({T o(A, X)},{T o(B, Y)})$ ".</p>
<p>We design a set of trigger words to match potential functions [74] and extract arguments (i.e., participants, positions, and numbers) according to their relative positions to the trigger words. For uncertain sentences with no matched function, we also build a neural classification model based on RoBERTa to predict their corresponding function types. The combination of functions in each sentence is the interpreted program. In figure 1, the set of interpreted programs corresponding to the AR example is also presented.
3) Program Execution: We recognize the programs that immediately determine the positions of some participants to construct an initial assignment. For example, the constraint " $D$ and $F$ both serve on the $X$ committee" corresponds to the initial assignment in Figure 3. Each assignment is formulated as a table with columns as participants and rows as positions. Each cell in the assignment has three possible states, i.e.,</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 3: The tree-based reasoning process. Here "T/F/-" means "True/False/Unknown".</p>
<p><em>True, False, Unknown</em>, which means whether a participant is assigned to a position.</p>
<p>Starting from the initial assignment, we conduct reasoning to deduce legitimate assignments satisfying all constraints by executing other programs. The reasoning process is formulated into a tree-based heuristic shown in Figure 3. Specifically, each node is an assignment while each edge is an executable program, and the initial assignment is taken as the root node <em>a</em><sub>0</sub>. At each iteration, for a program <em>f</em><sub>i</sub> we enumerate all possible positions for participants involved in this program if they are unknown, and execute the program to check satisfaction for each assignment to remove the illegitimate ones. Then taking each legitimate assignment as a new root and starting a new iteration, we validate the next program to further extend the reasoning tree. The tree is recursively expanded until all programs are executed. The leaf nodes that satisfy all constraints are obtained as final legitimate assignments.</p>
<p><em>4) Option Selection:</em> After deducing all legitimate assignments, we analyze the options to select the most plausible one as the answer. As each option can be interpreted as a program in the same way described in § IV-B2, we can further extend the reasoning tree and execute the option-based program. We take the number of legitimate assignments of each option as its score and the option with the maximum score is selected as the final answer.</p>
<h3><em>C. Neural Model: CGAR</em></h3>
<p>As ARM requires substantial effort to craft sets of rules which are far from perfect, we attempt to design two neural models to ease the manual work. We first adopt the state-of-the-art pre-trained models including RoBERTa [63] and ALBERT [64] as described in § III-B. However, they struggle to capture complex reasoning ability beyond shallow-level semantic understanding and perform nearly a random guess [19].</p>
<p>We also propose a Constraint Graph-based Analytical Reasoning (CGAR) framework. Considering that for each AR problem, participants are to be assigned into several positions, and each constraint describes a restriction relationship between some participants and positions. To better model the relationship structure of involved participants and positions to deduce the legitimate solutions, we propose constructing constraint graphs for each question. We thus introduce a CGAR framework that utilizes a graph convolutional network (GCN) [86] and a pre-trained model to reason over the constraint structure. The framework is composed of three modules, namely, a graph construction module, a graph reasoning module and an answer prediction module.</p>
<p><em>1) Constraint Graph Construction:</em> We construct a constraint graph <em>G</em><sub><em>i</em></sub> for each (context <em>c</em>, question <em>q</em>, option <em>o</em><sub><em>i</em></sub>) triple. Then five graphs can be constructed corresponding to five options of a question. Each is designed as a heterogeneous undirected graph where the nodes consist of participants, positions and constraints in the context. Each constraint node is connected to its mentioned participant nodes and position nodes. Besides, the (question, option) pair is also injected as a global node to establish linkages with all constraint nodes, to indicate whether the option satisfies the constraints and answers the question. We follow the extraction method in [19] which utilizes named entity recognition to extract participants and positions from the leading sentence of the context. And we simply take each sentence in the context as a constraint.</p>
<p><em>2) Graph Reasoning:</em> To initialize the node representations, we utilize the output of the pre-trained model as the embedding of each token. For participant and position nodes, we perform mean pooling on the constituent token embeddings to get their representations. For constraint nodes, we take the average of the start and end token embeddings of each sentence as their representations. Then two [<em>SEP</em>] token embeddings are also averaged to initialize the representation of the global node. To model the heterogeneity of the graph, we also define three types of nodes, including the entity node, the constraint node and the global node. Participant and position nodes are both viewed as entity nodes. We utilize a linear transformation onto the node representations for different node types to get their type-specific representations.</p>
<p>We employ a GCN to perform reasoning over a constraint graph <em>G</em><sub><em>i</em></sub>. During each message-passing iteration, we hope to model the feasible states of participants and positions by aggregating the constraint information to entities. Correspondingly, constraint features and global features are also updated. After multiple iterations, the global node is aware of available states of participants and positions in (question, option) pair for predicting whether option <em>o</em><sub><em>i</em></sub> is the correct answer.</p>
<p><em>3) Answer Prediction:</em> As in § III-B, we also need to compute scores of each option to find the most plausible answer. We determine the plausibility of each option <em>o</em><sub><em>i</em></sub> given the question <em>q</em> with the information from both text <em>c</em> and graph <em>G</em><sub><em>i</em></sub>. Specifically, we concatenate the final representation of the global node with the representation of [<em>CLS</em>] token from the pre-trained model and feed it into a classification layer.</p>
<h3><em>D. Neural-Symbolic Model: NSAR</em></h3>
<p>Although neural models are capable of well capturing language semantics, they disregard the interpretability of predictions. To reconcile the robust learning in neural models and the discrete reasoning of symbolic methods, we design a neural-symbolic model to solve the AR task. We propose an approach named NSAR (Neural-Symbolic model for Analytical Reasoning), which extracts the arguments and parses the constraints</p>
<p>into compositional programs in a neural manner, and executes the programs to derive the answer with a symbolic inference engine.</p>
<p>As the symbolic executor is non-differential, policy-gradient methods are usually employed to train the model [74, 87]. However, analytical reasoning questions can only be answered after examining the satisfiability of all the constraints, which leads to extremely sparse rewards and makes the model hard to be optimized. Thus, we manually annotate programs for supervision learning.</p>
<p>1) Data Annotation: We first extend the constraint function set defined in ARM [19] to improve the scalability (e.g., FirstPos and LastPos are too specific). It is composed of common logical functions (AND, OR, IF, NOT, etc.) and operator functions including arithmetics $(+,-,=,&gt;,&lt;$, etc.), sorting (ARGMAX, MAX, etc.), assignment (VALUE), selection (SELECT) and counting (COUNT) operations.</p>
<p>Before program annotation, we need to annotate the participant and position sets of each problem. Then for each constraint sentence in the context and the (question, option) pair, we annotate a program following the above definition, which is a composition of functions over the involved participants and positions. For example, we annotate a program as "VALUE(roadster) $&gt;$ VALUE(van) AND VALUE(roadster) $&lt;$ VALUE(hatchback)" for the constraint "The roadster is serviced later in the week than the van and earlier in the week than the hatchback". The statistics and examples of our data annotation are listed in Appendix A. 2) Neural Parser: In the neural perception module, we need to extract participants and positions from the context and interpret constraints into programs. a) Participant/Position Extractor: We separately take participant extraction and position extraction as two sequence tagging tasks. For each task, a pre-trained model with a linear token classification head on top is employed for predicting which tokens are parts of participants or positions [63]. b) Program Parser: In order to model the relevance and dependency relationship between different constraints for program parsing, we take the whole context as an input and generate a sequence of compositional programs. The concatenation of the question and each option is also fed as an input to generate a program. Here we adopt a pre-trained encoderdecoder model for program generation [18, 88]. Besides, to alleviate generating irrelevant or incorrect content in programs, we dynamically limit the vocabulary for each input to tokens of the input and all constraint functions. 3) Symbolic Executor: After obtaining programs from the context, question and each option, we need to execute these programs and present a score for each option. To do this, we inherit the executor from § IV-B3 and § IV-B4. We first execute programs from the context to obtain legitimate assignments. Then we execute the program of each (question, option) pair on these assignments and calculate the ratio of assignments satisfying the option as the score. We finally choose the option with the highest score as the answer.</p>
<h2>E. Results and Analysis</h2>
<p>1) Overall Comparison: We compare the performance of the above three methods with a baseline pre-trained model and human performance [19] on the validation and test sets. The pre-trained baseline model, CGAR and the extractor in NSAR all take RoBERTa-large [63] as the backbone while the parser in NSAR employs a T5-based model [88].</p>
<table>
<thead>
<tr>
<th>Methods</th>
<th>Val (\%)</th>
<th>Test (\%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Human Performance</td>
<td>-</td>
<td>59.7</td>
</tr>
<tr>
<td>Random Guess</td>
<td>20.0</td>
<td>20.0</td>
</tr>
<tr>
<td>ARM</td>
<td>$\mathbf{3 4 . 2}$</td>
<td>$\mathbf{3 0 . 9}$</td>
</tr>
<tr>
<td>RoBERTa</td>
<td>24.2</td>
<td>23.1</td>
</tr>
<tr>
<td>CGAR</td>
<td>27.7</td>
<td>24.9</td>
</tr>
<tr>
<td>NSAR</td>
<td>24.2</td>
<td>24.8</td>
</tr>
</tbody>
</table>
<p>TABLE II: The answer prediction accuracy (\%) of different methods on AR-LSAT.</p>
<p>The results are shown in Table II. We observe that the symbolic system $A R M$ outperforms $R o B E R T a$ and $C G A R$. It shows that the complex analytical reasoning process is difficult to be completely parameterized by neural models, while $A R M$ works better by customizing complicated rules targeted at the AR-LSAT dataset and performing a deterministic deduction. Meanwhile, such difficulty for neural learning is exacerbated by limited data. From the improvement of $C G A R$ compared to RoBERTa, multiple message-passing iterations over the constraint graph are proved to partly work on modeling the analytical reasoning process. However, NSAR outperforms RoBERTa while performing worse than both CGAR and ARM, because there is no large-scale supervised data. We annotate a small number of instances for extracting participant/position and parsing program, which results in interpreting imperfect programs and further influences the execution performance. We deem that annotating more data or heuristically augmenting data will boost the performance of NSAR. Although we have achieved an improvement over the baseline model, our systems are still far from equivalent to human performance, leaving significant opportunities for further exploration of this highly challenging task. 2) Detailed Analysis on NSAR: We first analyze the performance of participant extraction and position extraction in Table III. The NSAR performs relatively worse than $A R M$ in both validation and test sets, indicating that it is more appropriate to apply a rule-based extraction method to cover low-resource but diverse datasets. In addition, there is still a certain gap between the $A R M$ model and perfect extraction, showing that AR-LSAT is extremely challenging and needs a finer set of extraction rules.</p>
<p>To investigate the performance of our program parser, we evaluate the programs generated by combining all sentences in the context and the question-option pair (as Combination setting) and by separately feeding each sentence or the questionoption pair (as Separation setting), respectively. As shown in Table IV, our generated programs achieve a high Rouge-L while the exact match score is low and even equals zero for the combination setting. Besides the limited training data, it</p>
<table>
<thead>
<tr>
<th>Methods</th>
<th>Val</th>
<th></th>
<th>Test</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Prec.</td>
<td>Recall</td>
<td>Prec.</td>
<td>Recall</td>
</tr>
<tr>
<td>$A R M$</td>
<td>96.2</td>
<td>92.9</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>$N S A R$</td>
<td>87.5</td>
<td>86.0</td>
<td>85.8</td>
<td>87.9</td>
</tr>
<tr>
<td>$A R M$</td>
<td>84.4</td>
<td>85.8</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>$N S A R$</td>
<td>56.3</td>
<td>52.2</td>
<td>44.9</td>
<td>61.5</td>
</tr>
</tbody>
</table>
<p>TABLE III: Performance (\%) of the participant extraction (top) and position extraction (bottom).</p>
<table>
<thead>
<tr>
<th>Parser Settings</th>
<th>EM</th>
<th>Rouge-L</th>
</tr>
</thead>
<tbody>
<tr>
<td>Combination</td>
<td>0.0</td>
<td>60.9</td>
</tr>
<tr>
<td>Separation</td>
<td>16.2</td>
<td>68.4</td>
</tr>
</tbody>
</table>
<p>TABLE IV: Evaluation results (\%) of the program parser on AR-LSAT. EM means Exact Match score.
is because that program parsing itself is a challenging task. Specifically, it is susceptible to generating invalid programs by a small midterm mistake and suffers from the intrinsic diversity of programs that a constraint description can be formulated as different programs. Moreover, we observe that the program generation for long context is much more difficult than shorter sentences. How to design a simple and generic program language is an essential direction for saving annotation resources and improving program generation quality.
3) Error Analysis: We further dive into the error cases within our methods and summarize the major reasons causing wrong predictions for AR problems. The first reason is that participants and positions sometimes fail to be correctly extracted, which fundamentally causes the misunderstanding of the problem settings and thus affects the answer prediction of the aforementioned three methods.</p>
<p>Some other errors occur because the predefined program language is not designed perfectly to cover some constraint descriptions with complex semantics. For example, "two consecutive" in the constraint "No breed is featured on any two consecutive days." is difficult to be formulated. The obstacle performance of the program parsing method also hinders the correct analytical deduction.</p>
<p>Although the textual descriptions in AR-LSAT are straightforward, basic commonsense knowledge is also needed to fully understand problem descriptions. For example, the system should realize that " $9: 00$ A.M." and " $2: 00$ P.M." are respectively in the morning and afternoon when it needs to arrange the schedule to satisfy "Some participants should be scheduled in the morning.".
4) Discussion: We make different attempts on AR-LSAT, including neural, symbolic and neural-symbolic models, and observe that there is a certain gap between human performance and all attempted methods. Our models achieve a nearly $31 \%$ accuracy while the powerful pre-trained models obtain only random performance. We therefore would like to highlight the challenges of analytical reasoning and shed a light on the potential directions.</p>
<p>In order to solve the AR problem, the main step is to exactly understand and abstract the textual constraints to machine cognitive programs with minimum manual effort. Moreover,
a question is usually answered through multiple constraints. The research of modeling multiple constraints and mitigating error accumulation can be further studied. As commonsense knowledge is required for better understanding constraint descriptions, how to inject external knowledge into the AR task is also a further research direction. Although analytical reasoning assesses both deep analytical understanding and complex deduction reasoning capabilities, only few data is available for exploration. How to develop solid complex reasoning ability and ease the dependency on the data size should be given top priority in future research. Data augmentation is yet another feasible direction.</p>
<h2>V. LOGICAL REASONING</h2>
<h2>A. Challenges in Logical Reasoning</h2>
<p>Logical reasoning requires understanding a given text at a logical level and performing logical inference to deduce implications from asserted ones. It is a challenging task widely studied in recent years and several logical reasoning benchmarks have been introduced, such as ReClor [14] and LogiQA [25]. Previous work usually treats the task as a traditional reading comprehension problem, and utilizes largescale pre-trained language models $[62,63,64]$ or graph neural networks [76] to match the context with candidate options. Although promising results have been achieved, they mainly rely on word-level semantics without capturing symbolic logic.</p>
<p>In order to solve questions in LR-LSAT, as the example in Figure 4, the reasoning system needs to extract the critical constituents from the context as logical symbols like " $\alpha$ : have keyboarding skills", " $\beta$ : be able to use a compute", " $\gamma$ : be able to write your essay using a word processing program" and identify the logical relationships between them to constituent existing logical expressions, like $(\neg \alpha \rightarrow \neg \beta)$ and $(\neg \beta \rightarrow \neg \gamma)$. Then according to equivalence laws, it performs logical inference to extend the logical expressions that are not explicitly mentioned in the context. Comparing the extended expressions with the expressions of candidate options, it selects the most similar option as the answer.</p>
<h2>B. LReasoner Model</h2>
<p>We propose a logic-driven reasoner (LReasoner) model for logical reasoning problems [20] from a neural-symbolic perspective. It utilizes a logic-driven context extension framework to integrate the above reasoning process. Besides, a logic-driven data augmentation algorithm is also introduced, to construct literally similar but logically different samples and utilize contrastive learning to encourage our model better capture logical information.</p>
<p>1) Logic-Driven Context Extension: The overall logicdriven context extension framework is illustrated in Figure 4. It first identifies the logical symbols and expressions explicitly mentioned in the context as the elementary components for reasoning (Logic Identification). Then it performs logical inference following equivalence laws to extend the implicit logical expressions (Logic Extension). Finally, it verbalizes the extended logical expressions related to each option as an extended context and utilizes it into the pre-trained model to match the answer (Logic Verbalization).</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 4: The overall architecture of the logic-driven context extension framework for LR. c, q, o<sup>i</sup> and e<sup>i</sup> are the context, question, i-th option and the extended context for i-th option, respectively. The texts in green mean that the option B is matched against its extended context which has the highest score.</p>
<p>a) <strong>Logic Identification:</strong> It employs a constituency parser [89] to extract constituents including noun phrases and gerundial phrases from the context as basic logical symbols. Then the logical symbols in each sentence are combined by logical negative and conditional connectives {¬, →} to constitute the logical expression as a follow-up. If any negative word among {“<em>not</em>”, “<em>n't</em>”, “<em>unable</em>”, “<em>no</em>”, “<em>few</em>”, “<em>little</em>”, “<em>neither</em>”, “<em>none of</em>”) is in or immediately before a logical symbol α, we add the negation connective ¬ before α as ¬α. If there is a conditional relationship between two logical symbols α and β in a sentence, such as “<em>if α, then β</em>”, “<em>α thus β</em>”, “<em>β due to α</em>” and “<em>¬β unless α</em>”, we can construct the corresponding logical expression as (α → β). As illustrated in Figure 4, it extracts three logical symbols {α,β,γ} and identifies two existing logical expressions as (¬α → ¬β) and (¬β → ¬γ).</p>
<p>b) <strong>Logic Extension:</strong> There still exists some other implicit logical expressions which can be deduced from asserted ones. Therefore, it integrates the identified logical expressions in all sentences of the context, and performs logical inference over them to further extend the implicit expressions according to logical equivalence laws, including contraposition [90] and transitive law [91]:</p>
<p>$$
\text{Contraposition} : (\alpha \rightarrow \beta) \implies (\neg \beta \rightarrow \neg \alpha) \tag{1}
$$</p>
<p>$$
\text{Transitive Law} : (\alpha \rightarrow \beta) \land (\beta \rightarrow \gamma) \implies (\alpha \rightarrow \gamma) \tag{2}
$$</p>
<p>As shown in Figure 4, it implies a set of extended logical expressions as S<sup>E</sup> = {(β → α), (γ → β), (¬α → ¬γ), (γ → α)}.</p>
<p>c) <strong>Logic Verbalization:</strong> Considering that symbolic logic is more difficult to encode, it uses the pre-trained model as the backbone of our framework. It verbalizes extended logical expressions into natural language and feeds them as an extended context into the pre-trained model. Specifically, it selects the related extended expressions for each option that have the same logical symbols as the option and transforms such expressions into natural language by filling them into a template. (¬α → ¬γ) can be verbalized as “<em>If do not α, then will not γ</em>”. It takes such a sentence as an extended context for each option and feeds [CLS] c [SEP] q || o [EXT] e [SEP] into the pre-trained model to get each option's score.</p>
<p>2) <strong>Logic-Driven Data Augmentation:</strong> In order to make our model better capture logical information from the context, we also introduce a logic-driven data augmentation algorithm. It utilizes logical expressions to augment challenging samples with literally similar but logically different contexts. Taking the original context to construct the positive sample, it constructs logical negative samples by modifying the existing logical expressions in the context and verbalizing the modified expressions into a negative context. The modification operations include randomly deleting a logical expression, reversing the conditional order of a logical expression and negating a logical symbol in a logical expression.</p>
<p>It then adopts contrastive learning [92] and trains our model to select the correct context supporting the answer to encourage the model to put more focus on logical information, especially logical negative and conditional relationships. As a result, the model is trained in a combination of answer prediction loss and context classification loss.</p>
<h3>C. Results and Analysis</h3>
<p>1) <strong>Overall Comparison:</strong> We compare our LReasoner model with several baseline models for logical reasoning, and the comparison results are shown in Table V. We can see that LReasoner<sub>ALBERT</sub> achieves a great performance, outperforming all baseline models by a considerable margin on both validation and test sets. This indicates the effectiveness of our logic-driven system for logical reasoning. And LReasoner<sub>RoBERTa</sub> and LReasoner<sub>ALBERT</sub> both perform better than the corresponding baseline models RoBERTa and ALBERT. It demonstrates that LReasoner is robust to be effective for logical reasoning on top of different pre-trained models.</p>
<p>We also conduct ablation study which takes ALBERT as our backbone model. LReasoner<sub>ALBERT</sub> (<em>w/o CE</em>) and LReasoner<sub>ALBERT</sub> (<em>w/o DA</em>) both outperform the baseline</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Methods</th>
<th style="text-align: center;">Val (\%)</th>
<th style="text-align: center;">Test (\%)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Random Guess</td>
<td style="text-align: center;">20.0</td>
<td style="text-align: center;">20.0</td>
</tr>
<tr>
<td style="text-align: center;">BERT</td>
<td style="text-align: center;">39.3</td>
<td style="text-align: center;">39.4</td>
</tr>
<tr>
<td style="text-align: center;">RoBERTa</td>
<td style="text-align: center;">49.2</td>
<td style="text-align: center;">49.6</td>
</tr>
<tr>
<td style="text-align: center;">ALBERT</td>
<td style="text-align: center;">57.9</td>
<td style="text-align: center;">57.8</td>
</tr>
<tr>
<td style="text-align: center;">LReasoner ${ }_{\text {RoBERTa }}$</td>
<td style="text-align: center;">54.0</td>
<td style="text-align: center;">53.3</td>
</tr>
<tr>
<td style="text-align: center;">LReasoner ${ }_{\text {ALBERT }}$</td>
<td style="text-align: center;">$\mathbf{6 5 . 0}$</td>
<td style="text-align: center;">$\mathbf{6 3 . 5}$</td>
</tr>
<tr>
<td style="text-align: center;">Ablation study</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">LReasoner ${ }_{\text {ALBERT }}$ (w/o CE)</td>
<td style="text-align: center;">63.4</td>
<td style="text-align: center;">61.6</td>
</tr>
<tr>
<td style="text-align: center;">LReasoner ${ }_{\text {ALBERT }}$ (w/o DA)</td>
<td style="text-align: center;">61.7</td>
<td style="text-align: center;">60.0</td>
</tr>
</tbody>
</table>
<p>TABLE V: The answer prediction accuracy (\%) of different methods on LR-LSAT. $C E$ and $D A$ are our logic-driven context extension framework and data augmentation algorithm.
model ALBERT and perform worse than our final system LReasoner ${ }_{\text {ALBERT }}$. It demonstrates that both logic-driven context extension framework and logic-driven data augmentation algorithm are beneficial for logical reasoning.
2) Analysis of Logic Identification: To investigate the performance of the heuristic logic identification method, we randomly sample 50 instances and manually annotate the logical symbols and expressions as labels. We report the recall score of logical symbol identification and logical expression identification as $65.9 \%$ and $48.9 \%$, respectively. We can see that our generic logic extraction method which operates in an unsupervised manner achieves relatively reliable performance. How to design an unsupervised and generic logic extraction method is essential to be studied to further enhance the performance of the overall system.
3) Performance on ReClor \&amp; LogiQA: We also conduct experiments on two public logical reasoning datasets, ReClor [14] and LogiQA [25], to investigate the robustness of our logic-driven reasoner. ReClor dataset is proposed from GMAT and LSAT tests while LogiQA is collected from the National Civil Servants Examination of China, and each question is provided with a context and four answer options. As shown in Table VI, our system is robust to be effective on both ReClor and LogiQA, and even surpasses the human performance of ReClor.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">ReClor</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">LogiQA</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Val</td>
<td style="text-align: center;">Test</td>
<td style="text-align: center;">Val</td>
<td style="text-align: center;">Test</td>
</tr>
<tr>
<td style="text-align: center;">RoBERTa [63]</td>
<td style="text-align: center;">62.6</td>
<td style="text-align: center;">55.6</td>
<td style="text-align: center;">35.9</td>
<td style="text-align: center;">35.3</td>
</tr>
<tr>
<td style="text-align: center;">ALBERT [64]</td>
<td style="text-align: center;">70.2</td>
<td style="text-align: center;">66.5</td>
<td style="text-align: center;">38.9</td>
<td style="text-align: center;">37.6</td>
</tr>
<tr>
<td style="text-align: center;">DAGN [76]</td>
<td style="text-align: center;">65.8</td>
<td style="text-align: center;">58.3</td>
<td style="text-align: center;">36.9</td>
<td style="text-align: center;">39.3</td>
</tr>
<tr>
<td style="text-align: center;">LReasoner ${ }_{\text {RoBERTa }}$</td>
<td style="text-align: center;">66.2</td>
<td style="text-align: center;">62.4</td>
<td style="text-align: center;">38.1</td>
<td style="text-align: center;">40.6</td>
</tr>
<tr>
<td style="text-align: center;">LReasoner ${ }_{\text {ALBERT }}$</td>
<td style="text-align: center;">73.2</td>
<td style="text-align: center;">70.7</td>
<td style="text-align: center;">41.6</td>
<td style="text-align: center;">41.2</td>
</tr>
<tr>
<td style="text-align: center;">Human Performance</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">63.0</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">86.0</td>
</tr>
</tbody>
</table>
<p>TABLE VI: Experimental results (accuracy \%) of different models on ReClor and LogiQA.
4) Error Analysis: Although our LReasoner system achieves outstanding performance, there still exist some instances that cannot be solved. Similar to the logical reasoning dataset ReClor [14], LSAT also integrates various types of logical reasoning skills, including "Necessary Assumptions", "Sufficient Assumptions", "Implication", "Most Strongly Sup-
ported", "Strength", "Weaken", "Match flaws", etc. We thus investigate the detailed performance with respect to different logical reasoning types to analyze which type of questions tend to be more challenging.</p>
<p>Among nearly 17 categories, our model performs relatively poorly on Match flaws and Weaken with an almost $60 \%$ accuracy while accuracies of other types are higher than $70 \%$. Weaken aims to find the statement that weaken the argument. Match flaws is even more challenging as it requires analysis of the flaw that conflicts with the complete logical chain illustrated in the context, and find an option exhibiting the same flaw. Our system that first extracts logical expressions and then implies the implicit logical expressions is not suitable for abstracting the complete logical chain for flaw matching and modeling the different degrees of a logical statement to identify weaken statements.
5) Discussion: Our logic-driven system is able to model the discrete logical inference process explicitly and achieves an outstanding performance on LR-LSAT. Our system even surpasses human performance on another logical reasoning dataset, ReClor. However, some challenges are still there. The first is that current methods treat all types of logical reasoning skills alike and do not dive into the difference between reasoning types. How to deal with different logical reasoning types is a further research direction. Moreover, the main challenge for logical reasoning is to point out the logical structures among the context. Specifically, automatically extracting the logical elementary units and identifying the logical relationships between units in an unsupervised manner is essential to be explored and improved. Further research can also focus on directly encoding the symbolic logical structure rather than verbalizing them into natural language for utilization. Concretely, we can separately model each logical connectives in different networks, and take the involved logical symbols as the network inputs to learn the logical expressions.</p>
<h2>VI. READING COMPREHENSION</h2>
<h2>A. RC-LSAT Challenges</h2>
<p>Apart from analytical reasoning and logical reasoning, LSAT also involves reading comprehension, which is a fundamental ability of human intelligence. It requires understanding long-form, complex passages and distinguishing what is the correct statement by synthesis, comparison, and application of principles. Many widely studied datasets have been developed for reading comprehension, such as SQuAD [93], MCTest [94] and RACE [95]. Recent pre-trained language models [63, 64] and diverse attention modules [96, 21] achieve state-of-the-art performance on them, and even exceed human performance. We compare RC-LSAT with several similar multiple-choice reading comprehension datasets including MCTest, RACE, and COSMOS QA [33] to investigate its challenges. The overall statistics are presented in Table VII.</p>
<p>We can see that the context, question and option of RCLSAT are more complicated than other datasets with longer sequences, which are also more difficult to be comprehended. Take a look at the following example question "Which one of the following most accurately and completely describes</p>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>MCTest</th>
<th>RACE</th>
<th>COSMOS QA</th>
<th>RC-LSAT</th>
</tr>
</thead>
<tbody>
<tr>
<td># of contexts</td>
<td>660</td>
<td>27,933</td>
<td>21,866</td>
<td>360</td>
</tr>
<tr>
<td># of questions</td>
<td>2,640</td>
<td>97,687</td>
<td>35,588</td>
<td>2,419</td>
</tr>
<tr>
<td>Context Len</td>
<td>210.1</td>
<td>321.9</td>
<td>70.3</td>
<td>511.5</td>
</tr>
<tr>
<td>Question Len</td>
<td>7.8</td>
<td>10.0</td>
<td>10.6</td>
<td>20.5</td>
</tr>
<tr>
<td>Option Len</td>
<td>3.4</td>
<td>5.3</td>
<td>8.1</td>
<td>16.8</td>
</tr>
</tbody>
</table>
<p>TABLE VII: Statistics of RACE, COSMOS QA, and RCLSAT.
the function of the second paragraph of the passage?" and the corresponding answer "explains the ramifications of the strict constructionists claims and helps clarify the relevance of evidence offered in subsequent paragraphs". Not only text understanding and function abstraction, but also positional information modeling, such as "the second paragraph of the passage", should be both incorporated for answer prediction. Besides, RC-LSAT is of relatively limited data size. The above-mentioned challenges make models stuck in more complex reading comprehension with few data.</p>
<h2>B. Position-aware DUMA Model</h2>
<p>Considering the state-of-the-art performance achieved by DUMA model [21] on most similar examination-based reading comprehension datasets RACE involving reasoning, we also employ DUMA for RC-LSAT. Compared to the baseline Model introduced in Sec III-B, it additionally employs a Dual Multi-head Co-Attention module between the pre-trained encoder model and the classification layer. It simulates human transposition thinking patterns to further capture relationships of key information from the passage, question and answer options. In Dual Multi-head Co-Attention module, it first separates the output representation of the encoder to obtain $E^{P}=\left[e_{1}^{p}, e_{2}^{p}, \ldots, e_{l_{p}}^{p}\right]$ and $E^{Q A}=\left[e_{1}^{q a}, e_{2}^{q a}, \ldots, e_{l_{q a}}^{q a}\right]$, where $e_{i}^{p}$, $e_{j}^{q a}$ denote the $i$-th and $j$-th token representation of passage and question-answer respectively and $l_{p}, l_{q a}$ are the corresponding lengths. It then calculates question-answer-aware passage representation $E^{P(Q A)}$ and passage-aware questionanswer representation $E^{Q A(P)}$ in a bi-directional way. It aggregates the key information from $E^{Q A(P)}$ and $E^{P(Q A)}$ as $O_{i}$ by mean pooling and concatenation operations and utilizes it for answer classification instead of $[C L S]$ representation.</p>
<p>$$
\begin{aligned}
E^{Q A(P)} &amp; =\text { MultiHeadAttn }\left(E^{P}, E^{Q A}, E^{Q A}\right) \
E^{P(Q A)} &amp; =\text { MultiHeadAttn }\left(E^{Q A}, E^{P}, E^{P}\right) \
O_{i} &amp; =\left[\text { Mean }\left(E^{Q A(P)}\right) ; \text { Mean }\left(E^{P(Q A)}\right)\right]
\end{aligned}
$$</p>
<p>Note that questions of RC-LSAT usually involve positional information indicators, like "line 3-5" and "second paragraph", we label the context with position marks, e.g., "〈line3〉... 〈/line3〉" for line 3 and "〈P2〉... 〈/P2〉" for paragraph 2. We feed labeled context as input and implement a positionaware DUMA model.</p>
<h2>C. Results and Analysis</h2>
<p>1) Overall Comparison: We compare our position-aware DUMA (P-DUMA) model with several baseline models and</p>
<p>DUMA model and the comparison result is shown in Table VIII. We can see that our P-DUMA model achieves outstanding performance on both validation and test sets. Position marks are observed to help improve performance on top of both ALBERT and DUMA, which shows the effectiveness of our proposed position mark for RC-LSAT.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Val (\%)</th>
<th style="text-align: center;">Test (\%)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">RoBERTa</td>
<td style="text-align: center;">52.0</td>
<td style="text-align: center;">44.0</td>
</tr>
<tr>
<td style="text-align: left;">ALBERT</td>
<td style="text-align: center;">51.9</td>
<td style="text-align: center;">48.7</td>
</tr>
<tr>
<td style="text-align: left;">DUMA</td>
<td style="text-align: center;">$\mathbf{6 0 . 0}$</td>
<td style="text-align: center;">52.0</td>
</tr>
<tr>
<td style="text-align: left;">$P$-ALBERT</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">55.4</td>
</tr>
<tr>
<td style="text-align: left;">$P$-DUMA</td>
<td style="text-align: center;">57.4</td>
<td style="text-align: center;">$\mathbf{5 6 . 1}$</td>
</tr>
</tbody>
</table>
<p>TABLE VIII: Overall performance (\%) on RC-LSAT. $P$ ALBERT and $P$-DUMA mean position-aware ALBERT and our position-aware DUMA model, respectively.
2) Transfer Learning: Previous work [97, 98] has shown the effectiveness of pre-training on similar datasets then finetuning on the target dataset for transfer learning, which can partly relieve the pressure of data sparsity. Due to limited samples in the RC-LSAT, we adopt the most similar RACE as the source dataset and conduct a set of transfer learning experiments. As shown in Table IX, a significant improvement is obtained after transfer learning for all models, which further validates the potential of transfer learning for reading comprehension. However, positional information has no effect in transfer learning settings compared to position-unaware ALBERT and DUMA. The reason may be that the gap between RC-LSAT and RACE becomes larger after using position marks, as no position label is provided in RACE.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Val (\%)</th>
<th style="text-align: center;">Test (\%)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">ALBERT $_{\text {RACE }}$</td>
<td style="text-align: center;">$\mathbf{7 3 . 7}$</td>
<td style="text-align: center;">67.7</td>
</tr>
<tr>
<td style="text-align: left;">DUMA $_{\text {RACE }}$</td>
<td style="text-align: center;">71.9</td>
<td style="text-align: center;">$\mathbf{6 9 . 1}$</td>
</tr>
<tr>
<td style="text-align: left;">$P$-ALBERT $_{\text {RACE }}$</td>
<td style="text-align: center;">71.5</td>
<td style="text-align: center;">68.4</td>
</tr>
<tr>
<td style="text-align: left;">$P$-DUMA $_{\text {RACE }}$</td>
<td style="text-align: center;">68.5</td>
<td style="text-align: center;">63.9</td>
</tr>
</tbody>
</table>
<p>TABLE IX: Transfer learning results of models first trained on RACE and then fine-tuned on RC-LSAT.
3) Error Analysis: Although outstanding performance has been achieved, there still exist some challenging instances. We illustrate the major error types of RC-LSAT as follows.</p>
<p>The first type of error is caused by the reason that the context is too long and some essential information for answer prediction is truncated and cannot be effectively encoded. The second error type is that some comparative questions require comparative learning ability, which still has not been considered. Take the question "The authors of the passages would be most likely to disagree over whether?" as an example, the model not only needs to understand the view of each author, but also aims to comparatively infer the point that authors would disagree with. In addition, the lack of commonsense knowledge is another key problem for the wrong prediction. For example, unaware that 1934 and 1939 are within the 1930s, the model would fail to answer the question "According to the passage, which one of the following was true of the physics community during the 1930s?".</p>
<p>4) Discussion: Although previous work [64, 21] and our models have shown promising results on RC-LSAT, we still have a way to go to improve performance. As the truncation mechanism of pre-trained models threatens modeling long sequence and the sparse self-attention mechanism [99] sometimes fails to be effective, designing an appropriate hierarchical encoder for long-form sequence encoding is emerging as an area for further exploration. Besides, current methods rarely specialize in answering comparative questions, how to comparatively reading multiple passages and diving into the differences also requires potential research.</p>
<p>A more challenging direction is to retrieve relevant commonsense or passages from open source and incorporate them as evidence for answer prediction. Previous work [100, 101] can only achieve poor performance on this topic due to intrinsic noise in retrieved passages. Further research can focus on improving evidence retrieval and predicting answers from noised evidence.</p>
<h2>VII. FURTHER DISCUSSION</h2>
<p>After making attempts on three tasks of the LSAT, we have achieved some progress towards complex reasoning. We evaluate our whole system on the LSAT tests and raise some positive findings. We further discuss the existing challenges of complex reasoning and shed a light on the future research directions.</p>
<h2>A. Overall Performance of LSAT Tests</h2>
<p>To give an intuitive overview of our machine intelligence in LSAT tests, we convert our raw accuracy scores of three tasks to an LSAT scale, which ranges from 120 to 180 [102]. We also integrate the accuracies of AR, LR and RC, to calculate an overall score by weighted averaging with the original proportion of $1: 2: 1$. We compare our scaled scores with the median score of candidates taking LSAT exams during $2019 \sim 2020$ [103]. We further demonstrate which level of schools our systems could be admitted to according to the law school rankings displayed by Internet Legal Research Group [104].</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Scaled (Raw) Score</th>
<th style="text-align: center;">School Ranking</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Overall system</td>
<td style="text-align: center;">$151(56.8 \%)$</td>
<td style="text-align: center;">Top 104</td>
</tr>
<tr>
<td style="text-align: left;">AR system</td>
<td style="text-align: center;">$135(30.9 \%)$</td>
<td style="text-align: center;">$&gt;200$</td>
</tr>
<tr>
<td style="text-align: left;">LR system</td>
<td style="text-align: center;">$155(63.5 \%)$</td>
<td style="text-align: center;">Top 58</td>
</tr>
<tr>
<td style="text-align: left;">RC system</td>
<td style="text-align: center;">$158(69.1 \%)$</td>
<td style="text-align: center;">Top 30</td>
</tr>
<tr>
<td style="text-align: left;">Candidates</td>
<td style="text-align: center;">$152(58.0 \%)$</td>
<td style="text-align: center;">Top 94</td>
</tr>
</tbody>
</table>
<p>TABLE X: Comparison results of our systems with human candidates. $&gt;200$ means that the ranking of AR system is beyond the top 200 which is not displayed by Internet Legal Research Group [104].</p>
<p>As shown in Table X, we have several positive findings. Our overall system achieves impressive performance on the standard LSAT tests designed to examine the reasoning ability of prospective law school candidates, and performs comparably with the median candidate scores, which indicates the potential of machine complex reasoning. Our systems for RC and LR even have a chance to be accepted by the top 30 and 58 law schools, respectively, which demonstrates that the combination of the powerful pre-trained models and taskspecific reasoning modules is effective in performing complex reasoning. Concretely, our logic-driven system endows itself an excellent logical reasoning ability by performing explicit logical inference while the DUMA model aware of position information with transfer learning possesses fundamental complex reading comprehension capability. Although AR is an extremely challenging task requiring a more comprehensive understanding of all context pieces to build the whole reasoning chain and only few data is available, our symbolic ARM system is still able to get into a law school, which shows that symbolic knowledge plus discrete interpretable reasoning steps is essential in solving analytical reasoning task.</p>
<h2>B. Challenges \&amp; Future Directions</h2>
<p>Despite the positive achievement, some unsolved challenges remain in complex reasoning. We investigate the major challenges and the corresponding potential solutions as follows.</p>
<p>1) Unsupervised Symbolic Knowledge Extraction: The automatic extraction of elementary symbolic units or expressions builds the foundation of complex reasoning tasks as it is required to fully understand complex scenarios, which further affects the performance of the overall reasoning system. For example, the extraction of mathematical expressions composed of quantities and arithmetic signs is essential for numerical reasoning, and logical reasoning is heavily reliant upon logical expression identification. However, predefined rule patterns by domain experts or large-scale annotated data for symbolic knowledge extraction are expensive, which are impractical to be obtained for all the tasks. Therefore, the unsupervised extraction of symbolic knowledge is a major challenge in complex reasoning.</p>
<p>To handle this challenge, we can begin by utilizing formal programming languages [105, 106] to design a generic and extensible extraction framework for universal symbolic knowledge, supplemented by a set of task-specific extension and modification operations. In this way, we can further modify and extend the generic framework, and obtain the specific extraction method for different complex reasoning tasks to automatically extract high-quality symbolic knowledge.
2) Model Interpretability: Interpretability is a significant characteristic of trustworthy and controllable reasoning systems, which makes the decision-making process of complex reasoning comprehensible and predicts more reliable results. Besides, the incorrect prediction can be traced to learn the cause and intervened to make a revised prediction. For instance, the explicit walk along the multi-hop relational paths makes the multi-hop reasoning process more interpretable to find the answer. Although neural models achieve robust performance on complex reasoning, their prediction is always a black box for humans to understand. How to improve the interpretability of a neural system is essential to be studied.</p>
<p>We can design the neural model structure from the perspective of simulating human cognition and the reasoning process. It integrates multiple modules for different reasoning steps,</p>
<p>and injects the intermediate results into the whole reasoning chain, which makes the neural model interpretable.
3) Few-Shot Learning: As the data targeted at complex reasoning with high quality and difficulty is rare and hard to be collected or annotated, the traditional data-driven learning methods heavily relying on a huge amount of training instances may have poor performance on complex reasoning tasks. The analytical reasoning task is a typical example with few data. Therefore, a few-shot learning paradigm [107, 108, 109] urgently needs to be explored for complex reasoning to improve the reasoning ability and the generalization capability of systems with only a few training instances.</p>
<p>Transfer learning will be a potential direction of few-shot learning for complex reasoning. It uses the pre-training models on related tasks as the starting point which can ease the sufferings of data sparsity, and transfer the reasoning ability learned from source task to target domain. We can also heuristically synthesize the data by modifying original data to augment the dataset of the current complex reasoning task.
4) All-Sided Benchmark for Complex Reasoning: Recent years have witnessed an increasing trend in natural language understanding towards complex reasoning, yet there is no existing integrated benchmark to the best of our knowledge, that comprehensively evaluates different types and domains of complex reasoning ability. It is worthwhile to build an all-sided benchmark dataset to promote research in complex reasoning.</p>
<p>First of all, the benchmark should cover the three reasoning capabilities involved in the LSAT. Specifically, reading comprehension establishes the foundation of complex reasoning to understand and summarize the semantics of substances and qualities. Logical reasoning extends complex reasoning ability with logical deduction over propositions while analytical reasoning simulates the human analytical thinking and problemsolving capacity. Then several widely studied complex reasoning tasks should be integrated, such as reasoning for commonsense knowledge [27, 29, 30], multi-hop relationships [35, 36] and numerical calculation [44, 45] described in § II-A.</p>
<p>Some other rarely explored complex reasoning abilities also need to be considered. For example, we should dive into abductive reasoning [110] and counterfactual reasoning [111, 112] to research cause-and-effect complex reasoning. The former aims to trace the most likely explanation to partial observations and the latter focus on the illation of how alternative events in the past result in different outcomes. Analogical reasoning [113] that draws a comparison between different things and based on their similarities to infer their further shared properties is widely adopted in human daily thinking. As no benchmark dataset so far has been proposed for mainly enhancing analogical inference, it also should be involved in this comprehensive benchmark.</p>
<h2>VIII. CONCLUSION</h2>
<p>In this paper, we take a step towards complex reasoning research by studying three tasks involved in LSAT tests, namely, analytical reasoning, logical reasoning and reading comprehension. Inspired by the advantages and disadvantages of symbolic, neural, and neural-symbolic methods of complex
reasoning, we propose a hybrid system for three tasks and achieve promising performance on the LSAT tests. In particular, our position-aware DUMA model with transfer learning for reading comprehension and logic-driven model for logical reasoning even have a chance to be recruited to the top 30 and top 58 law schools, respectively. It demonstrates our progress in modeling complex reasoning abilities, notably the fundamental reading comprehension and challenging logical reasoning capability. Through a systematical study of the LSAT, we further overall discuss the unsolved challenges in complex reasoning and investigate the potential directions. In the future, how to extract symbolic knowledge in an unsupervised manner and improve the interpretability of a neural reasoning system are promising directions. Few-shot complex reasoning and building a comprehensive complex reasoning benchmark are also worthy of exploration.</p>
<h2>APPENDIX A</h2>
<h2>Data Annotation</h2>
<p>We annotate a subset of programs to investigate the operation mechanism of our neural-symbolic method. An example of our annotation is shown in Figure 5. For each problem, we not only annotate the participants and positions, but also annotate the programs of all constraints in the context and question-option pairs. We annotate a total of $100 / 40 / 40$ instances for participants and positions extraction in the training/validation/test set. As the AR task has a situational property that a group of questions share the same context but ask different aspects of information, we annotate programs for total 77 contexts and 428 questions, with $50 / 13 / 14$ contexts and $274 / 75 / 79$ questions in the train/validation/test set.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Context</span><span class="w"> </span><span class="o">:</span>
<span class="n">A</span><span class="w"> </span><span class="n">closet</span><span class="w"> </span><span class="n">contains</span><span class="w"> </span><span class="n">exactly</span><span class="w"> </span><span class="n">six</span><span class="w"> </span><span class="n">hangers</span><span class="o">-</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="mi">3</span><span class="o">,</span><span class="mi">4</span><span class="o">,</span><span class="mi">5</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="mi">6</span><span class="o">-</span><span class="n">hanging</span><span class="o">,</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">order</span><span class="o">,</span>
<span class="n">from</span><span class="w"> </span><span class="n">left</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">right</span><span class="o">.</span><span class="w"> </span><span class="n">It</span><span class="w"> </span><span class="n">also</span><span class="w"> </span><span class="n">contains</span><span class="w"> </span><span class="n">exactly</span><span class="w"> </span><span class="n">six</span><span class="w"> </span><span class="n">dresses</span><span class="o">-</span><span class="n">one</span><span class="w"> </span><span class="n">gauze</span><span class="o">,</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">linen</span><span class="o">,</span><span class="w"> </span><span class="n">one</span>
<span class="n">polyester</span><span class="o">,</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">rayon</span><span class="o">,</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">silk</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">wool</span><span class="o">-</span><span class="n">a</span><span class="w"> </span><span class="n">different</span><span class="w"> </span><span class="n">dress</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="k">each</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span>
<span class="n">hangers</span><span class="o">,</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">order</span><span class="w"> </span><span class="n">satisfying</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">following</span><span class="w"> </span><span class="n">conditions</span><span class="o">:</span>
<span class="n">The</span><span class="w"> </span><span class="n">gauze</span><span class="w"> </span><span class="n">dress</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lower</span><span class="o">-</span><span class="n">numbered</span><span class="w"> </span><span class="n">hanger</span><span class="w"> </span><span class="n">than</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">polyester</span><span class="w"> </span><span class="n">dress</span><span class="o">.</span><span class="w"> </span><span class="o">(</span><span class="n">C</span><span class="o">-</span><span class="mi">1</span><span class="o">)</span>
<span class="n">The</span><span class="w"> </span><span class="n">rayon</span><span class="w"> </span><span class="n">dress</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">hanger</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">hanger</span><span class="w"> </span><span class="mi">6</span><span class="o">.</span><span class="w"> </span><span class="o">(</span><span class="n">C</span><span class="o">-</span><span class="mi">2</span><span class="o">)</span>
<span class="n">Either</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">wool</span><span class="w"> </span><span class="n">dress</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">silk</span><span class="w"> </span><span class="n">dress</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">hanger</span><span class="w"> </span><span class="mi">3</span><span class="o">.</span><span class="w"> </span><span class="o">(</span><span class="n">C</span><span class="o">-</span><span class="mi">3</span><span class="o">)</span>
<span class="n">The</span><span class="w"> </span><span class="n">linen</span><span class="w"> </span><span class="n">dress</span><span class="w"> </span><span class="n">hangs</span><span class="w"> </span><span class="n">immediately</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">right</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">silk</span><span class="w"> </span><span class="n">dress</span><span class="o">.</span><span class="w"> </span><span class="o">(</span><span class="n">C</span><span class="o">-</span><span class="mi">4</span><span class="o">)</span>
<span class="n">Question</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">Which</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">following</span><span class="w"> </span><span class="n">CANNOT</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="kc">true</span><span class="o">?</span>
<span class="n">Options</span><span class="w"> </span><span class="o">:</span>
<span class="n">A</span><span class="o">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">linen</span><span class="w"> </span><span class="n">dress</span><span class="w"> </span><span class="n">hangs</span><span class="w"> </span><span class="n">immediately</span><span class="w"> </span><span class="n">next</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">gauze</span><span class="w"> </span><span class="n">dress</span><span class="o">.</span>
<span class="n">B</span><span class="o">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">polyester</span><span class="w"> </span><span class="n">dress</span><span class="w"> </span><span class="n">hangs</span><span class="w"> </span><span class="n">immediately</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">right</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">rayon</span><span class="w"> </span><span class="n">dress</span><span class="o">.</span>
<span class="n">C</span><span class="o">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">rayon</span><span class="w"> </span><span class="n">dress</span><span class="w"> </span><span class="n">hangs</span><span class="w"> </span><span class="n">immediately</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">left</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">wool</span><span class="w"> </span><span class="n">dress</span><span class="o">.</span>
<span class="n">D</span><span class="o">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">silk</span><span class="w"> </span><span class="n">dress</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lower</span><span class="o">-</span><span class="n">numbered</span><span class="w"> </span><span class="n">hanger</span><span class="w"> </span><span class="n">than</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">gauze</span><span class="w"> </span><span class="n">dress</span><span class="o">.</span>
<span class="n">E</span><span class="o">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">wool</span><span class="w"> </span><span class="n">dress</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">higher</span><span class="o">-</span><span class="n">numbered</span><span class="w"> </span><span class="n">hanger</span><span class="w"> </span><span class="n">than</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">rayon</span><span class="w"> </span><span class="n">dress</span><span class="o">.</span>
</code></pre></div>

<table>
<thead>
<tr>
<th style="text-align: left;">Annotated</th>
<th style="text-align: left;">Participants: gauze, linen, polyester, rayon, silk, wool</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Participants \&amp;</td>
<td style="text-align: left;">Positions: $1,2,3,4,5,6$</td>
</tr>
<tr>
<td style="text-align: left;">Positions</td>
<td style="text-align: left;">C-1: VALUE(gauze) &lt; VALUE (polyester)</td>
</tr>
<tr>
<td style="text-align: left;">Annotated</td>
<td style="text-align: left;">C-2: VALUE (rayon) = 1 OR VALUE (rayon) = 6</td>
</tr>
<tr>
<td style="text-align: left;">Programs</td>
<td style="text-align: left;">C-3: VALUE (wool) = 3 OR VALUE (silk) = 3</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">C-4: VALUE (linen) = VALUE (silk) + 1</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Q-A: NOT ABS/VALUE(linen) - VALUE (gauze)) = 1</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Q-B: NOT VALUE (polyester) = VALUE (rayon) + 1</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Q-C: NOT VALUE (rayon) = VALUE (wool) - 1</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Q-D: NOT VALUE (silk) &lt; VALUE (gauze)</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Q-E: NOT VALUE (wool) &gt; VALUE (rayon)</td>
</tr>
</tbody>
</table>
<p>Fig. 5: An example of our annotation for an AR problem. C - $i$ means the $i$-th constraint while Q - $j$ denotes the pair of the question and option $j$.</p>
<h2>REFERENCES</h2>
<p>[1] R. A. Duschl, H. A. Schweingruber, and A. W. Shouse, "Taking science to school: Learning and teaching science in grades k-8," Eurasia Journal of Mathematics, Science \&amp; Technology Education, vol. 3, no. 2, pp. 163166, 2007.
[2] N. B. Songer, B. Kelcey, and A. W. Gotwals, "How and when does complex reasoning occur? empirically driven development of a learning progression focused on complex reasoning about biodiversity," Journal of Research in Science Teaching: The Official Journal of the National Association for Research in Science Teaching, vol. 46, no. 6, pp. 610-631, 2009.
[3] S. Chattopadhyay, S. Banerjee, F. A. Rabhi, and U. R. Acharya, "A case-based reasoning system for complex medical diagnosis," Expert Systems, vol. 30, no. 1, pp. 12-20, 2013.
[4] S. Shi, Y. Wang, C.-Y. Lin, X. Liu, and Y. Rui, "Automatically solving number word problems by semantic parsing and reasoning," in Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, 2015, pp. 1132-1142.
[5] F. Reinhold, S. Hofer, M. Berkowitz, A. Strohmaier, S. Scheuerer, F. Loch, B. Vogel-Heuser, and K. Reiss, "The role of spatial, verbal, numerical, and general reasoning abilities in complex word problem solving for young female and male adults," Mathematics Education Research Journal, vol. 32, no. 2, pp. 189-211, 2020.
[6] A. Galassi, K. Kersting, M. Lippi, X. Shao, and P. Torroni, "Neural-symbolic argumentation mining: An argument in favor of deep learning and reasoning," Frontiers in big Data, vol. 2, p. 52, 2020.
[7] A. Fujita, A. Kameda, A. Kawazoe, and Y. Miyao, "Overview of todai robot project and evaluation framework of its nlp-based problem solving," World History, vol. 36, no. 36, p. 148, 2014.
[8] G. Cheng, W. Zhu, Z. Wang, J. Chen, and Y. Qu, "Taking up the gaokao challenge: An information retrieval approach." in IJCAI, vol. 2016, 2016, pp. 2479-2485.
[9] K. Yu, Q. Liu, Y. Zheng, T. Zhao, and D. Zheng, "History question classification and representation for chinese gaokao," in 2016 International Conference on Asian Language Processing (IALP). IEEE, 2016, pp. $129-132$.
[10] Z. Zhang, L. Zhang, H. Zhang, W. He, Z. Sun, G. Cheng, Q. Liu, X. Dai, and Y. Qu, "Towards answering geography questions in gaokao: A hybrid approach," in China Conference on Knowledge Graph and Semantic Computing. Springer, 2018, pp. 1-13.
[11] D. Gunning, V. K. Chaudhri, P. E. Clark, K. Barker, S.Y. Chaw, M. Greaves, B. Grosof, A. Leung, D. D. McDonald, S. Mishra et al., "Project halo update-progress toward digital aristotle," AI Magazine, vol. 31, no. 3, pp. 33-58, 2010.
[12] J. Ding, Y. Wang, W. Hu, L. Shi, and Y. Qu, "Answering multiple-choice questions in geographical gaokao with a concept graph," in European Semantic Web Conference.</p>
<p>Springer, 2018, pp. 161-176.
[13] Z. Zhang and H. Zhao, "One-shot learning for questionanswering in gaokao history challenge," arXiv preprint arXiv:1806.09105, 2018.
[14] W. Yu, Z. Jiang, Y. Dong, and J. Feng, "Reclor: A reading comprehension dataset requiring logical reasoning," in International Conference on Learning Representations (ICLR), April 2020.
[15] S. Itzhaky, S. Gulwani, N. Immerman, and M. Sagiv, "Solving geometry problems using a combination of symbolic and numerical reasoning," in International Conference on Logic for Programming Artificial Intelligence and Reasoning. Springer, 2013, pp. 457-472.
[16] S. H. Bach, M. Broecheler, B. Huang, and L. Getoor, "Hinge-loss markov random fields and probabilistic soft logic," arXiv preprint arXiv:1505.04406, 2015.
[17] J. Zhang, B. Chen, L. Zhang, X. Ke, and H. Ding, "Neural, symbolic and neural-symbolic reasoning on knowledge graphs," AI Open, vol. 2, pp. 14-35, 2021.
[18] X. Chen, C. Liang, A. W. Yu, D. Zhou, D. Song, and Q. V. Le, "Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension," in International Conference on Learning Representations, 2019.
[19] W. Zhong, S. Wang, D. Tang, Z. Xu, D. Guo, J. Wang, J. Yin, M. Zhou, and N. Duan, "Ar-lsat: Investigating analytical reasoning of text," 2021.
[20] S. Wang, W. Zhong, D. Tang, Z. Wei, Z. Fan, D. Jiang, M. Zhou, and N. Duan, "Logic-driven context extension and data augmentation for logical reasoning of text," 2021.
[21] P. Zhu, H. Zhao, and X. Li, "Duma: Reading comprehension with transposition thinking," arXiv: 2001.09415, 2020.
[22] I. Dagan, O. Glickman, and B. Magnini, "The pascal recognising textual entailment challenge," in Machine Learning Challenges Workshop. Springer, 2005, pp. $177-190$.
[23] S. R. Bowman, G. Angeli, C. Potts, and C. D. Manning, "A large annotated corpus for learning natural language inference," in Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Lisbon, Portugal: Association for Computational Linguistics, Sep. 2015, pp. 632-642.
[24] A. Williams, N. Nangia, and S. R. Bowman, "A broadcoverage challenge corpus for sentence understanding through inference," arXiv preprint arXiv:1704.05426, 2017.
[25] J. Liu, L. Cui, H. Liu, D. Huang, Y. Wang, and Y. Zhang, "Logiqa: A challenge dataset for machine reading comprehension with logical reasoning," in Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, 2020.
[26] H. Rashkin, M. Sap, E. Allaway, N. A. Smith, and Y. Choi, "Event2mind: Commonsense inference on events, intents, and reactions," arXiv preprint arXiv:1805.06939, 2018.
[27] A. Talmor, J. Herzig, N. Lourie, and J. Berant,</p>
<p>"Commonsenseqa: A question answering challenge targeting commonsense knowledge," arXiv preprint arXiv:1811.00937, 2018.
[28] B. Zhou, D. Khashabi, Q. Ning, and D. Roth, "" going on a vacation" takes longer than" going for a walk": A study of temporal commonsense understanding," arXiv preprint arXiv:1909.03065, 2019.
[29] R. Speer, J. Chin, and C. Havasi, "Conceptnet 5.5: An open multilingual graph of general knowledge," in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 31, no. 1, 2017.
[30] M. Sap, R. Le Bras, E. Allaway, C. Bhagavatula, N. Lourie, H. Rashkin, B. Roof, N. A. Smith, and Y. Choi, "Atomic: An atlas of machine commonsense for if-then reasoning," in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, no. 01, 2019, pp. 3027-3035.
[31] M. Sap, V. Shwartz, A. Bosselut, Y. Choi, and D. Roth, "Introductory tutorial: Commonsense reasoning for natural language processing," Association for Computational Linguistics (ACL 2020): Tutorial Abstracts, p. 27, 2020.
[32] S. Zhang, X. Liu, J. Liu, J. Gao, K. Duh, and B. Van Durme, "Record: Bridging the gap between human and machine commonsense reading comprehension," arXiv preprint arXiv:1810.12885, 2018.
[33] L. Huang, R. L. Bras, C. Bhagavatula, and Y. Choi, "Cosmos qa: Machine reading comprehension with contextual commonsense reasoning," arXiv preprint arXiv:1909.00277, 2019.
[34] D. Khashabi, S. Chaturvedi, M. Roth, S. Upadhyay, and D. Roth, "Looking beyond the surface: A challenge set for reading comprehension over multiple sentences," in Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), 2018, pp. 252-262.
[35] J. Welbl, P. Stenetorp, and S. Riedel, "Constructing datasets for multi-hop reading comprehension across documents," Transactions of the Association for Computational Linguistics, vol. 6, pp. 287-302, 2018.
[36] Z. Yang, P. Qi, S. Zhang, Y. Bengio, W. W. Cohen, R. Salakhutdinov, and C. D. Manning, "Hotpotqa: A dataset for diverse, explainable multi-hop question answering," arXiv preprint arXiv:1809.09600, 2018.
[37] N. Inoue, P. Stenetorp, and K. Inui, "R4c: A benchmark for evaluating rc systems to get the right answer for the right reason," arXiv preprint arXiv:1910.04601, 2019.
[38] E. Choi, H. He, M. Iyyer, M. Yatskar, W.-t. Yih, Y. Choi, P. Liang, and L. Zettlemoyer, "Quac: Question answering in context," arXiv preprint arXiv:1808.07036, 2018.
[39] S. Reddy, D. Chen, and C. D. Manning, "Coqa: A conversational question answering challenge," Transactions of the Association for Computational Linguistics, vol. 7, pp. 249-266, 2019.
[40] J. Chen, S.-t. Lin, and G. Durrett, "Multi-hop question answering via reasoning chains," arXiv preprint arXiv:1910.02610, 2019.
[41] H. Wang, M. Yu, X. Guo, R. Das, W. Xiong, and T. Gao, "Do multi-hop readers dream of reasoning chains?" arXiv preprint arXiv:1910.14520, 2019.
[42] P. Clark, O. Etzioni, T. Khot, A. Sabharwal, O. Tafjord, P. Turney, and D. Khashabi, "Combining retrieval, statistics, and inference to answer elementary science questions," in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 30, no. 1, 2016.
[43] W. Ling, D. Yogatama, C. Dyer, and P. Blunsom, "Program induction by rationale generation: Learning to solve and explain algebraic word problems," arXiv preprint arXiv:1705.04146, 2017.
[44] D. Dua, Y. Wang, P. Dasigi, G. Stanovsky, S. Singh, and M. Gardner, "Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs," arXiv preprint arXiv:1903.00161, 2019.
[45] A. Amini, S. Gabriel, P. Lin, R. Koncel-Kedziorski, Y. Choi, and H. Hajishirzi, "Mathqa: Towards interpretable math word problem solving with operationbased formalisms," arXiv preprint arXiv:1905.13319, 2019.
[46] L. Wang, Y. Wang, D. Cai, D. Zhang, and X. Liu, "Translating a math word problem to an expression tree," arXiv preprint arXiv:1811.05632, 2018.
[47] Z. Xie and S. Sun, "A goal-driven tree-structured neural model for math word problems." in IJCAI, 2019, pp. 5299-5305.
[48] Y. Hong, Q. Li, D. Ciao, S. Huang, and S.-C. Zhu, "Learning by fixing: Solving math word problems with weak supervision," in AAAI Conference on Artificial Intelligence, 2021.
[49] A. Saha, S. Joty, and S. C. Hoi, "Weakly supervised neuro-symbolic module networks for numerical reasoning," arXiv preprint arXiv:2101.11802, 2021.
[50] L. A. Galárraga, C. Teflioudi, K. Hose, and F. Suchanek, "Amie: association rule mining under incomplete evidence in ontological knowledge bases," in Proceedings of the 22nd international conference on World Wide Web, 2013, pp. 413-422.
[51] W. Zheng, L. Zou, X. Lian, J. X. Yu, S. Song, and D. Zhao, "How to build templates for rdf question/answering: An uncertain graph similarity join approach," in Proceedings of the 2015 ACM SIGMOD international conference on management of data, 2015, pp. 1809-1824.
[52] M. Minsky and S. A. Papert, Perceptrons: An introduction to computational geometry. MIT press, 2017.
[53] I. Donadello, L. Serafini, and A. D. Garcez, "Logic tensor networks for semantic image interpretation," arXiv preprint arXiv:1705.08968, 2017.
[54] L. S. Fuchs, D. C. Geary, D. L. Compton, D. Fuchs, C. Schatschneider, C. L. Hamlett, J. DeSelms, P. M. Seethaler, J. Wilson, C. F. Craddock et al., "Effects of first-grade number knowledge tutoring with contrasting forms of practice." Journal of Educational Psychology, vol. 105, no. 1, p. 58, 2013.
[55] K. Supekar, A. G. Swigart, C. Tenison, D. D. Jolles, M. Rosenberg-Lee, L. Fuchs, and V. Menon, "Neural</p>
<p>predictors of individual differences in response to math tutoring in primary-grade school children," Proceedings of the National Academy of Sciences, vol. 110, no. 20, pp. 8230-8235, 2013.
[56] I. Donadello and L. Serafini, "Integration of numeric and symbolic information for semantic image interpretation," Intelligenza Artificiale, vol. 10, no. 1, pp. 33-47, 2016.
[57] R. Sun, "Robust reasoning: integrating rule-based and similarity-based reasoning," Artificial Intelligence, vol. 75, no. 2, pp. 241-295, 1995.
[58] F. Rosenblatt, "The perceptron: a probabilistic model for information storage and organization in the brain." Psychological review, vol. 65, no. 6, p. 386, 1958.
[59] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, "Learning representations by back-propagating errors," nature, vol. 323, no. 6088, pp. 533-536, 1986.
[60] G. E. Hinton, S. Osindero, and Y.-W. Teh, "A fast learning algorithm for deep belief nets," Neural computation, vol. 18, no. 7, pp. 1527-1554, 2006.
[61] Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle, "Greedy layer-wise training of deep networks," in Advances in neural information processing systems, 2007, pp. 153-160.
[62] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, "BERT: Pre-training of deep bidirectional transformers for language understanding," in Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Minneapolis, Minnesota: Association for Computational Linguistics, Jun. 2019, pp. 4171-4186.
[63] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov, "Roberta: A robustly optimized bert pretraining approach," CoRR, vol. abs/1907.11692, 2019.
[64] Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut, "Albert: A lite bert for self-supervised learning of language representations," in International Conference on Learning Representations, 2020.
[65] T. N. Kipf and M. Welling, "Semi-supervised classification with graph convolutional networks," arXiv preprint arXiv:1609.02907, 2016.
[66] P. Veličković, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio, "Graph attention networks," arXiv preprint arXiv:1710.10903, 2017.
[67] J. Andreas, M. Rohrbach, T. Darrell, and D. Klein, "Neural module networks," in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 39-48.
[68] N. Gupta, K. Lin, D. Roth, S. Singh, and M. Gardner, "Neural module networks for reasoning over text," arXiv preprint arXiv:1912.04971, 2019.
[69] S. I. Gallant, "Connectionist expert systems," Communications of the ACM, vol. 31, no. 2, pp. 152-169, 1988.
[70] S. I. Gallant and S. I. Gallant, Neural network learning and expert systems. MIT press, 1993.
[71] H. L. H. de Penning, A. S. d. Garcez, L. C. Lamb,
and J.-J. C. Meyer, "A neural-symbolic cognitive agent for online learning and reasoning," in Twenty-Second International Joint Conference on Artificial Intelligence, 2011.
[72] T. R. Besold, A. d. Garcez, S. Bader, H. Bowman, P. Domingos, P. Hitzler, K.-U. Kühnberger, L. C. Lamb, D. Lowd, P. M. V. Lima et al., "Neural-symbolic learning and reasoning: A survey and interpretation," arXiv preprint arXiv:1711.03902, 2017.
[73] A. d. Garcez, M. Gori, L. C. Lamb, L. Serafini, M. Spranger, and S. N. Tran, "Neural-symbolic computing: An effective methodology for principled integration of machine learning and reasoning," arXiv preprint arXiv:1905.06088, 2019.
[74] C. Liang, J. Berant, Q. Le, K. D. Forbus, and N. Lao, "Neural symbolic machines: Learning semantic parsers on freebase with weak supervision," arXiv preprint arXiv:1611.00020, 2016.
[75] W. Zhong, D. Tang, Z. Feng, N. Duan, M. Zhou, M. Gong, L. Shou, D. Jiang, J. Wang, and J. Yin, "Logicalfactchecker: Leveraging logical operations for fact checking with graph module network," arXiv preprint arXiv:2004.13659, 2020.
[76] Y. Huang, M. Fang, Y. Cao, L. Wang, and X. Liang, "Dagn: Discourse-aware graph network for logical reasoning," arXiv preprint arXiv:2103.14349, 2021.
[77] F. Arabshahi, J. Lee, M. Gawarecki, K. Mazaitis, A. Azaria, and T. Mitchell, "Conversational neurosymbolic commonsense reasoning," arXiv preprint arXiv:2006.10022, 2020.
[78] Y. Liu, M. Hildebrandt, M. Joblin, M. Ringsquandl, and V. Tresp, "Integrating logical rules into neural multihop reasoning for drug repurposing," arXiv preprint arXiv:2007.05292, 2020.
[79] Y. Liu, M. Hildebrandt, M. Joblin, M. Ringsquandl, R. Raissouni, and V. Tresp, "Neural multi-hop reasoning with logical rules on biomedical knowledge graphs," in European Semantic Web Conference. Springer, 2021, pp. 375-391.
[80] F. Moghimifar, L. Qu, Y. Zhuo, G. Haffari, and M. Baktashmotlagh, "Neural-symbolic commonsense reasoner with relation predictors," arXiv preprint arXiv:2105.06717, 2021.
[81] P. Clark, "Elementary school science and math tests as a driver for ai: Take the aristo challenge!" in AAAI. Citeseer, 2015, pp. 4019-4021.
[82] N. Arai, Artificial intelligence vs. Children who can't read textbooks. Toyo Keizai Shimpo, 2018.
[83] G. Lai, Q. Xie, H. Liu, Y. Yang, and E. Hovy, "RACE: Large-scale ReAding comprehension dataset from examinations," in Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Copenhagen, Denmark: Association for Computational Linguistics, Sep. 2017, pp. 785-794.
[84] V. Kumar, "Algorithms for constraint-satisfaction problems: A survey," AI magazine, vol. 13, no. 1, pp. 32-32, 1992.
[85] M. E. Peters, W. Ammar, C. Bhagavatula, and R. Power,</p>
<p>"Semi-supervised sequence tagging with bidirectional language models," arXiv preprint arXiv:1705.00108, 2017.
[86] T. N. Kipf and M. Welling, "Semi-supervised classification with graph convolutional networks," in International Conference on Learning Representations (ICLR), 2017.
[87] R. Bunel, M. Hausknecht, J. Devlin, R. Singh, and P. Kohli, "Leveraging grammar and reinforcement learning for neural program synthesis," arXiv preprint arXiv:1805.04276, 2018.
[88] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu, "Exploring the limits of transfer learning with a unified text-to-text transformer," arXiv preprint arXiv:1910.10683, 2019.
[89] V. Joshi, M. Peters, and M. Hopkins, "Extending a parser to distant domains using a few dozen partially annotated examples," in Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Melbourne, Australia: Association for Computational Linguistics, Jul. 2018, pp. 1190-1199.
[90] S. Russel, P. Norvig et al., Artificial intelligence: a modern approach. Pearson Education Limited, 2013.
[91] J.-K. Zhao, E. M. Rudnick, and J. H. Patel, "Static logic implication with application to redundancy identification," in Proceedings. 15th IEEE VLSI Test Symposium (Cat. No. 97TB100125). IEEE, 1997, pp. 288-293.
[92] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton, "A simple framework for contrastive learning of visual representations," in International conference on machine learning. PMLR, 2020, pp. 1597-1607.
[93] P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang, "Squad: 100,000+ questions for machine comprehension of text," arXiv preprint arXiv:1606.05250, 2016.
[94] M. Richardson, C. J. Burges, and E. Renshaw, "Mctest: A challenge dataset for the open-domain machine comprehension of text," in Proceedings of the 2013 conference on empirical methods in natural language processing, 2013, pp. 193-203.
[95] G. Lai, Q. Xie, H. Liu, Y. Yang, and E. H. Hovy, "RACE: large-scale reading comprehension dataset from examinations," in Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017, 2017, pp. 785-794.
[96] Z. Zhang, J. Yang, and H. Zhao, "Retrospective reader for machine reading comprehension," arXiv preprint arXiv:2001.09694, 2020.
[97] S. Min, M. Seo, and H. Hajishirzi, "Question answering through transfer learning from large fine-grained supervision data," arXiv preprint arXiv:1702.02171, 2017.
[98] D. Jin, S. Gao, J.-Y. Kao, T. Chung, and D. Hakkanitur, "Mmm: Multi-stage multi-task learning for multichoice reading comprehension," in Proceedings of the AAAI Conference on Artificial Intelligence, 2020, pp. 8010-8017.
[99] I. Beltagy, M. E. Peters, and A. Cohan, "Long-
former: The long-document transformer," arXiv preprint arXiv:2004.05150, 2020.
[100] Y. Lin, H. Ji, Z. Liu, and M. Sun, "Denoising distantly supervised open-domain question answering," in Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers, 2018, pp. 1736-1745.
[101] L. Pang, Y. Lan, J. Guo, J. Xu, L. Su, and X. Cheng, "HAS-QA: hierarchical answer spans model for opendomain question answering," in The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019, Honolulu, Hawaii, USA, January 27 February 1, 2019, 2019, pp. 6875-6882.
[102] "Test prep nerds." https://testprepnerds.com/lsat/ lsat-scores/ Accessed July 1, 2021.
[103] "Law school admission council." https://www.lsac. org/lsat-interpretive-guide/2019-2020 Accessed July 1, 2021.
[104] "Internet legal research group." https://www.ilrg.com/ rankings/law/index/1/desc/LSATLow Accessed July 1, 2021.
[105] C. Rawlings, W. Taylor, J. Nyakairu, J. Fox, and M. J. Sternberg, "Reasoning about protein topology using the logic programming language prolog," Journal of Molecular Graphics, vol. 3, no. 4, pp. 151-157, 1985.
[106] R. J. Boulton, "A tool to support formal reasoning about computer languages," in International Workshop on Tools and Algorithms for the Construction and Analysis of Systems. Springer, 1997, pp. 81-95.
[107] L. Fei-Fei, R. Fergus, and P. Perona, "One-shot learning of object categories," IEEE transactions on pattern analysis and machine intelligence, vol. 28, no. 4, pp. 594-611, 2006.
[108] W. Xiong, M. Yu, S. Chang, X. Guo, and W. Y. Wang, "One-shot relational learning for knowledge graphs," arXiv preprint arXiv:1808.09040, 2018.
[109] Z. Du, C. Zhou, M. Ding, H. Yang, and J. Tang, "Cognitive knowledge graph reasoning for one-shot relational learning," arXiv preprint arXiv:1906.05489, 2019.
[110] C. Bhagavatula, R. L. Bras, C. Malaviya, K. Sakaguchi, A. Holtzman, H. Rashkin, D. Downey, S. W.-t. Yih, and Y. Choi, "Abductive commonsense reasoning," arXiv preprint arXiv:1908.05739, 2019.
[111] W. Starr, "Counterfactuals," 2019.
[112] L. Qin, A. Bosselut, A. Holtzman, C. Bhagavatula, E. Clark, and Y. Choi, "Counterfactual story reasoning and generation," arXiv preprint arXiv:1909.04076, 2019.
[113] P. Bartha, "Analogy and analogical reasoning," 2013.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>Work is done during internship at Lanboat. Corresponding author: Ming Zhou, Zhongyu Wei.</p>
<p>Siyuan Wang and Zhongyu Wei are with the School of Data Science, Fudan University, Shanghai 200433, China. And Zhongyu Wei is also with the Research Institute of Intelligent and Complex Systems, Fudan University, Shanghai 200433, China (email: wangsy18@fudan.edu.cn; zywei@fudan.edu.cn).</p>
<p>Zhongkun Liu and Zhumin Chen are with the School of Computer Science and Technology, Shandong University, Qingdao 266237, China (email: liuzhongkun@mail.sdu.edu.cn; chenzhumin@mail.sdu.edu.cn)</p>
<p>Wanjun Zhong is with the School of Computer Science and Engineering, Sun Yat-Sen University, Guangzhou 510275, China (email: zhongwj25@mail2.sysu.edu.cn).</p>
<p>Ming Zhou is with the Sinovation Ventures, Beijing 100080, China (email: zhouming@chuangxin.com).</p>
<p>Nan Duan is with Microsoft Research, Beijing 100080, China (email: nanduan@microsoft.com).&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{1}$ https://www:lsac:org/lsat/.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>