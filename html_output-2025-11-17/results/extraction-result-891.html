<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-891 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-891</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-891</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-21.html">extraction-schema-21</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <p><strong>Paper ID:</strong> paper-e8443666cf927806576ace54b9351af72a1d2d9b</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/e8443666cf927806576ace54b9351af72a1d2d9b" target="_blank">Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Learning Representations</p>
                <p><strong>Paper TL;DR:</strong> A neural machine-reading model that constructs dynamic knowledge graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities to present some evidence that the model’s knowledge graphs help it to impose commonsense constraints on its predictions.</p>
                <p><strong>Paper Abstract:</strong> We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension (MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans. The explicit, structured, and evolving knowledge graph representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically. On two comprehension tasks from the recently proposed PROPARA dataset (Dalvi et al., 2018), our model achieves state-of-the-art results. We further show that our model is competitive on the RECIPES dataset (Kiddon et al., 2015), suggesting it may be generally applicable. We present some evidence that the model’s knowledge graphs help it to impose commonsense constraints on its predictions.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e891.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e891.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KG-MRC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>KG-MRC (Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural machine-reading model that constructs recurrent, dynamic bipartite knowledge graphs (entities and their location nodes) while reading procedural text, using an MRC component to extract location spans which are integrated into the graph and used to condition further extraction and downstream QA.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>KG-MRC</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>KG-MRC associates each participant entity with an entity node e_{i,t} and a corresponding location node λ_{i,t} in a bipartite graph G_t. It uses a modified DrQA span-predictive MRC module conditioned on the entity node embedding e_{i,t-1} to query the paragraph prefix for the entity's current location; the returned span is encoded as ψ_{i,t}. Soft co-reference across time is resolved by attention of ψ_{i,t} against previous location node matrix Λ_{t-1}, producing a gated interpolation λ'_{i,t}=g ψ_{i,t} + (1-g) ψ'_{i,t}; within-time-step co-reference is resolved by self-attention pooling (forming adjacency U_t). Graph updates stack L recurrent layers: for each layer an LSTM composes [e_{i,t}^{l-1}; λ_{i,t}^{l-1}; h_{i,t-1}^l] producing h_{i,t}^l which is added residually to entity and location nodes, followed by co-reference pooling λ_{i,t} = ̃Λ_t^l u_{i,t}. The updated entity embeddings e_{i,t} condition subsequent MRC queries. Training is end-to-end with teacher-forcing on correct spans for location nodes; word embeddings are initialized with FastText.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Procedural text (ProPara dataset) and recipe paragraphs (RECIPES dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Paragraphs describing scientific or instructional processes; KG-MRC processes the paragraph incrementally by reading prefixes up to sentence s_t at each time step t. Challenges: entity states are arbitrary text spans (variable surface forms), entities may be created/destroyed, aliasing of mentions, small training data, and the need for global consistency across time steps.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>Explicit recurrent dynamic knowledge graph: a bipartite set of learned vector nodes for entities (e_{i,t}) and per-entity location nodes (λ_{i,t}), plus a co-reference adjacency matrix U_t. The model maintains history via LSTM hidden summaries h_{i,t}^l in stacked recurrent graph layers, residual updates to node embeddings, and soft-attention-based co-reference linking across time and within a time step.</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>At each step the MRC module returns a span encoded ψ_{i,t}. Cross-time co-reference attends ψ_{i,t} to previous location nodes Λ_{t-1} to compute ψ'_{i,t}; a gate g interpolates between ψ and ψ' producing λ'_{i,t}. Within-step self-attention pools λ' vectors to tie duplicates: λ_{i,t} = Λ'_t u_{i,t}. Then recurrent graph LSTM layers compose [e_{i,t}^{l-1}; λ_{i,t}^{l-1}; h_{i,t-1}^l] to produce h_{i,t}^l which is added residually to both entity and location nodes; co-reference pooling using U_t is applied to location nodes. (Training uses teacher-forcing updates of location nodes from gold spans.)</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>No explicit planning algorithm or search-based planner; the model is a learned, end-to-end recurrent MRC + graph updater that conditions future extraction on the constructed belief graph (i.e., learned policy-like behavior but not a symbolic planner).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>KG-MRC shows that conditioning an MRC extractor on an explicit, recurrent knowledge graph (and integrating extractor spans into that graph via soft co-reference and gated updates) improves tracking of entity states in partially observable procedural text, reduces commonsense-constraint violations, and yields state-of-the-art results on ProPara and competitive performance on RECIPES. The model does not use external planning tools or spatial navigators; instead it maintains an internal belief graph and uses it to guide further extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e891.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e891.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DrQA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DrQA (Document Reader / Question Answering)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A span-extractive machine reading comprehension model that encodes passage and question with RNNs and predicts start/end token scores for answer spans; KG-MRC uses a modified DrQA as its MRC module, conditioning question representation on entity embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Reading wikipedia to answer open-domain questions.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>DrQA (as MRC component)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Multi-layer RNN encoders for passage and question, self-attention matching, and output layer producing start/end scores for span answers. In KG-MRC the question representation is concatenated with the entity node embedding e_{i,t-1} and passed through an MLP to yield an entity-dependent query for span prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Procedural text paragraphs (as used inside KG-MRC on ProPara / RECIPES prefixes)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Operates on paragraph prefixes at each timestep to extract the current location span for a queried entity; the environment is temporally partially observable (future sentences not yet read).</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td>text spans</td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>None internally (DrQA is an extractor). In KG-MRC its span outputs ψ_{i,t} are consumed into the graph belief state.</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>DrQA outputs a span which is encoded into ψ_{i,t}; KG-MRC uses ψ_{i,t} in attention/gating with previous location nodes and in graph LSTM updates (see KG-MRC belief_update_description).</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>No planning; supervised extraction</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Conditioning an MRC extractor on evolving entity embeddings (from a dynamic graph) improves span extraction for changing entity states compared to unconditioned extraction on paragraph prefixes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e891.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e891.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EntNet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recurrent Entity Networks (EntNet)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A memory-augmented neural model that maintains dynamic hidden-state memory slots (which can be tied to entities) and updates them with gated mechanisms at each step to track world state.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Tracking the world state with recurrent entity networks.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>EntNet</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>EntNet uses a set of memory slots updated via gated recurrent mechanisms; slots can represent entities and are updated when relevant sentences are processed. It returns answers via classification rather than span prediction and lacks explicit separate state (e.g., location) node embeddings or explicit co-reference resolution.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>bAbI synthetic tasks (and used as a baseline on ProPara comparisons)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Originally evaluated on synthetic story-based QA (bAbI); when applied to real procedural text (ProPara), EntNet struggles due to richer language and span-based state representations required.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>Dynamic recurrent memory slots (hidden vectors) with gated updates per timestep</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>Gated updates to memory slots driven by incoming sentence encodings; no explicit span-to-node integration or soft co-reference mechanism described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>Learned memory updates (no explicit planning/search)</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>EntNet provides a dynamic memory mechanism for entity tracking but lacks explicit state nodes and co-reference handling, which limits performance on span-based procedural text tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e891.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e891.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PROSTRUCT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PROSTRUCT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural structured-prediction model that injects hard and soft commonsense constraints to improve global consistency when predicting entity state changes from procedural text.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Reasoning about actions and state changes by injecting commonsense knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>PROSTRUCT</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A structured-prediction architecture that encodes sentences and predicts state-change events while incorporating manually specified commonsense constraints (hard and soft) to discourage globally inconsistent predictions (e.g., entity cannot be moved before creation).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>ProPara (document-level task)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Procedural text where global consistency across time is important (document-level), partially observable in the sense of sequential reading but PROSTRUCT enforces global constraints across the whole document.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>Structured predictions with constraints; uses previous-step probability distributions over paragraph tokens to capture previous states</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>Model predictions are adjusted via injection of commonsense constraints to enforce feasibility of state sequences; implementation details are in the cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>Constraint-steered prediction (not explicit planning/search)</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Explicit commonsense constraints can reduce globally inconsistent state-change predictions; KG-MRC empirically learns similar constraints from data using its recurrent graph without hand-engineered constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e891.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e891.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NPN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Process Networks (NPN)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A model that learns to parameterize actions and compose them with entity representations to simulate action dynamics for procedural text understanding.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Simulating action dynamics with neural process networks.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Neural Process Networks (NPN)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>NPN explicitly parameterizes action operators and composes them with entity vectors to model state changes (e.g., affecting location, composition) in procedural text; used as a baseline on RECIPES dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>RECIPES dataset (and other procedural text)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Cooking recipe paragraphs with annotated states (location, shape, composition). Challenges include many possible location classes and varying textual realizations.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>Action-parameterized entity state representations composed over time</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>Entity vectors are updated via learned action operators applied when actions are inferred from text; not via an external tool.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>Learned composition of actions with entity representations (no explicit planner)</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>NPN models dynamics by composing learned action operators with entities; KG-MRC approaches state tracking differently via explicit location span extraction and a recurrent knowledge graph.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Tracking the world state with recurrent entity networks. <em>(Rating: 2)</em></li>
                <li>Tracking state changes in procedural text: a challenge dataset and models for process paragraph comprehension. <em>(Rating: 2)</em></li>
                <li>Reasoning about actions and state changes by injecting commonsense knowledge. <em>(Rating: 2)</em></li>
                <li>Simulating action dynamics with neural process networks. <em>(Rating: 2)</em></li>
                <li>Query-reduction networks for question answering. <em>(Rating: 1)</em></li>
                <li>Reading wikipedia to answer open-domain questions. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-891",
    "paper_id": "paper-e8443666cf927806576ace54b9351af72a1d2d9b",
    "extraction_schema_id": "extraction-schema-21",
    "extracted_data": [
        {
            "name_short": "KG-MRC",
            "name_full": "KG-MRC (Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension)",
            "brief_description": "A neural machine-reading model that constructs recurrent, dynamic bipartite knowledge graphs (entities and their location nodes) while reading procedural text, using an MRC component to extract location spans which are integrated into the graph and used to condition further extraction and downstream QA.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "KG-MRC",
            "agent_description": "KG-MRC associates each participant entity with an entity node e_{i,t} and a corresponding location node λ_{i,t} in a bipartite graph G_t. It uses a modified DrQA span-predictive MRC module conditioned on the entity node embedding e_{i,t-1} to query the paragraph prefix for the entity's current location; the returned span is encoded as ψ_{i,t}. Soft co-reference across time is resolved by attention of ψ_{i,t} against previous location node matrix Λ_{t-1}, producing a gated interpolation λ'_{i,t}=g ψ_{i,t} + (1-g) ψ'_{i,t}; within-time-step co-reference is resolved by self-attention pooling (forming adjacency U_t). Graph updates stack L recurrent layers: for each layer an LSTM composes [e_{i,t}^{l-1}; λ_{i,t}^{l-1}; h_{i,t-1}^l] producing h_{i,t}^l which is added residually to entity and location nodes, followed by co-reference pooling λ_{i,t} = ̃Λ_t^l u_{i,t}. The updated entity embeddings e_{i,t} condition subsequent MRC queries. Training is end-to-end with teacher-forcing on correct spans for location nodes; word embeddings are initialized with FastText.",
            "environment_name": "Procedural text (ProPara dataset) and recipe paragraphs (RECIPES dataset)",
            "environment_description": "Paragraphs describing scientific or instructional processes; KG-MRC processes the paragraph incrementally by reading prefixes up to sentence s_t at each time step t. Challenges: entity states are arbitrary text spans (variable surface forms), entities may be created/destroyed, aliasing of mentions, small training data, and the need for global consistency across time steps.",
            "is_partially_observable": true,
            "external_tools_used": null,
            "tool_output_types": null,
            "belief_state_mechanism": "Explicit recurrent dynamic knowledge graph: a bipartite set of learned vector nodes for entities (e_{i,t}) and per-entity location nodes (λ_{i,t}), plus a co-reference adjacency matrix U_t. The model maintains history via LSTM hidden summaries h_{i,t}^l in stacked recurrent graph layers, residual updates to node embeddings, and soft-attention-based co-reference linking across time and within a time step.",
            "incorporates_tool_outputs_in_belief": true,
            "belief_update_description": "At each step the MRC module returns a span encoded ψ_{i,t}. Cross-time co-reference attends ψ_{i,t} to previous location nodes Λ_{t-1} to compute ψ'_{i,t}; a gate g interpolates between ψ and ψ' producing λ'_{i,t}. Within-step self-attention pools λ' vectors to tie duplicates: λ_{i,t} = Λ'_t u_{i,t}. Then recurrent graph LSTM layers compose [e_{i,t}^{l-1}; λ_{i,t}^{l-1}; h_{i,t-1}^l] to produce h_{i,t}^l which is added residually to both entity and location nodes; co-reference pooling using U_t is applied to location nodes. (Training uses teacher-forcing updates of location nodes from gold spans.)",
            "planning_approach": "No explicit planning algorithm or search-based planner; the model is a learned, end-to-end recurrent MRC + graph updater that conditions future extraction on the constructed belief graph (i.e., learned policy-like behavior but not a symbolic planner).",
            "uses_shortest_path_planning": false,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": false,
            "key_findings": "KG-MRC shows that conditioning an MRC extractor on an explicit, recurrent knowledge graph (and integrating extractor spans into that graph via soft co-reference and gated updates) improves tracking of entity states in partially observable procedural text, reduces commonsense-constraint violations, and yields state-of-the-art results on ProPara and competitive performance on RECIPES. The model does not use external planning tools or spatial navigators; instead it maintains an internal belief graph and uses it to guide further extraction.",
            "uuid": "e891.0",
            "source_info": {
                "paper_title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension",
                "publication_date_yy_mm": "2018-09"
            }
        },
        {
            "name_short": "DrQA",
            "name_full": "DrQA (Document Reader / Question Answering)",
            "brief_description": "A span-extractive machine reading comprehension model that encodes passage and question with RNNs and predicts start/end token scores for answer spans; KG-MRC uses a modified DrQA as its MRC module, conditioning question representation on entity embeddings.",
            "citation_title": "Reading wikipedia to answer open-domain questions.",
            "mention_or_use": "use",
            "agent_name": "DrQA (as MRC component)",
            "agent_description": "Multi-layer RNN encoders for passage and question, self-attention matching, and output layer producing start/end scores for span answers. In KG-MRC the question representation is concatenated with the entity node embedding e_{i,t-1} and passed through an MLP to yield an entity-dependent query for span prediction.",
            "environment_name": "Procedural text paragraphs (as used inside KG-MRC on ProPara / RECIPES prefixes)",
            "environment_description": "Operates on paragraph prefixes at each timestep to extract the current location span for a queried entity; the environment is temporally partially observable (future sentences not yet read).",
            "is_partially_observable": true,
            "external_tools_used": null,
            "tool_output_types": "text spans",
            "belief_state_mechanism": "None internally (DrQA is an extractor). In KG-MRC its span outputs ψ_{i,t} are consumed into the graph belief state.",
            "incorporates_tool_outputs_in_belief": true,
            "belief_update_description": "DrQA outputs a span which is encoded into ψ_{i,t}; KG-MRC uses ψ_{i,t} in attention/gating with previous location nodes and in graph LSTM updates (see KG-MRC belief_update_description).",
            "planning_approach": "No planning; supervised extraction",
            "uses_shortest_path_planning": false,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": false,
            "key_findings": "Conditioning an MRC extractor on evolving entity embeddings (from a dynamic graph) improves span extraction for changing entity states compared to unconditioned extraction on paragraph prefixes.",
            "uuid": "e891.1",
            "source_info": {
                "paper_title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension",
                "publication_date_yy_mm": "2018-09"
            }
        },
        {
            "name_short": "EntNet",
            "name_full": "Recurrent Entity Networks (EntNet)",
            "brief_description": "A memory-augmented neural model that maintains dynamic hidden-state memory slots (which can be tied to entities) and updates them with gated mechanisms at each step to track world state.",
            "citation_title": "Tracking the world state with recurrent entity networks.",
            "mention_or_use": "mention",
            "agent_name": "EntNet",
            "agent_description": "EntNet uses a set of memory slots updated via gated recurrent mechanisms; slots can represent entities and are updated when relevant sentences are processed. It returns answers via classification rather than span prediction and lacks explicit separate state (e.g., location) node embeddings or explicit co-reference resolution.",
            "environment_name": "bAbI synthetic tasks (and used as a baseline on ProPara comparisons)",
            "environment_description": "Originally evaluated on synthetic story-based QA (bAbI); when applied to real procedural text (ProPara), EntNet struggles due to richer language and span-based state representations required.",
            "is_partially_observable": null,
            "external_tools_used": null,
            "tool_output_types": null,
            "belief_state_mechanism": "Dynamic recurrent memory slots (hidden vectors) with gated updates per timestep",
            "incorporates_tool_outputs_in_belief": false,
            "belief_update_description": "Gated updates to memory slots driven by incoming sentence encodings; no explicit span-to-node integration or soft co-reference mechanism described in this paper.",
            "planning_approach": "Learned memory updates (no explicit planning/search)",
            "uses_shortest_path_planning": false,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": null,
            "key_findings": "EntNet provides a dynamic memory mechanism for entity tracking but lacks explicit state nodes and co-reference handling, which limits performance on span-based procedural text tasks.",
            "uuid": "e891.2",
            "source_info": {
                "paper_title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension",
                "publication_date_yy_mm": "2018-09"
            }
        },
        {
            "name_short": "PROSTRUCT",
            "name_full": "PROSTRUCT",
            "brief_description": "A neural structured-prediction model that injects hard and soft commonsense constraints to improve global consistency when predicting entity state changes from procedural text.",
            "citation_title": "Reasoning about actions and state changes by injecting commonsense knowledge.",
            "mention_or_use": "mention",
            "agent_name": "PROSTRUCT",
            "agent_description": "A structured-prediction architecture that encodes sentences and predicts state-change events while incorporating manually specified commonsense constraints (hard and soft) to discourage globally inconsistent predictions (e.g., entity cannot be moved before creation).",
            "environment_name": "ProPara (document-level task)",
            "environment_description": "Procedural text where global consistency across time is important (document-level), partially observable in the sense of sequential reading but PROSTRUCT enforces global constraints across the whole document.",
            "is_partially_observable": true,
            "external_tools_used": null,
            "tool_output_types": null,
            "belief_state_mechanism": "Structured predictions with constraints; uses previous-step probability distributions over paragraph tokens to capture previous states",
            "incorporates_tool_outputs_in_belief": null,
            "belief_update_description": "Model predictions are adjusted via injection of commonsense constraints to enforce feasibility of state sequences; implementation details are in the cited work.",
            "planning_approach": "Constraint-steered prediction (not explicit planning/search)",
            "uses_shortest_path_planning": false,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": null,
            "key_findings": "Explicit commonsense constraints can reduce globally inconsistent state-change predictions; KG-MRC empirically learns similar constraints from data using its recurrent graph without hand-engineered constraints.",
            "uuid": "e891.3",
            "source_info": {
                "paper_title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension",
                "publication_date_yy_mm": "2018-09"
            }
        },
        {
            "name_short": "NPN",
            "name_full": "Neural Process Networks (NPN)",
            "brief_description": "A model that learns to parameterize actions and compose them with entity representations to simulate action dynamics for procedural text understanding.",
            "citation_title": "Simulating action dynamics with neural process networks.",
            "mention_or_use": "mention",
            "agent_name": "Neural Process Networks (NPN)",
            "agent_description": "NPN explicitly parameterizes action operators and composes them with entity vectors to model state changes (e.g., affecting location, composition) in procedural text; used as a baseline on RECIPES dataset.",
            "environment_name": "RECIPES dataset (and other procedural text)",
            "environment_description": "Cooking recipe paragraphs with annotated states (location, shape, composition). Challenges include many possible location classes and varying textual realizations.",
            "is_partially_observable": null,
            "external_tools_used": null,
            "tool_output_types": null,
            "belief_state_mechanism": "Action-parameterized entity state representations composed over time",
            "incorporates_tool_outputs_in_belief": false,
            "belief_update_description": "Entity vectors are updated via learned action operators applied when actions are inferred from text; not via an external tool.",
            "planning_approach": "Learned composition of actions with entity representations (no explicit planner)",
            "uses_shortest_path_planning": false,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": null,
            "key_findings": "NPN models dynamics by composing learned action operators with entities; KG-MRC approaches state tracking differently via explicit location span extraction and a recurrent knowledge graph.",
            "uuid": "e891.4",
            "source_info": {
                "paper_title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension",
                "publication_date_yy_mm": "2018-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Tracking the world state with recurrent entity networks.",
            "rating": 2
        },
        {
            "paper_title": "Tracking state changes in procedural text: a challenge dataset and models for process paragraph comprehension.",
            "rating": 2
        },
        {
            "paper_title": "Reasoning about actions and state changes by injecting commonsense knowledge.",
            "rating": 2
        },
        {
            "paper_title": "Simulating action dynamics with neural process networks.",
            "rating": 2
        },
        {
            "paper_title": "Query-reduction networks for question answering.",
            "rating": 1
        },
        {
            "paper_title": "Reading wikipedia to answer open-domain questions.",
            "rating": 1
        }
    ],
    "cost": 0.01578325,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension</h1>
<p>Rajarshi Das ${ }^{11}$, Tsendsuren Munkhdalai ${ }^{2}$, Xingdi Yuan ${ }^{2}$, Adam Trischler ${ }^{2}$, Andrew McCallum ${ }^{1}$<br>${ }^{1}$ College of Information and Computer Sciences<br>University of Massachusetts, Amherst<br>{rajarshi, mccallum}@cs.umass.edu<br>${ }^{2}$ Microsoft Research Montréal<br>Montréal, Québec, Canada<br>{tsendsuren.munkhdalai, eric.yuan, adam.trischler}@microsoft.com</p>
<h4>Abstract</h4>
<p>We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension (MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans. The explicit, structured, and evolving knowledge graph representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically. On two comprehension tasks from the recently proposed ProPara dataset (Dalvi et al., 2018), our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset (Kiddon et al., 2015), suggesting it may be generally applicable. We present some evidence that the model's knowledge graphs help it to impose commonsense constraints on its predictions.</p>
<h2>1 INTRODUCTION</h2>
<p>Automatically building knowledge graphs (KGs) from text is a long-standing goal in artificial intelligence research. KGs organize raw information in a structured form, capturing relationships (labeled edges) between entities (nodes). They enable automated reasoning, e.g., the ability to infer unobserved facts from observed evidence and to make logical "hops," and render data amenable to decades of work in graph analysis.
There exists a profusion of text that describes complex, dynamic worlds in which entities' relationships evolve through time. This includes news articles, scientific manuals, and procedural text (e.g., recipes, how-to guides, and so on). Building KGs from this data would not only help us to study the changing relations among participant entities, but also to make implicit information more explicit. For example, the graphs at each step in Figure 1 help us to infer that the new entity mixture is created in the leaf, since the previous location of its participant entities (light, $\mathrm{CO}_{2}$, water) was leaf - even though this is never stated in the text.</p>
<p>This paper introduces a neural machine-reading model, KG-MRC, that (i) explicitly constructs dynamic knowledge graphs to track state changes in procedural text and (ii) conditions on its own constructed knowledge graphs to improve downstream question answering on the text. Our dynamic graph model is recurrent, that is, the graph at each time step depends on the state of the graph at the previous time step. The constructed graphs are parameterized by real-valued embeddings for each node that change through time.</p>
<p>In text, entities and their states (e.g., their locations) are given by spans of words. Because of the variety of natural language, the same entity/state may be described with several surface forms. To address the challenge of entity/state recognition, our model uses a machine reading comprehension</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Snapshot of the knowledge graphs created by our model before and after reading the sentence in boldface. Since the KG explicitly stores the current location of light, $\mathrm{CO}<em 2="2">{2}$, and water as leaf, the model can infer that mixture is formed in the leaf even though this is not explicitly stated. The three participant entities also get destroyed in the process, which is captured in the graph by pointing to a special Nowhere node.
(MRC) mechanism (Seo et al., 2017a; Xiong et al., 2017; Chen et al., 2017; Yu et al., 2018, inter alia), which queries for entities and their states at each time step. We leverage MRC mechanisms because they have proven adept at extracting text spans that answer entity-centric questions (Levy et al., 2017). However, such models are static by design, returning the same answer for the same query and context. Since we expect answers about entity states to change over the course of the text, our model's MRC component conditions on the evolving graph at the current time step (this graph captures the instantaneous states of entities).
To address the challenge of aliased text mentions, our model performs soft co-reference as it updates the graph. Instead of adding an alias node, like the leaf or leaves as aliases for leaf, the graph update procedure soft-attends (Bahdanau et al., 2014) over all nodes at the previous time step and performs a gated update (Cho et al., 2014; Chung et al., 2014) of the current embeddings with the previous ones. This ensures that state information is preserved and propagated across time steps. Soft coreference can also handle the case that entity states do not change across time steps, by applying a near-null update to the existing state node rather than duplicating it.
At each time step, after the graph has been updated with the (possibly) new states of all entities, our model updates each entity representation with information about its state. The updated information about each individual entity is further propagated to all other entities (§ 4.4). This enables the model to recognize, for example, that entities are present in the same location (e.g., light, $\mathrm{CO}</em>$ and water in Figure 1). Thus, our model can use the information encoded in its internal knowledge graphs for a more comprehensive understanding of the text. We will demonstrate this experimentally by tackling comprehension tasks from the the recently released PROPARA and RECIPES datasets.
Our complete machine reading model, which both builds and leverages dynamic knowledge graphs, can be trained end-to-end using only the loss from its MRC component; i.e., the negative loglikelihood that the MRC component assigns to the span that correctly describes each entity's queried state. We evaluate our model (KG-MRC) on the above two ProPara tasks and find that the same model significantly outperforms the previous state of the art. For example, KG-MRC obtains a $9.92 \%$ relative improvement on the hard task of predicting at which time-step an entity moves. Similarly on the latter task, KG-MRC obtains a $5.7 \%$ relative improvement over PROSTRUCT and $41 \%$ relative improvement over other entity-centric models such as ENTNET (Henaff et al., 2017). On the RECIPES dataset, the same model obtains competitive performance.</p>
<h1>2 Related Work</h1>
<p>There are few datasets that address the challenging problem of tracking entity state changes. The bAbI dataset (Weston et al., 2015) includes questions about movement of entities; however, its language is generated synthetically over a small lexicon, and hence models trained on bAbI often do not generalize well when tested on real-world data. For example, state-of-the-art models like EntNet (Henaff et al., 2017) and Query Reduction Networks (Seo et al., 2017b) fail to perform well on ProPara.</p>
<p>ProRead (Berant et al., 2014) introduced the ProcesSBank dataset, which contains paragraphs of procedural text as in ProPara. However, this earlier task involves mining arguments and rela-</p>
<p>tions from events, not tracking the dynamic state changes of entities. The model that Berant et al. (2014) propose builds small knowledge graphs from the text, but they are not dynamic in nature. The model also relies on densely annotated process structure for training, demanding curation by domain experts. On the other hand, our model, KG-MRC, learns to build dynamic KGs just from annotations of text spans, which are much easier to collect.
For the sentence-level ProPara task they propose, Dalvi et al. (2018) introduce two models: ProLocal and ProGlobal. ProLocal makes local predictions about entities by considering just the current sentence. This is followed by some heuristic/rule-based answer propagation. PROGlobal considers a broader context (previous sentences) and also includes the previous state of entities by considering the probability distribution over paragraph tokens in the previous step. Tandon et al. (2018) recently proposed a neural structured-prediction model, (PROSTRUCT), where hard and soft common-sense constraints are injected to steer their model away from globally incoherent predictions. We evaluate KG-MRC on the two ProPara tasks proposed by Dalvi et al. (2018) and Tandon et al. (2018), respectively, and find that our single model outperforms each of the above models on their respective tasks of focus.
ENTNET (Henaff et al., 2017) and query reduction networks (QRN) (Seo et al., 2017b) are two state-of-the-art entity-centric models for the bAbI dataset. ENTNET maintains a dynamic memory of hidden states with a gated update to the memory slots at each step. Memory slots can be tied to specific entities, but unlike our model, ENTNET does not maintain separate embeddings of individual states (e.g., current locations); it also does not perform explicit co-reference updates. QRN refines the query vector as it processes each subsequent sentence until the query points to the answer, but does not maintain explicit representations of entity states. Neural Process Networks (NPN) (Bosselut et al., 2018) learn to understand procedural text by explicitly parameterizing actions and composing them with entities. These three models return an answer by predicting a vocabulary item in a multi-class classification setup, while in our work we predict spans of text directly from the paragraph.
MRC models have been used previously for extracting the argument of knowledge base (KB) relations, by associating one or more natural language questions with each relation (querification). These models have been shown to perform well in a zero-shot setting, i.e., for a previously unseen relation type (Levy et al., 2017), and for extracting entities that belong to non-standard types (Roth et al., 2018). These recent positive results motivate our use of an MRC component in KG-MRC.</p>
<h1>3 Data \&amp; Tasks</h1>
<p>We evaluate KG-MRC on the recently released ProPara dataset (Dalvi et al., 2018), which comprises procedural text about scientific processes. The location states of participant entities at each time step (sentence) in these processes are labeled by human annotators, and the names of participant entities are given. As an example, for a process describing photosynthesis, the participant entities provided are: light, $\mathrm{CO}_{2}$, water, mixture and glucose. Although participant entities are thus known a priori, the location of an entity could be any arbitrary span in the process text. This makes the task of determining and tracking an entity's changing location quite challenging. It should also be noted that the dataset does not provide information on whether a particular entity is an input to or output of a process. Not all entities exist from the beginning of the process (e.g. glucose) and not all exist at the end (e.g. water). Table 1 shows statistics of ProPara. As can be seen, the training set is small, which makes learning challenging.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"># para</th>
<th style="text-align: right;">488</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"># train/#dev/#test</td>
<td style="text-align: right;">$391 / 43 / 54$</td>
</tr>
<tr>
<td style="text-align: left;">avg. # entities</td>
<td style="text-align: right;">4.17</td>
</tr>
<tr>
<td style="text-align: left;">avg. # sentences</td>
<td style="text-align: right;">6.7</td>
</tr>
<tr>
<td style="text-align: left;"># sentences</td>
<td style="text-align: right;">3.3 K</td>
</tr>
</tbody>
</table>
<p>Table 1: Statistics of ProPara.
Along with the dataset, Dalvi et al. (2018) introduce the task of tracking state changes at a fine-grained sentence level. To solve this task, a model must answer three categories of questions ( 10 questions in total) about an entity $E$ : (1) Is $E$ created, (destroyed, moved) in the process? (2) When (step #) is $E$ created, (destroyed, moved)? (3) Where is $E$ created, (destroyed, moved from/to)? Cat. 1 asks boolean questions about the existence and movement of entities. Cat. 2 and 3 are harder tasks, as the model must correctly predict the step number at which a state changes as well as the correct locations (text spans) of entities at each step.</p>
<p>Tandon et al. (2018) introduce a second task on the PROPARA dataset that measures state changes at a coarser process level. To solve this task, a model must correctly answer the following four types of questions: (1) What are the inputs to the process? (2) What are the outputs of the process? (3) What conversions occur, when and where? (4) What movements occur, when and where? Inputs to a process are defined as entities that exist at the start of the process but not at the end and outputs are entities that exist at the end of the process and were created during it. A conversion is when some entities are created and others destroyed, while movements refer to changes in location. Dalvi et al. (2018) and Tandon et al. (2018) propose different models to solve each of these tasks separately, whereas we evaluate the same model, KG-MRC, on both tasks.</p>
<p>Bosselut et al. (2018) recently released the RECIPES dataset, which has various annotated states (e.g. shape, composition, location, etc.) for ingredients in cooking recipes. We further test KG-MRC on the location task to align with our ProPara experiments. This is arguably the dataset's hardest task, since it requires classification over more than 260 classes while the others have a much smaller label space (maximum of 4). Note that rather than treating this problem as classification over a fixed lexicon as in previous models, our model aims to find the location-describing span of text in the recipe paragraph.</p>
<h1>4 MODEL</h1>
<p>KG-MRC tracks the temporal state change of entities in procedural text. Naturally, the model is entity-centric (Henaff et al., 2017; Bansal et al., 2017): it associates each participant entity of the procedural text with a unique node and embedding in its internal graph. KG-MRC is also equipped with a neural machine reading comprehension model which is queried about the current location of each entity.</p>
<p>At a high level, our model operates as follows. We summarize some important notation in Table 2. KG-MRC processes a paragraph $p=\left{w_{j}\right}<em t="t">{j=1}^{P}$, of $P$ words, by incrementally reading prefixes of the paragraph up to and including sentence $s</em>\right}}$ at each time step $t$. This continues until it has seen all sentences $\left{s_{t<em i_="i," t-1="t-1">{t=1}^{T}$ of the paragraph. At each time step (sentence) $t$, we engage the MRC module to query for the state of each participant entity (participants are known in PROPARA a priori). The query process conditions on both the input text and the target entity's node embedding, $e</em>$ from the previous time step.}$, where the latter comes from the graph at the previous time step. The MRC module returns an answer span describing the entity's current location at $t$; we encode this text span as the vector $\psi_{i, t}$. Conditioning on the span vectors $\psi_{i, t}$, the model constructs the graph $G_{t}$ by updating $G_{t-1</p>
<p>The model's knowledge graphs $G_{t}$ are bipartite, having two sets of nodes with implied connections between them: $G_{t}=\left{e_{i, t}, \lambda_{i, t}\right}$. Each node denotes either an entity $\left(e_{i, t}\right)$ or that entity's corresponding location $\left(\lambda_{i, t}\right)$, and is associated with a real-valued vector. We use $e_{i, t}$ and $\lambda_{i, t}$ to denote nodes in the graph and their vector representations interchangeably. The bipartite graphs $G_{t}$ have only one (implicit) relation type, the current location, though we plan to extend this in future work. To derive $G_{t}$ from its previous iterate $G_{t-1}$, we combine both hard and soft graph updates. The update to an entity's node representation with new location information arises from a hard decision made by the MRC model, whereas co-reference between entities across time steps is resolved with soft attention. We now describe all components of the model in detail.</p>
<h3>4.1 EnTity and SpAN REPRESENTATIONS</h3>
<p>In the PROPARA dataset, entities appear in the paragraph text. ${ }^{1}$ Therefore, we derive the initial entity representations from contextualized hidden vectors by encoding the paragraph with a bi-directional LSTM (Hochreiter \&amp; Schmidhuber, 1997). This choice has the added advantage that initial entity representations share information through context, unlike in previous models (Henaff et al., 2017; Das et al., 2017; Bansal et al., 2017). Entities in the dataset can be multi-word expressions (e.g., electric oven). To obtain a single representation, we concatenate the contextualized hidden vectors corresponding to the start and end span tokens and take a linear projection. i.e., if the mention of entity $i$ occurs between the $j$-th and $j+k$-th position, then the initial entity representation $v_{i}$ is computed as $v_{i}=W_{e}\left[c_{j} ; c_{j+k}\right]+b_{e}$. We use $i$ to index an entity and its corresponding location,</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;">Notation</th>
<th style="text-align: left;">Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">$N \in \mathbb{N}$</td>
<td style="text-align: left;">Number of participant entities in the process.</td>
</tr>
<tr>
<td style="text-align: left;">$\mathrm{v}_{i} \in \mathbb{R}^{d}$</td>
<td style="text-align: left;">Initial entity representation, derived from the text, for the $i$-th entity at time $t=0(\S 4.1)$</td>
</tr>
<tr>
<td style="text-align: left;">$e_{i, t} \in \mathbb{R}^{d}$</td>
<td style="text-align: left;">Entity node representation for the $i$-th entity at time $t$, in the graph $G_{t}(\S 4.4)$</td>
</tr>
<tr>
<td style="text-align: left;">$\psi_{i, t} \in \mathbb{R}^{d}$</td>
<td style="text-align: left;">Location representation derived from the text for the $i$-th entity at time $t(\S 4.1)$</td>
</tr>
<tr>
<td style="text-align: left;">$\lambda_{i, t} \in \mathbb{R}^{d}$</td>
<td style="text-align: left;">Location node representation for the $i$-th entity at time $t$, in the graph $G_{t}(\S 4.3,4.4)$</td>
</tr>
<tr>
<td style="text-align: left;">$\Lambda_{t} \in \mathbb{R}^{N \times d}$</td>
<td style="text-align: left;">Matrix of all location node representations at time $t$</td>
</tr>
<tr>
<td style="text-align: left;">$U_{t} \in \mathbb{R}^{N \times N}$</td>
<td style="text-align: left;">Soft co-reference matrix at time step $t(\S 4.3)$</td>
</tr>
</tbody>
</table>
<p>Table 2: Symbols used in Section 4. The text-based representations of entities and locations are derived from the hidden representations of the context-RNN (§ 4.1). The node representations are added to the graph $G_{t}$ at the end of time step $t(\S 4.4)$.
while $c_{j}$ represents the contextualized hidden vectors for token $j$ and $[;]$ represents the concatenate operation. An entity may occur multiple times within a paragraph. We give equal importance to all occurrences by summing the representations for each.</p>
<p>When queried about the current location of an entity, the MRC module (§ 4.2) returns a span of text as the answer, whose representation is later used to update the appropriate node vector in the graph. We obtain this answer-span representation analogously as above, and denote it with $\psi_{i, t}$.</p>
<h1>4.2 Machine Reading Comprehension Model</h1>
<p>Rather than design a specialized MRC architecture, we make simple extensions to a widely used model - DrQA (Chen et al., 2017) - to adapt it to query about the evolving states of entities. In summary, our modified DrQA implementation operates on prefixes of sentences rather than the full paragraph (like ProGlobal), and at each sentence (time step) it conditions on both the current sentence representation $s_{t}$ and the dynamic entity representations in $G_{t-1}$.</p>
<p>For complete details of the DrQA model, we refer readers to the original publication (Chen et al., 2017). Broadly, it uses a multi-layer recurrent neural network (RNN) architecture for encoding both the passage and question text and uses self-attention to match these two encodings. For each token $j$ in the text, it outputs a score indicating its likelihood of being the start or end of the span that answers the question. We reuse all of these operations in our model, modified as described below.</p>
<p>We query the DrQA model about the state of each participant entity at each time step $t$. This involves reading the paragraph up to and including sentence $s_{t}$. To query, we generate simple natural language questions for an entity, $E$, such as "Where is $E$ located?" This is motivated by the work of Levy et al. (2017). Our DrQA component also conditions on entities. Recall that vector $e_{i, t-1}$ denotes the entity's representation in the knowledge graph $G_{t-1}$. The module conditions on $e_{i, t-1}$ in its output layer, basically the same way as the question representation is used in the output alignment step in Chen et al. (2017). However, instead of taking a bi-linear map between the question and passage representations as in that work, we first concatenate the question representation with $e_{i, t-1}$ and pass the concatenation through a 2-layer MLP. This yields an entity-dependent question representation. We use this to compute the output start and end scores for each token position, taking the arg max to obtain the most likely span. As mentioned, we encode this span as vector $\psi_{i, t}(\S 4.1)$.</p>
<p>The ProPara dataset includes two special locations that don't appear as text spans: nowhere and somewhere. The current location of an entity is nowhere when the entity does not exist yet or has been destroyed, whereas it is somewhere when the entity exists but its location is unknown from the text. Since these locations don't appear as tokens in the text, the span-predictive MRC module cannot extract them. Following Dalvi et al. (2018), we address this with a separate classifier that predicts, given a graph entity node and the text, whether the entity represented by the node is nowhere, somewhere, or its location is stated. We learn the location-node representations for nowhere and somewhere during training.</p>
<h3>4.3 SOFT CO-REFERENCE</h3>
<p>To handle cases when entity states do not change and when states are referred to with different surface forms (either of which could lead to undesired node duplication), our model uses soft co-</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Soft co-reference across time steps. The sentence at the current time step is highlighted. When the MRC model predicts a span (leaf) present in the graph at the previous time step, KG-MRC does soft attention and a gated update to preserve information across time steps (§ 4.3). The thicker arrow shows higher attention weight between the old and new node.
reference mechanisms (Figure 2) both across and within time steps. Disambiguation across time steps is accomplished by attention and a gated update, using the incoming location vector $\psi_{i, t}$ and the location node representations from the previous time step:</p>
<p>$$
\begin{aligned}
&amp; a_{i, t}=\operatorname{softmax}\left(\Lambda_{t-1} \psi_{i, t}\right) \
&amp; \psi_{i, t}^{\prime}=\Lambda_{t-1}^{\prime} a_{i, t} \
&amp; g_{i}=\operatorname{sigmoid}\left(W_{i}\left[\psi_{i, t}^{\prime} ; \psi_{i, t}\right]+b_{i}\right) \
&amp; \lambda_{i, t}^{\prime}=g_{i} \psi_{i, t}+\left(1-g_{i}\right) \psi_{i, t}^{\prime}
\end{aligned}
$$</p>
<p>where $\Lambda_{t-1}=\left[\lambda_{i, t}\right]<em i_="i," t="t">{i=1}^{N} \in \mathbb{R}^{N \times d}$ is a matrix of location node representations from the previous time step (stacked row-wise) and $\psi</em>$ is a disambiguated intermediate node representation.}$ is the location span vector output by the MRC module. The result vector $\lambda_{i, t}^{\prime</p>
<p>This process only partially addresses node de-duplication. Since different instances of the same location can be predicted for multiple entities, we also perform a co-reference disambiguation within each time step using a self-attention mechanism:</p>
<p>$$
\begin{aligned}
&amp; u_{i, t}=\operatorname{softmax}\left(\Lambda_{t}^{\prime} \lambda_{i, t}^{\prime}\right) \
&amp; \lambda_{i, t}=\Lambda_{t}^{\prime} u_{i, t}
\end{aligned}
$$</p>
<p>where $\Lambda_{t}^{\prime}=\left[\lambda_{i, t}^{\prime}\right]<em t="t">{i=1}^{N} \in \mathbb{R}^{N \times d}$ is a matrix of intermediate node representations (stacked row-wise) and $U</em>$ is a co-reference adjacency matrix. We calculate this adjacency matrix at the beginning of each time step to track related nodes within $t$, and re-use it in the graph update step.}=\left[u_{i, t}\right]_{i=1}^{N} \in \mathbb{R}^{N \times N</p>
<h1>4.4 GRAPH UPDATE</h1>
<p>The graph update proceeds according to the following set of equations for each update layer $l$ :</p>
<p>$$
\begin{aligned}
h_{i, t}^{l} &amp; =\operatorname{LSTM}\left(\left[e_{i, t}^{l-1} ; \lambda_{i, t}^{l-1} ; h_{i, t-1}^{l}\right]\right) \
e_{i, t}^{l} &amp; =e_{i, t}^{l-1}+h_{i, t}^{l} \
\tilde{\lambda}<em i_="i," t="t">{i, t}^{l} &amp; =\lambda</em> \
\lambda_{i, t}^{l} &amp; =\tilde{\Lambda}}^{l-1}+h_{i, t}^{l<em i_="i," t="t">{t}^{l} u</em>
\end{aligned}
$$</p>
<p>We first compose all connected entity and location nodes with their history summary, $h_{i, t-1}^{l}$, using an LSTM unit. Next, the updated node information is attached to the entity and location representations through two residual updates (He et al., 2016). These propagate information between the entity and location representations; i.e., if two entities are at the same location, then the corresponding entity representations will receive a similar update. Likewise, location representations are updated with pertinent entity information. Last, we perform a co-reference pooling operation for the location</p>
<p>node representations. This uses the adjacency matrix $U_{t}$, where $\tilde{\Lambda}<em i_="i," t="t">{t}^{l}$ is a row-wise stacked matrix of the $\tilde{\lambda}</em>$, to tie co-referent location nodes together.}^{l</p>
<p>The recurrent graph module stacks $L$ such layers to propagate node information along the graph's edges. The resulting node representations are $e_{i, t}^{L}$ and $\lambda_{i, t}^{L}$ for each participant entity and its location. We use $e_{i, t}=e_{i, t}^{L}$ to condition the MRC model, as described in $\S 4.2$. We make use of this particular graph module structure, rather than adopting an existing model like GraphCNNs (Edwards \&amp; Xie, 2016; Kipf \&amp; Welling, 2017), because recurrent networks are designed to propagate information through time.</p>
<h1>4.5 Training</h1>
<p>The full KG-MRC model is trained end-to-end by minimizing the negative log-likelihood of the correct span tokens under the MRC module's output distribution and the textual entailment model. This is a fairly soft supervision signal, since we do not train the graph construction modules directly. We teacher-force the model at training time by updating the location-node representations with the encoding of the correct span. We do not pretrain the MRC module, but we represent paragraph tokens with pretrained FastText embeddings (Joulin et al., 2016). See the appendix A for full implementation and training details.</p>
<h2>5 EXPERIMENTS AND DISCUSSION</h2>
<p>We evaluate our model on three different tasks. We also provide an ablation study along with quantitative and qualitative analyses to highlight the performance contributions of each module.</p>
<h3>5.1 Results on Procedural Text</h3>
<p>We benchmarked our model on two ProPara comprehension tasks introduced respectively in Dalvi et al. (2018) and Tandon et al. (2018). Refer to Section 3 for a detailed description about the data and tasks. Dalvi et al. (2018) and Tandon et al. (2018) respectively introduce a specific model for each task, whereas we test KG-MRC on both tasks. A primary motivation for building KGs is because they can be queried for salient knowledge in downstream applications. We evaluate KG-MRC on the above two tasks by querying the KGs it builds at each time-step; we use the official evaluation pipeline ${ }^{2}$ for each task. In results below, we report an average score of three runs of our model with different hyperparameter settings.</p>
<h3>5.1.1 Task 1: Sentence-Level Evaluation</h3>
<p>Table 3 shows our main results on the first task. Following the original task evaluation, we report model accuracy on each subtask category and macro and micro averages over the subtasks.</p>
<p>Human performance is $79.69 \%$, micro-average. A state-of-the-art memory augmented network, ENTNET (Henaff et al., 2017), which is built to track entities but lacks an explicit graph structure, achieves $25.96 \%$. The previous best performing model is ProGlobal, which achieves $45.37 \%$. Our KG-MRC improves over this result by $1.25 \%$ absolute score in terms of micro-averaged accuracy. Comparing various models for each subtask category, ProGlobal leads in Category 1 by a small margin of around $0.1 \%$. For the more challenging Categories 2 and 3, KG-MRC outperforms PROGlobal by a large margin. These questions require fine-grained predictions of state changes.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Cat 1</th>
<th style="text-align: center;">Cat 2</th>
<th style="text-align: center;">Cat 3</th>
<th style="text-align: center;">Macro-avg</th>
<th style="text-align: center;">Micro-avg</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Human upper bound</td>
<td style="text-align: center;">91.67</td>
<td style="text-align: center;">87.66</td>
<td style="text-align: center;">62.96</td>
<td style="text-align: center;">80.76</td>
<td style="text-align: center;">79.69</td>
</tr>
<tr>
<td style="text-align: center;">Majority</td>
<td style="text-align: center;">51.01</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">Rule based</td>
<td style="text-align: center;">57.14</td>
<td style="text-align: center;">20.33</td>
<td style="text-align: center;">2.40</td>
<td style="text-align: center;">26.62</td>
<td style="text-align: center;">26.24</td>
</tr>
<tr>
<td style="text-align: center;">Feature based</td>
<td style="text-align: center;">58.64</td>
<td style="text-align: center;">20.82</td>
<td style="text-align: center;">9.66</td>
<td style="text-align: center;">29.7</td>
<td style="text-align: center;">29.64</td>
</tr>
<tr>
<td style="text-align: center;">EntNet (Henaff et al. (2017))</td>
<td style="text-align: center;">51.62</td>
<td style="text-align: center;">18.83</td>
<td style="text-align: center;">7.77</td>
<td style="text-align: center;">26.07</td>
<td style="text-align: center;">25.96</td>
</tr>
<tr>
<td style="text-align: center;">Pro-Local (Dalvi et al. (2018))</td>
<td style="text-align: center;">62.65</td>
<td style="text-align: center;">30.50</td>
<td style="text-align: center;">10.35</td>
<td style="text-align: center;">34.50</td>
<td style="text-align: center;">33.96</td>
</tr>
<tr>
<td style="text-align: center;">Pro-Global (Dalvi et al. (2018))</td>
<td style="text-align: center;">$\mathbf{6 2 . 9 5}$</td>
<td style="text-align: center;">36.39</td>
<td style="text-align: center;">35.90</td>
<td style="text-align: center;">45.08</td>
<td style="text-align: center;">45.37</td>
</tr>
<tr>
<td style="text-align: center;">KG-MRC (ours)</td>
<td style="text-align: center;">62.86</td>
<td style="text-align: center;">$\mathbf{4 0 . 0 0}$</td>
<td style="text-align: center;">$\mathbf{3 8 . 2 3}$</td>
<td style="text-align: center;">$\mathbf{4 7 . 0 3}$</td>
<td style="text-align: center;">$\mathbf{4 6 . 6 2}$</td>
</tr>
</tbody>
</table>
<p>Table 3: Task 1 results (accuracy).</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>5.1.2 Task 2: Document-Level Evaluation</h1>
<p>We report the performance of our model on the document-level task, along with previously published results, in Table 4. The same Kg-MRC model achieves $3.02 \%$ absolute improvement in $\mathrm{F}_{1}$ over the previous best result of ProStruct. ProStruct incorporates a set of commonsense constraints for globally consistent predictions. We analyzed Kg-MRC's outputs and were surprised to discover that our model learns these commonsense constraints from the data in an end-to-end fashion, as we show quantitatively in $\S 5.4$.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">$\mathrm{F}_{1}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Pro-Local (Dalvi et al. (2018))</td>
<td style="text-align: center;">$\mathbf{7 7 . 4}$</td>
<td style="text-align: center;">22.9</td>
<td style="text-align: center;">35.3</td>
</tr>
<tr>
<td style="text-align: center;">QRN (Seo et al. (2017b))</td>
<td style="text-align: center;">55.5</td>
<td style="text-align: center;">31.3</td>
<td style="text-align: center;">40.0</td>
</tr>
<tr>
<td style="text-align: center;">EntNet (Henaff et al. (2017))</td>
<td style="text-align: center;">50.2</td>
<td style="text-align: center;">33.5</td>
<td style="text-align: center;">40.2</td>
</tr>
<tr>
<td style="text-align: center;">Pro-Global (Dalvi et al. (2018))</td>
<td style="text-align: center;">46.7</td>
<td style="text-align: center;">$\mathbf{5 2 . 4}$</td>
<td style="text-align: center;">49.4</td>
</tr>
<tr>
<td style="text-align: center;">Pro-Struct (Tandon et al. (2018))</td>
<td style="text-align: center;">74.2</td>
<td style="text-align: center;">42.1</td>
<td style="text-align: center;">53.75</td>
</tr>
<tr>
<td style="text-align: center;">Kg-MRC (ours)</td>
<td style="text-align: center;">64.52</td>
<td style="text-align: center;">50.68</td>
<td style="text-align: center;">$\mathbf{5 6 . 7 7}$</td>
</tr>
</tbody>
</table>
<p>Table 4: Task 2 results.</p>
<h3>5.2 Recipe Description EXPERIMENTS</h3>
<p>We also evaluate our model on the RECIPEs dataset, where we predict the locations of cooking ingredients. In the original work of Bosselut et al. (2018), they treat this problem as classification over a fixed lexicon of locations, whereas KG-MRC searches for the correct location span in the text. Our model slightly outperforms the baseline NPN model on this task even after it was trained on just 10 K examples (the full training set is around 60 K examples): NPN achieves $51.28 \% \mathrm{~F}<em 1="1">{1}$ training on all the data, while $\mathrm{KG}-\mathrm{MRC}$ achieves $\mathbf{5 1 . 6 4} \% \mathrm{~F}</em>$ after 10 k examples.</p>
<h3>5.3 Ablation Study</h3>
<p>We performed an ablation study to evaluate different model variations on ProPara Task 1. The main results are reported in Table 5. Removing the soft co-reference disambiguation within time steps (Equations 2) from KG-MRC resulted in around $1 \%$ performance drop. The drop is more significant when the co-reference disambiguation across time steps (Equations 1) is removed.
We also replaced the recurrent graph module with the standard LSTM unit and used the LSTM hidden state for the entity representation. As this model variation lacks the information propagation across graph nodes, we observed a large performance decrease.
For the last two variations, we simply train the MRC model in isolation and predict location spans from the current sentence or paragraph prefix text (i.e., the current and all previous sentences). These models construct no internal knowledge graphs. We can see that training the MRC model on paragraph prefixes already provides a good starting performance of $40.83 \%$ micro-average, which is significantly boosted by the recurrent graph module and graph conditioning up to $47.64 \%$.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Cat 1</th>
<th style="text-align: center;">Cat 2</th>
<th style="text-align: center;">Cat 3</th>
<th style="text-align: center;">Macro-avg</th>
<th style="text-align: center;">Micro-avg</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">KG-MRC</td>
<td style="text-align: center;">58.55</td>
<td style="text-align: center;">38.52</td>
<td style="text-align: center;">42.22</td>
<td style="text-align: center;">46.43</td>
<td style="text-align: center;">47.64</td>
</tr>
<tr>
<td style="text-align: center;">- Coref across time steps</td>
<td style="text-align: center;">61.07</td>
<td style="text-align: center;">37.38</td>
<td style="text-align: center;">35.58</td>
<td style="text-align: center;">44.68</td>
<td style="text-align: center;">46.32</td>
</tr>
<tr>
<td style="text-align: center;">- Coref within time step</td>
<td style="text-align: center;">57.88</td>
<td style="text-align: center;">38.09</td>
<td style="text-align: center;">40.19</td>
<td style="text-align: center;">45.39</td>
<td style="text-align: center;">46.63</td>
</tr>
<tr>
<td style="text-align: center;">Standard LSTM as graph unit</td>
<td style="text-align: center;">56.84</td>
<td style="text-align: center;">13.15</td>
<td style="text-align: center;">10.95</td>
<td style="text-align: center;">26.98</td>
<td style="text-align: center;">29.97</td>
</tr>
<tr>
<td style="text-align: center;">MRC on entire paragraph</td>
<td style="text-align: center;">58.85</td>
<td style="text-align: center;">21.82</td>
<td style="text-align: center;">26.52</td>
<td style="text-align: center;">35.73</td>
<td style="text-align: center;">35.98</td>
</tr>
<tr>
<td style="text-align: center;">MRC on prefix</td>
<td style="text-align: center;">61.28</td>
<td style="text-align: center;">32.58</td>
<td style="text-align: center;">29.48</td>
<td style="text-align: center;">41.11</td>
<td style="text-align: center;">40.83</td>
</tr>
</tbody>
</table>
<p>Table 5: Ablation experiment results</p>
<h3>5.4 COMMONSENSE CONSTRAINTS</h3>
<p>For accurate, globally consistent predictions for the second task, Tandon et al. (2018) introduced a set of commonsense constraints on their model. Stated in natural language, these constraints are: 1) An entity must exist before it can be moved or destroyed; 2) An entity cannot be created if it already exists; 3) An entity cannot change until it is mentioned in the paragraph.
To analyze whether our model can learn the above constraints from data, we count the number of predictions that violate any constraints on the test set. In Table 6 we compare the behavior of</p>
<p>different models by computing the number of violations made by Tandon et al. (2018)'s model and several variants of our model. Note that we only count instances where a model predicts an entity state change.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">State Change Predictions</th>
<th style="text-align: center;">Violations</th>
<th style="text-align: center;">Violation Proportion (\%)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Pro-Struct (Tandon et al. (2018))</td>
<td style="text-align: center;">270</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">6.30</td>
</tr>
<tr>
<td style="text-align: center;">MRC on entire paragraph</td>
<td style="text-align: center;">381</td>
<td style="text-align: center;">104</td>
<td style="text-align: center;">27.30</td>
</tr>
<tr>
<td style="text-align: center;">MRC on prefix</td>
<td style="text-align: center;">703</td>
<td style="text-align: center;">154</td>
<td style="text-align: center;">21.93</td>
</tr>
<tr>
<td style="text-align: center;">Standard LSTM as graph unit</td>
<td style="text-align: center;">447</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">4.47</td>
</tr>
<tr>
<td style="text-align: center;">KG-MRC</td>
<td style="text-align: center;">466</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">$\mathbf{4 . 0 8}$</td>
</tr>
</tbody>
</table>
<p>Table 6: Commonsense constraints violation.</p>
<p>To our surprise, KG-MRC learns to violate fewer constraints (proportionally) than ProStruct even without explicitly training it to do so. As the table shows, MRC models without recurrent graph modules perform worse in terms of constraint violations than both KG-MRC and a model with standard LSTM as its graph unit. This suggests that recurrency and graph representations play an important role in helping the model to learn commonsense constraints.</p>
<h1>5.5 Qualitative Analysis</h1>
<p>We picked an example from the test data and took a closer look at the model outputs to investigate how KG-MRC dynamically adjusts its decisions via the dynamic graph module and finds accurate spans with the conditional MRC model. The step-by-step output of both ProGlobal (Dalvi et al. (2018)) and KG-MRC is shown in Table 7, where we track the state of entity blood across six sentences. KG-MRC outputs smoother and more accurate predictions.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Sentences</th>
<th style="text-align: left;">Location of entities after each sentence</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">(Before first sentence)</td>
<td style="text-align: left;">somewhere</td>
<td style="text-align: left;">somewhere</td>
</tr>
<tr>
<td style="text-align: left;">Blood enters the right side of your heart.</td>
<td style="text-align: left;">heart</td>
<td style="text-align: left;">right side of your heart</td>
</tr>
<tr>
<td style="text-align: left;">Blood travels to the lungs.</td>
<td style="text-align: left;">lung</td>
<td style="text-align: left;">lungs</td>
</tr>
<tr>
<td style="text-align: left;">Carbon dioxide is removed from the blood.</td>
<td style="text-align: left;">blood</td>
<td style="text-align: left;">lungs</td>
</tr>
<tr>
<td style="text-align: left;">Oxygen is added to your blood.</td>
<td style="text-align: left;">lung</td>
<td style="text-align: left;">lungs</td>
</tr>
<tr>
<td style="text-align: left;">Blood returns to left side of your heart.</td>
<td style="text-align: left;">blood</td>
<td style="text-align: left;">heart</td>
</tr>
<tr>
<td style="text-align: left;">The blood travels through the body.</td>
<td style="text-align: left;">body</td>
<td style="text-align: left;">body</td>
</tr>
</tbody>
</table>
<p>Table 7: Two models' predictions of entity locations, on randomly selected paragraph about blood circulation. In this example the entity is blood. Predicted results from Pro-Local (Dalvi et al. (2018)) are in orange, results from KG-MRC are in red, important locations in paragraph are in blue.</p>
<h2>6 CONCLUSION</h2>
<p>We proposed a neural machine-reading model that constructs dynamic knowledge graphs from text to track locations of participant entities in procedural text. It further uses these graphical representations to improve its downstream comprehension of text. Our model, KG-MRC, achieves state-of-theart results on two question-answering tasks from the PROPARA dataset and one from the RECIPES dataset. In future work, we will extend the model to construct more general knowledge graphs with multiple relation types.</p>
<h2>REFERENCES</h2>
<p>Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.</p>
<p>Trapit Bansal, Arvind Neelakantan, and Andrew McCallum. Relnet: End-to-end modeling of entities \&amp; relations. In AKBC, NIPS, 2017.</p>
<p>Jonathan Berant, Vivek Srikumar, Pei-Chun Chen, Abby Vander Linden, Brittany Harding, Brad Huang, Peter Clark, and Christopher D Manning. Modeling biological processes for reading comprehension. In EMNLP, 2014.</p>
<p>Antoine Bosselut, Omer Levy, Ari Holtzman, Corin Ennis, Dieter Fox, and Yejin Choi. Simulating action dynamics with neural process networks. In $I C L R, 2018$.</p>
<p>Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. Reading wikipedia to answer opendomain questions. In $A C L, 2017$.</p>
<p>Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.</p>
<p>Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555, 2014.</p>
<p>Bhavana Dalvi, Lifu Huang, Niket Tandon, Wen-tau Yih, and Peter Clark. Tracking state changes in procedural text: a challenge dataset and models for process paragraph comprehension. In NAACL, 2018.</p>
<p>Rajarshi Das, Manzil Zaheer, Siva Reddy, and Andrew McCallum. Question answering on knowledge bases and text using universal schema and memory networks. In ACL, 2017.</p>
<p>Michael Edwards and Xianghua Xie. Graph based convolutional neural network. arXiv preprint arXiv:1609.08965, 2016.</p>
<p>Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. $770-778,2016$.</p>
<p>Mikael Henaff, Jason Weston, Arthur Szlam, Antoine Bordes, and Yann LeCun. Tracking the world state with recurrent entity networks. In $I C L R, 2017$.</p>
<p>Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 1997.
Armand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze, Hérve Jégou, and Tomas Mikolov. Fasttext.zip: Compressing text classification models. arXiv preprint arXiv:1612.03651, 2016.</p>
<p>Chloé Kiddon, Ganesa Thandavam Ponnuraj, Luke Zettlemoyer, and Yejin Choi. Mise en place: Unsupervised interpretation of instructional recipes. In EMNLP, 2015.</p>
<p>Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.</p>
<p>Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In $I C L R, 2017$.</p>
<p>Omer Levy, Minjoon Seo, Eunsol Choi, and Luke S. Zettlemoyer. Zero-shot relation extraction via reading comprehension. In CoNLL, 2017.</p>
<p>Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. In NIPS-W, 2017.</p>
<p>Benjamin Roth, Costanza Conforti, Nina Poerner, Sanjeev Karn, and Hinrich Schütze. Neural architectures for open-type relation argument extraction. arXiv preprint arXiv:1803.01707, 2018.</p>
<p>Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and Hannaneh Hajishirzi. Bidirectional attention flow for machine comprehension. In $I C L R, 2017 a$.</p>
<p>Minjoon Seo, Sewon Min, Ali Farhadi, and Hannaneh Hajishirzi. Query-reduction networks for question answering. In $I C L R, 2017 \mathrm{~b}$.</p>
<p>Niket Tandon, Bhavana Dalvi Mishra, Joel Grus, Wen-tau Yih, Antoine Bosselut, and Peter Clark. Reasoning about actions and state changes by injecting commonsense knowledge. In EMNLP, 2018.</p>
<p>Jason Weston, Antoine Bordes, Sumit Chopra, Alexander M Rush, Bart van Merriënboer, Armand Joulin, and Tomas Mikolov. Towards ai-complete question answering: A set of prerequisite toy tasks. arXiv preprint arXiv:1502.05698, 2015.</p>
<p>Caiming Xiong, Victor Zhong, and Richard Socher. Dynamic coattention networks for question answering. In $I C L R, 2017$.</p>
<p>Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen, Mohammad Norouzi, and Quoc V Le. Qanet: Combining local convolution with global self-attention for reading comprehension. In $I C L R, 2018$.</p>
<h1>A IMPLEMENTATION DETAILS</h1>
<p>Implementation details of KG-MRC are as follows.
In all experiments, the word embeddings are initialized with FastText embeddings (Joulin et al., 2016); we use a document LSTM with two layers, the number of hidden units in each layer is 64. We apply dropout rate of 0.4 in all recurrent layers, and 0.3 in all other layers. The number of recurrent graph layers were set to $(L=2)$. The hidden unit size for the recurrent graph component was set to 64 .</p>
<p>During training, the mini-batch size is 8 . We use adam (Kingma \&amp; Ba, 2014) as the step rule for optimization, The learning rate is set to 0.002 . The model is implemented using PyTorch (Paszke et al., 2017).</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ https://github.com/allenai/propara/tree/master/propara/eval&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>