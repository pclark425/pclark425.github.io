<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2782 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2782</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2782</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-70.html">extraction-schema-70</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve text games, including details about the memory architecture, performance comparisons, and what makes memory effective or ineffective.</div>
                <p><strong>Paper ID:</strong> paper-227458886343b86bd15adf58c769be326b4b058a</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/227458886343b86bd15adf58c769be326b4b058a" target="_blank">Wizard of Wikipedia: Knowledge-Powered Conversational agents</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Learning Representations</p>
                <p><strong>Paper TL;DR:</strong> The best performing dialogue models are able to conduct knowledgeable discussions on open-domain topics as evaluated by automatic metrics and human evaluations, while a new benchmark allows for measuring further improvements in this important research direction.</p>
                <p><strong>Paper Abstract:</strong> In open-domain dialogue intelligent agents should exhibit the use of knowledge, however there are few convincing demonstrations of this to date. The most popular sequence to sequence models typically "generate and hope" generic utterances that can be memorized in the weights of the model when mapping from input utterance(s) to output, rather than employing recalled knowledge as context. Use of knowledge has so far proved difficult, in part because of the lack of a supervised learning benchmark task which exhibits knowledgeable open dialogue with clear grounding. To that end we collect and release a large dataset with conversations directly grounded with knowledge retrieved from Wikipedia. We then design architectures capable of retrieving knowledge, reading and conditioning on it, and finally generating natural responses. Our best performing dialogue models are able to conduct knowledgeable discussions on open-domain topics as evaluated by automatic metrics and human evaluations, while our new benchmark allows for measuring further improvements in this important research direction.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2782.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2782.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve text games, including details about the memory architecture, performance comparisons, and what makes memory effective or ineffective.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformer MemNet (Retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval Transformer Memory Network (Transformer Memory Network)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-style dialogue agent that encodes dialogue context and retrieved Wikipedia sentences with Transformers, attends over the knowledge, and selects a response from a candidate pool by cosine similarity between context+knowledge and candidate encodings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Retrieval Transformer MemNet</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Encodes each retrieved knowledge sentence and the dialogue context with a Transformer encoder, performs dot-product attention to obtain a knowledge-conditioned context vector, encodes candidate responses with a separate Transformer, and selects the highest-scoring candidate via cosine similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>base_model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_benchmark_name</strong></td>
                            <td>Wizard of Wikipedia</td>
                        </tr>
                        <tr>
                            <td><strong>game_description</strong></td>
                            <td>An open-domain, multi-turn dialogue benchmark where a wizard (agent) must ground responses in Wikipedia: tasks include knowledge selection (choose the sentence the human wizard used) and dialogue response selection/generation conditioned on retrieved knowledge passages.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented external knowledge memory (Wikipedia passages)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_structure</strong></td>
                            <td>Hierarchical Wikipedia collection (articles→paragraphs→sentences) but flattened for the model: an IR stage returns a top-K set of sentence candidates (each prepended with article title) which are encoded independently for attention.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_content</strong></td>
                            <td>Sentences (first paragraph or first 10 sentences of topic article) and article titles from Wikipedia relevant to the topic and the last two turns of dialogue.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td>IR retrieves top 7 articles per query (topic and each of the last two turns) and flattens into ~61 candidate sentences per turn (paper reports ~61 candidates per turn); K is therefore on the order of tens to low hundreds.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_strategy</strong></td>
                            <td>Two-stage: (1) IR using TF–IDF / inverted index / hashed n-gram vectors (Open-SQuAD retriever) to return top articles for three queries (topic, last two turns); (2) fine-grained dot-product attention (Transformer encodings) over the returned sentence candidates (relevance-based / semantic similarity).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td>Static encyclopedic KB (Wikipedia); memory is not incrementally written to — retrieval is performed anew each dialogue turn conditioned on the dialogue context (topic and last two turns).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_usage_purpose</strong></td>
                            <td>Ground and inform selection of a natural response (retrieval of an existing training utterance) by providing factual content and topical context to improve response relevance and factuality.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Predicted-knowledge (Test Seen): R@1 = 86.8, F1 = 15.4; Predicted-knowledge (Test Unseen): R@1 = 69.8, F1 = 12.4; Gold-knowledge (Seen): R@1 = 91.6; Gold-knowledge (Unseen): R@1 = 82.3. (Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Transformer (no knowledge, with Reddit pretraining) Predicted-knowledge (Test Seen): R@1 = 79.0, F1 = 15.0; Predicted-knowledge (Test Unseen): R@1 = 54.0, F1 = 11.6. (Table 3)  — adding memory improves R@1 substantially.</td>
                        </tr>
                        <tr>
                            <td><strong>has_memory_ablation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_effectiveness_findings</strong></td>
                            <td>Having explicit knowledge memory substantially improves retrieval performance (large R@1 gains). Pretraining the Transformer (Reddit) improves knowledge selection and downstream retrieval. Retrieval quality (IR + fine-grained attention) is crucial: providing gold knowledge yields much higher performance, indicating selection is a bottleneck. Memory helps especially for seen topics and improves topical sticking; it also increases Wiki-F1 (models exhibit more Wikipedia content).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td>IR retrieval errors and incorrect knowledge selection produce factually incorrect responses; the need for a separate IR stage arises because full neural attention over millions of articles is infeasible; the retriever can fail when the human changes topic, causing off-topic or inaccurate replies. Models can be overly anchored to retrieved sentences (parroting) and still make factual mistakes if retrieval is wrong.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>best_memory_configuration</strong></td>
                            <td>Transformer MemNet with Reddit pretraining (optionally further tuned with SQuAD) performed best for retrieval tasks; using gold knowledge yields the best possible performance, indicating that improving retriever/selection is the most important lever.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Wizard of Wikipedia: Knowledge-Powered Conversational agents', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2782.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2782.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve text games, including details about the memory architecture, performance comparisons, and what makes memory effective or ineffective.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Two-stage Transformer MemNet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Two-stage Generative Transformer Memory Network</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generative dialogue agent that first selects a single knowledge sentence with a dedicated Transformer-based selector, then conditions a separate Transformer generator on that chosen knowledge concatenated with the dialogue to produce a word-by-word response; includes knowledge dropout to improve robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Two-stage Generative Transformer MemNet</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Two separate models: (1) a Transformer knowledge selection module (pretrained on Reddit then fine-tuned) that picks the most relevant retrieved sentence; (2) a Transformer-based sequence generator that conditions on the selected sentence concatenated with dialogue history to decode the next utterance. Knowledge Dropout (K.D.) randomly blocks access to knowledge during training to increase robustness to selection errors.</td>
                        </tr>
                        <tr>
                            <td><strong>base_model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_benchmark_name</strong></td>
                            <td>Wizard of Wikipedia</td>
                        </tr>
                        <tr>
                            <td><strong>game_description</strong></td>
                            <td>As above: multi-turn knowledge-grounded dialogue; generator must produce fluent, grounded replies using external Wikipedia memory.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented external knowledge memory (selected sentence used as explicit conditioning memory)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_structure</strong></td>
                            <td>Same flattened sentence candidates from IR; a single best sentence (hard selection) is chosen and concatenated with dialogue for the generator; memory thus used as a single selected slot per turn.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_content</strong></td>
                            <td>Single selected Wikipedia sentence (from IR candidates) representing the factual grounding for the response; article titles prepended to sentences.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td>Selection operates over the IR-provided candidate set (tens of candidates; ~61 candidates per turn reported); the generator conditions on only the single selected sentence.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_strategy</strong></td>
                            <td>IR (TF–IDF) to get candidates, followed by a Transformer-based selector (semantic scoring) that outputs a hard decision for the best sentence; Knowledge Dropout may force the generator to operate without the selected sentence some fraction of training steps.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td>Static KB; selection performed each turn based on new queries (topic and last two turns); no persistent memory writes across episodes beyond standard model parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_usage_purpose</strong></td>
                            <td>Provide factual content to condition the generative decoder, enabling the model to copy/ground facts from Wikipedia and generalize to unseen topics by using retrieved external knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Predicted-knowledge (Test Seen): PPL = 54.8, F1 = 18.6; Predicted-knowledge with Knowledge Dropout (Test Seen): PPL = 46.5, F1 = 18.9. Predicted-knowledge (Test Unseen): PPL = 88.5, F1 = 17.4. Gold-knowledge (Seen): PPL = 30.0, F1 = 30.7; Gold-knowledge (Unseen): PPL = 42.7, F1 = 28.6. (Table 4)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Generative Transformer (no knowledge) on gold-knowledge evaluation: Seen PPL = 41.8, F1 = 17.8; Unseen PPL = 87.0, F1 = 14.0. (Table 4) — Two-stage model with memory improves F1 and lowers perplexity relative to no-knowledge baseline, especially with predicted knowledge on seen topics.</td>
                        </tr>
                        <tr>
                            <td><strong>has_memory_ablation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_effectiveness_findings</strong></td>
                            <td>A strong, separately optimized knowledge selector is vital: the two-stage approach performs best when the selector is optimized (improved perplexity and F1 with predicted knowledge). Knowledge Dropout improves robustness to selection errors. Generative models with memory generalize better to unseen topics than retrieval models because they can compose new utterances from retrieved facts. However, the generator benefits greatly when the selected knowledge is correct (gold knowledge gives large gains).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td>Hard selection of a single sentence can bottleneck the generator if the selector errs; retrieved-but-incorrect knowledge leads to factual mistakes in generated replies; generator sometimes copies Wikipedia verbatim or produces formulaic responses; factual inaccuracies (wrong dates/names) are observed when retrieval is imperfect.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>best_memory_configuration</strong></td>
                            <td>Two-stage system with a strong Transformer-based knowledge selector (pretrained on Reddit) plus Knowledge Dropout for the generator gave the best predicted-knowledge performance; however, when given gold knowledge the End-to-end model performed better at using that knowledge (see End-to-end entry).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Wizard of Wikipedia: Knowledge-Powered Conversational agents', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2782.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2782.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve text games, including details about the memory architecture, performance comparisons, and what makes memory effective or ineffective.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>End-to-end Transformer MemNet (Generative)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>End-to-end Generative Transformer Memory Network</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generative Transformer model that encodes dialogue and all retrieved knowledge candidates in a shared encoder, computes a soft attention distribution over candidates to pick the best knowledge, concatenates the selected knowledge encoding with the dialogue encoding, and decodes the response; can be trained with an auxiliary supervised loss on knowledge selection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>End-to-end Generative Transformer MemNet</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Shared Transformer encoder encodes dialogue and all candidate knowledge sentences; candidates are flattened to sentence vectors with length-normalized pooling; attention over candidates yields a soft selection (m_best), which is concatenated with dialogue encodings and passed to a Transformer decoder to generate the response. Optionally trained with an auxiliary cross-entropy loss forcing the attention to match human-chosen knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>base_model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_benchmark_name</strong></td>
                            <td>Wizard of Wikipedia</td>
                        </tr>
                        <tr>
                            <td><strong>game_description</strong></td>
                            <td>Knowledge-grounded multi-turn dialogue requiring selection of relevant Wikipedia sentences and generation of informative replies.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented external knowledge memory with soft attention selection</td>
                        </tr>
                        <tr>
                            <td><strong>memory_structure</strong></td>
                            <td>IR-provided candidate sentences (flattened) encoded and pooled into sentence vectors; attention yields a soft-weighted selection of memory which is then used as full sequence encoding (concatenated to dialogue) for decoding.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_content</strong></td>
                            <td>All IR-returned Wikipedia candidate sentences for the current turn (titles + sentences), encoded and pooled for attention-based selection.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td>Operates over the IR candidates set (tens to low hundreds; ~61 candidates per turn reported); unlike two-stage it uses soft selection over all candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_strategy</strong></td>
                            <td>IR (TF–IDF) followed by Transformer-based encoding and attention (soft selection) over candidate sentence vectors; optionally supervised with auxiliary loss to match human-chosen knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td>Static KB; retrieval and attention applied each turn conditioned on dialogue context; no persistent episodic write mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_usage_purpose</strong></td>
                            <td>Provide contextual factual grounding for the generative decoder, enabling it to attend to and copy from retrieved Wikipedia content while generating responses.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>E2E (no auxiliary loss) Predicted-knowledge (Test Seen): PPL = 66.5, F1 = 15.9; with auxiliary loss Predicted-knowledge (Seen): PPL = 63.5, F1 = 16.9. Gold-knowledge (Seen) with auxiliary loss: PPL = 23.1, F1 = 35.5; Gold-knowledge (Unseen): PPL = 32.8, F1 = 32.2. (Table 4)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Generative Transformer (no knowledge) baseline: Gold-knowledge evaluation (Seen) PPL = 41.8, F1 = 17.8; Unseen PPL = 87.0, F1 = 14.0. (Table 4) — End-to-end model with auxiliary loss substantially outperforms no-knowledge generator when given gold knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>has_memory_ablation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_effectiveness_findings</strong></td>
                            <td>Tightly integrating knowledge selection and generation (end-to-end) is beneficial when the selected knowledge is accurate: E2E outperforms two-stage when provided gold knowledge. Adding an auxiliary supervised loss on knowledge selection improves E2E performance across metrics. However, when selection must be predicted, two-stage (with a strong separate selector) performs better overall, indicating that selection quality is critical.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td>Soft attention over many candidates is limited by the initial retrieval quality; E2E can underperform when the attention/selection is not strongly supervised. Like other models, it depends on IR returning relevant candidates; incorrect retrieval causes factual errors in outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>best_memory_configuration</strong></td>
                            <td>End-to-end with auxiliary (knowledge) loss is best at using correct knowledge (gold) to maximize generation quality; for predicted selection, two-stage with a dedicated selector can be superior because it maximizes knowledge-selection accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Wizard of Wikipedia: Knowledge-Powered Conversational agents', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2782.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2782.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve text games, including details about the memory architecture, performance comparisons, and what makes memory effective or ineffective.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BoW MemNet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bag-of-Words Memory Network (Memory Network baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline Memory Network that encodes candidate facts as bag-of-words vectors and attends over them to select knowledge or condition responses; used as a simpler non-Transformer baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>End-to-end memory networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>BoW Memory Network (MemNet baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Classical Memory Network variant where knowledge sentences are encoded as bag-of-words (or bag-of-features) and attended with a memory-style architecture to score or retrieve relevant responses; used as baseline for knowledge selection and retrieval tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>base_model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_benchmark_name</strong></td>
                            <td>Wizard of Wikipedia</td>
                        </tr>
                        <tr>
                            <td><strong>game_description</strong></td>
                            <td>Knowledge-grounded multi-turn dialogue with explicit human-selected knowledge annotations for supervised training and evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external memory (bag-of-words fact store)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_structure</strong></td>
                            <td>Flat set of sentence-level memory vectors represented as bag-of-words feature vectors (no deep contextual encoding).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_content</strong></td>
                            <td>Retrieved Wikipedia sentences represented as BoW vectors (same IR candidates used as other models).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td>Operates over the IR candidate set (same tens-to-hundreds of candidates per turn).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_strategy</strong></td>
                            <td>IR to obtain candidates, then BoW-based memory network attention/scoring to pick top sentence(s) or to condition response retrieval/generation.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td>Static KB; per-turn retrieval and attention; no incremental updates.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_usage_purpose</strong></td>
                            <td>Provide factual grounding via simple fact encodings to aid selection/retrieval of relevant responses.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Knowledge selection: R@1 = 23.0, F1 = 36.3 (Seen); Retrieval full-task (Predicted Knowledge): R@1 = 71.3, F1 = 15.6 (Seen). (Tables 2 & 3)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>BoW MemNet (no knowledge baseline for retrieval): R@1 = 56.1 (Seen predicted), F1 = 14.2 — adding knowledge improved performance (56.1 → 71.3 R@1). (Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>has_memory_ablation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_effectiveness_findings</strong></td>
                            <td>Simple BoW memory provides substantial gains over no-knowledge baselines, demonstrating that explicit external facts help retrieval. However, contextual Transformer encodings with pretraining outperform BoW MemNet, especially on knowledge selection and unseen topics.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td>BoW representations lack contextual encoding, perform poorly on unseen topics relative to Transformer encoders, and yield lower selection accuracy — they are less effective at capturing nuanced semantic matches than Transformer-based encoders.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>best_memory_configuration</strong></td>
                            <td>While BoW MemNet improves over no-knowledge baselines, the paper finds Transformer-based encoders (with Reddit pretraining and optional SQuAD multi-tasking) produce superior knowledge selection and retrieval performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Wizard of Wikipedia: Knowledge-Powered Conversational agents', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>End-to-end memory networks <em>(Rating: 2)</em></li>
                <li>Attention is all you need <em>(Rating: 2)</em></li>
                <li>Reading wikipedia to answer open-domain questions <em>(Rating: 2)</em></li>
                <li>A knowledge-grounded neural conversation model <em>(Rating: 2)</em></li>
                <li>Extending neural generative conversational model using external knowledge sources <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2782",
    "paper_id": "paper-227458886343b86bd15adf58c769be326b4b058a",
    "extraction_schema_id": "extraction-schema-70",
    "extracted_data": [
        {
            "name_short": "Transformer MemNet (Retrieval)",
            "name_full": "Retrieval Transformer Memory Network (Transformer Memory Network)",
            "brief_description": "A retrieval-style dialogue agent that encodes dialogue context and retrieved Wikipedia sentences with Transformers, attends over the knowledge, and selects a response from a candidate pool by cosine similarity between context+knowledge and candidate encodings.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Retrieval Transformer MemNet",
            "agent_description": "Encodes each retrieved knowledge sentence and the dialogue context with a Transformer encoder, performs dot-product attention to obtain a knowledge-conditioned context vector, encodes candidate responses with a separate Transformer, and selects the highest-scoring candidate via cosine similarity.",
            "base_model_size": null,
            "game_benchmark_name": "Wizard of Wikipedia",
            "game_description": "An open-domain, multi-turn dialogue benchmark where a wizard (agent) must ground responses in Wikipedia: tasks include knowledge selection (choose the sentence the human wizard used) and dialogue response selection/generation conditioned on retrieved knowledge passages.",
            "uses_memory": true,
            "memory_type": "retrieval-augmented external knowledge memory (Wikipedia passages)",
            "memory_structure": "Hierarchical Wikipedia collection (articles→paragraphs→sentences) but flattened for the model: an IR stage returns a top-K set of sentence candidates (each prepended with article title) which are encoded independently for attention.",
            "memory_content": "Sentences (first paragraph or first 10 sentences of topic article) and article titles from Wikipedia relevant to the topic and the last two turns of dialogue.",
            "memory_capacity": "IR retrieves top 7 articles per query (topic and each of the last two turns) and flattens into ~61 candidate sentences per turn (paper reports ~61 candidates per turn); K is therefore on the order of tens to low hundreds.",
            "memory_retrieval_strategy": "Two-stage: (1) IR using TF–IDF / inverted index / hashed n-gram vectors (Open-SQuAD retriever) to return top articles for three queries (topic, last two turns); (2) fine-grained dot-product attention (Transformer encodings) over the returned sentence candidates (relevance-based / semantic similarity).",
            "memory_update_strategy": "Static encyclopedic KB (Wikipedia); memory is not incrementally written to — retrieval is performed anew each dialogue turn conditioned on the dialogue context (topic and last two turns).",
            "memory_usage_purpose": "Ground and inform selection of a natural response (retrieval of an existing training utterance) by providing factual content and topical context to improve response relevance and factuality.",
            "performance_with_memory": "Predicted-knowledge (Test Seen): R@1 = 86.8, F1 = 15.4; Predicted-knowledge (Test Unseen): R@1 = 69.8, F1 = 12.4; Gold-knowledge (Seen): R@1 = 91.6; Gold-knowledge (Unseen): R@1 = 82.3. (Table 3)",
            "performance_without_memory": "Transformer (no knowledge, with Reddit pretraining) Predicted-knowledge (Test Seen): R@1 = 79.0, F1 = 15.0; Predicted-knowledge (Test Unseen): R@1 = 54.0, F1 = 11.6. (Table 3)  — adding memory improves R@1 substantially.",
            "has_memory_ablation": true,
            "memory_effectiveness_findings": "Having explicit knowledge memory substantially improves retrieval performance (large R@1 gains). Pretraining the Transformer (Reddit) improves knowledge selection and downstream retrieval. Retrieval quality (IR + fine-grained attention) is crucial: providing gold knowledge yields much higher performance, indicating selection is a bottleneck. Memory helps especially for seen topics and improves topical sticking; it also increases Wiki-F1 (models exhibit more Wikipedia content).",
            "memory_limitations": "IR retrieval errors and incorrect knowledge selection produce factually incorrect responses; the need for a separate IR stage arises because full neural attention over millions of articles is infeasible; the retriever can fail when the human changes topic, causing off-topic or inaccurate replies. Models can be overly anchored to retrieved sentences (parroting) and still make factual mistakes if retrieval is wrong.",
            "comparison_with_other_memory_types": true,
            "best_memory_configuration": "Transformer MemNet with Reddit pretraining (optionally further tuned with SQuAD) performed best for retrieval tasks; using gold knowledge yields the best possible performance, indicating that improving retriever/selection is the most important lever.",
            "uuid": "e2782.0",
            "source_info": {
                "paper_title": "Wizard of Wikipedia: Knowledge-Powered Conversational agents",
                "publication_date_yy_mm": "2018-09"
            }
        },
        {
            "name_short": "Two-stage Transformer MemNet",
            "name_full": "Two-stage Generative Transformer Memory Network",
            "brief_description": "A generative dialogue agent that first selects a single knowledge sentence with a dedicated Transformer-based selector, then conditions a separate Transformer generator on that chosen knowledge concatenated with the dialogue to produce a word-by-word response; includes knowledge dropout to improve robustness.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Two-stage Generative Transformer MemNet",
            "agent_description": "Two separate models: (1) a Transformer knowledge selection module (pretrained on Reddit then fine-tuned) that picks the most relevant retrieved sentence; (2) a Transformer-based sequence generator that conditions on the selected sentence concatenated with dialogue history to decode the next utterance. Knowledge Dropout (K.D.) randomly blocks access to knowledge during training to increase robustness to selection errors.",
            "base_model_size": null,
            "game_benchmark_name": "Wizard of Wikipedia",
            "game_description": "As above: multi-turn knowledge-grounded dialogue; generator must produce fluent, grounded replies using external Wikipedia memory.",
            "uses_memory": true,
            "memory_type": "retrieval-augmented external knowledge memory (selected sentence used as explicit conditioning memory)",
            "memory_structure": "Same flattened sentence candidates from IR; a single best sentence (hard selection) is chosen and concatenated with dialogue for the generator; memory thus used as a single selected slot per turn.",
            "memory_content": "Single selected Wikipedia sentence (from IR candidates) representing the factual grounding for the response; article titles prepended to sentences.",
            "memory_capacity": "Selection operates over the IR-provided candidate set (tens of candidates; ~61 candidates per turn reported); the generator conditions on only the single selected sentence.",
            "memory_retrieval_strategy": "IR (TF–IDF) to get candidates, followed by a Transformer-based selector (semantic scoring) that outputs a hard decision for the best sentence; Knowledge Dropout may force the generator to operate without the selected sentence some fraction of training steps.",
            "memory_update_strategy": "Static KB; selection performed each turn based on new queries (topic and last two turns); no persistent memory writes across episodes beyond standard model parameters.",
            "memory_usage_purpose": "Provide factual content to condition the generative decoder, enabling the model to copy/ground facts from Wikipedia and generalize to unseen topics by using retrieved external knowledge.",
            "performance_with_memory": "Predicted-knowledge (Test Seen): PPL = 54.8, F1 = 18.6; Predicted-knowledge with Knowledge Dropout (Test Seen): PPL = 46.5, F1 = 18.9. Predicted-knowledge (Test Unseen): PPL = 88.5, F1 = 17.4. Gold-knowledge (Seen): PPL = 30.0, F1 = 30.7; Gold-knowledge (Unseen): PPL = 42.7, F1 = 28.6. (Table 4)",
            "performance_without_memory": "Generative Transformer (no knowledge) on gold-knowledge evaluation: Seen PPL = 41.8, F1 = 17.8; Unseen PPL = 87.0, F1 = 14.0. (Table 4) — Two-stage model with memory improves F1 and lowers perplexity relative to no-knowledge baseline, especially with predicted knowledge on seen topics.",
            "has_memory_ablation": true,
            "memory_effectiveness_findings": "A strong, separately optimized knowledge selector is vital: the two-stage approach performs best when the selector is optimized (improved perplexity and F1 with predicted knowledge). Knowledge Dropout improves robustness to selection errors. Generative models with memory generalize better to unseen topics than retrieval models because they can compose new utterances from retrieved facts. However, the generator benefits greatly when the selected knowledge is correct (gold knowledge gives large gains).",
            "memory_limitations": "Hard selection of a single sentence can bottleneck the generator if the selector errs; retrieved-but-incorrect knowledge leads to factual mistakes in generated replies; generator sometimes copies Wikipedia verbatim or produces formulaic responses; factual inaccuracies (wrong dates/names) are observed when retrieval is imperfect.",
            "comparison_with_other_memory_types": true,
            "best_memory_configuration": "Two-stage system with a strong Transformer-based knowledge selector (pretrained on Reddit) plus Knowledge Dropout for the generator gave the best predicted-knowledge performance; however, when given gold knowledge the End-to-end model performed better at using that knowledge (see End-to-end entry).",
            "uuid": "e2782.1",
            "source_info": {
                "paper_title": "Wizard of Wikipedia: Knowledge-Powered Conversational agents",
                "publication_date_yy_mm": "2018-09"
            }
        },
        {
            "name_short": "End-to-end Transformer MemNet (Generative)",
            "name_full": "End-to-end Generative Transformer Memory Network",
            "brief_description": "A generative Transformer model that encodes dialogue and all retrieved knowledge candidates in a shared encoder, computes a soft attention distribution over candidates to pick the best knowledge, concatenates the selected knowledge encoding with the dialogue encoding, and decodes the response; can be trained with an auxiliary supervised loss on knowledge selection.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "End-to-end Generative Transformer MemNet",
            "agent_description": "Shared Transformer encoder encodes dialogue and all candidate knowledge sentences; candidates are flattened to sentence vectors with length-normalized pooling; attention over candidates yields a soft selection (m_best), which is concatenated with dialogue encodings and passed to a Transformer decoder to generate the response. Optionally trained with an auxiliary cross-entropy loss forcing the attention to match human-chosen knowledge.",
            "base_model_size": null,
            "game_benchmark_name": "Wizard of Wikipedia",
            "game_description": "Knowledge-grounded multi-turn dialogue requiring selection of relevant Wikipedia sentences and generation of informative replies.",
            "uses_memory": true,
            "memory_type": "retrieval-augmented external knowledge memory with soft attention selection",
            "memory_structure": "IR-provided candidate sentences (flattened) encoded and pooled into sentence vectors; attention yields a soft-weighted selection of memory which is then used as full sequence encoding (concatenated to dialogue) for decoding.",
            "memory_content": "All IR-returned Wikipedia candidate sentences for the current turn (titles + sentences), encoded and pooled for attention-based selection.",
            "memory_capacity": "Operates over the IR candidates set (tens to low hundreds; ~61 candidates per turn reported); unlike two-stage it uses soft selection over all candidates.",
            "memory_retrieval_strategy": "IR (TF–IDF) followed by Transformer-based encoding and attention (soft selection) over candidate sentence vectors; optionally supervised with auxiliary loss to match human-chosen knowledge.",
            "memory_update_strategy": "Static KB; retrieval and attention applied each turn conditioned on dialogue context; no persistent episodic write mechanism.",
            "memory_usage_purpose": "Provide contextual factual grounding for the generative decoder, enabling it to attend to and copy from retrieved Wikipedia content while generating responses.",
            "performance_with_memory": "E2E (no auxiliary loss) Predicted-knowledge (Test Seen): PPL = 66.5, F1 = 15.9; with auxiliary loss Predicted-knowledge (Seen): PPL = 63.5, F1 = 16.9. Gold-knowledge (Seen) with auxiliary loss: PPL = 23.1, F1 = 35.5; Gold-knowledge (Unseen): PPL = 32.8, F1 = 32.2. (Table 4)",
            "performance_without_memory": "Generative Transformer (no knowledge) baseline: Gold-knowledge evaluation (Seen) PPL = 41.8, F1 = 17.8; Unseen PPL = 87.0, F1 = 14.0. (Table 4) — End-to-end model with auxiliary loss substantially outperforms no-knowledge generator when given gold knowledge.",
            "has_memory_ablation": true,
            "memory_effectiveness_findings": "Tightly integrating knowledge selection and generation (end-to-end) is beneficial when the selected knowledge is accurate: E2E outperforms two-stage when provided gold knowledge. Adding an auxiliary supervised loss on knowledge selection improves E2E performance across metrics. However, when selection must be predicted, two-stage (with a strong separate selector) performs better overall, indicating that selection quality is critical.",
            "memory_limitations": "Soft attention over many candidates is limited by the initial retrieval quality; E2E can underperform when the attention/selection is not strongly supervised. Like other models, it depends on IR returning relevant candidates; incorrect retrieval causes factual errors in outputs.",
            "comparison_with_other_memory_types": true,
            "best_memory_configuration": "End-to-end with auxiliary (knowledge) loss is best at using correct knowledge (gold) to maximize generation quality; for predicted selection, two-stage with a dedicated selector can be superior because it maximizes knowledge-selection accuracy.",
            "uuid": "e2782.2",
            "source_info": {
                "paper_title": "Wizard of Wikipedia: Knowledge-Powered Conversational agents",
                "publication_date_yy_mm": "2018-09"
            }
        },
        {
            "name_short": "BoW MemNet",
            "name_full": "Bag-of-Words Memory Network (Memory Network baseline)",
            "brief_description": "A baseline Memory Network that encodes candidate facts as bag-of-words vectors and attends over them to select knowledge or condition responses; used as a simpler non-Transformer baseline.",
            "citation_title": "End-to-end memory networks",
            "mention_or_use": "use",
            "agent_name": "BoW Memory Network (MemNet baseline)",
            "agent_description": "Classical Memory Network variant where knowledge sentences are encoded as bag-of-words (or bag-of-features) and attended with a memory-style architecture to score or retrieve relevant responses; used as baseline for knowledge selection and retrieval tasks.",
            "base_model_size": null,
            "game_benchmark_name": "Wizard of Wikipedia",
            "game_description": "Knowledge-grounded multi-turn dialogue with explicit human-selected knowledge annotations for supervised training and evaluation.",
            "uses_memory": true,
            "memory_type": "external memory (bag-of-words fact store)",
            "memory_structure": "Flat set of sentence-level memory vectors represented as bag-of-words feature vectors (no deep contextual encoding).",
            "memory_content": "Retrieved Wikipedia sentences represented as BoW vectors (same IR candidates used as other models).",
            "memory_capacity": "Operates over the IR candidate set (same tens-to-hundreds of candidates per turn).",
            "memory_retrieval_strategy": "IR to obtain candidates, then BoW-based memory network attention/scoring to pick top sentence(s) or to condition response retrieval/generation.",
            "memory_update_strategy": "Static KB; per-turn retrieval and attention; no incremental updates.",
            "memory_usage_purpose": "Provide factual grounding via simple fact encodings to aid selection/retrieval of relevant responses.",
            "performance_with_memory": "Knowledge selection: R@1 = 23.0, F1 = 36.3 (Seen); Retrieval full-task (Predicted Knowledge): R@1 = 71.3, F1 = 15.6 (Seen). (Tables 2 & 3)",
            "performance_without_memory": "BoW MemNet (no knowledge baseline for retrieval): R@1 = 56.1 (Seen predicted), F1 = 14.2 — adding knowledge improved performance (56.1 → 71.3 R@1). (Table 3)",
            "has_memory_ablation": true,
            "memory_effectiveness_findings": "Simple BoW memory provides substantial gains over no-knowledge baselines, demonstrating that explicit external facts help retrieval. However, contextual Transformer encodings with pretraining outperform BoW MemNet, especially on knowledge selection and unseen topics.",
            "memory_limitations": "BoW representations lack contextual encoding, perform poorly on unseen topics relative to Transformer encoders, and yield lower selection accuracy — they are less effective at capturing nuanced semantic matches than Transformer-based encoders.",
            "comparison_with_other_memory_types": true,
            "best_memory_configuration": "While BoW MemNet improves over no-knowledge baselines, the paper finds Transformer-based encoders (with Reddit pretraining and optional SQuAD multi-tasking) produce superior knowledge selection and retrieval performance.",
            "uuid": "e2782.3",
            "source_info": {
                "paper_title": "Wizard of Wikipedia: Knowledge-Powered Conversational agents",
                "publication_date_yy_mm": "2018-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "End-to-end memory networks",
            "rating": 2
        },
        {
            "paper_title": "Attention is all you need",
            "rating": 2
        },
        {
            "paper_title": "Reading wikipedia to answer open-domain questions",
            "rating": 2
        },
        {
            "paper_title": "A knowledge-grounded neural conversation model",
            "rating": 2
        },
        {
            "paper_title": "Extending neural generative conversational model using external knowledge sources",
            "rating": 2
        }
    ],
    "cost": 0.01758025,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>of WIKIPEDIA: <br> KNOWLEDGE-POWERED CONVERSATIONAL AGENTS</h1>
<p>Emily Dinan<em>, Stephen Roller</em>, Kurt Shuster*, Angela Fan, Michael Auli, Jason Weston</p>
<p>Facebook AI Research
{edinan,roller,kshuster,angelafan,michaelauli,jase}@fb.com</p>
<h4>Abstract</h4>
<p>In open-domain dialogue intelligent agents should exhibit the use of knowledge, however there are few convincing demonstrations of this to date. The most popular sequence to sequence models typically "generate and hope" generic utterances that can be memorized in the weights of the model when mapping from input utterance(s) to output, rather than employing recalled knowledge as context. Use of knowledge has so far proved difficult, in part because of the lack of a supervised learning benchmark task which exhibits knowledgeable open dialogue with clear grounding. To that end we collect and release a large dataset with conversations directly grounded with knowledge retrieved from Wikipedia. We then design architectures capable of retrieving knowledge, reading and conditioning on it, and finally generating natural responses. Our best performing dialogue models are able to conduct knowledgeable discussions on open-domain topics as evaluated by automatic metrics and human evaluations, while our new benchmark allows for measuring further improvements in this important research direction.</p>
<h2>1 INTRODUCTION</h2>
<p>Arguably, one of the key goals of AI, and the ultimate the goal of natural language research, is for humans to be able to talk to machines. In order to get close to this goal, machines must master a number of skills: to be able to comprehend language, employ memory to retain and recall knowledge, to reason about these concepts together, and finally output a response that both fulfills functional goals in the conversation while simultaneously being captivating to their human speaking partner. The current state-of-the-art approaches, sequence to sequence models of various kinds (Sutskever et al., 2014; Vinyals \&amp; Le, 2015; Serban et al., 2016; Vaswani et al., 2017) attempt to address some of these skills, but generally suffer from an inability to bring memory and knowledge to bear; as indicated by their name, they involve encoding an input sequence, providing limited reasoning by transforming their hidden state given the input, and then decoding to an output. To converse intelligently on a given topic, a speaker clearly needs knowledge of that subject, and it is our contention here that more direct knowledge memory mechanisms need to be employed. In this work we consider setups where this can be naturally measured and built.</p>
<p>We consider the task of open-domain dialogue, where two speakers conduct open-ended chit-chat given an initial starting topic, and during the course of the conversation the topic can broaden or focus on related themes. During such conversations, an interlocutor can glean new information and personal points of view from their speaking partner, while providing similarly themselves. This is a challenging task as it requires several components not found in many standard models. We design a set of architectures specifically for this goal that combine elements of Memory Network architectures (Sukhbaatar et al., 2015) to retrieve knowledge and read and condition on it, and Transformer architectures (Vaswani et al., 2017) to provide state-of-the-art text representations and sequence models for generating outputs, which we term Transformer Memory Networks.</p>
<p>As, to our knowledge, no public domain dataset of requisite scale exists, we build a supervised dataset of human-human conversations using crowd-sourced workers, first crowd-sourcing 1365 diverse discussion topics and then conversations involving 201, 999 utterances about them. Each</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>topic is connected to Wikipedia, and one of the humans (the wizard) is asked to link the knowledge they use to sentences from existing articles. In this way, we have both a natural way to train a knowledgeable conversation agent, by employing a memory component that can recall and ground on this existing text, and a natural way to evaluate models that we build, by assessing their ability at locating and using such knowledge.</p>
<p>Our Transformer Memory Network architectures, both in retrieval and generative versions, are tested in this setup using both automatic metrics and human evaluations. We show their ability to execute engaging knowledgeable conversations with humans, compared to a number of baselines such as standard Memory Networks or Transformers. Our new benchmark, publicly in ParlAI (http:// parl.ai/projects/wizard_of_wikipedia/), aims to encourage and measure further improvements in this important research direction.</p>
<h1>2 Related Work</h1>
<p>Many existing dialogue tasks do not study the use of knowledge explicitly. For example, popular chit-chat datasets such as Open-Subtitles (Vinyals \&amp; Le, 2015), Persona-Chat (Zhang et al., 2018) and Twitter (Sordoni et al., 2015) have tested the ability of sequence-to-sequence models that attend over the recent dialogue history, but do not attempt to recall long-term knowledge beyond encoding it directly into the weights of the feed-forward network.</p>
<p>In the area of goal-directed dialogue, separate from open domain chit-chat, such as airline (El Asri et al., 2017) or restaurant booking (Henderson et al., 2014; Wen et al., 2016; Bordes et al., 2017), knowledge conditioning is typically employed by allowing access to a database through API calls or otherwise. In contrast, our work investigates unstructured knowledge across a large, diverse set of topics potentially spanning all of Wikipedia.</p>
<p>In question answering one does not produce a dialogue response based on a conversation history, but a factual answer based on a question. In that case, it is clear that retrieving and conditioning knowledge is vital. For example, in SQuAD neural models have been developed that attend to a given paragraph from Wikipedia to answer questions (Rajpurkar et al., 2016), or Open-SQuAD which extends this to answering without being given the paragraph, instead performing retrieval over the entirety of Wikipedia (Chen et al., 2017). Recently, the QuAC dataset investigates similar themes, but as a sequence of questions and answers in dialogue form instead (Choi et al., 2018). In this work we do not address question answering, but focus on natural human dialogues which contain a diverse set of utterances, not just questions and answers.</p>
<p>The closest work to ours lies in the area of non-goal directed dialogue incorporating knowledge. The work of Dodge et al. (2016) employed Memory Networks to perform dialogue discussing movies in terms of recommendation and open-ended discussion from Reddit, conditioning on a structured knowledge base. Zhou et al. (2018) also links Reddit to structured knowledge. Both Parthasarathi \&amp; Pineau (2018) and Ghazvininejad et al. (2018) use unstructured text instead, as we do: the former to discuss news articles using Wikipedia summaries as knowledge, and the latter to discuss local businesses in two-turn dialogues using Foursquare tips as knowledge. Ghazvininejad et al. (2018) uses an extended Encoder-Decoder where the decoder is provided with an encoding of the context along with the external knowledge encoding. Neither involves dialogue authored with the given knowledge, so it is unclear when knowledge is useful or not. In contrast, in our task, we know the Wikipedia articles and sentences that ground crowdworkers dialogues. Model-wise, Parthasarathi \&amp; Pineau (2018) uses a Bag-of-Words Memory Network type fact encoder and an RNN decoder. Our work compares Memory Networks (Sukhbaatar et al., 2015) and Transformers which have been shown to be on-par or superior to RNN encoder-decoders (Vaswani et al., 2017), and develops an architecture that combines these approaches. Concurrently with our work Moghe et al. (2018) proposed a dataset based on the closed domain of movie chats. Our paper shows models working on full multi-turn dialogue in an open-domain setting, which to our knowledge was not shown before.</p>
<h2>3 WIZARD OF WIKIPEDIA</h2>
<p>We consider the following general open-domain dialogue setting: two participants engage in chitchat, with one of the participants selecting a beginning topic, and during the conversation the topic</p>
<p>is allowed to naturally change. The two participants, however, are not quite symmetric: one will play the role of a knowledgeable expert (which we refer to as the wizard) while the other is a curious learner (the apprentice).</p>
<p>Apprentice At each stage of the conversation the apprentice talks to the wizard freely, playing the role of a curious learner, eager to chat. Their goal is to go into depth about a chosen topic that interests themselves or their partner, while keeping the conversation engaging and fun. Note that the instruction to delve deeply into a topic makes this different to more "shallow" chit-chat tasks. In this task the use of knowledge is emphasized more.</p>
<p>Wizard The wizard is given the following instructions: "You have just met the other person, who seems quite curious, and you are eager to discuss a topic with them!" Their goal is to inform their conversation partner about a topic that one of them will choose. Crucially, the wizard has access to an information retrieval system that shows them paragraphs from Wikipedia possibly relevant to the conversation, which are unobserved by the apprentice. Before each conversation turn the wizard can read these paragraphs and then potentially base their next reply on that observed knowledge. Note, the wizard is particularly instructed not to simply parrot this knowledge, but to use it to craft a relevant reply, and to present any relevant knowledge in a fun and engaging way, if possible.</p>
<p>Conversation Flow The flow of the conversation thus takes place as follows.</p>
<ol>
<li>Either the wizard or apprentice is picked to choose the topic and speak first. The other player receives the topic information, and the conversation begins.</li>
<li>When the apprentice sends the wizard a message, the wizard is shown relevant knowledge (described below), and chooses a relevant sentence in order to construct a response, or else chooses the no sentence used option.</li>
<li>The Wizard responds to the apprentice basing their response on their chosen sentence.</li>
<li>The conversation repeats until one of the conversation partners ends the chat (after a minimum of 4 or 5 turns each, randomly chosen beforehand).</li>
</ol>
<p>After collecting data of such wizard-apprentice conversations between humans, the goal is to then replace the human wizard with a learned agent that will speak to a human apprentice instead, similar to the procedure in Wizard of Oz experiments (Bernsen et al., 2012).</p>
<p>Topics We crowd-sourced a set of 1365 natural, open-domain dialogue topics, each linked to a Wikipedia article. These include diverse topics such as commuting, Gouda cheese, music festivals, podcasts, bowling, and Arnold Schwarzenegger.</p>
<p>Knowledge Retrieval At each step of the dialogue the wizard has access to a set of passages of knowledge which may be relevant to the given dialogue context. While this is a potentially learnable part of the model, we required for this to be fixed so that we could present the results to the annotator when collecting the dataset. We thus used exactly the same retriever that is commonly used for the Open-SQuAD dataset in Chen et al. (2017). It uses a simple inverted index lookup followed by term vector model scoring. Articles and queries are compared as TF-IDF weighted bag-of-word and $n$-gram vectors, using the hashing trick. We retrieve the top 7 articles (first paragraph only) for the last two turns of dialogue (by wizard and apprentice) and the article (first 10 sentences only) for the original topic, and present these articles to the wizard as knowledge context, along with their titles. Note that while this system is used to build the dataset, a superior method can in principle be learned and used by a model at test time.</p>
<p>Knowledge Selection and Response Generation During data collection, the wizard can click on any of the retrieved article titles in the dialogue UI to expand that article, at which point they can click on a sentence that is most relevant to the response they want to make (only one article, and one sentence can be selected on any turn, for simplicity). If they see no relevant article or sentence they can choose no sentence used instead. The wizard then enters their response to the apprentice. An image of the Wizard's UI is shown in Appendix A.1.</p>
<p>Table 1: Dataset statistics of the Wizard of Wikipedia task.</p>
<table>
<thead>
<tr>
<th>Wizard of Wikipedia Task</th>
<th>Train</th>
<th>Valid</th>
<th>Test Seen</th>
<th>Test Unseen</th>
</tr>
</thead>
<tbody>
<tr>
<td>Number of Utterances</td>
<td>166,787</td>
<td>17,715</td>
<td>8,715</td>
<td>8,782</td>
</tr>
<tr>
<td>Number of Dialogues</td>
<td>18,430</td>
<td>1,948</td>
<td>965</td>
<td>968</td>
</tr>
<tr>
<td>Number of Topics</td>
<td>1,247</td>
<td>599</td>
<td>533</td>
<td>58</td>
</tr>
<tr>
<td>Average Turns per Dialogue</td>
<td>9.0</td>
<td>9.1</td>
<td>9.0</td>
<td>9.1</td>
</tr>
<tr>
<td>Knowledge Database</td>
<td>5.4M articles</td>
<td></td>
<td>93M sentences</td>
<td></td>
</tr>
</tbody>
</table>
<p>Final Dialogue Dataset The final dialogue dataset we collect consists of 22,311 dialogues with 201,999 turns, which we divide into 166,787 for train, 17,715 for validation, and 17,497 for test. The test set is split into two subsets, Test Seen and Test Unseen. Test Seen contains 533 overlapping topics with the training set with new dialogues about those topics. Test Unseen consists of 58 topics never seen before in train or validation. Overall data statistics can be found in Table 1, and further statistics and examples of collected conversations in Appendix A.2. We observe wizards and apprentices both asking and answering questions, and providing each other with a mixture of facts and personal feelings during their general discussion.</p>
<h1>4 MODELS</h1>
<p>In this work we consider learning dialogue models to replace the wizard in our learning tasks, i.e. the knowledgeable speaker. The dialogue model thus can have access to a knowledge source, in this case Wikipedia, to ground the conversation with. We thus develop extensions of the Memory Network (Sukhbaatar et al., 2015) and Transformer (Vaswani et al., 2017) models that can (i) retrieve from a large memory relevant information conditioned on the dialogue history, (ii) carefully read and attend over the retrieved set of knowledge, and then (iii) generate the next dialogue utterance. This model is then used consecutively on each turn to form an entire dialogue with a user.</p>
<p>We develop two classes of models capable of leveraging knowledge: (i) retrieval models that produce an output among a set of candidate responses (the set of utterances from the training set); and (ii) generative models that generate word-by-word (using a beam).</p>
<p>The input to either model is the same: at each dialogue turn where the model is intended to make a response, it is given the current dialogue context $x_{1}, \ldots, x_{t}$ of $t$ dialogue turns, where $x_{1}$ is always the initial starting topic (e.g. "Kurt Cobain"), and the remaining turns swap between the two speakers. The goal at each stage is to output the next utterance $x_{t+1}$.</p>
<p>Knowledge Retrieval We assume a large knowledge base (memory) $m_{1}, \ldots, m_{N}$ which is hierarchically organized into documents consisting of paragraphs and sentences. As it is infeasible for current neural attention techniques to operate on this scale, we use standard information retrieval (IR) techniques $(c=\operatorname{IR}(x, m))$ as a first step to return a smaller set of candidates $m_{c_{1}}, \ldots, m_{c_{K}}$ for fine-grained selection.</p>
<p>In our experiments, we use the IR system provided to the human annotators during dataset creation, detailed in Section 3. The retriever operates on the topic $\left(x_{1}\right)$ and the last two turns ( $x_{t}$ and $x_{t-1}$ ) if they exist, effectively calling the IR system three times with three different queries. Empirically, this provided better performance compared to merging into one query, likely because it can address quite different topics. We retrieve the top 7 articles (first paragraph only) for each lookup and then flatten all the results into separate sentences (i.e. remove the organization of sentences belonging to articles), but prepend every sentence with its article title. In this way the candidates $m_{c_{1}}, \ldots, m_{c_{K}}$ given to the neural model in the next stage can be attended to independently without having to deal with hierarchical issues.</p>
<p>Knowledge Attention We use an attention mechanism to perform fine-grained selection of which knowledge sentences will be used to produce the next turn of dialogue. Each sentence in the memory is independently encoded with a Transformer encoder (Vaswani et al., 2017), and the same Trans-</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Generative Transformer Memory Network. An IR system provides knowledge candidates from Wikipedia. Dialogue Context and Knowledge are encoded using a shared encoder. In the Two-stage model, the dialogue and knowledge are re-encoded after knowledge selection.
former is used to encode the dialogue context $x$. We then perform standard dot-product attention between the memory candidates and the dialogue context.</p>
<p>Utterance Prediction Given the hidden state derived from the memory attention process described above, the final stage is to predict the output utterance that will form the next dialogue turn.
We consider different variants of the two stages above, knowledge attention and utterance prediction, when considering retrieval and generative variants of our models. We will now detail these in turn.</p>
<h1>4.1 RETRIEVAL TRANSFORMER MEMORY NETWORK</h1>
<p>This model encodes each knowledge sentence $m_{c_{1}}, \ldots, m_{c_{K}}$ and the dialogue context $x$ with a Transformer, as described above. The final input encoding is calculated by performing dot-product attention over $\operatorname{enc}\left(m_{c_{1}}\right), \ldots, \operatorname{enc}\left(m_{c_{K}}\right)$ and adding the resulting weighted sum of these vectors to $\operatorname{enc}(x)$ to get the representation $\operatorname{rep}<em c__1="c_{1">{\mathrm{LHS}}\left(m</em>}}, \ldots, m_{c_{K}}, x\right)$. The candidate responses $r_{1}, \ldots, r_{L}$ are encoded with a separate Transformer to get $\operatorname{rep<em i="i">{\mathrm{RHS}}\left(r</em>$ where}\right)$ for each $i$. We choose as a response $r_{\ell</p>
<p>$$
\ell=\underset{i \in{1, \ldots, L}}{\arg \max } \frac{\operatorname{rep}<em c__1="c_{1">{\mathrm{LHS}}\left(m</em>}}, \cdots, m_{c_{K}}, x\right)}{\left|\operatorname{rep<em c__1="c_{1">{\mathrm{LHS}}\left(m</em>, x\right)\right|}}, \ldots, m_{c_{K}<em _mathrm_RHS="\mathrm{RHS">{2}} \bullet \frac{\operatorname{rep}</em>}}\left(r_{i}\right)}{\left|\operatorname{rep<em i="i">{\mathrm{RHS}}\left(r</em>
$$}\right)\right|_{2}</p>
<p>The model is trained to minimize the cross-entropy loss, where the negative candidates for each example are the responses to the other examples in the batch (Henderson et al., 2017).</p>
<h3>4.2 Generative Transformer Memory Network</h3>
<p>We consider two versions: a Two-stage and an End-to-end version. Both models find the most relevant piece of knowledge $m_{\text {best }}$, and then perform an encoding step by concatenating it with the dialogue context, allowing the decoder to attend over both the knowledge and dialogue when formulating its response. We employ a beam search of 5 to select our best response. All generative models employ BPE encoding (Sennrich et al., 2016), which we found effective at enabling generators to copy rare words from Wikipedia sentences (Fan et al., 2018).</p>
<p>In the End-to-end version, a shared Transformer encoder is used to encode all candidates $m_{c_{i}}$ and the dialogue history. The encoded candidates are flattened into vectors using the normalization from Cer et al. (2018) (summing, and normalizing by the square root of the sentence length in order to balance short and long sentences) to produce an attention prediction over the memory. The full sequence encoding of the single highest selected knowledge $m_{\text {best }}$ is concatenated with the encoding of the dialogue, and passed into a Transformer decoder. An illustration of our End-to-end model is shown in Figure 1. We train the model to minimize the negative log-likelihood of the response utterance. We can add additional supervision by forcing the knowledge selection to correctly choose the same knowledge candidate as the human wizard in the training set by adding an additional crossentropy loss over the knowledge attention, modulated by a weight $\lambda$ :</p>
<p>$$
\mathcal{L}=(1-\lambda) \mathcal{L}<em _knowledge="{knowledge" _text="\text">{\mathrm{NLL}}+\lambda \mathcal{L}</em>
$$}</p>
<p>In the Two-stage version, we employ two separately trained models for each of these two tasks, knowledge selection and utterance prediction. As the knowledge selection step creates a hard deci-</p>
<p>Table 2: Test performance of various methods on the Knowledge Selection Task. The models must select the gold knowledge sentences chosen by humans given the dialogue context.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: right;">Seen Test</th>
<th style="text-align: right;"></th>
<th style="text-align: right;">Unseen Test</th>
<th style="text-align: right;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Method</td>
<td style="text-align: right;">R@1</td>
<td style="text-align: right;">F1</td>
<td style="text-align: right;">R@1</td>
<td style="text-align: right;">F1</td>
</tr>
<tr>
<td style="text-align: left;">Random</td>
<td style="text-align: right;">2.7</td>
<td style="text-align: right;">13.5</td>
<td style="text-align: right;">2.3</td>
<td style="text-align: right;">13.1</td>
</tr>
<tr>
<td style="text-align: left;">IR baseline</td>
<td style="text-align: right;">5.8</td>
<td style="text-align: right;">21.8</td>
<td style="text-align: right;">7.6</td>
<td style="text-align: right;">23.5</td>
</tr>
<tr>
<td style="text-align: left;">BoW MemNet</td>
<td style="text-align: right;">23.0</td>
<td style="text-align: right;">36.3</td>
<td style="text-align: right;">8.9</td>
<td style="text-align: right;">22.9</td>
</tr>
<tr>
<td style="text-align: left;">Transformer</td>
<td style="text-align: right;">22.5</td>
<td style="text-align: right;">33.2</td>
<td style="text-align: right;">12.2</td>
<td style="text-align: right;">19.8</td>
</tr>
<tr>
<td style="text-align: left;">Transformer (+Reddit pretraining)</td>
<td style="text-align: right;">24.5</td>
<td style="text-align: right;">$\mathbf{3 6 . 4}$</td>
<td style="text-align: right;">$\mathbf{2 3 . 7}$</td>
<td style="text-align: right;">$\mathbf{3 5 . 8}$</td>
</tr>
<tr>
<td style="text-align: left;">Transformer (+Reddit pretraining, +SQuAD training)</td>
<td style="text-align: right;">$\mathbf{2 5 . 5}$</td>
<td style="text-align: right;">36.2</td>
<td style="text-align: right;">22.9</td>
<td style="text-align: right;">34.2</td>
</tr>
</tbody>
</table>
<p>sion influencing the output of the generator, we find maximizing the performance of this component to be vital. We can also improve performance of the decoder by employing knowledge dropout (K.D.), wherein we artificially prevent the model from attending to knowledge a fraction of the time during training. We find this helps the generator be more resilient to errors at the knowledge selection stage, and makes training faster. K. D. is a novel technique we propose here, however it is similar to many other dropout techniques, e.g. feature dropout used in Wu et al. (2017).</p>
<h1>5 EXPERIMENTS</h1>
<p>We describe each of our experimental setups and results. We first investigate the ability of our models to select knowledge appropriately, and then consider the full task of dialogue with knowledge.</p>
<h3>5.1 KNOWLEDGE SELECTION TASK</h3>
<p>Before looking at the full Wizard dialogue task, we assess the ability of models to predict the knowledge selected by human wizards in the dataset given the dialogue history. This will inform us of the feasibility of this task and the best models to use in a two-stage architecture. We compare Transformers against various baselines including a random baseline; an Information Retrieval (IR) baseline, which uses simple word overlap; and a Bag-of-Words Memory Network (Sukhbaatar et al., 2015). Where noted, the Transformer is pretrained on Reddit data (Mazaré et al., 2018), and fine-tuned for our task. The results are shown in Table 2 Transformers work best, as long as they are pretrained on a large dataset (Reddit), while multi-tasking on SQuAD provides marginal impact. Further analysis of this task using other models is provided in Appendix B.1. We use the best performing Transformer model reported here for our two-stage generative Memory Network in the full dialogue task.</p>
<h3>5.2 Full Task: Dialogue with Knowledge</h3>
<p>We evaluate our models on the full task of dialogue generation given knowledge in two settings: given the gold knowledge sentence chosen by a human, or where the model needs to predict which knowledge to use. We separately describe experiments for retrieval and generative models.</p>
<p>Retrieval Experiments We use similar baselines as in the knowledge selection experiments, but now also apply Transformer Memory Networks, which attend over knowledge. Models are evaluated measuring Recall@1 when ranking the gold response among 99 randomly chosen candidates, and unigram F1 of the model's prediction with the gold response. The results are shown in Table 3. We find that the addition of knowledge improves all models (improving Bow MemNet from 56 to 71 R@1 and the Transformer MemNet from 79 to 87 R@1) for predicted knowledge. Performance improves dramatically when models are provided gold knowledge, but otherwise retain similar trends.</p>
<p>Generative Experiments We compare our generative End-to-end and Two-stage Transformer Memory Network models to two more baselines: repeating the last utterance, and a generative Transformer model trained to respond to dialogue but without access to knowledge. Models are evaluated using perplexity (PPL) of the gold response and unigram F1.</p>
<p>Table 3: Retrieval methods on the full Wizard task. Models must select relevant knowledge and retrieve a response from the training set as a dialogue response. Using knowledge always helps, and the Transformer Memory Network with pretraining performs best.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Predicted Knowledge</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Gold Knowledge</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Test Seen</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Test Unseen</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Seen</td>
<td style="text-align: center;">Unseen</td>
</tr>
<tr>
<td style="text-align: left;">Method</td>
<td style="text-align: center;">R@1</td>
<td style="text-align: center;">F1</td>
<td style="text-align: center;">R@1</td>
<td style="text-align: center;">F1</td>
<td style="text-align: center;">R@1</td>
<td style="text-align: center;">R@1</td>
</tr>
<tr>
<td style="text-align: left;">Random</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">7.4</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">7.3</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">1.0</td>
</tr>
<tr>
<td style="text-align: left;">IR baseline</td>
<td style="text-align: center;">17.8</td>
<td style="text-align: center;">12.7</td>
<td style="text-align: center;">14.2</td>
<td style="text-align: center;">11.6</td>
<td style="text-align: center;">73.5</td>
<td style="text-align: center;">67.5</td>
</tr>
<tr>
<td style="text-align: left;">BoW MemNet (no knowledge)</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">14.2</td>
<td style="text-align: center;">28.8</td>
<td style="text-align: center;">11.6</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">28.8</td>
</tr>
<tr>
<td style="text-align: left;">BoW MemNet</td>
<td style="text-align: center;">71.3</td>
<td style="text-align: center;">$\mathbf{1 5 . 6}$</td>
<td style="text-align: center;">33.1</td>
<td style="text-align: center;">12.3</td>
<td style="text-align: center;">84.5</td>
<td style="text-align: center;">66.7</td>
</tr>
<tr>
<td style="text-align: left;">Transformer (no knowledge, w/o Reddit)</td>
<td style="text-align: center;">60.8</td>
<td style="text-align: center;">13.3</td>
<td style="text-align: center;">25.5</td>
<td style="text-align: center;">9.7</td>
<td style="text-align: center;">60.8</td>
<td style="text-align: center;">25.5</td>
</tr>
<tr>
<td style="text-align: left;">Transformer (no knowledge, w/ Reddit)</td>
<td style="text-align: center;">79.0</td>
<td style="text-align: center;">15.0</td>
<td style="text-align: center;">54.0</td>
<td style="text-align: center;">11.6</td>
<td style="text-align: center;">79.0</td>
<td style="text-align: center;">54.0</td>
</tr>
<tr>
<td style="text-align: left;">Transformer MemNet (w/ Reddit)</td>
<td style="text-align: center;">86.8</td>
<td style="text-align: center;">15.4</td>
<td style="text-align: center;">$\mathbf{6 9 . 8}$</td>
<td style="text-align: center;">$\mathbf{1 2 . 4}$</td>
<td style="text-align: center;">91.6</td>
<td style="text-align: center;">82.3</td>
</tr>
<tr>
<td style="text-align: left;">Transformer MemNet (w/ Reddit+SQuAD)</td>
<td style="text-align: center;">$\mathbf{8 7 . 4}$</td>
<td style="text-align: center;">15.4</td>
<td style="text-align: center;">$\mathbf{6 9 . 8}$</td>
<td style="text-align: center;">$\mathbf{1 2 . 4}$</td>
<td style="text-align: center;">$\mathbf{9 2 . 3}$</td>
<td style="text-align: center;">$\mathbf{8 3 . 1}$</td>
</tr>
</tbody>
</table>
<p>Table 4: Generative models on the full Wizard Task. The Two-stage model performs best using predicted knowledge, while the End-to-end (E2E) model performs best with gold knowledge.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Predicted Knowledge</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Gold Knowledge</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Test Seen</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Test Unseen</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Test Seen</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Test Unseen</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">Method</td>
<td style="text-align: center;">PPL</td>
<td style="text-align: center;">F1</td>
<td style="text-align: center;">PPL</td>
<td style="text-align: center;">F1</td>
<td style="text-align: center;">PPL</td>
<td style="text-align: center;">F1</td>
<td style="text-align: center;">PPL</td>
<td style="text-align: center;">F1</td>
</tr>
<tr>
<td style="text-align: left;">Repeat last utterance</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">13.8</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">13.7</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">13.8</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">13.7</td>
</tr>
<tr>
<td style="text-align: left;">Transformer (no knowledge)</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">41.8</td>
<td style="text-align: center;">17.8</td>
<td style="text-align: center;">87.0</td>
<td style="text-align: center;">14.0</td>
</tr>
<tr>
<td style="text-align: left;">E2E Transformer MemNet (no auxiliary loss)</td>
<td style="text-align: center;">66.5</td>
<td style="text-align: center;">15.9</td>
<td style="text-align: center;">103.6</td>
<td style="text-align: center;">14.3</td>
<td style="text-align: center;">24.2</td>
<td style="text-align: center;">33.6</td>
<td style="text-align: center;">35.5</td>
<td style="text-align: center;">29.5</td>
</tr>
<tr>
<td style="text-align: left;">E2E Transformer MemNet (w/ auxiliary loss)</td>
<td style="text-align: center;">63.5</td>
<td style="text-align: center;">16.9</td>
<td style="text-align: center;">97.3</td>
<td style="text-align: center;">14.4</td>
<td style="text-align: center;">$\mathbf{2 3 . 1}$</td>
<td style="text-align: center;">$\mathbf{3 5 . 5}$</td>
<td style="text-align: center;">$\mathbf{3 2 . 8}$</td>
<td style="text-align: center;">$\mathbf{3 2 . 2}$</td>
</tr>
<tr>
<td style="text-align: left;">Two-Stage Transformer MemNet</td>
<td style="text-align: center;">54.8</td>
<td style="text-align: center;">18.6</td>
<td style="text-align: center;">88.5</td>
<td style="text-align: center;">$\mathbf{1 7 . 4}$</td>
<td style="text-align: center;">30.0</td>
<td style="text-align: center;">30.7</td>
<td style="text-align: center;">42.7</td>
<td style="text-align: center;">28.6</td>
</tr>
<tr>
<td style="text-align: left;">Two-Stage Transformer MemNet (w/ K.D.)</td>
<td style="text-align: center;">$\mathbf{4 6 . 5}$</td>
<td style="text-align: center;">$\mathbf{1 8 . 9}$</td>
<td style="text-align: center;">$\mathbf{8 4 . 8}$</td>
<td style="text-align: center;">17.3</td>
<td style="text-align: center;">28.6</td>
<td style="text-align: center;">30.6</td>
<td style="text-align: center;">43.7</td>
<td style="text-align: center;">28.0</td>
</tr>
</tbody>
</table>
<p>Table 5: Human Experiments. Evaluations of the best generative and retrieval models on full dialogues with humans. Human ratings are reported as mean (stddev). Wiki F1 measures unigram overlap with the Wikipedia entry for the chosen topic, a measure of knowledge used in conversations.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Seen</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Unseen</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Method</td>
<td style="text-align: center;">Rating</td>
<td style="text-align: center;">Wiki F1</td>
<td style="text-align: center;">Rating</td>
<td style="text-align: center;">Wiki F1</td>
</tr>
<tr>
<td style="text-align: left;">Human Performance</td>
<td style="text-align: center;">$4.13(1.08)$</td>
<td style="text-align: center;">11.1</td>
<td style="text-align: center;">$4.34(0.98)$</td>
<td style="text-align: center;">10.6</td>
</tr>
<tr>
<td style="text-align: left;">Retrieval Transformer (no knowledge)</td>
<td style="text-align: center;">$3.33(1.30)$</td>
<td style="text-align: center;">19.8</td>
<td style="text-align: center;">$3.12(1.34)$</td>
<td style="text-align: center;">13.7</td>
</tr>
<tr>
<td style="text-align: left;">Generative Transformer (no knowledge)</td>
<td style="text-align: center;">$2.11(1.11)$</td>
<td style="text-align: center;">15.3</td>
<td style="text-align: center;">$2.54(1.38)$</td>
<td style="text-align: center;">10.1</td>
</tr>
<tr>
<td style="text-align: left;">Retrieval Transformer MemNet</td>
<td style="text-align: center;">$3.43(1.10)$</td>
<td style="text-align: center;">23.4</td>
<td style="text-align: center;">$3.14(1.31)$</td>
<td style="text-align: center;">16.3</td>
</tr>
<tr>
<td style="text-align: left;">Two-Stage Generative Transformer MemNet</td>
<td style="text-align: center;">$2.92(1.33)$</td>
<td style="text-align: center;">30.0</td>
<td style="text-align: center;">$2.93(1.30)$</td>
<td style="text-align: center;">26.2</td>
</tr>
</tbody>
</table>
<p>The results are given in Table 4. Our experiments show that both the End-to-end and Two-stage models employ the knowledge in their response predictions, as they outperform their counterpart Transformer without knowledge, and demonstrate substantial improvements when provided the gold knowledge. While the Two-stage model produces significantly stronger perplexity and F1 scores using the predicted knowledge, the End-to-end model outperforms the Two-stage model in the gold knowledge experiments. This suggests that the Two-stage model benefits from the strong knowledge selection module (Section 5.1), but that the End-to-end model is better at employing the selected knowledge. Furthermore, we find that the additional knowledge selection supervision (auxiliary loss) in the End-to-end model improves it on every metric, suggesting that tightly integrating these tasks is beneficial. Knowledge dropout (K. D.) also helps (compare last two rows). More evidence</p>
<h1>Model: Retrieval Transformer MemNet</h1>
<p>Topic: E-book (seen)
Human: i do not know why, but I have never gotten into E-books
Model: Same here. I have a kindle, but I don't use it for books. It's nicer to hold a real book and turn pages.
Human: yes, i like the physical feel and smell of a real book
Model: I actually had a Nook e-book where you had to download the e-book after selecting it online. I grew out of it, I prefer paper books also.
Human: i tried e-books but I do not like reading on a screen, its disorientated for me
Model: Yes, reading a book on a tablet just isn't the same!
Human: plus I like owning the physical copy of a real book, I feel like I own it
Model: I prefer print and newsreels.
Topic: Toga party (seen)
Model: I love toga parties! I usually make my toga out of a bed sheet and wear my sandals.
Human: Me too!!! I usually use some flip flops and my blanket!
Model: Toga parties typically have games involving kegs and excessive drinking!
Human: Yeah! And getting to wear funny outfits and a crown of leaves!
Model: I love me some Toga Parties!
Human: I love me some too!
Model: Toga parties are so much fun with the Roman or Greek theme.
Human: Yeah! I especially like Greek themes
Model: Two-Stage Generative Transformer MemNet
Topic: Shower (unseen)
Human: So I've been looking for a better showerhead with more water pressure for my shower.
Model: I love pressure-versed water at nearly constant temperature to a shower
Human: That sounds pretty great! Love those rainshower showers!
Model: the ancient greeks were the first people to have showers.
Human: Well I knew they were good for something.
Model: the original showers were neither indoor structures nor man made but were common.
Human: Ah that sounds intimidating!
Model: it is required manual transport of both fresh and waste water.
Figure 2: Selected conversations between humans and models.
for this is shown in Appendix B.1. Lastly, we note that both Two-stage models give higher F1 scores than any of the retrieval models shown in Table 3.</p>
<h3>5.3 Human Evaluation</h3>
<p>We perform human evaluation of our models using crowd-sourced workers. Humans are paired with our models and asked to chat about a specific topic (given a choice of 2-3 topics) for 3-5 dialogue turns. Following their conversation, the humans are asked to rate their dialogue partner on a scale of $1-5$, with the rating indicating how much they "liked" the conversation ( 5 is best), which we refer to as the engagingness rating. Using the collected conversations, we also calculate a metric we call the Wiki F1 sore: the F1 overlap of the model's utterances with the first 10 sentences of the Wikipedia page for the chosen topic as a proxy for how much knowledge the model exhibits. We seek a model that can be simultaneously engaging and knowledgeable, hence we would like to maximize both these metrics ${ }^{1}$. For comparison, we also collect 100 human-human conversations, with only one human choosing the topic and performing evaluation. In total, we collect a total of 546 conversations with ratings from 464 distinct workers. These results are shown in Table 5.</p>
<p>We find that the retrieval models significantly outperform the generative models on the human engagingness evaluation(Student's t-test, $p&lt;.05$ ). The human engagingness differences between retriever models with and without knowledge are not significant, but note they both trend toward use of knowledge due to the candidate sentences retrieved, with the knowledgeable version obtaining significantly higher Wiki F1 scores in both seen and unseen test sets.</p>
<p>For the generative models, we find human engagingness ratings are significantly improved by the use of knowledge ( $p&lt;.01$ ). The significantly higher Wiki F1 scores indicate that (i) these models convey more knowledge than their counterparts without knowledge conditioning; and (ii) on both seen and unseen sets they convey more knowledge than the retrieval models. In particular, on unseen</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>data the gap between retrieval and generative models is larger. This is understandable, as retrieval models are limited to producing a response from the training set where the unseen topic did not appear.</p>
<p>There is still a considerable gap to human ratings of other humans compared to all our models (first row of Table 5). Figure 2 shows example conversations with the retrieval and generative models. Additional analysis and examples can be found in Appendix B. 3 and C.</p>
<h1>6 CONCLUSION</h1>
<p>In this work we build dialogue agents which are able to employ large memory systems containing encyclopedic knowledge about the world in order to conduct engaging open-domain conversations. We develop a set of architectures, Transformer Memory Network models, that are capable of retrieving and attending to such knowledge and outputting a response, either in retrieval or generative modes. To train and evaluate such models, we collect the Wizard of Wikipedia dataset, a large collection of open-domain dialogues grounded by Wikipedia knowledge, and demonstrated the effectiveness of our models in automatic and human experiments. Our new publicly available benchmark aims to encourage further model exploration, and we expect such efforts will result in significant advances in this important research direction.</p>
<p>There is much future work to be explored using our task and dataset. Some of these include: (i) bridging the gap between the engagingness of retrieval responses versus the ability of generative models to work on new knowledge and topics, (ii) learning to retrieve and reason simultaneously rather than using a separate IR component; and (iii) investigating the relationship between knowledge-grounded dialogue and existing QA tasks which also employ such IR systems. The aim is for those strands to come together to obtain an engaging and knowledgeable conversational agent.</p>
<h2>REFERENCES</h2>
<p>Niels O Bernsen, Hans Dybkjær, and Laila Dybkjær. Designing interactive speech systems: From first ideas to user testing. Springer Science \&amp; Business Media, 2012.</p>
<p>Antoine Bordes, Y-Lan Boureau, and Jason Weston. Learning end-to-end goal-oriented dialog. In Proceedings of the International Conference on Learning Representations (ICLR), 2017.</p>
<p>Daniel Cer, Yinfei Yang, Sheng yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope, and Ray Kurzweil. Universal sentence encoder. arXiv preprint arXiv:1803.11175, 2018.</p>
<p>Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. Reading wikipedia to answer opendomain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pp. 1870-1879. Association for Computational Linguistics, 2017.</p>
<p>Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang, and Luke Zettlemoyer. QuAC: Question answering in context. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 2018.</p>
<p>Jesse Dodge, Andreea Gane, Xiang Zhang, Antoine Bordes, Sumit Chopra, Alexander Miller, Arthur Szlam, and Jason Weston. Evaluating prerequisite qualities for learning end-to-end dialog systems. In Proceedings of the International Conference on Learning Representations (ICLR), 2016.</p>
<p>Layla El Asri, Hannes Schulz, Shikhar Sharma, Jeremie Zumer, Justin Harris, Emery Fine, Rahul Mehrotra, and Kaheer Suleman. Frames: a corpus for adding memory to goal-oriented dialogue systems. In Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue, pp. 207-219, Saarbrücken, Germany, August 2017. Association for Computational Linguistics.</p>
<p>Angela Fan, David Grangier, and Michael Auli. Controllable abstractive summarization. In Proceedings of the 2nd Workshop on Neural Machine Translation and Generation, pp. 45-54. Association for Computational Linguistics, 2018.</p>
<p>Marjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao, Wen-tau Yih, and Michel Galley. A knowledge-grounded neural conversation model. In Proceedings of the Conference on Association for the Advancement of Artificial Intelligence (AAAI), 2018.</p>
<p>Matthew Henderson, Blaise Thomson, and Jason D Williams. The second dialog state tracking challenge. In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pp. 263-272, 2014.</p>
<p>Matthew Henderson, Rami Al-Rfou, Brian Strope, Yun-hsuan Sung, L'aszl'o Luk'acs, Ruiqi Guo, Sanjiv Kumar, Balint Miklos, and Ray Kurzweil. Efficient Natural Language Response Suggestion for Smart Reply. arXiv preprint arXiv:1705.00652, 2017.</p>
<p>Jiwei Li, Will Monroe, and Daniel Jurafsky. A simple, fast diverse decoding algorithm for neural generation. arXiv preprint arXiv:1611.08562, 2016.</p>
<p>Pierre-Emmanuel Mazaré, Samuel Humeau, Martin Raison, and Antoine Bordes. Training millions of personalized dialogue agents. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 2018. Association for Computational Linguistics.</p>
<p>Nikita Moghe, Siddhartha Arora, Suman Banerjee, and Mitesh M. Khapra. Towards exploiting background knowledge for building conversation systems. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 2322-2332. Association for Computational Linguistics, 2018. URL http://aclweb.org/anthology/D18-1255.</p>
<p>Prasanna Parthasarathi and Joelle Pineau. Extending neural generative conversational model using external knowledge sources. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 2018.</p>
<p>Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. SQuAD: 100,000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pp. 2383-2392, Austin, Texas, November 2016. Association for Computational Linguistics.</p>
<p>Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with subword units. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pp. 1715-1725, Berlin, Germany, August 2016. Association for Computational Linguistics.</p>
<p>Iulian Vlad Serban, Ryan Lowe, Laurent Charlin, and Joelle Pineau. Generative deep neural networks for dialogue: A short review. arXiv preprint arXiv:1611.06216, 2016.</p>
<p>Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji, Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. A neural network approach to context-sensitive generation of conversational responses. arXiv preprint arXiv:1506.06714, 2015.</p>
<p>Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al. End-to-end memory networks. In Advances in Neural Information Processing Systems, pp. 2440-2448, 2015.</p>
<p>Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems, pp. 3104-3112, 2014.</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, pp. 5998-6008, 2017.</p>
<p>Ashwin K. Vijayakumar, Michael Cogswell, Ramprasaath R. Selvaraju, Qing Sun, Stefan Lee, David J. Crandall, and Dhruv Batra. Diverse beam search: Decoding diverse solutions from neural sequence models. arXiv preprint arXiv:1610.02424, 2016.</p>
<p>Oriol Vinyals and Quoc Le. A neural conversational model. In Proceedings of the 31st International Conference on Machine Learning, Deep Learning Workshop, Lille, France, 2015.</p>
<p>Tsung-Hsien Wen, David Vandyke, Nikola Mrksic, Milica Gasic, Lina M Rojas-Barahona, Pei-Hao Su, Stefan Ultes, and Steve Young. A network-based end-to-end trainable task-oriented dialogue system. arXiv preprint arXiv:1604.04562, 2016.</p>
<p>Ledell Wu, Adam Fisch, Sumit Chopra, Keith Adams, Antoine Bordes, and Jason Weston. Starspace: Embed all the things! arXiv preprint arXiv:1709.03856, 2017.</p>
<p>Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. Personalizing dialogue agents: I have a dog, do you have pets too? In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pp. 2204-2213, Melbourne, Australia, July 2018. Association for Computational Linguistics.</p>
<p>Hao Zhou, Tom Young, Minlie Huang, Haizhou Zhao, Jingfang Xu, and Xiaoyan Zhu. Commonsense knowledge aware conversation generation with graph attention. In Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI), pp. 4623-4629. International Joint Conferences on Artificial Intelligence Organization, 72018.</p>
<h1>A DATASET COLLECTION</h1>
<h2>A. 1 HUMAN ANNOTATION INTERFACE (FOR WIZARD)</h2>
<h2>Chat with Knowledge!</h2>
<h2>You have just met the other person, who seems quite curious, and you are eager to discuss a topic with them!</h2>
<p>You will try to inform your conversation partner about a topic that one of you will choose. After a topic is chosen, you will receive information about that topic that will be visible throughout the chat.</p>
<h2>Passage for Chosen Topic</h2>
<ul>
<li>C) Cupcake</li>
</ul>
<p>A cupcake (also British English: fairy cake; Hiberno-English: bun; Australian English: fairy cake or patty cake) is a small cake designed to serve one person, which may be baked in a small thin paper or aluminum cup.</p>
<p>As with larger cakes, icing and other cake decorations such as fruit and candy may be applied.</p>
<p>The earliest extant description of what is now often called a cupcake was in 1796, when a recipe for "a light cake to bake in small cups" was written in "American Cookery" by Amelia Simmons.</p>
<p>The earliest extant documentation of the term "cupcake"</p>
<h2>Relevant Information</h2>
<p>Click on a topic below to expand it. Then, click the checkbox next to the sentence that you use to craft your response, or check 'No Sentence Used.'
No Sentence Used</p>
<h2>Information about your partner's message</h2>
<ul>
<li>Cupcake</li>
<li>(1) Hostess CupCake</li>
<li>Hostess CupCake is a brand of snack cake formerly produced and distributed by Hostess Brands and currently owned by private equity firms Apollo Global Management and Metropoulos \&amp; Co. Its most common form is a chocolate cupcake with chocolate icing and vanilla creme filling, with eight distinctive white squiggles across the top.
However, other flavors have been available at times.
It has been claimed to be the first commercially produced cupcake and has become an iconic American brand.</li>
</ul>
<h2>Information about your message</h2>
<ul>
<li>Fartey's \&amp; Sathers Candy Company</li>
<li>Hi-Chew</li>
<li>Candy</li>
<li>Field ration</li>
<li>Candy Candy</li>
<li>Hi-5 (Australian band)</li>
<li>Drum kit</li>
</ul>
<p>SYSTEM: Your partner has selected the topic. Please look to the left to find the relevant information for this topic.</p>
<p>Partner: Hi! Do you have any good recipes for cupcakes?</p>
<p>SYSTEM: Please take a look at the relevant information to your left and check the appropriate sentence before answering, but try not to copy the sentence as your whole response.</p>
<p>You: Hi! You can add fruit and candy to make them even more delicious!</p>
<p>Partner: That's cool! What's your favorite cupcake?</p>
<p>SYSTEM: Please take a look at the relevant information to your left and check the appropriate sentence before answering, but try not to copy the sentence as your whole response.</p>
<p>I love Hostess cupcakes - they have chocolate icing and vanilla creme filling</p>
<h1>A. 2 Wizard of Wikipedia Examples</h1>
<p>Topic: Lifeguard
Apprentice: So I am a lifeguard. Know anything about saving lives in water?
Wizard: I'm impressed! It's a big responsibility to supervise other people's safety in the water! Tell me more.
Apprentice: Well, I help make sure people do not drown or get injured while in or near the water!
Knowledge: A lifeguard is a rescuer who supervises the safety and rescue of swimmers, surfers, ... Lifeguards are strong swimmers and trained in CPR/AED first aid, certified in water ...</p>
<p>In some areas, the lifeguard service also carries out mountain rescues, or may function as the primary EMS provider.
Wizard: I've heard that in some places, lifeguards also help with other sorts of emergencies, like mountain rescues!
Is that part of your job too?
Apprentice: I have! I feel like you know much about this! What brings you to know so much?
Wizard: Oh, that's about the extent of my knowledge. I've just been around beaches and I've always admired lifeguards. I'm not a super strong swimmer myself.
Topic: Armadillo
Wizard: I love animals and think armadillos are awesome with their leathery shell.
Apprentice: I don't think I've ever seen an armadillo in real life!
Wizard: I've seen them at the zoo. Armadillo means little armored one in Spanish.
Apprentice: Are they native to a Spanish-speaking part of the world?
Knowledge: Armadillos are New World placental mammals in the order Cingulata ...
The word "armadillo" means "little armoured one" in Spanish.
The nine-banded armadillo ("Dasypus novemcinctus"), or the nine-banded, long-nosed armadillo, is a medium-sized mammal found in North, Central, and South America.
Wizard: Yes, they are most commonly found in North, Central, and South America
Topic: Ice cream
Wizard: I just love ice cream. I love the types with fruits and flavours. Do you like ice cream?
Apprentice: I love Ice cream as much as any one. I especially like Gelato, foreign ice cream!
Knowledge Ice cream is a sweetened frozen food typically eaten as a snack or dessert....
It is usually made from dairy products, such as milk and cream, and ...
Bacon ice cream (or bacon-and-egg ice cream) is an ice cream generally created by adding bacon to egg custard and freezing the mixture.
Wizard: Me too. There are some strange combinations though, have you heard of bacon ice cream? where they add bacon and even egg custard to the freezing mixture!
Apprentice: Surprisingly bacon ice cream doesn't surprise me. That doesn't sound appealing to me, but perhaps it could be delicious...</p>
<p>Figure 3: The Wizard of Wikipedia dataset. Examples of collected conversations from the dataset, where both wizard and apprentice are humans. The wizard has access to an information retrieval system over Wikipedia, so that they can ask and answer questions, and make statements relevant to the discussion. For each utterance, knowledge retrieval is performed based on dialogue history, giving $\sim 61$ knowledge candidates per turn, with wizards clicking no sentence used $6.2 \%$ of the time. Assuming that a question contains a question mark or begins with 'how', 'why', 'who', 'where', 'what' or 'when', in the dataset Apprentices ask questions in $13.9 \%$ of training set utterances, and answer questions (i.e., the Wizard has asked a question) $39.5 \%$ of the time, while saying new or follow-on statements (neither asking nor answering a question) $49.3 \%$ of the time. Hence, the wizard and apprentice conduct conversations with a variety of dialogue acts.</p>
<h2>A. 3 Topic Selection</h2>
<p>To choose between topics that are natural we employed the existing Persona-Chat dataset (Zhang et al., 2018) where crowdworkers where asked to create personas of typical speakers. There are</p>
<p>$\sim 1000$ personas, each of which consists of 4-5 sentences describing that person's interests, e.g. "I love watching Game of Thrones", "I like to eat cheetos" and "I recently got a cat". These can thus naturally be seen as topics of interest, and using another set of annotators we mapped each sentence to 1 or more relevant Wikipedia pages, if possible, e.g. "Ariel is my favorite princess" was labeled with the Wikipedia page for The Little Mermaid. As some sentences are harder to connect with Wikipedia, e.g. "I am witty", they are left unlabeled. We thus obtain 1,431 topics in total to use for our task. We retain the persona topic sets and thus present 2-3 related topic choices as conversation starters per dialogue during data collection.</p>
<h1>B ADDITIONAL EXPERIMENTS</h1>
<h2>B. 1 KNOWLEDGE SELECTION</h2>
<p>Table 6: Test performance of the Knowledge Selection Tasks. We also tested the performance of our models trained to do the full dialogue task (see Section 5.2) on the knowledge selection task. For our retrieval system, this refers to the performance of the knowledge attention. The results show that our retrieval system could be improved, and the auxiliary loss clearly helps the generative models.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: right;">Seen Test</th>
<th style="text-align: right;"></th>
<th style="text-align: right;">Unseen Test</th>
<th style="text-align: right;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Method</td>
<td style="text-align: right;">R@1</td>
<td style="text-align: right;">F1</td>
<td style="text-align: right;">R@1</td>
<td style="text-align: right;">F1</td>
</tr>
<tr>
<td style="text-align: left;">Random</td>
<td style="text-align: right;">2.7</td>
<td style="text-align: right;">13.5</td>
<td style="text-align: right;">2.3</td>
<td style="text-align: right;">13.1</td>
</tr>
<tr>
<td style="text-align: left;">IR baseline</td>
<td style="text-align: right;">5.8</td>
<td style="text-align: right;">21.8</td>
<td style="text-align: right;">7.6</td>
<td style="text-align: right;">23.5</td>
</tr>
<tr>
<td style="text-align: left;">BoW MemNet</td>
<td style="text-align: right;">23.0</td>
<td style="text-align: right;">36.3</td>
<td style="text-align: right;">8.9</td>
<td style="text-align: right;">22.9</td>
</tr>
<tr>
<td style="text-align: left;">Transformer</td>
<td style="text-align: right;">22.5</td>
<td style="text-align: right;">33.2</td>
<td style="text-align: right;">12.2</td>
<td style="text-align: right;">19.8</td>
</tr>
<tr>
<td style="text-align: left;">Transformer (+Reddit pretraining)</td>
<td style="text-align: right;">24.5</td>
<td style="text-align: right;">$\mathbf{3 6 . 4}$</td>
<td style="text-align: right;">$\mathbf{2 3 . 7}$</td>
<td style="text-align: right;">$\mathbf{3 5 . 8}$</td>
</tr>
<tr>
<td style="text-align: left;">Transformer (+Reddit pretraining, +SQuAD training)</td>
<td style="text-align: right;">$\mathbf{2 5 . 5}$</td>
<td style="text-align: right;">36.2</td>
<td style="text-align: right;">22.9</td>
<td style="text-align: right;">34.2</td>
</tr>
<tr>
<td style="text-align: left;">Retrieval Transformer MemNet (no auxiliary loss)</td>
<td style="text-align: right;">12.9</td>
<td style="text-align: right;">24.6</td>
<td style="text-align: right;">14.6</td>
<td style="text-align: right;">26.3</td>
</tr>
<tr>
<td style="text-align: left;">Generative E2E Transformer MemNet (no auxiliary loss)</td>
<td style="text-align: right;">13.4</td>
<td style="text-align: right;">28.3</td>
<td style="text-align: right;">11.8</td>
<td style="text-align: right;">25.9</td>
</tr>
<tr>
<td style="text-align: left;">Generative E2E Transformer MemNet (w/ auxiliary loss)</td>
<td style="text-align: right;">21.1</td>
<td style="text-align: right;">32.8</td>
<td style="text-align: right;">14.3</td>
<td style="text-align: right;">22.8</td>
</tr>
</tbody>
</table>
<h2>B. 2 Full Dialogue with Retrieval</h2>
<h2>B. 3 HUMAN EXPERIMENTS</h2>
<h2>C ERror ANALYSIS</h2>
<p>We perform an analysis of the dialogues produced from the human evaluation experiments detailed in Section 5.3. We sample 20 conversations from each experimental setting, split between seen and unseen. Conversations are re-tokenized and lowercased to reduce superficial differences between models, and then analyzed in a single-blind setup. We note of common errors and behaviors exhibited in each of the different conversations.</p>
<p>In general, the human-human conversations are starkly different than any of the bot conversations - humans tend to have more small talk, or use the topic of discussion as a mere icebreaker, with neither human behaving as a wizard. This is in contrast to human-human conversations from the Wizard dataset itself, where one human has access to Wikipedia, and the conversation becomes more grounded in factual sentences. Similarly, all models attempt to play the role of wizard and produce more factual sentences too. In some rounds, humans treat the bot as a sort of question-answer machine, suggesting that the models could be improved by additionally employing SQuAD-like training data.</p>
<p>The retriever without knowledge is particularly prone to non sequiturs, or rapidly changing the subject. During unseen conversations, it is especially likely to discuss something other than the chosen topic. In contrast, the retriever with knowledge tends to stick to the chosen topic strongly, but has difficulty if the human changes the subject. Frequently in unseen topics, the retriever with</p>
<p>Table 7: Retrieval methods on the full Wizard task. In addition to the models we tested in the paper, we also tested a two-stage retrieval system in which we used our best-performing model on the knowledge selection task to choose a single knowledge sentence to condition on for the dialogue retrieval task. This outperformed our best retrieval method in terms of F1 but not not in terms of Recall@1. Furthermore, we compared these results to a two-stage retrieval system in which the dialogue retrieval module is optimized for seeing the gold chosen knowledge sentence. The performance of this system on the gold knowledge task suggests that the retrieval system could be improved by increasing performance on the knowledge selection subtask.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Predicted Knowledge</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Gold Knowledge</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Test Seen</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Test Unseen</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Seen</td>
<td style="text-align: center;">Unseen</td>
</tr>
<tr>
<td style="text-align: left;">Method</td>
<td style="text-align: center;">R@1</td>
<td style="text-align: center;">F1</td>
<td style="text-align: center;">R@1</td>
<td style="text-align: center;">F1</td>
<td style="text-align: center;">R@1</td>
<td style="text-align: center;">R@1</td>
</tr>
<tr>
<td style="text-align: left;">Random</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">7.4</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">7.3</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">1.0</td>
</tr>
<tr>
<td style="text-align: left;">IR baseline</td>
<td style="text-align: center;">17.8</td>
<td style="text-align: center;">12.7</td>
<td style="text-align: center;">14.2</td>
<td style="text-align: center;">11.6</td>
<td style="text-align: center;">73.5</td>
<td style="text-align: center;">67.5</td>
</tr>
<tr>
<td style="text-align: left;">BoW MemNet (no knowledge)</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">14.2</td>
<td style="text-align: center;">28.8</td>
<td style="text-align: center;">11.6</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">28.8</td>
</tr>
<tr>
<td style="text-align: left;">BoW MemNet</td>
<td style="text-align: center;">71.3</td>
<td style="text-align: center;">15.6</td>
<td style="text-align: center;">33.1</td>
<td style="text-align: center;">12.3</td>
<td style="text-align: center;">84.5</td>
<td style="text-align: center;">66.7</td>
</tr>
<tr>
<td style="text-align: left;">Transformer (no knowledge, w/o Reddit)</td>
<td style="text-align: center;">60.8</td>
<td style="text-align: center;">13.3</td>
<td style="text-align: center;">25.5</td>
<td style="text-align: center;">9.7</td>
<td style="text-align: center;">60.8</td>
<td style="text-align: center;">25.5</td>
</tr>
<tr>
<td style="text-align: left;">Transformer (no knowledge, w/ Reddit)</td>
<td style="text-align: center;">79.0</td>
<td style="text-align: center;">15.0</td>
<td style="text-align: center;">54.0</td>
<td style="text-align: center;">11.6</td>
<td style="text-align: center;">79.0</td>
<td style="text-align: center;">54.0</td>
</tr>
<tr>
<td style="text-align: left;">Transformer MemNet (w/ Reddit)</td>
<td style="text-align: center;">86.8</td>
<td style="text-align: center;">15.4</td>
<td style="text-align: center;">$\mathbf{6 9 . 8}$</td>
<td style="text-align: center;">12.4</td>
<td style="text-align: center;">91.6</td>
<td style="text-align: center;">82.3</td>
</tr>
<tr>
<td style="text-align: left;">Transformer MemNet (w/ Reddit+SQuAD)</td>
<td style="text-align: center;">$\mathbf{8 7 . 4}$</td>
<td style="text-align: center;">15.4</td>
<td style="text-align: center;">$\mathbf{6 9 . 8}$</td>
<td style="text-align: center;">12.4</td>
<td style="text-align: center;">92.3</td>
<td style="text-align: center;">83.1</td>
</tr>
<tr>
<td style="text-align: left;">Two-stage Transformer (optimized for predicted knowledge)</td>
<td style="text-align: center;">84.2</td>
<td style="text-align: center;">16.2</td>
<td style="text-align: center;">63.1</td>
<td style="text-align: center;">$\mathbf{1 3 . 2}$</td>
<td style="text-align: center;">92.3</td>
<td style="text-align: center;">83.1</td>
</tr>
<tr>
<td style="text-align: left;">Two-stage Transformer (optimized for gold knowledge)</td>
<td style="text-align: center;">79.6</td>
<td style="text-align: center;">$\mathbf{1 6 . 6}$</td>
<td style="text-align: center;">60.1</td>
<td style="text-align: center;">13.1</td>
<td style="text-align: center;">$\mathbf{9 6 . 3}$</td>
<td style="text-align: center;">$\mathbf{8 8 . 3}$</td>
</tr>
</tbody>
</table>
<p>Table 8: Human Experiments. We calculate the Wiki F1 score for the wizard and apprentice as they appear in the dataset for the sake of comparison to our human evaluations. Note that this differed from the human-human evaluation set-up in the sense that the wizard had direct access to Wikipedia passages in the UI, which explains the higher values of Wiki F1 both for the wizard (who uses Wikipedia) and for the apprentice (who would likely reference that use).</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Seen</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Unseen</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Method</td>
<td style="text-align: center;">Rating</td>
<td style="text-align: center;">Wiki F1</td>
<td style="text-align: center;">Rating</td>
<td style="text-align: center;">Wiki F1</td>
</tr>
<tr>
<td style="text-align: left;">Human Performance</td>
<td style="text-align: center;">$4.13(1.08)$</td>
<td style="text-align: center;">11.1</td>
<td style="text-align: center;">$4.34(0.98)$</td>
<td style="text-align: center;">10.6</td>
</tr>
<tr>
<td style="text-align: left;">Wizard Performance (in dataset)</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">43.3</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">43.1</td>
</tr>
<tr>
<td style="text-align: left;">Apprentice Performance (in dataset)</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">23.2</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">23.7</td>
</tr>
<tr>
<td style="text-align: left;">Retrieval Transformer (no knowledge)</td>
<td style="text-align: center;">$3.33(1.30)$</td>
<td style="text-align: center;">19.8</td>
<td style="text-align: center;">$3.12(1.34)$</td>
<td style="text-align: center;">13.7</td>
</tr>
<tr>
<td style="text-align: left;">Generative Transformer (no knowledge)</td>
<td style="text-align: center;">$2.11(1.11)$</td>
<td style="text-align: center;">15.3</td>
<td style="text-align: center;">$2.54(1.38)$</td>
<td style="text-align: center;">10.1</td>
</tr>
<tr>
<td style="text-align: left;">Retrieval Transformer MemNet</td>
<td style="text-align: center;">$3.43(1.10)$</td>
<td style="text-align: center;">23.4</td>
<td style="text-align: center;">$3.14(1.31)$</td>
<td style="text-align: center;">16.3</td>
</tr>
<tr>
<td style="text-align: left;">Two-Stage Generative Transformer MemNet</td>
<td style="text-align: center;">$2.92(1.33)$</td>
<td style="text-align: center;">30.0</td>
<td style="text-align: center;">$2.93(1.30)$</td>
<td style="text-align: center;">26.2</td>
</tr>
</tbody>
</table>
<p>knowledge produces similar, but factually inaccurate answers to user queries. For example, when one user asks about parts of Ireland to visit, the model enumerates a list of locations in Greece. Nonetheless, its repertoire of available responses often include inviting responses, allowing the bot to have a more natural conversational flow. Selected conversations with the retriever with knowledge may be found in Figure 4, for both seen and unseen topics.</p>
<p>The generator without knowledge is particularly prone to many of the typical behaviors of seq2seq systems (Li et al., 2016; Vijayakumar et al., 2016), including local repetition ("cookies are made of flour, oil, oil, and oil"), global repetition (producing the near same utterance for multiple turns), or inconsistencies in its personality (saying it both likes and dislikes movies). The generator with knowledge has significantly fewer issues with repetition, as it errs on the side of copying large fragments from the Wikipedia knowledge. The generator with knowledge can also act as a selfish conversationalist, choosing to respond or detail information without inviting a response. Although it generally produces accurate statements, it sometimes produces statements using an incorrect date,</p>
<p>name or word. It also frequently produces formulaic responses, like "I don't know, but I do know that [Wikipedia excerpt]". Nonetheless, we find the generator with knowledge is able to successfully generalize to unseen topics using the knowledge from Wikipedia. Selected conversations with the generator with knowledge may be found in Figure 5.</p>
<h1>Model: Retrieval Transformer MemNet</h1>
<p>Topic: Arnold Schwarzenegger (seen)
Human: Hey are you into the movie The Running Man
Model: Yeah! That's one of my favorite movies! I can't believe that Team America: World Police was made in 2004 - 14 years ago!
Human: Another one of Arnies movies I like is Terminator 2 JUDGMENT DAY
Model: The Terminator is probably his most iconic role, but he got his start from the movie "Conan the Barbarian", which came out a couple years earlier. I actually haven't seen that one.
Human: Which one? Conan or "Da Terminata"
Model: I like Arnold Schwarzeneggar as well! I thought he was a fantastic governator, serving from 2003-2011.
Human: HAha Governator! Yeah, it's pretty crazy they he held higher office.
Model: Yes, he won the LIFETIME ACHIEVEMENT AWARD! Interestingly, he joined the U.S. Army in 1961 and was a paratrooper! (*)</p>
<p>Topic: Steak (seen)
Human: Hello, it's lunch time here, and I'm in the mood for a great steak
Model: Wow that sounds delicious I wish I could say the same hahah, When the word "steak" is used without qualification, it normally refers to a Beefsteak
Human: Interesting, I don't really have a favorite steak, how about you?
Model: I like rib eye it is really good specially medium rare, When the word "steak" is used without qualification, it generally refers to a beefsteak
Human: I like rib eye too! What is it about a rib eye that you enjoy?
Model: Most steak cuts are very tender meat but I think rib eye can be quite tender
Human: They really are. How do you choose a good steak?
Model: When it comes to steak and other cuts of meat you have rare, medium rare, medium, well done and so on
Human: How do you prefer your steak prepared?
Model: I like that you can prepare it many different ways. You can fried it, grill it, or even broil the steak
Topic: Ireland (unseen)
Model: Hi, have you ever been to Dublin? It is the capital and largest city in Ireland.
Human: No, I haven't but would love to
Model: It is the largest city in Northern Ireland. (<em>)
Human: I've always found Ireland to be fascinating and would love to visit sometime
Model: Same here! It is the capital of Ireland too!
Human: What is the most popular place to visit in Ireland?
Model: I would recommend the Thrace, Crete, and the Ionian Islands as must see places. (</em>)
Human: I don't know anything about the Ionian Islands
Model: It was once referred to as the Hellenic Republic! (<em>)
Topic: American football (unseen)
Model: American football can be traced back to Britain in the mid-19th century. The rules were very similar!
Human: I did not know that. Did they wear equipment back then?
Model: Am not really certain about it but American football resulted from several major divergences from association football and rugby football
Human: The Philadelphia eagles actually have a rugby player on their team this year. he never played football until this year.
Model: Philadelphia is one of a few cities to have all four teams, but they love the Eagles more than anything else by a long shot!
Human: As a life long Philadelphia sports fan I have to agree with you.
Model: I've always been more of a fan of the American Football team from Pittsburgh, The Steelers!
Human: Being from Philadelphia I am not much of a pittsburgh fan.
Model: Are the Pittsburgh Steelers in the AFC?
Human: Yes they are. the AFC north to be exact.
Topic: List of national parks of the United States (unseen)
Human: I have never visited a national park in the United States, but I would really like to!
Model: Me too. I'd love to live in a national park
Human: Which one do you think is the best to visit first?
Model: The United Nations is an important place to visit, the Statue of Liberty, Central park is great also
Human: Is the Statue of Liberty considered a National Park?
Model: Yes, the statue of Liberty is there on an island - The Liberty Island.
Human: I had no idea that that was a National Park. I have heard Zion National Park is really nice!
Model: Yes, it links the shenandoah national park and the great smoky mountains together! (</em>)
Figure 4: Retriever with Knowledge conversations. Selected conversations with a human. (*) indicates clear factual mistakes by the model.</p>
<h1>Model: Two-Stage Generative Transformer MemNet</h1>
<p>Topic: Circus (seen)
Model: have you ever been to a circus? it is a company of performers who put on diverse entertainment shows.
Human: I went to the circus once when I was a child actually.
Model: that's great! entertainment is a form of activity that holds the attention and interest of an audience.
Human: That's true. Have you ever been to a circus?
Model: I have not, but I know they were built with various types of seating ring, and sometimes a stage.
Human: I went to one held in a stadium, so we had box seats.
Model: that's awesome! i'm sure you'll have to go to the circus, with appropriate music.
Human: Yes, circuses usually have their own kind of music.
Model: circuses can be done by circuses.
Topic: Granny Smith (seen)
Human: I really love Granny Smith apples, they're my favorite type of apple.
Model: I love granny smith apples. they have hard, light green skin and a crisp flesh.
Human: Yes, I really enjoy them. I also like Honeycrisp apples but they're so expensive!
Model: they've been grown for thousands of years in asia and europe, and were brought to north america by european colonists (*)
Human: Oh really? They've been around way longer than I thought!
Model: they're also consumed raw, it's one of the most popular cooking apples.
Human: I always eat them raw, I hate cooked apples for some reason, even in pie.
Model: i'm not sure if it's cooked, but I do know that they can be cooked raw.
Topic: Culture of Chicago (seen)
Human: hi do you like chicago
Model: I love chicago. it's the third most populous city in the us.
Human: how many people live there?
Model: about 2. 7 million residents, it is also the most populous city in the state of illinois.
Human: do you like chicago deep dish pizza?
Model: chicago-style pizza may be made in deep dish style and as a stuffed pizza.
Human: what is the name of the baseball team?
Model: dano's pizzeria specializes in chicago style stuffed pizza.
Human: Is Dano's pizzaria open everyday?
Model: yes it is. it is an american style pizza chain headquartered in midtown brook, illinois.
Topic: Animals in sport (unseen)
Model: i love to watch animals. it's the most popular form of animal-related sport.
Human: horse racing is the most awesome animal sport!
Model: horse racing is an equestrian performance sport, typically involving two or more horses ridden by jockeys or driven over a set distance for competition.
Human: yes, the Kentucky Derby and the triple crown is something I look forward to every year!
Model: the horse has evolved over the past 45 to 55 million years from a small multi toed creature
Human: that is very interesting, how did people come to domesticate horses for sport?
Model: i'm not sure but the domestication is believed to have been widespread by 3000 bc
Human: very interesting! I wonder how long people used horses to hunt before deciding to race them.
Model: i'm not sure but I do know that horses have been domesticated for thousands of years.
Topic: Dairy farming (unseen)
Human: hi there i was wondering how you felt about farming
Model: I do not like dairy farming but I do know that in developed countries, dairy farms typically consist of high dairy products.
Human: oh yes they have alot of cows and push out alot of dairy every hour
Model: other species used in commercial dairy farming include goats, sheep, and camels
Human: i did not know you could get milk a camel
Model: camel milk has supported bedouin
Human: oh wow thats very interesting
Model: in italy they are growing in popularity to produce an alternative milk source for humans
Human: i have had goat milk before
Model: the earliest evidence of using domesticated cows for dairy production is the seventh millennium bc-the neolithic era -
Human: thats so neat. i would say cow milk is my favorite
Model: I love cow milk, especially since the iphone is used in the iphone.
Human: iphone and cow milk
Model: the iphone was first released in 2007.
Human: oh ok well thanks for the talk have a great day
Model: no problem! the iphone was first released in 2007.</p>
<p>Figure 5: Two-stage Generator conversations. Selected conversations with a human. (*) indicates clear factual mistakes by the model.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ For example, a model could display knowledge by copying parts of Wikipedia, but not be engaging at all.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>