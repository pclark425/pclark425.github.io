<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1998 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1998</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1998</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-46.html">extraction-schema-46</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <p><strong>Paper ID:</strong> paper-278658695</p>
                <p><strong>Paper Title:</strong> AlphaEvolve : A coding agent for scientific and algorithmic discovery</p>
                <p><strong>Paper Abstract:</strong> In this white paper, we present AlphaEvolve , an evolutionary coding agent that substantially enhances capabilities of state-of-the-art LLMs on highly challenging tasks such as tackling open scientific problems or optimizing critical pieces of computational infrastructure. AlphaEvolve orchestrates an autonomous pipeline of LLMs, whose task is to improve an algorithm by making direct changes to the code. Using an evolutionary approach, continuously receiving feedback from one or more evaluators, AlphaEvolve iteratively improves the algorithm, potentially leading to new scientific and practical discoveries. We demonstrate the broad applicability of this approach by applying it to a number of important computational problems. When applied to optimizing critical components of large-scale computational stacks at Google, AlphaEvolve developed a more efficient scheduling algorithm for data centers, found a functionally equivalent simplification in the circuit design of hardware accelerators, and accelerated the training of the LLM underpinning AlphaEvolve itself. Furthermore, AlphaEvolve discovered novel, provably correct algorithms that surpass state-of-the-art solutions on a spectrum of problems in mathematics and computer science, significantly expanding the scope of prior automated discovery methods (Romera-Paredes et al., 2023). Notably, AlphaEvolve developed a search algorithm that found a procedure to multiply two 4 × 4 complex-valued matrices using 48 scalar multiplications; offering the first improvement, after 56 years, over Strassen’s algorithm in this setting. We believe AlphaEvolve and coding agents like it can have a significant impact in improving solutions of problems across many areas of science and computation.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1998.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1998.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaEvolve</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AlphaEvolve: A coding agent for scientific and algorithmic discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An evolutionary code-superoptimization system that uses large language models to propose code mutations (operators) and program execution + automated evaluation as the fitness signal, enabling discovery of novel algorithms and system optimizations across mathematics and engineering.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AlphaEvolve</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based (learned) operators within an evolutionary framework (hybrid: LLM proposals + program-execution evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Operators are implemented by prompting SOTA LLMs (ensemble of Gemini 2.0 Flash and Gemini 2.0 Pro) to propose diffs/edits to code blocks stored in an evolutionary database; prompts include examples of prior high-performing programs, evaluation results, and optional meta-prompts. The LLMs generate candidate mutations (diff-format or full replacements) rather than the system using hand-designed mutation/crossover functions. Candidates are executed and scored by user-provided evaluate functions; high-scoring candidates are stored and surfaced in future prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Algorithm discovery and code superoptimization across multiple domains: tensor decomposition / matrix multiplication algorithm search (exact tensor decompositions), many mathematical construction problems (packing, kissing numbers, combinatorics), data-center scheduling (Borg simulator), Pallas/JAX kernel tiling optimization for Gemini training, RTL circuit simplification for TPUs, and FlashAttention XLA IR optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Classical genetic/evolutionary programming (hand-designed mutation/crossover operators), FunSearch (prior LLM-guided evolution with small code-trained LMs), ablation baselines used in-paper: 'No evolution' (repeated sampling of same initial program), 'No context in prompt', 'No meta prompt evolution', 'No full-file evolution', 'Small base LLM only'.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Multiple task-specific outcomes reported: discovered 4x4 complex matrix multiplication algorithm using 48 scalar multiplications (improves prior 49 over fields of characteristic 0); scheduling heuristic recovered on average 0.7% of fleet-wide compute resources in production; tiling heuristic produced average 23% kernel speedup for a matrix-multiplication kernel and ~1% reduction in overall Gemini training time; optimized FlashAttention kernel sped up by 32% and pre/postprocessing by 15%.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Yes in at least one applied setting: data-center scheduling heuristic was evaluated on an unseen test dataset of realistic workloads and generalization was confirmed by simulator and by post-deployment fleet measurements (0.7% resource recovery). For kernel tiling, a held-out evaluation set of input shapes was used to test general applicability and production deployment was achieved.</td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td>Paper reports sensitivity to seed/initialization in some tasks: seeding the initial program with human ideas (e.g., adding stochasticity or evolutionary approaches) improved performance on some tensor-decomposition targets, indicating dependence on initial conditions. Also, AlphaEvolve's performance improves with stronger underlying LLMs, implying model pretraining/distribution affects operator quality.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>Qualitative and some quantitative statements: AlphaEvolve is sample-efficient compared to earlier FunSearch (FunSearch used millions of LLM samples; AlphaEvolve uses thousands). Evaluation can consume on order of 100 compute-hours per new solution but is parallelized across evaluators; ensemble LLM strategy (Flash for throughput, Pro for higher-quality occasional samples) trades latency vs quality. No wall-clock microbenchmarks directly comparing LLM-operator runtime to traditional GP operator runtimes are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td>Compared at a high level: FunSearch used relatively small LLMs trained only on code and saw no benefit from larger models; AlphaEvolve uses frontier general-purpose LLMs (Gemini models) with rich natural-language context and benefits from larger models—paper reports AlphaEvolve 'performs increasingly better as the underlying LLM improves'. Exact training corpora / pretraining details are not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td>Multiple ablations performed (tensor decomposition and kissing-number tasks): disabling evolution ('No evolution'), removing prompt context, disabling meta-prompt evolution, restricting to evolving only a single loss function ('No full-file evolution'), or using only a small base LLM ('Small base LLM only') each caused significant degradations; the full AlphaEvolve pipeline outperformed each ablated variant. Quantitative curves are shown in Figure 8 but numerical values are not listed in-text.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td>Not explicitly quantified. The system stores a large database of past programs and uses MAP-elites/island-inspired storage to balance exploration and exploitation; the paper qualitatively argues that evolving whole files and multi-metric optimization increases coverage of diverse program structures, but no explicit coverage statistics are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>Yes — adaptation happens by (1) re-surfacing past programs in prompts (evolutionary database) and (2) 'meta prompt evolution' where prompts/instructions fed to the LLM are themselves co-evolved; these mechanisms are credited with improving performance. No online fine-tuning of base LLM weights is reported (LLMs are used at inference time), though related works that fine-tune are cited.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Main limitations: requires an automated evaluator (cannot directly handle tasks needing manual experimentation); scaling issues (e.g., running discovered tensor-decomposition programs at larger sizes ran into memory limits on GPUs); dependence on initial seed/program can affect outcomes; no explicit per-task invalidity rates reported. LLM hallucinations are mitigated by program execution but not eliminated as a design constraint.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>LLM-based learned operators (generated edits/mutations) integrated into an evolutionary loop can effectively replace hand-designed GP operators for complex code-evolution tasks, provided (a) there is programmatic, automated evaluation to ground proposals, (b) prompts include rich context and past solutions, and (c) higher-capability LLMs and ensemble sampling improve search quality. Ablations show that evolution, prompt context, meta-prompt adaptation, whole-file evolution, and using powerful LLMs each materially contribute to performance. Further, hybrid human+AlphaEvolve seeding can boost outcomes, and the approach scales to real production problems where generalization can be validated (e.g., scheduling, kernel tiling).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1998.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1998.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FunSearch</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FunSearch (LLM-guided evolution for mathematical discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior LLM-guided evolutionary system that evolved single Python functions to discover mathematical constructions and heuristics, using relatively small LLMs trained on code and limited-context prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mathematical discoveries from program search with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>FunSearch</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based operators (small code-trained LLMs) within an evolutionary framework</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Evolved a single Python function (single-function evolution), used small LLMs trained primarily on code to propose edits, and optimized a single objective with minimal context (previous solutions only). Operators were effectively LLM-sampled code edits restricted by a narrow prompt/context design.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Not reported in detail in this paper; described as small LLMs trained on code (FunSearch used smaller code-only models relative to AlphaEvolve).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Mathematical discovery tasks (finding witnesses/counterexamples and constructing mathematical objects) and some heuristic discovery use-cases cited.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared qualitatively to AlphaEvolve (AlphaEvolve extends FunSearch by evolving entire files, multiobjective optimization, using SOTA LLMs and richer prompts).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td>Implicit: limited context and smaller model size constrained novelty/diversity relative to AlphaEvolve, per authors' statements.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>FunSearch used many more LLM samples historically (millions) compared to AlphaEvolve's thousands; exact compute/time comparisons not provided but this is highlighted as an efficiency advantage for AlphaEvolve.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td>FunSearch used smaller LMs trained on code only; AlphaEvolve uses larger general-purpose SOTA LLMs with natural-language context—paper reports AlphaEvolve benefits from larger models.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>FunSearch used a simpler prompt-history based approach; did not use meta-prompt evolution or full-file evolution as AlphaEvolve does.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Limited to evolving single functions and single-objective optimization; needed fast evaluation (≤20 minutes on 1 CPU) per sample unlike AlphaEvolve which supports longer and parallel evaluations; lacked benefit from larger models per authors.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>FunSearch demonstrates feasibility of LLM-guided evolution but is constrained by model capacity, narrow prompt context, and limited program abstraction; scaling to whole-file evolution, multiobjective optimization, richer contexts, and more capable LLMs (as in AlphaEvolve) yields broader capability and better sample efficiency.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1998.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1998.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ClassicalGP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Classical Genetic Programming / Evolutionary Methods</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Traditional genetic programming approaches that evolve programs using hand-designed mutation and crossover operators, widely used for symbolic regression, automated algorithm discovery, and optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Genetic Programming: An Introduction on the Automatic Evolution of computer programs and its Applications.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Classical Genetic Programming (GP)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>traditional GP (hand-designed mutation/crossover operators, grammar/tree-based operators)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Uses pre-specified sets of mutation and crossover operators (e.g., subtree crossover, point mutation, grammar-guided transformations) applied to populations of program trees or code representations. Operators are manually designed and task-specific tuning is often required.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Symbolic regression, automated scientific/algorithmic discovery, scheduling, and other evolutionary search problems (general GP domains).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Mentioned as the classical baseline contrasted with AlphaEvolve's LLM-based operators; no direct empirical head-to-head comparisons provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>Not quantitatively compared in-paper. Authors argue hand-designed operators can be hard to craft and may fail to capture important domain structure, motivating automated operator construction via LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Requires careful hand-design; may not capture domain-specific program transformations leading to limited exploration; authors position LLM-based operators as an approach to automate operator design.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>The paper positions LLM-generated operators as a way to overcome human-design bottlenecks in GP operators, enabling richer, context-aware mutations that leverage world knowledge and flexible natural-language conditioning; however, no direct empirical numeric comparison to classical GP operators was provided.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1998.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1998.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>No-evolution ablation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>No evolution (ablation baseline in AlphaEvolve)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ablation baseline where the system repeatedly samples the language model given the same initial program without using the evolutionary database to iterate on past generated solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>No evolution (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based proposals without evolutionary resurfacing (repeated sampling)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>LLM is repeatedly prompted with the same initial program; newly generated candidates are evaluated but the evolutionary database/resurfacing mechanism is disabled, so no accumulation and reuse of past improved programs in prompts occurs.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Used as ablation on tensor decomposition (faster matrix multiplication) and kissing-number tasks in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against full AlphaEvolve (evolutionary database + context + other components).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td>In ablations, 'No evolution' performed substantially worse than the full AlphaEvolve pipeline across compute budgets (Figure 8), indicating the evolutionary resurfacing of past solutions is a key contributor to performance.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Loses the benefit of iterative accumulation of improvements; reduced ability to hill-climb from previously discovered high-performing solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Shows that iterative evolution (resurfacing and reusing past programs in prompts) is an important mechanism by which LLM-based proposal operators become effective search operators over long runs.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1998.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1998.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SmallBaseLLM ablation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Small base LLM only (ablation baseline in AlphaEvolve)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ablation variant where AlphaEvolve uses only a single small base language model (analogous to FunSearch), testing the impact of model capability and ensemble diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Small base LLM only</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based (small model) operators</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Same evolutionary framework but restricted to sampling a single small base LLM for proposing code edits, removing the ensemble and higher-capability model samples.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Ablation on tensor decomposition task (matrix multiplication) as reported in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to full AlphaEvolve (ensemble of Gemini 2.0 Flash + Pro, meta-prompting, context, full-file evolution).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td>Paper reports that AlphaEvolve gains from stronger LLMs; 'Small base LLM only' ablation underperforms the full system, implying training/model capacity and potentially training data/domain coverage affect operator quality.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>Not quantitatively reported; implicitly smaller models have lower per-sample cost but reduced effectiveness, trading off throughput and quality.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td>Ablation shows using only a small LLM significantly degrades final performance relative to the full AlphaEvolve setup; the full system benefits from an ensemble strategy combining high-throughput smaller model and higher-quality larger model.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Reduced creativity/diversity and lower ability to propose high-quality complex edits; requires many more samples historically (as paper contrasts with FunSearch).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Model capability and ensemble diversity materially influence the quality of LLM-derived mutation operators; investing in more capable LLM samples (even intermittently) improves evolutionary outcomes.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1998.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1998.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Surina et al.</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Algorithm discovery with LLMs: Evolutionary search meets reinforcement learning (Surina et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited recent work that augments LLM-guided evolution by continuously fine-tuning the LLM through reinforcement learning during the evolutionary process.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Algorithm discovery with LLMs: Evolutionary search meets reinforcement learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Surina et al. approach</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>Hybrid (LLM-based operators + continual RL fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Complementary idea where an LLM is continuously fine-tuned (via RL) on high-performing program edits discovered during evolution, so the proposal operator adapts its output distribution over the run.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Mentioned in related work as an enhancement to LLM-guided evolution; specific domains in that paper not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Mentioned as complementary to AlphaEvolve; no direct comparisons in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>Yes (this cited work performs online adaptation of the LLM via RL which could improve operator proposals during evolution).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Points to an alternative mechanism for improving LLM-derived operators: online adaptation (fine-tuning) rather than only prompt/meta-prompt adaptation; authors note more investigation is required to understand benefits at AlphaEvolve scale.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1998.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1998.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Grayeli et al.</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Symbolic regression with a learned concept library (Grayeli et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited work that augments evolutionary search by having an LLM summarize high-performing programs into natural language 'concepts' which are then used to guide further synthesis.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Symbolic regression with a learned concept library.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Concept-learning augmentation (Grayeli et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based augmentation (concept summarization + guidance)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>An LLM-directed concept learning step summarizes patterns from high-performing programs into natural language concepts, which are then used to bias future generation/search, acting as a learned operator/higher-level guidance mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Symbolic regression and program search (cited as related augmentation to LLM-guided evolution).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Mentioned as a complementary enhancement to LLM-guided evolution; not empirically compared in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>Yes (uses learned natural-language summarizations of program concepts to adapt search); described as a promising complementary idea to basic LLM-guided evolution.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Suggests that extracting higher-level, human-readable concepts from program pools can serve as powerful learned operators or biases to direct subsequent evolutionary proposals; AlphaEvolve notes such ideas merit study at its scale.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Mathematical discoveries from program search with large language models. <em>(Rating: 2)</em></li>
                <li>Discovering faster matrix multiplication algorithms with reinforcement learning. <em>(Rating: 2)</em></li>
                <li>Genetic Programming: An Introduction on the Automatic Evolution of computer programs and its Applications. <em>(Rating: 2)</em></li>
                <li>Evolution Through Large Models. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1998",
    "paper_id": "paper-278658695",
    "extraction_schema_id": "extraction-schema-46",
    "extracted_data": [
        {
            "name_short": "AlphaEvolve",
            "name_full": "AlphaEvolve: A coding agent for scientific and algorithmic discovery",
            "brief_description": "An evolutionary code-superoptimization system that uses large language models to propose code mutations (operators) and program execution + automated evaluation as the fitness signal, enabling discovery of novel algorithms and system optimizations across mathematics and engineering.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "AlphaEvolve",
            "operator_type": "LLM-based (learned) operators within an evolutionary framework (hybrid: LLM proposals + program-execution evaluation)",
            "operator_description": "Operators are implemented by prompting SOTA LLMs (ensemble of Gemini 2.0 Flash and Gemini 2.0 Pro) to propose diffs/edits to code blocks stored in an evolutionary database; prompts include examples of prior high-performing programs, evaluation results, and optional meta-prompts. The LLMs generate candidate mutations (diff-format or full replacements) rather than the system using hand-designed mutation/crossover functions. Candidates are executed and scored by user-provided evaluate functions; high-scoring candidates are stored and surfaced in future prompts.",
            "training_data_description": null,
            "domain_or_benchmark": "Algorithm discovery and code superoptimization across multiple domains: tensor decomposition / matrix multiplication algorithm search (exact tensor decompositions), many mathematical construction problems (packing, kissing numbers, combinatorics), data-center scheduling (Borg simulator), Pallas/JAX kernel tiling optimization for Gemini training, RTL circuit simplification for TPUs, and FlashAttention XLA IR optimization.",
            "comparison_baseline": "Classical genetic/evolutionary programming (hand-designed mutation/crossover operators), FunSearch (prior LLM-guided evolution with small code-trained LMs), ablation baselines used in-paper: 'No evolution' (repeated sampling of same initial program), 'No context in prompt', 'No meta prompt evolution', 'No full-file evolution', 'Small base LLM only'.",
            "performance_learned_operator": "Multiple task-specific outcomes reported: discovered 4x4 complex matrix multiplication algorithm using 48 scalar multiplications (improves prior 49 over fields of characteristic 0); scheduling heuristic recovered on average 0.7% of fleet-wide compute resources in production; tiling heuristic produced average 23% kernel speedup for a matrix-multiplication kernel and ~1% reduction in overall Gemini training time; optimized FlashAttention kernel sped up by 32% and pre/postprocessing by 15%.",
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": "Yes in at least one applied setting: data-center scheduling heuristic was evaluated on an unseen test dataset of realistic workloads and generalization was confirmed by simulator and by post-deployment fleet measurements (0.7% resource recovery). For kernel tiling, a held-out evaluation set of input shapes was used to test general applicability and production deployment was achieved.",
            "training_bias_evidence": "Paper reports sensitivity to seed/initialization in some tasks: seeding the initial program with human ideas (e.g., adding stochasticity or evolutionary approaches) improved performance on some tensor-decomposition targets, indicating dependence on initial conditions. Also, AlphaEvolve's performance improves with stronger underlying LLMs, implying model pretraining/distribution affects operator quality.",
            "computational_cost_comparison": "Qualitative and some quantitative statements: AlphaEvolve is sample-efficient compared to earlier FunSearch (FunSearch used millions of LLM samples; AlphaEvolve uses thousands). Evaluation can consume on order of 100 compute-hours per new solution but is parallelized across evaluators; ensemble LLM strategy (Flash for throughput, Pro for higher-quality occasional samples) trades latency vs quality. No wall-clock microbenchmarks directly comparing LLM-operator runtime to traditional GP operator runtimes are provided.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": "Compared at a high level: FunSearch used relatively small LLMs trained only on code and saw no benefit from larger models; AlphaEvolve uses frontier general-purpose LLMs (Gemini models) with rich natural-language context and benefits from larger models—paper reports AlphaEvolve 'performs increasingly better as the underlying LLM improves'. Exact training corpora / pretraining details are not reported.",
            "ablation_study_results": "Multiple ablations performed (tensor decomposition and kissing-number tasks): disabling evolution ('No evolution'), removing prompt context, disabling meta-prompt evolution, restricting to evolving only a single loss function ('No full-file evolution'), or using only a small base LLM ('Small base LLM only') each caused significant degradations; the full AlphaEvolve pipeline outperformed each ablated variant. Quantitative curves are shown in Figure 8 but numerical values are not listed in-text.",
            "hypothesis_space_characterization": "Not explicitly quantified. The system stores a large database of past programs and uses MAP-elites/island-inspired storage to balance exploration and exploitation; the paper qualitatively argues that evolving whole files and multi-metric optimization increases coverage of diverse program structures, but no explicit coverage statistics are reported.",
            "adaptation_during_evolution": "Yes — adaptation happens by (1) re-surfacing past programs in prompts (evolutionary database) and (2) 'meta prompt evolution' where prompts/instructions fed to the LLM are themselves co-evolved; these mechanisms are credited with improving performance. No online fine-tuning of base LLM weights is reported (LLMs are used at inference time), though related works that fine-tune are cited.",
            "failure_modes": "Main limitations: requires an automated evaluator (cannot directly handle tasks needing manual experimentation); scaling issues (e.g., running discovered tensor-decomposition programs at larger sizes ran into memory limits on GPUs); dependence on initial seed/program can affect outcomes; no explicit per-task invalidity rates reported. LLM hallucinations are mitigated by program execution but not eliminated as a design constraint.",
            "key_findings_for_theory": "LLM-based learned operators (generated edits/mutations) integrated into an evolutionary loop can effectively replace hand-designed GP operators for complex code-evolution tasks, provided (a) there is programmatic, automated evaluation to ground proposals, (b) prompts include rich context and past solutions, and (c) higher-capability LLMs and ensemble sampling improve search quality. Ablations show that evolution, prompt context, meta-prompt adaptation, whole-file evolution, and using powerful LLMs each materially contribute to performance. Further, hybrid human+AlphaEvolve seeding can boost outcomes, and the approach scales to real production problems where generalization can be validated (e.g., scheduling, kernel tiling).",
            "uuid": "e1998.0"
        },
        {
            "name_short": "FunSearch",
            "name_full": "FunSearch (LLM-guided evolution for mathematical discovery)",
            "brief_description": "Prior LLM-guided evolutionary system that evolved single Python functions to discover mathematical constructions and heuristics, using relatively small LLMs trained on code and limited-context prompts.",
            "citation_title": "Mathematical discoveries from program search with large language models.",
            "mention_or_use": "mention",
            "system_name": "FunSearch",
            "operator_type": "LLM-based operators (small code-trained LLMs) within an evolutionary framework",
            "operator_description": "Evolved a single Python function (single-function evolution), used small LLMs trained primarily on code to propose edits, and optimized a single objective with minimal context (previous solutions only). Operators were effectively LLM-sampled code edits restricted by a narrow prompt/context design.",
            "training_data_description": "Not reported in detail in this paper; described as small LLMs trained on code (FunSearch used smaller code-only models relative to AlphaEvolve).",
            "domain_or_benchmark": "Mathematical discovery tasks (finding witnesses/counterexamples and constructing mathematical objects) and some heuristic discovery use-cases cited.",
            "comparison_baseline": "Compared qualitatively to AlphaEvolve (AlphaEvolve extends FunSearch by evolving entire files, multiobjective optimization, using SOTA LLMs and richer prompts).",
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": "Implicit: limited context and smaller model size constrained novelty/diversity relative to AlphaEvolve, per authors' statements.",
            "computational_cost_comparison": "FunSearch used many more LLM samples historically (millions) compared to AlphaEvolve's thousands; exact compute/time comparisons not provided but this is highlighted as an efficiency advantage for AlphaEvolve.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": "FunSearch used smaller LMs trained on code only; AlphaEvolve uses larger general-purpose SOTA LLMs with natural-language context—paper reports AlphaEvolve benefits from larger models.",
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": "FunSearch used a simpler prompt-history based approach; did not use meta-prompt evolution or full-file evolution as AlphaEvolve does.",
            "failure_modes": "Limited to evolving single functions and single-objective optimization; needed fast evaluation (≤20 minutes on 1 CPU) per sample unlike AlphaEvolve which supports longer and parallel evaluations; lacked benefit from larger models per authors.",
            "key_findings_for_theory": "FunSearch demonstrates feasibility of LLM-guided evolution but is constrained by model capacity, narrow prompt context, and limited program abstraction; scaling to whole-file evolution, multiobjective optimization, richer contexts, and more capable LLMs (as in AlphaEvolve) yields broader capability and better sample efficiency.",
            "uuid": "e1998.1"
        },
        {
            "name_short": "ClassicalGP",
            "name_full": "Classical Genetic Programming / Evolutionary Methods",
            "brief_description": "Traditional genetic programming approaches that evolve programs using hand-designed mutation and crossover operators, widely used for symbolic regression, automated algorithm discovery, and optimization.",
            "citation_title": "Genetic Programming: An Introduction on the Automatic Evolution of computer programs and its Applications.",
            "mention_or_use": "mention",
            "system_name": "Classical Genetic Programming (GP)",
            "operator_type": "traditional GP (hand-designed mutation/crossover operators, grammar/tree-based operators)",
            "operator_description": "Uses pre-specified sets of mutation and crossover operators (e.g., subtree crossover, point mutation, grammar-guided transformations) applied to populations of program trees or code representations. Operators are manually designed and task-specific tuning is often required.",
            "training_data_description": null,
            "domain_or_benchmark": "Symbolic regression, automated scientific/algorithmic discovery, scheduling, and other evolutionary search problems (general GP domains).",
            "comparison_baseline": "Mentioned as the classical baseline contrasted with AlphaEvolve's LLM-based operators; no direct empirical head-to-head comparisons provided in this paper.",
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": "Not quantitatively compared in-paper. Authors argue hand-designed operators can be hard to craft and may fail to capture important domain structure, motivating automated operator construction via LLMs.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": "Requires careful hand-design; may not capture domain-specific program transformations leading to limited exploration; authors position LLM-based operators as an approach to automate operator design.",
            "key_findings_for_theory": "The paper positions LLM-generated operators as a way to overcome human-design bottlenecks in GP operators, enabling richer, context-aware mutations that leverage world knowledge and flexible natural-language conditioning; however, no direct empirical numeric comparison to classical GP operators was provided.",
            "uuid": "e1998.2"
        },
        {
            "name_short": "No-evolution ablation",
            "name_full": "No evolution (ablation baseline in AlphaEvolve)",
            "brief_description": "An ablation baseline where the system repeatedly samples the language model given the same initial program without using the evolutionary database to iterate on past generated solutions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "No evolution (baseline)",
            "operator_type": "LLM-based proposals without evolutionary resurfacing (repeated sampling)",
            "operator_description": "LLM is repeatedly prompted with the same initial program; newly generated candidates are evaluated but the evolutionary database/resurfacing mechanism is disabled, so no accumulation and reuse of past improved programs in prompts occurs.",
            "training_data_description": null,
            "domain_or_benchmark": "Used as ablation on tensor decomposition (faster matrix multiplication) and kissing-number tasks in the paper.",
            "comparison_baseline": "Compared against full AlphaEvolve (evolutionary database + context + other components).",
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": null,
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": "In ablations, 'No evolution' performed substantially worse than the full AlphaEvolve pipeline across compute budgets (Figure 8), indicating the evolutionary resurfacing of past solutions is a key contributor to performance.",
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": "Loses the benefit of iterative accumulation of improvements; reduced ability to hill-climb from previously discovered high-performing solutions.",
            "key_findings_for_theory": "Shows that iterative evolution (resurfacing and reusing past programs in prompts) is an important mechanism by which LLM-based proposal operators become effective search operators over long runs.",
            "uuid": "e1998.3"
        },
        {
            "name_short": "SmallBaseLLM ablation",
            "name_full": "Small base LLM only (ablation baseline in AlphaEvolve)",
            "brief_description": "An ablation variant where AlphaEvolve uses only a single small base language model (analogous to FunSearch), testing the impact of model capability and ensemble diversity.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Small base LLM only",
            "operator_type": "LLM-based (small model) operators",
            "operator_description": "Same evolutionary framework but restricted to sampling a single small base LLM for proposing code edits, removing the ensemble and higher-capability model samples.",
            "training_data_description": null,
            "domain_or_benchmark": "Ablation on tensor decomposition task (matrix multiplication) as reported in paper.",
            "comparison_baseline": "Compared to full AlphaEvolve (ensemble of Gemini 2.0 Flash + Pro, meta-prompting, context, full-file evolution).",
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": "Paper reports that AlphaEvolve gains from stronger LLMs; 'Small base LLM only' ablation underperforms the full system, implying training/model capacity and potentially training data/domain coverage affect operator quality.",
            "computational_cost_comparison": "Not quantitatively reported; implicitly smaller models have lower per-sample cost but reduced effectiveness, trading off throughput and quality.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": "Ablation shows using only a small LLM significantly degrades final performance relative to the full AlphaEvolve setup; the full system benefits from an ensemble strategy combining high-throughput smaller model and higher-quality larger model.",
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": "Reduced creativity/diversity and lower ability to propose high-quality complex edits; requires many more samples historically (as paper contrasts with FunSearch).",
            "key_findings_for_theory": "Model capability and ensemble diversity materially influence the quality of LLM-derived mutation operators; investing in more capable LLM samples (even intermittently) improves evolutionary outcomes.",
            "uuid": "e1998.4"
        },
        {
            "name_short": "Surina et al.",
            "name_full": "Algorithm discovery with LLMs: Evolutionary search meets reinforcement learning (Surina et al.)",
            "brief_description": "A cited recent work that augments LLM-guided evolution by continuously fine-tuning the LLM through reinforcement learning during the evolutionary process.",
            "citation_title": "Algorithm discovery with LLMs: Evolutionary search meets reinforcement learning.",
            "mention_or_use": "mention",
            "system_name": "Surina et al. approach",
            "operator_type": "Hybrid (LLM-based operators + continual RL fine-tuning)",
            "operator_description": "Complementary idea where an LLM is continuously fine-tuned (via RL) on high-performing program edits discovered during evolution, so the proposal operator adapts its output distribution over the run.",
            "training_data_description": null,
            "domain_or_benchmark": "Mentioned in related work as an enhancement to LLM-guided evolution; specific domains in that paper not detailed here.",
            "comparison_baseline": "Mentioned as complementary to AlphaEvolve; no direct comparisons in this paper.",
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": null,
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": "Yes (this cited work performs online adaptation of the LLM via RL which could improve operator proposals during evolution).",
            "failure_modes": null,
            "key_findings_for_theory": "Points to an alternative mechanism for improving LLM-derived operators: online adaptation (fine-tuning) rather than only prompt/meta-prompt adaptation; authors note more investigation is required to understand benefits at AlphaEvolve scale.",
            "uuid": "e1998.5"
        },
        {
            "name_short": "Grayeli et al.",
            "name_full": "Symbolic regression with a learned concept library (Grayeli et al.)",
            "brief_description": "Cited work that augments evolutionary search by having an LLM summarize high-performing programs into natural language 'concepts' which are then used to guide further synthesis.",
            "citation_title": "Symbolic regression with a learned concept library.",
            "mention_or_use": "mention",
            "system_name": "Concept-learning augmentation (Grayeli et al.)",
            "operator_type": "LLM-based augmentation (concept summarization + guidance)",
            "operator_description": "An LLM-directed concept learning step summarizes patterns from high-performing programs into natural language concepts, which are then used to bias future generation/search, acting as a learned operator/higher-level guidance mechanism.",
            "training_data_description": null,
            "domain_or_benchmark": "Symbolic regression and program search (cited as related augmentation to LLM-guided evolution).",
            "comparison_baseline": "Mentioned as a complementary enhancement to LLM-guided evolution; not empirically compared in this paper.",
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": null,
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": "Yes (uses learned natural-language summarizations of program concepts to adapt search); described as a promising complementary idea to basic LLM-guided evolution.",
            "failure_modes": null,
            "key_findings_for_theory": "Suggests that extracting higher-level, human-readable concepts from program pools can serve as powerful learned operators or biases to direct subsequent evolutionary proposals; AlphaEvolve notes such ideas merit study at its scale.",
            "uuid": "e1998.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Mathematical discoveries from program search with large language models.",
            "rating": 2
        },
        {
            "paper_title": "Discovering faster matrix multiplication algorithms with reinforcement learning.",
            "rating": 2
        },
        {
            "paper_title": "Genetic Programming: An Introduction on the Automatic Evolution of computer programs and its Applications.",
            "rating": 2
        },
        {
            "paper_title": "Evolution Through Large Models.",
            "rating": 1
        }
    ],
    "cost": 0.020191,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>AlphaEvolve: A coding agent for scientific and algorithmic discovery</p>
<p>Alexander Novikov 
Ngân Vũ 
Marvin Eisenberger 
Emilien Dupont 
Po-Sen Huang 
Adam Zsolt Wagner 
Sergey Shirobokov 
Borislav Kozlovskii 
Francisco J R Ruiz 
Abbas Mehrabian 
M Pawan Kumar 
Abigail See 
Swarat Chaudhuri 
George Holland 
Alex Davies 
Sebastian Nowozin 
Pushmeet Kohli 
Matej Balog 
Google Deepmind 
AlphaEvolve: A coding agent for scientific and algorithmic discovery
C348DAA6B93F3B0AB935D8FCC7C6AE16
In this white paper, we present AlphaEvolve, an evolutionary coding agent that substantially enhances capabilities of state-of-the-art LLMs on highly challenging tasks such as tackling open scientific problems or optimizing critical pieces of computational infrastructure.AlphaEvolve orchestrates an autonomous pipeline of LLMs, whose task is to improve an algorithm by making direct changes to the code.Using an evolutionary approach, continuously receiving feedback from one or more evaluators, AlphaEvolve iteratively improves the algorithm, potentially leading to new scientific and practical discoveries.We demonstrate the broad applicability of this approach by applying it to a number of important computational problems.When applied to optimizing critical components of large-scale computational stacks at Google, AlphaEvolve developed a more efficient scheduling algorithm for data centers, found a functionally equivalent simplification in the circuit design of hardware accelerators, and accelerated the training of the LLM underpinning AlphaEvolve itself.Furthermore, AlphaEvolve discovered novel, provably correct algorithms that surpass state-of-the-art solutions on a spectrum of problems in mathematics and computer science, significantly expanding the scope of prior automated discovery methods (Romera-Paredes et al., 2023).Notably, AlphaEvolve developed a search algorithm that found a procedure to multiply two 4 × 4 complex-valued matrices using 48 scalar multiplications; offering the first improvement, after 56 years, over Strassen's algorithm in this setting.We believe AlphaEvolve and coding agents like it can have a significant impact in improving solutions of problems across many areas of science and computation.</p>
<p>Introduction</p>
<p>Discovering new high-value knowledge, such as making a novel scientific discovery or developing a commercially valuable algorithm, generally requires a prolonged process of ideation, exploration, backtracking on unpromising hypotheses, experimentation, and validation.There has been much recent interest in using large language models (LLMs) to automate significant parts of this process.Hopes of success here are driven by the breathtaking power of recent LLMs [31,73], which can enhance their capabilities using test-time compute, and the rise of agents that combine language generation and action [85,111].These advances have improved performance across a range of established benchmarks and accelerated discoveryoriented tasks like hypothesis generation [33] and experiment design [7,42].However, getting LLM pipelines all the way to making entirely new scientific or practical discoveries remains challenging.</p>
<p>In this white paper, we present an LLM code superoptimization agent, called AlphaEvolve, that takes on this challenge using a combination of evolutionary computation and LLM-based code generation.AlphaEvolve focuses on the broad spectrum of scientific and engineering discovery problems in which the candidates of discovery can be automatically evaluated.It represents the candidates (for example, new mathematical objects or practical heuristics) as algorithms and uses a set of LLMs to generate, critique, and evolve a pool of such algorithms.The LLM-directed evolution process is grounded using code execution and automatic evaluation.This evaluation mechanism allows AlphaEvolve to avoid any incorrect suggestions from the base LLM [43].</p>
<p>The evolutionary process in AlphaEvolve leverages modern LLMs' ability to respond to feedback, enabling the discovery of candidates that are substantially different from the initial candidate pool in syntax and function.It is applicable both to problems where discovering new algorithms is the intrinsic goal, as well as to the broad range of problems where the solution of interest is not an algorithm itself but an algorithm can describe how that solution is to be constructed or found.In the latter case, discovering the algorithm is only an instrumental goal, but it turns out to be a surprisingly effective strategy compared to searching for the solution directly [80].</p>
<p>The idea of combining evolutionary methods with coding LLMs has been previously explored in various specialized settings.In particular, AlphaEvolve is a substantial enhancement of FunSearch [80] (see Table 1), which used LLM-guided evolution to discover heuristics in order to construct novel mathematical objects or to drive the operation of online algorithms.Also, related approaches have been used in tasks such as discovering policies for simulated robots [55], symbolic regression [34,86], and the synthesis of heuristic functions for combinatorial optimization [61].In contrast to these systems, AlphaEvolve leverages state-of-the-art (SOTA) LLMs to evolve large pieces of code that implement complex algorithms spanning multiple functions and components.As a result, it is able to go significantly beyond its predecessors in scale and generality.</p>
<p>FunSearch [80] AlphaEvolve evolves single function evolves entire code file evolves up to 10-20 lines of code evolves up to hundreds of lines of code evolves code in Python evolves any language needs fast evaluation (≤ 20min on 1 CPU) can evaluate for hours, in parallel, on accelerators millions of LLM samples used thousands of LLM samples suffice small LLMs used; no benefit from larger benefits from SOTA LLMs minimal context (only previous solutions) rich context and feedback in prompts optimizes single metric can simultaneously optimize multiple metrics Table 1 | Capabilities and typical behaviours of AlphaEvolve and our previous agent.</p>
<p>While the use of an automated evaluation metric offers AlphaEvolve a key advantage, it is also a limitation-in particular, it puts tasks that require manual experimentation out of our scope.Because problems in mathematics, computer science, and system optimization typically permit automated evaluation metrics, our efforts on AlphaEvolve focus on these domains.Specifically, we use AlphaEvolve to make progress on several well-known open problems in algorithm design and constructive mathematics, as well as the optimization of critical layers in the large-scale computation stacks at Google.Within algorithm design, we consider the fundamental problem of discovering fast algorithms for multiplying matrices, a problem to which a more specialized AI approach had been applied previously [25].Despite being general-purpose, AlphaEvolve goes beyond [25], improving the SOTA for 14 matrix multiplication algorithms; notably, for 4 × 4 matrices, AlphaEvolve improves Strassen (1969)'s algorithm by discovering an algorithm using 48 multiplications to multiply 4 × 4 complex-valued matrices. 2n mathematics, we consider a broad range of open problems on which one can make progress by discovering constructions (objects) with better properties than all previously known constructions, according to given mathematical definitions.We apply AlphaEvolve to a large number (over 50) of such problems and match the best known constructions on ∼75% of them (in many cases these constructions are likely to already be optimal).On ∼20% of the problems, AlphaEvolve surpasses the SOTA and discovers new, provably better constructions.This includes an improvement on the Minimum Overlap Problem set by Erdős [24] and an improved construction on the Kissing Numbers problem in 11 dimensions [8,30].</p>
<p>Finally, we use AlphaEvolve in four engineering problems spanning different layers of Google's compute stack: discovering scheduling heuristics for Google's cluster management system, optimizing matrix-multiplication kernels used to train LLMs, optimizing arithmetic circuits used within TPUs, and optimizing the runtime of attention in Transformers.Because these components are run repeatedly over a long period of time, any improvements are highly valuable.AlphaEvolve is a coding agent that orchestrates an autonomous pipeline of computations including queries to LLMs, and produces algorithms that address a userspecified task.At a high level, the orchestrating procedure is an evolutionary algorithm that gradually develops programs that improve the score on the automated evaluation metrics associated with the task.A high-level overview of AlphaEvolve is shown in Figure 1, and Figure 2 gives an expanded view.</p>
<p>AlphaEvolve</p>
<p>Task specification</p>
<p>Evaluation.Since AlphaEvolve tackles problems with machine-gradeable solutions, the user must provide a mechanism for automatically assessing generated solutions.This mechanism takes the form of a function ℎ mapping a solution to a set of scalar evaluation metrics.By convention, these metrics are maximized.In our current setup, ℎ is typically implemented as a Python function, called evaluate, with a fixed input/output signature, returning a dictionary of scalars.</p>
<p>Depending on the application, executing this function may take only seconds on a single device or spawn extensive computations.For mathematical problems, the function ℎ is typically very simple.For example, when wishing to find largest possible graphs satisfying a given property, ℎ invokes the evolved code to generate a graph, checks whether the property holds, and then simply returns the size of the graph as the score.In more complicated cases, the function ℎ might involve performing an evolved search algorithm, or training and evaluating a machine learning model.</p>
<p>API.</p>
<p>To support evolving multiple components across a codebase, AlphaEvolve exposes an input API where blocks of code can be annotated as to-be-evolved-by-the-system; see Figure 3a for an illustration.This design facilitates integrating it with existing codebases while requiring only minimal changes, simply by adding special markers (# EVOLVE-BLOCK-START and # EVOLVE-BLOCK-END) as comments into the code.</p>
<p>Any user-provided code inside such evolution blocks serves as the initial solution to be improved by AlphaEvolve, and the rest of the code forms a skeleton that ties the evolved pieces together, so that they can be invoked from evaluate.While this initial implementation must be complete, it can be rudimentary-for instance, consisting of single-line functions that return constants of the appropriate types.</p>
<p>Flexibility in choosing the abstraction.AlphaEvolve can be applied to the same problem in very different ways-especially when the evolved programs are not the final output but a means to discover solutions.For example, AlphaEvolve can evolve the solution in raw string representation (as in classical evolutionary algorithms); evolve a function of a definite form that specifies how to construct the solution from scratch (the approach taken in [80]); evolve a bespoke search algorithm to find the solution within some fixed compute budget; or even co-evolve intermediate solutions and search algorithms together, such that each search algorithm is specifically tailored to further improve upon a particular intermediate solution.</p>
<p>We find that different levels of abstraction work better for different problems.For example, we hypothesize that for problems with highly symmetric solutions it is advantageous to evolve constructor functions as these tend to be more concise [80], whereas for problems with non-symmetric solutions it works better to evolve customized search algorithms.</p>
<p>Prompt sampling</p>
<p>As AlphaEvolve leverages SOTA LLMs, it supports various types of customization and providing long contexts as part of the primary evolution prompt.This prompt comprises multiple previously discovered solutions sampled from the program database, as well as system instructions on how to propose changes to a particular solution.Beyond these key ingredients, users can further tailor prompts to their specific needs in different ways, such as the following.</p>
<p>• Explicit context: details about the problem being solved, such as fixed human-written instructions, equations, code snippets, or relevant literature (e.g., pdf files).• Stochastic formatting: template placeholders with human-provided alternatives for increased diversity, instantiated using probability distributions provided in a separate config file.• Rendered evaluation results: usually this will include a program, the result of executing that program, and the scores assigned by the evaluate function.</p>
<p>• Meta prompt evolution: instructions and context suggested by the LLM itself in an additional prompt-generation step, co-evolved in a separate database analogous to the solution programs.</p>
<p>Creative generation</p>
<p>To drive the evolutionary procedure, AlphaEvolve leverages the capabilities of SOTA LLMs, whose principal role is to digest information about previously developed solutions and propose new, diverse ways to improve the solutions.Although AlphaEvolve is model-agnostic, in ablations we observe that AlphaEvolve performs increasingly better as the underlying LLM improves (see Section 4).</p>
<p>(a)</p>
<p>The current model uses a simple ResNet architecture with only three ResNet blocks.We can improve its performance by increasing the model capacity and adding regularization.This will allow the model to learn more complex features and generalize better to unseen data.We also add weight decay to the optimizer to further regularize the model and prevent overfitting.AdamW is generally a better choice than Adam, especially with weight decay.Output format.When AlphaEvolve asks an LLM to modify existing code, especially within larger codebases, it requests the changes to be provided as a sequence of diff blocks in a specific format:</p>
<p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; SEARCH</p>
<h1>Original code block to be found and replaced ======= # New code block to replace the original &gt;&gt;&gt;&gt;&gt;&gt;&gt; REPLACE</h1>
<p>Here, the code between &lt;&lt;&lt;&lt;&lt;&lt;&lt; SEARCH and ======= is the exact segment to match in the current program version.The code between ======= and &gt;&gt;&gt;&gt;&gt;&gt;&gt; REPLACE is the new segment that will replace the original one.This allows for targeted updates to specific parts of the code.</p>
<p>In cases where the code being evolved is very short, or when a complete rewrite is more appropriate than a small modification, AlphaEvolve can be configured to instruct the LLM to output the entire code block directly, rather than using the diff format.</p>
<p>Models used.</p>
<p>AlphaEvolve employs an ensemble of large language models.Specifically, we utilize a combination of Gemini 2.0 Flash and Gemini 2.0 Pro.This ensemble approach allows us to balance computational throughput with the quality of generated solutions.Gemini 2.0 Flash, with its lower latency, enables a higher rate of candidate generation, increasing the number of ideas explored per unit of time.Concurrently, Gemini 2.0 Pro, possessing greater capabilities, provides occasional, higher-quality suggestions that can significantly advance the evolutionary search and potentially lead to breakthroughs.This strategic mix optimizes the overall discovery process by maximizing the volume of evaluated ideas while retaining the potential for substantial improvements driven by the more powerful model.</p>
<p>Evaluation</p>
<p>To track AlphaEvolve's progress and to select which ideas to propagate in future generations, each new solution proposed by the LLMs is automatically evaluated.In principle, this process amounts to simply executing the user-provided evaluation function ℎ on the generated solution.In practice, AlphaEvolve supports optional mechanisms to make this evaluation more flexible and more efficient:</p>
<p>• Evaluation cascade (hypothesis testing): the user can specify ensembles of test cases of increasing difficulty, such that new solutions are evaluated on the next stage only if they achieve sufficiently promising results in all earlier stages.This helps to prune out less promising solutions more quickly.Moreover, new solutions are initially evaluated on a small scale before being subjected to the main test cases, to filter out faulty programs early.• LLM-generated feedback: in some applications, desirable solutions have certain characteristics that are difficult to capture precisely in the user-provided evaluation function ℎ; for example, simplicity of the discovered program.These properties can be graded using separate LLM calls and added to the dictionary of scores to steer evolution, or they can be used to discard solutions when a criterion is not fulfilled.• Parallelized evaluation: the sample efficiency of AlphaEvolve makes it feasible to spend on the order of 100 compute-hours to evaluate any new solution.However, unless individual evaluations are parallelized to reduce their wall-clock duration, this can slow down the rate at which new generations appear, limiting the ability of the evolutionary algorithm to apply several consecutive mutations.In many applications, evaluation is embarrassingly parallel (for example, running a search algorithm from multiple randomized initializations), allowing AlphaEvolve to distribute this work through asynchronous calls to an evaluation cluster.</p>
<p>Multiple scores.AlphaEvolve allows for optimizing multiple user-provided scores, i.e., evolving objects that achieve a high score under one or multiple evaluation metrics.This has both an intrinsic and instrumental value.While in multiple applications we genuinely care about developing solutions for multiple evaluation metrics (or one solution that is strong on all of them simultaneously), we find that even if one metric is of particular interest, optimizing for multiple metrics often improves results for the single target metric.Perhaps this occurs because programs excelling under different evaluation criteria often possess distinct structures or logic and, by incorporating examples of these diverse, high-performing programs-each representing a different definition of "good"-into the prompts provided to the language model, we can stimulate the generation of more varied candidate solutions, increasing the chances of discovering novel approaches that are highly effective for the target metric.</p>
<p>Evolution</p>
<p>During its evolutionary procedure, AlphaEvolve continually generates a growing number of solutions with evaluation results (scores and program outputs) attached to them.These solutions are stored in an evolutionary database, the primary goal of which is to optimally resurface previously explored ideas in future generations.A key challenge in designing such databases is balancing exploration and exploitation, to continuously improve the best programs while maintaining diversity to encourage exploration of the entire search space.</p>
<p>In AlphaEvolve, the evolutionary database implements an algorithm that is inspired by a combination of the MAP elites algorithm [71] and island-based population models [80,94].</p>
<p>Distributed pipeline</p>
<p>AlphaEvolve is implemented as an asynchronous computational pipeline (using the asyncio Python library) in which many computations are run concurrently, with each computation blocking (waiting) whenever its next step relies on the result of another, yet unfinished computation.More specifically, the asynchronous pipeline comprises a controller, LLM samplers, and evaluation nodes.The entire pipeline is optimized for throughput (rather than the speed of any one particular computation), in order to maximize the number of ideas that can be proposed and evaluated within a specific overall computation budget.</p>
<p>Results</p>
<p>Faster matrix multiplication via finding novel algorithms for tensor decomposition</p>
<p>From accelerating machine learning computations to enabling realistic computer graphics, matrix multiplication serves as a fundamental operation underpinning numerous critical algorithms and applications within computer science.Since the pioneering work of Strassen [92], it has been known that any algorithm for multiplying two matrices can be represented as a decomposition of a given 3D tensor into rank-one tensors.The rank (number of terms) of the decomposition exactly specifies the number of scalar multiplications needed to compute the matrix product.Hence, to develop faster matrix multiplication algorithms one needs to find low-rank decompositions of particular tensors.This problem has been tackled with many approaches, from specialized alternating least squares solvers [90] to deep reinforcement learning [25] and custom search algorithms [46]; yet, despite decades of effort, even for the simple case of multiplying two 3 × 3 matrices, the minimum achievable rank is not known, showcasing the difficulty of the problem.</p>
<p>Starting from the problem description and a standard gradient-based algorithm (including an initializer, a reconstruction loss function, and an Adam optimizer [48]), AlphaEvolve is able to develop sophisticated tensor decomposition algorithms that outperform existing approaches.To evaluate each evolved program, we choose a set of matrix multiplication targets and run the algorithm, initialized with multiple random seeds using the evaluation cascade described in Section 2.4.The performance is then measured as the best (lowest) rank achieved on each target as well as the fraction of seeds that achieved this rank, providing a signal for AlphaEvolve to hill-climb.To ensure the exactness of the decomposition and avoid any potential numerical error, when evaluating, we round each element to the nearest integer or the nearest half-integer; and, to encourage the algorithm to generate near-integral solutions, we include this request in natural language in the LLM's prompt.</p>
<p>In Table 2, one can see that the various algorithms developed by AlphaEvolve improve the state of the art for 14 different matrix multiplication targets.Notably, for multiplying two 4 × 4 matrices, applying the algorithm of Strassen [92] recursively results in an algorithm with 49 multiplications, which works over any field.For the very specific case of multiplying in the field with 2 elements, Fawzi et al. [25] found an algorithm with 47 multiplications.For 56 years, designing an algorithm with fewer than 49 multiplications over any field with characteristic 0 was an open problem.AlphaEvolve is the first method to find an algorithm to multiply two 4 × 4 complex-valued matrices using 48 multiplications.</p>
<p>As shown in Figure 4, AlphaEvolve makes significant changes to the initial program, introducing several original ideas to design increasingly better algorithms.While most results in Table 2 (including ⟨4, 4, 4⟩) were obtained from a simple initial program, we found that for some parameters, seeding the initial program with our own ideas (such as adding stochasticity to the evaluation function or using evolutionary approaches) could further boost performance, highlighting the possibility of scientific collaboration between researchers and AlphaEvolve.</p>
<p>Finding tailored search algorithms for a wide range of open mathematical problems</p>
<p>A significant frontier in mathematical research involves discovering objects or constructions that possess optimal, or near-optimal, properties according to some measure.Examples range from finding dense packings of geometric shapes [28] to identifying functions or sets satisfying specific combinatorial or analytic constraints (e.g., [38,39,68,101]).Progress often relies on finding a single construction that surpasses all previously known examples, thereby establishing new lower or upper bounds for the optimal value.We demonstrate that AlphaEvolve serves as a powerful tool for exploring the vast search space inherent in these problems, successfully tackling a diverse array of open mathematical challenges.</p>
<p>To assess its capabilities, we apply AlphaEvolve to a curated set of over 50 mathematical problems, spanning more than five different branches of mathematics, including analysis, combinatorics, number theory, and geometry, evaluated across numerous specific parameter settings (e.g., different dimensions or sizes).In 75% of the cases AlphaEvolve rediscovered the best known constructions, and in 20% of the cases it discovered a new object that is better than a previously known best construction, thereby improving the SOTA.In all these cases, the initial starting point was a simple or a random construction.These results underscore AlphaEvolve's broad potential as a versatile tool for mathematical research.@@ -45 ,9 +45 ,14 @@ # EVOLVE -BLOCK -START def <em>ge t_opt imizer ( self ) -&gt; optax .G r a d i e n t T r a n s f o r m a t i o n : """ Returns optimizer .# Add penalty for large values ( stability ) .+ l a r g e _ v a l u e _ p e n a l t y = 0.0 + for factor in decomposition : + l a r g e _ v a l u e _ p e n a l t y += jnp .mean ( jnp .abs ( factor ) ** 2) + l a r g e _ v a l u e _ p e n a l t y /= len ( decomposition ) + total_loss += self .hypers .l a r g e _ v a l u e _ p e n a l t y _ w e i g h t * l a r g e _ v a l u e _p e n a l t y + + return jnp .real ( total_loss ) + def l 2</em> los s _c ompl ex ( x : jnp .ndarray , y : jnp .ndarray ) -&gt; jnp .ndarray :</p>
<p>""" E l e m e n t w i s e L2 loss for complex numbers .""" @@ -117 ,6 +255 ,18 @@ return hyper .A significant advantage of the AlphaEvolve configuration used here is its versatility and speed of application.The core methodology, focused on evolving heuristic search programs (detailed below), can be rapidly deployed across a diverse range of mathematical construction problems and conjectures, often requiring less initial problem-specific expert tailoring compared to traditional bespoke approaches.While deep mathematical insight naturally aids in problem formulation and search space definition, AlphaEvolve often demonstrates a capacity to autonomously discover effective search patterns and attack strategies by identifying subtle structures within the problem landscape.This allows for efficient, large-scale exploration across many different problems.</p>
<p>The key methodological innovation enabling these discoveries is AlphaEvolve's ability to evolve heuristic search algorithms rather than directly evolving the constructions themselves.For many problems, particularly those with fast objective function evaluations-which are common in mathematics-we employed an iterative refinement strategy.Each generation of AlphaEvolve was tasked with evolving a program representing a search heuristic.This program was given a fixed time budget (e.g., 1000 seconds) and was shown the best construction found by the previous best heuristic.Its goal was to leverage this starting point and the allotted time to find an even better construction.The evolutionary process thus selects for heuristics that are effective at improving already high-quality solutions.The final constructions were often the result of a sequence of different, specialized heuristics discovered by AlphaEvolve-early heuristics proficient at making large gains from random or simple initial states, and later heuristics adept at fine-tuning near-optimal configurations.This automated discovery of multi-stage, adaptive search strategies is challenging to replicate manually and proved crucial for surpassing the SOTA.</p>
<p>Below are high-level descriptions of some of the problems where AlphaEvolve yielded new results.Full list of problems and details are provided in Appendix B.</p>
<p>• Analysis -Autocorrelation inequalities.AlphaEvolve was able to improve the best known bounds on several autocorrelation inequalities.-Uncertainty principles.AlphaEvolve was able to produce a refined configuration for a problem arising in Fourier analysis, by polishing an uncertainty principle construction [32] leading to a slightly better upper bound.</p>
<p>• Combinatorics and number theory -Erdős's minimum overlap problem.AlphaEvolve established a new upper bound for the minimum overlap problem [24], slightly improving upon the previous record [39].</p>
<p>• Geometry and packing -Kissing number problem.In 11 dimensions, AlphaEvolve improved the lower bound on the kissing number, finding a configuration of 593 non-overlapping unit spheres that can simultaneously touch a central unit sphere, surpassing the previous record of 592 [30].-Packing problems.AlphaEvolve achieved several new results in packing problems, such as packing  points in a shape to minimize the ratio of the maximum and minimum distance, packing various polygons in other polygons in the most efficient way, and variants of the Heilbronn problem concerning point sets avoiding small-area triangles [28].</p>
<p>The full list of problems appears in Appendix B and the new constructions found by AlphaEvolve can be found in the accompanying Google Colab.More examples and details on these problems and the methods used will be provided in an upcoming paper.Most of these discoveries are on open problems suggested to us by external mathematicians Javier Gomez Serrano and Terence Tao, who also advised on how to best formulate them as inputs to AlphaEvolve.This highlights the potential for synergistic partnerships between AI-driven discovery engines like AlphaEvolve and human mathematical expertise.</p>
<p>Optimizing Google's computing ecosystem</p>
<p>In addition to the scientific applications presented in preceding sections, here we demonstrate how AlphaEvolve has been used to improve performance of mission-critical infrastructure and deliver real-world impact.</p>
<p>Improving data center scheduling</p>
<p>Efficiently scheduling compute jobs onto a cluster of machines is a critical optimization problem, particularly at the scale of Google's data centers, orchestrated by Borg [99].This task involves assigning jobs to available machines based on job resource requirements and machine capacity.Inefficient assignments can result in stranded resources: when a machine can no longer accept jobs because it has run out of one kind of resource (e.g., memory) but still has other resources free (e.g., CPU).Improvements in scheduling efficiency can recover these stranded resources, allowing more jobs to be completed on the same amount We address this challenge by framing the online job scheduling problem as a vector bin-packing problem with two variables.In this context, machines represent bins with defined capacities for CPU and memory, and incoming jobs are items with specific resource demands.A heuristic function takes as input a pending job's CPU and memory requirements and a potential machine's CPU and memory availability.This function then outputs a priority score for the machine.The Borg scheduler subsequently assigns the pending job to the machine with the highest priority score as determined by the heuristic function, among other objectives.Because this heuristic only influences the ranking of machines already determined by Borg to be available and capable of running each pending job, the resulting scheduling decisions are effectively correct by construction.</p>
<p>An early version of AlphaEvolve was used to discover a remarkably simple yet effective heuristic function (shown in Figure 6), evolving from the existing one in production.We use a simulator of our data centers to provide feedback to AlphaEvolve based on historical snapshots of workloads and capacity across Google's fleet.We measure the performance of AlphaEvolve's heuristic function on an unseen test dataset of recent workloads and capacity to ensure generalization.Observing that AlphaEvolve's heuristic function outperforms the one in production, we rolled out AlphaEvolve's heuristic function to the entire fleet.Postdeployment measurements across Google's fleet confirmed the simulator results, revealing that this heuristic function continuously recovers on average 0.7% of Google's fleet-wide compute resources, which would otherwise be stranded.AlphaEvolve was chosen over a deep reinforcement learning approach because its code solution not only leads to better performance, but also offers clear advantages in interpretability, debuggability, predictability, and ease of deployment-essential qualities for a mission-critical system.Creating a heuristic that automatically chooses the right tile size (, , ) for all input shapes is difficult because one has to know the matrix multiplication unit's optimal shapes and memory capacity, the memory requirements of surrounding operations, extra operations that are fused into the kernel, and low-level compiler intricacies, among other details.</p>
<p>Enhancing Gemini kernel engineering</p>
<p>Training large models like Gemini requires substantial computational resources.Gemini is built on JAX [9], and Pallas is an extension to JAX that enables writing custom, highly specialized programs (kernels) tailored for optimal execution on hardware accelerators.Therefore, efficient Pallas kernels are crucial for optimizing Gemini's training performance.</p>
<p>A critical aspect of kernel optimization is tuning the tiling strategy for matrix multiplication operations (see Figure 7).This technique involves dividing a large matrix multiplication computation into smaller subproblems to better balance computation with data movement, which is key to accelerating the overall computation.Traditionally, kernel engineers rely on either search-based autotuning or manually crafted heuristics to determine near-optimal tiling configurations for various input shapes.Search-based tuning interrupts the research workflow, necessitating retuning for every input shape change.Conversely, manually crafting effective tiling heuristics is a major engineering bottleneck due to its complexity, demanding a deep understanding of both kernel functionality and hardware intricacies.The key advantage of a performant heuristic is its ability to deliver high performance across arbitrary input shapes.Consequently, to expedite the design of performant kernels for emerging hardware and to simplify their utilization by model developers, we aim to facilitate the heuristic generation process.</p>
<p>We address this challenge by employing AlphaEvolve to optimize tiling heuristics for an important matrix multiplication kernel used to train Gemini.The objective is to minimize the kernel's actual runtime.AlphaEvolve iteratively explores and refines tiling heuristics for this kernel by proposing candidate code, aiming to minimize this runtime on various input shapes on real TPU accelerators.The kernel's correctness is maintained by construction because AlphaEvolve is optimizing the tiling strategy for this kernel rather than altering its underlying mathematical operation.To build the training and evaluation datasets for AlphaEvolve, we automatically collect realistic kernel input shapes from kernel users.Half of these input shapes form the training set, providing the optimization targets during the evolutionary process.The remaining input shapes form the evaluation set, used to test the general applicability of the resulting heuristic.This automated approach enables AlphaEvolve to discover a heuristic that yields an average 23% kernel speedup across all kernels over the existing expert-designed heuristic, and a corresponding 1% reduction in Gemini's overall training time.In addition, the use of AlphaEvolve significantly reduced the kernel optimization time, from several months of dedicated engineering effort to just days of automated experimentation.This acceleration speeds up the deployment of optimized kernels, allowing kernel engineers to dedicate their expertise to more strategic, higher-level optimization problems.Furthermore, AlphaEvolve offers a path towards automating the manual tuning process and improving the ergonomics of Gemini kernel usage.The tiling heuristic discovered by AlphaEvolve has been deployed in production, directly enhancing Gemini's training efficiency and the Gemini team's research and engineering velocity.This deployment also marks a novel instance where Gemini, through the capabilities of AlphaEvolve, optimizes its own training process.</p>
<p>Assisting in hardware circuit design</p>
<p>Specialized hardware, such as Google's Tensor Processing Units (TPUs), is crucial for achieving the resource efficiency required to run modern AI systems at scale.However, designing new computer chips is a complex and time-consuming process, often spanning years.Register-Transfer Level (RTL) optimization, a critical step in this process, involves manually rewriting hardware descriptions to improve metrics like power, performance, and area, demanding months of iteration by highly skilled engineers.</p>
<p>In this work, AlphaEvolve was challenged to optimize an already highly optimized Verilog implementation of a key TPU arithmetic circuit within the matrix multiplication unit.The optimization objectives were to reduce both area and power consumption while preserving the component's core functionality.Crucially, the final proposal must pass robust verification methods to confirm that the modified circuit maintains functional correctness.AlphaEvolve was able to find a simple code rewrite that removed unnecessary bits, a change validated by TPU designers for correctness.While this specific improvement was also independently caught by downstream synthesis tools, AlphaEvolve's contribution at the RTL stage demonstrates its capability to refine source RTL and provide optimizations early in the design flow.</p>
<p>Integrated into an upcoming TPU, this improvement represents Gemini's first direct contribution to TPU arithmetic circuits, achieved via AlphaEvolve, paving the way for future contributions.A key advantage of AlphaEvolve is that it communicates the suggested changes directly in Verilog, the standard language used by hardware engineers, fostering trust and simplifying adoption.This early exploration demonstrates a novel approach where LLMpowered code evolution assists in hardware design, potentially reducing time to market.</p>
<p>Directly optimizing compiler-generated code</p>
<p>The transformer architecture [97] is used in the majority of modern neural networks, ranging from LLMs to AlphaFold [1].The core computation of transformers is the attention mechanism [4], which is most commonly implemented using FlashAttention [21].In our stack, FlashAttention is implemented as an accelerator kernel in Pallas, wrapped by higher-level code in JAX that handles input preparation and output postprocessing.The machine learning compiler (XLA [74]) then translates this implementation into a sequence of intermediate representations (IRs), each adding more detail for execution on particular hardware.At these stages, improved decisions on memory access orchestration or computation scheduling can significantly reduce runtime on specific hardware.</p>
<p>We challenged AlphaEvolve to directly optimize the XLA-generated IRs encapsulating the FlashAttention kernel along with pre-and postprocessing code.We optimized a configuration corresponding to a highly impactful transformer model used for inference at scale on GPUs, with the goal of minimizing the module's overall execution time.This was a particularly challenging task, because (1) the IR is designed for debugging purposes rather than for direct editing by developers, and (2) it is compiler-generated and already highly optimized.Each modification proposed by AlphaEvolve was checked against the reference (unmodified) code on randomized inputs in order to ensure numerical correctness throughout optimization.The final version of the code was rigorously confirmed by human experts to be correct for all possible inputs.</p>
<p>AlphaEvolve was able to provide meaningful optimizations for both levels of abstraction exposed by the IR.Firstly, the FlashAttention kernel for the configuration of interest was sped up by 32%.Secondly, AlphaEvolve found improvements in pre-and postprocessing of kernel inputs and outputs, resulting in a 15% speed up in this part.These results demonstrate the ability of AlphaEvolve to optimize compiler-generated code, offering the potential of incorporating discovered optimizations into existing compilers for specific use cases, or, in the longer term, incorporating AlphaEvolve into the compiler workflow itself.</p>
<p>Ablations</p>
<p>We carried out ablations on two tasks: finding tensor decompositions for faster matrix multiplication (Section 3.1) and computing lower bounds on kissing numbers (Section 3.2), aiming to understand the efficacy of the following components of AlphaEvolve.</p>
<p>• Evolutionary approach.AlphaEvolve utilizes an evolutionary approach, where previously generated programs are stored in a database and used to obtain better programs in subsequent iterations.To analyze the importance of evolution, we consider an alternative approach, which repeatedly feeds the same initial program to the language model.We refer to this approach as "No evolution".• Context in prompts.AlphaEvolve uses powerful language models with large context windows, whose output can be improved significantly by providing problem-specific context in the prompt.To test the importance of context, we consider an alternative approach where no explicit context is added to the prompt.We refer to this approach as "No context in the prompt".
0% 25% 50% 75% 100%
Fraction of compute budget • Meta prompts.AlphaEvolve also uses meta prompts in order to improve the prompts that are provided to the language model.This allows it to potentially surpass the performance one can obtain using a human prompter.To test the efficacy of meta prompting, we disable it for the task of tensor decomposition.We refer to this approach as "No meta prompt evolution".• Full-file evolution.Unlike previous approaches such as FunSearch, AlphaEvolve can evolve an entire codebase instead of focusing on a single function.To test the importance of full-file evolution, we consider an alternative in the context of tensor decomposition where only the loss function is evolved.We refer to this approach as "No full-file evolution".• Powerful language models.AlphaEvolve relies on a mixture of small and large language models in order to obtain highly diverse samples.To understand the importance of this component, we consider an alternative where only a single small base model is used.We refer to this approach as "Small base LLM only".</p>
<p>Figure 8 shows the results of the all-inclusive AlphaEvolve approach as well as the various alternatives listed above.As can be seen, each of the components is responsible for a significant improvement in the results.</p>
<p>Related work</p>
<p>Evolutionary methods.AlphaEvolve extends a long tradition of research on evolutionary or genetic programming [52], where one repeatedly uses a set of mutation and crossover operators to evolve a pool of programs [5,49].In particular, classical evolutionary techniques have succeeded in symbolic regression applications [64,84], automated scientific [20] or algorithmic [16] discovery, and scheduling [115] problems.However, a challenge with these methods is the use of handwritten evolution operators, which can be hard to design and may fail to capture important properties of the domain.In contrast, AlphaEvolve uses LLMs to automate the construction of these operators-it leverages the LLM's world knowledge to mutate programs without the need to pre-define a set of allowed mutation operations.</p>
<p>AlphaEvolve was preceded by a body of recent efforts that combine LLMs and evolution; specifically, it extends the FunSearch system, introduced by Romera-Paredes et al. [80] as an approach to mathematical discovery.FunSearch was subsequently used in downstream tasks such as learning acquisition functions for Bayesian optimization [2], discovering cognitive models [13], computing distances between graphs [100], or combinatorial competitive programming [98].AlphaEvolve goes beyond FunSearch and its recent reimplementation [23] in three key ways.First, while FunSearch only allowed the evolution of a single Python function, AlphaEvolve allows evolution over entire codebases written in a wide range of programming languages.Second, FunSearch optimized a single objective function, while AlphaEvolve provides the ability to perform multiobjective optimization.Third, the LLMs in FunSearch were relatively small and solely trained on code.By contrast, AlphaEvolve uses frontier LLMs and rich forms of natural-language context and feedback.As has been demonstrated in this paper, these extensions allow AlphaEvolve to address important challenging problems that were not amenable to FunSearch.</p>
<p>Other efforts in this category include the approach by Lehman et al. [55], which uses an LLM-guided evolution process to discover programmatic policies for a set of simulated robots; or the approach by Hemberg et al. [40] for code synthesis.Similar approaches have found use in several scientific and mathematical tasks, including symbolic regression [34,86], discovering heuristics for combinatorial optimization [61,112,114], and synthesizing molecular structures [102].LLM-guided evolution has also been used to improve AI systems by enhancing LLM prompts [26] and searching over neural architectures [14].AlphaEvolve differs from these approaches in its scale, flexibility, and general applicability to a broad range of domains.Some recent efforts have augmented the basic paradigm of LLM-guided evolution with complementary ideas.For example, Surina et al. [93] complement the evolution process by continuously finetuning the LLM through reinforcement learning.Grayeli et al. [34] enhance the evolution process with an LLM-directed concept learning step that summarizes high-performing programs in the pool into natural language.More investigation is required to understand the benefits of these ideas at the scale at which AlphaEvolve operates.</p>
<p>Evolutionary methods have also found use in the recent AI Co-Scientist work [33], which seeks to automate scientific discovery using distinct agents for tasks like hypothesis discovery, ranking of hypotheses, and literature review.While AI Co-Scientist represents scientific hypotheses and their evaluation criteria in natural language, AlphaEvolve focuses on evolving code, and directs evolution using programmatic evaluation functions.This choice enables us to substantially sidestep LLM hallucinations, which allows AlphaEvolve to carry on the evolution process for a large number of time steps.Nevertheless, it is possible in principle to combine the two approaches, leading to a method that allows a flexible combination of natural-language and programmatic idioms.Superoptimization and algorithm discovery.AlphaEvolve can be viewed as a method for code superoptimization in that it iteratively improves an initial program using execution feedback.The idea of code superoptimization goes back to the 1980s [67]; pre-LLM approaches to the problem included systematic enumeration [67], genetic search [19], Monte Carlo sampling [83], and deep reinforcement learning [66].Additionally, in limited settings that focus on a single problem such as matrix multiplication, there have been systems such as AlphaTensor that were also able to discover provably correct algorithms [25].</p>
<p>More recently, a body of LLM-based approaches to superoptimization and algorithm discovery have emerged.This literature builds on the success of LLMs in coding tasks, perhaps best illustrated by their success in (simulated) programming competitions as in the case of AlphaCode [58].For instance, LLM agents have been used to optimize certain operations in GPU kernels, such as the attention operation [15] or more general user-specified operations [54].There is also work on using LLMs to discover novel evolutionary algorithms [53], train language models [56], and optimize warehouse-scale computers [59].Other recent work [105] has also proposed the use of multiple LLM agents that converse with each other to accomplish mathematical and coding tasks.</p>
<p>While previous work on using LLMs for algorithm discovery provided promising results, AlphaEvolve's approach to leverage it for evolutionary algorithms allows us to address significantly more challenging problems, as demonstrated in Section 3.</p>
<p>AI for scientific and mathematical discovery.Over the last decade, AI systems have been applied to a wide range of scientific disciplines and tasks, from protein structure prediction [45] to quantum physics [6,81] to climate sciences [51].In particular, there are numerous recent LLM-based methods that target scientific problems in multiple disciplines, such as materials science [44,69,91,116], chemistry [12,62], bioinformatics [65,82], geoscience [76], and quantum physics [29,75] (for surveys on the topic, see [35,63,78]).</p>
<p>Many of these methods use LLMs to automate several distinct stages of the scientific discovery process [36,57,103,106,109], e.g., for generating and ranking hypotheses and ideas [37,87].Of these methods, especially related to AlphaEvolve are the methods that use LLM-guided tree search-based algorithms [11] or LLM-guided evolutionary algorithms [33,110,117].Other works use LLMs to optimize experimental planning and design [7,10,42,72] or experiment execution and workflow [27,60,79,102,113].Finally, there are also works focusing on the data analysis stage [77].AlphaEvolve differs from most of these methods in its use of programmatic hypothesis representations and evaluation metrics.</p>
<p>AI systems have also contributed to advances in pure mathematics [22].In this context, the FunSearch approach [23,80] established LLM-guided evolution as a powerful tool for discovering witnesses for, and counterexamples to, mathematical statements-a problem that is complementary to that of finding formal and informal proofs of mathematical statements [3,18,95,96,107,108].</p>
<p>Discussion</p>
<p>AlphaEvolve demonstrates the surprising power of combining state-of-the-art LLMs with automated evaluation metrics within an evolutionary framework, which can lead to new discoveries on decades-old mathematical problems as well as practical improvements to highly optimized compute stacks.</p>
<p>Interestingly, AlphaEvolve often allows approaching the same problem in different ways: searching for the solution directly, finding a function that constructs it from scratch, or evolving a search algorithm to find it.Applying AlphaEvolve in different ways comes with different biases (for example, finding constructive functions may favor discovering highly symmetric objects [80]) and thus can suit different problems.</p>
<p>AlphaEvolve can also be seen as a test-time compute agent that, through its evolutionary procedure, significantly enhances the capability of the base LLM (compared to, e.g., repeated sampling).On one hand, this can be seen as a compelling demonstration of how machine feedback is able to sustain test-time compute scaling up to regimes where new scientific discoveries and highly valuable practical optimizations are made.On the other hand, a natural next step will be to consider distilling the AlphaEvolve-augmented performance of the base LLMs into the next generation of the base models.This can have intrinsic value and also, likely, uplift the next version of AlphaEvolve.</p>
<p>Beyond distillation, it is also intriguing that AlphaEvolve can make practical discoveries that increase the efficiency of its own infrastructure and of (future versions of) its base LLMs.Currently, the gains are moderate and the feedback loops for improving the next version of AlphaEvolve are on the order of months.However, with these improvements we envision that the value of setting up more environments (problems) with robust evaluation functions will become more widely recognized, which in turn will result in more high-value practical discoveries going forward.</p>
<p>The main limitation of AlphaEvolve is that it handles problems for which it is possible to devise an automated evaluator.While this is true of many problems in the mathematical and computational sciences, there are domains such as the natural sciences where only some experiments can be simulated or automated.While AlphaEvolve does allow for LLM-provided evaluation of ideas, this is not a setting we have optimized for.However, concurrent work shows this is possible [33], and a natural step would be to link the two settings, with LLMs providing feedback on high-level ideas before transitioning to an implementation stage, for which machine feedback is available through code execution.</p>
<p>Terence Tao, Javier Gomez Serrano, and Jordan Ellenberg for suggesting specific open mathematical problems and advising on how to best formulate them for AlphaEvolve; Bogdan Georgiev and Johannes Bausch for their contributions to applying AlphaEvolve to such problems.</p>
<p>Mohammadamin Barekatain, Patrick Heisel, Chase Hensel, Robert O'Callahan, and Pengming Wang for co-leading the application to data center scheduling; Federico Piccinini, Sultan Kenjeyev, and Andrea Michi for making significant contributions; Kieran Milan, Daniel Mankowitz, Cosmin Paduraru, Calin Cascaval, Tammo Spalink, and Natasha Antropova for providing helpful advice; Aaron Gentleman, Gaurav Dhiman, Parthasarathy Ranganatha, and Amin Vahdat for reviewing this work.</p>
<p>Yanislav Donchev for leading the application to Gemini kernel engineering; Richard Tanburn for making significant contributions; Justin Chiu and Julian Walker for providing helpful advice; Jean-Baptiste Alayrac, Dmitry Lepikhin, Sebastian Borgeaud, Koray Kavukcuoglu and Jeff Dean for reviewing this work.Timur Sitdikov for leading the application to TPU circuit design; Georges Rotival for providing the circuit evaluation infrastructure; Kirk Sanders, Srikanth Dwarakanath, Indranil Chakraborty, Christopher Clark for verifying and validating the results in the TPU design; Vinod Nair, Sergio Guadarrama, Dimitrios Vytiniotis, and Daniel Belov for their helpful advice; Kerry Takenaka, Jeff Dean, Sridhar Lakshmanamurthy, Parthasarathy Ranganathan, and Amin Vahdat for reviewing this work.</p>
<p>Benjamin Chetioui, Sergei Lebedev, Alexander Belyaev, Henning Becker, Oleg Shyshkov, and Aliia Khasanova for their help with XLA modifications as well as their helpful advice; Giorgio Arena, Marco Cornero, and Sebastian Bodenstein for reviewing this work.majority of code reviews.M.B., E.D., S.C., N.V., A.Z.W., F.J.R.R., M.E., A.N., B.K., S.S., A.M., and M.P.K. wrote the paper, with input from A.S., P.-S.H and P.K. N.V., E.D., M.E., S.C., A.N., and A.Z.W. created the figures.F.J.R.R., A.M., and A.Z.W. assembled the accompanying Google Colab.S.N., A.D. and P.K. advised and enabled multiple strands of this work.M.B., A.N., N.V. and G.H. coordinated the team.P.K. supervised and coordinated the research program.</p>
<p>Corresponding authors.Matej Balog, Alexander Novikov and Pushmeet Kohli.</p>
<p>A. Faster matrix multiplication: Full results</p>
<p>Full table of results.We provide the best ranks obtained by AlphaEvolve in Table 3. Overall, we considered 54 matrix multiplication sizes in our experiments.These were chosen roughly representing sizes ⟨, , ⟩ where 2 ≤ ,  ≤ 5, with some reasonable cutoff for .Due to symmetries of the underlying matrix multiplication tensor, there exist equivalent algorithms for any permutations of the three axes, hence we focus on sorted sizes  ≤  ≤ .</p>
<p>In all but two considered sizes, AlphaEvolve discovered programs which either match or surpass the best known rank.Anecdotally, we encountered some difficulty when increasing the problem size: when we run the discovered programs on sizes beyond ⟨5, 5, 5⟩ on 1000 random seeds on evaluators with a single GPU accelerator, we often run out of memory.Hence, extending our setup to larger matrix sizes requires further optimization.# Add penalty for large values ( stability ) .+ l a r g e _ v a l u e _ p e n a l t y = 0.0 + for factor in decomposition : + l a r g e _ v a l u e _ p e n a l t y += jnp .mean ( jnp .abs ( factor ) ** 2) + l a r g e _ v a l u e _ p e n a l t y /= len ( decomposition ) + total_loss += self .hypers .l a r g e _ v a l u e _ p e n a l t y _ w e i g h t * l a r g e _ v a l u e _ p e n a l t y + + return jnp .real ( total_loss ) + def l 2_ los s_c omp lex ( x : jnp .ndarray , y : jnp .ndarray ) -&gt; jnp .ndarray :</p>
<p>""" E l e m e n t w i s e L2 loss for complex numbers .""" @ @ -117 ,6 +255 ,18 @@ return hyper .</p>
<p>B. Details of mathematical discoveries of AlphaEvolve</p>
<p>The data and verification code for all constructions reported in this section appear in the accompanying Google Colab.</p>
<p>B.1. First autocorrelation inequality</p>
<p>For any function  : ℝ → ℝ, define the autoconvolution of  as
𝑓 * 𝑓 (𝑡) ∫ ℝ 𝑓 (𝑡 − 𝑥) 𝑓 (𝑥) 𝑑𝑥.
Let</p>
<p>B.2. Second autocorrelation inequality</p>
<p>Let  2 be the smallest constant for which one has
∥ 𝑓 * 𝑓 ∥ 2 2 ≤ 𝐶 2 ∥ 𝑓 * 𝑓 ∥ 1 ∥ 𝑓 * 𝑓 ∥ ∞ for all non-negative 𝑓 : ℝ → ℝ. It is known that 0.88922 ≤ 𝐶 2 ≤ 1
with the lower bound coming from a step function construction [68].AlphaEvolve found a step function with 50 equally-spaced intervals on [−1/4, 1/4] that gives a slightly better lower bound 0.8962 ≤  2 .</p>
<p>B.3. Third autocorrelation inequality</p>
<p>Let  3 be the largest constant satisfying  .This constant controls the asymptotics of the Minimum Overlap Problem of [24].The bounds 0.379005 ≤  5 ≤ 0.380927 are known, where the lower bound was obtained in [104] via convex programming methods.</p>
<p>It is known (see [39]) that this constant is equal to the infimum, over all step functions ℎ on [0, 2] with values in [0, 1] and satisfying The upper bound to the Erdős minimum overlap problem was then obtained by using this result, in [39] by a step function construction.The step function depicted in Figure 10 does ever so slightly better than the previous bound, giving the upper bound of  5 ≤ 0.380924.</p>
<p>B.6. Sums and differences of finite sets</p>
<p>Let  6 be the largest constant for which the following statement holds: there exist arbitrarily large finite sets of integers</p>
<p>B.7. Packing unit regular hexagons inside a regular hexagon</p>
<p>Consider the problem of packing  disjoint regular hexagons with unit side length into a larger regular hexagon, minimizing the side length of the outer hexagon.For  = 11 and  = 12, the best known constructions use outer hexagons of side lengths 3.943 and 4.0, respectively [28].AlphaEvolve found packing arrangements that improve these bounds to 3.931 and 3.942, respectively.These arrangements are shown in Figure 11.</p>
<p>B.8. Minimizing the ratio of maximum to minimum distance</p>
<p>For any  and , the goal of this problem is to find  points in the -dimensional space so as to minimize the ratio between the maximum and minimum pairwise distances.AlphaEvolve found two new constructions improving the best known bounds.The found constructions are shown in Figure 12.</p>
<p>In 2 dimensions, AlphaEvolve found 16 points with ratio ≈ √ 12.889266112, improving the best known bound of √ 12.890 [28].(In this reference, instead of the ratio itself, the square of the ratio is reported, and we use the same convention.)</p>
<p>In 3 dimensions, AlphaEvolve found 14 points with ratio ≈ √ 4.165849767, improving the best known bound of √ 4.168 [28].</p>
<p>B.9. The Heilbronn problem for triangles</p>
<p>The goal of this problem is to find  points on or inside a triangle with unit area so that the area of the smallest triangle formed by these points is maximized.For  = 11, the SOTA was 0.036 [28], and AlphaEvolve found a construction with minimum area larger than 0.0365, which is shown in Figure 13 (left).</p>
<p>B.10. The Heilbronn problem for convex regions</p>
<p>The goal of this problem is to find  points on or inside a convex region with unit area so that the area of the smallest triangle formed by these points is maximized.AlphaEvolve improved two of the best known bounds.</p>
<p>For  = 13, the SOTA was 0.0306 [28], and AlphaEvolve improved it to 0.0309 (see Figure 13 (middle)).For  = 14, the SOTA was 0.0277 [28] and AlphaEvolve improved it to 0.0278 (see Figure 13 (right)).</p>
<p>B.11. Kissing number in dimension 11</p>
<p>The kissing problem asks how many disjoint unit spheres can be packed tangent to a given unit sphere.The maximum such number in  dimensions is called the -dimensional kissing number [8].For  = 11, the best known lower bound was 592 [30] and AlphaEvolve improved this to 593.To prove the lower bound of 593 for the kissing number in dimension 11, AlphaEvolve found 593 many 11-dimensional points with integral coordinates satisfying (a) The maximum norm of these points is smaller than their minimum pairwise distance, and (b) for any pair of the points, the square root of their dot product is smaller than both of their norms.Let  denote the maximum norm of the found points, and normalize all points so their norms become equal to .Because of the second property, this normalization does not decrease their minimum pairwise distance.This results in a set of 593 points in 11 dimensions with exactly the same norm such that their minimum pairwise distance is greater than their norm.Thus, we can scale the norm down to 2 and pack unit spheres centered at the points, obtaining a valid kissing configuration of 593 points.</p>
<p>B.12. Packing circles inside a unit square to maximize sum of radii</p>
<p>Given a positive integer , the problem is to pack  disjoint circles inside a unit square so as to maximize the sum of their radii.AlphaEvolve found two new constructions improving the state of the art [28].</p>
<p>For  = 26, the SOTA was 2.634, and AlphaEvolve improved it to 2.635; see Figure (left).For  = 32, the SOTA was 2.936, and AlphaEvolve improved it to 2.937; see Figure (middle).</p>
<p>B.13. Packing circles inside a rectangle of perimeter 4 to maximize sum of radii</p>
<p>Given a positive integer , the problem is to pack  disjoint circles inside a rectangle of perimeter 4 so as to maximize the sum of their radii.AlphaEvolve found a new construction for  = 21, improving the state of the art from 2.364 [28] to 2.3658; see Figure 14</p>
<p>Figure 1 |
1
Figure 1 | AlphaEvolve high-level overview.</p>
<p>Figure 2 |
2
Figure2| Expanded view of the AlphaEvolve discovery process.The user provides an initial program (with components to evolve marked), evaluation code, and optional configurations (Section 2.1).AlphaEvolve then initiates an evolutionary loop.The Prompt sampler uses programs from the Program database to construct rich prompts (Section 2.2).Given these prompts, the LLMs generate code modifications (diffs), which are applied to create new programs (Section 2.3).These are then scored by Evaluators (Section 2.4), and promising solutions are registered back into the Program database (Section 2.5), driving the iterative discovery of better and better programs.</p>
<p>Figure 3 |
3
Figure 3 | Illustrative example of applying AlphaEvolve to evolving a supervised learning pipeline.All snippets are abbreviated, with ellipsis (...) indicating skipped lines.(a) The user-provided file with blocks marked for evolution, and the special evaluate function that can be invoked to score the current version of the code.(b) Example of an assembled prompt to be provided to the LLMs.(c) Example output generated by the LLM.The proposed diffs in (c) will be applied to the "current program" shown in the prompt (b), and the resulting modified program will then be sent to the evaluators.The evaluators will invoke the evaluate function from (a) in order to obtain the scores of the newly proposed program.</p>
<p>Figure 4 |
4
Figure 4 | Changes proposed by AlphaEvolve to discover faster matrix multiplication algorithms.The full diff is outlined on the left (see magnified version in Figures9a to 9c) and some excerpts are highlighted on the right.In this example, AlphaEvolve proposes extensive changes across several components, including the optimizer and weight initialization (top right), the loss function (middle right), and hyperparameter sweep (bottom right).These changes are highly non-trivial, requiring 15 mutations during the evolutionary process.</p>
<p>Figure 4 | Changes proposed by AlphaEvolve to discover faster matrix multiplication algorithms.The full diff is outlined on the left (see magnified version in Figures9a to 9c) and some excerpts are highlighted on the right.In this example, AlphaEvolve proposes extensive changes across several components, including the optimizer and weight initialization (top right), the loss function (middle right), and hyperparameter sweep (bottom right).These changes are highly non-trivial, requiring 15 mutations during the evolutionary process.</p>
<p>Figure 5 |
5
Figure 5 | Examples of SOTA-breaking mathematical constructions discovered with AlphaEvolve.The versatility of AlphaEvolve allows us to tackle problems in analysis (autocorrelation and uncertainty inequalities), geometry (packing and minimum/maximum distance problems) and combinatorics (Erdős's minimum overlap problem and sums and differences of finite sets).</p>
<p>Figure 7 |
7
Figure7| Visualization of the tiling heuristic problem for a matrix product  = .Creating a heuristic that automatically chooses the right tile size (, , ) for all input shapes is difficult because one has to know the matrix multiplication unit's optimal shapes and memory capacity, the memory requirements of surrounding operations, extra operations that are fused into the kernel, and low-level compiler intricacies, among other details.</p>
<p>Figure 8 |
8
Figure8| Left: Ablations of AlphaEvolve on the problem of finding low-rank tensor decomposition for faster matrix multiplication.Right: Ablations of AlphaEvolve on the problem of finding sphere packings for improving kissing numbers.Each curve shows the performance of an individual setting with increasing compute budget, averaged over all considered targets (higher values on the target metric are better).The shades indicate intra-target standard deviation, averaged over three independent runs of AlphaEvolve, initialized with different random seeds.</p>
<p>max − 1 /2≤𝑡≤1/ 2 | 3 ∫ 1 / 4 − 1 / 4 𝑓
1231414
 *  ()| ≥  ()  2 for any function  : ℝ → ℝ. Clearly  3 ≤  1 , since we now allow  to take positive and negative values.There is a step function that gives the upper bound  3 ≤ 1.45810 [101, page 75].AlphaEvolve found a step function with 400 equally-spaced intervals on [−1/4, 1/4] that gives a slightly better upper bound  3 ≤ 1.4557.</p>
<p>Figure 10 |
10
Figure 10 | Construction found by AlphaEvolve for the minimum overlap problem of Erdős.</p>
<p>) (1 − ℎ( + )).</p>
<p>Figure 11 |
11
Figure 11 | Constructions of the packing problems found by AlphaEvolve.Left: Packing 11 unit hexagons into a regular hexagon of side length 3.931.Right: Packing 12 unit hexagons into a regular hexagon of side length 3.942.</p>
<p>Figure 12 |
12
Figure 12 | Left: 16 points in 2 dimensions achieving a ratio of maximum distance to minimum distance of ≈ √ 12.889266112.Right: 14 points in 3 dimensions achieving a ratio of ≈ √ 4.165849767.Both constructions improve the best known bounds.</p>
<p>Figure 13 |
13
Figure 13 | New constructions found by AlphaEvolve improving the best known bounds on two variants of the Heilbronn problem.Left: 11 points in a unit-area triangle with all formed triangles having area ≥ 0.0365.Middle: 13 points inside a convex region with unit area with all formed triangles having area ≥ 0.0309.Right: 14 points inside a unit convex region with minimum area ≥ 0.0278.</p>
<p>(right).</p>
<p>Figure 14 |
14
Figure 14 | New constructions found by AlphaEvolve improving the best known bounds on packing circles to maximize their sum of radii.Left: 26 circles in a unit square with sum of radii ≥ 2.635.Middle: 32 circles in a unit square with sum of radii ≥ 2.937.Right: circles in a rectangle with perimeter 4, with sum of radii ≥ 2.365.</p>
<p>Table 2 |
2
Upper bounds on the number of scalar multiplications needed to compute the product of an  ×  matrix and an  ×  matrix; equivalently, the rank of the corresponding 3D tensor with parameters ⟨, , ⟩.Beyond the examples shown here, for all parameters , ,  ≤ 5, AlphaEvolve either matched or surpassed the best known solutions, and provided exact algorithms (see Table3in appendix for full results).For ⟨3, 4, 7⟩, ⟨4, 4, 4⟩, and ⟨4, 4, 8⟩, the algorithms discovered by AlphaEvolve use complex-valued multiplications which can be used for exact multiplication of complex or real-valued matrices.The decompositions shown in this table can be found in the accompanying Google Colab.
⟨𝑚, 𝑛, 𝑝⟩ best known [reference] AlphaEvolve⟨2, 4, 5⟩33 [41]32⟨2, 4, 7⟩46 [90]45⟨2, 4, 8⟩52 [90]51⟨2, 5, 6⟩48 [90]47⟨3, 3, 3⟩23 [50]23⟨3, 4, 6⟩56 [47]54⟨3, 4, 7⟩66 [88]63⟨3, 4, 8⟩75 [88]74⟨3, 5, 6⟩70 [47]68⟨3, 5, 7⟩82 [88]80⟨4, 4, 4⟩49 [92]48⟨4, 4, 5⟩62 [46]61⟨4, 4, 7⟩87 [90]85⟨4, 4, 8⟩98 [92]96⟨4, 5, 6⟩93 [47]90⟨5, 5, 5⟩93 [70]93</p>
<p>Left: The heuristic function discovered by AlphaEvolve, tailored to Google's workloads and capacity.Right: Visualization of the heuristic scoring function.Yellow regions represent high scores, while purple regions represent low scores.
100%def alpha_evolve_score(required, free): cpu_residual = required.cpu / free.cpu mem_residual = required.mem / free.mem return -1.0 * (cpu_residual + mem_residual + mem_residual / cpu_residual + cpu_residual / mem_residual)Memory residual25% 50% 75%0% 0%25%50% CPU residual75%100%Figure 6 |
of computational footprint.This recovery is essential to accommodate growing compute needs without a proportional increase in resource consumption.Furthermore, this problem is challenging since it combines typical engineering difficulties, such as debuggability and scale, on top of the classically difficult bin-packing problem.</p>
<p>Table 3 |
3
Full version of Table2, showing the best ranks obtained by AlphaEvolve for tensor decomposition for all considered parameters.Of the 54 targets, AlphaEvolve matches the state of the art in 38 cases, surpasses it in 14 cases (green), and falls behind in 2 cases (red).In all cases, AlphaEvolve provides exact algorithms, using integer or half-integer entries in the decomposition.For ⟨3, 4, 7⟩, ⟨4, 4, 4⟩, and ⟨4, 4, 8⟩, the algorithms discovered by AlphaEvolve use complex-valued multiplications which can be used for exact multiplication of complex or real-valued matrices.The decompositions shown in this table can be found in the accompanying Google Colab.Magnified version of Figure4(left), giving the program that discovers a faster algorithm to multiply 4 × 4 matrices (2/3).
Magnified version of Figure 4 (left). In Figures 9a to 9c, we show a magnified version ofFigure 4 (left), which corresponds to the program that discovers a decomposition of rank 48for the 3D tensor representing the operation of multiplying two 4 × 4 matrices.
Figure 9a | Magnified version of Figure 4(left), giving the program that discovers a faster algorithm to multiply 4 × 4 matrices (1/3).</p>
<p>[38]ith |  + | ≪ | | and |  − | ≫ |  + |  6 .(Here+={+:∈ ,  ∈ } and  −  = { −  :  ∈ ,  ∈ } denote the sumset and difference set, respectively.The notation  ≪  means that  ≤  for some constant  independent of the sets ,  (for sufficiently large sets , ).The notation  ≫  means that  ≥  ′  for some positive constant  ′ independent of the sets ,  (for sufficiently large sets , ).)Corollary 3]for the upper bound and[38, Theorem 1]for the lower bound.The main tool for the lower bound is the following result of Gyarmati et al.[38]: AlphaEvolve found a set  1 of size 2003 improving the lower bound to 1.1479 ≤  6 , and another set  2 of size 54265 further improving the lower bound to 1.1584 ≤  6 .
1.14465 ≤ 𝐶 6 ≤4 3;(2)see [38, 𝐶 6 ≥ 1 +log |𝑈−𝑈| |𝑈+𝑈| log(2 max(𝑈) + 1)(3)
for any finite set  of non-negative integers containing zero satisfying | −  | ≤ 2 max() + 1.</p>
<p>See Acknowledgments and Author information section. * Equal contributions. ©
Google DeepMind. All rights reserved
These discovered algorithms as well as our other new mathematical results can be found at https: //colab.research.google.com/github/google-deepmind/alphaevolve_results/blob/mast er/mathematical_results.ipynb.
AcknowledgementsWe thank Michael Figurnov for reviewing this white paper; Alhussein Fawzi, Bernardino Romera-Paredes, and Ankit Anand for early explorations and insightful discussions; Stig Petersen and Demis Hassabis for support and advice; JD Velasquez for helpful advice on managing the practical applications; and all early users and collaborators of AlphaEvolve for their diverse use cases and insightful feedback, which shaped it into a more robust and versatile tool for a wide range of applications.We gratefully acknowledge the invaluable contributions of these individuals towards the applications highlighted in this white paper:Author informationThese authors contributed equally: Alexander Novikov, Ngân Vũ, Marvin Eisenberger, Emilien Dupont, Po-Sen Huang, Adam Zsolt Wagner, Sergey Shirobokov, Borislav Kozlovskii, and Matej Balog.Let  4 be the largest constant for which one hasfor all even  with max(  (0), f (0)) &lt; 0. It is known[32]that(The upper bound is stated as 0.353 in the paper, but rounding their solution to the fourth digit gives 0.3523).We improved the upper bound to  4 ≤ 0.3521 with a similar linear combination as in[32], but with refined constants that were found by AlphaEvolve.To obtain upper bounds for  4 , one constructs a specific "test function"  satisfying the conditions and calculates the value (  ) ( f ) for this function, which provides an upper bound  4 ≤ (  ) ( f ).Following the approach in[32], the test function is sought in the form  () = () − 2 , where () is an even polynomial constructed as a linear combination of Hermite polynomials  4 ().This form is particularly useful because the Fourier transform ofThus, (  ) is related to the largest positive root of (), and ( f ) is related to the largest positive root of ().Specifically, if () ≥ 0 for large ||, (  ) is the largest positive root of (), and ( f ) is the largest positive root of (), implying (  ) = ( f ).The inequality becomes  4 ≤ ( (  )) 2 .The method involves finding coefficients  0 ,  1 ,  2 , . . .for the polynomial () =  0  0 () +  1  4 ()+ 2  8 ()+. . .such that () satisfies certain constraints (related to  (0) &lt; 0, f (0) &lt; 0 and being positive for large ||) and minimizes the largest positive root of ().In our approach, the polynomial () is constructed such that (0) = 0 (a condition used in the optimization process to simplify constraints), meaning () has a factor of  2 .The largest positive root  max of () is then the largest positive root of ()/ 2 .The upper bound on  4 derived from this construction is  2 max /(2).The refined constants found by AlphaEvolve for. Using these coefficients to construct (), finding its largest positive root  max (by finding the largest positive root of ()/ 2 ), and calculating  2 max /(2) yields the improved upper bound  4 ≤ 0.3521.Qualitatively our linear combination is very similar to the one found in[32], thus empirically confirming their hypothesis the construction is nearly optimal.B.5. Erdős' minimum overlap problemLet  5 be the largest constant for which
Accurate structure prediction of biomolecular interactions with alphafold 3. J Abramson, J Adler, J Dunger, R Evans, T Green, A Pritzel, O Ronneberger, L Willmore, A J Ballard, J Bambrick, Nature. 63080162024</p>
<p>FunBO: Discovering acquisition functions for Bayesian optimization with FunSearch. V Aglietti, I Ktena, J Schrouff, E Sgouritsa, F J R Ruiz, A Malek, A Bellot, S Chiappa, International Conference on Machine Learning. 2025</p>
<p>AI achieves silver-medal standard solving International Mathematical Olympiad problems. 2024AlphaProof and AlphaGeometry teams</p>
<p>Neural machine translation by jointly learning to align and translate. D Bahdanau, K Cho, Y Bengio, arXiv:1409.04732014arXiv preprint</p>
<p>Genetic Programming: An Introduction on the Automatic Evolution of computer programs and its Applications. W Banzhaf, P Nordin, R E Keller, F D Francone, The Morgan Kaufmann Series in Artificial Intelligence. 1998</p>
<p>Learning high-accuracy error decoding for quantum processors. J Bausch, A W Senior, F J H Heras, T Edlich, A Davies, M Newman, C Jones, K Satzinger, M Y Niu, S Blackwell, G Holland, D Kafri, J Atalaya, C Gidney, D Hassabis, S Boixo, H Neven, P Kohli, 10.1038/s41586-024-08148-8Nature. 63580402024</p>
<p>Autonomous chemical research with large language models. D A Boiko, R Macknight, B Kline, G Gomes, 10.1038/s41586-023-06792-0Nature. 62479922023</p>
<p>A survey on the kissing numbers. P Boyvalenkov, S Dodunekov, O Musin, Serdica Math. J. 1310-66003842012</p>
<p>JAX: composable transformations of Python+NumPy programs. J Bradbury, R Frostig, P Hawkins, M J Johnson, C Leary, D Maclaurin, G Necula, A Paszke, J Vanderplas, S Wanderman-Milne, Q Zhang, 2018</p>
<p>Augmenting large language models with chemistry tools. A M Bran, S Cox, O Schilter, C Baldassari, A D White, P Schwaller, 10.1038/s42256-024-00832-8Nature Machine Intelligence. 652024</p>
<p>Chemical reasoning in LLMs unlocks steerable synthesis planning and reaction mechanism elucidation. A M Bran, T A Neukomm, D P Armstrong, Z Jončev, P Schwaller, arXivpreprintarXiv:2503.085372025</p>
<p>A review of large language models and autonomous agents in chemistry. M Caldas Ramos, C J Collison, A D White, 10.1039/D4SC03921AChemical Science. 162025</p>
<p>Discovering symbolic cognitive models from human and animal behavior. P S Castro, N Tomasev, A Anand, N Sharma, R Mohanta, A Dev, K Perlin, S Jain, K Levin, N Éltető, W Dabney, A Novikov, G C Turner, M K Eckstein, N D Daw, K J Miller, K L Stachenfeld, International Conference on Machine Learning. 2025</p>
<p>EvoPrompting: Language models for code-level neural architecture search. A Chen, D M Dohan, D R So, Advances in Neural Information Processing Systems. 2023</p>
<p>Automating GPU kernel generation with DeepSeek-R1 and inference time scaling. T Chen, B Xu, K Devleker, 2025</p>
<p>Symbolic discovery of optimization algorithms. X Chen, C Liang, D Huang, E Real, K Wang, H Pham, X Dong, T Luong, C.-J Hsieh, Y Lu, Q V Le, Advances in Neural Information Processing Systems. 2023</p>
<p>On suprema of autoconvolutions with an application to Sidon sets. A Cloninger, S Steinerberger, Proceedings of the American Mathematical Society. 14582017</p>
<p>Evaluating language models for mathematics through interactions. K M Collins, A Q Jiang, S Frieder, L Wong, M Zilka, U Bhatt, T Lukasiewicz, Y Wu, J B Tenenbaum, W Hart, Proceedings of the National Academy of Sciences. 12124e23181241212024</p>
<p>Adaptive optimizing compilers for the 21st century. K D Cooper, D Subramanian, L Torczon, The Journal of Supercomputing. 232002</p>
<p>Interpretable machine learning for science with pysr and symbolicregression. M Cranmer, arXiv:2305.015822023jl. arXiv preprint</p>
<p>Flashattention: Fast and memoryefficient exact attention with io-awareness. T Dao, D Fu, S Ermon, A Rudra, C Ré, Advances in neural information processing systems. 202235</p>
<p>Advancing mathematics by guiding human intuition with AI. A Davies, P Veličković, L Buesing, S Blackwell, D Zheng, N Tomašev, R Tanburn, P Battaglia, C Blundell, A Juhász, M Lackenby, G Williamson, D Hassabis, P Kohli, 10.1038/s41586-021-04086-xNature. 60078872021</p>
<p>J S Ellenberg, C S Fraser-Taliente, T R Harvey, K Srivastava, A V Sutherland, arXiv:2503.11061Generative modelling for mathematical discovery. 2025arXiv preprint</p>
<p>Some remarks on number theory. P Erdős, Riveon Lematematika. 91955</p>
<p>Discovering faster matrix multiplication algorithms with reinforcement learning. A Fawzi, M Balog, A Huang, T Hubert, B Romera-Paredes, M Barekatain, A Novikov, F J R Ruiz, J Schrittwieser, G Swirszcz, D Silver, D Hassabis, P Kohli, 10.1038/s41586-022-05172-4Nature. 61079302022</p>
<p>Promptbreeder: Self-referential self-improvement via prompt evolution. C Fernando, D Banarse, H Michalewski, S Osindero, T Rocktäschel, arXiv:2309.167972023arXiv preprint</p>
<p>Controllable protein design with language models. N Ferruz, B Höcker, Nature Machine Intelligence. 462022</p>
<p>Erich's Packing Center. E Friedman, </p>
<p>Discovering emergent connections in quantum physics research via dynamic word embeddings. F Frohnert, X Gu, M Krenn, E Van Nieuwenburg, 10.1088/2632-2153/adb00aMachine Learning: Science and Technology. 612025</p>
<p>Highly symmetric lines. M Ganzhinov, arXivpreprintarXiv:2207.08266v12022</p>
<p>Gemini team. Gemini 2.5: Our most intelligent AI model. 2025</p>
<p>Hermite polynomials, linear flows on the torus, and an uncertainty principle for roots. F Gonçalves, D O Silva, S Steinerberger, Journal of Mathematical Analysis and Applications. 45122017</p>
<p>J Gottweis, W.-H Weng, A Daryin, T Tu, A Palepu, P Sirkovic, A Myaskovsky, F Weissenberger, K Rong, R Tanno, K Saab, D Popovici, J Blum, F Zhang, K Chou, A Hassidim, B Gokturk, A Vahdat, P Kohli, Y Matias, A Carroll, K Kulkarni, N Tomasev, Y Guan, V Dhillon, E D Vaishnav, B Lee, T R D Costa, J R Penadés, G Peltz, Y Xu, A Pawlosky, A Karthikesalingam, V Natarajan, arXiv:2502.18864Towards an AI co-scientist. 2025arXiv preprint</p>
<p>Symbolic regression with a learned concept library. A Grayeli, A Sehgal, O Reyes, M Cranmer, S Chaudhuri, Advances in Neural Information Processing Systems. 202437</p>
<p>Agentic AI for scientific discovery: A survey of progress, challenges, and future directions. M Gridach, J Nanavati, C Mack, K Z E Abidine, L Mendes, ICLR Workshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation. 2025</p>
<p>Interesting scientific idea generation using knowledge graphs and LLMs: Evaluations with 100 research group leaders. X Gu, M Krenn, arXivpreprintarXiv:2405.170442024</p>
<p>Embracing foundation models for advancing scientific discovery. S Guo, A H Shariatmadari, G Xiong, A Zhang, 10.1109/bigdata62323.2024.10825618Proceedings of the IEEE International Conference on Big Data. the IEEE International Conference on Big Data2024</p>
<p>Sums and differences of finite sets. K Gyarmati, F Hennecart, I Z Ruzsa, Functiones et Approximatio Commentarii Mathematici. 3712007</p>
<p>J K Haugland, arXiv:1609.08000The minimum overlap problem revisited. 2016arXiv preprint</p>
<p>Evolving code with a large language model. E Hemberg, S Moskal, U.-M O'reilly, 10.1007/s10710-024-09494-2Genetic Programming and Evolvable Machines. 252212024</p>
<p>On minimizing the number of multiplications necessary for matrix multiplication. J E Hopcroft, L R Kerr, 10.1137/0120004SIAM J. Appl. Math. 0036- 1399201Jan. 1971</p>
<p>CRISPR-GPT: An LLM agent for automated design of geneediting experiments. K Huang, Y Qu, H Cousins, W A Johnson, D Yin, M Shah, D Zhou, R Altman, M Wang, L Cong, arXivpreprintarXiv:2404.180212024</p>
<p>A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. L Huang, W Yu, W Ma, W Zhong, Z Feng, H Wang, Q Chen, W Peng, X Feng, B Qin, ACM Transactions on Information Systems. 4322025</p>
<p>LLMatDesign: Autonomous materials discovery with large language models. S Jia, C Zhang, V Fung, arXivpreprintarXiv:2406.131632024</p>
<p>Highly accurate protein structure prediction with AlphaFold. J Jumper, R Evans, A Pritzel, T Green, M Figurnov, O Ronneberger, K Tunyasuvunakool, R Bates, A Žídek, A Potapenko, A Bridgland, C Meyer, S A A Kohl, A J Ballard, A Cowie, B Romera-Paredes, S Nikolov, R Jain, J Adler, T Back, S Petersen, D Reiman, E Clancy, M Zielinski, M Steinegger, M Pacholska, T Berghammer, S Bodenstein, D Silver, O Vinyals, A W Senior, K Kavukcuoglu, P Kohli, D Hassabis, 10.1038/s41586-021-03819-2Nature. 59678732021</p>
<p>Flip graphs for matrix multiplication. M Kauers, J Moosbauer, Proceedings of the 2023 International Symposium on Symbolic and Algebraic Computation. the 2023 International Symposium on Symbolic and Algebraic Computation2023</p>
<p>Some new non-commutative matrix multiplication algorithms of size (𝑛, 𝑚, 6). M Kauers, J Moosbauer, 10.1145/3712020.3712021ACM Commun. Comput. Algebra. 1932-2232581Jan. 2025</p>
<p>Adam: A method for stochastic optimization. D P Kingma, J Ba, International Conference on Learning Representations (ICLR). 2015</p>
<p>Genetic programming as a means for programming computers by natural selection. J R Koza, 10.1007/BF00175355Statistics and Computing. 421994</p>
<p>A noncommutative algorithm for multiplying 3 × 3 matrices using 23 multiplications. J D Laderman, Bulletin of the American Mathematical Society. 8211976</p>
<p>Learning skillful medium-range global weather forecasting. R Lam, A Sanchez-Gonzalez, M Willson, P Wirnsberger, M Fortunato, F Alet, S Ravuri, T Ewalds, Z Eaton-Rosen, W Hu, A Merose, S Hoyer, G Holland, O Vinyals, J Stott, A Pritzel, S Mohamed, P Battaglia, 10.1126/science.adi2336Science. 38266772023</p>
<p>Foundations of genetic programming. W B Langdon, R Poli, 2013Springer Science &amp; Business Media</p>
<p>Large language models as evolution strategies. R Lange, Y Tian, Y Tang, 10.1145/3638530.3654238Proceedings of the Genetic and Evolutionary Computation Conference Companion, GECCO '24 Companion. the Genetic and Evolutionary Computation Conference Companion, GECCO '24 CompanionAssociation for Computing Machinery2024</p>
<p>The AI CUDA engineer: Agentic CUDA kernel discovery, optimization and composition. R T Lange, A Prasad, Q Sun, M Faldor, Y Tang, D Ha, Sakana AI. 022025Technical report</p>
<p>Evolution through large models. J Lehman, J Gordon, S Jain, K Ndousse, C Yeh, K O Stanley, Handbook of evolutionary machine learning. Springer2023</p>
<p>Evolution Through Large Models. J Lehman, J Gordon, S Jain, K Ndousse, C Yeh, K O Stanley, 10.1007/978-981-99-3814-8_11Springer Nature2024Singapore</p>
<p>A large language model framework for literature-based disease-gene association prediction. P.-H Li, Y.-Y Sun, H.-F Juan, C.-Y Chen, H.-K Tsai, J.-H Huang, 10.1093/bib/bbaf070Briefings in Bioinformatics. 1477-40542617002 2025</p>
<p>Competitionlevel code generation with AlphaCode. Y Li, D Choi, J Chung, N Kushman, J Schrittwieser, R Leblond, T Eccles, J Keeling, F Gimeno, A D Lago, T Hubert, P Choy, C De Masson D'autume, I Babuschkin, X Chen, P.-S Huang, J Welbl, S Gowal, A Cherepanov, J Molloy, D J Mankowitz, E S Robson, P Kohli, N Freitas, K Kavukcuoglu, O Vinyals, 10.1126/science.abq1158Science. 37866242022</p>
<p>ECO: An LLM-driven efficient code optimizer for warehouse scale computers. H Lin, M Maas, M Roquemore, A Hasanzadeh, F Lewis, Y Simonson, T.-W Yang, A Yazdanbakhsh, D Altinbüken, F Papa, arXiv:2503.156692025arXiv preprint</p>
<p>Evolutionary-scale prediction of atomic-level protein structure with a language model. Z Lin, H Akin, R Rao, B Hie, Z Zhu, W Lu, N Smetanin, R Verkuil, O Kabeli, Y Shmueli, A Dos Santos Costa, M Fazel-Zarandi, T Sercu, S Candido, A Rives, 10.1126/science.ade2574Science. 37966372023</p>
<p>F Liu, X Tong, M Yuan, X Lin, F Luo, Z Wang, Z Lu, Q Zhang, arXiv:2401.02051Evolution of heuristics: Towards efficient automatic algorithm design using large language model. 2024arXiv preprint</p>
<p>Leveraging prompt engineering in large language models for accelerating chemical research. F Luo, J Zhang, Q Wang, C Yang, 10.1021/acscentsci.4c01935ACS Central Science. 2025</p>
<p>LLM4SR: A survey on large language models for scientific research. Z Luo, Z Yang, Z Xu, W Yang, X Du, arXivpreprintarXiv:2501.043062025</p>
<p>Evolving symbolic density functionals. H Ma, A Narayanaswamy, P Riley, L Li, 10.1126/sciadv.abq0279Science Advances. 8362792022</p>
<p>Large language models generate functional protein sequences across diverse families. A Madani, B Krause, E R Greene, S Subramanian, B P Mohr, J M Holton, J L Olmos, C Xiong, Z Z Sun, R Socher, J S Fraser, N Naik, 10.1038/s41587-022-01618-2Nature Biotechnology. 1087-0156418August 2023</p>
<p>Faster sorting algorithms discovered using deep reinforcement learning. D J Mankowitz, A Michi, A Zhernov, M Gelmi, M Selvi, C Paduraru, E Leurent, S Iqbal, J.-B Lespiau, A Ahern, T Köppe, K Millikin, S Gaffney, S Elster, J Broshear, C Gamble, K Milan, R Tung, M Hwang, T Cemgil, M Barekatain, Y Li, A Mandhane, T Hubert, J Schrittwieser, D Hassabis, P Kohli, M Riedmiller, O Vinyals, D Silver, 10.1038/s41586-023-06004-9Nature. 61879642023</p>
<p>Superoptimizer -A look at the smallest program. H Massalin, 10.1145/36206.36194Proceedings of the Second International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS II). R H Katz, M Freeman, the Second International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS II)Palo Alto, California, USAACM PressOctober 5-8, 1987. 1987</p>
<p>Improved bounds on the supremum of autoconvolutions. M Matolcsi, C Vinuesa, Journal of mathematical analysis and applications. 37222010</p>
<p>Are LLMs ready for real-world materials discovery?. S Miret, N M A Krishnan, arXiv:2402.052002024arXiv preprint</p>
<p>J Moosbauer, M Poole, arXiv:2502.04514Flip graphs with symmetry and new matrix multiplication schemes. 2025arXiv preprint</p>
<p>Illuminating search spaces by mapping elites. J.-B Mouret, J Clune, arXiv:1504.049092015arXiv preprint</p>
<p>DORA AI scientist: Multi-agent virtual research team for scientific exploration discovery and automated report generation. V Naumov, D Zagirova, S Lin, Y Xie, W Gou, A Urban, N Tikhonova, K Alawi, M Durymanov, F Galkin, S Chen, D Sidorenko, M Korzinkin, M Scheibye-Knudsen, A Aspuru-Guzik, E Izumchenko, D Gennert, F W Pun, M Zhang, P Kamya, A Aliper, F Ren, A Zhavoronkov, preprint:10.1101/2025.03.06.641840doi: 10.1101/2025.03.06.6418402025Cold Spring Harbor Laboratory</p>
<p>Introducing OpenAI o3 and o4-mini. Openai, 2025</p>
<p>XLA: composable transformations of Python+NumPy programs. OpenXLA. </p>
<p>Quantum many-body physics calculations with large language models. H Pan, N Mudur, W Taranto, M Tikhanovskaya, S Venugopalan, Y Bahri, M P Brenner, E.-A Kim, 10.1038/s42005-025-01956-yCommunications Physics. 812025</p>
<p>Accelerating Earth science discovery via multi-agent LLM systems. D Pantiukhin, B Shapkin, I Kuznetsov, A A Jost, N Koldunov, arXivpreprintarXiv:2503.058542025</p>
<p>Can large language models serve as data analysts? a multi-agent assisted approach for qualitative data analysis. Z Rasheed, M Waseem, A Ahmad, K.-K Kemell, W Xiaofeng, A N Duc, P Abrahamsson, arXiv:2402.013862024arXiv preprint</p>
<p>Towards scientific intelligence: A survey of LLM-based scientific agents. S Ren, P Jian, Z Ren, C Leng, C Xie, J Zhang, arXivpreprintarXiv:2503.240472025</p>
<p>Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences. A Rives, J Meier, T Sercu, S Goyal, Z Lin, J Liu, D Guo, M Ott, C L Zitnick, J Ma, R Fergus, 10.1073/pnas.2016239118Proceedings of the National Academy of Sciences. 118152021</p>
<p>Mathematical discoveries from program search with large language models. B Romera-Paredes, M Barekatain, A Novikov, M Balog, M P Kumar, E Dupont, F J R Ruiz, J Ellenberg, P Wang, O Fawzi, P Kohli, A Fawzi, 10.1038/s41586-023-06924-6Nature. 62579952023</p>
<p>Quantum circuit optimization with AlphaTensor. F J R Ruiz, T Laakkonen, J Bausch, M Balog, M Barekatain, F J H Heras, A Novikov, N Fitzpatrick, B Romera-Paredes, J Van De Wetering, A Fawzi, K Meichanetzidis, P Kohli, 10.1038/s42256-025-01001-1Nature Machine Intelligence. 732025</p>
<p>Large language models and their applications in bioinformatics. O A Sarumi, D Heider, 10.1016/j.csbj.2024.09.031Computational and Structural Biotechnology Journal. 2001-0370232024</p>
<p>Stochastic superoptimization. E Schkufza, R Sharma, A Aiken, 10.1145/2451116.2451150Architectural Support for Programming Languages and Operating Systems, ASPLOS 2013. V Sarkar, R Bodík, Houston, TX, USAACMMarch 16-20, 2013. 2013</p>
<p>Distilling free-form natural laws from experimental data. M Schmidt, H Lipson, 10.1126/science.1165893Science. 32459232009</p>
<p>Reflexion: Language agents with verbal reinforcement learning. N Shinn, F Cassano, A Gopinath, K Narasimhan, S Yao, Advances in Neural Information Processing Systems. 202336</p>
<p>LLM-SR: Scientific equation discovery via programming with large language models. P Shojaee, K Meidani, S Gupta, A B Farimani, C K Reddy, International Conference on Learning Representations. 2025</p>
<p>Can LLMs generate novel research ideas? a largescale human study with 100+ NLP researchers. C Si, D Yang, T Hashimoto, International Conference on Learning Representations. 2025</p>
<p>Several bilinear algorithms for matrix multiplication problems ⟨3, 𝑃. A Smirnov, 042021</p>
<p>Bilinear algorithm for matrix multiplication ⟨4 × 4 × 9; 104⟩. an irreducibly irrational solution of the brent system?. A Smirnov, 102022</p>
<p>The bilinear complexity and practical algorithms for matrix multiplication. A V Smirnov, Computational Mathematics and Mathematical Physics. 53122013</p>
<p>LLM-Feynman: Leveraging large language models for universal scientific formula and theory discovery. Z Song, M Ju, C Ren, Q Li, C Li, Q Zhou, J Wang, arXivpreprintarXiv:2503.065122025</p>
<p>Gaussian elimination is not optimal. V Strassen, Numerische mathematik. 1341969</p>
<p>Algorithm discovery with LLMs: Evolutionary search meets reinforcement learning. A Surina, A Mansouri, L Quaedvlieg, A Seddas, M Viazovska, E Abbe, C Gulcehre, arXivpreprintarXiv:2504.051082025</p>
<p>Distributed genetic algorithms for function optimization. R Tanese, 1989University of Michigan</p>
<p>An in-context learning agent for formal theorem-proving. A Thakur, G Tsoukalas, Y Wen, J Xin, S Chaudhuri, Conference on Language Models. 2024</p>
<p>Solving olympiad geometry without human demonstrations. T H Trinh, Y Wu, Q V Le, H He, T Luong, Nature. 62579952024</p>
<p>Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, Advances in Neural Information Processing Systems. 2017</p>
<p>Amplifying human performance in combinatorial competitive programming. P Veličković, A Vitvitskyi, L Markeeva, B Ibarz, L Buesing, M Balog, A Novikov, 2024</p>
<p>Largescale cluster management at Google with Borg. A Verma, L Pedrosa, M Korupolu, D Oppenheimer, E Tune, J Wilkes, 10.1145/2741948.2741964Proceedings of the Tenth European Conference on Computer Systems, EuroSys '15. the Tenth European Conference on Computer Systems, EuroSys '15New York, NY, USAAssociation for Computing Machinery2015</p>
<p>GRAIL: Graph edit distance and node alignment using llm-generated code. S Verma, A Goyal, A Mathur, A Anand, S Ranu, International Conference on Machine Learning. 2025</p>
<p>Generalized Sidon sets. C Vinuesa, Del Rio, 2010Universidad Autónoma de MadridPhD thesis</p>
<p>Efficient evolutionary search over chemical space with large language models. H Wang, M Skreta, C T Ser, W Gao, L Kong, F Strieth-Kalthoff, C Duan, Y Zhuang, Y Yu, Y Zhu, Y Du, A Aspuru-Guzik, K Neklyudov, C Zhang, International Conference on Learning Representations. 2025</p>
<p>SciMON: Scientific inspiration machines optimized for novelty. Q Wang, D Downey, H Ji, T Hope, 10.18653/v1/2024.acl-long.18Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 62nd Annual Meeting of the Association for Computational LinguisticsBangkok, ThailandAssociation for Computational Linguistics20241</p>
<p>A new bound for Erdős' minimum overlap problem. E P White, Acta Arithmetica. 2082023</p>
<p>AutoGen: Enabling next-gen LLM applications via multi-agent conversation. Q Wu, G Bansal, J Zhang, Y Wu, B Li, E Zhu, L Jiang, X Zhang, S Zhang, J Liu, A H Awadallah, R W White, D Burger, C Wang, arXivpreprintarXiv:2308.081552023</p>
<p>Nature language model: Deciphering the language of nature for scientific discovery. Y Xia, P Jin, S Xie, L He, C Cao, R Luo, G Liu, Y Wang, Z Liu, Y.-J Chen, Z Guo, Y Bai, P Deng, Y Min, Z Lu, H Hao, H Yang, J Li, C Liu, J Zhang, J Zhu, R Bi, K Wu, W Zhang, K Gao, Q Pei, Q Wang, X Liu, Y Li, H Zhu, Y Lu, M Ma, Z Wang, T Xie, K Maziarz, M Segler, Z Yang, Z Chen, Y Shi, S Zheng, L Wu, C Hu, P Dai, T.-Y Liu, H Liu, T Qin, arXivpreprintarXiv:2502.07527v22025</p>
<p>Leandojo: Theorem proving with retrieval-augmented language models. K Yang, A Swope, A Gu, R Chalamala, P Song, S Yu, S Godil, R J Prenger, A Anandkumar, Advances in Neural Information Processing Systems. 202336</p>
<p>K Yang, G Poesia, J He, W Li, K Lauter, S Chaudhuri, D Song, arXiv:2412.16075Formal mathematical reasoning: A new frontier in AI. 2024arXiv preprint</p>
<p>Large language models for automated open-domain scientific hypotheses discovery. Z Yang, X Du, J Li, J Zheng, S Poria, E Cambria, 10.18653/v1/2024.findings-acl.804Findings of the Association for Computational Linguistics: ACL 2024. Association for Computational Linguistics2024</p>
<p>MOOSE-Chem: Large language models for rediscovering unseen chemistry scientific hypotheses. Z Yang, W Liu, B Gao, T Xie, Y Li, W Ouyang, S Poria, E Cambria, D Zhou, International Conference on Learning Representations. 2025</p>
<p>React: Synergizing reasoning and acting in language models. S Yao, J Zhao, D Yu, N Du, I Shafran, K Narasimhan, Y Cao, International Conference on Learning Representations (ICLR). 2023</p>
<p>Multi-objective evolution of heuristic using large language model. S Yao, F Liu, X Lin, Z Lu, Z Wang, Q Zhang, 10.1609/aaai.v39i25.34922AAAI Conference on Artificial Intelligence. 202539</p>
<p>DrugAssist: A large language model for molecule optimization. G Ye, X Cai, H Lai, X Wang, J Huang, L Wang, W Liu, X Zeng, arXivpreprintarXiv:2401.103342023</p>
<p>ReEvo: Large language models as hyper-heuristics with reflective evolution. H Ye, J Wang, Z Cao, F Berto, C Hua, H Kim, J Park, G Song, Advances in Neural Information Processing Systems. 202437</p>
<p>Genetic Programming for Production Scheduling. F Zhang, S Nguyen, Y Mei, M Zhang, 2021Springer</p>
<p>HoneyComb: A flexible LLM-based agent system for materials science. H Zhang, Y Song, Z Hou, S Miret, B Liu, 10.18653/v1/2024.findings-emnlp.192Findings of the Association for Computational Linguistics: EMNLP 2024. Y Al-Onaizan, M Bansal, Y.-N Chen, Association for Computational LinguisticsNov. 2024</p>
<p>Hypothesis generation with large language models. Y Zhou, H Liu, T Srivastava, H Mei, C Tan, 10.18653/v1/2024.nlp4science-1.10Proceedings of the 1st Workshop on NLP for Science (NLP4Science). L Peled-Cohen, N Calderon, S Lissak, R Reichart, the 1st Workshop on NLP for Science (NLP4Science)Association for Computational Linguistics2024</p>            </div>
        </div>

    </div>
</body>
</html>