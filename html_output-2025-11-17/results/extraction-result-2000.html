<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2000 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2000</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2000</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-46.html">extraction-schema-46</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <p><strong>Paper ID:</strong> paper-280561003</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2505.18602v2.pdf" target="_blank">LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have revolutionized algorithm development, yet their application in symbolic regression, where algorithms automatically discover symbolic expressions from data, remains constrained and is typically designed manually by human experts. In this paper, we propose a meta learning framework that enables LLMs to automatically design selection operators for evolutionary symbolic regression algorithms. We first identify two key limitations in existing LLM-based algorithm evolution techniques: a lack of semantic guidance and code bloat. The absence of semantic awareness can lead to ineffective exchange of useful code components, and bloat results in unnecessarily complex components, both of which can reduce the interpretability of the designed algorithm or hinder evolutionary learning progress. To address these issues, we enhance the LLM-based evolution framework for meta symbolic regression with two key innovations: a complementary, semantics-aware selection operator and bloat control. Additionally, we embed domain knowledge into the prompt, enabling the LLM to generate more effective and contextually relevant selection operators. Our experimental results on symbolic regression benchmarks show that LLMs can devise selection operators that outperform nine expert-designed baselines, achieving state-of-the-art performance. Moreover, the evolved operator can further improve the state-of-the-art symbolic regression algorithm, achieving the best performance among 26 symbolic regression and machine learning algorithms across 116 regression datasets. This demonstrates that LLMs can exceed expert-level algorithm design for symbolic regression.</p>
                <p><strong>Cost:</strong> 0.023</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2000.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2000.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-Meta-SR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A meta-evolution framework that uses an LLM (GPT-4.1 Mini) with in-context learning to generate, crossover and mutate selection-operator code for genetic-programming-based symbolic regression; it incorporates semantic feedback, prompt-based bloat control, and domain-knowledge prompts to guide generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM-Meta-SR</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based (learned/generated by LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Generates Python selection-operator implementations by prompting an LLM (GPT-4.1 Mini) using in-context examples and performance history (dataset-specific score vectors). Uses LLM-based crossover (prompting LLM with two parent codes + score vectors) and mutation (prompting with elite code), enforces a target line-count in prompts, and applies multi-objective survival selection combining average task performance and code length (measured as non-empty non-comment lines). Semantic-aware parent pairing is used (complementarity measured via dataset-specific score vectors) and vectorized NumPy operations are preferred in prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Meta-evolution (the 'training' of operators) used 4 high-dimensional datasets from SRBench (OpenML IDs: 505, 4544, 588, 650). Dataset summaries: OPENML 505 (n=240, d=124), 4544 (n=10,591, d=17), 588 (n=10,000, d=100), 650 (n=500, d=50). Final evaluation used 116 unseen SRBench datasets (4 meta-evolution datasets excluded).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Symbolic regression (SRBench); meta-evolution inner-loop on 4 SRBench datasets; final evaluation on 116 SRBench datasets</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Expert-designed selection operators used as baselines (examples mentioned: tournament selection, Boltzmann sampling with temperature scheduling, automatic-ε-lexicase / AutoLex, CPS, PLex, DALex, D-Split, RDS-Tour), as well as prior LLM-driven algorithm-evolution frameworks referenced (FunSearch, ReEvo, EoH).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Median historical best average test R² = 0.86 (LLM-Meta-SR, Table 1) across the reported runs; paper reports that LLM-discovered operators outperform nine expert-designed baselines and achieve state-of-the-art performance across 116 datasets (numerical per-baseline breakdown not fully enumerated in main text).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td>Diversity/novelty measured with cosine-distance between residuals (population-level cosine distance) and complementarity for pairing measured via per-dataset score vectors (µ_i = (1/d) Σ_j max(s_a,j, s_i,j)); no absolute percentage values reported, but results show higher maintained diversity vs baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Operators were evaluated on 116 datasets not used during meta-evolution and generalized well (LLM-evolved operator improved performance across those unseen datasets). However, a logical bug revealed poorer behavior on small datasets (datasets with ≤100 instances) showing sensitivity to the distribution of training/inner-loop datasets; a repaired operator fixed that failure mode.</td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td>Ablations show strong dependence on prompt-embedded domain knowledge (removing domain knowledge caused the largest performance drop). The small-dataset bug indicates bias / fragility when meta-evolution only sees larger/high-dimensional datasets—lack of exposure to small datasets produced a logical failure on small data.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>Meta-evolution with LLMs has higher token/inference cost; bloat (longer generated code) substantially increases token count (Figure 12). Prompt-based length limits and multi-objective survival reduce token counts. The evolved Omni operator is slightly more time-consuming during selection than some baselines (increasing symbolic-regression training time slightly) but tends to produce smaller models, reducing evaluation/deployment cost. No exact monetary/token-cost numbers provided.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td>Evolved operators transferred when plugged into a state-of-the-art Transformer-assisted SR algorithm (RAG-SR) producing RAG-SR-Omni; this hybrid outperformed original RAG-SR across 116 datasets (median R², model sizes, training time improved), indicating practical transferability.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td>Not directly compared; framework uses a general-purpose LLM (GPT-4.1 Mini) plus domain-knowledge prompt injection. Ablation removing domain knowledge shows substantial performance loss, implying prompt-injected domain knowledge is important even for a generally pretrained LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td>Ablations include: without semantics (W/O Semantics), without semantics and bloat control (W/O SE+BC), without domain knowledge (W/O Knowledge), and combinations. Key findings: removing domain knowledge causes the largest drop; semantic-aware evolution materially improves objective scores (providing score vectors rather than averages); bloat control reduces code length and token costs and stabilizes optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>The framework uses in-context LLM generation that conditions on execution history (per-dataset score vectors) enabling the LLM to adapt generation to observed behaviors; mutation generates variants from the current elite operator (LLM Mutate), but no gradient fine-tuning of the LLM itself is performed.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>1) Code bloat: LLMs tend to produce overly long/intricate code if not constrained; 2) Logical bug on small datasets due to structured division producing empty subsets (fixed by repaired Omni); 3) LLM not always obeying length constraints, requiring multi-objective survival selection; 4) occasional generation of invalid code (fallback tournament operator used).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Semantic (per-instance) feedback is critical: providing dataset-specific score vectors and selecting semantically complementary parents produces better offspring than averaging behavior. Bloat control (prompted length targets + multi-objective survival) is necessary to control complexity, token cost, and optimization stability. Injecting domain knowledge into prompts is essential for high performance. LLM-based crossover can semantically fuse building blocks from parents producing offspring that generalize across tasks better than simple concatenation or random subtree crossover. However, generalization depends on diversity of meta-evolution training instances (exposure to small datasets needed to avoid logical failure modes). Overall, LLM-generated selection operators can outperform expert-designed traditional operators on SRBench while trading additional meta-evolution inference cost for downstream model compactness and better R².</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2000.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2000.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Omni</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Omni selection operator (LLM-evolved)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A specific selection operator discovered by LLM-Meta-SR that combines subset-specific error (specificity), model complexity (nodes + height), residual-based complementarity (absolute cosine similarity), and stage-aware weighting to select complementary parents and maintain diversity while favoring interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Omni (evolved selection operator)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-generated operator (handed as code produced by LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Selects parent A by ranking candidates on subset MSE (structured + random subsets) with complexity as a tie-breaker; selects parent B by computing absolute cosine similarity between residuals and combining complementarity score with complexity via a stage-dependent comp_factor; implements vectorized NumPy operations; code length constrained in prompt. Operators include stage-aware linear weighting to relax parsimony early and increase it later.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Produced by meta-evolution using the 4 SRBench meta-training datasets (OpenML 505, 4544, 588, 650); evaluated on 116 SRBench datasets (4 excluded).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Symbolic regression (SRBench)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared experimentally against expert-designed selection operators such as AutoLex (automatic-lexicase), CPS, tournament selection, Boltzmann sampling, PLex, DALex, D-Split, RDS-Tour and others; also used to replace automatic-lexicase in RAG-SR to form RAG-SR-Omni.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Reported to outperform the expert-designed baselines on test R² across SRBench; when evaluated as part of LLM-Meta-SR the median historical best score was 0.86 (Table 1) and Omni produced better test R² plots (Fig.7) and significant pairwise improvements (Wilcoxon with BH correction) relative to baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td>Population diversity measured via cosine distance between individuals' residual vectors; Omni maintained higher diversity than baseline operators (quantified trajectories shown, absolute numbers not tabulated in main text).</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Generalized across 116 unseen datasets and improved downstream RAG-SR performance; however, original Omni had a logical corner-case failure on small datasets (≤100 instances) that was fixed in a repaired version, which improved small-dataset performance but slightly increased tree sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td>The small-dataset bug indicates Omni was biased by meta-evolution exposure to larger datasets; removal of domain knowledge degraded performance, indicating sensitivity to prompt-provided domain priors.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>Omni is slightly more time-consuming during selection than some other operators (increasing symbolic-regression training time marginally), but it tends to produce smaller models which reduces evaluation/deployment cost; no absolute runtimes provided in-text, figures compare training times qualitatively.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td>When plugged into RAG-SR (forming RAG-SR-Omni), Omni improved median R², model sizes, and training time compared to original RAG-SR across 116 datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td>Removal of semantic evolution or bloat control hurts learned operator discovery; domain knowledge in prompts is crucial—omitting it causes largest performance drop.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td>Monitored code-length evolution and token counts; bloat control stabilized code length (operators stabilized around ~50 lines with bloat control) and reduced token count versus no bloat control.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>Operator uses stage-aware weighting (evolutionary stage) to adapt selection pressure over generations (favor exploration early, exploitation late).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Logical bug on small datasets due to structured division producing empty subsets (fixed by repaired version that replaces empty subsets with random subsets); LLM sometimes ignores prompt length target requiring multi-objective survival to enforce compactness.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>A selection operator that integrates per-instance specificity, complexity penalties, residual-based complementarity, and stage-awareness can (1) maintain population diversity, (2) find parsimonious models with higher R², and (3) outperform traditional hand-designed selection methods. However, robustness requires exposure to a diverse set of training instances (including small datasets) during meta-evolution and explicit bloat control.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2000.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2000.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Omni-Zero</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Omni-Zero (LLM-evolved operator without domain-knowledge prompts)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A selection operator evolved by LLM-Meta-SR when domain-knowledge prompts were omitted; demonstrates that LLMs can synthesize selection heuristics from scratch but tend to rely more on aggregate MSE and miss some complementarity/specificity behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Omni-Zero</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based (learned/generated without domain-knowledge prompts)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Generated by the same meta-evolution pipeline but with domain-knowledge prompts removed. Uses cosine-distance-based novelty for diversity, a non-linear stage-aware weighting function for error vs novelty trade-off, and complexity penalty based on nodes and tree height; however, it lacks explicit complementarity metrics and specificity-based subset selection.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Meta-evolution used same inner-loop datasets but prompt removed; thus operators were evolved from the LLM's internal knowledge plus execution history.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Symbolic regression (SRBench)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to Omni and expert-designed operators in ablations; Omni-Zero displays desirable properties (diversity- and stage-awareness) but is weaker in complementarity and specificity.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td>Novelty defined with cosine-distance-based novelty score (formula provided in text); used normalized cosine similarities for robustness; absolute numeric comparisons vs baselines not tabulated.</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Operates reasonably but inferior to Omni (with domain knowledge) on the benchmark; lacks some behaviors that improve generalization across diverse tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td>Without domain knowledge, LLM can still craft functional operators but performs worse than when domain knowledge is included—indicating the LLM's internal prior is insufficient to match prompt-augmented performance.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td>Analysis showed Omni-Zero satisfies several desirable properties but misses specificity and complementarity features; its selection is dominated by mean squared error in some cases.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>Uses a stage-aware non-linear weighting function for balancing exploration vs exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Dominated by aggregate MSE; lacks complementarity-aware pairing and specificity guidance, which harms multi-dataset combination performance.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>LLMs can autonomously generate selection heuristics from scratch, but prompt-injected domain knowledge materially improves the quality and generality of evolved operators.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2000.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2000.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAG-SR-Omni</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RAG-SR-Omni: RAG-SR with Omni selection operator</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid system created by replacing automatic-ε-lexicase selection in the Transformer-assisted RAG-SR algorithm with the LLM-evolved Omni selection operator, resulting in improved performance across symbolic-regression benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>RAG-SR-Omni</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>hybrid (Transformer-assisted SR with LLM-evolved selection operator)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>RAG-SR is a retrieval-augmentation-generation Transformer-assisted symbolic regression algorithm; in RAG-SR-Omni the only change is replacing the automatic-ε-lexicase selection with the Omni operator (Code 3). All other components of RAG-SR remain unchanged.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Evaluated on 116 SRBench datasets (excluding the 4 used in meta-evolution).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Symbolic regression (SRBench)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared directly to RAG-SR (original) and to 25 other SR/ML algorithms in the benchmark (26 algorithms total).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Paper reports that RAG-SR-Omni outperforms RAG-SR in terms of median R², model sizes, and training time and achieves the best performance among 26 symbolic regression and ML algorithms on SRBench (no single numeric per-algorithm table in the main text, but summarized in Figure 11 and Pareto plots).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Demonstrates improved generalization across the 116 dataset benchmark (datasets were unseen during meta-evolution).</td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>RAG-SR-Omni shows improved training time relative to RAG-SR in the reported experiments (figure-based comparisons), meaning that substitution of the learned operator produced not only accuracy and size benefits but also training-time benefits in this setup.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td>Represents direct transfer of a learned selection operator into a different SR pipeline (transformer-assisted) successfully improving overall performance.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Integrating an LLM-evolved selection operator into an independent, state-of-the-art SR pipeline can yield consistent improvements in accuracy, parsimony (model size), and training time, indicating that learned operators can be modularly transferred across SR architectures.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2000.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2000.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Expert baselines</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Expert-designed selection operators (AutoLex, CPS, PLex, DALex, D-Split, tournament, Boltzmann, RDS-Tour, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of traditional, manually designed selection operators commonly used in genetic programming and symbolic regression (lexicase variants, tournament selection, Boltzmann sampling, CPS, etc.), used as experimental baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Expert-designed selection operators (group)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>hand-designed / traditional GP selection operators</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Includes many common selection mechanisms: tournament selection (select best from sampled subset), lexicase selection and its variants (automatic-ε-lexicase, probabilistic lexicase, down-sampled lexicase variants), Boltzmann sampling with temperature scheduling, CPS (first parent by tournament then other criteria), RDS-Tour (random down-sampled tournament), PLex, DALex, D-Split, etc. Parameters set to defaults or literature-recommended values in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Symbolic regression (SRBench) used as baselines for comparisons</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Used as baselines to compare against LLM-evolved operators in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>Some traditional operators are computationally cheaper for selection, but Omni's slightly higher selection cost is offset by producing smaller models and better final performance; paper provides qualitative training-time plots but not exhaustive numeric cost-per-operator tables.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Traditional expert-designed selection operators are strong baselines, but LLM-evolved operators can surpass them when semantic feedback, bloat control, and domain-knowledge prompting are used; lexicase-style subset emphasis remains a strong principle and is explicitly leveraged/extended by the LLM-evolved operators.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2000.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2000.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-evolution frameworks (mention)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Related LLM-driven algorithm-evolution systems (FunSearch, ReEvo, EoH, HSEvo, LLM-SR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Related systems/frameworks that use LLMs for algorithm/heuristic generation or to replace traditional evolutionary operators; cited in related work but not experimentally compared head-to-head within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>FunSearch / ReEvo / EoH / HSEvo / LLM-SR (referenced frameworks)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based / LLM-assisted algorithm evolution frameworks (mentioned)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Examples: FunSearch (LLM-based algorithm evolution for combinatorial tasks), ReEvo (random selection baseline and LLM-driven evolution), EoH (LLM-based heuristic evolution), HSEvo (diversity-driven harmony search + GA using LLMs), LLM-SR (LLM for symbolic regression generation). These are cited as prior work and motivating context; this paper extends them by adding semantic-aware selection and bloat control.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Various optimization tasks and symbolic regression (depending on the cited work); not directly reimplemented here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Prior LLM-driven algorithm-evolution techniques provide groundwork but often omit fine-grained semantic feedback and do not address code bloat; this paper situates itself as addressing those gaps.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>FunSearch <em>(Rating: 2)</em></li>
                <li>ReEvo <em>(Rating: 2)</em></li>
                <li>EoH <em>(Rating: 2)</em></li>
                <li>RAG-SR: retrieval-augmentation-generation-based symbolic regression <em>(Rating: 2)</em></li>
                <li>LLM-SR: Scientific Equation Discovery via Programming with Large Language Models <em>(Rating: 1)</em></li>
                <li>AutoML-Zero <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2000",
    "paper_id": "paper-280561003",
    "extraction_schema_id": "extraction-schema-46",
    "extracted_data": [
        {
            "name_short": "LLM-Meta-SR",
            "name_full": "LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression",
            "brief_description": "A meta-evolution framework that uses an LLM (GPT-4.1 Mini) with in-context learning to generate, crossover and mutate selection-operator code for genetic-programming-based symbolic regression; it incorporates semantic feedback, prompt-based bloat control, and domain-knowledge prompts to guide generation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "LLM-Meta-SR",
            "operator_type": "LLM-based (learned/generated by LLM)",
            "operator_description": "Generates Python selection-operator implementations by prompting an LLM (GPT-4.1 Mini) using in-context examples and performance history (dataset-specific score vectors). Uses LLM-based crossover (prompting LLM with two parent codes + score vectors) and mutation (prompting with elite code), enforces a target line-count in prompts, and applies multi-objective survival selection combining average task performance and code length (measured as non-empty non-comment lines). Semantic-aware parent pairing is used (complementarity measured via dataset-specific score vectors) and vectorized NumPy operations are preferred in prompts.",
            "training_data_description": "Meta-evolution (the 'training' of operators) used 4 high-dimensional datasets from SRBench (OpenML IDs: 505, 4544, 588, 650). Dataset summaries: OPENML 505 (n=240, d=124), 4544 (n=10,591, d=17), 588 (n=10,000, d=100), 650 (n=500, d=50). Final evaluation used 116 unseen SRBench datasets (4 meta-evolution datasets excluded).",
            "domain_or_benchmark": "Symbolic regression (SRBench); meta-evolution inner-loop on 4 SRBench datasets; final evaluation on 116 SRBench datasets",
            "comparison_baseline": "Expert-designed selection operators used as baselines (examples mentioned: tournament selection, Boltzmann sampling with temperature scheduling, automatic-ε-lexicase / AutoLex, CPS, PLex, DALex, D-Split, RDS-Tour), as well as prior LLM-driven algorithm-evolution frameworks referenced (FunSearch, ReEvo, EoH).",
            "performance_learned_operator": "Median historical best average test R² = 0.86 (LLM-Meta-SR, Table 1) across the reported runs; paper reports that LLM-discovered operators outperform nine expert-designed baselines and achieve state-of-the-art performance across 116 datasets (numerical per-baseline breakdown not fully enumerated in main text).",
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": "Diversity/novelty measured with cosine-distance between residuals (population-level cosine distance) and complementarity for pairing measured via per-dataset score vectors (µ_i = (1/d) Σ_j max(s_a,j, s_i,j)); no absolute percentage values reported, but results show higher maintained diversity vs baselines.",
            "out_of_distribution_performance": "Operators were evaluated on 116 datasets not used during meta-evolution and generalized well (LLM-evolved operator improved performance across those unseen datasets). However, a logical bug revealed poorer behavior on small datasets (datasets with ≤100 instances) showing sensitivity to the distribution of training/inner-loop datasets; a repaired operator fixed that failure mode.",
            "training_bias_evidence": "Ablations show strong dependence on prompt-embedded domain knowledge (removing domain knowledge caused the largest performance drop). The small-dataset bug indicates bias / fragility when meta-evolution only sees larger/high-dimensional datasets—lack of exposure to small datasets produced a logical failure on small data.",
            "computational_cost_comparison": "Meta-evolution with LLMs has higher token/inference cost; bloat (longer generated code) substantially increases token count (Figure 12). Prompt-based length limits and multi-objective survival reduce token counts. The evolved Omni operator is slightly more time-consuming during selection than some baselines (increasing symbolic-regression training time slightly) but tends to produce smaller models, reducing evaluation/deployment cost. No exact monetary/token-cost numbers provided.",
            "transfer_learning_results": "Evolved operators transferred when plugged into a state-of-the-art Transformer-assisted SR algorithm (RAG-SR) producing RAG-SR-Omni; this hybrid outperformed original RAG-SR across 116 datasets (median R², model sizes, training time improved), indicating practical transferability.",
            "domain_specific_vs_general_pretraining": "Not directly compared; framework uses a general-purpose LLM (GPT-4.1 Mini) plus domain-knowledge prompt injection. Ablation removing domain knowledge shows substantial performance loss, implying prompt-injected domain knowledge is important even for a generally pretrained LLM.",
            "ablation_study_results": "Ablations include: without semantics (W/O Semantics), without semantics and bloat control (W/O SE+BC), without domain knowledge (W/O Knowledge), and combinations. Key findings: removing domain knowledge causes the largest drop; semantic-aware evolution materially improves objective scores (providing score vectors rather than averages); bloat control reduces code length and token costs and stabilizes optimization.",
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": "The framework uses in-context LLM generation that conditions on execution history (per-dataset score vectors) enabling the LLM to adapt generation to observed behaviors; mutation generates variants from the current elite operator (LLM Mutate), but no gradient fine-tuning of the LLM itself is performed.",
            "failure_modes": "1) Code bloat: LLMs tend to produce overly long/intricate code if not constrained; 2) Logical bug on small datasets due to structured division producing empty subsets (fixed by repaired Omni); 3) LLM not always obeying length constraints, requiring multi-objective survival selection; 4) occasional generation of invalid code (fallback tournament operator used).",
            "key_findings_for_theory": "Semantic (per-instance) feedback is critical: providing dataset-specific score vectors and selecting semantically complementary parents produces better offspring than averaging behavior. Bloat control (prompted length targets + multi-objective survival) is necessary to control complexity, token cost, and optimization stability. Injecting domain knowledge into prompts is essential for high performance. LLM-based crossover can semantically fuse building blocks from parents producing offspring that generalize across tasks better than simple concatenation or random subtree crossover. However, generalization depends on diversity of meta-evolution training instances (exposure to small datasets needed to avoid logical failure modes). Overall, LLM-generated selection operators can outperform expert-designed traditional operators on SRBench while trading additional meta-evolution inference cost for downstream model compactness and better R².",
            "uuid": "e2000.0"
        },
        {
            "name_short": "Omni",
            "name_full": "Omni selection operator (LLM-evolved)",
            "brief_description": "A specific selection operator discovered by LLM-Meta-SR that combines subset-specific error (specificity), model complexity (nodes + height), residual-based complementarity (absolute cosine similarity), and stage-aware weighting to select complementary parents and maintain diversity while favoring interpretability.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Omni (evolved selection operator)",
            "operator_type": "LLM-generated operator (handed as code produced by LLM)",
            "operator_description": "Selects parent A by ranking candidates on subset MSE (structured + random subsets) with complexity as a tie-breaker; selects parent B by computing absolute cosine similarity between residuals and combining complementarity score with complexity via a stage-dependent comp_factor; implements vectorized NumPy operations; code length constrained in prompt. Operators include stage-aware linear weighting to relax parsimony early and increase it later.",
            "training_data_description": "Produced by meta-evolution using the 4 SRBench meta-training datasets (OpenML 505, 4544, 588, 650); evaluated on 116 SRBench datasets (4 excluded).",
            "domain_or_benchmark": "Symbolic regression (SRBench)",
            "comparison_baseline": "Compared experimentally against expert-designed selection operators such as AutoLex (automatic-lexicase), CPS, tournament selection, Boltzmann sampling, PLex, DALex, D-Split, RDS-Tour and others; also used to replace automatic-lexicase in RAG-SR to form RAG-SR-Omni.",
            "performance_learned_operator": "Reported to outperform the expert-designed baselines on test R² across SRBench; when evaluated as part of LLM-Meta-SR the median historical best score was 0.86 (Table 1) and Omni produced better test R² plots (Fig.7) and significant pairwise improvements (Wilcoxon with BH correction) relative to baselines.",
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": "Population diversity measured via cosine distance between individuals' residual vectors; Omni maintained higher diversity than baseline operators (quantified trajectories shown, absolute numbers not tabulated in main text).",
            "out_of_distribution_performance": "Generalized across 116 unseen datasets and improved downstream RAG-SR performance; however, original Omni had a logical corner-case failure on small datasets (≤100 instances) that was fixed in a repaired version, which improved small-dataset performance but slightly increased tree sizes.",
            "training_bias_evidence": "The small-dataset bug indicates Omni was biased by meta-evolution exposure to larger datasets; removal of domain knowledge degraded performance, indicating sensitivity to prompt-provided domain priors.",
            "computational_cost_comparison": "Omni is slightly more time-consuming during selection than some other operators (increasing symbolic-regression training time marginally), but it tends to produce smaller models which reduces evaluation/deployment cost; no absolute runtimes provided in-text, figures compare training times qualitatively.",
            "transfer_learning_results": "When plugged into RAG-SR (forming RAG-SR-Omni), Omni improved median R², model sizes, and training time compared to original RAG-SR across 116 datasets.",
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": "Removal of semantic evolution or bloat control hurts learned operator discovery; domain knowledge in prompts is crucial—omitting it causes largest performance drop.",
            "hypothesis_space_characterization": "Monitored code-length evolution and token counts; bloat control stabilized code length (operators stabilized around ~50 lines with bloat control) and reduced token count versus no bloat control.",
            "adaptation_during_evolution": "Operator uses stage-aware weighting (evolutionary stage) to adapt selection pressure over generations (favor exploration early, exploitation late).",
            "failure_modes": "Logical bug on small datasets due to structured division producing empty subsets (fixed by repaired version that replaces empty subsets with random subsets); LLM sometimes ignores prompt length target requiring multi-objective survival to enforce compactness.",
            "key_findings_for_theory": "A selection operator that integrates per-instance specificity, complexity penalties, residual-based complementarity, and stage-awareness can (1) maintain population diversity, (2) find parsimonious models with higher R², and (3) outperform traditional hand-designed selection methods. However, robustness requires exposure to a diverse set of training instances (including small datasets) during meta-evolution and explicit bloat control.",
            "uuid": "e2000.1"
        },
        {
            "name_short": "Omni-Zero",
            "name_full": "Omni-Zero (LLM-evolved operator without domain-knowledge prompts)",
            "brief_description": "A selection operator evolved by LLM-Meta-SR when domain-knowledge prompts were omitted; demonstrates that LLMs can synthesize selection heuristics from scratch but tend to rely more on aggregate MSE and miss some complementarity/specificity behaviors.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Omni-Zero",
            "operator_type": "LLM-based (learned/generated without domain-knowledge prompts)",
            "operator_description": "Generated by the same meta-evolution pipeline but with domain-knowledge prompts removed. Uses cosine-distance-based novelty for diversity, a non-linear stage-aware weighting function for error vs novelty trade-off, and complexity penalty based on nodes and tree height; however, it lacks explicit complementarity metrics and specificity-based subset selection.",
            "training_data_description": "Meta-evolution used same inner-loop datasets but prompt removed; thus operators were evolved from the LLM's internal knowledge plus execution history.",
            "domain_or_benchmark": "Symbolic regression (SRBench)",
            "comparison_baseline": "Compared to Omni and expert-designed operators in ablations; Omni-Zero displays desirable properties (diversity- and stage-awareness) but is weaker in complementarity and specificity.",
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": "Novelty defined with cosine-distance-based novelty score (formula provided in text); used normalized cosine similarities for robustness; absolute numeric comparisons vs baselines not tabulated.",
            "out_of_distribution_performance": "Operates reasonably but inferior to Omni (with domain knowledge) on the benchmark; lacks some behaviors that improve generalization across diverse tasks.",
            "training_bias_evidence": "Without domain knowledge, LLM can still craft functional operators but performs worse than when domain knowledge is included—indicating the LLM's internal prior is insufficient to match prompt-augmented performance.",
            "computational_cost_comparison": null,
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": "Analysis showed Omni-Zero satisfies several desirable properties but misses specificity and complementarity features; its selection is dominated by mean squared error in some cases.",
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": "Uses a stage-aware non-linear weighting function for balancing exploration vs exploitation.",
            "failure_modes": "Dominated by aggregate MSE; lacks complementarity-aware pairing and specificity guidance, which harms multi-dataset combination performance.",
            "key_findings_for_theory": "LLMs can autonomously generate selection heuristics from scratch, but prompt-injected domain knowledge materially improves the quality and generality of evolved operators.",
            "uuid": "e2000.2"
        },
        {
            "name_short": "RAG-SR-Omni",
            "name_full": "RAG-SR-Omni: RAG-SR with Omni selection operator",
            "brief_description": "A hybrid system created by replacing automatic-ε-lexicase selection in the Transformer-assisted RAG-SR algorithm with the LLM-evolved Omni selection operator, resulting in improved performance across symbolic-regression benchmarks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "RAG-SR-Omni",
            "operator_type": "hybrid (Transformer-assisted SR with LLM-evolved selection operator)",
            "operator_description": "RAG-SR is a retrieval-augmentation-generation Transformer-assisted symbolic regression algorithm; in RAG-SR-Omni the only change is replacing the automatic-ε-lexicase selection with the Omni operator (Code 3). All other components of RAG-SR remain unchanged.",
            "training_data_description": "Evaluated on 116 SRBench datasets (excluding the 4 used in meta-evolution).",
            "domain_or_benchmark": "Symbolic regression (SRBench)",
            "comparison_baseline": "Compared directly to RAG-SR (original) and to 25 other SR/ML algorithms in the benchmark (26 algorithms total).",
            "performance_learned_operator": "Paper reports that RAG-SR-Omni outperforms RAG-SR in terms of median R², model sizes, and training time and achieves the best performance among 26 symbolic regression and ML algorithms on SRBench (no single numeric per-algorithm table in the main text, but summarized in Figure 11 and Pareto plots).",
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": "Demonstrates improved generalization across the 116 dataset benchmark (datasets were unseen during meta-evolution).",
            "training_bias_evidence": null,
            "computational_cost_comparison": "RAG-SR-Omni shows improved training time relative to RAG-SR in the reported experiments (figure-based comparisons), meaning that substitution of the learned operator produced not only accuracy and size benefits but also training-time benefits in this setup.",
            "transfer_learning_results": "Represents direct transfer of a learned selection operator into a different SR pipeline (transformer-assisted) successfully improving overall performance.",
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": null,
            "key_findings_for_theory": "Integrating an LLM-evolved selection operator into an independent, state-of-the-art SR pipeline can yield consistent improvements in accuracy, parsimony (model size), and training time, indicating that learned operators can be modularly transferred across SR architectures.",
            "uuid": "e2000.3"
        },
        {
            "name_short": "Expert baselines",
            "name_full": "Expert-designed selection operators (AutoLex, CPS, PLex, DALex, D-Split, tournament, Boltzmann, RDS-Tour, etc.)",
            "brief_description": "A set of traditional, manually designed selection operators commonly used in genetic programming and symbolic regression (lexicase variants, tournament selection, Boltzmann sampling, CPS, etc.), used as experimental baselines.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Expert-designed selection operators (group)",
            "operator_type": "hand-designed / traditional GP selection operators",
            "operator_description": "Includes many common selection mechanisms: tournament selection (select best from sampled subset), lexicase selection and its variants (automatic-ε-lexicase, probabilistic lexicase, down-sampled lexicase variants), Boltzmann sampling with temperature scheduling, CPS (first parent by tournament then other criteria), RDS-Tour (random down-sampled tournament), PLex, DALex, D-Split, etc. Parameters set to defaults or literature-recommended values in experiments.",
            "training_data_description": null,
            "domain_or_benchmark": "Symbolic regression (SRBench) used as baselines for comparisons",
            "comparison_baseline": "Used as baselines to compare against LLM-evolved operators in experiments.",
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": "Some traditional operators are computationally cheaper for selection, but Omni's slightly higher selection cost is offset by producing smaller models and better final performance; paper provides qualitative training-time plots but not exhaustive numeric cost-per-operator tables.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": null,
            "key_findings_for_theory": "Traditional expert-designed selection operators are strong baselines, but LLM-evolved operators can surpass them when semantic feedback, bloat control, and domain-knowledge prompting are used; lexicase-style subset emphasis remains a strong principle and is explicitly leveraged/extended by the LLM-evolved operators.",
            "uuid": "e2000.4"
        },
        {
            "name_short": "LLM-evolution frameworks (mention)",
            "name_full": "Related LLM-driven algorithm-evolution systems (FunSearch, ReEvo, EoH, HSEvo, LLM-SR)",
            "brief_description": "Related systems/frameworks that use LLMs for algorithm/heuristic generation or to replace traditional evolutionary operators; cited in related work but not experimentally compared head-to-head within this paper.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "FunSearch / ReEvo / EoH / HSEvo / LLM-SR (referenced frameworks)",
            "operator_type": "LLM-based / LLM-assisted algorithm evolution frameworks (mentioned)",
            "operator_description": "Examples: FunSearch (LLM-based algorithm evolution for combinatorial tasks), ReEvo (random selection baseline and LLM-driven evolution), EoH (LLM-based heuristic evolution), HSEvo (diversity-driven harmony search + GA using LLMs), LLM-SR (LLM for symbolic regression generation). These are cited as prior work and motivating context; this paper extends them by adding semantic-aware selection and bloat control.",
            "training_data_description": null,
            "domain_or_benchmark": "Various optimization tasks and symbolic regression (depending on the cited work); not directly reimplemented here.",
            "comparison_baseline": null,
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": null,
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": null,
            "key_findings_for_theory": "Prior LLM-driven algorithm-evolution techniques provide groundwork but often omit fine-grained semantic feedback and do not address code bloat; this paper situates itself as addressing those gaps.",
            "uuid": "e2000.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "FunSearch",
            "rating": 2
        },
        {
            "paper_title": "ReEvo",
            "rating": 2
        },
        {
            "paper_title": "EoH",
            "rating": 2
        },
        {
            "paper_title": "RAG-SR: retrieval-augmentation-generation-based symbolic regression",
            "rating": 2
        },
        {
            "paper_title": "LLM-SR: Scientific Equation Discovery via Programming with Large Language Models",
            "rating": 1
        },
        {
            "paper_title": "AutoML-Zero",
            "rating": 1
        }
    ],
    "cost": 0.02348875,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression</p>
<p>Hengzhe Zhang hengzhe.zhang@ecs.vuw.ac.nz 
Centre for Data Science and Artificial Intelligence &amp; School of Engineering and Computer Science
Victoria University of Wellington
PO Box 6006140WellingtonNew Zealand</p>
<p>Qi Chen qi.chen@ecs.vuw.ac.nz 
Centre for Data Science and Artificial Intelligence &amp; School of Engineering and Computer Science
Victoria University of Wellington
PO Box 6006140WellingtonNew Zealand</p>
<p>Bing Xue bing.xue@ecs.vuw.ac.nz 
Centre for Data Science and Artificial Intelligence &amp; School of Engineering and Computer Science
Victoria University of Wellington
PO Box 6006140WellingtonNew Zealand</p>
<p>Wolfgang Banzhaf banzhafw@msu.edu 
Department of Computer Science and Engineering
Michigan State University
48824East LansingMIUSA</p>
<p>Mengjie Zhang mengjie.zhang@ecs.vuw.ac.nz 
Centre for Data Science and Artificial Intelligence &amp; School of Engineering and Computer Science
Victoria University of Wellington
PO Box 6006140WellingtonNew Zealand</p>
<p>LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression
51E7499141BBDBD5B93357566D110BE5
Large language models (LLMs) have revolutionized algorithm development, yet their application in symbolic regression, where algorithms automatically discover symbolic expressions from data, remains constrained and is typically designed manually by human experts.In this paper, we propose a meta learning framework that enables LLMs to automatically design selection operators for evolutionary symbolic regression algorithms.We first identify two key limitations in existing LLM-based algorithm evolution techniques: a lack of semantic guidance and code bloat.The absence of semantic awareness can lead to ineffective exchange of useful code components, and bloat results in unnecessarily complex components, both of which can reduce the interpretability of the designed algorithm or hinder evolutionary learning progress.To address these issues, we enhance the LLM-based evolution framework for meta symbolic regression with two key innovations: a complementary, semantics-aware selection operator and bloat control.Additionally, we embed domain knowledge into the prompt, enabling the LLM to generate more effective and contextually relevant selection operators.Our experimental results on symbolic regression benchmarks show that LLMs can devise selection operators that outperform nine expert-designed baselines, achieving state-of-the-art performance.Moreover, the evolved operator can further improve the state-of-the-art symbolic regression algorithm, achieving the best performance among 26 symbolic regression and machine learning algorithms across 116 regression datasets.This demonstrates that LLMs can exceed expert-level algorithm design for symbolic regression.</p>
<p>Introduction</p>
<p>Symbolic regression (SR) is the task of discovering mathematical expressions that accurately model a given dataset.It is widely used in domains such as finance (Shi et al. 2025), education (Shen et al. 2024),chemistry (Chen et al. 2025), andphysics (Feng et al. 2025), due to its interpretability and ability to uncover underlying relationships.Formally, given a dataset D = {x (i) , y (i) } N i=1 , where x (i) ∈ R d are input features and y (i) ∈ R are target values, the goal is to find a symbolic expression f * ∈ F from a space of candidate expressions F that minimizes a loss function L:</p>
<p>f * = arg min f ∈F L(f (x), y).</p>
<p>(1)</p>
<p>Many SR algorithms have been proposed, including evolutionary (Jiang and Xue 2024;Fong and Motani 2024b), neural (Biggio et al. 2021;Kamienny et al. 2022), and searchbased (Kahlmeyer, Fischer, and Giesen 2025;Yu et al. 2025) approaches.In recent years, there has been growing interest in hybrid methods that combine the flexibility of evolutionary algorithms with the learning capabilities of neural networks (Landajuela et al. 2022;Grayeli et al. 2024;Zhang et al. 2025).</p>
<p>In both evolutionary (Jiang and Xue 2024;Fong and Motani 2024b) and neural-evolutionary (Landajuela et al. 2022;Grayeli et al. 2024;Zhang et al. 2025) symbolic regression algorithms, the system follows an iterative optimization process in which solutions are progressively refined by selecting promising candidates.In this process, the selection operator responsible for identifying candidate solutions worth refining, plays a key role in system effectiveness.However, current selection operators are typically manually designed by experts, requiring significant effort and trial-and-error, which can limit the pace of progress.Ideally, an automated algorithm design framework capable of generating effective selection operators for symbolic regression would substantially enhance research and development efficiency in this area.</p>
<p>Large language models (LLMs) have recently emerged as powerful tools for automated heuristic design in various optimization tasks (Romera-Paredes et al. 2024;Liu et al. 2024a;Ye et al. 2024).However, most existing frameworks primarily focus on generating heuristic rules for specific combinatorial optimization tasks.In this paper, we pursue a more ambitious goal: to automatically design a core algorithmic component-specifically, the selection operator-in evolutionary symbolic regression, with the aim of achieving strong performance across a wide range of regression tasks.While frameworks such as FunSearch (Romera-Paredes et al. 2024), EoH (Liu et al. 2024a), and ReEvo (Ye et al. 2024) lay groundwork for algorithm evolution, two challenges remain underexplored in LLM-driven algorithm evolution.The first is the underutilization of semantic information in the generated code.Here, we define semantic information as the performance of an algorithm on individual task instances.Typically, only the average performance across all training instances is provided to the LLM to guide code generation (Huang et al. 2025a), which overlooks fine-grained behavior.As illustrated in Figure 1, consider a scenario with three algorithms: the first two perform well on the first dataset but poorly on the second, while the third shows the opposite pattern.Despite their contrasting behaviors, all three algorithms may exhibit similar average performance.However, presenting the first two algorithms together to the LLM offers limited benefit, as they exhibit redundant patterns-both succeeding and failing on the same datasets.In contrast, combining the first and third algorithms allows the LLM to integrate complementary strengths, potentially generating an algorithm that performs well on both datasets.Thus, incorporating semantic information is crucial for effective algorithm evolution.</p>
<p>The second challenge is complexity bias, illustrated in Figure 2. LLMs tend to generate overly long or intricate code during optimization, similar to code bloat in genetic programming (Banzhaf et al. 1998).This results in the accumulation of redundant or non-functional logic, which impairs interpretability, wastes a large number of tokens, and slows optimization.As shown in Figure 2, such complexity can lead to performance stagnation, ultimately limiting the effectiveness of evolution.</p>
<p>In this paper, we propose an LLM-driven method for meta symbolic regression to automatically design selection operators1 .The main contributions are as follows:</p>
<p>• We propose an LLM-driven meta symbolic regression framework to automatically design selection operators using in-context learning.The LLM learns from design and evaluation history to automatically discover generalizable operators that consistently outperform human-designed counterparts across a wide range of unseen datasets.• We identify the issue of bloat in LLM-based code generation and introduce a bloat control strategy that improves both the interpretability of the evolved code and the effectiveness of the evolutionary process.• We propose semantic-based feedback and complementary selection mechanisms to fully leverage semantic information during LLM-driven generation, explicitly guiding algorithm evolution by integrating effective building blocks and enhancing learning performance.• We design ideal properties of selection operators based on domain knowledge to craft more effective prompts that guide LLMs in generating high-quality selection operators.</p>
<p>2 Background and Related Work</p>
<p>Selection Operators in Symbolic Regression</p>
<p>There has been significant research on designing selection operators for symbolic regression, including tournament selection (Xie and Zhang 2012), Boltzmann sampling (Shojaee et al. 2025;Romera-Paredes et al. 2024)</p>
<p>LLMs for Symbolic Regression</p>
<p>Early work on LLMs for symbolic regression focused on specialized language models (Kamienny et al. 2022;Biggio et al. 2021), often assisted by Monte Carlo Tree Search (Kamienny et al. 2023;Shojaee et al. 2024) or evolutionary algorithms (Zhang et al. 2025).With the advent of generalpurpose LLMs, their use in symbolic regression has attracted increasing attention (Shojaee et al. 2025), either through the FunSearch framework (Romera-Paredes et al. 2024) or via integration with evolutionary algorithm frameworks (Grayeli et al. 2024).In these studies, LLMs effectively replace traditional crossover and mutation operators to generate candidate solutions, but selection operators are still manually designed.This motivates the exploration of automated selection operator design using LLMs.Some recent work incorporates dataset descriptions into symbolic regression, referring to this as "semantics" (Liu, Huynh, and van der Schaar 2025).However, this differs from the concept of semantics in genetic programming (Moraglio, Krawiec, and Johnson 2012), where it refers to the behavior of a program.In LLM-based program evolution, the finegrained behavior of candidate programs is often overlooked and reduced to aggregate scores, which can obscure meaningful information and hinder evolutionary progress.</p>
<p>Solution Representation</p>
<p>Each solution is a piece of code representing a selection operator.The input to the selection operator is a list of individuals.Each individual contains a list representing squared error, a list of predicted values, and a list of nodes, which can be used to compute the height and depth of the symbolic tree.The evolutionary status, specifically the ratio between the current and total generations, is also provided.The expected output of the selection operator is a list of promising symbolic trees.The structure of the selection operator is presented in Code 7 of the supplementary material.</p>
<p>Meta-Evolution Workflow</p>
<p>The meta-evolution algorithm consists of two nested loops: an outer meta-evolution loop and an inner symbolic regression loop.The outer loop generates new selection operators, while the inner loop evaluates their performance.An overview of the workflow is shown in Figure 3.</p>
<p>Let
P (t) = {O (t) 1 , O (t) 2 , . . . , O(t)
N } denote the population of selection operators at generation t, where N is the population size and each
O (t) i is a selection operator. The fitness of each operator O (t) i , denoted f (O (t)
i ), is evaluated based on its performance in the symbolic regression loop.The metaevolution process includes the following components:</p>
<p>• Population Initialization: The initial population P (0)  is generated by prompting the LLM to produce N random selection operators.The details of the initialization prompts are provided in Appendix K of the supplementary material.∈ P (t) , its fitness is computed as f (O -Operator Crossover: For each pair (O
(t) i ) = 1 T T j=1 SR(O (t) i , D j ),(t) a , O (t) b ), a new operator is generated as O (t+1) new = LLM Crossover O (t) a , O (t) b
. The goal is to generate a new piece of code that combines effective building blocks from the selected parent operators, guided by their performance scores on the evaluated datasets.</p>
<p>-Operator</p>
<p>Mutation:
Let O * = arg max O (t) i ∈P (t) f (O (t)
i ) be the best-performing operator in generation t (Ye et al. 2024).Mutated variants are then generated as
O (t+1) mut = LLM Mutate(O * ),
with the objective of generating novel code based on the elite operator.The prompts used for crossover and mutation are provided in Appendix K. Solution generation leverages the in-context learning capability of LLMs (Gao and Das 2024), expecting that LLMs can generate better solutions by analyzing historical execution results.This process continues until a predefined number of generations T max is reached.The operator with the highest fitness value across all generations is selected as the final selection operator.</p>
<p>Semantics-Aware Evolution</p>
<p>Semantic-based Selection: In the meta-evolution scenario, the goal of the crossover operator is to combine the strengths of two LLM-generated selection operators.As introduced in Section 1, crossover benefits more from combining solutions with complementary strengths than from pairing generalists.</p>
<p>To this end, we propose a semantics-aware selection strategy, with the pseudocode provided in Algorithm 1.Because each selection operator O i ∈ P (t) has been evaluated across d datasets and is associated with a score vector s i = [s i,1 , . . ., s i,d ], we can compute a complementarity score for each candidate in the population.The process begins by randomly selecting the first parent O a ∈ P (t) .Random selection, as used in ReEvo (Ye et al. 2024) and HSEvo (Dat, Doan, and Binh 2025), helps mitigate premature convergence (Dat, Doan, and Binh 2025).Then, for each candidate O i ∈ P (t) , we compute a complementarity score:
µ i = 1 d d j=1 max(s a,j , s i,j ),(2)Compute µ i ← 1 d d j=1 max(s a,j , s i,j ) 4: end for 5: i * ← arg max i µ i 6: O b ← O i * // Retrieve Complement Operator 7: return O b
Semantic Feedback: The semantic selection strategy ensures that crossover is guided by semantically diverse behaviors.Furthermore, to enhance semantic awareness, we provide the full score vector s i of dataset-specific scores to the LLM in the solution generation stage, rather than averaging them into a single aggregate value.This enables the LLM to reason explicitly about behavioral differences across tasks.</p>
<p>Bloat Control</p>
<p>Prompt-based Length Limit: To mitigate code bloat in the evolution of selection operators, we incorporate a length constraint in the prompt during solution generation.For any operator O i ∈ P (t) , its code length is denoted by ℓ(O i ), measured as the number of non-empty, non-comment lines in the implementation.We choose to constrain the number of lines, rather than the number of tokens, because line count is less sensitive to variations in variable name length.Rather than enforcing a hard upper bound ℓ(O i ) ≤ L max , which is difficult to control during LLM generation, we embed the maximum length ℓ target directly into the prompt.For instance, the LLM is instructed: "Write a selection operator with code length ≤ ℓ target ."This prompt-guided strategy encourages the model to produce more concise programs.</p>
<p>Multi-Objective Survival Selection: Beyond promptbased constraints, we employ a multi-objective survival selection strategy based on both operator fitness and code length to further control bloat, since LLMs do not always follow instructions to generate code within a specified length.Each operator O i is represented as a tuple (f (O i ), ℓ(O i )), where f (O i ) denotes its average task performance across T tasks, and ℓ(O i ) denotes its code length.The parents for generating the next generation P (t+1) are selected from the combined set P (t) ∪ P offspring using a dominance-dissimilarity selection mechanism (Yao et al. 2025).</p>
<p>The key idea is to compute a dominance score for each operator based on weak Pareto dominance (Lin et al. 2022) and code similarity.An operator O i is said to weakly Pareto dominate another operator O j , denoted
O i ⪰ O j , if and only if f (O i ) ≥ f (O j ) and ℓ(O i ) ≤ ℓ(O j ).
For each such pair (O i , O j ), the score of O j is penalized by the code similarity sim(O i , O j ), computed using the CodeBLEU metric (Ren et al. 2020).The total dominance score of O j is then defined as s(O j ) = Oi⪰Oj −sim(O i , O j ).Operators are then ranked, and the top-N operators with higher scores are selected, as they are less frequently dominated and exhibit greater dissimilarity from dominating counterparts.This selection strategy encourages a trade-off between maximizing task performance and minimizing code complexity, effectively reducing operator bloat while maintaining diversity and effectiveness.</p>
<p>Incorporating Domain Knowledge into Prompts</p>
<p>Algorithm evolution requires deep domain expertise, which general-purpose LLMs often lack.To compensate, domain knowledge is commonly incorporated into prompts to enhance LLM-based algorithm evolution (Romera-Paredes et al. 2024;Liu et al. 2024a).For the design of selection operators, we embed the following principles into the prompt to guide the LLM toward generating more effective solutions: Diversity-aware: Purely objective-driven selection can cause premature convergence.To counter this, it is desirable to select models that perform well on different training instances to maintain population diversity.</p>
<p>Interpretability-aware: Interpretability, often measured by the number of nodes in a symbolic expression, is a critical criterion.Let n i denote the number of nodes in solution p i .The selection operator should favor solutions with smaller n i to promote simpler, more interpretable models.</p>
<p>Stage-aware: Selection pressure should adapt over time.In early generations (t ≪ T max ), it should favor exploration.In later stages (t ≈ T max ), it should prioritize exploitation of high-fitness solutions to encourage convergence.</p>
<p>Complementarity-aware: To effectively recombine useful traits, crossover should favor solutions with complementary strengths.Given performance vectors s i and s j over d instances, complementarity means selecting pairs with low correlation.Such combinations integrate distinct capabilities and can yield offspring that perform well across a broader range of instances.</p>
<p>Vectorization-aware: Vectorized operations are preferred, as they can be efficiently accelerated using NumPy or GPU computation.This improves the runtime efficiency of the evolved operator and reduces evaluation overhead during meta-evolution.</p>
<p>The prompt incorporating these domain knowledge principles is provided in Figure 34 of the supplementary material.</p>
<p>Experimental Settings</p>
<p>Meta-Evolution: The experiments are conducted using GPT-4.1 Mini.For the outer loop, the population size N is set to 20, the number of solutions generated by mutation M is set to 1, and the number of solutions generated by crossover is 19.The total number of generations is set to 20.A length limit of 30 lines is imposed to control operator complexity.For the inner loop, four datasets are selected to evaluate the quality of the generated selection operators.These datasets have OpenML IDs 505, 4544, 588, and 650, corresponding to the four highest-dimensional datasets in the contemporary symbolic regression benchmark (SRBench) (La Cava et al. 2021).High-dimensional datasets pose greater challenges for symbolic regression algorithms, and optimizing on these is likely to generalize well to both easy and hard problems.The number of generations in the inner loop is set to 30, and the population size is 100.More detailed experimental settings for the inner symbolic regression loop are provided in Appendix A of the supplementary material.All experiments are repeated three times (Yao et al. 2025) with random seeds set to 0, 1, and 2, to report the median and confidence intervals.</p>
<p>Symbolic Regression: For symbolic regression, experiments are conducted on 116 out of the 120 datasets in SRBench, excluding the 4 datasets used during the metaevolution phase to prevent potential data leakage.Each algorithm is evaluated using 10 independent runs per dataset to ensure statistically robust comparisons.The symbolic regression algorithm used is standard genetic programming with linear scaling, which is a widely adopted framework in symbolic regression research (Virgolin et al. 2021;Kronberger et al. 2022).The parameter settings are the same as those used in the inner symbolic regression loop, except that the number of generations is increased to 100.</p>
<p>Experimental Results</p>
<p>Meta-Evolution Results</p>
<p>In this section, we evaluate our meta-evolution framework (LLM-Meta-SR) against several ablated variants, including: without semantic evolution (W/O Semantics), without semantic evolution and bloat control (W/O SE+BC), without domain knowledge (W/O Knowledge), without domain knowledge and semantic evolution (W/O DK+SE), and without domain knowledge, semantic evolution, and bloat control (W/O DK+SE+BC).Since domain knowledge is not always available in practice, we include ablation studies under the setting without domain knowledge to evaluate how the proposed strategy performs in entirely new domains.In the W/O Semantics setting, random selection with identical objective prevention from ReEvo (Ye et al. 2024) is used as the baseline.In the W/O SE+BC setting, survival selection is replaced with direct population replacement and elitism, following the strategy used in ReEvo (Ye et al. 2024).In the W/O Knowledge setting, semantic evolution and bloat control are retained, but the domain knowledge prompt is removed.</p>
<p>Objective Score: The objective score is measured by the average test R 2 score of each selection operator across the four training datasets.For the W/O DK+SE+BC setting, only one run completed within 24 hours and is thus reported.The results in Figure 4, along with the numerical values presented in Table 1, show that the absence of domain knowledge causes the largest performance drop, highlighting the importance of domain knowledge introduced in Section 3.5 in guiding algorithm evolution.This is consistent with findings from FunSearch (Romera-Paredes et al. 2024) and EoH (Liu et al. 2024a) that LLMs often require external knowledge for guidance.</p>
<p>However, domain knowledge alone is insufficient to discover high-performing operators.As shown in Figure 4, semantic evolution plays a critical role in achieving higher objective scores, both with and without domain knowledge.To investigate the role of semantics, we visualize the semantic distribution of solutions over the first five generations in Figure 6.Each point represents a solution, colored by its average score across the four tasks.Positions are computed via t-SNE based on the four-dimensional score vector.The figure reveals that the number of solutions achieving top-3 performance on at least one dataset consistently exceeds three, indicating that top individuals by average score do not dominate all tasks.Additionally, the final subplot in Figure 6 shows that some solutions, marked with stars, achieve top-3 performance on at least one dataset despite having modest average scores.This illustrates that relying solely on average performance may overlook individuals with strong task-specific capabilities.To further understand how semantic-aware selection works, a real example of parent crossover is provided in Appendix D of the supplementary material, which further confirms the importance of semantic-aware selection for generating better offspring.These findings highlight the importance of semantics-based algorithm evolution in capturing diverse and task-specific behaviors that aggregate metrics may obscure.</p>
<p>Code Length: Figure 5 shows the evolution of code length for the best-performing solutions.Without bloat control, code length grows excessively throughout the optimization process when domain knowledge is absent.Incorporating domain knowledge helps shape the basic structure and mitigates excessive growth, but the code length still remains substantial.In contrast, when bloat control is applied, it directly curbs the complexity bias of LLMs, resulting in smaller generated programs that stabilize at a length of around 50, while simultaneously achieving faster improvements in objective scores.</p>
<p>Discovered Operators</p>
<p>In this section, we present experiments on datasets from contemporary symbolic regression benchmarks to evaluate the performance of the discovered operators.
P Q L ' $ / H [ $ X WR / H [ &amp; 3 6 ' 6 S OL W 5 ' 6 7 R X U 7 R X U 7 R X U % R OW ] P D Q Q 3 / H [ R 2 6FRUH Figure 7: Test R 2 scores of different3 / H [ 2 P Q L $ X WR / H [ 7 R X U &amp; 3 6 ' 6 S OL W 5 ' 6 7 R X U % R OW ] P D Q Q ' $ / H [ 7 R X U 1XPEHURI1RGHV
Figure 9: Tree sizes of selection operators on symbolic regression benchmarks.2025).All of these operators were manually designed by domain experts.This section only presents results for a single LLM-discovered operator.Additional results for other LLM-discovered operators are presented in Appendix E of the supplementary material.
% R OW ] P D Q Q ' $ / H [ $ X WR / H [ 7 R X U 7 R X U ' 6 S OL W 5 ' 6 7 R X U 3 / H [ &amp; 3 6 2 P Q L 7UDLQLQJ7LPHV
Test Accuracy: The results in Figure 7 show that the LLMgenerated selection operator outperforms the expert-designed baselines in terms of R 2 scores and achieves the best overall performance.A Wilcoxon signed-rank test with Benjamini-Hochberg correction is presented in Figure 8.These results demonstrate that the evolved Omni selection operator performs significantly better than existing expert-designed operators, many of which cannot be statistically distinguished from one another.This confirms that LLMs can effectively discover selection operators that surpass those created by domain experts.</p>
<p>Tree Size: The distribution of model sizes is presented in Figure 9.The results show that the evolved operator produces smaller models compared to top-performing selection operators like AutoLex and CPS.This is primarily because the evolved operator incorporates model size into the selection process, biasing the search toward regions where symbolic expressions are more compact.As shown in Figure 9 and Fig- Training Time: As shown in Figure 10, the proposed Omni selection operator is efficient, even though it integrates multiple criteria into the selection process, which makes it slightly more time-consuming than some other operators in terms of overall symbolic regression time.However, it is important to consider not only the training phase but also the cost of evaluating and deploying candidate models.Since Omni selection tends to favor smaller models with fewer nodes, it reduces computational cost during evaluation and deployment, especially on resource-constrained devices.Thus, despite its multi-faceted design leading to a slight increase in selection time, Omni remains an efficient and practical selection operator.</p>
<p>Analysis on State-of-the-Art Symbolic Regression Algorithms</p>
<p>Experimental Settings In this section, we apply the evolved operator to a state-of-the-art Transformer-assisted symbolic regression algorithm, namely retrieval-augmentationgeneration-based symbolic regression (RAG-SR) (Zhang et al. 2025) Recall that RAG-SR uses automatic-lexicase selection, which only considers diversity-awareness.These results suggest that even for a state-of-the-art symbolic regression algorithm, it is still desirable to consider multiple aspects, such as diversity, stage-awareness, complementarity, and interpretability, during selection to achieve stronger performance.Nonetheless, manually designing such an operator is challenging, which highlights the value of leveraging LLMs in this context.</p>
<p>Conclusions and Limitations</p>
<p>In this paper, we propose an LLM-driven framework for automatically designing selection operators in symbolic regression, and design several strategies to enhance its effectiveness.First, we highlight the challenges of limited semantic awareness and bloat in LLM-driven evolution.To enhance semantic awareness, we propose a semantic-based selection operator and a semantic feedback mechanism.To mitigate bloat, we introduce a prompt-based length control and a multi-objective survival selection strategy.Additionally, we define a set of design principles derived from domain knowledge to guide LLM for operator generation.Ablation studies confirm that addressing these three factors significantly enhances the effectiveness of the evolved algorithms.Next, we evaluate an LLM-generated selection operator against expert-designed baselines across a wide range of symbolic regression datasets, and also apply the evolved operator to state-of-the-art symbolic regression algorithms.The results show that the evolved operator outperforms expert-designed selection operators and can boost the performance of SR algorithms, achieving the best performance among 26 SR and ML algorithms, demonstrating that LLMs can discover selection operators that outperform those crafted by domain experts.For future work, it is worth exploring the automatic design of crossover and mutation operators in symbolic regression to further reduce the effort required for developing novel SR algorithms.</p>
<p>A Evolutionary Symbolic Regression</p>
<p>A.1 Solution Representation</p>
<p>The symbolic regression model is represented as a symbolic expression tree with linear scaling (Nadizar et al. 2024).For a given expression Φ, the prediction is computed as Ŷ = α • Φ(X) + β, where the coefficients α ∈ R and β ∈ R are fitted using ridge regression by minimizing the regularized squared error between Ŷ and the targets Y .</p>
<p>A.2 Algorithm Workflow</p>
<p>The symbolic regression algorithm is implemented using the genetic programming framework (Banzhaf et al. 1998).Let F (t) = {Φ 1 , Φ 2 , . . ., Φ λ } denote the population of λ symbolic expressions at generation t.The evolutionary process proceeds as follows:</p>
<p>• Population Initialization: The initial population F (0) is generated using the ramped half-and-half method (Banzhaf et al. 1998).</p>
<p>• Fitness Evaluation:
Each expression Φ i ∈ F (t) is eval- uated on the dataset (X, Y ). Let z i = Φ i (X) ∈ R n
denote the vector of symbolic outputs.The linear coefficients α i and β i are computed by fitting a ridge regression model of the form Ŷi = α i • z i + β i .The leave-oneout cross-validation (LOOCV) (Allen 1974) squared error is computed efficiently as
E i = n j=1 rij 1−Hijj 2 ,
where r i = Y − Ŷi is the residual vector, and
H i = Z i (Z ⊤ i Z i + λI) −1 Z ⊤ i is the hat matrix for ridge regres- sion with input Z i = [z i 1] ∈ R n×2 .
The full error vector is retained for use in selection.</p>
<p>• Elitism: The best-performing expression Φ * = arg min Φi∈F (t) E i is preserved in an external archive and used for solution selection to maintain historical performance.</p>
<p>• Solution Selection: The LLM-evolved selection operator is invoked to select a set of promising parent expressions from the current population and the elite archive.</p>
<p>• Solution Generation: A new population F (t+1) is generated from the selected parents using standard genetic programming operators:</p>
<p>-Subtree Crossover: Given two parent expressions Φ a and Φ b , offspring are generated by exchanging randomly selected subtrees.-Subtree Mutation: A randomly selected subtree of an expression Φ i is replaced with a newly generated subtree.</p>
<p>During solution generation, all solutions generated in the evolutionary process are stored in a hash set.If an offspring is identical to any historical solution, it is discarded and a new solution is generated.The hash set is used because it maintains O(1) query complexity.This mechanism prevents symbolic regression from wasting resources by evaluating the same solution multiple times.</p>
<p>A.3 Parameter Settings</p>
<p>The parameters for symbolic regression follow conventional settings.The population size and number of generations are set to match those used in D-Split (Imai Aldeia, De Franc ¸a, and La Cava 2024).To prevent division-by-zero errors, we use the analytical quotient (AQ(x, y) =</p>
<p>x √ 1+y 2 ) (Ni, Drieberg, and Rockett 2012) in place of the standard division operator.</p>
<p>B Analysis of Token Count of Generated Code</p>
<p>The token count directly impacts the cost of algorithm evolution, as language service providers typically charge based on the number of tokens.In this section, we analyze how bloat influences the token count of generated code.Token counting is performed using the cl100k base tokenizer, which is employed by OpenAI models.The experimental results are shown in Figure 12.It is evident that when no bloat control strategy is applied, the token count of the generated code is significantly higher.In contrast, the application of a bloat control strategy substantially reduces the token count in both the LLM-Meta-SR and LLM-Meta-SR without domain knowledge settings.This indicates that the bloat control strategy is not only helpful for improving the interpretability of generated code, but also beneficial for reducing the cost of algorithm evolution.</p>
<p>C Analysis of an Evolved Selection Operator</p>
<p>C.1 Code Evolved by LLM-Meta-SR Static Analysis Code 1 shows the best evolved selection operator among all runs.The code has been simplified by removing logically redundant parts.In selecting the first parent (parent a), the operator evaluates two key criteria: specificity-quantified as the lowest error achieved on any subset of the dataset, with lower values indicating superior performance in specialized regions-and a complexity measure that jointly considers the number of nodes in the symbolic expression tree and the height of the tree, thereby reflecting the interpretability of the solution.Candidate solutions are ranked such that subset error is prioritized, with model complexity serving as a secondary criterion when the subset error alone does not sufficiently differentiate candidates.This approach encourages the identification of solutions that balance high accuracy with interpretability.</p>
<p>For the selection of the second parent (parent b), the operator computes the absolute cosine similarity between the residuals of each candidate in the population and the residual of the previously selected first parent.The second parent is then chosen based on a combination of semantic complementarity, as measured by cosine similarity, and model complexity.The trade-off between complementarity and complexity is controlled by a linear function related to the evolutionary stage.In the early stages, the pressure toward parsimony is intentionally relaxed to promote broader exploration of the search space.In contrast, in later stages, the pressure increases to favor models that are both accurate and concise, thus facilitating interpretability.</p>
<p>Overall, the selection operator satisfies all the desired properties, including interpretability, diversity, complementarity, stage-awareness, and vectorization, as defined in Section 3.5.13.The diversity of the population is shown in Figure 14, and the tree size is shown in Figure 15.</p>
<p>Test R 2 Scores: The test R 2 scores demonstrate that the Omni selection operator achieves an advantage at the beginning of the search, indicating that it is an effective selection operator for anytime performance (Ye et al. 2022).</p>
<p>Population Diversity: To understand why the Omni selection operator achieves this performance, we plot the population diversity trajectory in Figure 14.Diversity is measured by the cosine distance between individuals, which is preferred over Euclidean distance because the latter can be trivially large if some solutions have very large errors.The results show that population diversity is well maintained across generations and is better than the baseline.In other words, the Omni selection operator maintains a more diverse population, with individuals making errors on different subsets of instances.This helps explain the superior performance of the Omni selection operator compared to the baseline.</p>
<p>Tree Size: Finally, we plot the tree size trajectory in Figure 15.The results show that Omni selection not only achieves better performance but also suffers less from rapid growth in tree size compared to other selection operators throughout the entire evolution process.This suggests that the Omni selection operator explores regions of the search space containing parsimonious solutions more exhaustively than other operators, which is an ideal behavior for finding effective and parsimonious solutions in symbolic regression.</p>
<p>C.2 Code Evolved by LLM-Meta-SR without Domain Knowledge</p>
<p>In this section, we analyze the code evolved by LLM-Meta-SR without domain knowledge to understand how an LLM can generate algorithms based solely on its internal knowledge.The evolved code is shown in Code 2. We refer to the resulting algorithm as Omni-Zero, as it evolves the model from scratch, similar to AutoML-Zero (Real et al. 2020).</p>
<p>Static Analysis Based on the code in Code 2, the LLM can evolve selection operators with desirable properties even without domain-specific guidance.These properties include diversity-awareness, stage-awareness, and interpretabilityawareness. For diversity-awareness, the selection operator uses cosine similarity to measure pairwise distances between individuals.Formally, it defines the novelty score as:
nov i = 1 − 1 n n k=1 xi−xi ∥xi−xi∥2+ϵ , x k −x k ∥x k −x k ∥2+ϵ max j 1 − 1 n n k=1 xj −xj ∥xj −xj ∥2+ϵ , x k −x k ∥x k −x k ∥2+ϵ
(3)</p>
<p>This cosine-distance-based novelty score is better suited for symbolic regression than Euclidean-distance-based novelty scores, as it is more robust to outliers and cannot be easily manipulated by increasing the distance with some outlier, as discussed in Appendix C.1.For stage-awareness, the selection operator applies a non-linear weighting function to control the trade-off between error and novelty.The function is defined as 0
.35 + 0.3 1 − t Tmax 0.8
, where t is the current generation and T max is the maximum number of generations, as described in Code 2. This function gradually decreases over time, promoting exploration in early generations and exploitation in later ones.This dynamic trade-off satisfies the stage-awareness criterion defined in Section 3.5.</p>
<p>For interpretability-awareness, the selection operator uses both the number of nodes and the height of the tree to measure solution complexity.A linear weighting function is used to balance interpretability and accuracy during selection.</p>
<p>A limitation of this operator is that it does not consider diversity from the perspective of specificity, the selection of each individual is largely dominated by the mean squared error of each individual, nor does it account for the complementarity between two parents.
$ / H [ $ X WR / H [ &amp; 3 6 ' 6 S OL W 2 P Q L = H UR 5 ' 6 7 R X U 7 R X U 7 R X U % R OW ] P D Q Q 3 / H [ R 2 6FRUH</p>
<p>C.3 A Repaired Version of Omni Selection for Small Datasets</p>
<p>Problem Analysis Upon closely analyzing the code generated by the LLM in Code 1, we identified a logical bug that can lead to poor performance of the selection operator on small datasets.When the dataset is small, the structured division in line 10 of Code 1 does not yield enough samples to form sufficient subsets, which can result in some
3 / H [ $ X WR / H [ 2 P Q L = H UR 7 R X U &amp; 3 6 ' 6 S OL W 5 ' 6 7 R X U % R OW ] P D Q Q ' $ / H [ 7 R X U 1XPEHURI1RGHV
Figure 18: Tree sizes of different selection operators on symbolic regression benchmarks, including Omni-Zero.subsets being empty.These empty subsets cause the subsequent selection process to rely solely on complexity when selecting individuals, without considering their predictive performance.This issue arises because the datasets used during meta-evolution generally contain a relatively large number of training instances, as shown in Table 3.Consequently, the bug has limited impact during training but becomes problematic when applied to smaller datasets.
% R OW ] P D Q Q 2 P Q L = H UR ' $ / H [ $ X WR / H [ 7 R X U 7 R X U ' 6 S OL W 5 ' 6 7 R X U 3 / H [ &amp;3
Solution To address this issue, we propose a repaired version of the Omni selection operator, as shown in Code 3. In this version, random subsets are used to replace any empty subsets generated during structured division.All other parts of the code remain unchanged.</p>
<p>Benchmark Analysis We compare the performance of the repaired and original versions on datasets with no more than 100 training instances.The results, presented in Figure 20, show that the repaired version outperforms the original, indicating that the logical bug in the original version is indeed problematic.Regarding model size, as shown in Figure 21, the repaired version results in an increased tree size, which is reasonable because it corrects the previous behavior of selecting individuals solely based on complexity by also con-
2 P Q L 5 2 P Q L ' $ / H [ $ X WR / H [ &amp; 3 6 ' 6 S OL W % R OW ] P D Q Q 5 ' 6 7 R X U 7 R X U 7 R X U 3 / H [ R 2 6FRUH
Figure 20: Test R 2 scores of different selection operators on small-scale symbolic regression benchmarks, including the repaired omni selection.sidering the error on subsets.Nonetheless, the increase in tree size is not substantial and still leads to a competitive model size compared to other selection operators.This failure highlights that, when using LLMs for metaevolution, it is important that the LLM is exposed to a wide range of instances.Otherwise, the generated code may contain subtle logical bugs that are not easily detected.
3 / H [ 2 P Q L 2 P Q L 5 5 ' 6 7 R X U $ X WR / H [ &amp; 3 6 ' $ / H [ 7 R X U ' 6 S OL W % R OW ] P D Q Q 7 R X U 1XPEHURI1RGHV</p>
<p>D Further Analysis of the Semantic-Aware Evolution</p>
<p>In this paper, we propose a semantic-aware evolutionary approach that explicitly selects complementary pairs of individuals for crossover.To illustrate how two complementary codes work together to generate improved solutions, we provide a concrete example in this section.In the existing literature, the most common approach to combining the capabilities of two selection operators is to embed them within a dynamic algorithm selection framework (Xue et al. 2022), allowing each operator to be applied under different conditions.While this strategy permits both operators to contribute, it does so sequentially and without integrating their underlying semantics.Moreover, repeatedly combining two code fragments over multiple generations can lead to exponential code growth (Martins et al. 2018), impairing interpretability and maintainability.In contrast, our approach enables a more meaningful integration by combining semantically complementary code fragments through crossover.As shown in Code 4 and its parent codes in Code 5 and Code 6, the resulting offspring code fragments are not simply concatenations but structured combinations of meaningful components from both parents, as detailed in Table 4. Compared to the mutation operator, which performs a random search around a single solution, crossover provides a directional search by explicitly fusing different capabilities.Thus, the generated code is expected to perform well across multiple datasets.As shown in Figure 22, parent 1 and parent 2 excel on dataset 4 and dataset 3, respectively.By combining their complementary strengths through the mixing strategy performed by the LLM in Table 4, the offspring operator achieves strong performance on both datasets 3 and 4, thereby yielding better average performance.Unlike random subtree crossover in tree-based genetic programming (Banzhaf et al. 1998) or one-point crossover in linear genetic programming (Huang et al. 2024), LLM-based crossover can synthesize code that semantically resembles an intermediate between the two parent programs by leveraging its code understanding capability.This highlights the importance of semantic diversity: if both parents are highly similar, even if performant, the resulting offspring would be nearly identical to the parents, leading to redundant evaluations and wasted computation.Therefore, semantic-aware evolution is vital for automated algorithm design.</p>
<p>E Results on More Discovered Operators</p>
<p>The proposed LLM-Meta-SR method can discover various selection operators.For example, Code 4 presents a selection operator discovered by the LLM-Meta-SR algorithm, which differs from the operator shown in Code 1.To avoid confusion, we refer to the discovered operator in Code 4 as "Holo".The results of the test R 2 scores are shown in Figure 23 and Figure 24, which demonstrate that the Holo selection operator outperforms expert-designed selection operators.Additionally, the complexity size, shown in Figure 25, indicates that the discovered operator is competitive in terms of model complexity.A direct comparison with the tree sizes evolved using the Omni selection, reported in Figure 9, shows that the discovered operator is even slightly smaller.Therefore, the "Holo" selection operator is preferred when interpretability is a key concern.
+ R OR ' $ / H [ $ X WR / H [ &amp; 3 6 ' 6 S OL W 5 ' 6 7 R X U 7 R X U 7 R X U % R OW ] P D Q Q 3 / H [ R 2 6FRUH</p>
<p>F Test Cases for Synthetic Evaluation</p>
<p>For the synthetic evaluation in Section 3.2, two synthetic test cases are designed to reveal implementation flaws and inefficiencies early in the evaluation process, prior to applying each evolved selection operator to real symbolic regression tasks.The first case consists of 100 solutions whose predicted values and training errors are independently sampled from 100 random integers in the range [1,10].The second case also
/ H [ + R OR $ X WR / H [ 7 R X U &amp; 3 6 ' 6 S OL W 5 ' 6 7 R X U % R OW ] P D Q Q ' $ / H [ 7 R X U 1XPEHURI1RGHV</p>
<p>G More Analysis on Symbolic Regression Benchmark</p>
<p>The results of the top-5 performing algorithms are shown in Figure 26 for better clarity, and the Pareto front of the ranks of test R 2 scores and model sizes across different algorithms is shown in Figure 27.These results demonstrate that RAG-SR-Omni is a Pareto-optimal algorithm on SRBench.Specifically, RAG-SR-Omni dominates retrievalaugmentation-generation-based symbolic regression (RAG-SR) (Zhang et al. 2025) as well as transformer-based planning for symbolic regression (Shojaee et al. 2024).Overall, these results show the effectiveness of the LLM-evolved selection operator.</p>
<p>H Baseline Selection Operators</p>
<p>The hyperparameters for the baseline selection operators follow the default settings specified in their respective original papers.For RDS-Tour, the sampling ratio is set to 10% and the tournament size to 7 (Geiger et al. 2025).For PLex selection, the temperature parameter is set to 1.0 (Ding, Pantridge, and Spector 2023).For DALex, a particularity pressure of 3 is used (Ni, Ding, and Spector 2024).For CPS, the first parent is selected via tournament, with the tournament size set to 7 (Xu et al. 2022).</p>
<p>For Boltzmann sampling with temperature scheduling (Shojaee et al. 2025;Romera-Paredes et al. 2024), a temperature decay rule is applied to balance exploration and exploitation over time, similar to the approaches used in LLM-SR (Shojaee et al. 2025) andFunSearch (Romera-Paredes et al. 2024).The sampling probability for individual i is defined as:
P i = exp si τc i ′ exp s i ′ τc , τ c = τ 0 1 − t mod T max T max ,(4)
where s i denotes the score of individual i, τ 0 = 0.1 is the initial temperature (Shojaee et al. 2025), t is the current generation, and T max is the total number of generations.This scheduling rule linearly decays the temperature over generations and gradually shifts the selection pressure from exploration (high temperature) to exploitation (low temperature) as evolution progresses in evolutionary symbolic regression.</p>
<p>I Further Investigation on Crossover and Mutation Ratio</p>
<p>In the main paper, the number of individuals in the population generated by crossover is 19, and the number generated by mutation is 1.In this section, we investigate the proposed method under different settings of crossover and mutation ratios to examine how these ratios affect its performance.Specifically, in this section, the number of individuals generated by crossover is 15 and by mutation is First, the experimental results in Figure 28 and Figure 29 show that the conclusions from the ablation studies in Section 5.2 generalize to different settings of crossover and mutation ratios.This includes the effectiveness of semantics-based evolution, bloat control, and domain-knowledge-based operators.</p>
<p>Second, the results in Figure 28 as well as the numerical values in Table 5 indicate that the optimal crossover and mutation ratios vary depending on the prompts.When domain knowledge is available, a smaller mutation rate, as used in Section 5.2, achieves slightly better performance than the larger mutation rate used in this section.In contrast, when Code 9: Default code used when no code can be extracted from the LLM response.</p>
<p>L Computing Infrastructure</p>
<p>All experiments are run on AMD Milan CPUs.The software packages used in our experiments are listed in Table 6.</p>
<p>Figure 1: Illustration of the importance of fine-grained semantic differences between solutions during algorithm evolution.</p>
<p>where D 1 , . . ., D T are symbolic regression datasets, and SR(O (t) i , D j ) denotes the symbolic regression performance of O (t) i on dataset D j .In brief, each dataset is split into a training and validation set.Symbolic regression is performed on the training set, and the fitness of the selection operator is computed based on its performance on the validation set.Details of the solution evaluation procedure are provided in Appendix A of the supplementary material.• Survival Selection: A subset of operators is retained to form the next generation P (t+1) .To control bloat, a multiobjective survival selection strategy is employed, as described in Section 3.4.• Solution Selection: Two parent operators O (t) a , O (t) b ∈ P (t) are selected for recombination.The selection strat-egy incorporates semantic information, as detailed in Section 3.3.• Solution Generation: Based on the selected parents, N candidate operators are generated per generation.Of these, N − M are generated via crossover and M via mutation:</p>
<p>Figure 4 :Figure 5 :Figure 6
456
Figure 4: Validation R 2 of the best solution across generations for different LLMdriven search strategies.</p>
<p>2</p>
<p>Figure 10 :
10
Figure 10: Training times of selection operators on symbolic regression benchmarks.</p>
<p>, to evaluate the effectiveness of the proposed operator in the context of modern symbolic regression.The only modification is the replacement of the automatic epsilon lexicase selection(La Cava et al. 2019)  with the Omni selection operator described in Code 3 in the supplementary material.All other components remain unchanged.The resulting algorithm is referred to as RAG-SR-Omni.For the experimental datasets, following the setup in Section 4, we use 116 out of 120 regression problems, excluding the four used during meta-evolution.Experimental ResultsThe results are presented in Figure 11.The figure show that RAG-SR-Omni outperforms RAG-SR in terms of median R 2 scores, model sizes, and training time, achieving the best performance among 26 symbolic regression and machine learning algorithms.These results indicate that the LLM-evolved selection operator can be seamlessly integrated into state-of-the-art symbolic regression methods to further enhance their performance.</p>
<p>Figure 12 :
12
Figure 12: Average token count of generated code across generations for different LLM-driven search strategies.</p>
<p>Figure 13 :
13
Figure 13: Test R 2 scores across generations.</p>
<p>'</p>
<p>Figure 17: Pairwise statistical comparison of selection operators using the Wilcoxon signed-rank test with Benjamini-Hochberg correction.</p>
<p>6 7UDLQLQJ7LPHVFigure 19 :
619
Figure 19: Training times of different selection operators on symbolic regression benchmarks, including Omni-Zero.</p>
<p>Figure 21 :
21
Figure 21: Tree sizes of different selection operators on small-scale symbolic regression benchmarks, including the repaired omni selection.</p>
<p>Figure 24: Pairwise statistical comparison of selection operators using the Wilcoxon signed-rank test with Benjamini-Hochberg correction.</p>
<p>Figure 25 :Figure 26 :
2526
Figure 25: Tree sizes of different selection operators on symbolic regression benchmarks, including the Holo selection operator.</p>
<p>Figure 27 :
27
Figure 27: Pareto front of the ranks of test R 2 scores and model sizes for different algorithms.</p>
<ol>
<li>The results related to validation score and code length are shown in Figure 28 and Figure 29, respectively.</li>
</ol>
<p>Evolutionary Symbolic Regression Meta Evolution Test Score Synthetic Evaluation Synthetic Evaluation Bloat Control Bloat Control Semantics Aware Evolution Semantics Aware Evolution Bloat Control Semantics Aware Evolution</p>
<p>P (t) = {O 1 , . . ., O N }: population where each O i has score vector s i 1: O a ← Random sample from P (t) 2: for each O i ∈ P (t) do
NoPopulation Initialization Population Initialization Solution Evaluation Solution EvaluationSelection OperatorPopulation Initialization Population Initialization Solution Evaluation Solution EvaluationEnd End Termination? Yes NoTermination?Survival Selection Survival SelectionYesSolution Selection Solution SelectionEnd EndSolution Selection Solution SelectionSolution GenerationSolution Generation Solution GenerationElitism ElitismFigure 3: Workflow of LLM-driven selection operator evolution.Algorithm 1: Semantics-Aware SelectionRequire: 3:which measures the potential combined performance of O aand O i across all datasets. The second parent O b is retrievedas the operator with the highest complementarity score, i.e.,O b = O i  *  where i  *  = arg max i µ i . This process can beviewed as retrieval-augmented generation (RAG), where com-plementarity serves as the similarity function to retrieve themost complementary code from the population to guide gen-eration.</p>
<p>Table 1 :
1
Median historical best scores and the corresponding code lengths for each algorithm over three runs.LLM-Meta-SR W/O Semantics W/O SE+BC W/O Knowledge W/O DK+SE W/O DK+SE+BC
Score0.860.840.840.790.750.75Lines of Code48438055412220.8Best Score0.6 0.70 2 4 6 8 10 12 14 16 18 20 GenerationLLM-Meta-SR W/O Semantics W/O SE+BCW/O Knowledge W/O DK+SE W/O DK+SE+BC</p>
<p>Median R 2 scores, model sizes, and training time of 26 algorithms on the symbolic regression benchmark.ure 7, model size and performance are not always in conflict.By carefully designing the selection operator, it is possible to evolve symbolic models that achieve both high accuracy and small model size, indicating high interpretability.
R 2 7HVW0RGHO6L]H7UDLQLQJ7LPHV5$<em>652PQL 5$</em>65 367UHH 7365 2SHURQ 6%3<em>3 )($7 61,3 (3/(; ;</em>% /<em>%0 </em>3<em>20($ $GD%RRVW 5DQGRP)RUHVW ,7($ $)3B)( $)3 )); .HUQHO5LGJH JSOHDUQ '65 05</em>3 0/3 /LQHDU %65 $,)H\QPDQíFigure 11:</p>
<p>Table 2 :
2
Parameter settings
ParameterValuePopulation size100Maximum generations 100Maximum tree depth10Initialization methodRamped half-and-half (depth 0-6)+, −, ×, AQ, | • |,Function setlog(1 + | • |), | • |, (•) 2 , sin π (•),cos π (•), Max, Min, NegCrossover rate0.9Mutation rate0.1For the experiment evaluating the evolved selection operatoron SRBench, the dataset is randomly split into a trainingset and a test set with an 80:20 ratio (La Cava et al. 2021).Subsampling is applied to limit the maximum number oftraining instances to 10,000, consistent with the SRBenchprotocol (La Cava et al. 2021). Symbolic regression is runon the training set and evaluated on the test set. All featuresare standardized, as this has been shown to be beneficialfor symbolic regression (Owen, Dick, and Whigham 2022).Standardization parameters are learned from the training dataand applied to both the training and test sets. All symbolicregression experiments are conducted on an AMD Milan7713 CPU.
Cava et al. 2021rotocol in Meta-EvolutionIn the evaluation of selection operators generated by the LLM, all other algorithmic components-including solution initialization, evaluation, generation, and elitism-follow standard practices commonly used in evolutionary symbolic regression.For each dataset D j , the data is split into training and validation subsets with an 80:20 ratio (LaCava et al. 2021).The regression model is optimized to maximize the training R 2 score, while the validation R 2 score is used as the final score of the selection operator.This encourages the selection of operators with implicit regularization capabilities.A.5 Evaluation Protocol for Discovered Operators</p>
<p>Benchmark AnalysisTo further analyze the behavior of the Omni selection operator, we plot the test R 2 scores on five representative datasets in Figure
])parent_b.append(population[b_idx1 def omni_selection(population, k=100,47 48return [ind for pair in zip(parent_a2status={}): stage = np.clip(status.get("49, parent_b) for ind in pair][:k]3 4evolutionary_stage", 0), 0, 1) n = len(population) half_k = k // 2Code 1: Omni Selection5y = population[0].y6n_cases = y.size78ssize = max(7, n_cases // max(1, 2 <em>half_k))9half_struct = half_k // 210structured = [11np.arange(i * ssize, min((i + 1)</em> ssize, n_cases)) for i in range(half_struct)12]13random_ = [14np.random.choice(n_cases, ssize,replace=False)15for _ in range(half_k -half_struct)16]17subsets = structured + random_1819residuals = np.vstack([ind.y -ind.predicted_values for ind inpopulation])20complexity = np.array([len(ind) +ind.height for ind in population],float)21complexity /= max(1, complexity.max())22subset_mse = np.array(23[24[((residuals[i, s]) ** 2).mean() if s.size else np.inf for s insubsets]25for i in range(n)26]27)28comp_factor = 0.25 + 0.25 * stage2930parent_a = [31population[np.lexsort((complexity, subset_mse[:, i]))[0]]32for i in range(len(subsets))33]3435idx_map = {ind: i for i, ind inenumerate(population)}36norms = np.linalg.norm(residuals,axis=1) + 1e-123738parent_b = []39for a in parent_a:40i_a = idx_map[a]41res_a = residuals[i_a]42cors = (residuals @ res_a) / (norms * norms[i_a])43cors[i_a] = 144comp_score = np.abs(cors) +comp_factor * complexity45b_idx = np.argmin(comp_score)</p>
<p>Table 3 :
3
Summary of datasets used in meta-evolution.
Datasetn observations n featuresOPENML 505240124OPENML 45441059117OPENML 5881000100OPENML 65050050</p>
<p>Table 4 :
4
Fusion of key selection components.Here s = sizes, h = heights, n c is the number of cases, comp pen is the complexity penalty, and corr denotes the normalized residual correlation.
6FRUH'DWDVHW'DWDVHW'DWDVHW'DWDVHW$YHUDJH3DUHQW3DUHQW2IIVSULQJFigure 22: Validation R 2 scores of parent and offspring se-lection operators on different datasets.1 def omni_selection(population, k=100,status={}):2stage = status.get("evolutionary_stage", 0)3n = len(population)4half_k = k // 25rng = np.random.default_rng(12345)67errs = np.array([ind.case_values forind in population])# (n,n_cases)8residuals = np.array([ind.y -ind.predicted_values for ind inpopulation])9sizes = np.array([len(ind) for indin population])10heights = np.array([ind.height forind in population])1112n_cases = errs.shape[1]13comp_pen = (sizes + heights) * (0.4+ 0.6 * stage) / (40 + 60 * stage) #adaptive comp penalty1415subset_size = max(8, n_cases // (half_k + 2))16max_tries = 15 * half_k</p>
<p>Table 6 :
6
Software used for experiments.
TypeName
Source Code: https://anonymous.4open.science/r/LLM-Meta-SR/
CodeDEAP(Fortin et al. 2012) Code CodeBLEU (Ren et al. 2020) Benchmark SRBench(La Cava et al. 2021)domain knowledge is not available, a larger mutation rate appears to be more beneficial.One possible reason is that when domain knowledge is available, the search space is more confined and a large mutation rate does not provide additional benefit.Conversely, when domain knowledge is not available, the search space is larger and a higher mutation rate is needed to effectively explore the space.J Related WorkJ.1 Recent Advancements in Selection OperatorsIn recent years, lexicase selection has shown strong empirical performance and is widely adopted in modern symbolic regression systems(Cava et al. 2019;Zhang et al. 2025).Inspired by lexicase selection, several variants have been developed, including probabilistic lexicase selection(Ding, Pantridge, and Spector 2023), lexicase-like selection via diverse aggregation (DALex)(Ni, Ding, and Spector 2024), ϵlexicase selection with dynamic split (D-Split) (Imai Aldeia, De Franc ¸a, and LaCava 2024), down-sampled lexicase selection(Boldi et al. 2024), and random down-sampled tournament selection(Geiger, Sobania, and Rothlauf 2025).These methods share the core idea of emphasizing performance on subsets of training instances to encourage specialization, and they demonstrate advantages in various scenarios(Geiger, Sobania, and Rothlauf 2025).However, these operators are manually designed and do not fully satisfy all the desired properties outlined in Section 3.5, highlighting the need for further exploration of selection operators.J.2 Automated Evolutionary Algorithm DesignBefore the LLM era, genetic programming had been widely used for automated evolutionary algorithm design, including the design of fitness functions (Fong and Motani 2024a), parameter adaptation techniques(Stanovov, Akhmedova, and Semenkin 2022), and update strategies(Lones 2021).More recently, reinforcement learning has also been applied to designing update rules in differential evolution(Chen et al. 2024a).However, these approaches are typically limited to generating only small code segments, as exploring large program spaces remains challenging.The emergence of LLMs has made automated algorithm design more feasible.For example, LLMs have been used to design a differential evolution algorithm competitive with state-of-the-art continu-ous optimization methods(Stein and Bäck 2024).Similarly, LLMs have been employed to improve the self-organizing migrating algorithm(Pluhacek et al. 2024).This growing interest in LLMs motivates the development of efficient LLMbased approaches for automated algorithm design, where semantic awareness and code bloat are two key issues that remain underexplored and warrant further investigation.J.3 Large Language Models for OptimizationLLMs have been employed as optimization tools across various domains(Meyerson et al. 2024;Song et al. 2024)Exploring the potential of LLMs in automating the design of improved evolutionary search strategies is a worthwhile direction.However, evaluating LLM-based evolutionary search in automated algorithm design is computationally expensive.In comparison, genetic programming is a relatively inexpensive and historically dominant method for code generation prior to the LLM era(Peabody and Seitzer 2015;Chen et al. 2023;Maudet and Danoy 2025).Therefore, leveraging LLMs for the automated design of genetic programming algorithms presents a relevant and cost-effective avenue for investigation.K Prompt for Algorithm EvolutionSystem Prompt: Figure30shows the system prompt used for algorithm evolution, which is added before the specific prompt in all three phases of the automated algorithm design process, including initialization, crossover, and mutation.The system prompt is designed to guide the LLM in generating efficient selection operators by preferring NumPy vectorized operations and avoiding explicit Python for-loops unless absolutely necessary.Python is chosen for its simplicity and strong support in LLMs, but standard for-loops are timeconsuming.In contrast, NumPy vectorized operations are implemented in C++ and offer better computational speed.The system prompt also specifies the maximum number of lines of code that the LLM can generate.This constraint helps control bloat, as discussed in Section 3.4.Initialization/Mutation Prompt: Figure31presents the prompts used for initialization and mutation.The main goal of these prompts is to encourage the LLM to generate a novel selection operator to explore the search space.The key difference between the prompts used for the two phases is that in the initialization phase, no baseline code is provided to the LLM.In the mutation phase, the elite solution is provided as the baseline code.The prompt format for wrapping the baseline code is shown in Figure32, which aims to encourage the LLM to generate a novel selection operator based on the provided code.Crossover Prompt: Figure33shows the crossover prompt used for algorithm evolution.The goal is specified as "selection operator," and its plural form, "selection operators".The crossover prompt takes the code of two existing selection operators as input and aims to generate a better operator by combining effective building blocks from both.To support semantic awareness and concise code generation, the prompt includes the score vector and the corresponding line of code.The properties describe the desired characteristics of the selection operator based on domain knowledge from Section 3.5.The specific prompt is shown in Figure34.The template provides a function signature to ensure that the generated operator can be integrated into the automatic evaluation pipeline as shown in Code 7. When domain knowledge is not provided, the properties are left empty and a simplified template without knowledge guidance for the selection operator, as shown in Code 8, is used.Fallback Selection Operator: In rare cases where the LLM fails to generate valid Python code, a simple tournament selection operator, as shown in Code 9, is used to fill the population.When writing code, prefer NumPy vectorized operations and avoid explicit Python for-loops unless absolutely necessary.Please implement code within {max code lines} lines.Your task is to develop an innovative and novel {goal} for symbolic regression using genetic programming in Python.{Baseline} {Properties}Ensure that your newly designed function adheres to the following signature: {Template} You do not need to provide a usage example.Embrace creativity, novelty, and bold experimentation to push the boundaries of the state of the art in {goals} for genetic programming.-Encourage specialization to maintain a diverse population.2. Crossover-Aware Pairing -Promote complementarity between parents.Stage-Specific Pressure-Vary selection pressure based on the current stage of evolution.Interpretability-Prefer individuals with fewer nodes and lower tree height to improve model interpretability.Efficiency &amp; Scalability-Include clear stopping conditions to avoid infinite loops.Code Simplicity-Favor clear, concise logic with minimal complexity.Reproducibility Checklist Instructions for Authors:This document outlines key aspects for assessing reproducibility.Please provide your input by editing this .texfile directly.For each question (that applies), replace the "Type your response here" text with your answer.Example: If a question appears as \question{Proofs of all novel claims are included} {(yes/partial/no)} Type your response here you would change it to:\question{Proofs of all novel claims are included} {(yes/partial/no)} yes Please make sure to:• Replace ONLY the "Type your response here" text and nothing else.• Use one of the options listed for that question (e.g., yes, no, partial, or NA).• Not modify any other part of the \question command or any other lines in this document.You can \input this .texfile right before \end{document} of your main file or compile it as a stand-alone document.Check the instructions on your conference's website to see if you will be asked to provide this checklist with your paper or separately.General
The relationship between variable selection and data agumentation and a method for prediction. D M Allen, Technometrics. 1611974</p>
<p>Genetic programming: an introduction: on the automatic evolution of computer programs and its applications. W Banzhaf, P Nordin, R E Keller, F D Francone, 1998Morgan Kaufmann Publishers Inc</p>
<p>Informed Down-Sampled Lexicase Selection: Identifying productive training cases for efficient problem solving. L Biggio, T Bendinelli, A Neitz, A Lucchi, G Parascandolo, Pmlr, R Boldi, M Briesch, D Sobania, A Lalejini, T Helmuth, F Rothlauf, C Ofria, L Spector, International Conference on Machine Learning. 2021. 202432Neural symbolic regression that scales</p>
<p>Learning concise representations for regression by evolving networks of trees. W L Cava, T R Singh, J Taggart, S Suri, J Moore, International Conference on Learning Representations. 2019</p>
<p>J S Chan, N Chowdhury, O Jaffe, J Aung, D Sherburn, E Mays, G Starace, K Liu, L Maksin, T Patwardhan, MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering. 2025In ICLR. Open-Review.net</p>
<p>Evoprompting: Language models for code-level neural architecture search. A Chen, D Dohan, D So, Advances in Neural Information Processing Systems. 202336</p>
<p>SYMBOL: Generating Flexible Black-Box Optimizers through Symbolic Equation Learning. J Chen, Z Ma, H Guo, Y Ma, J Zhang, Y.-J Gong, The Twelfth International Conference on Learning Representations. 2024a</p>
<p>. J Chen, J Tian, L Wu, Chenxinwei, </p>
<p>KinFormer: Generalizable Dynamical Symbolic Regression for Catalytic Organic Reaction Kinetics. X Yang, Y Jin, Y Xu, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Symbolic discovery of optimization algorithms. X Chen, C Liang, D Huang, E Real, K Wang, H Pham, X Dong, T Luong, C.-J Hsieh, Y Lu, Advances in Neural Information Processing Systems. 202336</p>
<p>Z Chen, Z Zhou, Y Lu, R Xu, L Pan, Z Lan, arXiv:2412.20694QUBE: Enhancing Automatic Heuristic Design via Quality-Uncertainty Balanced Evolution. 2024barXiv preprint</p>
<p>Hsevo: Elevating automatic heuristic design with diversity-driven harmony search and genetic algorithm using llms. P V T Dat, L Doan, H T T Binh, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>MetaSR: A Meta-Learning Approach to Fitness Formulation for Frequency-Aware Symbolic Regression. L Ding, E Pantridge, L Spector, B Dolin, M G Arenas, J J Merelo, Springer, M Feng, Y Huang, Y Liu, B Jiang, J Yan, Parallel Problem Solving from Nature-PPSN VII: 7th International Conference Granada. K S Fong, M Motani, Spain2023. 2002. September 7-11. 2002. 20257Proceedings of the Genetic and Evolutionary Computation Conference</p>
<p>Symbolic regression enhanced decision trees for classification tasks. K S Fong, M Motani, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2024b38</p>
<p>DEAP: Evolutionary algorithms made easy. F.-A Fortin, F.-M De Rainville, M.-A G Gardner, M Parizeau, C Gagné, The Journal of Machine Learning Research. 1312012</p>
<p>Customizing language model responses with contrastive in-context learning. X Gao, K Das, Proceedings of the aaai conference on artificial intelligence. the aaai conference on artificial intelligence202438</p>
<p>A Performance Analysis of Lexicase-Based and Traditional Selection Methods in GP for Symbolic Regression. A Geiger, M Briesch, D Sobania, F Rothlauf, Springer, A Geiger, D Sobania, F Rothlauf, European Conference on Genetic Programming. 2025. 2025Was Tournament Selection All We Ever Needed? A Critical Reflection on Lexicase Selection</p>
<p>Evolutionary large language model for automated feature transformation. N Gong, C K Reddy, W Ying, H Chen, Y Fu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>Autonomous multi-objective optimization using large language model. A Grayeli, A Sehgal, O Costilla-Reyes, M Cranmer, S Chaudhuri, Y Huang, S Wu, W Zhang, J Wu, L Feng, K C Tan, arXiv:2409.09359IEEE Transactions on Evolutionary Computation. 2024. 2025aarXiv preprintSymbolic regression with a learned concept library</p>
<p>Toward evolving dispatching rules with flow control operations by grammar-guided linear genetic programming. Z Huang, Y Mei, F Zhang, M Zhang, IEEE Transactions on Evolutionary Computation. 2024</p>
<p>CALM: Co-evolution of Algorithms and Language Model for Automatic Heuristic Design. Z Huang, W Wu, K Wu, J Wang, W.-B Lee, arXiv:2505.12285Proceedings of the Genetic and Evolutionary Computation Conference. La Cava, W G , the Genetic and Evolutionary Computation Conference2025barXiv preprintImai Aldeia, G. S.; De Franc ¸a</p>
<p>LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch. C Jiang, X Shu, H Qian, X Lu, J Zhou, A Zhou, Y Yu, Proceedings of the Thirteenth International Conference on Learning Representations (ICLR). the Thirteenth International Conference on Learning Representations (ICLR)Singapore, Singapore2025</p>
<p>Racing Control Variable Genetic Programming for Symbolic Regression. N Jiang, Y Xue, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>Dimension Reduction for Symbolic Regression. P Kahlmeyer, M Fischer, J Giesen, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>End-to-end symbolic regression with transformers. P Kamienny, S -A.; D'ascoli, G Lample, F Charton, Advances in Neural Information Processing Systems. 202235</p>
<p>Deep generative symbolic regression with Monte-Carlo-tree-search. P.-A Kamienny, G Lample, S Lamprier, M Virgolin, International Conference on Machine Learning. PMLR2023</p>
<p>Shape-constrained symbolic regression-improving extrapolation with prior knowledge. G Kronberger, F O De Franc ¸a, B Burlacu, C Haider, M Kommenda, Evolutionary Computation. 3012022</p>
<p>Contemporary symbolic regression methods and their relative performance. Advances in neural information processing systems. La Cava, W Burlacu, B Virgolin, M Kommenda, M Orzechowski, P De Franc ¸a, F O Jin, Y Moore, J H , 202120211</p>
<p>. La Cava, W Helmuth, T Spector, L Moore, J , </p>
<p>A probabilistic and multi-objective analysis of lexicase selection and ε-lexicase selection. Evolutionary Computation. 273</p>
<p>A unified framework for deep symbolic regression. M Landajuela, C S Lee, J Yang, R Glatt, C P Santiago, I Aravena, T Mundhenk, G Mulcahy, B K Petersen, Advances in Neural Information Processing Systems. 202235</p>
<p>Efficiently evolving programs through the search for novelty. J Lehman, K O Stanley, Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computation. the 12th Annual Conference on Genetic and Evolutionary Computation2010</p>
<p>Pareto set learning for expensive multi-objective optimization. X Lin, Z Yang, X Zhang, Q Zhang, Advances in Neural Information Processing Systems. 202235</p>
<p>Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model. F Liu, T Xialiang, M Yuan, X Lin, F Luo, Z Wang, Z Lu, Q Zhang, International Conference on Machine Learning. PMLR2024a</p>
<p>Decision Tree Induction Through LLMs via Semantically-Aware Evolution. S Liu, C Chen, X Qu, K Tang, Y.-S Ong, The Thirteenth International Conference on Learning Representations. 2024b. 2024Large language models as evolutionary optimizers</p>
<p>Evolving continuous optimisers from scratch. Genetic Programming and Evolvable Machines. M A Lones, 202122</p>
<p>Eureka: Human-Level Reward Design via Coding Large Language Models. Y J Ma, W Liang, G Wang, D.-A Huang, O Bastani, D Jayaraman, Y Zhu, L Fan, A Anandkumar, The Twelfth International Conference on Learning Representations. 2024</p>
<p>Solving the exponential growth of symbolic regression trees in geometric semantic genetic programming. J F B Martins, L O V Oliveira, L F Miranda, F Casadei, G L Pappa, Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation Conference2018</p>
<p>Search Strategy Generation for Branch and Bound Using Genetic Programming. G Maudet, G Danoy, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>Language model crossover: Variation through few-shot prompting. E Meyerson, M J Nelson, H Bradley, A Gaier, A Moradi, A K Hoover, J Lehman, ACM Transactions on Evolutionary Learning. 442024</p>
<p>AutoS-GNN: automatic propagation mechanism discovery for spectral graph neural networks. S Mo, K Wu, Q Gao, X Teng, J Liu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>Geometric semantic GP with linear scaling: Darwinian versus Lamarckian evolution. A Moraglio, K Krawiec, C G Johnson, G Nadizar, B Sakallioglu, F Garrow, S Silva, L Vanneschi, Parallel Problem Solving from Nature-PPSN XII: 12th International Conference. Taormina, ItalyGenetic Programming and Evolvable Machines2012. September 1-5, 2012. 20241217Geometric semantic genetic programming</p>
<p>The use of an analytic quotient operator in genetic programming. A Ni, L Ding, L Spector, Springer, J Ni, R H Drieberg, P I Rockett, European Conference on Genetic Programming. 2024. 201217Dalex: Lexicase-like selection via diverse aggregation</p>
<p>Standardization and data augmentation in genetic programming. C A Owen, G Dick, P A Whigham, IEEE Transactions on Evolutionary Computation. 2662022</p>
<p>Using LLM for automatic evolvement of metaheuristics from swarm algorithm SOMA. C Peabody, J Seitzer, M Kovac, J Viktorin, A Janku, P Kadavy, T Senkerik, R , Proceedings of the Genetic and Evolutionary Computation Conference Companion. the Genetic and Evolutionary Computation Conference Companion2015. 2024. 2018-202229Proceedings of the AAAI Conference on Artificial Intelligence</p>
<p>Automl-zero: Evolving machine learning algorithms from scratch. E Real, C Liang, D So, Q Le, S Pmlr. Ren, D Guo, S Lu, L Zhou, S Liu, D Tang, N Sundaresan, M Zhou, A Blanco, S Ma, arXiv:2009.10297International Conference on Machine Learning. 2020. 2020arXiv preprintCodebleu: a method for automatic evaluation of code synthesis</p>
<p>Mathematical discoveries from program search with large language models. B Romera-Paredes, M Barekatain, A Novikov, M Balog, M P Kumar, E Dupont, F J Ruiz, J S Ellenberg, P Wang, O Fawzi, Nature. 62579952024</p>
<p>Symbolic cognitive diagnosis via hybrid optimization for intelligent education systems. J Shen, H Qian, W Zhang, A Zhou, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>AlphaForge: A Framework to Mine and Dynamically Combine Formulaic Alpha Factors. H Shi, W Song, X Zhang, J Shi, C Luo, X Ao, H Arian, L A Seco, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>. P Shojaee, K Meidani, A Barati Farimani, C Reddy, </p>
<p>Transformer-based planning for symbolic regression. Advances in Neural Information Processing Systems. 36</p>
<p>LLM-SR: Scientific Equation Discovery via Programming with Large Language Models. P Shojaee, K Meidani, S Gupta, A B Farimani, C K Reddy, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Position: leverage foundational models for blackbox optimization. X Song, Y Tian, R T Lange, C Lee, Y Tang, Y Chen, Proceedings of the 41st International Conference on Machine Learning. the 41st International Conference on Machine Learning2024</p>
<p>The automatic design of parameter adaptation techniques for differential evolution with genetic programming. V Stanovov, S Akhmedova, E Semenkin, Knowledge-Based Systems. 2391080702022</p>
<p>Llamea: A large language model evolutionary algorithm for automatically generating metaheuristics. N V Stein, T Bäck, IEEE Transactions on Evolutionary Computation. 2024</p>
<p>Algorithm Discovery With LLMs: Evolutionary Search Meets Reinforcement Learning. A Šurina, A Mansouri, A Seddas, M Viazovska, E Abbe, C Gulcehre, Scaling Self-Improving Foundation Models. 2025without Human Supervision</p>
<p>Improving model-based genetic programming for symbolic regression of small expressions. M Virgolin, T Alderliesten, C Witteveen, P A Bosman, Evolutionary computation. 2922021</p>
<p>Efficient Heuristics Generation for Solving Combinatorial Optimization Problems Using Large Language Models. X Wu, D Wang, C Wu, L Wen, C Miao, Y Xiao, Y Zhou, H Xie, M Zhang, M Xu, Y Mei, F Zhang, M Zhang, arXiv:2505.12627Proceedings of the Genetic and Evolutionary Computation Conference Companion. the Genetic and Evolutionary Computation Conference Companion2025. 2012. 202217arXiv preprintGenetic programming with diverse partner selection for dynamic flexible job shop scheduling</p>
<p>Multi-agent dynamic algorithm configuration. K Xue, J Xu, L Yuan, M Li, C Qian, Z Zhang, Y Yu, Advances in Neural Information Processing Systems. 202235</p>
<p>Large Language Models as Optimizers. C Yang, X Wang, Y Lu, H Liu, Q V Le, D Zhou, X Chen, The Twelfth International Conference on Learning Representations. 2024</p>
<p>Multi-objective evolution of heuristic using large language model. S Yao, F Liu, X Lin, Z Lu, Z Wang, Q Zhang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>Automated configuration of genetic algorithms by tuning for anytime performance. F Ye, C Doerr, H Wang, T Bäck, IEEE Transactions on Evolutionary Computation. 2662022</p>
<p>Large Language Model-driven Large Neighborhood Search for Large-Scale MILP Problems. H Ye, J Wang, Z Cao, F Berto, C Hua, H Kim, J Park, G Song, H Xu, A Yan, Y Cheng, The Thirtyeighth Annual Conference on Neural Information Processing Systems. Ye, H2024. 2025Forty-second International Conference on Machine Learning</p>
<p>Symbolic regression via MDLformer-guided search: from minimizing prediction error to minimizing description length. Z Yu, J Ding, Y Li, Jin , D Zhang, H Chen, Q Xue, B Banzhaf, W Zhang, M , The Thirteenth International Conference on Learning Representations. 2025. 2025The Thirteenth International Conference on Learning Representations</p>
<p>Understanding the importance of evolutionary search in automated heuristic design with large language models. R Zhang, F Liu, X Lin, Z Wang, Z Lu, Q Zhang, Springer, Z Zhao, H Wen, P Wang, Y Wei, Z Zhang, X Lin, F Liu, B An, H Xiong, Y Wang, arXiv:2503.10721From Understanding to Excelling: Template-Free Algorithm Design through Structural-Functional Co-Evolution. 2024. 2025arXiv preprintInternational Conference on Parallel Problem Solving from Nature</p>            </div>
        </div>

    </div>
</body>
</html>