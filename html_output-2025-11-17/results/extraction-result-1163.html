<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1163 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1163</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1163</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-28.html">extraction-schema-28</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <p><strong>Paper ID:</strong> paper-239016257</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2110.08488v2.pdf" target="_blank">Lifelong Topological Visual Navigation</a></p>
                <p><strong>Paper Abstract:</strong> Commonly, learning-based topological navigation approaches produce a local policy while preserving some loose connectivity of the space through a topological map. Nevertheless, spurious or missing edges in the topological graph often lead to navigation failure. In this work, we propose a sampling-based graph building method, which results in sparser graphs yet with higher navigation performance compared to baseline methods. We also propose graph maintenance strategies that eliminate spurious edges and expand the graph as needed, which improves lifelong navigation performance. Unlike controllers that learn from fixed training environments, we show that our model can be fine-tuned using only a small number of collected trajectory images from a real-world environment where the agent is deployed. We demonstrate successful navigation after fine-tuning on real-world environments, and notably show significant navigation improvements over time by applying our lifelong graph maintenance strategies.</p>
                <p><strong>Cost:</strong> 0.009</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1163.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1163.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LTvN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Lifelong Topological Visual Navigation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An image-goal topological navigation system that builds a sparse, controller-aware topological graph from RGB-D trajectory images using a learned reachability+waypoint model, and continuously refines that graph via Bayesian edge updates and node addition to improve lifelong navigation performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Gibson / iGibson indoor scenes (image-goal navigation)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Realistic cluttered indoor household/lab environments used via the Gibson/iGibson simulators and real-world LoCoBot deployments; tasks are image-goal navigation where goals are specified by RGB-D images of target locations.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td>Physical doorways and narrow openings are present and explicitly noted as navigation challenges (''small openings (e.g., doors)''); no mention of locked or conditional doors.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Sparse, sampling-based topological graph where edges encode controller-dependent reachability; initial graphs can contain spurious edges (e.g., across walls) which are pruned via lifelong maintenance; edges are weighted by SE(2) pose-distance estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Test maps reported with floor area and number of collected trajectory images: Barahona 57 m^2 (985 images), Bellemeade 70 m^2 (1,685 images), Akiak 124 m^2 (1,609 images), Caruthers 129 m^2 (2,243 images); graphs use a subset of collected images (sparsification).</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Model-based topological agent: CNN reachability+waypoint model + position-based feedback controller (iLQR used in real-world tests) with graph search (Dijkstra).</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agent localizes by comparing current RGB-D observation to graph nodes via the learned model f(o_i,o_j)→[reachability r, waypoint w(dx,dy,dθ)]; plans with Dijkstra over weighted directed topological graph; executes first-hop waypoint using a position-based feedback controller; graph maintenance updates edge existence probabilities (Bernoulli) and edge distance posteriors (Gaussian) using traversal outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Primary metrics: navigation success rate (episodes), graph sparsity (number of nodes/edges) as a proxy for planning/search efficiency; also collision counts, number of queries, and K-step episode limits.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Real-world reported: Apartment before maintenance 4/20 (20%), after 13/20 (65%); University lab before 4/20 (20%), after 14/20 (70%). Simulation: method yields consistently higher success rates than SPTM/ViNG, especially after fine-tuning (exact percentages not reported in text).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Planning-based topological policy using graph search with a local controller for edge execution (controller-aware, memory of graph structure); local reactive controllers alone are noted as insufficient for long-distance navigation.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Explicit relationships reported: (1) Spurious edges (false positives between nodes) cause infeasible plans and navigation failure; (2) Missing edges (false negatives) can make paths undiscoverable despite physical traversability; (3) Sparser, controller-aware graphs (via sampling and node merging) reduce false connectivity and improve navigation success and planning efficiency; (4) Lifelong graph maintenance that prunes edges with low posterior connectivity and adds nodes when paths are missing increases success rate over time while keeping graph size stable; (5) Edge weighting by predicted SE(2) pose-distance aids planning compared to unweighted edges.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Compared sampling-based sparse graphs (this work) vs. baseline dense graphs built from all trajectory images (SPTM, ViNG): sparse graphs produced fewer nodes/edges while maintaining coverage, exhibited fewer false-positive edges (e.g., across walls), and achieved higher navigation success and lower planning costs. ViNG's temporal-weighted edges and SPTM's unweighted edges are contrasted: unweighted false-positive edges are repeatedly chosen and cause failures; regressed-step weighting (ViNG) helps but requires large real-world data. Lifelong updates further improve performance by pruning spurious edges and selectively adding nodes required to find paths.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Findings tying policy structure to topology: (1) Local controller capability should be considered during graph construction (controller-dependent reachability) — graphs that ignore controller limits include edges that are not traversable in practice; (2) A planner+local-controller architecture (graph search + local waypoint controller) is more effective for long-distance navigation than purely reactive/global controllers; (3) Graph maintenance (updating edge existence probabilities and edge weights) effectively changes the policy's available action graph over time, improving robustness to spurious connectivity; (4) The paper implies that policies in environments with more spurious connectivity require additional mechanisms (edge validation/pruning) to avoid executing infeasible plans.</td>
                        </tr>
                        <tr>
                            <td><strong>additional_notes</strong></td>
                            <td>Graph-building uses two thresholds: isMergeable (Dm) to remove redundant nodes and isConnectable (Dc) to decide whether to add an edge; edge distance computed as Frobenius norm of log of SE(2) transform; reachability labels are defined controller-dependently and determined in simulation via visual overlap and feasible-path ratio; lifelong updates use a discrete Bayes update for edge existence and Gaussian filtering for edge-distance posterior.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Lifelong Topological Visual Navigation', 'publication_date_yy_mm': '2021-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Semi-parametric topological memory for navigation <em>(Rating: 2)</em></li>
                <li>Ving: Learning open-world navigation with visual goals <em>(Rating: 2)</em></li>
                <li>Scaling local control to large-scale topological navigation <em>(Rating: 2)</em></li>
                <li>Bayesian relational memory for semantic visual navigation <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1163",
    "paper_id": "paper-239016257",
    "extraction_schema_id": "extraction-schema-28",
    "extracted_data": [
        {
            "name_short": "LTvN",
            "name_full": "Lifelong Topological Visual Navigation",
            "brief_description": "An image-goal topological navigation system that builds a sparse, controller-aware topological graph from RGB-D trajectory images using a learned reachability+waypoint model, and continuously refines that graph via Bayesian edge updates and node addition to improve lifelong navigation performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "Gibson / iGibson indoor scenes (image-goal navigation)",
            "environment_description": "Realistic cluttered indoor household/lab environments used via the Gibson/iGibson simulators and real-world LoCoBot deployments; tasks are image-goal navigation where goals are specified by RGB-D images of target locations.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": true,
            "door_constraints_description": "Physical doorways and narrow openings are present and explicitly noted as navigation challenges (''small openings (e.g., doors)''); no mention of locked or conditional doors.",
            "graph_connectivity": "Sparse, sampling-based topological graph where edges encode controller-dependent reachability; initial graphs can contain spurious edges (e.g., across walls) which are pruned via lifelong maintenance; edges are weighted by SE(2) pose-distance estimates.",
            "environment_size": "Test maps reported with floor area and number of collected trajectory images: Barahona 57 m^2 (985 images), Bellemeade 70 m^2 (1,685 images), Akiak 124 m^2 (1,609 images), Caruthers 129 m^2 (2,243 images); graphs use a subset of collected images (sparsification).",
            "agent_name": "Model-based topological agent: CNN reachability+waypoint model + position-based feedback controller (iLQR used in real-world tests) with graph search (Dijkstra).",
            "agent_description": "Agent localizes by comparing current RGB-D observation to graph nodes via the learned model f(o_i,o_j)→[reachability r, waypoint w(dx,dy,dθ)]; plans with Dijkstra over weighted directed topological graph; executes first-hop waypoint using a position-based feedback controller; graph maintenance updates edge existence probabilities (Bernoulli) and edge distance posteriors (Gaussian) using traversal outcomes.",
            "exploration_efficiency_metric": "Primary metrics: navigation success rate (episodes), graph sparsity (number of nodes/edges) as a proxy for planning/search efficiency; also collision counts, number of queries, and K-step episode limits.",
            "exploration_efficiency_value": null,
            "success_rate": "Real-world reported: Apartment before maintenance 4/20 (20%), after 13/20 (65%); University lab before 4/20 (20%), after 14/20 (70%). Simulation: method yields consistently higher success rates than SPTM/ViNG, especially after fine-tuning (exact percentages not reported in text).",
            "optimal_policy_type": "Planning-based topological policy using graph search with a local controller for edge execution (controller-aware, memory of graph structure); local reactive controllers alone are noted as insufficient for long-distance navigation.",
            "topology_performance_relationship": "Explicit relationships reported: (1) Spurious edges (false positives between nodes) cause infeasible plans and navigation failure; (2) Missing edges (false negatives) can make paths undiscoverable despite physical traversability; (3) Sparser, controller-aware graphs (via sampling and node merging) reduce false connectivity and improve navigation success and planning efficiency; (4) Lifelong graph maintenance that prunes edges with low posterior connectivity and adds nodes when paths are missing increases success rate over time while keeping graph size stable; (5) Edge weighting by predicted SE(2) pose-distance aids planning compared to unweighted edges.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "Compared sampling-based sparse graphs (this work) vs. baseline dense graphs built from all trajectory images (SPTM, ViNG): sparse graphs produced fewer nodes/edges while maintaining coverage, exhibited fewer false-positive edges (e.g., across walls), and achieved higher navigation success and lower planning costs. ViNG's temporal-weighted edges and SPTM's unweighted edges are contrasted: unweighted false-positive edges are repeatedly chosen and cause failures; regressed-step weighting (ViNG) helps but requires large real-world data. Lifelong updates further improve performance by pruning spurious edges and selectively adding nodes required to find paths.",
            "policy_structure_findings": "Findings tying policy structure to topology: (1) Local controller capability should be considered during graph construction (controller-dependent reachability) — graphs that ignore controller limits include edges that are not traversable in practice; (2) A planner+local-controller architecture (graph search + local waypoint controller) is more effective for long-distance navigation than purely reactive/global controllers; (3) Graph maintenance (updating edge existence probabilities and edge weights) effectively changes the policy's available action graph over time, improving robustness to spurious connectivity; (4) The paper implies that policies in environments with more spurious connectivity require additional mechanisms (edge validation/pruning) to avoid executing infeasible plans.",
            "additional_notes": "Graph-building uses two thresholds: isMergeable (Dm) to remove redundant nodes and isConnectable (Dc) to decide whether to add an edge; edge distance computed as Frobenius norm of log of SE(2) transform; reachability labels are defined controller-dependently and determined in simulation via visual overlap and feasible-path ratio; lifelong updates use a discrete Bayes update for edge existence and Gaussian filtering for edge-distance posterior.",
            "uuid": "e1163.0",
            "source_info": {
                "paper_title": "Lifelong Topological Visual Navigation",
                "publication_date_yy_mm": "2021-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Semi-parametric topological memory for navigation",
            "rating": 2,
            "sanitized_title": "semiparametric_topological_memory_for_navigation"
        },
        {
            "paper_title": "Ving: Learning open-world navigation with visual goals",
            "rating": 2,
            "sanitized_title": "ving_learning_openworld_navigation_with_visual_goals"
        },
        {
            "paper_title": "Scaling local control to large-scale topological navigation",
            "rating": 2,
            "sanitized_title": "scaling_local_control_to_largescale_topological_navigation"
        },
        {
            "paper_title": "Bayesian relational memory for semantic visual navigation",
            "rating": 2,
            "sanitized_title": "bayesian_relational_memory_for_semantic_visual_navigation"
        }
    ],
    "cost": 0.0092865,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Lifelong Topological Visual Navigation
2022</p>
<p>Ieee 
Letters 
Version 
June 
Lifelong Topological Visual Navigation
12022This paper has been accepted to IEEE Robotics and Automation Letters (RA-L) and International Conference on Intelligent Robots and Systems (IROS) 2022.Index Terms-Vision-Based Navigation, Deep Learning for Visual Perception
Commonly, learning-based topological navigation approaches produce a local policy while preserving some loose connectivity of the space through a topological map. Nevertheless, spurious or missing edges in the topological graph often lead to navigation failure. In this work, we propose a samplingbased graph building method, which results in sparser graphs yet with higher navigation performance compared to baseline methods. We also propose graph maintenance strategies that eliminate spurious edges and expand the graph as needed, which improves lifelong navigation performance. Unlike controllers that learn from fixed training environments, we show that our model can be fine-tuned using only a small number of collected trajectory images from a real-world environment where the agent is deployed. We demonstrate successful navigation after finetuning on real-world environments, and notably show significant navigation improvements over time by applying our lifelong graph maintenance strategies. a</p>
<p>Lifelong Topological Visual Navigation</p>
<p>Rey Reza Wiyatno 1 , Anqi Xu 2 , and Liam Paull 1 Abstract-Commonly, learning-based topological navigation approaches produce a local policy while preserving some loose connectivity of the space through a topological map. Nevertheless, spurious or missing edges in the topological graph often lead to navigation failure. In this work, we propose a samplingbased graph building method, which results in sparser graphs yet with higher navigation performance compared to baseline methods. We also propose graph maintenance strategies that eliminate spurious edges and expand the graph as needed, which improves lifelong navigation performance. Unlike controllers that learn from fixed training environments, we show that our model can be fine-tuned using only a small number of collected trajectory images from a real-world environment where the agent is deployed. We demonstrate successful navigation after finetuning on real-world environments, and notably show significant navigation improvements over time by applying our lifelong graph maintenance strategies. a Index Terms-Vision-Based Navigation, Deep Learning for Visual Perception</p>
<p>I. INTRODUCTION</p>
<p>A standard workflow for robot navigation involves first manually piloting a robot to build a metric map with simultaneous localization and mapping (SLAM) [1]. However, with this type of metric-based navigation, it is unintuitive to specify goals in metric space, and also tedious for an expert user to pilot the robot around to build the map. Ideally, navigation goals should have an intuitive representation, such as images of target objects or locations, and a non-expert user should be able to provide them in a natural way. While we see the emergence of learning-based methods that directly map images to actions by learning a global controller [2], these policies tend to be reactive, are not data efficient, and are not suitable for long-distance navigation.</p>
<p>An alternative strategy is to forego the metric map and maintain a topological representation of the environment [3]. In such a setup, each edge in the graph encodes the traversability between two locations, while a local controller is used to actually navigate the edge. In contrast to a global controller, navigating within a local vicinity is an easier task than navigating globally through a complex environment. The challenge   Sample plans produced with our method to navigate from a start to a goal image, before and after graph maintenance. The blue dots indicate nodes within the planned path. The plan in Fig. 1(a) led to navigation failure since nodes #3 and #4 are erroneously connected. Fig. 1(b) showcases the refined plan after graph maintenance, which led to successful navigation.</p>
<p>here is how to construct such a representation in an efficient way that enables a local controller to navigate the environment.</p>
<p>A desirable setup is for the nodes in the topological graph to correspond directly to sensor data collected from the corresponding pose in space. We use colored depth (RGB-D) images as sensor data, and develop a model that jointly predicts reachability and relative transformation between two RGB-D images, which we will use to determine connectivity between the nodes of the graph. Importantly, we show that this model can be pre-trained using automatically generated simulated data, and then fine-tuned using only the data that is collected to build the graph in the target environment.</p>
<p>To build the graph, we take inspiration from traditional sampling-based robotics planners such as probabilistic roadmaps (PRM) [4] and rapidly-exploring random trees (RRT) [5] but formulate the problem over sensor data space rather than configuration space. We propose a sampling-based graph building process that produces sparser graphs and also improves navigation performance when compared to baselines. We construct this graph by sampling nodes from a pool of collected images and using the proposed model to determine the connectivity between the nodes.</p>
<p>Since the connectivity of our graph is determined by a potentially imperfect model, it is important to address the possibility of spurious edges. False positives from this model will induce spurious edges in the graph and may cause the agent to execute infeasible plans, while false negatives will result in edges being omitted and may result in failure to find a path when one actually exists. Thus, while other methods [6]- [8] treat their graphs as static objects, we continually refine ours based on what our agent experiences when executing navigation queries. As a result, these graph updates enable lifelong navigation; they eliminate spurious edges and possibly add new nodes that might be missing, as shown in Fig. 1, which improves navigation performance over time.</p>
<p>To summarize, our main contributions are: 1) A sampling-based graph building process that produces sparser graphs and improves navigation performance, 2) A multi-purpose model for graph building, path execution, and graph maintenance, that can be fine-tuned in real-world using small amount of data, 3) A graph maintenance procedure that enables continuous graph refinement during operation that improves lifelong navigation performance.</p>
<p>II. RELATED WORKS</p>
<p>Learning-based approaches have shown promising results in solving visual navigation tasks. For example, several works have used reinforcement learning (RL) to learn to navigate based on a goal image [2], [9]. Training RL policies requires significant computation and time however, and typically involve additional sim-to-real transfer method such as domain randomization [10] that in practice tend to not scale well in real-world. End-to-end methods also tend to not work well in long-distance navigation tasks.</p>
<p>More closely related to our approach are semi-parametric topological memory (SPTM) [6] and visual navigation with goals (ViNG) [8]. SPTM builds a graph using a classifier that infers if two images are temporally close. However, the graph edges are unweighted, so false positive edges may be repeatedly chosen during planning. ViNG regresses the number of steps required to move from one image to another, and uses this to weigh each edge. ViNG also proposes to prune edges that are deemed by their model to be easily traversable during the graph building stage. In contrast, our pruning strategy operates continually based on what our agent experiences when executing a navigation query, which leads into lifelong navigation improvements. Furthermore, while ViNG demonstrates the ability to navigate in the real-world, ViNG requires 40 hours of offline real-world data, which is tedious to gather. Our model can be fine-tuned in real-world using a significantly smaller dataset.</p>
<p>As a common concern, both SPTM and ViNG build a graph using all images within the collected trajectories, which poses scalability and false connectivity issues. Furthermore, both methods build the graph without considering the capability of their controller, which may result in edges that are not traversable in practice. Moreover, by solely relying on temporal distance within collected trajectories, they are blind to the connection of nodes that are spatially close, yet temporally far  2. A common topological navigation framework consists of separate graph building and navigation phases. When deployed in a new environment, an agent first collects observations from an environment and builds a topological graph. During navigation, the agent localizes itself on the graph, plans a path to a given goal, and moves to a subgoal using a controller. The agent then relocalizes itself, and repeats the planning and control steps until it reaches the goal. Our work highlights the importance of updating the graph, which is missing from most existing work.</p>
<p>within the explored trajectories (i.e., loops). In contrast, our graph building process relies on a model that is aware of the limitations of the controller used.</p>
<p>Bayesian Relational Memory (BRM) [11] builds a fullyconnected graph where nodes and edges map to room types and the probability of room connectivity. BRM trains a classifier that predicts the probability of an image belonging to different room types. As the agent navigates, edge weights are refined using Bayesian updates. Our graph maintenance strategy is similar to that of BRM, but we can also introduce new nodes to the graph as necessary to enable planning.</p>
<p>Meng et al. [7] proposed a controller-dependent graph building method. At its core, a classifier is trained based on the controller rollout outcome in simulation to predict if an image pair is reachable. To build the graph, this classifier model is used to first sparsify highly reachable redundant nodes in the trajectories. Then, the remaining nodes are connected with edges weighted by predicted reachability scores. As a drawback, it is impractical to fine-tune this reachability model in the real-world, as it would require empirically unsafe controller rollouts between location pairs.</p>
<p>Other methods rely on an actor-critic model to evaluate graph connectivity using the critic [12]- [14]. Scott et al. [14] further sparsify the graph by only adding perceptually distinct nodes, merging nodes with shared connections, limiting the number of edges per node, and removing edges predicted as not traversable during test time. However, these sparsification strategies may lead to excessive false negative edges and poor connectivity. Also, such simulation-trained policies may not transfer well to real-world environments.</p>
<p>Our system shares a common structure with other learningbased topological navigation methods, as shown in Fig. 2. Still, our approach differs in choices for the learned model, data collection procedure, graph building approach, what graph edges encode, the controller used, and the graph maintenance strategy. We summarize these differences in Table I. We shall show that our design choices lead to superior performance when deployed in various simulated environments, and also demonstrate strong system performance in the real-world. </p>
<p>III. PROPOSED METHOD</p>
<p>Our work focuses on navigation tasks where the goal is specified by a target RGB-D image. Following the framework in Fig. 2, during graph building, we first execute a trajectory collection phase to obtain RGB-D images T = {o 1 , ..., o N }. We then use T to build a graph G = (V, E), where vertices V are images and directed edges E represent traversability.</p>
<p>During navigation, we present the agent with a goal image o g . The agent first localizes itself on the graph based on its current observation o a , plans a path to o g , picks a subgoal observation o sg , and moves towards it using its controller. The agent then relocalizes itself on the graph using its latest observation, and updates the graph based on its experience. These processes are repeated until the agent reaches o g .</p>
<p>The rest of this section discusses our main contributions, which are illustrated in Fig. 3. First, we present a simple yet versatile model that is the crux of our navigation system, be it for graph building, path execution, or graph maintenance. We then discuss our proposed sampling-based graph building algorithm that produces sparser graphs compared to baselines, and how to perform navigation with the proposed model. Finally, we present lifelong graph maintenance strategies that lead to improved navigation performance as our agent executes more queries in a target environment.</p>
<p>A. Reachability and Waypoint Prediction Model</p>
<p>Our goal is to design a model that we can use in most of the navigation aspects. We train a convolutional neural network f (o i , o j ) = [r,dx,dy,dθ] that takes two RGB-D images (o i , o j ) and jointly estimates reachability r ∈ {0, 1} from one image to another, and their relative transformation represented as a waypoint w = [dx, dy, dθ] ∈ R 2 × (−π, π]. To simplify the pose estimation problem, the waypoint only contributes to the training loss for reachable data points.</p>
<p>This model is used in a number of the components of our system. First, we use our model for graph building by using the reachability and pose estimates to determine the node connectivity and edge weights, respectively. We also use our model to perform localization and graph maintenance. Furthermore, we use a position-based feedback controller to navigate to waypoints predicted by our model. We train our model with full supervision in simulation on a broad range of simulated scenes. Additionally, we can later fine-tune our model using only the trajectory data acquired from the environment where the agent is deployed. As a result, we can use our model in the real-world environment without needing to tediously collect and manually label a large amount of real-world data. We discuss how we create both simulated and fine-tuning datasets in Section III-B.</p>
<p>We train the proposed model by minimizing the binary cross-entropy for reachability and regression loss for the relative waypoint. Concretely, the loss functions are
L r (r,r) = −(r log(r) + (1 − r) log(1 −r)), L p (dx, dy,dx,dy) = ||[dx, dy] − [dx,dy]|| 2 , L θ (dθ,dθ) = | sin(dθ) − sin(dθ)| + | cos(dθ) − cos(dθ)|, L total (r, dx, dy, dθ,r,dx,dy,dθ) = L r (r,r) +r αL p (dx, dy,dx,dy) + βL θ (dθ,dθ) ,
(1) where L r (r,r) is the reachability loss, L p (dx, dy,dx,dy) is the position loss, and L θ (dθ,dθ) is the rotation loss. Variables r, dx, dy, d θ are the ground truth labels for the reachability and the relative waypoint predictions, whereas α and β are hyperparameters to weigh the loss terms.</p>
<p>B. Automated Dataset Creation</p>
<p>We aim to create a diverse dataset such that our model can generalize well to real-world environments without collecting a large real-world dataset. We thus create a dataset by sampling image pairs from various simulated environments.</p>
<p>In simulation, the waypoint label can be computed easily since the absolute pose of each observation is known. For reachability between two RGB-D observations, similar to Meng et al. [7], we define node-to-node reachability to be controller-dependent. Nevertheless, instead of rolling out a controller to determine reachability, we assume a simple control strategy based on motion primitives (i.e., Dubins curves), which allows us to compute reachability analytically.</p>
<p>We determine the reachability label based on visual overlap and spatial distance between two observations. Fig. 4, illustrates various reachable and non-reachable situations during data collection in simulation. Specifically, two observations are labeled as reachable if:</p>
<p>1) The visual overlap ratio between the two images, l, is larger than L min , computed based on depth data; 2) The ratio of the shortest feasible path length over Euclidean distance between the poses, r d , is smaller than R max , to filter out obstacle-laden paths; 3) The target pose must be visible in the initial image, so that our model can visually determine reachability;  Fig. 3(a) depicts the proposed model, which takes source and target RGB-D images and outputs a reachability scorer and a waypointŵ = [dx,dy,dθ]. As shown in Fig. 3(b), we first train our model in simulation by collecting RGB-D image pairs from different environments. Later, we fine-tune our model in a new environment using only RGB-D images and their corresponding odometry data from a collected trajectory. Our sampling-based graph building method is depicted in Fig. 3(c), where we only select a portion of trajectory images to build the graph. Fig. 3(d) illustrates one of the proposed graph maintenance methods that updates the graph based on the success of an agent in traversing an edge. If the agent fails, the edge connectivity is weakened, else, its connectivity is strengthened and its weight is updated. Fig. 3(e) illustrates the second graph maintenance method that expands the graph by sampling from the remaining trajectory data T to enable planning when the agent is unable to find a path.</p>
<p>4) The Euclidean distance to the target must be less than E max , and the relative yaw must be less than Θ max . During training, we define o j to be reachable only if it is in front of o i . Yet, when navigating, the agent can move from o j to o i by following the predicted waypoint w in reverse. Because of how we define reachability, we can sample pairs of observations independently from various environments. Thus, our dataset creation in simulation follows the common independently and identically distributed assumption when training a machine learning model. This is in contrast to SPTM and ViNG where each datapoint is sampled from sequential image trajectories that are obtained from an agent operating in an environment following a random policy.</p>
<p>S</p>
<p>A key feature of our method is the ability to fine-tune the proposed model in any target domain, by using the same trajectory data T that we use to build the graph. Although SPTM and ViNG can also be trained on target-domain trajectories, our model does not need to be trained on a large real-world dataset, as it has already been trained within various simulated environments. In order for fine-tuning to be practical in the real-world, we only assume that the collected trajectories must have associated pose odometry to substitute for groundtruth pose data. Thankfully, odometry is readily available from commodity sensors such as inertial measurement units or wheel encoders.</p>
<p>Since visual overlap and shortest feasible path length are no longer accessible during fine-tuning, as a proxy criterion to determine reachability, we take an observation pair (o i , o j ) ∈ T where j &gt; i and check if they are separated by at most H time steps during trajectory collection. While the use of odometry as a supervisory signal for pose estimation can be noisy, the long-term pose drift should be minimal since reachable waypoints must be temporally close.</p>
<p>C. Sampling-based Graph Building</p>
<p>A dense graph is inefficient to search over, and is also likely to exhibit spurious edges, which is a common cause of failure in topological navigation. Our goal is to build a graph with a minimum number of nodes and edges without sacrificing navigation performance. Thus, instead of using all images in T , we build our graph incrementally via sampling.</p>
<p>Algorithm 1 describes the proposed graph building process. We initialize the graph as a randomly drawn node o ∈ T . We also initialize a copy of the trajectory data T = T \ o to</p>
<p>Algorithm 1 Graph Building</p>
<p>Input: Trajectory data T Init.:
V = {o ∈ T }, E = ∅, u = True, T = T \ o while u == True do u = False for o r ∈ shuffled(T ) do if isMergeable(o r , V ) then T = T \ o r else c = False for all o j ∈ V do if isConnectable(o r , o j ) then V, E = V ∪ o r , E ∪ (o r , o j ) c = True end if end for if c then u = True T = T \ o r end if end if end for end while Return: (V , E), T
keep track of nodes that are not yet added to the graph. In each iteration, we sample a node o r ∈ T (or equivalently, sampling from shuffled T ), check if it can be merged with or connected to existing graph vertices, and if so, remove it from T . If o r can be connected with any of the existing nodes o j ∈ V , we weigh the edge with a distance function based on the relative pose transformation between the pair as predicted by the model f . Concretely, we define the distance to a waypoint w [16] as
d(w) = || log T (w)|| F ,(2)
where T (·) converts a waypoint into its matrix representation in SE(2) b , and || · || F computes the Frobenius norm. This procedure continues until no more nodes can be added.</p>
<p>To build a sparse yet reliable graph, we would like to connect nodes that are close together, but not the ones that are too close. To this end, we introduce two operators: isMergeable and isConnectable. First, isMergeable assesses whether a node is excessively close to existing nodes and thus can be thrown away for being redundant. Second, isConnectable checks if a node is sufficiently close to another node such that a local controller can successfully execute the edge directly. These two distance thresholds are controlled by empirically-tuned hyperparameters D m and D c . Due to the proposed node merging mechanism, our graph building method results in a sparser graph compared to other methods.
b A matrix in the form of R t 0 1×2 1
, where R ∈ R 2×2 denotes the rotation matrix, and t ∈ R 2 denotes the translation vector.</p>
<p>D. Navigation</p>
<p>Here, we describe how we can execute a navigation query with our model f and the graph G. We first localize the agent on the graph based on its current observation o a . Concretely, we use f to compare pairwise distances between o a and all nodes in the graph, and identify the closest vertex where the distance is below D . To save computational cost, we first attempt to localize locally by considering only directly adjacent vertices from nodes within the last planned path, and then reverting to global localization if this fails.</p>
<p>For planning, we use Dijkstra's algorithm [17] to find a path from where o a is localized to a given goal node o g ∈ V , and select the first node in the path as subgoal o sg . We then predict the waypoint from o a to o sg , and use a position-based feedback controller to reach o sg . At the end of controller execution, we take the agent's latest observation to relocalize the agent, and perform the proposed graph maintenance to refine the graph, as will be described in Section III-E. These are then repeated until the agent arrives at o g .</p>
<p>E. Lifelong Graph Maintenance</p>
<p>We propose two types of continuous graph refinements to aid navigation performance. The first is a method to correct graph edges based on the success of an agent in traversing an edge. This results in the removal of spurious edges and enhanced connectivity of traversable edges. Second, we add new nodes to the graph either when observations are novel or when we cannot find a path to a goal.</p>
<p>We define two properties associated with each edge between physical locations i and j that are revised during graph maintenance: an edge's true connectivity after the t-th update modeled as r t ij ∼ Bernoulli(p t ij ), and an edge's distance weight modeled as d t ij ∼ N (µ t ij , (σ t ij ) 2 ). These are initialized respectively as p 0
ij =r 0 ij , µ 0 ij = d(ŵ 0 ij ), and (σ 0 ij ) 2 = σ 2 , where (r 0 ij ,ŵ 0 ij ) = f (o i , o j )
are the predictions of our model during graph building, and σ 2 is derived empirically from the variance of our model's distance predictions across a validation dataset. We further define the probability of successful traversal through an edge as p(s), where the conditional likelihood of the edge's existence p(s|r) is also empirically determined. Fig. 3(d) depicts how we update these edge properties after each traversal attempt. Given the agent's observation o a that is localized to o i on the graph, a target node o j , the agent's latest observation after edge traversal o d , we determine success of traversal via isConnectable(o d , o j ). We then update the edge's connectivity using discrete Bayes update:
p(r t+1 ij |s) = p(s|r t ij )p(r t ij ) p(s) .(3)
When the agent fails to reach o j , we prune the edge when p(r t+1 ij |s) &lt; R p . Upon a successful traversal, we also use the predicted distance d(ŵ aj ) between o a and o j to compute the weight posterior with Gaussian filter:
µ t+1 ij = σ 2 (σ t ij ) 2 + σ 2 µ t ij + (σ t ij ) 2 (σ t ij ) 2 + σ 2 d(ŵ aj ), (σ t+1 ij ) 2 = 1 (σ t ij ) 2 + 1 σ 2 −1 .(4)
In this way we can correct for erroneous edges based on what the agent actually experiences during navigation.</p>
<p>To expand the graph, if an observation cannot be localized, we consider it as novel and add it to the graph. Separately, Fig. 3(e) depicts how we expand our graph when a path to a goal is not found during navigation. In this situation, we iteratively sample new nodes from the remaining trajectory data T until a path is found, and store them into a candidate setṼ . Denoting the nodes within the path as V p , we then add only the new nodes that are along the found pathṼ ∩V p to the graph permanently and remove them from T , while returning other nodesṼ \ (Ṽ ∩ V p ) back into T . When connecting a novel node to existing vertices, we loosen the graph building criteria by increasing D c and decreasing D m , especially to accommodate adding locations around sharp turns.</p>
<p>IV. EXPERIMENTAL RESULTS</p>
<p>A. Setup</p>
<p>We use the Gibson environment [18] both to generate training datasets and to evaluate navigation performance in simulation. We compare our method against SPTM [6] and ViNG [8], which adopt similar navigation pipelines, and can also be fairly assessed after training or fine-tuning on data from each target domain. Moreover, we perform our experiments in realistic cluttered indoor environments. We want to highlight the inherent difficulty arising from navigating in cluttered indoor environments, where the agent is required to continuously avoid colliding with obstacles and navigate through small openings (e.g., doors). We collect 288,000 data points from 10 interactive environments from iGibson [19] to initially train our model. In contrast, we collect 500,000 data points each for SPTM and ViNG, as they use a random exploration policy and thus need a larger size dataset to ensure sufficient exploration and visual diversity. The width and height of each RGB-D observation are 96 × 72. We use the LoCoBot [20] in both simulated and real-world experiments, and we teleoperate it in each test map to collect trajectories for building the graph. c</p>
<p>B. Evaluation Settings</p>
<p>We evaluate navigation performance to reflect real-world usage: the agent should be able to navigate between any image pairs from the graph, and should not merely repeat path sequences matching the collected trajectories. We pick 10 goal images from different locations that covers major locations in each map, and generate random test episodes. In simulation, we consider navigation as successful if the position and yaw errors from the goal pose are less than 0.72m and 0.4 radians. We consider an episode as a failure if the agent c Additional implementation details, e.g., visual overlap computation, CNN architecture, hyperparameters, environments, etc., can be found in our project page: https://montrealrobotics.ca/ltvn/ collides for more than 20 times, and if it requires more than K simulation steps. For real-world experiments, an episode is deemed successful if the robot's final observation has sufficient visual overlap with the goal image. We consider an episode as a failure if the robot collides with the environment, or if it gets stuck for more than 10 minutes.</p>
<p>During operations, if the agent is unable to localize itself or find a path, we rotate it in-place and take new observations until it recovers. In addition, to ensure fair comparison, instead of training an inverse dynamics model for SPTM, we equip SPTM agent with a pose estimator, and use the same positionbased feedback controller as ours and ViNG.</p>
<p>C. Navigation Performance in Simulation</p>
<p>In this section, we compare the navigation performance of our method with SPTM and ViNG in simulated environments both before and after fine-tuning. In addition to navigation performance, we also compare the sparsity of the graphs built with each method. Note that, in this set of experiments, we do not perform graph maintenance with our method, which is evaluated separately in Section IV-D.</p>
<p>We evaluate the navigation performance on four unseen test environments: Barahona (57m 2 ), Bellemeade (70m 2 ), Akiak (124m 2 ), and Caruthers (129m 2 ). For trajectory collection, we teleoperate the agent to explore roughly 3 − 4 loops around each map, resulting in 985, 1, 685, 1, 609, and 2, 243 images for Barahona, Bellemeade, Akiak, and Caruthers, respectively. We pick 10 goal images spanning major locations in each map and generate 500 random test episodes. Given diverse map sizes, we set K = 1, 000 for Barahona and Bellemeade, and K = 2, 000 for Akiak and Caruthers. Since our graph building method is stochastic, we evaluate our method with three random seeds per environment.</p>
<p>As seen in Fig. 5, our method consistently yields higher navigation success rates in all test environments when the model is fine-tuned. We can also observe that the performance gain of our model after fine-tuning is generally higher than others. Additionally, our graphs have significantly fewer number of nodes and edges, which keeps planning costs practical when scaling to large environments. Therefore, compared to the baselines that use entire trajectory datasets to build graphs, our sampling-based graph building method produces demonstrably superior performance and efficiency. Fig. 6 qualitatively compares sample graphs built using different methods. We see that our graph has the fewest vertices, yet still maintains proper map coverage. Visually, our graph also has few false positive edges through walls, and we shall later demonstrate how our graph maintenance can further prune these in Section IV-D.</p>
<p>D. Lifelong Navigation</p>
<p>We now evaluate the proposed graph maintenance methods to see how navigation performance is affected as the agent executes more queries. We start these experiments using graphs built with our fine-tuned models. The agent then executes randomly sampled navigation tasks while performing  continuous graph maintenance. After every 100 queries, we reevaluate the navigation performance on the same static set of test episodes used in Section IV-C. Same as before, we repeat the experiment with three random seeds per environment. As seen in Fig. 7, the success rate initially jumps and continues to generally improve as we perform more queries, while the number of nodes and edges in the graph do not substantially grow. We also see an initial decrease in the number of edges, suggesting that our graph maintenance pruned spurious edges causing initial navigation failures, then later added useful new nodes for better navigation. Qualitatively, we can also see fewer spurious edges when comparing sample graphs before and after updates in Fig. 8.</p>
<p>We observe that sometimes the success rate decreased after a batch of graph maintenance. This is likely caused by new spurious edges when adding new graph nodes near each 100th query, before we re-evaluate navigation performance. Nevertheless, such spurious edges are pruned in later updates, thus leading to increasing performance trends over time.</p>
<p>E. Real-World Experiments</p>
<p>We demonstrate the performance of our method in two realworld environments: a studio apartment and a medium-sized university laboratory. After teleoperating the robot for 3 − 4 loops around each space to collect trajectory data, we pick 5 goal images, and generate 20 test episodes. We use the iLQR [21] implementation from the PyRobot [22] library for our controller. In Table II, we report navigation success rates before and after graph maintenance with 30 queries. These results suggest that our model performs well without needing large amounts of real-world data, especially when combined with our proposed lifelong graph maintenance. Our graph maintenance enhances the navigation performance with more than 3× increase in success rate in both environments. Fig. 9 depicts a successful navigation task across multiple twists and turns within the lab environment.</p>
<p>V. CONCLUSIONS</p>
<p>We proposed a simple model that can be used in many topological navigation aspects. With this model, we proposed a new image-based topological graph construction method via sampling, which not only produces sparser graphs compared to baselines, but also higher navigation performance. We also introduced a lifelong graph maintenance approach by updating the graph based on what our agent experienced during navigation. We showed that these updates add useful new nodes and remove spurious edges, thus increasing lifelong navigation performance. We also demonstrated a training regime using purely simulated data, enhanced by fine-tuning on a much smaller dataset from a given target domain, which resulted in strong real-world navigation performance. Currently, our model fine-tuning method relies on piloted trajectories with odometry data. It would be more practical if we can fine-tune our model on an unordered set of images, or images taken from different sources such as a mobile phone. Furthermore, we also assume a static world; extending to nonstationary environments remains a fruitful challenge. Comparison between the initially built graph and updated graphs after executing 100, 400, and 700 navigation queries in Akiak. We can see a notable reduction in spurious edges, especially ones that are across walls, which improved navigation performance in our experiments. </p>
<p>Fig. 1 .
1Fig. 1. Sample plans produced with our method to navigate from a start to a goal image, before and after graph maintenance. The blue dots indicate nodes within the planned path. The plan in Fig. 1(a) led to navigation failure since nodes #3 and #4 are erroneously connected. Fig. 1(b) showcases the refined plan after graph maintenance, which led to successful navigation.</p>
<p>Fig. 3 .
3Illustrations of our main contributions.</p>
<p>Fig. 4 .
4Illustration of reachable and non-reachable situations for a pair of source (S) and target (T) nodes.</p>
<p>Fig. 7 .
7Changes in success rate, number of nodes, and number of edges as the agent performs more queries and updates its graph in each test environment.(a) No update (b) 100 queries (c) 400 queries (d) 700 queriesFig. 8.</p>
<p>Fig. 9 .
9Sequence of navigation images, from top-left to bottom-right, as seen by the robot in the real-world lab environment. supported by the National Science and Engineering Research Council of Canada under the Discovery Grant Program.</p>
<p>Manuscript received: February, 24, 2022; Revised May, 21, 2022; Accepted June, 17, 2022. This paper was recommended for publication by Editor Eric Marchand upon evaluation of the Associate Editor and Reviewers' comments. 1 Rey Reza Wiyatno and Liam Paull are with Montréal Robotics and Embodied AI Lab (REAL) and DIRO at the University of Montréal, QC H3T 1J4, Canada, and Mila, QC H2S 3H1, Canada rey.wiyatno@umontreal.ca, paulll@iro.umontreal.ca 2 Anqi Xu conducted this work with support from his past affiliation with Element AI, H2S 3G9, Canada anqi.xu@mail.mcgill.ca Digital Object Identifier (DOI): see top of this page. a Project page: https://montrealrobotics.ca/ltvn/</p>
<p>TABLE I COMPARISON
IOF VARIOUS LEARNING-BASED TOPOLOGICAL NAVIGATION METHODS FOR IMAGE-GOAL NAVIGATION TASKS.Controller 
Node selection 
Edge weight 
Path planner 
Graph maintenance 
Model fine-tuning 
SPTM [6] 
Inverse dynamics 
All nodes 
Temporal, unweighted 
Graph search 
None 
Self-supervised 
HTM [15] 
Inverse dynamics 
All nodes 
Contrastive loss 
Graph search 
None 
None 
Meng et al. [7] 
Potential-based 
Incrementally selected 
Reachability score 
Graph search 
None 
None 
LEAP [12] 
RL 
Optimization-based 
Value function 
Optimization-based 
None 
None 
SoRB [13] 
RL 
All nodes 
Value function 
Graph search 
None 
None 
SGM [14] 
RL 
Incrementally selected 
Value function 
Graph search 
Edge pruning 
None 
ViNG [8] 
Position-based 
All nodes 
Temporal 
Graph search 
None 
Self-supervised 
Ours 
Position-based 
Sampling-based 
Pose-based distance 
Graph search 
Edge update, node addition 
Self-supervised </p>
<p>Fig. 5.Comparison of navigation success rates and graph sizes among topological visual navigation methods in various test environments. For visual results of our experiments, including real-world deployment videos, see the video attachment or our project page: https://montrealrobotics.ca/ltvn/.Fig. 6. Graphs built after model fine-tuning in Bellemeade. Even without applying graph maintenance, our method naturally produces a sparser graph.1.00 </p>
<p>1.25 </p>
<p>1.50 </p>
<h1>edges</h1>
<p>1e5 </p>
<p>Barahona Bellemeade 
Akiak 
Caruthers </p>
<p>SPTM 
SPTM-finetuned 
ViNG 
ViNG-finetuned 
Ours 
Ours-finetuned </p>
<p>(a) SPTM 
(b) ViNG 
(c) Ours </p>
<p>TABLE II NAVIGATION
IISUCCESS RATE BEFORE AND AFTER GRAPH MAINTENANCE IN REAL-WORLD ENVIRONMENTS.Before 
After 
Apartment 
4/20 
13/20 
University Laboratory 
4/20 
14/20 </p>
<p>ACKNOWLEDGMENTSThe authors would like to thank Mitacs and Element AI (a ServiceNow company) for the support in this project. R. R. W. thanks IVADO for the support, as well as K. M. Jatavallabhula for useful discussions and feedback. L. P. is supported by the Canada CIFAR AI Chairs Program. The work was also
Simultaneous map building and localization for an autonomous mobile robot. J Leonard, H Durrant-Whyte, Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91. IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '913J. Leonard and H. Durrant-Whyte, "Simultaneous map building and localization for an autonomous mobile robot," in Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91, 1991, pp. 1442-1447 vol.3.</p>
<p>Target-driven visual navigation in indoor scenes using deep reinforcement learning. Y Zhu, R Mottaghi, E Kolve, J J Lim, A Gupta, L Fei-Fei, A Farhadi, 2017 IEEE international conference on robotics and automation (ICRA). IEEEY. Zhu, R. Mottaghi, E. Kolve, J. J. Lim, A. Gupta, L. Fei-Fei, and A. Farhadi, "Target-driven visual navigation in indoor scenes using deep reinforcement learning," in 2017 IEEE international conference on robotics and automation (ICRA). IEEE, 2017, pp. 3357-3364.</p>
<p>Navigation and mapping in large scale space. B J Kuipers, T S Levitt, AI Magazine. 9225B. J. Kuipers and T. S. Levitt, "Navigation and mapping in large scale space," AI Magazine, vol. 9, no. 2, p. 25, Jun. 1988.</p>
<p>Probabilistic roadmaps for path planning in high-dimensional configuration spaces. L Kavraki, P Svestka, J.-C Latombe, M Overmars, IEEE Transactions on Robotics and Automation. 124L. Kavraki, P. Svestka, J.-C. Latombe, and M. Overmars, "Probabilistic roadmaps for path planning in high-dimensional configuration spaces," IEEE Transactions on Robotics and Automation, vol. 12, no. 4, pp. 566- 580, 1996.</p>
<p>Rapidly-exploring random trees: A new tool for path planning. S M Lavalle, S. M. LaValle et al., "Rapidly-exploring random trees: A new tool for path planning," 1998.</p>
<p>Semi-parametric topological memory for navigation. N Savinov, A Dosovitskiy, V Koltun, International Conference on Learning Representations. N. Savinov, A. Dosovitskiy, and V. Koltun, "Semi-parametric topolog- ical memory for navigation," in International Conference on Learning Representations, 2018.</p>
<p>Scaling local control to large-scale topological navigation. X Meng, N Ratliff, Y Xiang, D Fox, 2020 IEEE International Conference on Robotics and Automation (ICRA). IEEEX. Meng, N. Ratliff, Y. Xiang, and D. Fox, "Scaling local control to large-scale topological navigation," in 2020 IEEE International Confer- ence on Robotics and Automation (ICRA). IEEE, 2020, pp. 672-678.</p>
<p>Ving: Learning open-world navigation with visual goals. D Shah, B Eysenbach, G Kahn, N Rhinehart, S Levine, 2021 IEEE International Conference on Robotics and Automation (ICRA). IEEED. Shah, B. Eysenbach, G. Kahn, N. Rhinehart, and S. Levine, "Ving: Learning open-world navigation with visual goals," in 2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2021, pp. 13 215-13 222.</p>
<p>Visual navigation with multiple goals based on deep reinforcement learning. Z Rao, Y Wu, Z Yang, W Zhang, S Lu, W Lu, Z Zha, IEEE Transactions on Neural Networks and Learning Systems. 3212Z. Rao, Y. Wu, Z. Yang, W. Zhang, S. Lu, W. Lu, and Z. Zha, "Visual navigation with multiple goals based on deep reinforcement learning," IEEE Transactions on Neural Networks and Learning Systems, vol. 32, no. 12, pp. 5445-5455, 2021.</p>
<p>Domain randomization for transferring deep neural networks from simulation to the real world. J Tobin, R Fong, A Ray, J Schneider, W Zaremba, P Abbeel, 2017 IEEE/RSJ international conference on intelligent robots and systems (IROS). IEEEJ. Tobin, R. Fong, A. Ray, J. Schneider, W. Zaremba, and P. Abbeel, "Domain randomization for transferring deep neural networks from simulation to the real world," in 2017 IEEE/RSJ international conference on intelligent robots and systems (IROS). IEEE, 2017, pp. 23-30.</p>
<p>Bayesian relational memory for semantic visual navigation. Y Wu, Y Wu, A Tamar, S Russell, G Gkioxari, Y Tian, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionY. Wu, Y. Wu, A. Tamar, S. Russell, G. Gkioxari, and Y. Tian, "Bayesian relational memory for semantic visual navigation," in Proceedings of the IEEE International Conference on Computer Vision, 2019, pp. 2769- 2779.</p>
<p>Planning with goalconditioned policies. S Nasiriany, V Pong, S Lin, S Levine, Advances in Neural Information Processing Systems. Curran Associates, Inc32S. Nasiriany, V. Pong, S. Lin, and S. Levine, "Planning with goal- conditioned policies," in Advances in Neural Information Processing Systems, vol. 32. Curran Associates, Inc., 2019.</p>
<p>Search on the replay buffer: Bridging planning and reinforcement learning. B Eysenbach, R R Salakhutdinov, S Levine, Advances in Neural Information Processing Systems. Curran Associates, Inc32B. Eysenbach, R. R. Salakhutdinov, and S. Levine, "Search on the replay buffer: Bridging planning and reinforcement learning," in Advances in Neural Information Processing Systems, vol. 32. Curran Associates, Inc., 2019.</p>
<p>Sparse graphical memory for robust planning. S Emmons, A Jain, M Laskin, T Kurutach, P Abbeel, D Pathak, Advances in Neural Information Processing Systems. Curran Associates, Inc33S. Emmons, A. Jain, M. Laskin, T. Kurutach, P. Abbeel, and D. Pathak, "Sparse graphical memory for robust planning," in Advances in Neural Information Processing Systems, vol. 33. Curran Associates, Inc., 2020, pp. 5251-5262.</p>
<p>Hallucinative topological memory for zero-shot visual planning. K Liu, T Kurutach, C Tung, P Abbeel, A Tamar, Proceedings of the 37th International Conference on Machine Learning, ser. Proceedings of Machine Learning Research. the 37th International Conference on Machine Learning, ser. Machine Learning ResearchPMLR119K. Liu, T. Kurutach, C. Tung, P. Abbeel, and A. Tamar, "Hallucinative topological memory for zero-shot visual planning," in Proceedings of the 37th International Conference on Machine Learning, ser. Proceedings of Machine Learning Research, vol. 119. PMLR, 13-18 Jul 2020, pp. 6259-6270.</p>
<p>T D Barfoot, State Estimation for Robotics. Cambridge University Press1st ed. USAT. D. Barfoot, State Estimation for Robotics, 1st ed. USA: Cambridge University Press, 2017.</p>
<p>A note on two problems in connexion with graphs. E W Dijkstra, Numer. Math. 11E. W. Dijkstra, "A note on two problems in connexion with graphs," Numer. Math., vol. 1, no. 1, p. 269-271, Dec. 1959.</p>
<p>Gibson env: real-world perception for embodied agents. F Xia, A R Zamir, Z.-Y He, A Sax, J Malik, S Savarese, Computer Vision and Pattern Recognition (CVPR). IEEEF. Xia, A. R. Zamir, Z.-Y. He, A. Sax, J. Malik, and S. Savarese, "Gibson env: real-world perception for embodied agents," in Computer Vision and Pattern Recognition (CVPR), 2018 IEEE Conference on. IEEE, 2018.</p>
<p>iGibson, a simulation environment for interactive tasks in large realistic scenes. B Shen, F Xia, C Li, R Martın-Martın, L Fan, G Wang, S Buch, C D&apos;arpino, S Srivastava, L P Tchapmi, K Vainio, L Fei-Fei, S Savarese, arXiv preprintB. Shen, F. Xia, C. Li, R. Martın-Martın, L. Fan, G. Wang, S. Buch, C. D'Arpino, S. Srivastava, L. P. Tchapmi, K. Vainio, L. Fei-Fei, and S. Savarese, "iGibson, a simulation environment for interactive tasks in large realistic scenes," arXiv preprint, 2020.</p>
<p>Locobot -an open source low cost robot. "Locobot -an open source low cost robot," http://www.locobot.org/, accessed: 2022-02-24.</p>
<p>Iterative linear quadratic regulator design for nonlinear biological movement systems. W Li, E Todorov, ICINCO 2004, Proceedings of the First International Conference on Informatics in Control, Automation and Robotics. Setúbal, PortugalINSTICC PressW. Li and E. Todorov, "Iterative linear quadratic regulator design for nonlinear biological movement systems," in ICINCO 2004, Proceedings of the First International Conference on Informatics in Control, Automa- tion and Robotics, Setúbal, Portugal, August 25-28, 2004. INSTICC Press, 2004, pp. 222-229.</p>
<p>Pyrobot: An open-source robotics framework for research and benchmarking. A Murali, T Chen, K V Alwala, D Gandhi, L Pinto, S Gupta, A Gupta, arXiv:1906.08236arXiv preprintA. Murali, T. Chen, K. V. Alwala, D. Gandhi, L. Pinto, S. Gupta, and A. Gupta, "Pyrobot: An open-source robotics framework for research and benchmarking," arXiv preprint arXiv:1906.08236, 2019.</p>            </div>
        </div>

    </div>
</body>
</html>