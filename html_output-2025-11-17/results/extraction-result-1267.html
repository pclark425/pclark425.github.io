<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1267 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1267</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1267</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-28.html">extraction-schema-28</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <p><strong>Paper ID:</strong> paper-988874</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1602.02261v2.pdf" target="_blank">End-to-End Goal-Driven Web Navigation</a></p>
                <p><strong>Paper Abstract:</strong> We propose a goal-driven web navigation as a benchmark task for evaluating an agent with abilities to understand natural language and plan on partially observed environments. In this challenging task, an agent navigates through a website, which is represented as a graph consisting of web pages as nodes and hyperlinks as directed edges, to find a web page in which a query appears. The agent is required to have sophisticated high-level reasoning based on natural languages and efficient sequential decision-making capability to succeed. We release a software tool, called WebNav, that automatically transforms a website into this goal-driven web navigation task, and as an example, we make WikiNav, a dataset constructed from the English Wikipedia. We extensively evaluate different variants of neural net based artificial agents on WikiNav and observe that the proposed goal-driven web navigation well reflects the advances in models, making it a suitable benchmark for evaluating future progress. Furthermore, we extend the WikiNav with question-answer pairs from Jeopardy! and test the proposed agent based on recurrent neural networks against strong inverted index based search engines. The artificial agents trained on WikiNav outperforms the engined based approaches, demonstrating the capability of the proposed goal-driven navigation as a good proxy for measuring the progress in real-world tasks such as focused crawling and question-answering.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1267.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1267.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>WebNav</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>WebNav (website -> goal-driven navigation compiler)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A software tool that converts an arbitrary website into a goal-driven web navigation task by constructing a directed graph (pages as nodes, hyperlinks as directed edges), selecting query sentences from pages, and producing train/validation/test splits.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Website graphs (compiled by WebNav)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>General information-network domain: each website is represented as a directed graph where nodes are web pages with natural-language text and directed edges are intra-site hyperlinks; the agent observes only current page and immediate neighbors' text (partial observability).</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Directed, sparse hyperlink graphs; connectivity varies by site and page — state-dependent action space (available outgoing actions equals outgoing hyperlinks).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Depends on site (example used: English Wikipedia >5 million pages). WebNav produces dataset partitions and example tasks (e.g., WikiNav variants) of varying sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Binary reward for correct stop (per-trial), average reward (fraction correct), steps/hops constrained by Nh; for retrieval-style tasks: Recall@K.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>If unconstrained, breadth-first search (graph-search) guarantees finding a target; under WebNav constraints, policies that incorporate local ranking + memory (history-conditioned, recurrent policies) are reported to perform best on hard instances.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Paper emphasizes that the search space size grows approximately exponentially with allowed maximum hops (Nh); therefore larger effective diameter (operationalized by higher Nh) reduces performance and requires policies with memory/long-term planning. Also, limiting outgoing edges considered per node (Nn) prevents degenerate global-search policies like BFS and forces local decision-making.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>The authors vary task structural parameters (Nh and Nq) and report: increasing Nh (allowing farther targets) increases difficulty and lowers agent performance; increasing query length Nq (more information in the query) decreases difficulty and raises performance. The constraint on maximum outgoing edges Nn prevents exhaustive search.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Degenerate global-search (BFS) is possible but disallowed by Nn; recurrent/memory-based agents and attention mechanisms are better for long-range navigation (higher Nh). Beam search (with width limited by Nn) is used at inference to explore multiple promising paths.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Goal-Driven Web Navigation', 'publication_date_yy_mm': '2016-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1267.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1267.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>WikiNav</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>WikiNav (WebNav applied to English Wikipedia)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A benchmark dataset built by WebNav from the September 2015 English Wikipedia; defines goal-driven navigation tasks WikiNav-Nh-Nq where Nh (max hops) and Nq (query length in sentences) control difficulty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>WikiNav (English Wikipedia graph)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Encyclopedic information network: nodes are Wikipedia articles (cleaned text) and directed edges are intra-wiki hyperlinks; agent must reach a page containing a multi-sentence query drawn from a (target) page, starting from a fixed start node.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Directed, large-scale, sparse hyperlink network. Action (outgoing link) set is state-dependent and can vary widely by node (variable out-degree).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Full English Wikipedia dump used: >5 million pages. Dataset splits (examples): WikiNav-4-* train 6.0k / valid 1k / test 1k; WikiNav-8-* train 1M / valid 20k / test 20k; WikiNav-16-* train 12M / valid 20k / test 20k. WikiNav-Jeopardy contains 133k QA pairs (train 113k / valid 10k / test 10k).</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>NeuAgent (NeuAgent-FF, NeuAgent-Rec)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Neural-network agent: content represented by pretrained CBOW word vectors averaged per document; query represented by BoW or attention-based dynamic representation; core f_core implemented as either feedforward tanh (NeuAgent-FF) or recurrent LSTM (NeuAgent-Rec); agent peeks at neighbor node content vectors when scoring outgoing edges; stop action modeled explicitly; trained supervised on example traces; inference via forward beam search (beam width <= Nn).</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Average reward (binary correct stop fraction) and constrained-hops notion (Nh). For retrieval-style extension: Recall@K.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Memory-based recurrent (history-conditioned) policies with attention on the query perform best for long-range tasks; greedy/local reactive policies suffice on very short tasks (small Nh).</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Higher Nh (allowing farther targets) increases the effective search space exponentially and degrades performance; shorter queries (lower Nq) reduce available information and similarly degrade performance, requiring better language understanding and planning; constraining Nn (max outgoing edges considered) prevents BFS and forces local selection quality.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Performance was compared across tasks with Nh in {4,8,16} and Nq in {1,2,4}: as Nh increases performance drops; as Nq increases performance improves. NeuAgent-Rec outperforms NeuAgent-FF for larger Nh, and deeper/larger recurrent models perform better for distant targets.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>History (RNN/LSTM) improves long-term planning (higher Nh). Attention-based query representations boost performance especially when queries are short (low Nq) and targets are distant. Beam search over multiple partial paths (width bounded by Nn) improves inference compared to greedy decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Goal-Driven Web Navigation', 'publication_date_yy_mm': '2016-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1267.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1267.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>WikiNav-Jeopardy</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>WikiNav-Jeopardy (Jeopardy! questions on WikiNav)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extension of WikiNav where queries are Jeopardy! questions and targets are Wikipedia article titles (answers); used to evaluate the NeuAgent against inverted-index search baselines using Recall@K.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>WikiNav-Jeopardy (Wikipedia graph with Jeopardy queries)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Same directed Wikipedia graph as WikiNav but with queries coming from Jeopardy! question-answer pairs whose answer is a Wikipedia article; dataset contains ~133k QA pairs filtered to article-title answers.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Directed, sparse hyperlink graph (Wikipedia); navigation is partially observed and agent only sees pages it visits plus immediate neighbors' content.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>133k QA pairs (after filtering); split: train 113k / valid 10k / test 10k. Average number of hops from start to target in these examples: 5.8 (std 1.2; min 2; max 10).</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>NeuAgent-Rec (pretrained and finetuned variants)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Large recurrent NeuAgent-Rec (8 layers of 2048 LSTM units) with attention-based query representation; trained either from scratch on WikiNav-Jeopardy or pretrained on WikiNav-16-4 then finetuned.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Recall@K (document recall among top-K returned nodes); beam search width set to K for NeuAgent; also uses average reward for other WikiNav tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>Pretrained NeuAgent-Rec (pretrained on WikiNav-16-4 then finetuned) achieved Recall@1 = 18.9%, Recall@4 = 23.6%, Recall@40 = 38.3%. Non-pretrained NeuAgent-Rec achieved Recall@1 = 13.9%, Recall@4 = 20.2%, Recall@40 = 33.2%.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Pretrained recurrent policy with attention and beam search (ranking + navigation hybrid) performs best for the QA-oriented navigation task.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Pretraining on a much larger graph (WikiNav-16-4) substantially improves ranking/navigation performance on WikiNav-Jeopardy, particularly when the candidate set is small (small K). Limited observability (agent only sees visited nodes) did not prevent the pretrained NeuAgent from outperforming inverted-index baselines on Recall@K.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Not directly varied across different graph topologies; main comparison was between training strategies (pretrained vs. trained-from-scratch) and vs search baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Pretraining on large navigation datasets improves the agent's ability to prioritize promising links and accurately rank target articles during constrained beam-search navigation; recurrent memory plus attention yields superior Recall@K performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Goal-Driven Web Navigation', 'publication_date_yy_mm': '2016-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1267.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1267.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NeuAgent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NeuAgent (Neural-network navigation agent: NeuAgent-FF and NeuAgent-Rec)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural-network agent family for goal-driven web navigation: two core variants — feedforward (NeuAgent-FF) and recurrent LSTM (NeuAgent-Rec) — using pretrained CBOW document vectors, optional attention over query words, peeking at neighbors' content when scoring outgoing actions, trained supervised on example traces and decoded with beam search.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>WikiNav / WikiNav-Jeopardy (website navigation tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Operates in partially-observed directed website graphs where at each step the agent reads the current page and observes textual content of immediate neighbors (peeking), then selects a hyperlink or the stop action.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Directed, sparse hyperlink topology; action space equals outgoing hyperlinks per node (variable out-degree).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Evaluated on WikiNav datasets derived from English Wikipedia (dataset sizes listed under WikiNav entry).</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>NeuAgent-FF (feedforward) and NeuAgent-Rec (recurrent LSTM)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Core network f_core combines current-node content vector and query vector to produce hidden state h_t; scores outgoing neighbors by similarity between neighbor content vectors and h_t; supports attention-based dynamic query representations; stop action modeled; trained with supervised cross-entropy on example traces; inference uses forward-only beam search capped at Nn.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Average binary reward (correct stop fraction) on WikiNav tasks; Recall@K on WikiNav-Jeopardy; number of hops up to Nh.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>See WikiNav-Jeopardy results: pretrained NeuAgent-Rec Recall@1 = 18.9%, Recall@4 = 23.6%, Recall@40 = 38.3%. On WikiNav classifications, reported trends (no single global numbers printed) show NeuAgent-Rec > NeuAgent-FF as Nh grows.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Recurrent LSTM-based policy with attention and beam search is reported as the best-performing architecture in the experiments, especially when targets are far (higher Nh) or queries are short (low Nq).</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>NeuAgent-Rec outperforms NeuAgent-FF for larger allowed-hop budgets (Nh), indicating history/memory is needed for traversing larger effective diameters; attention on the query yields gains when query information is limited; limiting Nn enforces local decision-making and prevents full-graph BFS.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Performance compared across task parameterizations (Nh,Nq): as Nh increases or Nq decreases, recurrent + attention architectures provide relatively larger gains; beam search helps under Nn constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Policies that condition on history (LSTM) are necessary for longer-range navigation; attention mechanisms shift focus across query words as the agent moves; supervised training on example traces plus pretraining on larger graph data improves exploration/ranking efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Goal-Driven Web Navigation', 'publication_date_yy_mm': '2016-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1267.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1267.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Wikispeedia</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Wikispeedia</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A previously proposed human navigation game on a small curated Wikipedia ("Wikipedia for Schools") where players navigate from a start article to a target article using hyperlinks; used in prior work to study human wayfinding and semantic distances.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Wikispeedia: An online game for inferring semantic distances between concepts</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Wikispeedia (small Wikipedia graph)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Small-scale directed Wikipedia graph (~4,000 articles as of 2008) used for human navigation studies; the target is given as an entire article rather than a short query.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Directed hyperlink graph on a small curated subset of Wikipedia; connectivity studied in prior work to infer semantic/graph distances between concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Approximately 4,000 articles (the "Wikipedia for Schools" corpus used in prior Wikispeedia work).</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Human navigators (studied) and algorithmic baselines in cited works</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Humans navigate using topical knowledge and heuristic link-following; prior work analyzed human paths to infer semantic distances.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Path length and success in reaching target (studied in prior works); specific metrics are external to this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Referenced as related work: Wikispeedia investigated how humans navigate information networks; this paper positions WikiNav as a generalization and more challenging benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Paper cites Wikispeedia to contrast target specification (full article in Wikispeedia vs short queries in WikiNav) and to motivate focus on algorithmic agents rather than human wayfinding.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Goal-Driven Web Navigation', 'publication_date_yy_mm': '2016-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1267.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1267.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MUDs (text-based games)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-User Dungeon (MUD) text-based games (prior RL/NLP work)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior text-based game environments where agents perceive state via textual descriptions and act with text commands; cited as less linguistically rich or smaller-vocabulary than WikiNav.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language understanding for textbased games using deep reinforcement learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>MUD/text-based-game environments (prior work)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Fantasy/interactive-text domains (MUDs) with relatively small vocabularies and scene-limited descriptions used in earlier language-and-planning research.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Varies by specific game; prior studies used smaller worlds (vocab sizes reported: ~1,340 to ~2,258 words) and simpler per-step descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Not specified here; prior cited MUD works used much smaller vocabularies and smaller state descriptions than Wikipedia-based WikiNav.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Paper contrasts these environments with WikiNav: MUDs typically lack the complex natural-language richness and large, variable action spaces of web graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>The paper notes that MUD experiments do not fully exercise natural language complexity and often have limited state descriptions, implying that policies required there differ from those needed on large web graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Goal-Driven Web Navigation', 'publication_date_yy_mm': '2016-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Wikispeedia: An online game for inferring semantic distances between concepts <em>(Rating: 2)</em></li>
                <li>Automatic versus human navigation in information networks <em>(Rating: 2)</em></li>
                <li>Human wayfinding in information networks <em>(Rating: 2)</em></li>
                <li>Language understanding for textbased games using deep reinforcement learning <em>(Rating: 2)</em></li>
                <li>Focused crawling: a new approach to topic-specific web resource discovery <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1267",
    "paper_id": "paper-988874",
    "extraction_schema_id": "extraction-schema-28",
    "extracted_data": [
        {
            "name_short": "WebNav",
            "name_full": "WebNav (website -&gt; goal-driven navigation compiler)",
            "brief_description": "A software tool that converts an arbitrary website into a goal-driven web navigation task by constructing a directed graph (pages as nodes, hyperlinks as directed edges), selecting query sentences from pages, and producing train/validation/test splits.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "Website graphs (compiled by WebNav)",
            "environment_description": "General information-network domain: each website is represented as a directed graph where nodes are web pages with natural-language text and directed edges are intra-site hyperlinks; the agent observes only current page and immediate neighbors' text (partial observability).",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Directed, sparse hyperlink graphs; connectivity varies by site and page — state-dependent action space (available outgoing actions equals outgoing hyperlinks).",
            "environment_size": "Depends on site (example used: English Wikipedia &gt;5 million pages). WebNav produces dataset partitions and example tasks (e.g., WikiNav variants) of varying sizes.",
            "agent_name": null,
            "agent_description": null,
            "exploration_efficiency_metric": "Binary reward for correct stop (per-trial), average reward (fraction correct), steps/hops constrained by Nh; for retrieval-style tasks: Recall@K.",
            "exploration_efficiency_value": null,
            "success_rate": null,
            "optimal_policy_type": "If unconstrained, breadth-first search (graph-search) guarantees finding a target; under WebNav constraints, policies that incorporate local ranking + memory (history-conditioned, recurrent policies) are reported to perform best on hard instances.",
            "topology_performance_relationship": "Paper emphasizes that the search space size grows approximately exponentially with allowed maximum hops (Nh); therefore larger effective diameter (operationalized by higher Nh) reduces performance and requires policies with memory/long-term planning. Also, limiting outgoing edges considered per node (Nn) prevents degenerate global-search policies like BFS and forces local decision-making.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "The authors vary task structural parameters (Nh and Nq) and report: increasing Nh (allowing farther targets) increases difficulty and lowers agent performance; increasing query length Nq (more information in the query) decreases difficulty and raises performance. The constraint on maximum outgoing edges Nn prevents exhaustive search.",
            "policy_structure_findings": "Degenerate global-search (BFS) is possible but disallowed by Nn; recurrent/memory-based agents and attention mechanisms are better for long-range navigation (higher Nh). Beam search (with width limited by Nn) is used at inference to explore multiple promising paths.",
            "uuid": "e1267.0",
            "source_info": {
                "paper_title": "End-to-End Goal-Driven Web Navigation",
                "publication_date_yy_mm": "2016-02"
            }
        },
        {
            "name_short": "WikiNav",
            "name_full": "WikiNav (WebNav applied to English Wikipedia)",
            "brief_description": "A benchmark dataset built by WebNav from the September 2015 English Wikipedia; defines goal-driven navigation tasks WikiNav-Nh-Nq where Nh (max hops) and Nq (query length in sentences) control difficulty.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "WikiNav (English Wikipedia graph)",
            "environment_description": "Encyclopedic information network: nodes are Wikipedia articles (cleaned text) and directed edges are intra-wiki hyperlinks; agent must reach a page containing a multi-sentence query drawn from a (target) page, starting from a fixed start node.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Directed, large-scale, sparse hyperlink network. Action (outgoing link) set is state-dependent and can vary widely by node (variable out-degree).",
            "environment_size": "Full English Wikipedia dump used: &gt;5 million pages. Dataset splits (examples): WikiNav-4-* train 6.0k / valid 1k / test 1k; WikiNav-8-* train 1M / valid 20k / test 20k; WikiNav-16-* train 12M / valid 20k / test 20k. WikiNav-Jeopardy contains 133k QA pairs (train 113k / valid 10k / test 10k).",
            "agent_name": "NeuAgent (NeuAgent-FF, NeuAgent-Rec)",
            "agent_description": "Neural-network agent: content represented by pretrained CBOW word vectors averaged per document; query represented by BoW or attention-based dynamic representation; core f_core implemented as either feedforward tanh (NeuAgent-FF) or recurrent LSTM (NeuAgent-Rec); agent peeks at neighbor node content vectors when scoring outgoing edges; stop action modeled explicitly; trained supervised on example traces; inference via forward beam search (beam width &lt;= Nn).",
            "exploration_efficiency_metric": "Average reward (binary correct stop fraction) and constrained-hops notion (Nh). For retrieval-style extension: Recall@K.",
            "exploration_efficiency_value": null,
            "success_rate": null,
            "optimal_policy_type": "Memory-based recurrent (history-conditioned) policies with attention on the query perform best for long-range tasks; greedy/local reactive policies suffice on very short tasks (small Nh).",
            "topology_performance_relationship": "Higher Nh (allowing farther targets) increases the effective search space exponentially and degrades performance; shorter queries (lower Nq) reduce available information and similarly degrade performance, requiring better language understanding and planning; constraining Nn (max outgoing edges considered) prevents BFS and forces local selection quality.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "Performance was compared across tasks with Nh in {4,8,16} and Nq in {1,2,4}: as Nh increases performance drops; as Nq increases performance improves. NeuAgent-Rec outperforms NeuAgent-FF for larger Nh, and deeper/larger recurrent models perform better for distant targets.",
            "policy_structure_findings": "History (RNN/LSTM) improves long-term planning (higher Nh). Attention-based query representations boost performance especially when queries are short (low Nq) and targets are distant. Beam search over multiple partial paths (width bounded by Nn) improves inference compared to greedy decisions.",
            "uuid": "e1267.1",
            "source_info": {
                "paper_title": "End-to-End Goal-Driven Web Navigation",
                "publication_date_yy_mm": "2016-02"
            }
        },
        {
            "name_short": "WikiNav-Jeopardy",
            "name_full": "WikiNav-Jeopardy (Jeopardy! questions on WikiNav)",
            "brief_description": "An extension of WikiNav where queries are Jeopardy! questions and targets are Wikipedia article titles (answers); used to evaluate the NeuAgent against inverted-index search baselines using Recall@K.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "WikiNav-Jeopardy (Wikipedia graph with Jeopardy queries)",
            "environment_description": "Same directed Wikipedia graph as WikiNav but with queries coming from Jeopardy! question-answer pairs whose answer is a Wikipedia article; dataset contains ~133k QA pairs filtered to article-title answers.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Directed, sparse hyperlink graph (Wikipedia); navigation is partially observed and agent only sees pages it visits plus immediate neighbors' content.",
            "environment_size": "133k QA pairs (after filtering); split: train 113k / valid 10k / test 10k. Average number of hops from start to target in these examples: 5.8 (std 1.2; min 2; max 10).",
            "agent_name": "NeuAgent-Rec (pretrained and finetuned variants)",
            "agent_description": "Large recurrent NeuAgent-Rec (8 layers of 2048 LSTM units) with attention-based query representation; trained either from scratch on WikiNav-Jeopardy or pretrained on WikiNav-16-4 then finetuned.",
            "exploration_efficiency_metric": "Recall@K (document recall among top-K returned nodes); beam search width set to K for NeuAgent; also uses average reward for other WikiNav tasks.",
            "exploration_efficiency_value": "Pretrained NeuAgent-Rec (pretrained on WikiNav-16-4 then finetuned) achieved Recall@1 = 18.9%, Recall@4 = 23.6%, Recall@40 = 38.3%. Non-pretrained NeuAgent-Rec achieved Recall@1 = 13.9%, Recall@4 = 20.2%, Recall@40 = 33.2%.",
            "success_rate": null,
            "optimal_policy_type": "Pretrained recurrent policy with attention and beam search (ranking + navigation hybrid) performs best for the QA-oriented navigation task.",
            "topology_performance_relationship": "Pretraining on a much larger graph (WikiNav-16-4) substantially improves ranking/navigation performance on WikiNav-Jeopardy, particularly when the candidate set is small (small K). Limited observability (agent only sees visited nodes) did not prevent the pretrained NeuAgent from outperforming inverted-index baselines on Recall@K.",
            "comparison_across_topologies": false,
            "topology_comparison_results": "Not directly varied across different graph topologies; main comparison was between training strategies (pretrained vs. trained-from-scratch) and vs search baselines.",
            "policy_structure_findings": "Pretraining on large navigation datasets improves the agent's ability to prioritize promising links and accurately rank target articles during constrained beam-search navigation; recurrent memory plus attention yields superior Recall@K performance.",
            "uuid": "e1267.2",
            "source_info": {
                "paper_title": "End-to-End Goal-Driven Web Navigation",
                "publication_date_yy_mm": "2016-02"
            }
        },
        {
            "name_short": "NeuAgent",
            "name_full": "NeuAgent (Neural-network navigation agent: NeuAgent-FF and NeuAgent-Rec)",
            "brief_description": "A neural-network agent family for goal-driven web navigation: two core variants — feedforward (NeuAgent-FF) and recurrent LSTM (NeuAgent-Rec) — using pretrained CBOW document vectors, optional attention over query words, peeking at neighbors' content when scoring outgoing actions, trained supervised on example traces and decoded with beam search.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "WikiNav / WikiNav-Jeopardy (website navigation tasks)",
            "environment_description": "Operates in partially-observed directed website graphs where at each step the agent reads the current page and observes textual content of immediate neighbors (peeking), then selects a hyperlink or the stop action.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Directed, sparse hyperlink topology; action space equals outgoing hyperlinks per node (variable out-degree).",
            "environment_size": "Evaluated on WikiNav datasets derived from English Wikipedia (dataset sizes listed under WikiNav entry).",
            "agent_name": "NeuAgent-FF (feedforward) and NeuAgent-Rec (recurrent LSTM)",
            "agent_description": "Core network f_core combines current-node content vector and query vector to produce hidden state h_t; scores outgoing neighbors by similarity between neighbor content vectors and h_t; supports attention-based dynamic query representations; stop action modeled; trained with supervised cross-entropy on example traces; inference uses forward-only beam search capped at Nn.",
            "exploration_efficiency_metric": "Average binary reward (correct stop fraction) on WikiNav tasks; Recall@K on WikiNav-Jeopardy; number of hops up to Nh.",
            "exploration_efficiency_value": "See WikiNav-Jeopardy results: pretrained NeuAgent-Rec Recall@1 = 18.9%, Recall@4 = 23.6%, Recall@40 = 38.3%. On WikiNav classifications, reported trends (no single global numbers printed) show NeuAgent-Rec &gt; NeuAgent-FF as Nh grows.",
            "success_rate": null,
            "optimal_policy_type": "Recurrent LSTM-based policy with attention and beam search is reported as the best-performing architecture in the experiments, especially when targets are far (higher Nh) or queries are short (low Nq).",
            "topology_performance_relationship": "NeuAgent-Rec outperforms NeuAgent-FF for larger allowed-hop budgets (Nh), indicating history/memory is needed for traversing larger effective diameters; attention on the query yields gains when query information is limited; limiting Nn enforces local decision-making and prevents full-graph BFS.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "Performance compared across task parameterizations (Nh,Nq): as Nh increases or Nq decreases, recurrent + attention architectures provide relatively larger gains; beam search helps under Nn constraints.",
            "policy_structure_findings": "Policies that condition on history (LSTM) are necessary for longer-range navigation; attention mechanisms shift focus across query words as the agent moves; supervised training on example traces plus pretraining on larger graph data improves exploration/ranking efficiency.",
            "uuid": "e1267.3",
            "source_info": {
                "paper_title": "End-to-End Goal-Driven Web Navigation",
                "publication_date_yy_mm": "2016-02"
            }
        },
        {
            "name_short": "Wikispeedia",
            "name_full": "Wikispeedia",
            "brief_description": "A previously proposed human navigation game on a small curated Wikipedia (\"Wikipedia for Schools\") where players navigate from a start article to a target article using hyperlinks; used in prior work to study human wayfinding and semantic distances.",
            "citation_title": "Wikispeedia: An online game for inferring semantic distances between concepts",
            "mention_or_use": "mention",
            "environment_name": "Wikispeedia (small Wikipedia graph)",
            "environment_description": "Small-scale directed Wikipedia graph (~4,000 articles as of 2008) used for human navigation studies; the target is given as an entire article rather than a short query.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Directed hyperlink graph on a small curated subset of Wikipedia; connectivity studied in prior work to infer semantic/graph distances between concepts.",
            "environment_size": "Approximately 4,000 articles (the \"Wikipedia for Schools\" corpus used in prior Wikispeedia work).",
            "agent_name": "Human navigators (studied) and algorithmic baselines in cited works",
            "agent_description": "Humans navigate using topical knowledge and heuristic link-following; prior work analyzed human paths to infer semantic distances.",
            "exploration_efficiency_metric": "Path length and success in reaching target (studied in prior works); specific metrics are external to this paper.",
            "exploration_efficiency_value": null,
            "success_rate": null,
            "optimal_policy_type": null,
            "topology_performance_relationship": "Referenced as related work: Wikispeedia investigated how humans navigate information networks; this paper positions WikiNav as a generalization and more challenging benchmark.",
            "comparison_across_topologies": null,
            "topology_comparison_results": null,
            "policy_structure_findings": "Paper cites Wikispeedia to contrast target specification (full article in Wikispeedia vs short queries in WikiNav) and to motivate focus on algorithmic agents rather than human wayfinding.",
            "uuid": "e1267.4",
            "source_info": {
                "paper_title": "End-to-End Goal-Driven Web Navigation",
                "publication_date_yy_mm": "2016-02"
            }
        },
        {
            "name_short": "MUDs (text-based games)",
            "name_full": "Multi-User Dungeon (MUD) text-based games (prior RL/NLP work)",
            "brief_description": "Prior text-based game environments where agents perceive state via textual descriptions and act with text commands; cited as less linguistically rich or smaller-vocabulary than WikiNav.",
            "citation_title": "Language understanding for textbased games using deep reinforcement learning",
            "mention_or_use": "mention",
            "environment_name": "MUD/text-based-game environments (prior work)",
            "environment_description": "Fantasy/interactive-text domains (MUDs) with relatively small vocabularies and scene-limited descriptions used in earlier language-and-planning research.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": null,
            "door_constraints_description": "",
            "graph_connectivity": "Varies by specific game; prior studies used smaller worlds (vocab sizes reported: ~1,340 to ~2,258 words) and simpler per-step descriptions.",
            "environment_size": "Not specified here; prior cited MUD works used much smaller vocabularies and smaller state descriptions than Wikipedia-based WikiNav.",
            "agent_name": null,
            "agent_description": null,
            "exploration_efficiency_metric": null,
            "exploration_efficiency_value": null,
            "success_rate": null,
            "optimal_policy_type": null,
            "topology_performance_relationship": "Paper contrasts these environments with WikiNav: MUDs typically lack the complex natural-language richness and large, variable action spaces of web graphs.",
            "comparison_across_topologies": null,
            "topology_comparison_results": null,
            "policy_structure_findings": "The paper notes that MUD experiments do not fully exercise natural language complexity and often have limited state descriptions, implying that policies required there differ from those needed on large web graphs.",
            "uuid": "e1267.5",
            "source_info": {
                "paper_title": "End-to-End Goal-Driven Web Navigation",
                "publication_date_yy_mm": "2016-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Wikispeedia: An online game for inferring semantic distances between concepts",
            "rating": 2,
            "sanitized_title": "wikispeedia_an_online_game_for_inferring_semantic_distances_between_concepts"
        },
        {
            "paper_title": "Automatic versus human navigation in information networks",
            "rating": 2,
            "sanitized_title": "automatic_versus_human_navigation_in_information_networks"
        },
        {
            "paper_title": "Human wayfinding in information networks",
            "rating": 2,
            "sanitized_title": "human_wayfinding_in_information_networks"
        },
        {
            "paper_title": "Language understanding for textbased games using deep reinforcement learning",
            "rating": 2,
            "sanitized_title": "language_understanding_for_textbased_games_using_deep_reinforcement_learning"
        },
        {
            "paper_title": "Focused crawling: a new approach to topic-specific web resource discovery",
            "rating": 1,
            "sanitized_title": "focused_crawling_a_new_approach_to_topicspecific_web_resource_discovery"
        }
    ],
    "cost": 0.02016525,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>End-to-End Goal-Driven Web Navigation
20 May 2016</p>
<p>Rodrigo Nogueira rodrigonogueira@nyu.edu 
Tandon School of Engineering
New York University</p>
<p>Kyunghyun Cho kyunghyun.cho@nyu.edu 
Courant Institute of Mathematical Sciences New York University</p>
<p>End-to-End Goal-Driven Web Navigation
20 May 20163DBC090ABED59B0E69831AA1BBDBF7B9arXiv:1602.02261v2[cs.AI]Kentuchy Derby Races CategoryKentuchy Derby CategorySports events in Louisville, Kentuchy CategorySports Events by City CategorySports Events CategorySports CategoryMain Topic Classifications
We propose a goal-driven web navigation as a benchmark task for evaluating an agent with abilities to understand natural language and plan on partially observed environments.In this challenging task, an agent navigates through a website, which is represented as a graph consisting of web pages as nodes and hyperlinks as directed edges, to find a web page in which a query appears.The agent is required to have sophisticated high-level reasoning based on natural languages and efficient sequential decision-making capability to succeed.We release a software tool, called WebNav, that automatically transforms a website into this goal-driven web navigation task, and as an example, we make WikiNav, a dataset constructed from the English Wikipedia.We extensively evaluate different variants of neural net based artificial agents on WikiNav and observe that the proposed goal-driven web navigation well reflects the advances in models, making it a suitable benchmark for evaluating future progress.Furthermore, we extend the WikiNav with questionanswer pairs from Jeopardy! and test the proposed agent based on recurrent neural networks against strong inverted index based search engines.The artificial agents trained on WikiNav outperforms the engined based approaches, demonstrating the capability of the proposed goal-driven navigation as a good proxy for measuring the progress in real-world tasks such as focused crawling and question-answering.</p>
<p>Introduction</p>
<p>In recent years, there have been many exciting advances in building an artificial agent, which can be trained with one learning algorithm, to solve many relatively large-scale, complicated tasks (see, e.g., [8,10,6].)In much of these works, target tasks were computer games such as Atari games [8] and racing car game [6].</p>
<p>These successes have stimulated researchers to apply a similar learning mechanism to language-based tasks, such as multi-user dungeon (MUD) games [9,4].Instead of visual perception, an agent perceives the state of the world by its written description.A set of actions allowed to the agent is either fixed or dependent on the current state.This type of task can efficiently evaluate the agent's ability of not only in planning but also language understanding.We, however, notice that these MUD games do not exhibit the complex nature of natural languages to the full extent.For instance, the largest game world tested by Narasimhan et al. [9] uses a vocabulary of only 1340 unique words, and the largest game tested by He et al. [4] uses only 2258 words.Furthermore, the description of a state at each time step is almost always limited to the visual description of the current scene, lacking any use of higher-level concepts present in natural languages.</p>
<p>In this paper, we propose a goal-driven web navigation as a large-scale alternative to the text-based games for evaluating artificial agents with natural language understanding and planning capability.The proposed goal-driven web navigation consists of the whole website as a graph, in which the web pages are nodes and hyperlinks are directed edges.An agent is given a query, which consists of one or more sentences taken from a randomly selected web page in the graph, and navigates the network, starting from a predefined starting node, to find a target node in which the query appears.Unlike the text-based games, this task utilizes the existing text as it is, resulting in a large vocabulary with a truly natural language description of the state.Furthermore, the task is more challenging as the action space greatly changes with respect to the state in which the agent is.</p>
<p>We release a software tool, called WebNav, that converts a given website into a goal-driven web navigation task.As an example of its use, we provide WikiNav, which was built from English Wikipedia.We design artificial agents based on neural networks (called NeuAgents) trained with supervised learning, and report their respective performances on the benchmark task as well as the performance of human volunteers.We observe that the difficulty of a task generated by WebNav is well controlled by two control parameters; (1) the maximum number of hops from a starting to a target node N h and (2) the length of query N q .Furthermore, we extend the WikiNav with an additional set of queries that are constructed from Jeopardy!questions, to which we refer by WikiNav-Jeopardy.We evaluate the proposed NeuAgents against the three search-based strategies; (1) SimpleSearch, (2) Apache Lucene and (3) Google Search API.The result in terms of document recall indicates that the NeuAgents outperform those search-based strategies, implying a potential for the proposed task as a good proxy for practical applications such as question-answering and focused crawling.</p>
<p>Goal-driven Web Navigation</p>
<p>A task T of goal-driven web navigation is characterized by
T = (A, s S , G, q, R, Ω).(1)
The world in which an agent A navigates is represented as a graph G = (N , E).The graph consists of a set of nodes
N = {s i } N N
i=1 and a set of directed edges E = {e i,j } connecting those nodes.Each node represents a page of the website, which, in turn, is represented by the natural language text D(s i ) in it.There exists an edge going from a page s i to s j if and only if there is a hyperlink in D(s i ) that points to s j .One of the nodes is designated as a starting node s S from which any navigation begins.A target node is the one whose natural language description contains a query q, and there may be more than one target node.</p>
<p>At each time step, the agent A reads the natural language description D(s t ) of the current node in which the agent has landed.At no point, the whole world, consisting of the nodes and edges, nor its structure or map (graph structure without any natural language description) is visible to the agent, thus making this task partially observed.</p>
<p>Once the agent A reads the description D(s i ) of the current node s i , it can take one of the actions available.A set of possible actions is defined as a union of all the outgoing edges e i,• and the stop action, thus making the agent have state-dependent action space.</p>
<p>Each edge e i,k corresponds to the agent jumping to a next node s k , while the stop action corresponds to the agent declaring that the current node s i is one of the target nodes.Each edge e i,k is represented by the description of the next node D(s k ).In other words, deciding which action to take is equivalent to taking a peek at each neighboring node and seeing whether that node is likely to lead ultimately to a target node.</p>
<p>The agent A receives a reward R(s i , q) when it chooses the stop action.This task uses a simple binary reward, where
R(s i , q) = 1, if q ⊆ D(s i ) 0, otherwise
Constraints It is clear that there exists an ultimate policy for the agent to succeed at every trial, which is to traverse the graph breadth-first until the agent finds a node in which the query appears.To avoid this kind of degenerate policies, the task includes a set of four rules/constraints Ω:</p>
<p>1.An agent can follow at most N n edges at each node.</p>
<ol>
<li>
<p>An agent has a finite memory of size smaller than T .</p>
</li>
<li>
<p>An agent moves up to N h hops away from s S .4. A query of size N q comes from at least two hops away from the starting node.</p>
</li>
</ol>
<p>The first constraint alone prevents degenerate policies, such as breadth-first search, forcing the agent to make good decisions as possible at each node.The second one further constraints ensure that the agent does not cheat by using earlier trials to reconstruct the whole graph structure (during test time) or to store the entire world in its memory (during training.)The third constraint, which is optional, is there for computational consideration.The fourth constraint is included because the agent is allowed to read the content of a next node.</p>
<p>3 WebNav: Software</p>
<p>As a part of this work, we build and release a software tool which turns a website into a goal-driven web navigation task. 1 We call this tool WebNav.Given a starting URL, the WebNav reads the whole website, constructs a graph with the web pages in the website as nodes.Each node is assigned a unique identifier s i .The text content of each node D(s i ) is a cleaned version of the actual HTML content of the corresponding web page.The WebNav turns intra-site hyperlinks into a set of edges e i,j .</p>
<p>In addition to transforming a website into a graph G from Eq. ( 1), the WebNav automatically selects queries from the nodes' texts and divides them into training, validation, and test sets.We ensure that there is no overlap among three sets by making each target node, from which a query is selected, belongs to only one of them.</p>
<p>Each generated example is defined as a tuple
X = (q, s * , p * ) (2)
where q is a query from a web page s * , which was found following a randomly selected path p * = (s S , . . ., s * ).In other words, the WebNav starts from a starting page s S , random-walks the graph for a predefined number of steps (N h /2, in our case), reaches a target node s * and selects a query q from D(s * ).A query consists of N q sentences and is selected among the top-5 candidates in the target node with the highest average TF-IDF, thus discouraging the WebNav from choosing a trivial query.</p>
<p>For the evaluation purpose alone, it is enough to use only a query q itself as an example.However, we include both one target node (among potentially many other target nodes) and one path from the starting node to this target node (again, among many possible connecting paths) so that they can be exploited when training an agent.They are not to be used when evaluating a trained agent.</p>
<p>WikiNav: A Benchmark Task</p>
<p>With the WebNav, we built a benchmark goal-driven navigation task using Wikipedia as a target website.We used the dump file of the English Wikipedia from September 2015, which consists of more than five million web pages.We built a set of separate tasks with different levels of difficulty by varying the maximum number of allowed hops N h ∈ {4, 8, 16} and the size of query N q ∈ {1, 2, 4}.</p>
<p>We refer to each task by WikiNav-N h -N q .</p>
<p>For each task, we generate training, validation and test examples from the pages half as many hops away from a starting page as the maximum number of hops allowed. 2 We use "Category:Main topic classifications" as a starting node s S .As a minimal cleanup procedure, we excluded meta articles whose titles start with "Wikipedia".Any hyperlink that leads to a web page outside Wikipedia is removed in advance together with the following sections: "References", "External Links", "Bibliography" and "Partial Bibliography".In Table 2, we present basic per-article statistics of the English Wikipedia.It is evident from these statistics that the world of WikiNav-N h -N q is large and complicated, even after the cleanup procedure.</p>
<p>Hyperlinks Words</p>
<p>We ended up with a fairly small dataset for WikiNav-4-<em>, but large for WikiNav-8-</em> and WikiNav-16-*.See Table 1 for details.</p>
<p>Related Work: Wikispeedia</p>
<p>This work is indeed not the first to notice the possibility of a website, or possibly the whole web, as a world in which intelligent agents explore to achieve a certain goal.One most relevant recent work to ours is perhaps Wikispeedia from [14,12,13].</p>
<p>West et al. [14,12,13] proposed the following game, called Wikispeedia.The game's world is nearly identical to the goal-driven navigation task proposed in this work.More specifically, they converted "Wikipedia for Schools", which contains approximately 4,000 articles as of 2008, into a graph whose nodes are articles and directed edges are hyperlinks.From this graph, a pair of nodes is randomly selected and provided to an agent.</p>
<p>The agent's goal is to start from the first node, navigate the graph and reach the second node.Similarly to the WikiNav, the agent has access to the text content of the current nodes and all the immediate neighboring nodes.One major difference is that the target is given as a whole article, meaning that there is a single target node in the Wikispeedia while there may be multiple target nodes in the proposed WikiNav.</p>
<p>From this description, we see that the goal-driven web navigation is a generalization and re-framing of the Wikispeedia.First, we constrain a query to contain less information, making it much more difficult for an agent to navigate to a target node.Furthermore, a major research question by West and Leskovec [13] was to "understand how humans navigate and find the information they are looking for ," whereas in this work we are fully focused on proposing an automatic tool to build a challenging goal-driven tasks for designing and evaluating artificial intelligent agents.</p>
<p>5 WikiNav-Jeopardy: Jeopardy! on WikiNav</p>
<p>One of the potential practical applications utilizing the goal-drive navigation is question-answering based on world knowledge.In this Q&amp;A task, a query is a question, and an agent navigates a given information network, e.g., website, to retrieve an answer.In this section, we propose and describe an extension of the WikiNav, in which query-target pairs are constructed from actual Jeopardy!question-answer pairs.We refer to this extension of WikiNav by WikiNav-Jeopardy.</p>
<p>We first extract all the question-answer pairs from J! Archive 3 , which has more than 300k such pairs.We keep only those pairs whose answers are titles of Wikipedia articles, leaving us with 133k pairs.We divide those pairs into 113k training, 10k validation, and 10k test examples while carefully ensuring that no article appears in more than one partition.Additionally, we do not shuffle the original pairs to ensure that the train and test examples are from different episodes.</p>
<p>For each training pair, we find one path from the starting node "Main Topic Classification" to the target node and include it for supervised learning.For reference, the average number of hops to the target node is 5.8, the standard deviation is 1.2, and the maximum and minimum are 2 and 10, respectively.See Table 3 for sample query-answer pairs.</p>
<p>6 NeuAgent: Neural Network based Agent</p>
<p>Model Description</p>
<p>Core Function The core of the NeuAgent is a parametric function f core that takes as input the content of the current node φ c (s i ) and a query φ q (q), and that returns the hidden state of the agent.This parametric function f core can be implemented either as a feedforward neural network f ff :
h t = f ff (φ c (s i ), φ q (q))
which does not take into account the previous hidden state of the agent or as a recurrent neural network f rec :
h t = f rec (h t−1 , φ c (s i ), φ q (q)).
We refer to these two types of agents by NeuAgent-FF and NeuAgent-Rec, respectively.For the NeuAgent-FF, we use a single tanh layer, while we use long short-term memory (LSTM) units [5], which have recently become de facto standard, for the NeuAgent-Rec.Based on the new hidden state h t , the NeuAgent computes the probability distribution over all the outgoing edges e i .The probability of each outgoing edge is proportional to the similarity between the hidden state h t such that p(e i,j |p) ∝ exp φ c (s j ) h t .</p>
<p>(3)</p>
<p>Note that the NeuAgent peeks at the content of the next node s j by considering its vector representation φ c (s j ).</p>
<p>In addition to all the outgoing edges, we also allow the agent to stop with the probability
p(∅|p) ∝ exp v ∅ h t ,(4)
where the stop action vector v ∅ is a trainable parameter.</p>
<p>In the case of NeuAgent-Rec, all these (unnormalized) probabilities are conditioned on the history p which is a sequence of actions (nodes) selected by the agent so far.We apply a softmax normalization on the unnormalized probabilities to obtain the probability distribution over all the possible actions at the current node s i .</p>
<p>The NeuAgent then selects its next action based on this action probability distribution (Eqs.( 3) and ( 4)).If the stop action is chosen, the NeuAgent returns the current node as an answer and receives a reward R(s i , q), which is one if correct and zero otherwise.If the agent selects one of the outgoing edges, it moves to the selected node and repeats this process of reading and acting.</p>
<p>See Fig. 1 for a single step of the described NeuAgent.</p>
<p>Content Representation</p>
<p>The NeuAgent represents the content of a node s i as a vector φ c (s i ) ∈ R d .In this work, we use a continuous bag-of-words vector for each document:
φ c (s i ) = 1 |D(s i )| |D(si)| k=1 e k .
Each word vector e k is from a pretrained continuous bag-of-words model [7].These word vectors are fixed throughout training.</p>
<p>Query Representation In the case of a query, we consider two types of representation.The first one is a continuous bag-of-words (BoW) vector, just as used for representing the content of a node.The other one is a dynamic representation based on the attention mechanism [2].</p>
<p>In the attention-based query representation, the query is first projected into a set of context vectors.The context vector of the k-th query word is
c k = k+u/2 k =k−u/2 W k e k ,
where W k ∈ R d×d and e k are respectively a trainable weight matrix and a pretrained word vector.u is the window size.Each context vector is scored at each time step t by .These normalized scores are used as the coefficients in computing the weighted-sum of query words to result in a query representation at time t:
β t k = f att (h t−1 , c k ) w.φ q (q) = 1 |q| |q| k=1 α t k c k .
Later, we empirically compare these two query representations.</p>
<p>Inference: Beam Search</p>
<p>Once the NeuAgent is trained, there are a number of approaches to using it for solving the proposed task.The most naive approach is simply to let the agent make a greedy decision at each time step, i.e., following the outgoing edge with the highest probability arg max k log p(e i,k | . ..).A better approach is to exploit the fact that the agent is allowed to explore up to N n outgoing edges per node.We use a simple, forward-only beam search with the beam width capped at N n .The beam search simply keeps the N n most likely traces, in terms of log p(e i,k | . ..), at each time step.</p>
<p>Training: Supervised Learning</p>
<p>In this paper, we investigate supervised learning, where we train the agent to follow an example trace p * = (s S , . . ., s * ) included in the training set at each step (see Eq. ( 2)).In this case, the cost per training example is
C sup = − log p(∅|p * , q) − |p * | k=1 log p(p * k |p * &lt;k , q).(5)
This per-example training cost is fully differentiable with respect to all the parameters of the neural network, and we use stochastic gradient descent (SGD) algorithm to minimize this cost over the whole training set, where the gradients can be computed by backpropagation [11].This allows the entire model to be trained in an end-to-end fashion, in which the query-to-target performance is optimized directly.</p>
<p>Human Evaluation</p>
<p>One unique aspect of the proposed task is that it is very difficult for an average person who was not trained specifically for finding information by navigating through an information network.There are a number of reasons behind this difficulty.First, the person must be familiar with, via training, the graph structure of the network, and this often requires many months, if not years, of training.Second, the person must have in-depth knowledge of a broad range of topics in order to make a connection via different concepts between the themes and topics of a query to a target node.Third, each trial requires the person carefully to read the whole content of the nodes as she navigates, which is a time-consuming and exhausting job.</p>
<p>We asked five volunteers to try up to 20 four-sentence-long queries 4 randomly selected from the test sets of WikiNav-{4, 8, 16}-4 datasets.They were given up to two hours, and they were allowed to choose up to the same maximum number of explored edges per node N n as the NeuAgents (that is, N n = 4), and also were given the option to give up.The average reward was computed as the fraction of correct trials over all the queries presented.</p>
<p>8 Results and Analysis</p>
<p>WikiNav</p>
<p>We report in Table 4 the performance of the NeuAgent-FF and NeuAgent-Rec models on the test set of all nine WikiNav-{4, 8, 16}-{1, 2, 4} datasets.In addition to the proposed NeuAgents, we also report the results of the human evaluation.</p>
<p>We clearly observe that the level of difficulty is indeed negatively correlated with the query length N q but is positively correlated with the maximum number of allowed hops N h .The latter may be considered trivial, as the size of the search space grows exponentially with respect to N h , but the former is not.The former negative correlation confirms that it is indeed easier to solve the task with more information in a query.We conjecture that the agent requires more in-depth understanding of natural languages and planning to overcome the lack of information in the query to find a path toward a target node.</p>
<p>The NeuAgent-FF and NeuAgent-Rec shares similar performance when the maximum number of allowed hops is small (N h = 4), but NeuAgent-Rec ((a) vs. (b)) performs consistently better for higher N h , which indicates that having access to history helps in long-term planning tasks.We also observe that the larger and deeper NeuAgent-Rec ((b) vs (c)) significantly outperforms the smaller one, when a target node is further away from the starting node s S .</p>
<p>The best performing model in (d) used the attention-based query representation, especially as the difficulty of the task increased (N q ↓ and N h ↑), which supports our claim that the proposed task of goal-driven web navigation is a challenging benchmark for evaluating future progress.In Fig. 2, we present an example of how the attention weights over the query words dynamically evolve as the model navigates toward a target node.</p>
<p>The human participants generally performed worse than the NeuAgents.We attribute this to a number of reasons.First, the NeuAgents are trained specifically on the target domain (Wikipedia), while the human participants have not been.Second, we observed that the volunteers were rapidly exhausted from reading multiple articles in sequence.In other words, we find the proposed benchmark, WebNav, as a good benchmark for machine intelligence but not for comparing it against human intelligence.</p>
<p>WikiNav-Jeopardy</p>
<p>Settings We test the best model from the previous experiment (NeuAgent-Rec with 8 layers of 2048 LSTM units and the attention-based query representation) on the WikiNav-Jeopardy.We evaluate two training strategies.The first strategy is straightforward supervise learning, in which we train a NeuAgent-Rec on WikiNav-Jeopardy from scratch.In the other strategy, we pretrain a NeuAgent-Rec first on the WikiNav-16-4 and finetune it on WikiNav-Jeopardy.</p>
<p>We compare the proposed NeuAgent against three search strategies.The first one, SimpleSearch, is a simple inverted index based strategy.SimpleSearch scores each Wikipedia article by the TF-IDF weighted sum of words that co-occur in the articles and a query and returns top-K articles.Second, we use Lucene, a popular open source information retrieval library, in its default configuration on the whole Wikipedia dump.Lastly, we use Google Search API 5 , while restricting the domain to wikipedia.org.</p>
<p>Each system is evaluated by document recall at K (Recall@K).We vary K to be 1, 4 or 40.In the case of the NeuAgent, we run beam search with width set to K and returns all the K final nodes to compute the document recall.Result and Analysis In Table 5, we report the results on WikiNav-Jeopardy.The proposed NeuAgent clearly outperforms all the three search-based strategies, when it was pretrained on the WikiNav-16-4.The superiority of the pretrained NeuAgent is more apparent when the number of candidate documents is constrained to be small, implying that the NeuAgent is able to accurately rank a correct target article.Although the NeuAgent performs comparably to the other search-based strategy even without pretraining, the benefit of pretraining on the much larger WikiNav is clear.</p>
<p>We emphasize that these search-based strategies have access to all the nodes for each input query.The NeuAgent, on the other hand, only observes the nodes as it visits during navigation.This success clearly demonstrates a potential in using the proposed NeuAgent pretrained with a dataset compiled by the proposed WebNav for the task of focused crawling [3,1], which is an interesting problem on its own, as much of the content available on the Internet is either hidden or dynamically generated [1].</p>
<p>Conclusion</p>
<p>In this work, we describe a large-scale goal-driven web navigation task and argue that it serves as a useful test bed for evaluating the capabilities of artificial agents on natural language understanding and planning.We release a software tool, called WebNav, that compiles a given website into a goal-driven web navigation task.As an example, we construct WikiNav from Wikipedia using WebNav.We extend WikiNav with Jeopardy!questions, thus creating WikiNav-Jeopardy.We evaluate various neural net based agents on WikiNav and WikiNav-Jeopardy.Our results show that more sophisticated agents have better performance, thus supporting our claim that this task is well suited to evaluate future progress in natural language understanding and planning.Furthermore, we show that our agent pretrained on WikiNav outperforms two strong inverted-index based search engines on the WikiNav-Jeopardy.These empirical results support our claim on the usefulness of the proposed task and agents in challenging applications such as focused crawling and question-answering.</p>
<p>Figure 1 :
1
Figure 1: Graphical illustration of a single step performed by the baseline model, NeuAgent.</p>
<p>Figure 2 :
2
Figure 2: Visualization of the attention weights over a test query.The horizontal axis corresponds to the query words, and the vertical axis to the articles titles visited.</p>
<p>Table 1 :
1
Dataset Statistics of WikiNav-4-<em>, WikiNav-8-</em>, WikiNav-16-<em> and WikiNav-Jeopardy.
WikiNav-4-</em> WikiNav-8-<em> WikiNav-16-</em> WikiNav-JeopardyTrain6.0k1M12M113kValid1k20k20k10kTest1k20k20k10k</p>
<p>Table 3 :
3
Sample query-answer pairs from WikiNav-Jeopardy.
QueryAnswerFor the last 8 years of his life, Galileo was under house arrest for espousing this man's theory.CopernicusIn the winter of 1971-72, a record 1,122 inches of snow fell Washington at Rainier Paradise Ranger Station in this state.This company's Accutron watch, introduced in 1960, had a guarantee of accuracy to within one minute a month.Bulova</p>
<p>Table 2 :
2
Per-page statistics of English Wikipedia.
Avg. √ Var4.29 13.85462.5 990.2Max300132881Min01</p>
<p>r.t. the previous hidden state of the NeuAgent, and all the scores are normalized to be positive and sum to one, i.e., α t k =
exp(β t k )|q| l=1 exp(β t l )</p>
<p>Table 4 :
4
The average reward by the NeuAgents and humans on the test sets of WikiNav-N h -N q .
Nq = 124</p>
<p>Table 5 :
5
Recall on WikiNav-Jeopardy.( ) Pretrained on WikiNav-16-4.
ModelPreRecall@1 Recall@4 Recall@40NeuAgent13.920.233.2NeuAgent18.923.638.3SimpleSearch5.412.628.4Lucene6.314.736.3Google14.022.125.9
The source code and datasets are publicly available at https://drive.google.com/folderview?id= 0B5LbsF7OcHjqUFhWQ242bzdlTWc&amp;usp=sharing.
This limit is an artificial limit we chose for computational reasons.
http://www.j-archive.com
In a preliminary study with other volunteers, we found that, when the queries were shorter than 4, they were not able to solve enough trials for us to have meaningful statistics.
https://cse.google.com/cse/
AcknowledgmentsKC thanks the support by Facebook, Google (Google Faculty Award 2016) and NVidia (GPU Center of Excellence 2015-2016).RN is funded by Coordenação de Aperfeicoamento de Pessoal de Nível Superior (CAPES).
Deepbot: a focused crawler for accessing hidden web content. Manuel Álvarez, Juan Raposo, Alberto Pan, Fidel Cacheda, Fernando Bellas, Víctor Carneiro, Proceedings of the 3rd international workshop on Data enginering issues in E-commerce and services: In conjunction with ACM Conference on Electronic Commerce (EC'07). the 3rd international workshop on Data enginering issues in E-commerce and services: In conjunction with ACM Conference on Electronic Commerce (EC'07)ACM2007</p>
<p>Neural machine translation by jointly learning to align and translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, ICLR 20152014</p>
<p>Focused crawling: a new approach to topic-specific web resource discovery. Soumen Chakrabarti, Martin Van Den, Byron Berg, Dom, Computer Networks. 31111999</p>
<p>Deep reinforcement learning with an unbounded action space. Ji He, Jianshu Chen, Xiaodong He, Jianfeng Gao, Lihong Li, Li Deng, Mari Ostendorf, arXiv:1511.046362015arXiv preprint</p>
<p>Long short-term memory. Sepp Hochreiter, Jürgen Schmidhuber, Neural computation. 981997</p>
<p>Evolving deep unsupervised convolutional networks for vision-based reinforcement learning. Jan Koutník, Jürgen Schmidhuber, Faustino Gomez, Proceedings of the 2014 conference on Genetic and evolutionary computation. the 2014 conference on Genetic and evolutionary computationACM2014</p>
<p>Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean, arXiv:1301.3781Efficient estimation of word representations in vector space. 2013arXiv preprint</p>
<p>Human-level control through deep reinforcement learning. Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, Nature. 51875402015</p>
<p>Language understanding for textbased games using deep reinforcement learning. Karthik Narasimhan, Tejas Kulkarni, Regina Barzilay, arXiv:1506.089412015arXiv preprint</p>
<p>Sebastian Risi, Julian Togelius, arXiv:1410.7326Neuroevolution in games: State of the art and open challenges. 2014arXiv preprint</p>
<p>Learning representations by backpropagating errors. David Rumelhart, Geoffrey Hinton, Ronald Williams, Nature. 1986</p>
<p>Automatic versus human navigation in information networks. Robert West, Jure Leskovec, ICWSM. 2012</p>
<p>Human wayfinding in information networks. Robert West, Jure Leskovec, 21st International World Wide Web Conference. ACM2012</p>
<p>Wikispeedia: An online game for inferring semantic distances between concepts. Robert West, Joelle Pineau, Doina Precup, IJCAI. 2009</p>            </div>
        </div>

    </div>
</body>
</html>