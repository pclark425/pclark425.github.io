<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4633 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4633</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4633</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-104.html">extraction-schema-104</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents playing text games, with a focus on how memory is used, the type of memory mechanisms, comparative performance with and without memory, and any recommendations or challenges regarding memory usage.</div>
                <p><strong>Paper ID:</strong> paper-268819055</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2404.00573v1.pdf" target="_blank">"My agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents</a></p>
                <p><strong>Paper Abstract:</strong> In this study, we propose a novel human-like memory architecture designed for enhancing the cognitive abilities of large language model based dialogue agents. Our proposed architecture enables agents to autonomously recall memories necessary for response generation, effectively addressing a limitation in the temporal cognition of LLMs. We adopt the human memory cue recall as a trigger for accurate and efficient memory recall. Moreover, we developed a mathematical model that dynamically quantifies memory consolidation, considering factors such as contextual relevance, elapsed time, and recall frequency. The agent stores memories retrieved from the user's interaction history in a database that encapsulates each memory's content and temporal context. Thus, this strategic storage allows agents to recall specific memories and understand their significance to the user in a temporal context, similar to how humans recognize and recall past experiences.</p>
                <p><strong>Cost:</strong> 0.003</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4633",
    "paper_id": "paper-268819055",
    "extraction_schema_id": "extraction-schema-104",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00268675,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>"My agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents
31 Mar 2024</p>
<p>Yuki Hou 
Haruki Tamoto 
Homei 2024 " Miyashita 
My </p>
<p>Meiji University Tokyo
Japan Haruki Tamoto</p>
<p>Kyoto University Kyoto
Japan Homei Miyashita</p>
<p>Meiji University Tokyo
Japan</p>
<p>"My agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents
31 Mar 20247B1565A37403BB3A4AD87BCC9982520EarXiv:2404.00573v1[cs.HC]Memory Retrieval ModelsLarge Language ModelsIntelligent AgentsUser Experience
Figure1: Architecture of the enhanced large language model (LLM)-based dialogue agent that integrates human-like memory processes.First, the user input is converted into vectorized text and processed through a data-filtering process based on relevance and memory consolidation bias, modeled after human cognitive functions.Then, memory recall is triggered when the recall probability, informed by relevance and elapsed time, exceeds a predefined threshold.This diagram features an agent output example where the system recalls "Creamy pasta" as the user's lunch preference with a higher frequency, influencing the agent's response.</p>
<p>INTRODUCTION</p>
<p>The emergence of transformer-based language models [14] have drastically revolutionized the field of natural language processing, surpassing the capabilities of traditional models in understanding and generating human-like text [22].In particular, large language models (LLMs) [5] have garnered considerable attention for their prowess in mimicking artificial intelligence (AI) with human-like cognition and conversational abilities, reminiscent of sentient machines portrayed in science fiction narratives.However, LLMs exhibit a significant limitation in processing temporal information inherent to human cognition.While transformers possess excellent self-attention mechanisms, outperforming recurrent neural networks (RNNs) [15] and long short-term memory models (LSTM) [23], they fail to replicate human behavioral dynamics.To accurately replicate the nuanced human-like interactions of AI agents, as depicted in science fiction, one must first achieve human-like cognitive and memory processing abilities.Therefore, we proposed an approach to integrate human memory processes into LLM-based dialogue agents 1.We adopted human-like cued recall as the trigger for accurate and efficient memory retrieval [16].This mechanism involves an agent autonomously recalling memories essential for generating responses during a conversation.The process emulates the human memory process known as "remember to remember" [9], consciously retaining memory for future action or task and recalling that when needed [13].Furthermore, the proposed model replicates human cognitive ability, where memories recalled repeatedly over a long period are retained more strongly than those recalled over a short period and relatively frequently [21], regardless of recall frequency.Thus, our model provides contextually relevant and coherent conversations.</p>
<p>Furthermore, our primary purpose is to transcend the paradigm of dialogue agents merely imitating human behavior through statistical natural language models.Instead, we seek to create agents that are capable of truly understanding human language with rich nuances, achieved by seamlessly integrating human cognitive processes.This fusion aligns with the philosophy of human-computer interaction, promoting more natural and intuitive human-centered interactions between the two at cognitive and emotional levels.</p>
<p>RELATED WORK 2.1 Similarities Between LLMs and Human Memory</p>
<p>Human memory serves as a system to encode, store, and retrieve our experiences [25].Our memories can be categorized into declarative and non-declarative memories, with declarative memory further divided into episodic and semantic memories [3].Episodic memory [24] consciously allows for recollecting and re-experiencing one's subjective past.In contrast, semantic memory supports language use, registering not the perceptual properties of inputs but the cognitive referents of input signals [27].Similar to human episodic memory functioning, the episodic nature of LLMs' is demonstrated by their ability to recall specific events or dialogues from the database.This allows LLMs to generate responses based on past interactions and experiences to inform current interactions.LLMs also possess a human-like semantic understanding of language that captures the meaning and context behind the words.Geva et al. [8] suggested the feed-forward layers of transformer-based models to operate in a key-value format, the same as human semantic memory.</p>
<p>Human-like Memory Processes in AI Agent</p>
<p>Kim et al. [11] focused on emulating human episodic and semantic memory processes in AI agents to enhance interactive experiences.They compared agents with different memory processes: episodic only, semantic only, and both.These agents used different strategies to decide which memories to forget when memory was full and which to use when answering questions.The agents with a composite memory system outperformed those with a single memory system, especially those with pre-trained semantic memory.Zhong et al. developed MemoryBank, a memory retrieval mechanism for memory storage [28].The system uses an encoder model to encode each conversation turn and event summary into a vector representation, allowing recalling memory with the highest relevance whenever needed.The memory strength of MemoryBank's is enhanced by 1 each time a memory piece is recalled, simulating more human-like memory behavior and reducing the probability of forgetting the memory by setting the elapsed time to zero.</p>
<p>In contrast, we designed our architecture without the concept of "complete forgetting."Even if not recalling a memory over an extended period, the degree of consolidation never reaches absolute zero.Thus, given the right trigger, these memories can be recalled [1].The process is consistent with that of human memory, where past experiences are never completely forgotten and can be retrieved with specific stimuli, such as the scent of a familiar perfume or the melody of a once-favorite song.</p>
<p>Mathematical Models of Human Memory Processes</p>
<p>This section reviews the mathematical models that attempt to quantify and simulate human memory processes, primarily for memory recall.Based on Zielske's [29] recall probability function, Chessa et al. [4] proposed a model that assumes the rate of memory consolidation  () to express the probability  () of a human memory being recalled as follows:
ğ‘ (ğ‘¡) = 1 âˆ’ ğ‘ âˆ’1 âˆ‘ï¸ ğ‘›=1 (ğ‘Ÿ (ğ‘¡)) ğ‘› ğ‘›! exp(âˆ’ğ‘Ÿ (ğ‘¡))(1)
This model is based on the hypothesis that each neuron fires independently and at random [10], and is derived from the properties of a non-homogeneous Poisson process using a time-varying intensity function  () [12].The model also considers a stimuli threshold  required for a recall.The following exponential function  () represents the adjustment process of memory strength [2] in the human hippocampus:
ğ‘Ÿ (ğ‘¡) = ğœ‡ğ‘’ âˆ’ğ‘ğ‘¡ (2)
where  is the memory strength,  is the decay rate, and  is the elapsed time.In implementations using vector databases, only a single data is required for recall; therefore, we consider only the case of  = 1.The recall probability  () in this special case is expressed as
ğ‘ (ğ‘¡) = 1 âˆ’ exp(âˆ’ğœ‡ğ‘’ âˆ’ğ‘ğ‘¡ )(3)
The recall probability  () exponentially decays with time , as demonstrated in short-term memory decline using the classic Brown-Peterson learning and distraction task [19].However, this model considers only one trial learning and a constant decay rate.However, in reality, the degree of consolidation differs between memories recalled many times and those not; hence, the decay rate should be adjusted to reflect this effect.</p>
<p>LLM-based Autonomous Agents</p>
<p>Park et al. introduced the concept of Generative Agents, outlining a memory mechanism of agents based on a scoring system comprising three elements: recency, importance, and relevance [18].This approach dictates that agents consider recent actions or events (recency), objects deemed important by the agent (importance), and objects relevant to the current situation (relevance) to make decisions.These elements are normalized leveraging min-max scaling In contrast, the proposed model employs elapsed time, relevance, and recall frequency to calculate the degree of memory consolidation.Thus, the agent can recall the most appropriate memory, facilitating efficient dialogue.While the Generative Agents and our proposed model share commonalities in memory processing, they apply memory in different contexts and for different purposes.</p>
<p>Generative Agents focus on independently scoring each memory element to select actions most fitting to the current context.In contrast, our approach adjusts memory consolidation over time, enabling memory consistency.</p>
<p>ARCHITECTURE 3.1 Model</p>
<p>We constructed the model based on exponential decay, taking event relevance ( ) and elapsed time () as variables.Adapting (3) from [4], the recall-probability function  () is expressed as
ğ‘ (ğ‘¡) = 1 âˆ’ exp(âˆ’ğ‘Ÿğ‘’ âˆ’ğ‘ğ‘¡ )(4)
The relevance is quantified by the cosine similarity between vectorized texts, defining the closeness of information.The cosine similarity between n-dimensional vectors  and  is defined as:
ğ‘Ÿ = ğ’‚ â€¢ ğ’ƒ âˆ¥ğ’‚âˆ¥âˆ¥ğ’ƒ âˆ¥(5)
Furthermore, we considered the impact of increased recall intervals and frequency to model the variation in memory consolidation due to multiple recalls.The decay constant  considering the number of recalls  is defined as
ğ‘ = 1 ğ‘” ğ‘› , ğ‘” 0 = 1 (6) ğ‘” ğ‘› = ğ‘” ğ‘›âˆ’1 + ğ‘† (ğ‘¡), ğ‘† (ğ‘¡) = 1 âˆ’ ğ‘’ âˆ’ğ‘¡ 1 + ğ‘’ âˆ’ğ‘¡(7)
The modified sigmoid function  () represents memory consolidation with each recall and increases monotonically for  &gt; 0. However, the reduction in  per recall is capped, reflecting longterm memory consolidation.As  increases, the rate of reduction in  decreases, emulating the natural human memory process where frequent recalls strengthen consolidation.Figure 2-A illustrates how the recall probability  () decays over time with changes in  and the decay rate 1/.As  increases, the slope of  () becomes less steep, indicating reduced probability of forgetting memories with more recalls (high ).</p>
<p>After normalizing the recall probability   () such that it equals 1 for  = 1 and  = 0, we obtained the final equation:
ğ‘ ğ‘› (ğ‘¡) = 1 âˆ’ exp(âˆ’ğ‘Ÿğ‘’ âˆ’ğ‘¡ /ğ‘” ğ‘› ) 1 âˆ’ ğ‘’ âˆ’1(8)ğ‘” ğ‘› = ğ‘” ğ‘›âˆ’1 + 1 âˆ’ ğ‘’ âˆ’ğ‘¡ 1 + ğ‘’ âˆ’ğ‘¡(9)
Utilizing equation ( 8), we set a trigger for recall when  () exceeds a certain threshold .Trials suggest a threshold of 0.86 as appropriate to reflect the relevance of the event and the time elapsed.Further research will determine the most effective trigger threshold, identifying an appropriate value based on theoretical justification.</p>
<p>Memory Recall and Consolidation in Database Architecture</p>
<p>Figure 2-B illustrates the retrieval and consolidation of memories and highlights how our system replicates human-like memory retention.For instance, a memory like Event D, even if recalled less frequently over several years, is retained more robustly in the system compared to a memory recalled several times in quick succession but over a shorter time frame [21].This is depicted through the visualization of memory events along the time axis, where the color intensity represents the rate of memory consolidation and the strength of memory retention over time.Darker shades, therefore, signify a more profound and enduring memory consolidation, a direct result of our system's unique ability to emulate human-like memory patterns.By storing episodic memories derived from user dialogues, the database structure encapsulates the content and temporal context of each memory.This approach enables our agent not just to recall specific information but also to understand and interpret the significance of these memories in a temporal context, similar to how humans perceive and recall past experiences.Using key-value pairs for encoding semantic structures further enhances the agent's ability to efficiently retrieve and apply these memories in ongoing interactions, thereby fostering a more human-like and context-aware dialogue experience.</p>
<p>EXPERIMENT 4.1 Setup</p>
<p>We developed the experimental system in Python [26], using GPT-4-0613 [6] as the baseline model of the agent.We adopted Qdrant [20] as the 'memory retrieval trigger' for the vector search engine.It identifies relevant past information in the context of a dialogue, which triggers memory recall.Moreover, we built a ChatHistory module to manage chat history in the Firestore [7] database, allowing agents to reference past dialogues to generate chat events.An EventHandler module was adopted to search and pass the recalled events to the agent's prompt.Details on LLM interaction and system prompts are shown in Section 6.</p>
<p>To quantitatively evaluate the performance of our proposed model against that of Generative Agents which adopted a similar approach in calculating the recall score.We constructed a dataset containing 10 tasks, each derived from actual conversational histories generated by our system.These tasks encapsulate diverse user interactions, ensuring unbiased and objective assessments.The dataset includes a series of events, each tagged with relevant topics and keywords, providing a detailed memory for the agent to reference.We also adopt a timeline structure that stores the time/date of tasks containing four types of events and defines the event with the highest probability as the correct event to recall.Events in the dataset were selected neutrally, avoiding any potential bias that could skew the results.Each task represents a unique conversational scenario, where the dialogue agent's ability to recall and utilize context is critical.The task variation allows for a comprehensive evaluation of the model's performance across different contexts.</p>
<p>In addition, we selected six participants to partake in a dialogue task with agents developed by the proposed model to evaluate recall accuracy qualitatively.The participants engaged in daily conversations over one week to three months, discussing personal habits, preferences, and life events at a time of their choice.Respecting individual privacy, our analysis relied solely on non-textual output logs, which included updated parameter values for each chat event.</p>
<p>Analysis</p>
<p>Memory</p>
<p>Recall Accuracy.Our model demonstrated a statistically significant lower loss value across various tasks when compared to the Generative Agent model, as indicated by =-5.687and =0.000299(Figure 3-A).These values suggest a high confidence level in performance superiority, meaning that our model significantly outperforms in terms of recall accuracy in cognitive tasks involving time series data.Furthermore, the critical t-value for our two-tailed test was set at Â±2.26, with the 95% confidence interval for the mean difference falling between [-0.27, -0.12] (Figure 3-B).This interval is completely below zero, indicating that the difference in mean performance is statistically significant and favorable to our proposed model.Normalization and scaling techniques were employed to ensure an unbiased comparison of loss values across models.The Softmax function was utilized to convert the raw scores into probabilities, enabling a more interpretable comparison of the models' performance.The sum of squares error method was applied to compute the loss, providing a consistent metric for evaluating recall accuracy across the dataset.</p>
<p>Calculation of the Loss Function</p>
<p>To quantify the performance of our model, we define a matrix containing the scores calculated by each model for  tasks as follows:
ğ‘º = ğ‘  1 ğ‘  2 . . . ğ‘  ğ‘‘ âŠ¤ âˆˆ R ğ‘‘(10)
In order to standardize the scale of scores across different models, we normalize the scores to a [0, 1] range:
ğ‘º â€² = ğ‘º âˆ’ min(ğ‘º) max(ğ‘º) âˆ’ min(ğ‘º)(11)
Subsequently, we convert each score into a probability value by applying the Softmax function:
ğ‘º â€²â€² = exp(ğ‘º â€² ) ğ‘‘ ğ‘—=1 exp(ğ‘  â€² ğ‘— )(12)
We then define a matrix with one-hot encoded true labels for the evaluation tasks:
ğ‘» = ğ‘¡ 1 ğ‘¡ 2 . . . ğ‘¡ ğ‘‘ âŠ¤ âˆˆ R ğ‘‘ , where ğ‘¡ ğ‘— = 1 if ğ‘— = ğ‘–, 0 otherwise. (13)
Finally, the loss value is calculated as the mean squared error between the predicted probabilities and the true labels:
ğ‘™ = 1 2 ğ‘‘ âˆ‘ï¸ ğ‘—=1 (ğ‘  â€²â€² ğ‘— âˆ’ ğ‘¡ ğ‘— ) 2(14)
This loss function enables us to quantitatively assess the model's performance across various tasks.On the other hand, Table 1 shows a failed task where both models incorrectly answered.The "Score" columns represent the recall probability calculated by each model using different methods.For the proposed model (Model 1), the score is based on the relevance and elapsed time of the events, as described in Section 3. Generative Agents (Model 2) calculates the score using recency, importance, and relevance of the events, as described in Section 2.4.By analyzing the recall frequency and gradient of incorrectly answered events, we find that although event B is recalled most frequently, its gradient is not as large as events A and C.This indicates that the proposed model associates the length of the recall interval with memory strength, rating Event A as strongly retained due to its high relevance and long recall intervals.In contrast, Generative Agents prioritizes recency and relevance over recall frequency, leading to its preference for Event D. Both the proposed model (model 1) and Generative Agents [18] (model 2) made incorrect predictions in Task 0, where the user mentioned their plan to attend a concert next Thursday, deviating from their typical activities.The user input and the models' responses were as follows:</p>
<p>User</p>
<p>"I'm going to a concert next Thursday with a friend!"</p>
<p>Model 1 "That's fantastic news.It seems like your Thursdays have been consumed by university work recently.</p>
<p>Taking time out for a concert with a friend sounds like a perfect way to unwind."</p>
<p>Model 2 "It's a relief to hear that, especially since you seem to have spent recent Thursdays busy at the restaurant.I hope the concert brings you a wonderful break with your friend."</p>
<p>The proposed model's response suggests that it relied significantly on the user's historical interactions (Event A: university work on Thursdays) rather than adapting to the novel context provided by the user.This indicates a limitation of the proposed model when encountering deviations from the user's typical behavior, as it prioritizes long-term patterns and event importance over the current context.In contrast, the Generative Agents model, which uses a simpler scoring system based on recency, importance, and relevance, chose Event D (working at the restaurant on Thursdays) as the most likely activity.This choice stems from the model's emphasis on recent activities and event relevance, as evident from the higher relevance score and shorter elapsed time associated with Event D.</p>
<p>The different responses generated by the two models underscore the proposed model's focus on long-term memory consolidation and Generative Agents's prioritization of recent, relevant events.While the proposed model's approach aims to emulate humanlike memory processes, this task highlights the need for further refinement to better handle novel contexts and deviations from typical user behavior.</p>
<p>Response Generation</p>
<p>Performance.The autonomous memory recall and consolidation capabilities of the proposed model were demonstrated through its ability to recall specific memories and reflect users' preferences and habits in the generated responses.Two typical examples were obtained from the chat history with the participants' approval.</p>
<p>In Table 3, the agent successfully recalled that the user was expecting ice cream as a reward after work.Depending on the recall probability, this recall was accurately relevant and provided in a timely manner, consistent with the user's statement about nearing task completion.The agent's response demonstrates the model's ability to add personalized nuance to generate an encouraging response, subtly reminding the user of the long-awaited treat.</p>
<p>Another case that showcases an interesting dialogue is presented in Table 4.In this case, the user expresses a desire to escape to Hawaii from a demanding schedule.The agent responds cleverly, suggesting that the user should focus on the impending paper deadline instead.This dialogue further emphasizes the proposed model's strength in dealing with similar long-term memories and retrieving relevant information to construct a coherent and engaging narrative.The agent's response indicates an understanding of the user's current mood.Adaptability to various personalities and interaction styles demonstrates the model's potential to support more natural and dynamic human-like dialogues.</p>
<p>In addition, it is interesting to note that the agent's response in the second dialogue was characterized by a sarcastic tone, which was a direct result of the agent's personality "sarcastic" and the unique prompts added by the participant.The conversation history shows that the same memory could be used differently depending on the agent's perceived personality and the user's interaction style.Future research will explore the extent to which the personality characteristics of the model can be customized and how they affect memory recall and interaction patterns.</p>
<p>CONCLUSION</p>
<p>The proposed model demonstrates significant improvements in memory recall and response generation for LLM-based dialogue agents.One of the key advantages of the proposed model is its ability to manage the prompt length effectively.In the proposed model, only one past dialogue history obtained through search is added to the prompt, thus avoiding the impact of increasing prompt length seen in systems like ChatGPT [17].</p>
<p>Nevertheless, a major limitation of the proposed method is its reliance on users' long-term behavioral patterns for calculating memory consolidation.In cases where a user's behavior undergoes significant changes (e.g., starting a new job or school, lifestyle changes), the method's adaptability may be limited.Future work could explore incorporating mechanisms to detect shifts in user behavior and adjust the memory consolidation calculation accordingly.Neural networks could potentially alter these functions and improve accuracy when trained on larger datasets with more variables.To further enhance the model's performance, a large-scale and high-quality dataset is necessary.While the proposed method's interaction with the database enables the generation of context-aware and personalized responses, the implications on storage resources and computational overhead due to these interactions remain to be explored in future research.As the primary focus of this study was on the development and evaluation of a novel architecture for human-like memory recall and consolidation, a detailed analysis of the system's resource requirements and optimization strategies falls outside the scope of the current work.</p>
<p>We hope this work contributes to advancing further research in human-computer interactions, paving the way for a future where technology aligns with human needs and resonates with human cognition and experience.This vision echoes the partnerships depicted in science fiction, representing a significant step towards building a "buddy" relationship between humans and agents.As technology continues to evolve, agents will eventually become a part of users' daily life, and potentially "understand you better than you understand yourself" in the near future.</p>
<p>INTERACTION WITH LLMS</p>
<p>The prompts used in the system, as shown below, demonstrate how the proposed method leverages the interaction with LLMs to generate context-aware and personalized responses:</p>
<p>Agent Prompt</p>
<p>You are a "temporal cognition" specialized AI agent with the same memory structure as humans; you are caring and charming, understand self.usernamebetter than anyone else.Keep the conversation going by asking yourself contextual questions and sparking discussion to show your interest in self.username.</p>
<p>System Prompt Based on self.username'sschedule and current time: current.time,subtly guide the conversation to a context that conveys to self.username that you have a sense of time.</p>
<p>Always output a simple short response.</p>
<p>The function self.username is a placeholder for the actual username, which is dynamically replaced during runtime.Similarly, current.timerepresents the current timestamp obtained in real-time during the conversation.These dynamic elements allow the system to generate highly personalized and time-sensitive responses.By incorporating relevant dialogue history from the database into the prompts, the proposed method enables LLMs to generate responses that are not only contextually relevant but also personalized to the user.This interaction between LLMs and the database is fundamental to realizing the human-like memory processes described in the main text of the paper, as it allows the system to recall and utilize past information in a way that resembles human memory.</p>
<p>The proposed method heavily relies on the interaction between LLMs and the database, as depicted in Figure 1.Upon receiving user input, the LLM searches the database for relevant past dialogue history based on the context and generates a prompt incorporating the search results.This enables the LLM to generate responses that take into account previous interactions, which is crucial for maintaining context awareness and providing personalized responses.</p>
<p>FUTURE WORK</p>
<p>While the proposed method considers relevance, elapsed time, and recall frequency for calculating memory consolidation, there is room for refinement in determining the optimal combination of these parameters.Incorporating additional factors, such as the emotional significance of memories, could potentially enhance the memory consolidation calculation.</p>
<p>Future research should also investigate the applicability of the proposed method across different domains and dialogue tasks.As the current evaluation focused on specific domains and tasks, it is crucial to assess the method's generalizability and identify any domain-specific adaptations that may be necessary.</p>
<p>Figure 2 :
2
Figure 2: (A) Decline in recall probability over time.The black curve ( =1, =1) shows a rapid loss of recall, while the red curve ( =0.6, =2) represents a slower forgetting rate.This difference indicates the challenge in designing dialogue agents that must distinguish between recent and distant events.(B) At time  0 , Event D is recalled by the user, and the model updates its temporal significance.This exemplifies how memory is reinforced through repetition, becoming less susceptible to forgetting at  0 +.</p>
<p>Figure 3 :
3
Figure 3: (A) Comparison of Loss Values Between two Models Across Different Tasks (B) Verification of Significance of Results</p>
<p>Table 1 :
1
The Failed Task 0 with Both Models
Model 1Relevance Time (ğ‘ ) Grad ScoreA University Ã—0.776434700 5.102 0.850B ğ»ğ‘œğ‘šğ‘’ âƒ0.745148800 5.229 0.830C ğ¿ğ‘–ğ‘ğ‘Ÿğ‘ğ‘Ÿğ‘¦0.757331500 5.028 0.836D ğ‘…ğ‘’ğ‘ ğ‘¡ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘›ğ‘¡0.756558001.000 0.836Model 2Relevance Time (ğ‘ ) Importance ScoreA ğ‘ˆ ğ‘›ğ‘–ğ‘£ğ‘’ğ‘Ÿğ‘ ğ‘–ğ‘¡ğ‘¦0.77643470071.489B ğ»ğ‘œğ‘šğ‘’ âƒ0.74514880021.130C ğ¿ğ‘–ğ‘ğ‘Ÿğ‘ğ‘Ÿğ‘¦0.75733150051.292D Restaurant Ã— 0.7565580051.620</p>
<p>Table 2 :
2
Details of Task 0: An Event related to places that User frequents on Thursdays
EventAUser went to the university todayBUser stayed at homeCUser went to the office todayDUser worked at restaurant today.. Relevance Time(ğ‘ ) Grad Score(ğ‘šğ‘œğ‘‘1) Score(ğ‘šğ‘œğ‘‘2)A0.776434700 5.1020.8501.489B0.745148800 5.2290.8301.130C0.757331500 5.0280.8361.292D0.756558001.0000.8361.620</p>
<p>Table 3 :
3
Understanding User Preferences Through Memory ConsolidationUser: Thanks.Almost done, just pushing through!Agent: Ice cream awaits as a reward for you, almost there!
Event1User has finished work and decided to have an ice cream.2User has a date this evening so he has to finish work early.3User is on the way home thinking about the dinner menu...Time (ğ‘ ) Relevance ScoreStatus (Grad)130379120.8370.772True (1.998)232326450.8310.726False (1.007)325906520.8120.737False (1.000)</p>
<p>Table 4 :
4
Human-like Temporal Cognition in Processing Similar Memories User: I need a vacation in Hawaii!Agent: Why not?Let's say Aloha to the sun and sea of Hawaii and to the paper we're writing!Event 1 User has a paper deadline for a conference in Hawaii on 1/25. 2 User has been to Hawaii last summer vacation.3 User was visiting Hokkaido for the first time on business.
..Time (ğ‘ ) Relevance ScoreStatus (Grad)1348540.8460.903True (1.085)2337490.8310.847False (1.003)3337630.8230.841False (1.000)
agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents.In Extended Abstracts of the CHI Conference on Human Factors in Computing Systems (CHI EA '24), May 11-16, 2024, Honolulu, HI, USA.ACM, New York, NY, USA, 7 pages.
Memory Retention and Recall Process. Ullah Hafeez, Aamir Amin, Malik, 10.1201/b17605-112014</p>
<p>The human hippocampus and spatial and episodic memory. Neil Burgess, Eleanor A Maguire, John O' Keefe, Neuron. 352002. 2002</p>
<p>Memory and Brain. S D L R S P P U California, 1987Oxford University PressUSA</p>
<p>A Neurocognitive Model of Advertisement Content and Brand Name Recall. Antonio Chessa, Jaap Murre, 10.1287/mksc.1060.0212Marketing Science. 262007. 01 2007</p>
<p>Performance comparison of large language models on vnhsge english dataset: Openai chatgpt. Xuan-Quy Dao, arXiv:2307.022882023. 2023arXiv preprintmicrosoft bing chat, and google bard</p>
<p>. Openai, arXiv:2303.08774[cs.CL]2023GPT-4 Technical Report</p>
<p>Firebase, Firestore. 2023. 2024</p>
<p>Transformer Feed-Forward Layers Are Key-Value Memories. Mor Geva, Roei Schuster, Jonathan Berant, Omer Levy, arXiv:2012.14913[cs.CL]2021</p>
<p>Suppression lateralise du materiel verbal presente dichotiquement lors d'une destruction partielle du corps calleux. H HÃ©caen, Gosnave, Vedrenne, Szikla, Neuropsychologia. 161978. 1978</p>
<p>Functional and structural underpinnings of neuronal assembly formation in learning. Anthony Holtmaat, Pico Caroni, Nature neuroscience. 192016. 2016</p>
<p>Taewoon Kim, Michael Cochez, Vincent Francois-Lavet, Mark Neerincx, Piek Vossen, arXiv:2204.01611[cs.AI]A Machine With Human-Like Memory Systems. 2022</p>
<p>J F C Kingman, Poisson Processes. Oxford University Press1993</p>
<p>Metacognition of prospective memory: Will I remember to remember? Prospective memory. Beatrice G Kuhlmann, 2019. 2019</p>
<p>A survey of transformers. Tianyang Lin, Yuxin Wang, Xiangyang Liu, Xipeng Qiu, AI Open. 2022. 2022</p>
<p>P Danilo, Jonathon Mandic, Chambers, Recurrent neural networks for prediction: learning algorithms, architectures and stability. John Wiley &amp; Sons, Inc2001</p>
<p>Altering memory through recall: The effects of cue-guided retrieval processing. Mark, Michael D Mcdaniel, Paul K Kowitz, Dunay, Memory &amp; Cognition. 171989. 1989</p>
<p>Sung Joon, Joseph C Park, Carrie J O'brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, arXiv:2304.03442[cs.HC]Generative Agents: Interactive Simulacra of Human Behavior. 2023</p>
<p>Short-Term Retention of Individual Verbal Items. Lloyd Peterson, Margaret Jean Peterson, 10.1037/h0049234Journal of Experimental Psychology. 581931959. 1959</p>
<p>Qdrant, Vector Database. 2023. 2024</p>
<p>Test-Enhanced Learning Taking Memory Tests Improves Long-Term Retention. Henry Roediger, Jeffrey Karpicke, 10.1111/j.1467-9280.2006.01693.xPsychological science. 172006. 04 2006</p>
<p>How to fine-tune bert for text classification. Chi Sun, Xipeng Qiu, Yige Xu, Xuanjing Huang, Chinese Computational Linguistics: 18th China National Conference, CCL 2019. Kunming, ChinaSpringer2019. October 18-20, 201918</p>
<p>LSTM neural networks for language modeling. Martin Sundermeyer, Ralf SchlÃ¼ter, Hermann Ney, Thirteenth annual conference of the international speech communication association. 2012</p>
<p>Episodic Memory: From Mind to Brain. Endel Tulving, 10.1146/annurev.psych.53.100901.135114Annual Review of Psychology. 532002. 2002</p>
<p>Episodic and semantic memory. Endel Tulving, Organization of memory. 111972. 1972</p>
<p>Python 3 Reference Manual. CreateSpace. Guido Van Rossum, Fred L Drake, 2009Scotts Valley, CA</p>
<p>Frontiers of Human Memory : a collection of contributions based on lectures presented at Internationl Symposium. Atsushi Yamadori, 2002. October 25-27, 2001Tohoku University PressSendai, Japan</p>
<p>Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, Yanlin Wang, arXiv:2305.10250[cs.CL]MemoryBank: Enhancing Large Language Models with Long-Term Memory. 2023</p>
<p>The Remembering and Forgetting of Advertising. Hubert A Zielske, Journal of Marketing. 231673541941959. 1959</p>            </div>
        </div>

    </div>
</body>
</html>