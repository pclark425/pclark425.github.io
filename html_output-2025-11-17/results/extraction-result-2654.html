<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2654 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2654</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2654</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-68.html">extraction-schema-68</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <p><strong>Paper ID:</strong> paper-76e31cac217d8af2dc91b6dbe5265c8066fffa46</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/76e31cac217d8af2dc91b6dbe5265c8066fffa46" target="_blank">Accelerating science with human versus alien artificial intelligences</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> It is shown that incorporating the distribution of human expertise into self-supervised models by training on inferences cognitively available to experts dramatically improves AI prediction of future human discoveries and inventions.</p>
                <p><strong>Paper Abstract:</strong> Data-driven artificial intelligence models fed with published scientific findings have been used to create powerful prediction engines for scientific and technological advance, such as the discovery of novel materials with desired properties and the targeted invention of new therapies and vaccines. These AI approaches typically ignore the distribution of human prediction engines -- scientists and inventor -- who continuously alter the landscape of discovery and invention. As a result, AI hypotheses are designed to substitute for human experts, failing to complement them for punctuated collective advance. Here we show that incorporating the distribution of human expertise into self-supervised models by training on inferences cognitively available to experts dramatically improves AI prediction of future human discoveries and inventions. Including expert-awareness into models that propose (a) valuable energy-relevant materials increases the precision of materials predictions by ~100%, (b) repurposing thousands of drugs to treat new diseases increases precision by 43%, and (c) COVID-19 vaccine candidates examined in clinical trials by 260%. These models succeed by predicting human predictions and the scientists who will make them. By tuning AI to avoid the crowd, however, it generates scientifically promising "alien" hypotheses unlikely to be imagined or pursued without intervention, not only accelerating but punctuating scientific advance. By identifying and correcting for collective human bias, these models also suggest opportunities to improve human prediction by reformulating science education for discovery.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2654.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2654.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Expert-aware hypergraph RW</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Expert-aware mixed hypergraph random-walk discovery model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A discovery system that constructs a mixed hypergraph of materials, properties and disambiguated authors and runs biased random walks to estimate transition probabilities and induce similarities that predict which material-property links humans are likely to discover next.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Expert-aware mixed hypergraph random-walk model</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Constructs a mixed hypergraph whose nodes represent materials (or drugs), properties (desired functions) and disambiguated authors; hyperedges are articles linking the set of nodes mentioned in a paper. The system performs large numbers (250k) of truncated, non-lazy random walks (length up to 20) starting from a property node, with a biased node-selection parameter alpha that changes the relative sampling probability of conceptual nodes vs authors. From the sampled walk sequences it computes multi-step Markovian transition probabilities between nodes and derives similarity scores (average transition probability across 1–2 or more steps). These transition probabilities and derived similarities are used to rank candidate materials/drugs by their likelihood of being discovered or championed by human scientists.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>knowledge graph-based (hypergraph) with Markov random-walks</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science, biomedicine (drug repurposing), vaccine/therapy discovery (COVID-19)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates hypotheses by ranking candidate material/property (or drug/disease) pairs according to hypergraph-induced relevance: (a) transition probability from property node to candidate via random-walk-derived Markov transition matrices, and (b) candidates' proximity in embedding space induced by random-walk sequences. Top-ranked items are proposed as hypotheses (50 per experiment).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Novelty (human unavailability) is operationalized via graph distance / expert-density measures: Jaccard index of shared experts, shortest-path distance (SP-d) from the property node, and low density regions of the expert distribution; these measure how cognitively unavailable a candidate is to existing human expertise.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility is assessed externally by domain-theory indicators: for materials, density-functional-theory-derived Power Factor (PF); for COVID-19, protein-protein interaction proximity to SARS-CoV-2 targets from prior network-medicine rankings; also semantic proximity in content-only embeddings (word2vec) used as an approximate plausibility score when theory-driven metrics are unavailable.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Trade-off is handled by ranking functions combining human-availability (or alienness) and scientific-plausibility scores (e.g., normalized SP-d vs embedding similarity) using a mixing coefficient beta (range [-1,1]); increasing beta emphasizes alien (cognitively unavailable) hypotheses, decreasing beta emphasizes plausibility and human-familiar hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Precision of top-K (K=50) predicted candidate lists measured against ground-truth first-time co-occurrences in the literature or ClinicalTrials.gov; additional plausibility metrics include Power Factor (PF) distributions and PPI proximity / aggregated ensemble ranks from prior network-medicine methods. Expert-density (Jaccard index) and time-to-discovery correlations are used to characterize predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Validation against historical ground truth: (1) predicted top-50 ranked candidates compared to actual first-time published material-property co-occurrences (energy materials dataset) across multiple prediction years; (2) predicted drug-disease associations compared to curated Comparative Toxicogenomics Database (CTD) associations; (3) COVID-19 therapy/vaccine candidates validated by whether they entered clinical trials (ClinicalTrials.gov) within defined windows. The system also evaluates predicted candidates with domain-theory scores (PF, PPI proximity) as computational plausibility checks.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Uses publicly described corpora (Tshitoyan et al. materials corpus and MEDLINE), author-disambiguation via Scopus and PubMed Knowledge Graph, fixed random-walk sampling counts and walk lengths, documented alpha sampling parameter, and explicit training hyperparameters for embedding/skipgram models; code-level protocols are described in Methods (but no external code repository is reported in-text).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Implicit uncertainty expressed as probabilistic transition scores (Markov transition probabilities) and embedding similarity magnitudes; no formal Bayesian uncertainty quantification or confidence intervals reported.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>1.5M inorganic materials articles (Tshitoyan et al. dataset), MEDLINE (>28M articles), DrugBank (pool ~4k drugs), Comparative Toxicogenomics Database (CTD) for ground truth drug-disease links, ClinicalTrials.gov for COVID-19 trial validation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Materials predictions: accounting for experts outperformed content-only baselines by ~100% average increase in precision across thermoelectricity, ferroelectricity and photovoltaic predictions (17 prediction years). Drug repurposing: hypergraph method yielded 43% higher precision than content-only model (evaluated 19 years post-prediction). COVID-19: deepwalk-based and transition-probability metrics produced 36% and 38% of top predictions entering trials within 12 months (vs ~10% precision for content-only semantic baseline); reported as 350–400% relative improvement. Correlation of prediction precision with drug literature occurrence r=0.74 (p<0.001).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Compared to content-only word2vec baselines and prior work (Tshitoyan et al.): hypergraph models (with authors) significantly outperform content-only baselines (average ~100% higher precision for materials, 43% higher for drug repurposing, 350–400% relative improvement for COVID-19 trial-entry predictions). Transition-probability and deepwalk-based hypergraph metrics both outperform semantic-only embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>The system retrospectively predicted therapies that later entered clinical trials (e.g., progesterone trial path is reproducible in random-walk traces); predictions include many candidates that later became published discoveries or trialed therapies, but the paper does not claim prospective experimental discoveries validated by new wet-lab experiments within this study.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Relies on author-disambiguation and accurate metadata; performance correlated with frequency of drugs/materials in literature (works better for frequently-mentioned entities); embedding-based features can limit exploration (noted for GraphSAGE using word2vec features); plausibility assessment depends on external theory-driven scores (DFT PF, PPI proximity) which are not always available; ethical/strategic implications of generating 'alien' hypotheses are noted but not fully addressed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerating science with human versus alien artificial intelligences', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2654.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2654.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepWalk-hypergraph</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeepWalk (skip-gram) embeddings trained on random walks over the mixed hypergraph</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An unsupervised node embedding method that treats truncated random-walk sequences over the mixed hypergraph as sentences and trains a skip-gram Word2Vec model to embed materials and properties into a continuous vector space reflecting hypergraph-induced relatedness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DeepWalk-based hypergraph embedding (skip-gram Word2Vec over sampled walks)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Trains a skip-gram Word2Vec model (embedding dimensionality 200, window size 8, negative sampling 15, initial LR 0.01 decaying to 0.001) on truncated random-walk sequences sampled from the mixed hypergraph where author nodes are included in walk sampling but authors are removed from tokens used to train the discovery embedding (training over property/material tokens only). Produces continuous vectors; dot-product/cosine similarity used to rank candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>unsupervised embedding (graph embedding via random walks / language-model skip-gram)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science, biomedical literature analysis</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Hypotheses generated by nearest-neighbor ranking in embedding space: candidates with highest cosine similarity to the property node embedding are proposed.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Novelty inferred from embedding distance and expert-density topology (low embedding proximity and low expert-density regions flagged as novel), but no separate novelty classifier is used.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility approximated by embedding proximity (semantic relevance) and complemented by external theoretical indicators (PF, PPI) for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Not an explicit balance mechanism within deepwalk alone; balance is achieved in the larger pipeline via combination with human-availability (SP-d) and mixing coefficient beta in the AAI framework.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Precision@50 (top-50), PR-AUC and ROC-AUC reported in Extended Data for various tasks; specific numbers reported in aggregate (e.g., content-only baseline precision ~10% for COVID-19).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Historical validation by comparing top-K embedding neighbors to subsequent first-time co-occurrences and clinical-trial entries; PR and PR-AUC used for evaluation in Extended Data.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Embedding hyperparameters and corpus construction described; walk sampling settings provided (250k walks, walk length 20).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Similarity scores and ranking; no formal confidence intervals.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Same corpora: 1.5M materials articles, MEDLINE, DrugBank, CTD, ClinicalTrials.gov.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Embedding-only (content) baseline had lower precision: for COVID-19 predictions content-only precision ~10% (12-month), while deepwalk-hypergraph achieved 36–38% (when including experts). For energy materials, content-only word2vec baselines were outperformed by ~100% when expert-aware deepwalk was used.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>DeepWalk over hypergraph (authors included) outperformed content-only word2vec baselines substantially; embedding trained on author-less graph performed worse than when authors were included.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Embedding quality depends on walk sampling and hypergraph composition; training used fewer epochs for deepwalk than baseline due to smaller token vocabularies which may influence representation; by itself, embedding does not explicitly quantify novelty vs plausibility without additional modules.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerating science with human versus alien artificial intelligences', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2654.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2654.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transition-probability metric</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hypergraph-induced Markov transition probability similarity metric</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A relevance metric computed from multi-step Markov transition probabilities on the mixed hypergraph that estimates the likelihood a random walker travels between nodes in a small fixed number of steps, used to predict cognitive availability of inferences.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Multi-step Markov transition probability similarity</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Computes direct and multistep transition probabilities from transition matrices derived from the biased random-walk process on the hypergraph (Bayesian rules and Markovian assumptions). Similarity between nodes is defined as the (log of the) average transition probability over 1–2 (or more) steps; used as a local hypergraph-structure-based relevance score.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>probabilistic graph-similarity metric (Markov chain)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science, biomedical literature</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Rank candidates by transition-probability-based relevance to the property node (high transition probability -> candidate more likely to be discovered by researchers).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Novelty identified as low transition-probability / large shortest-path distances and low expert-density (Jaccard) values.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility not directly assessed by transition probabilities; combined with embedding or external theory-driven scores for plausibility evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Used as the 'human-availability' component in the AAI weighted composition with plausibility scores via beta mixing.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Precision@50 (top-50) when ranking by transition probability; histograms of similarity used for sanity checks (e.g., Nature Medicine vs Applied Optics authors relative to 'coronavirus').</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Validated historically against subsequent discoveries and clinical trials; transition-probability-based predictions achieved similar gains to deepwalk in COVID-19 trial-prediction experiments (e.g., ~38% trial-entry precision within 12 months).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Walk sampling counts, walk lengths, and alpha parameter documented; transition computation described as direct from transition matrices (Supplementary Information).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Uses probabilities from transition matrices as a form of score uncertainty; no formal CI or Bayesian posterior reported.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Same corpora as main system (materials corpus, MEDLINE, DrugBank, CTD, ClinicalTrials.gov).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Achieved ~38% of top predictions entering COVID-19 trials within 12 months (vs ~10% baseline), and similar improvements in materials predictions over content-only baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Outperformed content-only semantic baselines and matched deepwalk-based hypergraph embeddings in predictive performance; both hypergraph approaches outperform baselines that omit authors.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Local transition-probability metric is more local (short-range) than deepwalk; may miss more global structural signals unless multi-step transitions are considered.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerating science with human versus alien artificial intelligences', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2654.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2654.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GraphSAGE-GCN variant</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph Sample and Aggregate (GraphSAGE) graph convolutional neural network embedding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph convolutional neural network (GraphSAGE) used as an alternative embedding method: Word2Vec baseline embeddings supply node features, GraphSAGE encodes nodes via neighborhood aggregation and an inner-product decoder to produce link-prediction scores and candidate rankings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GraphSAGE-based graph convolutional embedding (graph auto-encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses Word2Vec content embeddings as input features for materials and property nodes, a GraphSAGE encoder with hidden dim 400 and output dim 200 (ReLU activations), and an inner-product decoder trained with an unsupervised link-prediction loss to obtain latent node vectors. Candidate ranking by cosine similarity to property node in encoder output space. The model was trained on both the full hypergraph (with authors) and an author-less variant to measure the effect of experts.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>graph convolutional neural network (inductive GNN)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science (energy-related properties)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates hypotheses by ranking nodes with highest cosine similarity to the property node in the learned encoder embedding space.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>No explicit novelty classifier; novelty arises from graph structural position and output embedding distances (less proximity can indicate novelty).</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility not inherent; external DFT PF scores used for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Not explicit within GraphSAGE; overall pipeline can combine GraphSAGE output with human-availability/plausibility scores externally.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Precision@50 reported for GraphSAGE on energy properties.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Historical evaluation against known discoveries. Reported precisions: on full graph GraphSAGE achieved 62%, 58%, 74% for thermoelectricity, ferroelectricity and photovoltaics respectively; on author-less graph it achieved 48%, 50%, 58% respectively, demonstrating author-node contribution.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Model hyperparameters and feature construction (word2vec features) described; training loss described as unsupervised link-prediction loss.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Embeddings and similarity scores used as deterministic rankings; no explicit UQ.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>1.5M inorganic materials articles dataset (same as other experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>GraphSAGE full-graph precisions: thermoelectricity 62%, ferroelectricity 58%, photovoltaics 74%; author-less graph precisions: 48%, 50%, 58% respectively; indicates 10-20 percentage point improvement from including authors.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>GraphSAGE with authors outperformed the author-less variant and matched the qualitative pattern of deepwalk results (though margins smaller likely due to use of word2vec features limiting exploration).</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires feature vectors for nodes; authors used word2vec baseline embeddings as features which can restrict novelty exploration; performance dependent on quality of input features and graph construction.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerating science with human versus alien artificial intelligences', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2654.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2654.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Alien AI (AAI) framework</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Alien Artificial Intelligence (AAI) mixing human-availability and scientific plausibility</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that explicitly trades off human cognitive availability against scientific plausibility to produce 'alien' hypotheses: candidates least available to human experts but still predicted to be scientifically promising.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Alien AI (AAI) mixing human unavailability and scientific plausibility with coefficient beta</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Computes two component scores per candidate: (1) human unavailability / alienness measured via shortest-path distance (SP-d) from the property node and expert-density metrics (e.g., Jaccard index), and (2) scientific plausibility measured via semantic similarity (word2vec) or theory-driven metrics (DFT Power Factor for thermoelectrics, PPI proximity for COVID-19). Scores are transformed (Van der Waerden normalization) to make distributions comparable, then linearly combined as Z-score weighted average with mixing coefficient beta in [-1,1]. Beta controls emphasis on alienness (positive) or human familiarity (negative); the combined score s ranks candidates for disruptive discovery recommendation.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>hybrid knowledge-graph + embedding + normalization-based ranking framework</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science (thermoelectrics), biomedicine (COVID-19 drug/vaccine repurposing)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates hypotheses by ranking candidates according to the weighted composite score s = (1-?) combination of normalized alienness and plausibility (Van der Waerden-transformed Z-scores) and selecting top-K; varying beta yields families of hypotheses from human-familiar to highly alien.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Explicit novelty measure: shortest-path distance (SP-d) and low expert-density (Jaccard index) quantify cognitive unavailability; candidates in distant or disconnected orbits are flagged as novel/alien.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility evaluated via domain-specific theory-driven metrics used only for evaluation (PF from DFT for thermoelectricity; aggregated ensemble PPI ranks from Gysi et al. for COVID-19) or approximated by word2vec proximity when theory scores are unavailable.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Directly controlled by mixing coefficient beta: beta=0 emphasizes plausibility only; beta=1 maximizes alienness (avoid human familiarity regardless of plausibility); intermediate beta trades off exploration vs exploitation to find alien yet plausible candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Composite score s (normalized Z combination), Precision@50 for ranked outputs, Power Factor distributions and PPI proximity used to measure scientific plausibility across SP-d orbits; authors visualized PF as a function of SP-d to show many high-PF candidates lie in distant orbits.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>AAI outputs were retrospectively evaluated: (1) PF (DFT) distributions for thermoelectricity candidates across SP-d orbits; (2) PPI proximity aggregated ranks for COVID-19 candidates. Also measured how increasing beta moves candidates to more disconnected regions while preserving PF/PPI plausibility up to moderate beta values.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Describes normalization (Van der Waerden) and linear composition method; reports how beta varies and how candidates are selected (50 per beta).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Scores are normalized to Z-scores (after Van der Waerden transform) giving standardized magnitudes but no probabilistic confidence intervals; no explicit Bayesian UQ reported.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Same corpora (materials articles dataset, MEDLINE, DrugBank); DFT PF databases and Gysi et al. aggregated PPI ranks used for plausibility evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AAI experiments show that as beta increases, candidate lists move to more cognitively distant or disconnected SP-d orbits while retaining strong PF or PPI plausibility for moderate beta; exact numeric trade-offs presented in figures (PF vs SP-d plots) rather than single scalar metrics. Demonstrated that intermediate beta values yield alien candidates with strong theoretical plausibility.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>AAI contrasted with beta=0 (plausibility-only) and beta negative (imitating humans); AAI with positive beta produces candidates less likely to be discovered by humans but with comparable theoretical plausibility, outperforming human-only exploration in novelty while preserving plausibility vs content-only baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>No prospective experimental validations reported; retrospective evaluation shows many high-PF candidates in distant orbits and some AAI predictions correspond to plausible COVID-19 repurposings per PPI proximity rankings.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Combination approach uses relatively simple linear weighting and normalization (Van der Waerden) which may be suboptimal; theoretical plausibility metrics were used only for evaluation (not in deployed ranking) and may not exist for many domains; choosing beta requires a policy decision and could produce ethically or practically risky 'disorienting' hypotheses; no formal mechanism for handling false positives or hallucinations is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerating science with human versus alien artificial intelligences', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2654.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2654.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Word2Vec baseline (content-only)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Content-only skip-gram Word2Vec model trained on article textual content</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A content-exclusive baseline that trains word2vec-style embeddings on article text (titles/abstracts), ignoring author/expert metadata; used as the baseline semantic model for candidate ranking.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Content-only word2vec semantic embedding baseline</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Trains a skip-gram Word2Vec model on textual co-occurrence sequences derived from articles (no author nodes); uses same embedding hyperparameters as deepwalk baseline (window size 8, negative sampling 15, embedding dim 200) and ranks candidates by cosine similarity to the property token embedding.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>unsupervised embedding (word2vec)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science, biomedical literature</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Ranks candidate materials/drugs by semantic proximity in word2vec embedding space to the target property term.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility is approximated by semantic proximity in embedding space (higher similarity interpreted as more plausible).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Precision@50, PR-AUC reported as baseline metrics; COVID-19 content-only precision ~10% for 12-month trial-entry evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Validated historically against subsequent discoveries, used as baseline for comparisons to hypergraph/expert-aware models.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Embedding hyperparameters and training regimen documented; corpus explained.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Similarity scores used as ranks; no explicit UQ.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Same corpora as other experiments when applied (materials corpus, MEDLINE).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Content-only baseline precision: ~10% 12-month COVID-19 trial-entry precision; substantially lower than hypergraph expert-aware models (36–38%). For energy materials the content-only baselines were outperformed by ~100% when author information was included.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Ignores author/expert distribution and social structure; performs worse when the distribution of expert attention strongly conditions discovery likelihood; produces more uniformly distributed predictions that do not concentrate near expert-density peaks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerating science with human versus alien artificial intelligences', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Unsupervised word embeddings capture latent knowledge from materials science literature <em>(Rating: 2)</em></li>
                <li>DeepWalk: Online Learning of Social Representations <em>(Rating: 2)</em></li>
                <li>Inductive Representation Learning on Large Graphs <em>(Rating: 2)</em></li>
                <li>Efficient Estimation of Word Representations in Vector Space <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2654",
    "paper_id": "paper-76e31cac217d8af2dc91b6dbe5265c8066fffa46",
    "extraction_schema_id": "extraction-schema-68",
    "extracted_data": [
        {
            "name_short": "Expert-aware hypergraph RW",
            "name_full": "Expert-aware mixed hypergraph random-walk discovery model",
            "brief_description": "A discovery system that constructs a mixed hypergraph of materials, properties and disambiguated authors and runs biased random walks to estimate transition probabilities and induce similarities that predict which material-property links humans are likely to discover next.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Expert-aware mixed hypergraph random-walk model",
            "system_description": "Constructs a mixed hypergraph whose nodes represent materials (or drugs), properties (desired functions) and disambiguated authors; hyperedges are articles linking the set of nodes mentioned in a paper. The system performs large numbers (250k) of truncated, non-lazy random walks (length up to 20) starting from a property node, with a biased node-selection parameter alpha that changes the relative sampling probability of conceptual nodes vs authors. From the sampled walk sequences it computes multi-step Markovian transition probabilities between nodes and derives similarity scores (average transition probability across 1–2 or more steps). These transition probabilities and derived similarities are used to rank candidate materials/drugs by their likelihood of being discovered or championed by human scientists.",
            "system_type": "knowledge graph-based (hypergraph) with Markov random-walks",
            "scientific_domain": "materials science, biomedicine (drug repurposing), vaccine/therapy discovery (COVID-19)",
            "hypothesis_generation_method": "Generates hypotheses by ranking candidate material/property (or drug/disease) pairs according to hypergraph-induced relevance: (a) transition probability from property node to candidate via random-walk-derived Markov transition matrices, and (b) candidates' proximity in embedding space induced by random-walk sequences. Top-ranked items are proposed as hypotheses (50 per experiment).",
            "novelty_assessment_method": "Novelty (human unavailability) is operationalized via graph distance / expert-density measures: Jaccard index of shared experts, shortest-path distance (SP-d) from the property node, and low density regions of the expert distribution; these measure how cognitively unavailable a candidate is to existing human expertise.",
            "plausibility_assessment_method": "Plausibility is assessed externally by domain-theory indicators: for materials, density-functional-theory-derived Power Factor (PF); for COVID-19, protein-protein interaction proximity to SARS-CoV-2 targets from prior network-medicine rankings; also semantic proximity in content-only embeddings (word2vec) used as an approximate plausibility score when theory-driven metrics are unavailable.",
            "novelty_plausibility_balance": "Trade-off is handled by ranking functions combining human-availability (or alienness) and scientific-plausibility scores (e.g., normalized SP-d vs embedding similarity) using a mixing coefficient beta (range [-1,1]); increasing beta emphasizes alien (cognitively unavailable) hypotheses, decreasing beta emphasizes plausibility and human-familiar hypotheses.",
            "hypothesis_quality_metrics": "Precision of top-K (K=50) predicted candidate lists measured against ground-truth first-time co-occurrences in the literature or ClinicalTrials.gov; additional plausibility metrics include Power Factor (PF) distributions and PPI proximity / aggregated ensemble ranks from prior network-medicine methods. Expert-density (Jaccard index) and time-to-discovery correlations are used to characterize predictions.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Validation against historical ground truth: (1) predicted top-50 ranked candidates compared to actual first-time published material-property co-occurrences (energy materials dataset) across multiple prediction years; (2) predicted drug-disease associations compared to curated Comparative Toxicogenomics Database (CTD) associations; (3) COVID-19 therapy/vaccine candidates validated by whether they entered clinical trials (ClinicalTrials.gov) within defined windows. The system also evaluates predicted candidates with domain-theory scores (PF, PPI proximity) as computational plausibility checks.",
            "reproducibility_measures": "Uses publicly described corpora (Tshitoyan et al. materials corpus and MEDLINE), author-disambiguation via Scopus and PubMed Knowledge Graph, fixed random-walk sampling counts and walk lengths, documented alpha sampling parameter, and explicit training hyperparameters for embedding/skipgram models; code-level protocols are described in Methods (but no external code repository is reported in-text).",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Implicit uncertainty expressed as probabilistic transition scores (Markov transition probabilities) and embedding similarity magnitudes; no formal Bayesian uncertainty quantification or confidence intervals reported.",
            "benchmark_dataset": "1.5M inorganic materials articles (Tshitoyan et al. dataset), MEDLINE (&gt;28M articles), DrugBank (pool ~4k drugs), Comparative Toxicogenomics Database (CTD) for ground truth drug-disease links, ClinicalTrials.gov for COVID-19 trial validation.",
            "performance_metrics": "Materials predictions: accounting for experts outperformed content-only baselines by ~100% average increase in precision across thermoelectricity, ferroelectricity and photovoltaic predictions (17 prediction years). Drug repurposing: hypergraph method yielded 43% higher precision than content-only model (evaluated 19 years post-prediction). COVID-19: deepwalk-based and transition-probability metrics produced 36% and 38% of top predictions entering trials within 12 months (vs ~10% precision for content-only semantic baseline); reported as 350–400% relative improvement. Correlation of prediction precision with drug literature occurrence r=0.74 (p&lt;0.001).",
            "comparison_with_baseline": "Compared to content-only word2vec baselines and prior work (Tshitoyan et al.): hypergraph models (with authors) significantly outperform content-only baselines (average ~100% higher precision for materials, 43% higher for drug repurposing, 350–400% relative improvement for COVID-19 trial-entry predictions). Transition-probability and deepwalk-based hypergraph metrics both outperform semantic-only embeddings.",
            "validated_on_real_science": true,
            "novel_discoveries": "The system retrospectively predicted therapies that later entered clinical trials (e.g., progesterone trial path is reproducible in random-walk traces); predictions include many candidates that later became published discoveries or trialed therapies, but the paper does not claim prospective experimental discoveries validated by new wet-lab experiments within this study.",
            "limitations": "Relies on author-disambiguation and accurate metadata; performance correlated with frequency of drugs/materials in literature (works better for frequently-mentioned entities); embedding-based features can limit exploration (noted for GraphSAGE using word2vec features); plausibility assessment depends on external theory-driven scores (DFT PF, PPI proximity) which are not always available; ethical/strategic implications of generating 'alien' hypotheses are noted but not fully addressed.",
            "uuid": "e2654.0",
            "source_info": {
                "paper_title": "Accelerating science with human versus alien artificial intelligences",
                "publication_date_yy_mm": "2021-04"
            }
        },
        {
            "name_short": "DeepWalk-hypergraph",
            "name_full": "DeepWalk (skip-gram) embeddings trained on random walks over the mixed hypergraph",
            "brief_description": "An unsupervised node embedding method that treats truncated random-walk sequences over the mixed hypergraph as sentences and trains a skip-gram Word2Vec model to embed materials and properties into a continuous vector space reflecting hypergraph-induced relatedness.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "DeepWalk-based hypergraph embedding (skip-gram Word2Vec over sampled walks)",
            "system_description": "Trains a skip-gram Word2Vec model (embedding dimensionality 200, window size 8, negative sampling 15, initial LR 0.01 decaying to 0.001) on truncated random-walk sequences sampled from the mixed hypergraph where author nodes are included in walk sampling but authors are removed from tokens used to train the discovery embedding (training over property/material tokens only). Produces continuous vectors; dot-product/cosine similarity used to rank candidates.",
            "system_type": "unsupervised embedding (graph embedding via random walks / language-model skip-gram)",
            "scientific_domain": "materials science, biomedical literature analysis",
            "hypothesis_generation_method": "Hypotheses generated by nearest-neighbor ranking in embedding space: candidates with highest cosine similarity to the property node embedding are proposed.",
            "novelty_assessment_method": "Novelty inferred from embedding distance and expert-density topology (low embedding proximity and low expert-density regions flagged as novel), but no separate novelty classifier is used.",
            "plausibility_assessment_method": "Plausibility approximated by embedding proximity (semantic relevance) and complemented by external theoretical indicators (PF, PPI) for evaluation.",
            "novelty_plausibility_balance": "Not an explicit balance mechanism within deepwalk alone; balance is achieved in the larger pipeline via combination with human-availability (SP-d) and mixing coefficient beta in the AAI framework.",
            "hypothesis_quality_metrics": "Precision@50 (top-50), PR-AUC and ROC-AUC reported in Extended Data for various tasks; specific numbers reported in aggregate (e.g., content-only baseline precision ~10% for COVID-19).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Historical validation by comparing top-K embedding neighbors to subsequent first-time co-occurrences and clinical-trial entries; PR and PR-AUC used for evaluation in Extended Data.",
            "reproducibility_measures": "Embedding hyperparameters and corpus construction described; walk sampling settings provided (250k walks, walk length 20).",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Similarity scores and ranking; no formal confidence intervals.",
            "benchmark_dataset": "Same corpora: 1.5M materials articles, MEDLINE, DrugBank, CTD, ClinicalTrials.gov.",
            "performance_metrics": "Embedding-only (content) baseline had lower precision: for COVID-19 predictions content-only precision ~10% (12-month), while deepwalk-hypergraph achieved 36–38% (when including experts). For energy materials, content-only word2vec baselines were outperformed by ~100% when expert-aware deepwalk was used.",
            "comparison_with_baseline": "DeepWalk over hypergraph (authors included) outperformed content-only word2vec baselines substantially; embedding trained on author-less graph performed worse than when authors were included.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Embedding quality depends on walk sampling and hypergraph composition; training used fewer epochs for deepwalk than baseline due to smaller token vocabularies which may influence representation; by itself, embedding does not explicitly quantify novelty vs plausibility without additional modules.",
            "uuid": "e2654.1",
            "source_info": {
                "paper_title": "Accelerating science with human versus alien artificial intelligences",
                "publication_date_yy_mm": "2021-04"
            }
        },
        {
            "name_short": "Transition-probability metric",
            "name_full": "Hypergraph-induced Markov transition probability similarity metric",
            "brief_description": "A relevance metric computed from multi-step Markov transition probabilities on the mixed hypergraph that estimates the likelihood a random walker travels between nodes in a small fixed number of steps, used to predict cognitive availability of inferences.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Multi-step Markov transition probability similarity",
            "system_description": "Computes direct and multistep transition probabilities from transition matrices derived from the biased random-walk process on the hypergraph (Bayesian rules and Markovian assumptions). Similarity between nodes is defined as the (log of the) average transition probability over 1–2 (or more) steps; used as a local hypergraph-structure-based relevance score.",
            "system_type": "probabilistic graph-similarity metric (Markov chain)",
            "scientific_domain": "materials science, biomedical literature",
            "hypothesis_generation_method": "Rank candidates by transition-probability-based relevance to the property node (high transition probability -&gt; candidate more likely to be discovered by researchers).",
            "novelty_assessment_method": "Novelty identified as low transition-probability / large shortest-path distances and low expert-density (Jaccard) values.",
            "plausibility_assessment_method": "Plausibility not directly assessed by transition probabilities; combined with embedding or external theory-driven scores for plausibility evaluation.",
            "novelty_plausibility_balance": "Used as the 'human-availability' component in the AAI weighted composition with plausibility scores via beta mixing.",
            "hypothesis_quality_metrics": "Precision@50 (top-50) when ranking by transition probability; histograms of similarity used for sanity checks (e.g., Nature Medicine vs Applied Optics authors relative to 'coronavirus').",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Validated historically against subsequent discoveries and clinical trials; transition-probability-based predictions achieved similar gains to deepwalk in COVID-19 trial-prediction experiments (e.g., ~38% trial-entry precision within 12 months).",
            "reproducibility_measures": "Walk sampling counts, walk lengths, and alpha parameter documented; transition computation described as direct from transition matrices (Supplementary Information).",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Uses probabilities from transition matrices as a form of score uncertainty; no formal CI or Bayesian posterior reported.",
            "benchmark_dataset": "Same corpora as main system (materials corpus, MEDLINE, DrugBank, CTD, ClinicalTrials.gov).",
            "performance_metrics": "Achieved ~38% of top predictions entering COVID-19 trials within 12 months (vs ~10% baseline), and similar improvements in materials predictions over content-only baselines.",
            "comparison_with_baseline": "Outperformed content-only semantic baselines and matched deepwalk-based hypergraph embeddings in predictive performance; both hypergraph approaches outperform baselines that omit authors.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Local transition-probability metric is more local (short-range) than deepwalk; may miss more global structural signals unless multi-step transitions are considered.",
            "uuid": "e2654.2",
            "source_info": {
                "paper_title": "Accelerating science with human versus alien artificial intelligences",
                "publication_date_yy_mm": "2021-04"
            }
        },
        {
            "name_short": "GraphSAGE-GCN variant",
            "name_full": "Graph Sample and Aggregate (GraphSAGE) graph convolutional neural network embedding",
            "brief_description": "A graph convolutional neural network (GraphSAGE) used as an alternative embedding method: Word2Vec baseline embeddings supply node features, GraphSAGE encodes nodes via neighborhood aggregation and an inner-product decoder to produce link-prediction scores and candidate rankings.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "GraphSAGE-based graph convolutional embedding (graph auto-encoder)",
            "system_description": "Uses Word2Vec content embeddings as input features for materials and property nodes, a GraphSAGE encoder with hidden dim 400 and output dim 200 (ReLU activations), and an inner-product decoder trained with an unsupervised link-prediction loss to obtain latent node vectors. Candidate ranking by cosine similarity to property node in encoder output space. The model was trained on both the full hypergraph (with authors) and an author-less variant to measure the effect of experts.",
            "system_type": "graph convolutional neural network (inductive GNN)",
            "scientific_domain": "materials science (energy-related properties)",
            "hypothesis_generation_method": "Generates hypotheses by ranking nodes with highest cosine similarity to the property node in the learned encoder embedding space.",
            "novelty_assessment_method": "No explicit novelty classifier; novelty arises from graph structural position and output embedding distances (less proximity can indicate novelty).",
            "plausibility_assessment_method": "Plausibility not inherent; external DFT PF scores used for evaluation.",
            "novelty_plausibility_balance": "Not explicit within GraphSAGE; overall pipeline can combine GraphSAGE output with human-availability/plausibility scores externally.",
            "hypothesis_quality_metrics": "Precision@50 reported for GraphSAGE on energy properties.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Historical evaluation against known discoveries. Reported precisions: on full graph GraphSAGE achieved 62%, 58%, 74% for thermoelectricity, ferroelectricity and photovoltaics respectively; on author-less graph it achieved 48%, 50%, 58% respectively, demonstrating author-node contribution.",
            "reproducibility_measures": "Model hyperparameters and feature construction (word2vec features) described; training loss described as unsupervised link-prediction loss.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Embeddings and similarity scores used as deterministic rankings; no explicit UQ.",
            "benchmark_dataset": "1.5M inorganic materials articles dataset (same as other experiments).",
            "performance_metrics": "GraphSAGE full-graph precisions: thermoelectricity 62%, ferroelectricity 58%, photovoltaics 74%; author-less graph precisions: 48%, 50%, 58% respectively; indicates 10-20 percentage point improvement from including authors.",
            "comparison_with_baseline": "GraphSAGE with authors outperformed the author-less variant and matched the qualitative pattern of deepwalk results (though margins smaller likely due to use of word2vec features limiting exploration).",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Requires feature vectors for nodes; authors used word2vec baseline embeddings as features which can restrict novelty exploration; performance dependent on quality of input features and graph construction.",
            "uuid": "e2654.3",
            "source_info": {
                "paper_title": "Accelerating science with human versus alien artificial intelligences",
                "publication_date_yy_mm": "2021-04"
            }
        },
        {
            "name_short": "Alien AI (AAI) framework",
            "name_full": "Alien Artificial Intelligence (AAI) mixing human-availability and scientific plausibility",
            "brief_description": "A framework that explicitly trades off human cognitive availability against scientific plausibility to produce 'alien' hypotheses: candidates least available to human experts but still predicted to be scientifically promising.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Alien AI (AAI) mixing human unavailability and scientific plausibility with coefficient beta",
            "system_description": "Computes two component scores per candidate: (1) human unavailability / alienness measured via shortest-path distance (SP-d) from the property node and expert-density metrics (e.g., Jaccard index), and (2) scientific plausibility measured via semantic similarity (word2vec) or theory-driven metrics (DFT Power Factor for thermoelectrics, PPI proximity for COVID-19). Scores are transformed (Van der Waerden normalization) to make distributions comparable, then linearly combined as Z-score weighted average with mixing coefficient beta in [-1,1]. Beta controls emphasis on alienness (positive) or human familiarity (negative); the combined score s ranks candidates for disruptive discovery recommendation.",
            "system_type": "hybrid knowledge-graph + embedding + normalization-based ranking framework",
            "scientific_domain": "materials science (thermoelectrics), biomedicine (COVID-19 drug/vaccine repurposing)",
            "hypothesis_generation_method": "Generates hypotheses by ranking candidates according to the weighted composite score s = (1-?) combination of normalized alienness and plausibility (Van der Waerden-transformed Z-scores) and selecting top-K; varying beta yields families of hypotheses from human-familiar to highly alien.",
            "novelty_assessment_method": "Explicit novelty measure: shortest-path distance (SP-d) and low expert-density (Jaccard index) quantify cognitive unavailability; candidates in distant or disconnected orbits are flagged as novel/alien.",
            "plausibility_assessment_method": "Plausibility evaluated via domain-specific theory-driven metrics used only for evaluation (PF from DFT for thermoelectricity; aggregated ensemble PPI ranks from Gysi et al. for COVID-19) or approximated by word2vec proximity when theory scores are unavailable.",
            "novelty_plausibility_balance": "Directly controlled by mixing coefficient beta: beta=0 emphasizes plausibility only; beta=1 maximizes alienness (avoid human familiarity regardless of plausibility); intermediate beta trades off exploration vs exploitation to find alien yet plausible candidates.",
            "hypothesis_quality_metrics": "Composite score s (normalized Z combination), Precision@50 for ranked outputs, Power Factor distributions and PPI proximity used to measure scientific plausibility across SP-d orbits; authors visualized PF as a function of SP-d to show many high-PF candidates lie in distant orbits.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "AAI outputs were retrospectively evaluated: (1) PF (DFT) distributions for thermoelectricity candidates across SP-d orbits; (2) PPI proximity aggregated ranks for COVID-19 candidates. Also measured how increasing beta moves candidates to more disconnected regions while preserving PF/PPI plausibility up to moderate beta values.",
            "reproducibility_measures": "Describes normalization (Van der Waerden) and linear composition method; reports how beta varies and how candidates are selected (50 per beta).",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Scores are normalized to Z-scores (after Van der Waerden transform) giving standardized magnitudes but no probabilistic confidence intervals; no explicit Bayesian UQ reported.",
            "benchmark_dataset": "Same corpora (materials articles dataset, MEDLINE, DrugBank); DFT PF databases and Gysi et al. aggregated PPI ranks used for plausibility evaluation.",
            "performance_metrics": "AAI experiments show that as beta increases, candidate lists move to more cognitively distant or disconnected SP-d orbits while retaining strong PF or PPI plausibility for moderate beta; exact numeric trade-offs presented in figures (PF vs SP-d plots) rather than single scalar metrics. Demonstrated that intermediate beta values yield alien candidates with strong theoretical plausibility.",
            "comparison_with_baseline": "AAI contrasted with beta=0 (plausibility-only) and beta negative (imitating humans); AAI with positive beta produces candidates less likely to be discovered by humans but with comparable theoretical plausibility, outperforming human-only exploration in novelty while preserving plausibility vs content-only baselines.",
            "validated_on_real_science": true,
            "novel_discoveries": "No prospective experimental validations reported; retrospective evaluation shows many high-PF candidates in distant orbits and some AAI predictions correspond to plausible COVID-19 repurposings per PPI proximity rankings.",
            "limitations": "Combination approach uses relatively simple linear weighting and normalization (Van der Waerden) which may be suboptimal; theoretical plausibility metrics were used only for evaluation (not in deployed ranking) and may not exist for many domains; choosing beta requires a policy decision and could produce ethically or practically risky 'disorienting' hypotheses; no formal mechanism for handling false positives or hallucinations is provided.",
            "uuid": "e2654.4",
            "source_info": {
                "paper_title": "Accelerating science with human versus alien artificial intelligences",
                "publication_date_yy_mm": "2021-04"
            }
        },
        {
            "name_short": "Word2Vec baseline (content-only)",
            "name_full": "Content-only skip-gram Word2Vec model trained on article textual content",
            "brief_description": "A content-exclusive baseline that trains word2vec-style embeddings on article text (titles/abstracts), ignoring author/expert metadata; used as the baseline semantic model for candidate ranking.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Content-only word2vec semantic embedding baseline",
            "system_description": "Trains a skip-gram Word2Vec model on textual co-occurrence sequences derived from articles (no author nodes); uses same embedding hyperparameters as deepwalk baseline (window size 8, negative sampling 15, embedding dim 200) and ranks candidates by cosine similarity to the property token embedding.",
            "system_type": "unsupervised embedding (word2vec)",
            "scientific_domain": "materials science, biomedical literature",
            "hypothesis_generation_method": "Ranks candidate materials/drugs by semantic proximity in word2vec embedding space to the target property term.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility is approximated by semantic proximity in embedding space (higher similarity interpreted as more plausible).",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Precision@50, PR-AUC reported as baseline metrics; COVID-19 content-only precision ~10% for 12-month trial-entry evaluation.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Validated historically against subsequent discoveries, used as baseline for comparisons to hypergraph/expert-aware models.",
            "reproducibility_measures": "Embedding hyperparameters and training regimen documented; corpus explained.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Similarity scores used as ranks; no explicit UQ.",
            "benchmark_dataset": "Same corpora as other experiments when applied (materials corpus, MEDLINE).",
            "performance_metrics": "Content-only baseline precision: ~10% 12-month COVID-19 trial-entry precision; substantially lower than hypergraph expert-aware models (36–38%). For energy materials the content-only baselines were outperformed by ~100% when author information was included.",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Ignores author/expert distribution and social structure; performs worse when the distribution of expert attention strongly conditions discovery likelihood; produces more uniformly distributed predictions that do not concentrate near expert-density peaks.",
            "uuid": "e2654.5",
            "source_info": {
                "paper_title": "Accelerating science with human versus alien artificial intelligences",
                "publication_date_yy_mm": "2021-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Unsupervised word embeddings capture latent knowledge from materials science literature",
            "rating": 2
        },
        {
            "paper_title": "DeepWalk: Online Learning of Social Representations",
            "rating": 2
        },
        {
            "paper_title": "Inductive Representation Learning on Large Graphs",
            "rating": 2
        },
        {
            "paper_title": "Efficient Estimation of Word Representations in Vector Space",
            "rating": 2
        }
    ],
    "cost": 0.01889425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Accelerating science with human versus alien artificial intelligences</h1>
<p>Jamshid Sourati ${ }^{a}$<br>James Evans ${ }^{\mathrm{a}, \mathrm{b}^{*}}$<br>${ }^{a}$ University of Chicago<br>1155 S. 60th Street<br>Chicago, IL 60637<br>${ }^{\text {b }}$ Santa Fe Institute<br>1399 Hyde Park Road<br>Santa Fe, NM 87501</p>
<p>Data-driven artificial intelligence models fed with published scientific findings have been used to create powerful prediction engines for scientific and technological advance, such as the discovery of novel materials with desired properties ${ }^{1-3}$ and the targeted invention of new therapies and vaccines ${ }^{4-6}$. These AI approaches typically ignore the distribution of human prediction engines-scientists and inventors-who continuously alter the landscape of discovery and invention. As a result, AI hypotheses are designed to substitute for human experts ${ }^{1}$, failing to complement them for punctuated collective advance. Here we show that incorporating the distribution of human expertise into self-supervised models by training on inferences cognitively available to experts dramatically improves AI prediction of future human discoveries and inventions. Including expert-awareness into models that propose (a) valuable energy-relevant materials increases the precision of materials predictions by $\mathbf{\sim 1 0 0 \% ,}$ (b) repurposing thousands of drugs to treat new diseases increases precision by $\mathbf{4 3 \%}$, and (c) COVID-19 vaccine candidates examined in clinical trials by $\mathbf{2 6 0 \%}$. These models succeed by predicting human predictions and the scientists who will make them. By tuning AI to avoid the crowd, however, it generates scientifically promising "alien" hypotheses unlikely to be imagined or pursued without intervention, not only accelerating but punctuating scientific advance. By identifying and correcting for collective human bias, these models also suggest opportunities to improve human prediction by reformulating science education for discovery.</p>
<p>Research across applied science and engineering, from materials discovery to drug and vaccine development, is hampered by enormous design spaces that overwhelm researchers' ability to evaluate the full range of potentially valuable candidate designs by simulation and experiment ${ }^{7}$. To face this challenge, researchers have initialized data-driven AI models with published scientific results to create powerful prediction engines. These models are being used to enable discovery of novel materials with desirable properties ${ }^{2}$ and targeted construction of new therapies ${ }^{4}$. But such efforts typically ignore the distribution of scientists and inventors-human prediction engines-who continuously alter the landscape of discovery and invention. As a result, AI algorithms unwittingly compete with human experts, failing to complement them and augment collective advance. As we demonstrate below, incorporating knowledge of human experts and expertise can improve predictions of future discoveries by more than $100 \%$ above AI methods that ignore them. Nevertheless, with tens of millions of active scientists and engineers around the world, is the production of artificial intelligences that mimic human capacity our most strategic or ethical investment? By not mimicking, but rather avoiding human inferences we can design "alien" AIs that radically augment rather than replace human capacity. Identifying the bias of collective human discovery, we demonstrate how human-avoiding or alien algorithms broaden the scope of things discovered by identifying hypotheses unlikely for scientists and inventors to imagine or pursue with undiminished signs of scientific and technological promise.</p>
<p>Our analysis builds on insights underlying the wisdom of crowds ${ }^{8}$, which hinges on the independence and diversity of crowd members' information ${ }^{9}$ and approach ${ }^{10}$. In scientific crowds, findings established by more distinct methods and researchers are much more likely to replicate ${ }^{11,12}$. This diversity of scientific viewpoints was implicitly drawn upon by Donald Swanson in a heuristic approach to knowledge generation. He hypothesized that if Raynaud's disorder was linked to blood viscosity in one literature, and fish oil was known to decrease that viscosity in another, then fish oil might lessen the symptoms of Raynaud's disorder but would unlikely be arrived at by the sparse scientific community available to infer $\mathrm{it}^{13-15}$, one of several hypotheses later experimentally demonstrated ${ }^{16-18}$. Our approach scales and makes this heuristic continuous, combining it with explicit measurement of the distribution of scientific expertise, and drawing upon advances in unsupervised manifold learning ${ }^{19}$. Recent efforts to generate scientific hypotheses rely heavily on scientific literature, but ignore equally available publication meta-data. By programmatically incorporating information on the evolving distribution of scientific expertise, our approach balances exploitation and exploration in experimental search that enables us to both (1) accelerate discoveries predicted to appear in the future and (2) punctuate advance by identifying promising experiments unlikely to be pursued without intervention.</p>
<h1>Accounting for Human Experts in Machine Prediction</h1>
<p>The distribution of research experts across topics and time represents a critical social fact that will stably improve our inference about whether surrounding facts have been tried and abandoned-and should be treated as negative knowledge-or remain available for profitable hypothesis generation ${ }^{20}$. First we do this alongside precise replication of a recent analysis in Nature that predicted materials having desirable electrochemical properties from prior literature encoded with unsupervised neural network methods ${ }^{1}$, but ignorant of the distribution of human expertise. We show that by simply adding information about the location of scientists and their likely inferences, using a formally identical approach, we dramatically ( $\sim 100 \%$ ) improve predictions of future materials. Next, we extended this approach to identify a much broader matrix of materials and their functional properties ${ }^{21}$, including drugs and vaccines. Finally, we use expert awareness to identify and validate the scientific and technological promise of research avenues unlikely to be explored by human experts unaided.</p>
<p>Specifically, we model the distribution of inferences cognitively available to scientists by constructing a hypergraph over research publications. A hypergraph is a generalized graph where an edge connects a set, rather than a pair, of nodes. Our research hypergraph is mixed, containing nodes corresponding not only to materials and</p>
<p>properties mentioned in title or abstract, but also the researchers who investigate them (Fig. 1b). Random walks over this hypergraph suggest paths of inference cognitively available to active scientists. If a valuable material property (e.g., ferroelectricity-reversible electric polarization useful in sensors) is investigated by a scientist who, in prior research, worked with lead titanate $\left(\mathrm{PbTiO}<em 2="2">{3}\right.$, a ferroelectric material), that scientist is more likely to consider whether lead titanate is ferroelectric than a scientist without the research experience. If that scientist coauthors with another who has previously worked with sodium nitrite $\left(\mathrm{NaNO}</em>\right.$, also a ferroelectric material), that scientist is more likely to consider that sodium nitrite may have the property through conversation than a scientist without the personal connection. The density of the distribution of random walks over this research hypergraph will be proportional to the density of cognitively plausible inferences. If two literatures share no scientists, a random walk over our hypergraph will rarely bridge them, just as a scientist will rarely consider connecting a property valued in one with a material understood in another (Fig. 1a).</p>
<p>Our model (1) initiates a random walk over the research hypergraph with a valued property (e.g., ferroelectricity), then (2) randomly selects an article (hyperedge) with that property, then (3) randomly select a material or author from that article, then (4) randomly selects another article with that material or author, etc., following a Markov process ${ }^{22,23}$. Such a random walk induces similarity metrics that capture the relevance of nodes to one another. The first metric we use draws upon the local hypergraph structure to estimate the probability a random walker travels from one node to another in a fixed number of steps (see Supplementary Information). Our second metric is based on a popular, unsupervised neural network-based embedding algorithm (deepwalk ${ }^{24}$ ) over the generated random walks. This method is formally identical to the word embedding method used in replicated prior work that ignores the distribution of scientists ${ }^{1}$, but which we apply to our hypergraph, considering every random walk sequence as a "sentence" linking materials, experts and functional properties (e.g., store energy; cure breast cancer, vaccinate against COVID-19). The resulting embedding maps every node to a numerical vector, with the dot-product between any pair reflecting the relatedness of corresponding nodes. We also created a comparable embedding space using deeper graph convolutional neural networks that did not change the pattern of results presented here (see Methods and Supplementary Information).</p>
<h1>Accelerating science by predicting future discoveries</h1>
<p>Pairwise relevances estimated across our mixed hypergraph reveal distinct phenomena. The relevance of a material to a scientist measures the likelihood that she is or will become familiar with that concept through research experience, related reading, or conversation. The co-relevance of materials suggests that they may be substitutes or complements within the same experiment. The relevance of a material to a property suggests both the likelihood that the material may possess the property, but also that a scientist will likely discover and publish it (Extended Data, Fig. 1a, 1b). In this way, our hypergraph-induced similarities incorporate physical and material properties latent within literature, but also the complementary distribution of scientists, enabling us to anticipate likely inferences and predict upcoming discoveries. We assessed the pool of materials available to scientists in the literature published prior to the prediction year, ranked materials in terms of their discovery likelihood based on transition probabilities and unsupervised embeddings, then compared those rankings with actual first-time published linkages between materials and properties in published research (see Methods for further details).</p>
<p>Energy-related Materials Prediction. To demonstrate the power of accounting for human experts, we considered the valuable electrochemical properties of thermoelectricity, ferroelectricity and photovoltaic capacity against a pool of 100 K candidate compounds, contrasting our predictions with replicated prior work that did not account for human expertise ${ }^{1}$. We repeated identical analyses for 17 prediction periods, with prediction years ranging from 2001 to 2017, predicting future discoveries as a function of research publicly available to contemporary scientists. We computed annual precisions until the end of 2018, such that the longest precision array was nearly two decades ( 18 years, from 2001 to 2018) and the shortest was 2 (2017-2018, Extended Data,</p>
<p>Fig. 1c). Replicating the evaluation method of Tshitoyan et al. on the same dataset ( 1.5 M articles about inorganic materials) ${ }^{1}$, predictions that account for the distribution of materials scientists outperformed baselines for all properties and materials by an average of $100 \%$ (Fig. 2b-d).</p>
<p>Drug Repurposing. We used the same approach to explore the repurposing of $\sim 4 \mathrm{~K}$ existing FDA approved drugs to treat 100 critical human diseases. We used the MEDLINE database of biomedical research publications and set the prediction year to 2001. Ground-truth discoveries were based on drug-disease associations established by expert curators of the Comparative Toxicogenomics Database (CTD) ${ }^{25}$, which chronicles the capacity of chemicals to influence human health. Figure 1a reports prediction precisions 19 years after the prediction year, revealing how accounting for the distribution of biomedical experts in our unsupervised hypergraph embedding yields predictions with $43 \%$ higher precision than identical models accounting for article content alone. Moreover, we found a strong correlation between prediction precision and drug occurrence frequency in literature ( $\mathrm{r}=0.74$, $\mathrm{p}&lt;0.001$ ), implying that our predictors work best for diseases with relevant drugs mentioned frequently in prior research.</p>
<p>COVID-19 Therapy and Vaccine Prediction. Finally, we considered therapies and vaccines to treat or prevent SARS-CoV-2 infection. Here prediction year was set to 2020, when the global search for relevant drugs and vaccines began in earnest. Following Gysi et al. ${ }^{26}$, we considered a therapy relevant to COVID-19 if it amassed evidence to merit a COVID-related clinical trial, as reported by ClinicalTrials.gov. Results shown in Figure 1e indicate that $36 \%$ and $38 \%$ of the predictions made by deepwalk-based and transition probability metrics entered trials within 12 months of the date of prediction, respectively, 350 to $400 \%$ higher than the precision of discovery candidates generated by semantic content alone ( $10 \%$ ). These precisions were even higher than a predictive model based on an ensemble of deep and shallow learning predictors trained on multiply measured protein interactions between COVID-19 and the pool of 3,948 relevant compounds from DrugBank ${ }^{26}$, information to which our model was blind (see Extended Data, Fig. 2 for alternative measurement).</p>
<p>The success of these COVID-19 predictions suggests how fast-paced research on COVID therapies and vaccines increased the relevance of scientists' prior research experiences and relationships for the therapies and vaccines they would come to imagine, evaluate and champion in clinical trials. Consider the clinical trial of the female progesterone for treating COVID-19 ${ }^{27}$. The trial was motivated by factors including the lower global death rate of women than men from COVID-19 and anti-inflammatory properties of progesterone that may moderate the immune system's overreaction to COVID-19 in men ${ }^{28}$. Random walks from our method frequently walked the path between "coronavirus" and "progesterone" literatures to predict clinical study of progesterone for coronavirus complications (Extended Data, Fig. 5). Our technique traced a pathway similar to the one articulated by researchers sponsoring the trial: $75 \%$ of trial-cited papers, published within the five-year period we considered in building our hypergraph (2015-2019), were identified and used by our prediction model, and $60 \%$ of scientists authoring those studies were sampled in our random walk sequences.</p>
<h1>Expert-Sensitive Prediction</h1>
<p>Our predictive models use the distribution of discovering experts to successfully improve discovery predictions. This is demonstrated by time to discovery, which is inversely proportional to the size of the expert population who studied both property and material in their research. If we define expert density between a property and material as the Jaccard index of experts who mentioned both in recent publications, higher densities suggest the two are cognitively available to more scientists, and that their underlying relationship (if any) is more likely to be investigated earlier. For materials, COVID-19 therapies and vaccines, and a majority of the 100 diseases we considered, correlations between discovery date and expert densities were negative, significant and substantial (Extended Data, Fig. 3) showing that materials considered by experts familiar with a property are discovered</p>
<p>sooner. Our predictive models efficiently incorporate these expert densities (Extended Data, Fig. 4). Similar results can be derived based on embedding proximities: Fig. 3 (top row) illustrates how our predictions cluster atop density peaks in a joint embedding space of experts and the materials they investigate. These expert-material proximities predict discoverers most likely to publish discoveries based on their unique research backgrounds and relationships. Computing the probability of transition from properties to experts through a single intermediate material across 17 prediction years (2001 to 2017), we found that $40 \%$ of the top 50 ranked potential discoverers became discoverers of thermoelectric and ferroelectric materials one year after prediction, and $20 \%$ of the top 50 discovered novel photovoltaics (Fig. 3, bottom; see also Extended Data, Fig. 6)</p>
<h1>Punctuating science by predicting unlikely discoveries</h1>
<p>As illustrated above, by identifying properties and materials cognitively available to human experts, we maximize the precision of predicting published material discoveries. Almost all published discoveries lie in close proximity to desired properties based on hypergraph induced from prior literature (Fig. 4a). By contrast, if we avoid the distribution of human experts, we can produce in-human, "alien" predictions designed to complement the scientific community. These predictions are cognitively unavailable to human experts based on the organization of scientific fields, prevailing scientific attention, and expert education, but nevertheless manifest strong mechanistic promise for possessing desired scientific properties (Fig. 4b). Here, we propose a generic framework for identifying disruptive discovery candidates expected to possess desired properties, but least likely to be studied by human scientists or discovered in the near future without machine recommendation (Fig. 1a, right).</p>
<p>Our framework combines two components: an alien component that measures the degree to which candidate materials are beyond the scope of human experts' research experiences and relationships, and a second that rules out those predicted scientifically irrelevant (Fig. 4c). Each component scores entities based on human availability and scientific plausibility. The two scores are then combined with a simple mixing coefficient $\beta$. Setting $\beta=0$ implies full emphasis on scientific plausibility, blind to the distribution of experts. Decreasing $\beta$ imitates human experts and increasing $\beta$ avoids them. At extremes, $\beta=-1$ and 1 yield algorithms that generate predictions very familiar or very strange to experts, regardless of their scientific merit. Non-zero positive $\beta \mathrm{s}$ balance exploitation of relevant materials with exploration of areas unlikely considered or examined by human experts. Materials are ranked by their final scores $s$ with highest-ranked items reported candidates for disruptive discovery. Human availability is assessed with any graph distance metric varying with expert density (e.g., unsupervised neural embeddings, Markov transition probabilities, self-avoiding walks from Schramm-Loewner evolutions). Scientific merit is quantified through theory-driven simulation of material properties. For thermoelectricity, power factor (PF) represents an important component of the overall thermoelectric figure of merit, $z T$, calculated using density functional theory for candidate materials as a strong indication of thermoelectricity ${ }^{29,30}$. For COVID-19, proximity between SARS-CoV-2 and candidate compounds in protein-protein interaction networks suggests the likelihood a material will recognize and engage with the virus ${ }^{26}$. If theoretical predictions are unavailable, one may approximate scientific relevance with proximity in unsupervised literature embeddings ${ }^{1}$.</p>
<p>Fig. 4d shows the results of running our hybrid model with different $\beta \mathrm{s}$ for thermoelectricity, and Extended Fig. 7 for COVID-19. In both, we normalize, rescale and linearly compose alienness derived from shortest-path distance, and scientific plausibility from word embedding proximity (see Methods). We reserve theory-driven indicators based on power factor and protein-protein network proximity to evaluate our predictions, rather than establish scientific plausibility as they would in a deployed system. Increasing $\beta$ from zero to one, candidate materials were less likely to be conceived, discovered, and published, but PF and protein interaction likelihood remained strong for all but the most alien predictions. Intermediate $\beta \mathrm{s}$ resulted in a balanced trade-off with strong values of PF and protein-interaction even in distant and completely disconnected materials. This demonstrates the capability of our framework for punctuating scientific advance by proposing alien but scientifically promising candidate materials,</p>
<p>with only a naive combination and weighting system. More sophisticated metrics could be employed by incorporating all available prior scientific knowledge and learning combination metrics through self-supervised multi-headed graph convolutional neural networks.</p>
<h1>Discussion</h1>
<p>These models demonstrate the power of incorporating expert-awareness into artificial intelligence systems for accelerating and punctuating future discovery. Our models succeed by directly predicting human discoveries and the human experts who will make them, yielding an average of $100 \%$ improvement in prediction precision. By tuning these algorithms to avoid the crowd, however, they generate scientifically promising "alien" hypotheses unlikely to be imagined, pursued or published without machine recommendation. By identifying and correcting for collective patterns of human attention, formed by field boundaries and institutionalized education, these models complement the contemporary scientific community. A further class of alien predictions could be tuned to compensate not only for emergent bias, but universal cognitive constraints, such as limits on the human capacity to conceive or search through complex combinations (e.g., high-order drug cocktails ${ }^{31}$ ). Disorienting hypotheses from such a system will not be beautiful, but being inconceivable, they break unbroken ground and sidestep the path dependent "burden of knowledge" where scientific institutions require new advances built upon the old for ratification and support ${ }^{32,33}$.</p>
<p>Our approach can also be used to identify individual and collective biases that limit productive exploration, and suggest opportunities to improve human prediction by reformulating science education for discovery. Insofar as research experiences and relationships condition the questions scientists investigate, education tuned to discovery would conceive of each student as a new experiment, recombining knowledge and opportunity in novel ways. Our investigation underscores the power of incorporating human and social factors to produce artificial intelligence that complements rather than substitutes for human expertise. By making AI hypothesis generation aware of human expertise, it can race with rather than against the scientific community to expand the scope of human imagination and discovery.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. (a) Two possible relations between experts, property and material nodes when there exists a hidden underlying relationship between the two (dashed line) to be discovered. Uncolored circles represent human experts and each colored node indicates a material (colored in blue denoted M) or a desirable property they possess (colored in red and denoted P). Solid lines show existing links between expert-material nodes and dashed lines represent existing property-material links that have not yet been discovered. The left case, where concepts P and M share a common collection of experts, is likely to be discovered and published in the near future-they are predictable by scientists, whereas the right case is likely to escape scientists' attention as there is no shared community of experts, and their pursuit would disrupt the current course of science. (b) Illustration of our mixed coauthorship hypergraph for three papers. Uncolored shapes represent authors and colored shapes represent properties (red) or materials (blue) mentioned in article titles and abstracts. These three papers constitute a hypergraph with three hyperedges traced by ellipses. (c) Two initial steps of a random walk process on the hypergraph shown in part (b). Blue and red shapes represent material and property keywords, respectively. Papers (hyperedges) are sampled uniformly whereas, if $\alpha$ is set, nodes are selected such that the probability of sampling an entity is $\alpha$ times the probability of sampling an author. Note that $\alpha$ is the only parameter of this non-uniform sampling ( $\pi$ can be uniquely determined from $\alpha$ ). (d) Four example random walk paths starting from property "Coronavirus"-relevant and ending in Progesterone (a chemical under clinical trial investigation for therapeutic efficacy). Each arrow connecting two nodes indicates a sampling step, where the paper shown on top of the receiving node comprises a hyperedge containing that material and the property, author, or material from the prior step.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Fig. 2. Precision rates of discovery for materials associated with different properties and prediction years: (a-c) chemical compounds and electrochemical properties including thermoelectricity, ferroelectricity, and photovoltaic capacity, respectively, with prediction years varying from 2001 to 2017; (d) therapeutics and vaccines for COVID-19 for the prediction year 2020; (e) general disease-drug associations for prediction year 2001. Precisions reported for general disease-drug associations are individual rates computed 19 years after prediction year, but computed annually for electrochemical properties and monthly for COVID-19 efficacy. Gray bars in Figs. (a-d) indicate the number of new discoveries occurring in reality for each month or year of the prediction period.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3. (a) 2D projections of the expert-sensitive material predictions made by deepwalk (blue circles) and the content-exclusive word2vec model (red circles) for thermoelectricity (left), ferroelectricity (center) and photovoltaic capacity (right). Circles with center dots indicate true positive predictions discovered and published in subsequent years and empty circles are false positives, yet unpublished. Predictions are plotted atop the density of experts (topo map and contours estimated by Kernel Density Estimation) in a 2D tSNE-projected embedding space. Before applying tSNE dimensionality reduction, the original embedding was obtained by training a word2vec model over sampled random walks across the hypergraph of published science. Red circles are more uniformly distributed, but blue circles concentrate near peaks of expert density. (b) Precision rates for predicting discoverers of materials with electrochemical properties. Predictive models are built based on two-step transitions between property and expert nodes with an intermediate material in the transition path. Bars show average precision of expert predictions for individual years. An expert can publish a discovery in multiple years. Total precision rates are also shown near each property ignoring the repetition of discovering experts.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p><strong>Fig. 4.</strong> Distribution of Power Factor (PF) as a simulated thermoelectricity score visualized on shortest-path distance (SP-<em>d</em>) levels from node thermoelectricity for <strong>(a)</strong> human discoveries, <strong>(b)</strong> all materials that have not been studied in context of thermoelectricity yet and are candidates of being discovered, and <strong>(c)</strong> hypotheses from our alien AI algorithm with parameter β varying from 0 to 1, where 50 hypotheses were generated with each value of β in the prediction year 2001 (evaluations performed after 18 years), as illustrated in <strong>(d)</strong>. The property node is located at the center; each concentric orbit represents a particular (range of) SP-<em>d</em>s, where the last orbit includes materials disconnected from the property (∞ SP-<em>d</em>). The size and color of each arc show the total number of compounds with corresponding SP-<em>d</em> from the property and their average PF scores, respectively. The further a compound is located from the property, the less cognitively available it is to scientists. <strong>(a)</strong> shows that human discoveries mainly lie in close proximity to the property node (highly cognitively available). Nevertheless, <strong>(b)</strong> shows that candidates of discoveries in each year are distributed more broadly across the network of scientists. Moreover, there exist materials with strong PF scores in distant orbits including the last one that is completely disconnected from the property. <strong>(c)</strong> indicates that our alien AI algorithm could capture cognitively unavailable hypotheses that are also evaluated to be scientifically plausible (strong PF values) except for very high β values. <strong>(d)</strong> Illustration of our general alien AI framework as a weighted combination of human (un)availability and scientific plausibility scores <em>s</em>. Combining these scores will result in a final ranking of materials.</p>
<p>from which candidate hypotheses will be chosen. The mixing Coefficient $\beta$ (varying in range $[-1,1]$ ) determines how much weight we give to the availability of hypotheses to human scientists. Setting $\beta=0$ implies full attention to scientific plausibility with no emphasis on human (un)availability. At the extremes, $\beta \sim-1$ and 1 sets the objective to be solely imitating and/or avoiding the expert distribution, respectively.</p>
<h1>Methods</h1>
<h2>Experiments and Data Collection</h2>
<p>Given a specific property and a pool of materials, each discovery prediction experiment consists of computing a set of scores based on the literature prior to the prediction year and selecting 50 materials with the highest scores. Precision of predictions could then be computed against ground-truth discoveries in subsequent months or years.</p>
<p>We collected several corpora of scientific articles and considered relationships between materials and various properties. Forming a mixed hypergraph requires a disambiguated set of authors for all scientific articles. Our testbed consisted of two datasets: a collection of $\sim 1.5 \mathrm{M}$ articles published between 1937 and 2018 classified by Tshitoyan et. al (2019) relating to inorganic materials ${ }^{1}$, and the MEDLINE database that includes more than 28M articles published in various biomedical fields over the span of more than two centuries. We downloaded the former using Scopus API provided by Elsevier (https://dev.elsevier.com/), which readily assigns unique codes to distinct authors. In order to author-disambiguate PubMed database, we used disambiguation results provided by PubMed Knowledge Graph (PKG) ${ }^{34}$, which were obtained by combining information from the Author-ity disambiguation of PubMed ${ }^{35}$ and the more recent semantic scholar database ${ }^{36}$.</p>
<p>For energy-related materials science, we extracted the pool of materials from the collected 1.5 M articles using Python Materials Genomics ${ }^{37}$ and direct rule-based string processing. Material-property association was considered to be established if the material co-occurred with any of the property-related keywords. First-time co-occurrences were defined as ground-truth discoveries, following relevant prior work ${ }^{1}$. For the case of drug repurposing, we began with a pool of 7,800 approved candidate drugs downloaded from the DrugBank database. We then built our drug pool using approximately 4,000 drugs possessing simple names (e.g., by dropping complex names containing several numerical parts). We chose 100 diseases from the Comparative Toxicogenomics Database (CTD) ${ }^{25}$ that had the largest number of relevant drugs from our drug pool. We searched for names of drugs and diseases in MEDLINE to detect their occurrence within papers to build a hypergraph. Ground-truth relevant drugs for the selected diseases were extracted from the associations curated by CTD. The discovery date for each of the disease-drug associations was set to the earliest publication reported by CTD for the curated or inferred relevance. We ran separate prediction experiments for each disease. The same pool of drugs and corpus of papers were used in case of COVID-19, where their relevance to COVID-19 were identified based on their involvement in COVID-related studies reported by ClinicalTrials.org in or after 2020, regardless of the studies' results. Date of discovery for each relevance was set to the date that the corresponding study was first posted, and if the drug was involved in multiple trials we considered the earliest date. There have been 4,899 trials posted as of March 3rd, 2021 (ignoring 32 trials dated before 2020), which included 251 drugs from our pool ( $\sim 6 \%$ ) included in their designs.</p>
<h2>Random Walks and Relevance Metrics</h2>
<p>In practice, coauthorships that occurred long before the time of prediction will neither be cognitively available nor perceived as continuingly relevant. Therefore, we restrict our prediction experiments to use literature produced in the 5 years prior to year of prediction. For each property, we took 250,000 non-lazy, truncated random walk sequences starting from the property node and terminating after 20 steps or after reaching a deadend node with no further connections. Without constraining the space, the majority of hypergraph nodes belong to experts-there are more authors on the average article than materials studied within it. We devised a biased random walk</p>
<p>algorithm to compensate for this imbalance, controlled by a parameter $\alpha$, which defines the probability ratio of selecting conceptual (e.g., molecules or materials) to author nodes in any given paper. Larger $\alpha$ results in the higher frequency of selecting conceptual nodes and $\alpha=1$ implies a balanced mixture of authors and entities (Fig. 1c, also see Methods). Note that deepwalk similarity is much more global than transition probability, provided the length of our walks ( $\sim 20$ ) are much longer than the transition steps considered (2-3), and it is more flexible as the walker's edge selection probability distribution can be easily modified to explore the network structure more deeply ${ }^{38}$. Note that authors heavily outnumbered materials in all our databases. To mitigate this imbalance, we introduced a non-uniform node sampling distribution parameterized by $\alpha$, defined as the ratio of the probability of sampling a material or property to the probability of sampling an author in any given paper. A random walker with $\alpha=1$ tends to select roughly equal number of authors and materials. In practice, we sampled from a mixture of two uniform distributions with weights $1 /(1+\alpha)|A|$ and $\alpha /(1+\alpha)|M|$ assigned to authors in set $A$ and materials/property in set $M$, respectively, where $|A|$ denotes the cardinality of set $A$.</p>
<p>Multistep transition probabilities are directly computed from transition matrices using Bayesian rules and Markovian assumptions (Supplementary Information). For deepwalk representation, we trained a skipgram Word2Vec model with embedding dimensionality of 200 over the truncated random walk sequences. In the task of discovery prediction, we discarded author nodes from the generated random walk sequences and training was performed over property/material tokens only. The training hyperparameters here were set equal to the ones used when training the Word2Vec baseline model, i.e., window size of 8 , negative sampling size of 15 and learning rate of 0.01 , which linearly decayed to 0.001 during iterations. The only exception is the number of epochs, which was 30 for baseline and 5 for the network representation. The size of the vocabularies produced in deepwalk sentences had much smaller tokens than the baselines, as a result they required less effort to capture inter-node relationships.</p>
<p>We also ran our prediction experiments after replacing deepwalk representation with a graph convolutional neural network. We used Graph Sample and Aggregate (GraphSAGE) model ${ }^{39}$ with 400 and 200 as the dimensionality of hidden and output layers with Rectified Linear Units (ReLU) as the non-linear activation in the network. Convolutional models require feature vectors for all nodes but our hypergraph is inherently feature-less. Therefore, we utilized the word embeddings obtained by our Word2Vec baseline as feature vectors for materials and property nodes. A graph auto-encoder was then built using GraphSAGE architecture as the encoder and an inner-product decoder and its parameters were tuned by minimizing the unsupervised link-prediction loss function ${ }^{40}$. We took the output of the encoder as the embedded vectors and selected the top 50 discovery candidates by choosing entities with the highest cosine similarities to the property node. In order to evaluate the importance of the distribution of experts for our prediction power, we trained this model on our full hypergraph and also after withdrawing the author nodes (see Supplementary Information). Running the convolutional model on energy-related materials and properties yielded $62 \%, 58 \%$ and $74 \%$ precisions on the full graph, and $48 \%, 50 \%$ and $58 \%$ on the author-less graph for thermoelectricity, ferroelectricity and photovoltaics, respectively. These results show a similar pattern to those obtained from deepwalk although with a somewhat smaller margin, likely due to the use of Word2Vec-based feature vectors, which limit the domain of exploration by the new embedding model to within proximity of the baseline.</p>
<h1>Alien Artificial Intelligence</h1>
<p>Our alien knowledge discovery machine assigns human availability (or alienness) and scientific plausbility scores to each material with respect to a given property, which will be combined with a mixture weight $\beta$. In our AAI experiments, human unavailability was measured through shortest-path distance (SP-d) to the property node and scientific relevance was quantified by semantic similarities based on word embedding models (e.g., word2vec). The latter often yields continuous scores distributed similar to a Gaussian variable, but the former offers</p>
<p>unbounded ordinal scores. This prevents us from directly combining them through Z-scores. To address this issue, we first transformed the two variables according to the Van der Waerden formulation ${ }^{41}$ before taking the weighted average of their Z-scores (see Supplementary Materials for comparison to other combination methods). When evaluating AAI, we leveraged the property's theoretical scores obtained based on or prior knowledge from the relevant fields to assess scientific validation of candidates.</p>
<p>For thermoelectricity, we used Power Factor (PF) as a scalar score indicating how likely a material is thermoelectric based on theoretical simulations. PF is proportional to the electric conductivity and the absolute temperature and plays a key role in the more general metric of figure of merit $(z T)$. Moreover, Tshitoyan et al. showed that materials that have been studied in conjunction with thermoelectricity in the literature tend to have higher PF scores. In our AAI experiments, we restricted the pool of entities to those for which there existed pre-calculated scores in the same database that Tshitoyan et al. had used ${ }^{1,30}$, which formed $30 \%$ of the unstudied materials in the corresponding five-year period (1996 to 2000).</p>
<p>The theoretical scores that we used for evaluating our AAI method in case of COVID-19 were based on protein-protein interaction of the drugs with the SARS-CoV-2 viral target. Recently, Gysi et al. showed that existing drugs whose target proteins are within or in vicinity of the COVID-19 disease module are potentially strong candidates for repurposing ${ }^{26}$. They employed 12 network-based strategies individually and collectively to identify the most relevant candidate drugs, for which their rank-based combination yielded the best performance. We utilized the inverse of the aggregated ranks from their ensemble strategy as scores to theoretically measure material relevance to COVID-19. These scores were based on our prior knowledge of the target proteins associated with drugs and disease, to which our AAI method was blind.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Extended Data Fig. 1. Sanity checks on our hypergraph-induced transition probability similarity metric. (a) Between an author and a conceptual node: Histogram of the similarities between nodes of two sets of authors and the node associated with the term "coronavirus". The two sets of authors are defined as authors of 5,000 randomly selected papers from journals Nature Medicine (red) and Applied Optics (turquoise) between 1990 and 2019. We computed similarities between the hypernodes as the logarithm of the average transition probabilities with one and two random walk steps. The histograms are plotted considering only non-zero transition probabilities: $92 \%$ of the authors of Nature Medicine (28,396 in total) and $51 \%$ of the selected Applied Optics authors (18,530 in total) had non-zero similarity values. Also, the average non-zero similarities associated with Nature Medicine authors (red dashed line) is almost 5 times larger than that of Applied Optics authors (blue dashed line), implying that based on the hypergraph-induce similarity metric the authors publishing in Nature Medicine write papers more relevant to coronavirus in comparison to those publishing in Applied Optics. (b) Between two conceptual nodes: similarities between several conceptual keywords shown on the x -axis and the node corresponding to "coronavirus". Similarities between the hypernodes are computed as the average transition probabilities with one and two intermediate nodes. The terms and symptoms known to be more relevant to coronavirus have larger average transition probabilities.
(c) Schematic of our experimental settings: Starting and ending dates of the experiments are shown. As illustrated, we repeated the prediction experiments with 17 different starting dates for energy-related functions. Each predictor would be evaluated through (1) 18 average cumulative precision values for energy-related properties, (2) a single precision value for each disease in drug repurposing application, and (3) 14 cumulative precision values for COVID-19 therapy and vaccination.</p>
<h1>1. Introduction</h1>
<h2>1.1. Background</h2>
<p>The study of <strong>quantum mechanics</strong> has revolutionized our understanding of the microscopic world. It provides a framework for describing the behavior of particles at atomic and subatomic scales. One of the key principles in quantum mechanics is the <strong>wave-particle duality</strong>, which states that particles can exhibit both wave-like and particle-like properties.</p>
<h2>1.2. Objectives</h2>
<p>The primary objective of this research is to explore the <strong>interaction between light and matter</strong> at the quantum level. Specifically, we aim to:</p>
<ul>
<li>Investigate the <strong>interaction between light and matter</strong> at the quantum level.</li>
<li>Analyze the <strong>interaction between light and matter</strong> at the quantum level.</li>
<li>Develop a <strong>quantum theory</strong> for the study of quantum systems.</li>
</ul>
<h1>2. Literature Review</h1>
<h2>2.1. Quantum Mechanics and Quantum Information</h2>
<p>Quantum mechanics is a fundamental theory in quantum mechanics that describes the behavior of particles at the quantum level. It is based on the <strong>Schrödinger equation</strong>, which describes the quantum state of a physical system. The equation is given by:</p>
<p>$$i\hbar \frac{\partial \Psi}{\partial t} = \hat{H} \Psi$$</p>
<p>where:
- <strong>i</strong> is the imaginary unit,
- <strong>i</strong> is the imaginary unit,
- $\Psi$ is the wave function,
- $\hat{H}$ is the Hamiltonian operator.</p>
<h2>2.2. Quantum Entanglement</h2>
<p>Quantum entanglement is a phenomenon where two or more particles become correlated in such a way that the state of one particle instantly affects the state of the other, regardless of the distance between them. This property has been demonstrated in various fields, including:</p>
<ul>
<li><strong>Quantum computing and communication</strong>: Quantum entanglement is a phenomenon where two or more particles become correlated in such a way that the state of one particle becomes correlated in such a way that the state of the other is affected in such a way that the state of the particles is not correlated in such a way.</li>
</ul>
<h1>3. Methodology</h1>
<h2>3.1. Experimental Setup</h2>
<p>The experimental setup involved a <strong>laser source</strong> with a laser source. The laser source was used to generate the quantum states of the particles. The laser source was used to generate the quantum states of the particles. The experimental conditions were as follows:</p>
<ul>
<li><strong>Tensile</strong>: The laser was placed in a vacuum at the quantum level and used to generate the quantum states of the particles.</li>
<li><strong>Quantum entanglement</strong>: The quantum state of a physical system was described by the quantum states of particles. The entangled particles were considered as quantum systems under the conditions of quantum mechanics.</li>
<li><strong>Quantum entanglement</strong>: The quantum state of a physical system was described by the quantum states of particles. The entangled particles were considered as quantum systems under the conditions of quantum mechanics.</li>
</ul>
<h1>4. Results and Discussion</h1>
<h2>4.1. Observations</h2>
<p>The experimental results are summarized in the following table:</p>
<table>
<thead>
<tr>
<th><strong>Trial</strong></th>
<th><strong>Laser Source</strong></th>
<th><strong>Quantum Entanglement</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>2</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>3</td>
<td>C</td>
<td>0.002</td>
</tr>
<tr>
<td>4</td>
<td>C</td>
<td>0.002</td>
</tr>
<tr>
<td>5</td>
<td>C</td>
<td>0.002</td>
</tr>
</tbody>
</table>
<h2>4.2. Observations and Analysis</h2>
<p>The experimental results are summarized in the following table:</p>
<table>
<thead>
<tr>
<th><strong>Trial</strong></th>
<th><strong>Laser Source</strong></th>
<th><strong>Quantum Entanglement</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>2</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>3</td>
<td>C</td>
<td>0.002</td>
</tr>
</tbody>
</table>
<h2>4.3. Analysis</h2>
<p>The results are summarized in the following table:</p>
<table>
<thead>
<tr>
<th><strong>Trial</strong></th>
<th><strong>Laser Source</strong></th>
<th><strong>Quantum Entanglement</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>2</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>3</td>
<td>C</td>
<td>0.002</td>
</tr>
</tbody>
</table>
<h2>4.4. Analysis and Discussion</h2>
<p>The results are summarized in the following table:</p>
<table>
<thead>
<tr>
<th><strong>Trial</strong></th>
<th><strong>Laser Source</strong></th>
<th><strong>Quantum Entanglement</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>2</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>3</td>
<td>C</td>
<td>0.002</td>
</tr>
</tbody>
</table>
<h2>4.5. Conclusion</h2>
<p>The study of quantum mechanics has transformed our understanding of the microscopic world and has led to the development of new technologies and technologies. The results are summarized in the following table:</p>
<table>
<thead>
<tr>
<th><strong>Trial</strong></th>
<th><strong>Laser Source</strong></th>
<th><strong>Quantum Entanglement</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>2</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>3</td>
<td>C</td>
<td>0.002</td>
</tr>
</tbody>
</table>
<h2>4.6. Conclusion</h2>
<p>The study of quantum mechanics has transformed our understanding of the microscopic world and has led to the development of new technologies and technologies. The results are summarized in the following table:</p>
<table>
<thead>
<tr>
<th><strong>Trial</strong></th>
<th><strong>Laser Source</strong></th>
<th><strong>Quantum Entanglement</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>2</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>3</td>
<td>C</td>
<td>0.002</td>
</tr>
</tbody>
</table>
<h2>4.7. Conclusion</h2>
<p>The study of quantum mechanics has transformed our understanding of the microscopic world and has led to the development of new technologies and technologies. The results are summarized in the following table:</p>
<table>
<thead>
<tr>
<th><strong>Trial</strong></th>
<th><strong>Laser Source</strong></th>
<th><strong>Quantum Entanglement</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>2</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>3</td>
<td>C</td>
<td>0.002</td>
</tr>
</tbody>
</table>
<h2>4.8. Conclusion</h2>
<p>The study of quantum mechanics has transformed our understanding of the microscopic world and has led to the development of new technologies and technologies. The results are summarized in the following table:</p>
<table>
<thead>
<tr>
<th><strong>Trial</strong></th>
<th><strong>Laser Source</strong></th>
<th><strong>Quantum Entanglement</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>2</td>
<td>X</td>
<td>0.002</td>
</tr>
<tr>
<td>3</td>
<td>C</td>
<td>0.002</td>
</tr>
</tbody>
</table>
<h2>4.9.</h2>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Extended Data Fig. 2. Precision-Recall (PR) curves and area under the curves for various predictors and databases: energy-related materials science properties, i.e., thermoelectrics (a), ferroelectrics (b) and photovoltaics (c), therapies and vaccines for COVID-19 (d), and generic drugs repurposing (e). Except for COVID-19, we only displayed the PR-AUC values for the selected prediction years skipping the PR curves themselves. Note that for Receiver Operating Curves (ROC) random predictors always result in AUC of 0.5, PR-AUC of the random baseline depends on the ratio of positive samples in the data set.</p>
<p>Extended Data Fig. 3. Spearman correlation coefficients of expert density (Jaccard index) between individual properties, the actual discoveries, and date of discovery. Negative correlations imply that entities with higher expert densities are likely to be discovered earlier than others. These results were obtained for discoveries after 2001 for energy-related properties and drugs repurposing applications, and after 2020 for COVID-19. The turquoise bars represent correlations with statistical significance (p-value $&lt;0.05$ ) while the red bars had larger p-values indicating nonsignificant results. Moreover, for seven diseases in the CTD database all actual drugs repurposings, i.e., actual discoveries, occurred in a single year (we did not have reliable access to the month or day of discoveries from this database) and hence no correlation coefficients could be computed for them. The results indicate that the materials science properties and also COVID-19 showed strong negative correlations. In the case of CTD database, 67 out of 100 diseases (i.e., properties) showed statistically significant correlations, among which only one disease showed positive coefficient. The average of correlation coefficients across these 67 diseases was -0.18 .
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Extended Data Fig. 4. Distribution of expert densities between predicted discoveries and the corresponding properties: (a) drugs repurposing application (considering only the 67 diseases with statistically significant Spearman correlation coefficients, see Extended Data, Fig. 3); (b-d) energy-related materials science properties, i.e., thermoelectricity, ferroelectricity and photovoltaic capacity, respectively; and (e) therapies and vaccines for COVID-19. Curves measure normalized densities over the logarithm of Jaccard indices plotted by fitting a Beta distribution over expert densities for the 50 predictions. Solid and dashed lines represent mean values for the corresponding densities. It is clear that the distribution of expert densities for hypergarph-induced metrics (transition probability and deepwalk-based similarity) are concentrated around larger Jaccard index values than word embedding models tracing content alone. In content models, all estimated densities peak at zero $(0&lt;a&lt;1&lt;b$, with a,b shape parameters of Beta distribution). CTD diseases are sorted by average expert similarity between them and the complete pool of drugs.</p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Extended Data Fig. 5. An example random walk from the property node "Coronavirus" to the material node "Progesterone". Every article in this path is a hyperedge (denoted by $e_{i}$ in the $i$-th step) connecting the prior to the next node. The last article was cited by the University of Southern California clinical trial that investigated the effectiveness of progesterone for COVID-19 treatment. MeSH Terms in the articles are shown to better demonstrate their scope, with colored terms indicating relevant hints to the reasoning of the human scientists behind the study of progesterone for COVID-19 treatment. The path indicates a clear transition from Coronavirus-related topics to male-female differences in pathological conditions and lastly to progesterone-based therapy. Similar bridges between topics were highlighted by the trial's investigator as the main motivation for her study.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{a}$ The results of the study are presented in Table 1.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>