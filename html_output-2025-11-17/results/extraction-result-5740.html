<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5740 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5740</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5740</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-115.html">extraction-schema-115</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <p><strong>Paper ID:</strong> paper-a2e667e4382aaa8e02a17d0522c1a910790ab65b</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/a2e667e4382aaa8e02a17d0522c1a910790ab65b" target="_blank">Deep Learning for Anomaly Detection: A Survey</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> A structured and comprehensive overview of research methods in deep learning-based anomaly detection, grouped state-of-the-art research techniques into different categories based on the underlying assumptions and approach adopted.</p>
                <p><strong>Paper Abstract:</strong> Anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. The aim of this survey is two-fold, firstly we present a structured and comprehensive overview of research methods in deep learning-based anomaly detection. Furthermore, we review the adoption of these methods for anomaly across various application domains and assess their effectiveness. We have grouped state-of-the-art research techniques into different categories based on the underlying assumptions and approach adopted. Within each category we outline the basic anomaly detection technique, along with its variants and present key assumptions, to differentiate between normal and anomalous behavior. For each category, we present we also present the advantages and limitations and discuss the computational complexity of the techniques in real application domains. Finally, we outline open issues in research and challenges faced while adopting these techniques.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5740.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5740.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Long Short-Term Memory (LSTM) networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recurrent neural network architecture used in the paper to model sequential data (e.g., system logs, time series) for anomaly detection; LSTMs capture temporal/contextual dependencies and are applied to identify out-of-context or sequence anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Recurrent neural network with gated memory cells designed to learn long-range temporal dependencies in sequences; used as a sequence model for prediction or reconstruction-based anomaly scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Sequence modeling of logs/time series using LSTM; anomalies detected via prediction errors or deviation from learned sequence/contextual patterns (contextual/sequence-based anomaly scoring).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences (system logs, time series, event sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Contextual anomalies and point anomalies in sequences (out-of-context events, abnormal sequence patterns)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper notes general challenges when applying sequence models: variable-length sequences, evolving anomalies over time, and high computational cost for long sequences; surveys do not report specific LSTM performance numbers or detailed comparisons in this text.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Learning for Anomaly Detection: A Survey', 'publication_date_yy_mm': '2019-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5740.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5740.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>word2vec</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>word2vec (neural word embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A shallow neural embedding method referenced in the survey as used to embed tokens from malware and related textual/byte sequences to serve as features for downstream anomaly/malware detection models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>word2vec</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Shallow neural embedding model (skip-gram / CBOW) that maps discrete tokens (words, API calls, byte-grams) into continuous vector space to capture contextual similarity; used as a feature representation for detection models.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Token embedding to produce dense feature vectors for sequences (e.g., API call sequences, byte token sequences); embeddings are fed to classifiers or sequence models to detect malicious/anomalous patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences (malware binaries tokenized as word/API-call/byte sequences), textual-like representations of structured artifacts</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Malware/anomalous binary behavior (semantic anomalies indicating malicious samples)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey only mentions word2vec as a preprocessing/feature step; limitations implied include dependence on tokenization and representativeness of training corpus and that embeddings alone do not constitute an end-to-end anomaly detector.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Learning for Anomaly Detection: A Survey', 'publication_date_yy_mm': '2019-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5740.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5740.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Log-as-Language</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Modeling system/application logs as natural-language sequences</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The survey highlights the approach of treating log messages as natural-language-like sequences and applying sequence/language modeling methods (LSTM/RNN/CNN) to detect anomalies in logs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LSTM / RNN / CNN (sequence / language models applied to logs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Sequence and convolutional neural architectures applied to tokenized log messages or sequences thereof; these models model the natural-language structure of logs for prediction or representation, enabling anomaly detection via deviations in predicted tokens or representations.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Natural-language-style sequence modeling of log events; anomalies scored by prediction/reconstruction error or by atypical sequence/context (ranking or thresholding of anomaly scores).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured/unstructured logs (textual sequences), treated as natural language sequences</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Log anomalies including out-of-context events, rare/unseen failure messages, and point/contextual anomalies in logs</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Examples of HIDS datasets mentioned in survey include ADFA-LD and UNM-LPR (used generally for HIDS evaluations), but no explicit dataset tied to log-language modeling experiments is specified in the text.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Survey contrasts language/sequence-modeling approaches with traditional rule/regex-based log-detection (which fail to detect new/unseen messages) and classical methods; however, no quantitative comparison numbers are provided in the surveyed text.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey reports challenges: diversity and unstructured format of logs, evolving log message formats, need for real-time adaptation, and that existing rule-based methods miss novel messages; the paper does not provide specific failure-case numbers for language-model approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Learning for Anomaly Detection: A Survey', 'publication_date_yy_mm': '2019-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Du et al. [2017] <em>(Rating: 2)</em></li>
                <li>Cakir and Dogdu [2018] <em>(Rating: 2)</em></li>
                <li>Silva et al. [2018] <em>(Rating: 2)</em></li>
                <li>Sakurada and Yairi [2014] <em>(Rating: 1)</em></li>
                <li>Tuor et al. [2017] <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5740",
    "paper_id": "paper-a2e667e4382aaa8e02a17d0522c1a910790ab65b",
    "extraction_schema_id": "extraction-schema-115",
    "extracted_data": [
        {
            "name_short": "LSTM",
            "name_full": "Long Short-Term Memory (LSTM) networks",
            "brief_description": "A recurrent neural network architecture used in the paper to model sequential data (e.g., system logs, time series) for anomaly detection; LSTMs capture temporal/contextual dependencies and are applied to identify out-of-context or sequence anomalies.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "LSTM",
            "model_description": "Recurrent neural network with gated memory cells designed to learn long-range temporal dependencies in sequences; used as a sequence model for prediction or reconstruction-based anomaly scoring.",
            "model_size": null,
            "anomaly_detection_method": "Sequence modeling of logs/time series using LSTM; anomalies detected via prediction errors or deviation from learned sequence/contextual patterns (contextual/sequence-based anomaly scoring).",
            "data_type": "Sequences (system logs, time series, event sequences)",
            "anomaly_type": "Contextual anomalies and point anomalies in sequences (out-of-context events, abnormal sequence patterns)",
            "dataset_name": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "limitations_or_failure_cases": "Paper notes general challenges when applying sequence models: variable-length sequences, evolving anomalies over time, and high computational cost for long sequences; surveys do not report specific LSTM performance numbers or detailed comparisons in this text.",
            "uuid": "e5740.0",
            "source_info": {
                "paper_title": "Deep Learning for Anomaly Detection: A Survey",
                "publication_date_yy_mm": "2019-01"
            }
        },
        {
            "name_short": "word2vec",
            "name_full": "word2vec (neural word embeddings)",
            "brief_description": "A shallow neural embedding method referenced in the survey as used to embed tokens from malware and related textual/byte sequences to serve as features for downstream anomaly/malware detection models.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "word2vec",
            "model_description": "Shallow neural embedding model (skip-gram / CBOW) that maps discrete tokens (words, API calls, byte-grams) into continuous vector space to capture contextual similarity; used as a feature representation for detection models.",
            "model_size": null,
            "anomaly_detection_method": "Token embedding to produce dense feature vectors for sequences (e.g., API call sequences, byte token sequences); embeddings are fed to classifiers or sequence models to detect malicious/anomalous patterns.",
            "data_type": "Sequences (malware binaries tokenized as word/API-call/byte sequences), textual-like representations of structured artifacts",
            "anomaly_type": "Malware/anomalous binary behavior (semantic anomalies indicating malicious samples)",
            "dataset_name": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "limitations_or_failure_cases": "Survey only mentions word2vec as a preprocessing/feature step; limitations implied include dependence on tokenization and representativeness of training corpus and that embeddings alone do not constitute an end-to-end anomaly detector.",
            "uuid": "e5740.1",
            "source_info": {
                "paper_title": "Deep Learning for Anomaly Detection: A Survey",
                "publication_date_yy_mm": "2019-01"
            }
        },
        {
            "name_short": "Log-as-Language",
            "name_full": "Modeling system/application logs as natural-language sequences",
            "brief_description": "The survey highlights the approach of treating log messages as natural-language-like sequences and applying sequence/language modeling methods (LSTM/RNN/CNN) to detect anomalies in logs.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "LSTM / RNN / CNN (sequence / language models applied to logs)",
            "model_description": "Sequence and convolutional neural architectures applied to tokenized log messages or sequences thereof; these models model the natural-language structure of logs for prediction or representation, enabling anomaly detection via deviations in predicted tokens or representations.",
            "model_size": null,
            "anomaly_detection_method": "Natural-language-style sequence modeling of log events; anomalies scored by prediction/reconstruction error or by atypical sequence/context (ranking or thresholding of anomaly scores).",
            "data_type": "Structured/unstructured logs (textual sequences), treated as natural language sequences",
            "anomaly_type": "Log anomalies including out-of-context events, rare/unseen failure messages, and point/contextual anomalies in logs",
            "dataset_name": "Examples of HIDS datasets mentioned in survey include ADFA-LD and UNM-LPR (used generally for HIDS evaluations), but no explicit dataset tied to log-language modeling experiments is specified in the text.",
            "performance_metrics": null,
            "baseline_comparison": "Survey contrasts language/sequence-modeling approaches with traditional rule/regex-based log-detection (which fail to detect new/unseen messages) and classical methods; however, no quantitative comparison numbers are provided in the surveyed text.",
            "limitations_or_failure_cases": "Survey reports challenges: diversity and unstructured format of logs, evolving log message formats, need for real-time adaptation, and that existing rule-based methods miss novel messages; the paper does not provide specific failure-case numbers for language-model approaches.",
            "uuid": "e5740.2",
            "source_info": {
                "paper_title": "Deep Learning for Anomaly Detection: A Survey",
                "publication_date_yy_mm": "2019-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Du et al. [2017]",
            "rating": 2
        },
        {
            "paper_title": "Cakir and Dogdu [2018]",
            "rating": 2
        },
        {
            "paper_title": "Silva et al. [2018]",
            "rating": 2
        },
        {
            "paper_title": "Sakurada and Yairi [2014]",
            "rating": 1
        },
        {
            "paper_title": "Tuor et al. [2017]",
            "rating": 1
        }
    ],
    "cost": 0.010971499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>DEEP LEARNING FOR ANOMALY DETECTION: A SURVEY</h1>
<p>A Preprint</p>
<p>Raghavendra Chalapathy<br>University of Sydney,<br>Capital Markets Co-operative Research Centre (CMCRC)<br>rcha9612@uni.sydney.edu.au</p>
<p>Sanjay Chawla<br>Qatar Computing Research Institute (QCRI), HBKU<br>schawla@qf.org.qa</p>
<p>January 24, 2019</p>
<h4>Abstract</h4>
<p>Anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. The aim of this survey is two-fold, firstly we present a structured and comprehensive overview of research methods in deep learning-based anomaly detection. Furthermore, we review the adoption of these methods for anomaly across various application domains and assess their effectiveness. We have grouped state-of-the-art deep anomaly detection research techniques into different categories based on the underlying assumptions and approach adopted. Within each category, we outline the basic anomaly detection technique, along with its variants and present key assumptions, to differentiate between normal and anomalous behavior. Besides, for each category, we also present the advantages and limitations and discuss the computational complexity of the techniques in real application domains. Finally, we outline open issues in research and challenges faced while adopting deep anomaly detection techniques for real-world problems.</p>
<p>Keywords anomalies, outlier, novelty, deep learning</p>
<h2>1 Introduction</h2>
<p>A common need when analyzing real-world data-sets is determining which instances stand out as being dissimilar to all others. Such instances are known as anomalies, and the goal of anomaly detection (also known as outlier detection) is to determine all such instances in a data-driven fashion (Chandola et al. [2007]). Anomalies can be caused by errors in the data but sometimes are indicative of a new, previously unknown, underlying process; Hawkins [1980] defines an outlier as an observation that deviates so significantly from other observations as to arouse suspicion that it was generated by a different mechanism. In the broader field of machine learning, the recent years have witnessed a proliferation of deep neural networks, with unprecedented results across various application domains. Deep learning is a subset of machine learning that achieves good performance and flexibility by learning to represent the data as a nested hierarchy of concepts within layers of the neural network. Deep learning outperforms the traditional machine learning as the scale of data increases as illustrated in Figure 1. In recent years, deep learning-based anomaly detection algorithms have become increasingly popular and have been applied for a diverse set of tasks as illustrated in Figure 2; studies have shown that deep learning completely surpasses traditional methods (Javaid et al. [2016], Peng and Marculescu [2015]). The aim of this survey is two-fold, firstly we present a structured and comprehensive review of research methods in deep anomaly detection (DAD). Furthermore, we also discuss the adoption of DAD methods across various application domains and assess their effectiveness.</p>
<h2>2 What are anomalies?</h2>
<p>Anomalies are also referred to as abnormalities, deviants, or outliers in the data mining and statistics literature (Aggarwal [2013]). As illustrated in Figure 3, $N_{1}$ and $N_{2}$ are regions consisting of a majority of observations and hence considered as normal data instance regions, whereas the region $O_{3}$, and data points $O_{1}$ and $O_{2}$ are few data points which are located further away from the bulk of data points and hence are considered anomalies. arise due to several</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Performance Comparison of Deep learning-based algorithms Vs Traditional Algorithms Alejandro [2016].
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Applications Deep learning-based anomaly detection algorithms.
(a) Video Surveillance, Image Analysis: Illegal Traffic detection Xie et al. [2017], (b) Health-care: Detecting Retinal Damage Schlegl et al. [2017]
(c) Networks: Cyber-intrusion detection Javaid et al. [2016] (d) Sensor Networks: Internet of Things (IoT) big-data anomaly detection Mohammadi et al. [2017]
reasons, such as malicious actions, system failures, intentional fraud. These anomalies reveal exciting insights about the data and are often convey valuable information about data. Therefore, anomaly detection considered an essential step in various decision-making systems.</p>
<h1>3 What are novelties?</h1>
<p>Novelty detection is the identification of a novel (new) or unobserved patterns in the data (Miljković [2010]). The novelties detected are not considered as anomalous data points; instead, they are been applied to the regular data model. A novelty score may be assigned for these previously unseen data points, using a decision threshold score (Pimentel et al. [2014]). The points which significantly deviate from this decision threshold may be considered as anomalies or outliers. For instance, in Figure 4 the images of (white tigers) among regular tigers may be considered as a novelty, while the image of (horse, panther, lion, and cheetah) are considered as anomalies. The techniques used for anomaly detection are often used for novelty detection and vice versa.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Illustration of anomalies in two-dimensional data set.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Illustration of novelty in the image data set.</p>
<h1>4 Motivation and Challenges: Deep anomaly detection (DAD) techniques</h1>
<ul>
<li>Performance of traditional algorithms in detecting outliers is sub-optimal on the image (e.g. medical images) and sequence datasets since it fails to capture complex structures in the data.</li>
<li>Need for large-scale anomaly detection: As the volume of data increases let's say to gigabytes then, it becomes nearly impossible for the traditional methods to scale to such large scale data to find outliers.</li>
<li>Deep anomaly detection (DAD) techniques learn hierarchical discriminative features from data. This automatic feature learning capability eliminates the need of developing manual features by domain experts, therefore advocates to solve the problem end-to-end taking raw input data in domains such as text and speech recognition.</li>
<li>The boundary between normal and anomalous (erroneous) behavior is often not precisely defined in several data domains and is continually evolving. This lack of well-defined representative normal boundary poses challenges for both conventional and deep learning-based algorithms.</li>
</ul>
<p>Table 1: Comparison of our Survey to Other Related Survey Articles.
1 —Our Survey, 2 -Kwon and Donghwoon Kwon et al. [2017], 5 -John and Derek Ball et al. [2017]
3 -Kiran and Thomas Kiran et al. [2018], 6 -Mohammadi and Al-Fuqaha Mohammadi et al. [2017]
4 -Adewumi and Andronicus Adewumi and Akinyelu [2017] 7 -Geert and Kooi et.al Litjens et al. [2017].</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Methods</th>
<th style="text-align: center;">Supervised <br> Unsupervised <br> Hybrid Models <br> one-Class Neural Networks</th>
<th style="text-align: center;">$\checkmark$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Applications</td>
<td style="text-align: center;">Fraud Detection</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\checkmark$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cyber-Intrusion Detection</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Medical Anomaly Detection</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Sensor Networks Anomaly Detection</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Internet Of Things (IoT) Big-data Anomaly Detection</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Log-Anomaly Detection</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Video Surveillance</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Industrial Damage Detection</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<h2>5 Related Work</h2>
<p>Despite the substantial advances made by deep learning methods in many machine learning problems, there is a relative scarcity of deep learning approaches for anomaly detection. Adewumi and Akinyelu [2017] provide a comprehensive survey of deep learning-based methods for fraud detection. A broad review of deep anomaly detection (DAD) techniques for cyber-intrusion detection is presented by Kwon et al. [2017]. An extensive review of using DAD techniques in the medical domain is presented by Litjens et al. [2017]. An overview of DAD techniques for the Internet of</p>
<p>Things (IoT) and big-data anomaly detection is introduced by <em>Mohammadi et al. (2017)</em>. Sensor networks anomaly detection has been reviewed by <em>Ball et al. (2017)</em>. The state-of-the-art deep learning based methods for video anomaly detection along with various categories have been presented in <em>Kiran et al. (2018)</em>. Although there are some reviews in applying DAD techniques, there is a shortage of comparative analysis of deep learning architecture adopted for outlier detection. For instance, a substantial amount of research on anomaly detection is conducted using deep autoencoders, but there is a lack of comprehensive survey of various deep architecture’s best suited for a given data-set and application domain. We hope that this survey bridges this gap and provides a comprehensive reference for researchers and engineers aspiring to leverage deep learning for anomaly detection. Table 1 shows the set of research methods and application domains covered by our survey.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Key components associated with deep learning-based anomaly detection technique.</p>
<h2>6 Our Contributions</h2>
<p>We follow the survey approach of (<em>Chandola et al. (2007)</em>) for deep anomaly detection (DAD). Our survey presents a detailed and structured overview of research and applications of DAD techniques. We summarize our main contributions as follows:</p>
<ul>
<li>Most of the existing surveys on DAD techniques either focus on a particular application domain or specific research area of interest (<em>Kiran et al. (2018); Mohammadi et al. (2017); Litjens et al. (2017); Kwon et al. (2017); Adewumi and Akinyelu (2017); Ball et al. (2017)</em>). This review aims to provide a comprehensive outline of state-of-the-art research in DAD techniques as well as several real-world applications these techniques is presented.</li>
<li>In recent years several new deep learning based anomaly detection techniques with greatly reduced computational requirements have been developed. The purpose of this paper is to survey these techniques and classify them into an organized schema for better understanding. We introduce two more sub-categories Hybrid models (<em>Erfani et al. (2016a)</em>) and one-class neural networks techniques (<em>Chalapathy et al. (2018a)</em>) as illustrated in Figure 5 based on the choice of training objective. For each category we discuss both the assumptions and techniques adopted for best performance. Furthermore, within each category, we also present the challenges, advantages, and disadvantages and provide an overview of the computational complexity of DAD methods.</li>
</ul>
<h2>7 Organization</h2>
<p>This chapter is organized by following structure described in Figure 5. In Section 8, we identify the various aspects that determine the formulation of the problem and highlight the richness and complexity associated with anomaly detection. We introduce and define two types of models: contextual and collective or group anomalies. In Section 9, we briefly describe the different application domains to which deep learning-based anomaly detection has been applied. In subsequent sections, we provide a categorization of deep learning-based techniques based on the research area to which they belong. Based on training objectives employed and availability of labels deep learning-based anomaly detection</p>
<table>
<thead>
<tr>
<th>Type of Data</th>
<th>Examples</th>
<th>DAD model architecture</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sequential</td>
<td>Video,Speech</td>
<td>CNN, RNN, LSTM</td>
</tr>
<tr>
<td></td>
<td>Protein Sequence,Time Series</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Text (Natural language)</td>
<td></td>
</tr>
<tr>
<td>Non-</td>
<td>Image,Sensor</td>
<td>CNN, AE and its variants</td>
</tr>
<tr>
<td>Sequential</td>
<td>Other (data)</td>
<td></td>
</tr>
</tbody>
</table>
<p>Table 2: Table illustrating nature of input data and corresponding deep anomaly detection model architectures proposed in literature.
CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks
AE: Autoencoders.
techniques can be categorized into supervised (Section 10.1), unsupervised (Section 10.5), hybrid (Section 10.3), and one-class neural network (Section 10.4). For each category of techniques we also discuss their computational complexity for training and testing phases. In Section 8.4 we discuss the point, contextual, and collective (group) deep learning-based anomaly detection techniques. We present some discussion of the limitations and relative performance of various existing techniques in Section 12. Section 13 contains concluding remarks.</p>
<h1>8 Different aspects of deep learning-based anomaly detection.</h1>
<p>This section identifies and discusses the different aspects of deep learning-based anomaly detection.</p>
<h3>8.1 Nature of Input Data</h3>
<p>The choice of a deep neural network architecture in deep anomaly detection methods primarily depends on the nature of input data. Input data can be broadly classified into sequential (eg, voice, text, music, time series, protein sequences) or non-sequential data (eg, images, other data). Table 2 illustrates the nature of input data and deep model architectures used in anomaly detection. Additionally input data depending on the number of features (or attributes) can be further classified into either low or high-dimensional data. DAD techniques have been to learn complex hierarchical feature relations within high-dimensional raw input data (LeCun et al. [2015]). The number of layers used in DAD techniques is driven by input data dimension, deeper networks are shown to produce better performance on high dimensional data. Later on, in Section 10 various models considered for outlier detection are reviewed at depth.</p>
<h3>8.2 Based on Availability of labels</h3>
<p>Labels indicate whether a chosen data instance is normal or an outlier. Anomalies are rare entities hence it is challenging to obtain their labels. Furthermore, anomalous behavior may change over time, for instance, the nature of anomaly had changed so significantly and that it remained unnoticed at Maroochy water treatment plant, for a long time which resulted in leakage of 150 million liters of untreated sewerage to local waterways (Ramotsoela et al. [2018]).
Deep anomaly detection (DAD) models can be broadly classified into three categories based on the extent of availability of labels. (1) Supervised deep anomaly detection. (2) Semi-supervised deep anomaly detection. (3) Unsupervised deep anomaly detection.</p>
<h3>8.2.1 Supervised deep anomaly detection</h3>
<p>Supervised deep anomaly detection involves training a deep supervised binary or multi-class classifier, using labels of both normal and anomalous data instances. For instance supervised DAD models, formulated as multi-class classifier aids in detecting rare brands, prohibited drug name mention and fraudulent health-care transactions (Chalapathy et al. [2016a,b]). Despite the improved performance of supervised DAD methods, these methods are not as popular as semi-supervised or unsupervised methods, owing to the lack of availability of labeled training samples. Moreover, the performance of deep supervised classifier used an anomaly detector is sub-optimal due to class imbalance (the total number of positive class instances are far more than the total number of negative class of data). Therefore we do not consider the review of supervised DAD methods in this survey.</p>
<h3>8.2.2 Semi-supervised deep anomaly detection</h3>
<p>The labels of normal instances are far more easy to obtain than anomalies, as a result, semi-supervised DAD techniques are more widely adopted, these techniques leverage existing labels of single (normally positive class) to separate</p>
<p>outliers. One common way of using deep autoencoders in anomaly detection is to train them in a semi-supervised way on data samples with no anomalies. With sufficient training samples, of normal class autoencoders would produce low reconstruction errors for normal instances, over unusual events (Wulsin et al. [2010], Nadeem et al. [2016], Song et al. [2017]). We consider a detailed review of these methods in Section 10.2.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Taxonomy based on the type of deep learning models for anomaly detection.</p>
<h1>8.2.3 Unsupervised deep anomaly detection</h1>
<p>Unsupervised deep anomaly detection techniques detect outliers solely based on intrinsic properties of the data instances. Unsupervised DAD techniques are used in automatic labeling of unlabelled data samples since labeled data is very hard to obtain (Patterson and Gibson [2017]). Variants of Unsupervised DAD models (Tuor et al. [2017]) are shown to outperform traditional methods such as principal component analysis (PCA) (Wold et al. [1987]), support vector machine (SVM) Cortes and Vapnik [1995] and Isolation Forest (Liu et al. [2008]) techniques in applications domains such as health and cyber-security. Autoencoders are the core of all Unsupervised DAD models. These models assume a high prevalence of normal instances than abnormal data instances failing which would result in high false positive rate. Additionally unsupervised learning algorithms such as restricted Boltzmann machine (RBM) (Sutskever et al. [2009]), deep Boltzmann machine (DBM), deep belief network (DBN) (Salakhutdinov and Larochelle [2010]), generalized denoising autoencoders (Vincent et al. [2008]), recurrent neural network (RNN) (Rodriguez et al. [1999]) Long short term memory networks (Lample et al. [2016]) which are used to detect outliers are discussed in detail in Section 11.7.</p>
<h3>8.3 Based on the training objective</h3>
<p>In this survey we introduce two new categories of deep anomaly detection (DAD) techniques based on training objectives employed 1) Deep hybrid models (DHM). 2) One class neural networks (OC-NN).</p>
<h3>8.3.1 Deep Hybrid Models (DHM)</h3>
<p>Deep hybrid models for anomaly detection use deep neural networks mainly autoencoders as feature extractors, the features learned within the hidden representations of autoencoders are input to traditional anomaly detection algorithms such as one-class SVM (OC-SVM) to detect outliers (Andrews et al. [2016a]). Figure 7 illustrates the deep hybrid model architecture used for anomaly detection. Following the success of transfer learning to obtain rich representative features from models pre-trained on large data-sets, hybrid models have also employed these pre-trained transfer learning models as feature extractors with great success (Pan et al. [2010]). A variant of hybrid model was proposed by Ergen et al. [2017] which considers joint training of feature extractor along-with OC-SVM (or SVDD) objective to maximize the detection performance. A notable shortcoming of these hybrid approaches is the lack of trainable objective customized for anomaly detection, hence these models fail to extract rich differential features to detect outliers. In order to overcome this limitation customized objective for anomaly detection such as Deep one-class classification (Ruff et al. [2018a]) and One class neural networks (Chalapathy et al. [2018a]) is introduced.</p>
<h3>8.3.2 One-Class Neural Networks (OC-NN)</h3>
<p>One class neural network (OC-NN) Chalapathy et al. [2018a] methods are inspired by kernel-based one-class classification which combines the ability of deep networks to extract a progressively rich representation of data with the one-class objective of creating a tight envelope around normal data. The OC-NN approach breaks new ground for the following crucial reason: data representation in the hidden layer is driven by the OC-NN objective and is thus</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: Deep Hybrid Model Architecture.
customized for anomaly detection. This is a departure from other approaches which use a hybrid approach of learning deep features using an autoencoder and then feeding the features into a separate anomaly detection method like one-class SVM (OC-SVM). The details of training and evaluation of one class neural networks is discussed in Section 10.4. Another variant of one class neural network architecture Deep Support Vector Data Description (Deep SVDD) (Ruff et al. [2018a]) trains deep neural network to extract common factors of variation by closely mapping the normal data instances to the center of sphere, is shown to produce performance improvements on MNIST (LeCun et al. [2010]) and CIFAR-10 (Krizhevsky and Hinton [2009]) datasets.</p>
<h1>8.4 Type of Anomaly</h1>
<p>Anomalies can be broadly classified into three types: point anomalies, contextual anomalies and collective anomalies. Deep anomaly detection (DAD) methods have been shown to detect all three types of anomalies with great success.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Deep learning techniques classification based on the type of anomaly.</p>
<h3>8.4.1 Point Anomalies</h3>
<p>The majority of work in literature focuses on point anomalies. Point anomalies often represent an irregularity or deviation that happens randomly and may have no particular interpretation. For instance, in Figure 10 a credit card transaction with high expenditure recorded at Monaco restaurant seems a point anomaly since it significantly deviates from the rest of the transactions. Several real world applications, considering point anomaly detection, are reviewed in Section 9.</p>
<h3>8.4.2 Contextual Anomaly Detection</h3>
<p>A contextual anomaly is also known as the conditional anomaly is a data instance that could be considered as anomalous in some specific context (Song et al. [2007]). Contextual anomaly is identified by considering both contextual and behavioural features. The contextual features, normally used are time and space. While the behavioral features may be</p>
<p>a pattern of spending money, the occurrence of system log events or any feature used to describe the normal behavior. Figure 9a illustrates the example of a contextual anomaly considering temperature data indicated by a drastic drop just before June; this value is not indicative of a normal value found during this time. Figure 9b illustrates using deep Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber [1997]) based model to identify anomalous system log events (Du et al. [2017]) in a given context (e.g event 53 is detected as being out of context).
<img alt="img-8.jpeg" src="img-8.jpeg" />
(a) Temperature data Hayes and Capretz [2015].
<img alt="img-9.jpeg" src="img-9.jpeg" />
(b) System logs Du et al. [2017].</p>
<p>Figure 9: Illustration of contextual anomaly detection.</p>
<h1>8.4.3 Collective or Group Anomaly Detection.</h1>
<p>Anomalous collections of individual data points are known as collective or group anomalies, wherein each of the individual points in isolation appears as normal data instances while observed in a group exhibit unusual characteristics. For example, consider an illustration of a fraudulent credit card transaction, in the log data shown in Figure 10, if a single transaction of "MISC" would have occurred, it might probably not seem as anomalous. The following group of transactions of valued at $\$ 75$ certainly seems to be a candidate for collective or group anomaly. Group anomaly detection (GAD) with an emphasis on irregular group distributions (e.g., irregular mixtures of image pixels are detected using a variant of autoencoder model (Chalapathy et al. [2018b], Bontemps et al. [2016], Araya et al. [2016], Zhuang et al. [2017]).
<img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<p>Figure 10: Credit Card Fraud Detection: Illustrating Point and Collective anomaly.</p>
<h3>8.5 Output of DAD Techniques</h3>
<p>A critical aspect for anomaly detection methods is the way in which the anomalies are detected. Generally, the outputs produced by anomaly detection methods are either anomaly score or binary labels.</p>
<h3>8.5.1 Anomaly Score:</h3>
<p>Anomaly score describes the level of outlierness for each data point. The data instances may be ranked according to anomalous score, and a domain-specific threshold (commonly known as decision score) will be selected by subject matter expert to identify the anomalies. In general, decision scores reveal more information than binary labels. For instance, in Deep SVDD approach the decision score is the measure of the distance of data point from the center of the sphere, the data points which are farther away from the center are considered anomalous (Ruff et al. [2018b]).</p>
<p>Table 3: Examples of DAD Techniques employed in HIDS
CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks
GRU: Gated Recurrent Unit, DNN : Deep Neural Networks
SPN: Sum Product Networks</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Techniques</th>
<th style="text-align: center;">Model Architecture</th>
<th style="text-align: center;">Section</th>
<th style="text-align: center;">References</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Discriminative</td>
<td style="text-align: center;">LSTM , CNN-LSTM-GRU, DNN</td>
<td style="text-align: center;">Section 11.7, 11.6, 11.1</td>
<td style="text-align: center;">Kim et al. [2016],Chawla et al. [2018],Chen et al. [2018],Sohi et al. [2018],Vinayakumar et al. [2017]</td>
</tr>
<tr>
<td style="text-align: center;">Hybrid</td>
<td style="text-align: center;">GAN</td>
<td style="text-align: center;">Section 10.3</td>
<td style="text-align: center;">Aghakhani et al. [2018], Li et al. [2018]</td>
</tr>
<tr>
<td style="text-align: center;">Generative</td>
<td style="text-align: center;">AE, SPN,</td>
<td style="text-align: center;">Section 11.8, 11.3</td>
<td style="text-align: center;">Gao et al. [2014],Peharz et al. [2018],Umer et al. [2018]</td>
</tr>
</tbody>
</table>
<h1>8.5.2 Labels:</h1>
<p>Instead of assigning scores, some techniques may assign a category label as normal or anomalous to each data instance. Unsupervised anomaly detection techniques using autoencoders measure the magnitude of the residual vector (i,e reconstruction error) for obtaining anomaly scores, later on, the reconstruction errors are either ranked or thresholded by domain experts to label data instances.</p>
<h2>9 Applications of Deep Anomaly Detection</h2>
<p>In this section, we discuss several applications of deep anomaly detection. For each application domain, we discuss the following four aspects:
-the notion of an anomaly;
-nature of the data;
-challenges associated with detecting anomalies;
-existing deep anomaly detection techniques.</p>
<h3>9.1 Intrusion Detection</h3>
<p>The intrusion detection system (IDS) refers to identifying malicious activity in a computer-related system (Phoha [2002]). IDS may be deployed at single computers known as Host Intrusion Detection (HIDS) to large networks Network Intrusion Detection (NIDS). The classification of deep anomaly detection techniques for intrusion detection is in Figure 11. IDS depending on detection method are classified into signature-based or anomaly based. Using signature-based IDS is not efficient to detect new attacks, for which no specific signature pattern is available, hence anomaly based detection methods are more popular. In this survey, we focus on deep anomaly detection (DAD) methods and architectures employed in intrusion detection.</p>
<h3>9.1.1 Host-Based Intrusion Detection Systems (HIDS):</h3>
<p>Such systems are installed software programs which monitors a single host or computer for malicious activity or policy violations by listening to system calls or events occurring within that host (Vigna and Kruegel [2005]). The system call logs could be generated by programs or by user interaction resulting in logs as shown in Figure 9b. Malicious interactions lead to the execution of these system calls in different sequences. HIDS may also monitor the state of a system, its stored information, in Random Access Memory (RAM), in the file system, log files or elsewhere for a valid sequence. Deep anomaly detection (DAD) techniques applied for HIDS are required to handle the variable length and sequential nature of data. The DAD techniques have to either model the sequence data or compute the similarity between sequences. Some of the success-full DAD techniques for HIDS is illustrated in Table 3.</p>
<h3>9.1.2 Network Intrusion Detection Systems (NIDS):</h3>
<p>NIDS systems deal with monitoring the entire network for suspicious traffic by examining each and every network packet. Owing to real-time streaming behavior, the nature of data is synonymous to big data with high volume, velocity, variety. The network data also has a temporal aspect associated with it. Some of the success-full DAD techniques for NIDS is illustrated in Table 4 . This survey also lists the data-sets used for evaluating the DAD intrusion detection methods in Table 5. A challenge faced by DAD techniques in intrusion detection is that the nature of anomalies keeps changing over time as the intruders adapt their network attacks to evade the existing intrusion detection solutions.</p>
<p>Table 4: Examples of DAD Techniques employed in NIDS.
CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks
RNN: Recurrent Neural Networks, RBM : Restricted Boltzmann Machines
DCA: Dilated Convolution Autoencoders, DBN : Deep Belief Network
AE: Autoencoders, SAE: Stacked Autoencoders
GAN: Generative Adversarial Networks, CVAE : Convolutional Variational Autoencoder.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Techniques</th>
<th style="text-align: center;">Model Architecture</th>
<th style="text-align: center;">Section</th>
<th style="text-align: center;">References</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Generative</td>
<td style="text-align: center;">DCA, SAE, RBM, DBN, <br> CVAE</td>
<td style="text-align: center;">Section 11.6, 11.8, 11.1, 11.5</td>
<td style="text-align: center;">Yu et al. [2017],Thing [2017], Zolotukhin et al. [2016], Cordero et al. [2016],Alrawashdeh and Purdy [2016], Tang et al. [2016],Lopez-Martin et al. [2017],Al-Qutf et al. [2018],Mirsky et al. [2018],Aygun and Yavuz [2017]</td>
</tr>
<tr>
<td style="text-align: center;">Hybrid</td>
<td style="text-align: center;">GAN</td>
<td style="text-align: center;">Section 10.3</td>
<td style="text-align: center;">Lin et al. [2018],Yin et al. [2018], Ring et al. [2018], Latah [2018], Intrator et al. [2018],Matsubara et al. [2018], Nicolau et al. [2016] ,Rigaki [2017].</td>
</tr>
<tr>
<td style="text-align: center;">Discriminative</td>
<td style="text-align: center;">RNN, LSTM,CNN</td>
<td style="text-align: center;">Section 11.7, 11.6</td>
<td style="text-align: center;">Yu et al. [2017], Malaiya et al. [2018] Kwon et al. [2018],Gao et al. [2014],Staudemeyer [2015],Naseer et al. [2018]</td>
</tr>
</tbody>
</table>
<p>Table 5: Datasets Used in Intrusion Detection</p>
<table>
<thead>
<tr>
<th style="text-align: center;">DataSet</th>
<th style="text-align: center;">IDS</th>
<th style="text-align: center;">Description</th>
<th style="text-align: center;">Type</th>
<th style="text-align: center;">References</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">CTU-UNB</td>
<td style="text-align: center;">NIDS</td>
<td style="text-align: center;">CTU-UNB ucs [2017] dataset consists of various botnet traffics from CTU-13 dataset [20] and normal traffics from the UNB ISCX IDS 2012 dataset Shiravi et al. [2012]</td>
<td style="text-align: center;">Hexadecimal</td>
<td style="text-align: center;">Yu et al. [2017]</td>
</tr>
<tr>
<td style="text-align: center;">Contagio-CTU-UNB</td>
<td style="text-align: center;">NIDS</td>
<td style="text-align: center;">Contagio-CTU-UNB dataset consists of six types of network traffic data. Adam et al. [2008]</td>
<td style="text-align: center;">Text</td>
<td style="text-align: center;">Yu et al. [2017].</td>
</tr>
<tr>
<td style="text-align: center;">NSL-KDD ${ }^{1}$</td>
<td style="text-align: center;">NIDS</td>
<td style="text-align: center;">The NSL-KDD data set is a refined version of its predecessor KDD-99 data set. ucs [2017]</td>
<td style="text-align: center;">Text</td>
<td style="text-align: center;">Yin et al. [2017], Javaid et al. [2016], Tang et al. [2016], YousefiAzar et al. [2017], Mohammadi and Namadchian [2017], Lopez-Martin et al. [2017]</td>
</tr>
<tr>
<td style="text-align: center;">DARPA KDD- CUP 99</td>
<td style="text-align: center;">NIDS</td>
<td style="text-align: center;">DARPA KDD Stolfo et al. [2000] The competition task was to build a network intrusion detector, a predictive model capable of distinguishing between "bad" connections, called intrusions or attacks, and "good" normal connections.</td>
<td style="text-align: center;">Text</td>
<td style="text-align: center;">Alrawashdeh and Purdy [2016] , Van et al. [2017], Mohammadi and Namadchian [2017]</td>
</tr>
<tr>
<td style="text-align: center;">MAWI</td>
<td style="text-align: center;">NIDS</td>
<td style="text-align: center;">The MAWI Fontugne et al. [2010] dataset consists of network traffic capturedfrom backbone links between Japan and USA. Every daysince 2007</td>
<td style="text-align: center;">Text</td>
<td style="text-align: center;">Cordero et al. [2016]</td>
</tr>
<tr>
<td style="text-align: center;">Realistic Global Cyber Environment (RGCE)</td>
<td style="text-align: center;">NIDS</td>
<td style="text-align: center;">RGCE jam [2009] contains realistic Internet Service Providers (ISPs) and numerous different web services as in the real Internet.</td>
<td style="text-align: center;">Text</td>
<td style="text-align: center;">Zolotukhin et al. [2016]</td>
</tr>
<tr>
<td style="text-align: center;">ADFA-LD</td>
<td style="text-align: center;">HIDS</td>
<td style="text-align: center;">The ADFA Linux Dataset (ADFALD). This dataset provides a contemporary Linux dataset for evaluation by traditional HIDS Creech and Hu [2014]</td>
<td style="text-align: center;">Text</td>
<td style="text-align: center;">Kim et al. [2016], Chawla et al. [2018]</td>
</tr>
<tr>
<td style="text-align: center;">UNM-LPR</td>
<td style="text-align: center;">HIDS</td>
<td style="text-align: center;">Consists of system calls to evalute HIDS system University [2012]</td>
<td style="text-align: center;">Text</td>
<td style="text-align: center;">Kim et al. [2016]</td>
</tr>
<tr>
<td style="text-align: center;">Infected PDF samples</td>
<td style="text-align: center;">HIDS</td>
<td style="text-align: center;">Consists of set of Infected PDF samples, which are used to monitor the malicious traffic</td>
<td style="text-align: center;">Text</td>
<td style="text-align: center;">Chen et al. [2018]</td>
</tr>
</tbody>
</table>
<p><img alt="img-11.jpeg" src="img-11.jpeg" /></p>
<p>Figure 11: Classification of deep learning methods for intrusion detection.</p>
<h1>9.2 Fraud Detection</h1>
<p>Fraud is a deliberate act of deception to access valuable resources (Abdallah et al. [2016]). The PricewaterhouseCoopers (PwC) global economic crime survey of 2018 (Lavion [2018], Zhao [2013]) found that half of the 7,200 companies they surveyed had experienced fraud of some nature. Fraud detection refers to the detection of unlawful activities across various industries, illustrated in 12.
<img alt="img-12.jpeg" src="img-12.jpeg" /></p>
<p>Figure 12: Fraud detection across various application domains.</p>
<p>Fraud in telecommunications, insurance ( health, automobile, etc) claims, banking ( tax return claims, credit card transactions etc) represent significant problems in both governments and private businesses. Detecting and preventing fraud is not a simple task since fraud is an adaptive crime. Many traditional machine learning algorithms have been applied successfully in fraud detection (Sorournejad et al. [2016]). The challenge associated with detecting fraud is that it requires real-time detection and prevention. This section focuses on deep anomaly detection (DAD) techniques for fraud detection.</p>
<p>Table 6: Examples of DAD techniques used in credit card fraud detection.
AE: Autoencoders, LSTM : Long Short Term Memory Networks
RBM: Restricted Botlzmann Machines, DNN : Deep Neural Networks
GRU: Gated Recurrent Unit, RNN: Recurrent Neural Networks
CNN: Convolutional Neural Networks,VAE: Variational Autoencoders
GAN: Generative Adversarial Networks</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Technique Used</th>
<th style="text-align: left;">Section</th>
<th style="text-align: left;">References</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">AE</td>
<td style="text-align: left;">Section 11.8</td>
<td style="text-align: left;">Schreyer et al. [2017], Wedge et al. [2017] , Paula et al. [2016], Ren- <br> ström and Holmsten [2018], Kazemi and Zarrabi [2017], Zheng et al. <br> [2018a], Pumsirirat and Yan [2018]</td>
</tr>
<tr>
<td style="text-align: left;">RBM</td>
<td style="text-align: left;">Section 11.1</td>
<td style="text-align: left;">Pumsirirat and Yan [2018]</td>
</tr>
<tr>
<td style="text-align: left;">DBN</td>
<td style="text-align: left;">Section 11.1</td>
<td style="text-align: left;">Seeja and Zareapoor [2014]</td>
</tr>
<tr>
<td style="text-align: left;">VAE</td>
<td style="text-align: left;">Section 11.5</td>
<td style="text-align: left;">Sweers et al. [2018]</td>
</tr>
<tr>
<td style="text-align: left;">GAN</td>
<td style="text-align: left;">Section 11.5</td>
<td style="text-align: left;">Fiore et al. [2017], Choi and Jang [2018]</td>
</tr>
<tr>
<td style="text-align: left;">DNN</td>
<td style="text-align: left;">Section 11.1</td>
<td style="text-align: left;">Dorronsoro et al. [1997], Gómez et al. [2018]</td>
</tr>
<tr>
<td style="text-align: left;">LSTM,RNN,GRU</td>
<td style="text-align: left;">Section 11.7</td>
<td style="text-align: left;">Wiese and Omlin [2009], Jurgovsky et al. [2018], Heryadi and Warnars <br> [2017], Ando et al. [2016], Wang et al. [2017a], Alowais and Soon <br> [2012], Amarasinghe et al. [2018a], Abroyan [2017a], Lp et al. [2018]</td>
</tr>
<tr>
<td style="text-align: left;">CNN</td>
<td style="text-align: left;">Section 11.6</td>
<td style="text-align: left;">Shen et al. [2007], Chouiekh and Haj [2018], Abroyan [2017b], Fu <br> et al. [2016], Lu [2017], Wang et al. [2018a], Abroyan [2017a] , Zhang <br> et al. [2018a]</td>
</tr>
</tbody>
</table>
<p>Table 7: Examples of DAD techniques used in mobile cellular network fraud detection.
CNN: convolution neural networks,DBN: Deep Belief Networks
SAE: Stacked Autoencoders, DNN : Deep neural networks
GAN: Generative Adversarial Networks</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Technique Used</th>
<th style="text-align: left;">Section</th>
<th style="text-align: left;">References</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">CNN</td>
<td style="text-align: left;">Section 11.6</td>
<td style="text-align: left;">Chouiekh and Haj [2018]</td>
</tr>
<tr>
<td style="text-align: left;">SAE, DBN</td>
<td style="text-align: left;">Section 11.8, 11.1</td>
<td style="text-align: left;">Alsheikh et al. [2016], Badhe <br> $[2017]$</td>
</tr>
<tr>
<td style="text-align: left;">DNN</td>
<td style="text-align: left;">Section 11.1</td>
<td style="text-align: left;">Akhter and Ahamad [2012], Jain <br> $[2017]$</td>
</tr>
<tr>
<td style="text-align: left;">GAN</td>
<td style="text-align: left;">Section 11.5</td>
<td style="text-align: left;">Zheng et al. [2018b]</td>
</tr>
</tbody>
</table>
<h1>9.2.1 Banking fraud</h1>
<p>Credit card has become a popular payment method in online shopping for goods and services. Credit card fraud involves theft of a payment card details, and use it as a fraudulent source of funds in a transaction. Many techniques for credit card fraud detection have been presented in the last few years (Zhou et al. [2018], Suganya and Kamalraj [2015]). We will briefly review some of DAD techniques as shown in Table 6. The challenge in credit card fraud detection is that frauds have no consistent patterns. The typical approach in credit card fraud detection is to maintain a usage profile for each user and monitor the user profiles to detect any deviations. Since there are billions of credit card users this technique of user profile approach is not very scalable. Owing to the inherent scalable nature of DAD techniques techniques are gaining broad spread adoption in credit card fraud detection.</p>
<h3>9.2.2 Mobile cellular network fraud</h3>
<p>In recent times, mobile cellular networks have witnessed rapid deployment and evolution supporting billions of users and a vastly diverse array of mobile devices. Due to this broad adoption and low mobile cellular service rates, mobile cellular networks is now faced with frauds such as voice scams targeted to steal customer private information, and messaging related scams to extort money from customers. Detecting such fraud is of paramount interest and not an easy task due to volume and velocity of the mobile cellular network. Traditional machine learning methods with static feature engineering techniques fail to adapt to the nature of evolving fraud. Table 7 lists DAD techniques for mobile cellular network fraud detection.</p>
<h3>9.2.3 Insurance fraud</h3>
<p>Several traditional machine learning methods have been applied successfully to detect fraud in insurance claims (Joudaki et al. [2015], Roy and George [2017]). The traditional approach for fraud detection is based on features</p>
<p>Table 8: Examples of DAD techniques used in insurance fraud detection.
DBN: Deep Belief Networks, DNN : Deep Neural Networks
CNN: Convolutional Neural Networks,VAE: Variational Autoencoders
GAN: Generative Adversarial Networks</p>
<table>
<thead>
<tr>
<th style="text-align: left;">DBN</th>
<th style="text-align: left;">Section 11.1</th>
<th style="text-align: left;">Viaene et al. [2005]</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">VAE</td>
<td style="text-align: left;">Section 11.5</td>
<td style="text-align: left;">Fajardo et al. [2018]</td>
</tr>
<tr>
<td style="text-align: left;">GAN</td>
<td style="text-align: left;">Section 11.5</td>
<td style="text-align: left;">Fiore et al. [2017], Choi and <br> Jang [2018]</td>
</tr>
<tr>
<td style="text-align: left;">DNN</td>
<td style="text-align: left;">Section 11.1</td>
<td style="text-align: left;">Keung et al. [2009]</td>
</tr>
<tr>
<td style="text-align: left;">CNN</td>
<td style="text-align: left;">Section 11.6</td>
<td style="text-align: left;">Shen et al. [2007], Zhang <br> et al. [2018a]</td>
</tr>
</tbody>
</table>
<p>Table 9: Examples of DAD techniques used in healthcare fraud detection.
RBM: Restricted Botlzmann Machines, GAN: Generative Adversarial Networks</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Technique Used</th>
<th style="text-align: left;">Section</th>
<th style="text-align: left;">References</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">RBM</td>
<td style="text-align: left;">Section 11.1</td>
<td style="text-align: left;">Lasaga and Santhana [2018]</td>
</tr>
<tr>
<td style="text-align: left;">GAN</td>
<td style="text-align: left;">Section 11.5</td>
<td style="text-align: left;">Ghasedi Dizaji et al. [2018], Fin- <br> layson et al. [2018]</td>
</tr>
<tr>
<td style="text-align: left;">CNN</td>
<td style="text-align: left;">Section 11.6</td>
<td style="text-align: left;">Esteva et al. [2017]</td>
</tr>
</tbody>
</table>
<p>which are fraud indicators. The challenge with these traditional approaches is that the need for manual expertise to extract robust features. Another challenge is insurance fraud detection is the that the incidence of frauds is far less than the total number of claims, and also each fraud is unique in its way. In order to overcome these limitations several DAD techniques are proposed which are illustrated in Table 8.</p>
<h1>9.2.4 Healthcare fraud</h1>
<p>Healthcare is an integral component in people's lives, waste, abuse, and fraud drive up costs in healthcare by tens of billions of dollars each year. Healthcare insurance claims fraud is a significant contributor to increased healthcare costs, but its impact can be mitigated through fraud detection. Several machine learning models have been used effectively in health care insurance fraud (Bauder and Khoshgoftaar [2017]). Table 9 presents an overview of DAD methods for health-care fraud identification.</p>
<h3>9.3 Malware Detection</h3>
<p>Malware, short for Malicious Software. In order to protect legitimate users from malware, machine learning based efficient malware detection methods are proposed (Ye et al. [2017]). In classical machine learning methods, the process of malware detection is usually divided into two stages: feature extraction and classification/clustering. The performance of traditional malware detection approaches critically depend on the extracted features and the methods for classification/clustering. The challenge associated in malware detection problems is the sheer scale of data, for instance considering data as bytes a specific sequence classification problem could be of the order of two million time steps. Furthermore, the malware is very adaptive in nature, wherein the attackers would use advanced techniques to hide the malicious behavior. Some DAD techniques which address these challenges effectively and detect malware are shown in Table 10.</p>
<h3>9.4 Medical Anomaly Detection</h3>
<p>Several studies have been conducted to understand the theoretical and practical applications of deep learning in medical and bio-informatics (Min et al. [2017], Cao et al. [2018a], Zhao et al. [2016], Khan and Yairi [2018]). Finding rare events (anomalies) in areas such as medical image analysis, clinical electroencephalography (EEG) records, enable to diagnose and provide preventive treatments for a variety of medical conditions. Deep learning based architectures are employed with great success to detect medical anomalies as illustrated in Table 11. The vast amount of imbalanced data in medical domain presents significant challenges to detect outliers. Additionally deep learning techniques for long have been considered as black-box techniques. Even though deep learning models produce outstanding performance, these models lack interpret-ability. In recent times models with good interpret-ability are proposed and shown to produce state-of-the-art performance (Gugulothu et al., Amarasinghe et al. [2018b], Choi [2018]).</p>
<p>Table 10: Examples of DAD techniques used for malware detection. AE: Autoencoders, LSTM : Long Short Term Memory Networks RBM: Restricted Botlzmann Machines, DNN : Deep Neural Networks GRU: Gated Recurrent Unit, RNN: Recurrent Neural Networks CNN: Convolutional Neural Networks,VAE: Variational Autoencoders GAN: Generative Adversarial Networks,CNN-BiLSTM: CNN- Bidirectional LSTM</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Technique Used</th>
<th style="text-align: center;">Section</th>
<th style="text-align: center;">References</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">AE</td>
<td style="text-align: center;">Section 11.8</td>
<td style="text-align: center;">Yousefi-Azar et al. [2017], Hardy et al. [2016], Yousefi-Azar et al. [2017], De Paola et al. [2018], Sewak et al. [2018], Kebede et al. [2017], De Paola et al. [2018], David and Netanyahu [2015]</td>
</tr>
<tr>
<td style="text-align: center;">word2vec</td>
<td style="text-align: center;">Section 11.4</td>
<td style="text-align: center;">Cakir and Dogdu [2018], Silva et al. [2018]</td>
</tr>
<tr>
<td style="text-align: center;">CNN</td>
<td style="text-align: center;">Section 11.6</td>
<td style="text-align: center;">Kolosnjaji et al. [2018], Suciu et al. [2018], Srisakaokul et al. [2018], Srisakaokul et al. [2018], King et al. [2018], Huang and Kao [2017], Guo et al. [2017], Abdelsalam et al. [2018], Raff et al. [2017], Karbab et al. [2018], Martinelli et al. [2017], McLaughlin et al. [2017], Gibert et al. [2018], Kolosnjaji et al. [2017]</td>
</tr>
<tr>
<td style="text-align: center;">DNN</td>
<td style="text-align: center;">Section 11.1</td>
<td style="text-align: center;">Rosenberg et al. [2018], Wang et al. [2017b]</td>
</tr>
<tr>
<td style="text-align: center;">DBN</td>
<td style="text-align: center;">Section 11.1</td>
<td style="text-align: center;">David and Netanyahu [2015], YANG et al. [2016], Ding et al. [2016], Yuxin and Siyi [2017], Selvaganapathy et al. [2018], Yuxin and Siyi [2017], Hou et al. [2017]</td>
</tr>
<tr>
<td style="text-align: center;">LSTM</td>
<td style="text-align: center;">Section 11.7</td>
<td style="text-align: center;">Tobiyama et al. [2016], Hu and Tan [2017], Tobiyama et al. [2018] , Passalis and Tefas</td>
</tr>
<tr>
<td style="text-align: center;">CNN-BiLSTM</td>
<td style="text-align: center;">$\begin{aligned} &amp; \text { Section } \ &amp; 11.6,11.7 \end{aligned}$</td>
<td style="text-align: center;">Le et al. [2018], Wang et al. [2017b]</td>
</tr>
<tr>
<td style="text-align: center;">GAN</td>
<td style="text-align: center;">Section 11.5</td>
<td style="text-align: center;">Kim et al. [2018]</td>
</tr>
<tr>
<td style="text-align: center;">Hybrid model(AE- <br> CNN),(AE-DBN)</td>
<td style="text-align: center;">Section 10.3</td>
<td style="text-align: center;">Wang et al. [2018b], Li et al. [2015]</td>
</tr>
<tr>
<td style="text-align: center;">RNN</td>
<td style="text-align: center;">Section 11.7</td>
<td style="text-align: center;">HaddadPajouh et al. [2018]</td>
</tr>
</tbody>
</table>
<p>Table 11: Examples of DAD techniques Used for medical anomaly detection. AE: Autoencoders, LSTM : Long Short Term Memory Networks GRU: Gated Recurrent Unit, RNN: Recurrent Neural Networks CNN: Convolutional Neural Networks,VAE: Variational Autoencoders GAN: Generative Adversarial Networks, KNN: K-nearest neighbours RBM: Restricted Boltzmann Machines.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Technique Used</th>
<th style="text-align: center;">Section</th>
<th style="text-align: center;">References</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">AE</td>
<td style="text-align: center;">Section 11.8</td>
<td style="text-align: center;">Wang et al. [2016], Cowton et al. [2018], Sato et al. [2018]</td>
</tr>
<tr>
<td style="text-align: center;">DBN</td>
<td style="text-align: center;">Section 11.1</td>
<td style="text-align: center;">Turner et al. [2014], Sharma et al. [2016], Wulsin et al. [2010], Ma et al. [2018], Zhang et al. [2016], Wulsin et al. [2011] , Wu et al. [2015a]</td>
</tr>
<tr>
<td style="text-align: center;">RBM</td>
<td style="text-align: center;">Section 11.1</td>
<td style="text-align: center;">Liao et al. [2016]</td>
</tr>
<tr>
<td style="text-align: center;">VAE</td>
<td style="text-align: center;">Section 11.5</td>
<td style="text-align: center;">Xu et al. [2018], Lu and Xu [2018]</td>
</tr>
<tr>
<td style="text-align: center;">GAN</td>
<td style="text-align: center;">Section 11.5</td>
<td style="text-align: center;">Ghasedi Dizaji et al. [2018], Chen and Konukoglu [2018]</td>
</tr>
<tr>
<td style="text-align: center;">LSTM ,RNN,GRU</td>
<td style="text-align: center;">Section 11.7</td>
<td style="text-align: center;">Yang and Gao [2018], Jagannatha and Yu [2016], Cowton et al. [2018], O’Shea et al. [2016], Latif et al. [2018], Zhang and Zou [2018], Chauhan and Vig [2015], Gugulothu et al., Amarasinghe et al. [2018b]</td>
</tr>
<tr>
<td style="text-align: center;">CNN</td>
<td style="text-align: center;">Section 11.6</td>
<td style="text-align: center;">Schmidt-Erfurth et al. [2018], Esteva et al. [2017], Wang et al. [2016], Iakovidis et al. [2018]</td>
</tr>
<tr>
<td style="text-align: center;">Hybrid( AE+ KNN)</td>
<td style="text-align: center;">Section 11.6</td>
<td style="text-align: center;">Song et al. [2017]</td>
</tr>
</tbody>
</table>
<p>Table 12: Examples of DAD techniques used to detect anomalies in social network. CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks AE: Autoencoders, DAE: Denoising Autoencoders SVM : Support Vector Machines., DNN : Deep Neural Network</p>
<table>
<thead>
<tr>
<th>Technique Used</th>
<th>Section</th>
<th>References</th>
</tr>
</thead>
<tbody>
<tr>
<td>AE,DAE</td>
<td>Section 11.8</td>
<td>Zhang et al. [2017], Castellini et al. [2017]</td>
</tr>
<tr>
<td>CNN-LSTM</td>
<td>Section 11.6, 11.7</td>
<td>Sun et al. [2018], Shu et al. [2017], Yang et al. [2018]</td>
</tr>
<tr>
<td>DNN</td>
<td>Section 11.1</td>
<td>Li et al. [2017a]</td>
</tr>
<tr>
<td>Hybrid Models (CNN-LSTM-SVM)</td>
<td>Section 10.3</td>
<td>Wei [2017]</td>
</tr>
</tbody>
</table>
<p>Table 13: Examples of Deep learning anomaly detection techniques used in system logs. CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks GRU: Gated Recurrent Unit, DNN : Deep Neural Networks AE: Autoencoders, DAE: Denoising Autoencoders</p>
<table>
<thead>
<tr>
<th>Techniques</th>
<th>Section</th>
<th>References</th>
</tr>
</thead>
<tbody>
<tr>
<td>LSTM</td>
<td>Section 11.7</td>
<td>Hochreiter and Schmidhuber [1997], Brown et al. [2018], Tuor et al. [2017], Das et al. [2018], Malhotra et al. [2015]</td>
</tr>
<tr>
<td>AE</td>
<td>Section 11.8</td>
<td>Du et al. [2017], Andrews et al. [2016a] , Sakurada and Yairi [2014], Nolle et al. [2018a], Nolle et al. [2016]</td>
</tr>
<tr>
<td>LSTM-AE</td>
<td>$\begin{aligned} &amp; \text { Section } 11.7, \ &amp; 11.8 \end{aligned}$</td>
<td>Grover [2018], Wolpher [2018]</td>
</tr>
<tr>
<td>RNN</td>
<td>Section 11.7</td>
<td>Brown et al. [2018], Zhang et al. [2018b], Nanduri and Sherry [2016], Fengming et al. [2017]</td>
</tr>
<tr>
<td>DAE</td>
<td>Section 11.8</td>
<td>Marchi et al. [2015], Nolle et al. [2016]</td>
</tr>
<tr>
<td>CNN</td>
<td>Section 11.6</td>
<td>Lu et al. [2018], Yuan et al. [2018a], Racki et al. [2018], Zhou et al. [2016], Gorokhov et al. [2017], Liao et al. [2017], Cheng et al. [2017], Zhang et al. [2018c]</td>
</tr>
</tbody>
</table>
<h1>9.5 Deep learning for Anomaly detection in Social Networks</h1>
<p>In recent times, online social networks have become part and parcel of daily life. Anomalies in a social network are irregular often unlawful behavior pattern of individuals within a social network; such individuals may be identified as spammers, sexual predators, online fraudsters, fake users or rumor-mongers. Detecting these irregular patterns is of prime importance since if not detected, the act of such individuals can have a serious social impact. A survey of traditional anomaly detection techniques and its challenges to detect anomalies in social networks is a well studied topic in literature (Liu and Chawla [2017], Savage et al. [2014], Anand et al. [2017], Yu et al. [2016], Cao et al. [2018b], Yu et al. [2016]). The heterogeneous and dynamic nature of data presents significant challenges to DAD techniques. Despite these challenges, several DAD techniques illustrated in Table 12 are shown outperform state-of-the-art methods.</p>
<h3>9.6 Log Anomaly Detection</h3>
<p>Anomaly detection in log file aims to find text, which can indicate the reasons and the nature of the failure of a system. Most commonly, a domain-specific regular-expression is constructed from past experience which finds new faults by pattern matching. The limitation of such approaches is that newer messages of failures are easily are not detected (Memon [2008]). The unstructured and diversity in both format and semantics of log data pose significant challenges to log anomaly detection. Anomaly detection techniques should adapt to the concurrent set of log data generated and detect outliers in real time. Following the success of deep neural networks in real time text analysis, several DAD techniques illustrated in Table 13 model the log data as a natural language sequence are shown very effective in detecting outliers.</p>
<h3>9.7 Internet of things (IoT) Big Data Anomaly Detection</h3>
<p>IoT is identified as a network of devices that are interconnected with soft-wares, servers, sensors and etc. In the field of the Internet of things (IoT), data generated by weather stations, Radio-frequency identification (RFID) tags, IT infrastructure components, and some other sensors are mostly time-series sequential data. Anomaly detection in these</p>
<p>Table 14: Examples of DAD techniques used in Internet of things (IoT) Big Data Anomaly Detection. AE: Autoencoders, LSTM : Long Short Term Memory Networks DBN : Deep Belief Networks.</p>
<table>
<thead>
<tr>
<th>Techniques</th>
<th>Section</th>
<th>References</th>
</tr>
</thead>
<tbody>
<tr>
<td>AE</td>
<td>Section 11.8</td>
<td>Luo and Nagarajany [2018], Mo-</td>
</tr>
<tr>
<td></td>
<td></td>
<td>hammadi and Kwasinski [2018]</td>
</tr>
<tr>
<td>DBN</td>
<td>Section 11.1</td>
<td>Kakanakova and Stoyanov [2017]</td>
</tr>
<tr>
<td>LSTM</td>
<td>Section 11.7</td>
<td>Zhang et al. [2018d], Mudassar</td>
</tr>
<tr>
<td></td>
<td></td>
<td>et al. [2018]</td>
</tr>
</tbody>
</table>
<p>Table 15: Examples of DAD techniques used in industrial operations.
CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks GRU: Gated Recurrent Unit, DNN : Deep Neural Networks
AE: Autoencoders, DAE: Denoising Autoencoders, SVM: Support Vector Machines
SDAE: Stacked Denoising Autoencoders, RNN : Recurrent Neural Networks.</p>
<table>
<thead>
<tr>
<th>Techniques</th>
<th>Section</th>
<th>References</th>
</tr>
</thead>
<tbody>
<tr>
<td>LSTM</td>
<td>Section 11.7</td>
<td>Inoue et al. [2017], Thi et al. [2017], Kravchik and Shab-</td>
</tr>
<tr>
<td></td>
<td></td>
<td>tai [2018], Huang et al. [2018], Park et al. [2018a], Chang</td>
</tr>
<tr>
<td></td>
<td></td>
<td>et al. [2018]</td>
</tr>
<tr>
<td>AE</td>
<td>Section 11.8</td>
<td>Yuan and Jia [2015], Araya et al. [2017], Qu et al.</td>
</tr>
<tr>
<td></td>
<td></td>
<td>[2017], Sakurada and Yairi [2014], Bhattad et al. [2018]</td>
</tr>
<tr>
<td>DNN</td>
<td>Section 11.1</td>
<td>Lodhi et al. [2017]</td>
</tr>
<tr>
<td>CNN</td>
<td>Section 11.6</td>
<td>Faghih-Roohi et al. [2016], Christiansen et al.</td>
</tr>
<tr>
<td></td>
<td></td>
<td>[2016], Lee et al. [2016], Faghih-Roohi et al. [2016],</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Dong et al. [2016], Nanduri and Sherry [2016], Fuentes</td>
</tr>
<tr>
<td></td>
<td></td>
<td>et al. [2017], Huang et al. [2018], Chang et al. [2018]</td>
</tr>
<tr>
<td>SDAE,DAE</td>
<td>Section 11.8</td>
<td>Yan and Yu [2015], Luo and Zhong [2017], Dai et al.</td>
</tr>
<tr>
<td></td>
<td></td>
<td>[2017]</td>
</tr>
<tr>
<td>RNN</td>
<td>Section 11.7</td>
<td>Banjanovic-Mehmedovic et al. [2017], Thi et al. [2017]</td>
</tr>
<tr>
<td>Hybrid Models (DNN-SVM)</td>
<td>Section 10.3</td>
<td>Inoue et al. [2017]</td>
</tr>
</tbody>
</table>
<p>IoT networks identifies fraudulent, faulty behavior of these massive scales of interconnected devices. The challenges associated with outlier detection is that heterogeneous devices are interconnected which renders the system more complex. A thorough overview of using deep learning (DL), to facilitate analytics and learning in the IoT domain is presented by (Mohammadi et al. [2018]). Table 14 illustrates the DAD techniques employed IoT devices.</p>
<h1>9.8 Industrial Anomalies Detection</h1>
<p>Industrial systems consisting of wind turbines, power plants, high-temperature energy systems, storage devices and with rotating mechanical parts are exposed to enormous stress on a day-to-day basis. Damage to these type of systems not only causes economic loss but also a loss of reputation, therefore detecting and repairing them early is of utmost importance. Several machine learning techniques have been used to detect such damage in industrial systems (Ramotsoela et al. [2018], Martí et al. [2015]). Several papers published utilizing deep learning models for detecting early industrial damage show great promise (Atha and Jahanshahi [2018], de Deijn [2018], Wang et al. [2018c]). Damages caused to equipment are rare events, thus detecting such events can be formulated as an outlier detection problem. The challenges associated with outlier detection in this domain is both volumes as well as the dynamic nature of data since failure is caused due to a variety of factors. Some of the DAD techniques employed across various industries are illustrated in Table 15.</p>
<h3>9.9 Anomaly Detection in Time Series</h3>
<p>Data recorded continuously over duration is known as time series. Time series data can be broadly classified into univariate and multivariate time series. In case of univariate time series, only single variable (or feature) varies over time. For instance, the data collected from a temperature sensor within the room for each second is an uni-variate time series data. A multivariate time series consists several variables (or features) which change over time. An accelerometer which produces three-dimensional data for every second one for each axis $(x, y, z)$ is a perfect example of multivariate time series data. In the literature, types of anomalies in univariate and multivariate time series are categorized into following groups: (1) Point Anomalies. 8.4.1 (2) Contextual Anomalies 8.4.2 (3) Collective Anomalies</p>
<p>Table 16: Examples of DAD techniques used in uni-variate time series data.
CNN: Convolution Neural Networks, GAN: Generative Adversarial networks, DNN: Deep Neural Networks,AE: Autoencoders,DAE: Denoising Autoencoders, VAE: Variational Autoencoder,SDAE: Stacked Denoising Autoencoders, LSTM: Long Short Term Memory Networks, GRU: Gated Recurrent Unit RNN: Recurrent Neural Networks, RNN: Replicator Neural Networks</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Techniques</th>
<th style="text-align: center;">Section</th>
<th style="text-align: center;">References</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">LSTM</td>
<td style="text-align: center;">Section 11.7</td>
<td style="text-align: center;">Shipmon et al. [2017a],Hundman et al. [2018],Zhu and Laptev [2017]Malhotra et al. [2015],Chauhan and Vig [2015],Assendorp [2017] <br> Ahmad et al. [2017],Malhotra et al. [2016a],Bontemps et al. [2016],Taylor et al. [2016],Cheng et al. [2016],Loganathan et al. [2018],Chauhan and Vig [2015],Malhotra et al. [2015],Gorokhov et al. [2017], Munir et al. [2018]</td>
</tr>
<tr>
<td style="text-align: center;">AE,LSTM- <br> AE,CNN-AE,GRU- <br> AE</td>
<td style="text-align: center;">Section 11.8</td>
<td style="text-align: center;">Shipmon et al. [2017b], Malhotra et al. [2016b], Filonov et al. [2016], Sugimoto et al. [2018], Oh and Yun [2018], Ebrahimzadeh and Kleinberg, Veeramachaneni et al. [2016], Dau et al. [2014]</td>
</tr>
<tr>
<td style="text-align: center;">RNN</td>
<td style="text-align: center;">Section 11.7</td>
<td style="text-align: center;">Wielgosz et al. [2017], Saurav et al. [2018], Wielgosz et al. [2018], Guo et al. [2016], Filonov et al. [2017]</td>
</tr>
<tr>
<td style="text-align: center;">CNN, CNN-LSTM</td>
<td style="text-align: center;">Section 11.6, 11.7</td>
<td style="text-align: center;">Kanarachos et al. [2017], Du et al., Gorokhov et al. [2017], Napoletano et al. [2018], Shanmugam et al. [2018],Medel and Savakis [2016]</td>
</tr>
<tr>
<td style="text-align: center;">LSTM-VAE</td>
<td style="text-align: center;">Section 11.7, 11.5</td>
<td style="text-align: center;">Park et al. [2018b], Sölch et al. [2016]</td>
</tr>
<tr>
<td style="text-align: center;">DNN</td>
<td style="text-align: center;">Section 11.1</td>
<td style="text-align: center;">Amarasinghe et al. [2018b]</td>
</tr>
<tr>
<td style="text-align: center;">GAN</td>
<td style="text-align: center;">Section 11.5</td>
<td style="text-align: center;">Li et al. [2018], Zenati et al. [2018], Lim et al. [2018], Laptev,Wei et al. [2018]</td>
</tr>
</tbody>
</table>
<p>8.4.3. In recent times, many deep learning models have been proposed for detecting anomalies within univariate and multivariate time series data as illustrated in Table 16 and Table 17 respectively. Some of the challenges to detect anomalies in time series using deep learning models data are:</p>
<ul>
<li>Lack of defined pattern in which an anomaly is occurring may be defined.</li>
<li>Noise within the input data seriously affects the performance of algorithms.</li>
<li>As the length of the time series data increases the computational complexity also increases.</li>
<li>Time series data is usually non-stationary, non-linear and dynamically evolving. Hence DAD models should be able to detect anomalies in real time.</li>
</ul>
<h1>9.9.1 Uni-variate time series deep anomaly detection</h1>
<p>The advancements in deep learning domain offer opportunities to extract rich hierarchical features which can greatly improve outlier detection within uni-variate time series data. The list of industry standard tools and datasets (both deep learning based and non-deep learning based) for benchmarking anomaly detection algorithms on both univariate and multivariate time-series data is presented and maintained at Github repository ${ }^{2}$. Table 16 illustrates various deep architectures adopted for anomaly detection within uni-variate time series data.</p>
<h3>9.9.2 Multi-variate time series deep anomaly detection</h3>
<p>Anomaly detection in multivariate time series data is a challenging task. Effective multivariate anomaly detection enables fault isolation diagnostics. RNN and LSTM based methods ${ }^{3}$ are shown to perform well in detecting interpretable anomalies within multivariate time series dataset. DeepAD, a generic framework based on deep learning for multivariate time series anomaly detection is proposed by (Buda et al. [2018]). Interpretable, anomaly detection systems designed using deep attention based models are effective in explaining the anomalies detected (Yuan et al. [2018b], Guo and Lin [2018]). Table 17 illustrates various deep architectures adopted for anomaly detection within multivariate time series data.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Table 17: Examples of DAD techniques used in multivariate time series data. CNN: Convolution Neural Networks, GAN: Generative Adversarial networks, DNN: Deep Neural Networks,AE: Autoencoders,DAE: Denoising Autoencoders, VAE: Variational Autoencoder,SDAE: Stacked Denoising Autoencoders, LSTM: Long Short Term Memory Networks, GRU: Gated Recurrent Unit</p>
<table>
<thead>
<tr>
<th>Techniques</th>
<th>Section</th>
<th>References</th>
</tr>
</thead>
<tbody>
<tr>
<td>LSTM</td>
<td>Section 11.7</td>
<td>Nucci et al. [2018], Hundman et al. [2018], Assendorp et al. [2017], Nolle et al. [2018b]</td>
</tr>
<tr>
<td>AE,LSTM- <br> AE,CNN-AE,GRU- <br> AE</td>
<td>Section 11.8</td>
<td>Zhang et al. [2018e] Guo et al. [2018], Fu et al. [2019], Kieu et al. [2018]</td>
</tr>
<tr>
<td>CNN, CNN-LSTM</td>
<td>Section 11.6, 11.7</td>
<td>Basumallik et al. [2019], Shanmugam et al. [2018]</td>
</tr>
<tr>
<td>LSTM-VAE</td>
<td>Section 11.7, 11.5</td>
<td>Ikeda et al. [2018], Park et al. [2018b]</td>
</tr>
<tr>
<td>GAN</td>
<td>Section 11.5</td>
<td>Assendorp [2017], Li et al. [2018], Li et al. [2019] Cowton et al. [2018]</td>
</tr>
<tr>
<td>DNN-RNN</td>
<td>Section 11.7</td>
<td>Tuor et al. [2017], Tuor et al. [2018]</td>
</tr>
</tbody>
</table>
<p>Table 18: Datasets used in multivariate anomaly detection.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Dataset</th>
<th style="text-align: left;">Description</th>
<th style="text-align: left;">References</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">NASA Shuttle Valve <br> Data</td>
<td style="text-align: left;">Includes spacecraft anomaly data <br> and experiments from the Mars Sci- <br> ence Laboratory and SMAP mis- <br> sions</td>
<td style="text-align: left;">Hundman et al. [2018]</td>
</tr>
<tr>
<td style="text-align: left;">Vessels</td>
<td style="text-align: left;">Multivariate temporal data analysis <br> for Vessels behavior anomaly de- <br> tection</td>
<td style="text-align: left;">Maia [2017]</td>
</tr>
<tr>
<td style="text-align: left;">SWaT and WADI</td>
<td style="text-align: left;">Secure Water Treatment (SWaT) <br> and the Water Distribution (WADI)</td>
<td style="text-align: left;">Li et al. [2019]</td>
</tr>
<tr>
<td style="text-align: left;">Credit Card Fraud <br> Detection</td>
<td style="text-align: left;">Anonymized credit card transac- <br> tions labeled as fraudulent or gen- <br> uine</td>
<td style="text-align: left;">Dal Pozzolo et al. [2015]</td>
</tr>
<tr>
<td style="text-align: left;">NYC taxi passenger <br> count</td>
<td style="text-align: left;">The New York City taxi passenger <br> data stream</td>
<td style="text-align: left;">Cui et al. [2016]</td>
</tr>
</tbody>
</table>
<p>${ }^{1}$ https://cs.fit.edu/ bkc/nasa/data/
${ }^{2}$ https://github.com/khundman/telemanom
${ }^{3}$ http://conferences.inf.ed.ac.uk/EuroDW2018/papers/eurodw18-Maia.pdf
${ }^{4}$ https://www.kaggle.com/peterkim95/multivariate-gaussian-anomaly-detection/ data
${ }^{5}$ https://github.com/chickenbestlover/RNN-Time-series-Anomaly-Detection</p>
<h1>9.10 Video Surveillance</h1>
<p>Video Surveillance also popularly known as Closed-circuit television (CCTV) involves monitoring designated areas of interest in order to ensure security. In videos surveillance applications unlabelled data is available in large amounts, this is a significant challenge for supervised machine learning and deep learning methods. Hence video surveillance applications have been modeled as anomaly detection problems owing to lack of availability of labeled data. Several works have studied the state-of-the-art deep models for video anomaly detection and have classified them based on the type of model and criteria of detection (Kiran et al. [2018], Chong and Tay [2015]). The challenges of robust 24/7 video surveillance systems are discussed in detail by (Boghossian and Black [2005]). The lack of an explicit definition of an anomaly in real-life video surveillance is a significant issue that hampers the performance of DAD methods as well. DAD techniques used in video surveillance are illustrated in Table 19.</p>
<p>Table 19: Examples of DAD techniques used in video surveillance.
CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks
RBM: Restricted Boltzmann Machine, DNN : Deep Neural Networks
AE: Autoencoders, DAE: Denoising Autoencoders
OCSVM: One class Support vector machines, CAE: Convolutional Autoencoders
SDAE: Stacked Denoising Autoencoders, STN : Spatial Transformer Networks</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Technique Used</th>
<th style="text-align: center;">Section</th>
<th style="text-align: center;">References</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">CNN</td>
<td style="text-align: center;">Section 11.6</td>
<td style="text-align: center;">Dong et al. [2016],Andrewsa et al.,Sabokrou et al. [2016a],Sabokrou et al. [2017],Munawar et al. [2017],Li et al. [2017b],Qiao et al. [2017],Tripathi et al. [2018],Nogas et al. [2018],Christiansen et al. [2016],Li et al. [2017b].</td>
</tr>
<tr>
<td style="text-align: center;">$\begin{aligned} &amp; \text { SAE } \quad \text { (AE-CNN- } \ &amp; \text { LSTM) } \end{aligned}$</td>
<td style="text-align: center;">Section 11.8, 11.6, 11.7</td>
<td style="text-align: center;">Chong and Tay [2017], Qiao et al. [2017], Khaleghi and Moin [2018]</td>
</tr>
<tr>
<td style="text-align: center;">AE</td>
<td style="text-align: center;">Section 11.8</td>
<td style="text-align: center;">Qiao et al. [2017],Yang et al. [2015],Chen et al. [2015],Gutoski et al.,D'Avino et al. [2017],Dotti et al. [2017],Yang et al. [2015],Chen et al. [2015],Sabokrou et al. [2016b], Tran and Hogg [2017],Chen et al. [2015] ,D'Avino et al. [2017],Hasan et al. [2016],Yang et al. [2015],Cinelli [2017],Sultani et al. [2018]</td>
</tr>
<tr>
<td style="text-align: center;">Hybrid Model (CAEOCSVM)</td>
<td style="text-align: center;">Section 10.3</td>
<td style="text-align: center;">Gutoski et al., Dotti et al. [2017]</td>
</tr>
<tr>
<td style="text-align: center;">LSTM-AE</td>
<td style="text-align: center;">Section 11.7, 11.8</td>
<td style="text-align: center;">D'Avino et al. [2017]</td>
</tr>
<tr>
<td style="text-align: center;">STN</td>
<td style="text-align: center;">Section 11.2</td>
<td style="text-align: center;">Chianucci and Savakis [2016]</td>
</tr>
<tr>
<td style="text-align: center;">RBM</td>
<td style="text-align: center;">Section 11.1</td>
<td style="text-align: center;">Munawar et al. [2017]</td>
</tr>
<tr>
<td style="text-align: center;">LSTM</td>
<td style="text-align: center;">Section 11.7</td>
<td style="text-align: center;">Medel and Savakis [2016], Luo et al. [2017a], Ben-Ari and Shwartz-Ziv [2018], Singh [2017]</td>
</tr>
<tr>
<td style="text-align: center;">RNN</td>
<td style="text-align: center;">Section 11.7</td>
<td style="text-align: center;">Luo et al. [2017b],Zhou and Zhang [2015] ,Hu et al. [2016], Chong and Tay [2015]</td>
</tr>
<tr>
<td style="text-align: center;">AAE</td>
<td style="text-align: center;">Section 11.5</td>
<td style="text-align: center;">Ravanbakhsh et al. [2017a]</td>
</tr>
</tbody>
</table>
<h1>10 Deep Anomaly Detection (DAD) Models</h1>
<p>In this section, we discuss various DAD models classified based on the availability of labels and training objective. For each model types domain, we discuss the following four aspects:
-assumptions;
—type of model architectures;
-computational complexity;
—advantages and disadvantages;</p>
<h3>10.1 Supervised deep anomaly detection</h3>
<p>Supervised anomaly detection techniques are superior in performance compared to unsupervised anomaly detection techniques since these techniques use labeled samples (Görnitz et al. [2013]). Supervised anomaly detection learns the separating boundary from a set of annotated data instances (training) and then, classify a test instance into either normal or anomalous classes with the learned model (testing).
Assumptions: Deep supervised learning methods depend on separating data classes whereas unsupervised techniques focus on explaining and understanding the characteristics of data. Multi-class classification based anomaly detection techniques assumes that the training data contains labeled instances of multiple normal classes (Shilton et al. [2013], Jumutc and Suykens [2014], Kim et al. [2015], Erfani et al. [2017]). Multi-class anomaly detection techniques learn a classifier to distinguish between anomalous class from the rest of the classes. In general, supervised deep learningbased classification schemes for anomaly detection have two sub-networks, a feature extraction network followed by a classifier network. Deep models require a substantial number of training samples (in the order of thousands or millions) to learn feature representations to discriminate various class instances effectively. Due to, lack of availability of clean data labels supervised deep anomaly detection techniques are not so popular as semi-supervised and unsupervised methods.
Computational Complexity: The computational complexity of deep supervised anomaly detection methods based techniques depends on the input data dimension and the number of hidden layers trained using back-propagation algorithm. High dimensional data tend to have more hidden layers to ensure meaning-full hierarchical learning of input features. The computational complexity also increases linearly with the number of hidden layers and require greater model training and update time.
Advantages and Disadvantages: The advantages of supervised DAD techniques are as follows:</p>
<ul>
<li>Supervised DAD methods are more accurate than semi-supervised and unsupervised models.</li>
</ul>
<p>Table 20: Semi-supervised DAD models overview
AE: Autoencoders, DAE: Denoising Autoencoders, KNN : K- Nearest Neighbours
CorGAN: Corrupted Generative Adversarial Networks, DBN: Deep Belief Networks
AAE: Adversarial Autoencoders, CNN: Convolution neural networks SVM: Support vector machines.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Techniques</th>
<th style="text-align: center;">Section</th>
<th style="text-align: center;">References</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">AE</td>
<td style="text-align: center;">Section 11.8</td>
<td style="text-align: center;">Edmunds and Feinstein [2017], Estiri and Murphy [2018]</td>
</tr>
<tr>
<td style="text-align: center;">RBM</td>
<td style="text-align: center;">Section 11.1</td>
<td style="text-align: center;">Jia et al. [2014]</td>
</tr>
<tr>
<td style="text-align: center;">DBN</td>
<td style="text-align: center;">Section 11.1</td>
<td style="text-align: center;">Wulsin et al. [2010], Wulsin et al. [2011]</td>
</tr>
<tr>
<td style="text-align: center;">CorGAN,GAN</td>
<td style="text-align: center;">Section 11.5</td>
<td style="text-align: center;">Gu et al. [2018] Akcay et al. [2018], Sabokrou et al. [2018]</td>
</tr>
<tr>
<td style="text-align: center;">AAE</td>
<td style="text-align: center;">Section 11.5</td>
<td style="text-align: center;">Dimokranitou [2017]</td>
</tr>
<tr>
<td style="text-align: center;">Hybrid Models (DAE- <br> KNN Altman [1992]), <br> (DBN-Random Forest Ho [1995]),CNN-Relief Kira and Rendell [1992],CNNSVM Cortes and Vapnik [1995]</td>
<td style="text-align: center;">Section 8.3.1</td>
<td style="text-align: center;">Song et al. [2017], Shi et al. [2017], Zhu et al. [2018]</td>
</tr>
<tr>
<td style="text-align: center;">CNN</td>
<td style="text-align: center;">Section 11.6</td>
<td style="text-align: center;">Racah et al. [2017], Perera and Patel [2018]</td>
</tr>
<tr>
<td style="text-align: center;">RNN</td>
<td style="text-align: center;">Section 11.7</td>
<td style="text-align: center;">Wu and Prasad [2018]</td>
</tr>
<tr>
<td style="text-align: center;">GAN</td>
<td style="text-align: center;">Section 11.5</td>
<td style="text-align: center;">Kliger and Fleishman [2018], Gu et al. [2018]</td>
</tr>
</tbody>
</table>
<ul>
<li>The testing phase of classification based techniques is fast since each test instance needs to be compared against the precomputed model.</li>
</ul>
<p>The disadvantages of Supervised DAD techniques are as follows:</p>
<ul>
<li>Multi-class supervised techniques require accurate labels for various normal classes and anomalous instances, which is often not available.</li>
<li>Deep supervised techniques fail to separate normal from anomalous data if the feature space is highly complex and non-linear.</li>
</ul>
<h1>10.2 Semi-supervised deep anomaly detection</h1>
<p>Semi-supervised or (one-class classification) DAD techniques assume that all training instances have only one class label. A review of deep learning based semi-supervised techniques for anomaly detection is presented by Kiran et al. [2018] and Min et al. [2018]. DAD techniques learn a discriminative boundary around the normal instances. The test instance that does not belong to the majority class is flagged as being anomalous (Perera and Patel [2018], Blanchard et al. [2010]). Various semi-supervised DAD model architectures are illustrated in Table 20.
Assumptions: Semi-supervised DAD methods proposed to rely on one of the following assumptions to score a data instance as an anomaly.</p>
<ul>
<li>Proximity and Continuity: Points which are close to each other both in input space and learned feature space are more likely to share the same label.</li>
<li>Robust features are learned within hidden layers of deep neural network layers and retain the discriminative attributes for separating normal from outlier data points.</li>
</ul>
<p>Computational Complexity: The computational complexity of semi-supervised DAD methods based techniques is similar to supervised DAD techniques, which primarily depends on the dimensionality of the input data and the</p>
<p>Table 21: Examples of Hybrid DAD techniques.
CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks
DBN: Deep Belief Networks, DNN : Deep Neural Networks.
AE: Autoencoders, DAE: Denoising Autoencoders, SVM: Support Vector Machines Cortes and Vapnik [1995]
SVDD: Support Vector Data Description, RNN : Recurrent Neural Networks
Relief: Feature selection Algorithm Kira and Rendell [1992], KNN: K- Nearest Neighbours Altman [1992]
CSI: Capture, Score, and Integrate Ruchansky et al. [2017].</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Techniques</th>
<th style="text-align: center;">Section</th>
<th style="text-align: center;">References</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">AE-OCSVM, AESVM</td>
<td style="text-align: center;">Section 11.8,</td>
<td style="text-align: center;">Andrews et al. [2016a]</td>
</tr>
<tr>
<td style="text-align: center;">DBN-SVDD, AESVDD</td>
<td style="text-align: center;">Section 11.1,</td>
<td style="text-align: center;">Erfani et al. [2016a], Kim et al. [2015]</td>
</tr>
<tr>
<td style="text-align: center;">DNN-SVM</td>
<td style="text-align: center;">21D</td>
<td style="text-align: center;">Inoue et al. [2017]</td>
</tr>
<tr>
<td style="text-align: center;">DAE-KNN, DBNRandom Forest Ho [1995],CNN- <br> Relief,CNN-SVM</td>
<td style="text-align: center;">Section 11.1,11.8</td>
<td style="text-align: center;">Song et al. [2017], Shi et al. [2017], Zhu et al. [2018], Urbanowicz et al. [2018]</td>
</tr>
<tr>
<td style="text-align: center;">AE-CNN, AE-DBN</td>
<td style="text-align: center;">$\begin{aligned} &amp; \text { Section } \ &amp; 11.1,11.6,11.8 \end{aligned}$</td>
<td style="text-align: center;">Wang et al. [2018b], Li et al. [2015]</td>
</tr>
<tr>
<td style="text-align: center;">AE+ KNN</td>
<td style="text-align: center;">Section 11.8</td>
<td style="text-align: center;">Song et al. [2017]</td>
</tr>
<tr>
<td style="text-align: center;">CNN-LSTM-SVM</td>
<td style="text-align: center;">Section 11.6,11.7</td>
<td style="text-align: center;">Wei [2017]</td>
</tr>
<tr>
<td style="text-align: center;">RNN-CSI</td>
<td style="text-align: center;">Section 11.7</td>
<td style="text-align: center;">Ruchansky et al. [2017]</td>
</tr>
<tr>
<td style="text-align: center;">CAE-OCSVM</td>
<td style="text-align: center;">Section 11.8</td>
<td style="text-align: center;">Gutoski et al., Dotti et al. [2017]</td>
</tr>
</tbody>
</table>
<p>number of hidden layers used for representative feature learning.</p>
<p>Advantages and Disadvantages: The advantages of semi-supervised deep anomaly detection techniques are as follows:</p>
<ul>
<li>Generative Adversarial Networks (GANs) trained in semi-supervised learning mode have shown great promise, even with very few labeled data.</li>
<li>Use of labeled data ( usually of one class), can produce considerable performance improvement over unsupervised techniques.</li>
</ul>
<p>The fundamental disadvantages of semi-supervised techniques presented by (Lu [2009]) are applicable even in a deep learning context. Furthermore, the hierarchical features extracted within hidden layers may not be representative of fewer anomalous instances hence are prone to the over-fitting problem.</p>
<h1>10.3 Hybrid deep anomaly detection</h1>
<p>Deep learning models are widely used as feature extractors to learn robust features (Andrews et al. [2016a]). In deep hybrid models, the representative features learned within deep models are input to traditional algorithms like oneclass Radial Basis Function (RBF), Support Vector Machine (SVM) classifiers. The hybrid models employ two step learning and are shown to produce state-of-the-art results (Erfani et al. [2016a,b], Wu et al. [2015b]). Deep hybrid architectures used in anomaly detection is presented in Table 21.</p>
<h2>Assumptions:</h2>
<p>The deep hybrid models proposed for anomaly detection rely on one of the following assumptions to detect outliers:</p>
<ul>
<li>Robust features are extracted within hidden layers of the deep neural network, aid in separating the irrelevant features which can conceal the presence of anomalies.</li>
<li>Building a robust anomaly detection model on complex, high-dimensional spaces require feature extractor and an anomaly detector. Various anomaly detectors used alongwith are illustrated in Table 21</li>
</ul>
<h2>Computational Complexity :</h2>
<p>The computational complexity of a hybrid model includes the complexity of both deep architectures as well as traditional algorithms used within. Additionally, an inherent issue of non-trivial choice of deep network architecture and parameters which involves searching optimized parameters in a considerably larger space introduces the computational complexity of using deep layers within hybrid models. Furthermore considering the classical algorithms such as linear</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ https://github.com/rob-med/awesome-TS-anomaly-detection
${ }^{3}$ https://github.com/pnnl/safekit&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>