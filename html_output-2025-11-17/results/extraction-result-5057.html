<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5057 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5057</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5057</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-106.html">extraction-schema-106</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <p><strong>Paper ID:</strong> paper-7d9d8d91eecf06a370dad2594705f406d98edf95</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/7d9d8d91eecf06a370dad2594705f406d98edf95" target="_blank">Hybrid Classification and Reasoning for Image-based Constraint Solving</a></p>
                <p><strong>Paper Venue:</strong> Integration of AI and OR Techniques in Constraint Programming</p>
                <p><strong>Paper TL;DR:</strong> This paper explores the hybridization of classifying the images with the reasoning of a constraint solver, and shows that such hybrid approaches vastly outperform a separate approach, which encourages a further integration of prediction (probabilities) and constraint solving.</p>
                <p><strong>Paper Abstract:</strong> There is an increased interest in solving complex constrained problems where part of the input is not given as facts but received as raw sensor data such as images or speech. We will use "visual sudoku" as a prototype problem, where the given cell digits are handwritten and provided as an image thereof. In this case, one first has to train and use a classifier to label the images, so that the labels can be used for solving the problem. In this paper, we explore the hybridization of classifying the images with the reasoning of a constraint solver. We show that pure constraint reasoning on predictions does not give satisfactory results. Instead, we explore the possibilities of a tighter integration, by exposing the probabilistic estimates of the classifier to the constraint solver. This allows joint inference on these probabilistic estimates, where we use the solver to find the maximum likelihood solution. We explore the trade-off between the power of the classifier and the power of the constraint reasoning, as well as further integration through the additional use of structural knowledge. Furthermore, we investigate the effect of calibration of the probabilistic estimates on the reasoning. Our results show that such hybrid approaches vastly outperform a separate approach, which encourages a further integration of prediction (probabilities) and constraint solving.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5057.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5057.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Baseline (LeNet+CP)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Separate classification (LeNet CNN) followed by constraint programming (CP) solver</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pipeline that classifies handwritten digit images with a LeNet convolutional neural network (trained on MNIST) and then feeds the argmax labels as givens into a CP sudoku solver; classification and reasoning are performed separately.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LeNet (CNN)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>LeNet architecture: two convolutional layers followed by two fully connected layers; trained on MNIST digit images for 10 epochs using Adam optimizer (learning rate 1e-5) in the experiments of this paper. Outputs softmax probabilities per digit, but baseline uses argmax label.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Visual Sudoku</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Standard 9x9 Sudoku where the provided givens are images of handwritten digits (MNIST). Solving requires spatial/relational reasoning across rows, columns, and 3x3 subgrids to enforce alldifferent constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Separate pipeline: classify each given image independently to a single digit (argmax of classifier probabilities), then treat these as fixed givens and solve the Sudoku as a CSP with a CP solver; no joint inference between classifier uncertainty and sudoku constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>The baseline itself does not incorporate spatial reasoning into the classifier; spatial reasoning is performed only by the CP solver after hard assignment of labels. The paper reports that even single misclassifications often make the CP unsolvable, illustrating the importance of spatial constraints but showing the baseline's inability to leverage them during classification.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On the dataset (3000 boards, avg 36.2 givens): image (img) accuracy 94.75%, cell accuracy 15.51%, grid accuracy (fully solved grids) 14.67%, grid failure rate 84.43%, average solve time per instance 0.01 s (very fast but poor grid success).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Extremely brittle to single classification errors: a single wrong argmax can render the puzzle unsolvable. Does not use classifier uncertainty or joint inference; therefore low grid-level success despite high per-image accuracy. No mechanism to correct mislabels using global constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>This is the baseline used for comparisons; hybrid methods in the same paper dramatically outperform it (see hybrid entries).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Hybrid Classification and Reasoning for Image-based Constraint Solving', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5057.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5057.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hybrid1 (Prob-CP)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Joint inference by CP over classifier class-probabilities (COP maximizing likelihood)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid approach that feeds per-cell class-probability vectors from the CNN into a constraint optimization problem (COP) and finds a grid assignment that maximizes the joint likelihood under sudoku constraints (equivalently minimizes sum of -log probabilities for assigned given cells).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LeNet (CNN) + Constraint Programming (COP)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Same LeNet CNN as in the baseline to produce 9-way softmax probability vectors per given image (trained on MNIST); CP solver (OR-Tools) solves a COP with objective equal to the negative log-likelihood of assigned labels on given cells, subject to sudoku alldifferent constraints. Training of CNN remains standard (not end-to-end).</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Visual Sudoku</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>9x9 Sudoku with givens as handwritten digit images; hybrid1 jointly reasons about classifier uncertainties and sudoku spatial constraints to obtain a full grid that best explains the image probabilities while satisfying row/column/box uniqueness constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Joint inference: treat each given image's predicted class-probability vector as a likelihood over possible digit values; construct a COP with domain values 1..9 for each cell, sudoku constraints as hard constraints, and objective minimizing sum_{given cells} -log P_theta(y=k | X). Solve by CP branch-and-bound to find most likely feasible grid. This allows the solver to trade off classifier probabilities across cells and correct misclassifications.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Spatial reasoning is performed explicitly by the CP solver via the sudoku alldifferent constraints; empirical evidence of spatial reasoning includes large increases in grid success (from 14.67% baseline to 92.33%) and increased per-image correction (hybrid corrects many classifier errors by selecting labels consistent with spatial constraints). The paper reports that the solver sometimes selects labels ranked below the classifier argmax (rank distribution shows non-top picks used when constraints demand them), indicating true use of relational/spatial information rather than per-cell independent decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On same dataset: image accuracy 99.69%, cell accuracy 99.38%, grid accuracy 92.33%, grid failure rate 0%, average time per instance 0.79 s. The approach corrects classifier errors substantially (example: transforms outputs of a 94.8% accurate classifier into ~99.7% joint-inference accuracy in some settings).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Considerably more computationally expensive than baseline (average ~0.79 s vs 0.01 s; reported as ~100x slower for COP vs CSP) and branch-and-bound time grows as classifier probabilities become less skewed; requires meaningful probability estimates (calibration matters); assumes independence of image observations for the joint likelihood; solver must handle larger domains for given cells increasing search space.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Substantially outperforms the separate baseline in grid-level success (92.33% vs 14.67%) and image/cell accuracy. Compared to hybrid2, hybrid1 is slightly less accurate (hybrid2 grid 92.93%) but faster to the extent uniqueness-check overhead exists only in hybrid2.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Hybrid Classification and Reasoning for Image-based Constraint Solving', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5057.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5057.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hybrid2 (Prob-CP + Uniqueness)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hybrid joint inference plus higher-order uniqueness checking (COP with nogoods for non-unique projections)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extension of Hybrid1 that, in addition to maximizing joint likelihood, checks whether the projected assignments to given cells yield a unique sudoku completion; if not unique, it blocks that projection (nogood) and repeats optimization to prefer solutions whose given assignments uniquely determine the intended solution.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LeNet (CNN) + Constraint Programming (COP) with higher-order nogood checks</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>LeNet CNN outputs per-given-cell probability vectors; COP optimization like hybrid1 finds most likely solution; an additional CSP check is performed to test for other completions that share the same given-cell assignments; if other completions exist, the given assignment is blocked (nogood / blocking clause) and optimization repeats until a solution whose given projection is unique is found. Implemented using OR-Tools CP solver and repeated CSP checks.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Visual Sudoku</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Same visual Sudoku: solving requires spatial relational reasoning across rows, columns, and boxes; hybrid2 uses both probabilistic joint inference and a second-order uniqueness property of standard sudoku puzzles to further disambiguate and correct labels.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Two-stage iterative strategy: (1) find most likely full grid via COP over classifier probabilities (as hybrid1); (2) project that solution to the given cells and check via CSP whether that projection admits any other full-grid completions; if other completions exist, add a nogood constraint forbidding that given-projection and re-run optimization (dominance / blocking clause) until a projection with unique completion is produced. This exploits additional global structural knowledge (uniqueness) to refine predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Uses the same explicit spatial constraints as hybrid1 but augments them with a higher-order relational property (uniqueness of completion), producing modest additional corrections: hybrid2 solved 18 additional puzzles relative to hybrid1 in experiments and further increased image/cell accuracies (99.72% img, 99.44% cell). The paper reports instances where hybrid2 selects lower-ranked classifier labels (rarely rank 8 or below) guided by uniqueness checks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On dataset: image accuracy 99.72%, cell accuracy 99.44%, grid accuracy 92.93%, grid failure rate 0%, average time per instance 0.83 s. In experiments with stronger classifier, hybrid2 achieved grid accuracy up to ~99.6% (Table 4) when classifier was stronger and better calibrated. Top-k experiments show grid accuracy improves as more top-k candidate digits are allowed; full 9-way reasoning yields best accuracy but highest time.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Additional computational cost versus hybrid1 due to repeated CSP checks and nogood additions (happened 18 times in reported experiments); still depends on quality and calibration of classifier probabilities; scalability concerns for larger or denser constraint problems; the approach requires sudoku property of intended uniqueness — not all puzzle instances/general tasks have such a property.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Slightly outperforms hybrid1 (grid 92.93% vs 92.33%) and massively outperforms the separate baseline (14.67% grid). Gains from uniqueness checks are modest but present (18 additional puzzles solved).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Hybrid Classification and Reasoning for Image-based Constraint Solving', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver <em>(Rating: 2)</em></li>
                <li>Optnet: Differentiable optimization as a layer in neural networks <em>(Rating: 2)</em></li>
                <li>DeepProbLog: Neural probabilistic logic programming <em>(Rating: 2)</em></li>
                <li>A logic-driven framework for consistency of neural models <em>(Rating: 1)</em></li>
                <li>Semantic role labeling via integer linear programming inference <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5057",
    "paper_id": "paper-7d9d8d91eecf06a370dad2594705f406d98edf95",
    "extraction_schema_id": "extraction-schema-106",
    "extracted_data": [
        {
            "name_short": "Baseline (LeNet+CP)",
            "name_full": "Separate classification (LeNet CNN) followed by constraint programming (CP) solver",
            "brief_description": "A pipeline that classifies handwritten digit images with a LeNet convolutional neural network (trained on MNIST) and then feeds the argmax labels as givens into a CP sudoku solver; classification and reasoning are performed separately.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LeNet (CNN)",
            "model_description": "LeNet architecture: two convolutional layers followed by two fully connected layers; trained on MNIST digit images for 10 epochs using Adam optimizer (learning rate 1e-5) in the experiments of this paper. Outputs softmax probabilities per digit, but baseline uses argmax label.",
            "puzzle_name": "Visual Sudoku",
            "puzzle_description": "Standard 9x9 Sudoku where the provided givens are images of handwritten digits (MNIST). Solving requires spatial/relational reasoning across rows, columns, and 3x3 subgrids to enforce alldifferent constraints.",
            "mechanism_or_strategy": "Separate pipeline: classify each given image independently to a single digit (argmax of classifier probabilities), then treat these as fixed givens and solve the Sudoku as a CSP with a CP solver; no joint inference between classifier uncertainty and sudoku constraints.",
            "evidence_of_spatial_reasoning": "The baseline itself does not incorporate spatial reasoning into the classifier; spatial reasoning is performed only by the CP solver after hard assignment of labels. The paper reports that even single misclassifications often make the CP unsolvable, illustrating the importance of spatial constraints but showing the baseline's inability to leverage them during classification.",
            "performance_metrics": "On the dataset (3000 boards, avg 36.2 givens): image (img) accuracy 94.75%, cell accuracy 15.51%, grid accuracy (fully solved grids) 14.67%, grid failure rate 84.43%, average solve time per instance 0.01 s (very fast but poor grid success).",
            "limitations_or_failure_cases": "Extremely brittle to single classification errors: a single wrong argmax can render the puzzle unsolvable. Does not use classifier uncertainty or joint inference; therefore low grid-level success despite high per-image accuracy. No mechanism to correct mislabels using global constraints.",
            "comparison_baseline": "This is the baseline used for comparisons; hybrid methods in the same paper dramatically outperform it (see hybrid entries).",
            "uuid": "e5057.0",
            "source_info": {
                "paper_title": "Hybrid Classification and Reasoning for Image-based Constraint Solving",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Hybrid1 (Prob-CP)",
            "name_full": "Joint inference by CP over classifier class-probabilities (COP maximizing likelihood)",
            "brief_description": "A hybrid approach that feeds per-cell class-probability vectors from the CNN into a constraint optimization problem (COP) and finds a grid assignment that maximizes the joint likelihood under sudoku constraints (equivalently minimizes sum of -log probabilities for assigned given cells).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LeNet (CNN) + Constraint Programming (COP)",
            "model_description": "Same LeNet CNN as in the baseline to produce 9-way softmax probability vectors per given image (trained on MNIST); CP solver (OR-Tools) solves a COP with objective equal to the negative log-likelihood of assigned labels on given cells, subject to sudoku alldifferent constraints. Training of CNN remains standard (not end-to-end).",
            "puzzle_name": "Visual Sudoku",
            "puzzle_description": "9x9 Sudoku with givens as handwritten digit images; hybrid1 jointly reasons about classifier uncertainties and sudoku spatial constraints to obtain a full grid that best explains the image probabilities while satisfying row/column/box uniqueness constraints.",
            "mechanism_or_strategy": "Joint inference: treat each given image's predicted class-probability vector as a likelihood over possible digit values; construct a COP with domain values 1..9 for each cell, sudoku constraints as hard constraints, and objective minimizing sum_{given cells} -log P_theta(y=k | X). Solve by CP branch-and-bound to find most likely feasible grid. This allows the solver to trade off classifier probabilities across cells and correct misclassifications.",
            "evidence_of_spatial_reasoning": "Spatial reasoning is performed explicitly by the CP solver via the sudoku alldifferent constraints; empirical evidence of spatial reasoning includes large increases in grid success (from 14.67% baseline to 92.33%) and increased per-image correction (hybrid corrects many classifier errors by selecting labels consistent with spatial constraints). The paper reports that the solver sometimes selects labels ranked below the classifier argmax (rank distribution shows non-top picks used when constraints demand them), indicating true use of relational/spatial information rather than per-cell independent decisions.",
            "performance_metrics": "On same dataset: image accuracy 99.69%, cell accuracy 99.38%, grid accuracy 92.33%, grid failure rate 0%, average time per instance 0.79 s. The approach corrects classifier errors substantially (example: transforms outputs of a 94.8% accurate classifier into ~99.7% joint-inference accuracy in some settings).",
            "limitations_or_failure_cases": "Considerably more computationally expensive than baseline (average ~0.79 s vs 0.01 s; reported as ~100x slower for COP vs CSP) and branch-and-bound time grows as classifier probabilities become less skewed; requires meaningful probability estimates (calibration matters); assumes independence of image observations for the joint likelihood; solver must handle larger domains for given cells increasing search space.",
            "comparison_baseline": "Substantially outperforms the separate baseline in grid-level success (92.33% vs 14.67%) and image/cell accuracy. Compared to hybrid2, hybrid1 is slightly less accurate (hybrid2 grid 92.93%) but faster to the extent uniqueness-check overhead exists only in hybrid2.",
            "uuid": "e5057.1",
            "source_info": {
                "paper_title": "Hybrid Classification and Reasoning for Image-based Constraint Solving",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Hybrid2 (Prob-CP + Uniqueness)",
            "name_full": "Hybrid joint inference plus higher-order uniqueness checking (COP with nogoods for non-unique projections)",
            "brief_description": "An extension of Hybrid1 that, in addition to maximizing joint likelihood, checks whether the projected assignments to given cells yield a unique sudoku completion; if not unique, it blocks that projection (nogood) and repeats optimization to prefer solutions whose given assignments uniquely determine the intended solution.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LeNet (CNN) + Constraint Programming (COP) with higher-order nogood checks",
            "model_description": "LeNet CNN outputs per-given-cell probability vectors; COP optimization like hybrid1 finds most likely solution; an additional CSP check is performed to test for other completions that share the same given-cell assignments; if other completions exist, the given assignment is blocked (nogood / blocking clause) and optimization repeats until a solution whose given projection is unique is found. Implemented using OR-Tools CP solver and repeated CSP checks.",
            "puzzle_name": "Visual Sudoku",
            "puzzle_description": "Same visual Sudoku: solving requires spatial relational reasoning across rows, columns, and boxes; hybrid2 uses both probabilistic joint inference and a second-order uniqueness property of standard sudoku puzzles to further disambiguate and correct labels.",
            "mechanism_or_strategy": "Two-stage iterative strategy: (1) find most likely full grid via COP over classifier probabilities (as hybrid1); (2) project that solution to the given cells and check via CSP whether that projection admits any other full-grid completions; if other completions exist, add a nogood constraint forbidding that given-projection and re-run optimization (dominance / blocking clause) until a projection with unique completion is produced. This exploits additional global structural knowledge (uniqueness) to refine predictions.",
            "evidence_of_spatial_reasoning": "Uses the same explicit spatial constraints as hybrid1 but augments them with a higher-order relational property (uniqueness of completion), producing modest additional corrections: hybrid2 solved 18 additional puzzles relative to hybrid1 in experiments and further increased image/cell accuracies (99.72% img, 99.44% cell). The paper reports instances where hybrid2 selects lower-ranked classifier labels (rarely rank 8 or below) guided by uniqueness checks.",
            "performance_metrics": "On dataset: image accuracy 99.72%, cell accuracy 99.44%, grid accuracy 92.93%, grid failure rate 0%, average time per instance 0.83 s. In experiments with stronger classifier, hybrid2 achieved grid accuracy up to ~99.6% (Table 4) when classifier was stronger and better calibrated. Top-k experiments show grid accuracy improves as more top-k candidate digits are allowed; full 9-way reasoning yields best accuracy but highest time.",
            "limitations_or_failure_cases": "Additional computational cost versus hybrid1 due to repeated CSP checks and nogood additions (happened 18 times in reported experiments); still depends on quality and calibration of classifier probabilities; scalability concerns for larger or denser constraint problems; the approach requires sudoku property of intended uniqueness — not all puzzle instances/general tasks have such a property.",
            "comparison_baseline": "Slightly outperforms hybrid1 (grid 92.93% vs 92.33%) and massively outperforms the separate baseline (14.67% grid). Gains from uniqueness checks are modest but present (18 additional puzzles solved).",
            "uuid": "e5057.2",
            "source_info": {
                "paper_title": "Hybrid Classification and Reasoning for Image-based Constraint Solving",
                "publication_date_yy_mm": "2020-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver",
            "rating": 2
        },
        {
            "paper_title": "Optnet: Differentiable optimization as a layer in neural networks",
            "rating": 2
        },
        {
            "paper_title": "DeepProbLog: Neural probabilistic logic programming",
            "rating": 2
        },
        {
            "paper_title": "A logic-driven framework for consistency of neural models",
            "rating": 1
        },
        {
            "paper_title": "Semantic role labeling via integer linear programming inference",
            "rating": 1
        }
    ],
    "cost": 0.01048725,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Hybrid Classification and Reasoning for Image-based Constraint Solving</h1>
<p>Maxime Mulamba ${ }^{[0000-0002-9122-926 X]}$, Jayanta Mandi ${ }^{[0000-0001-8675-8178]}$,<br>Rocsildes Canoy ${ }^{[0000-0003-1810-082 X]}$, and Tias Guns ${ }^{[0000-0002-2156-2155]}$.<br>Data Analytics Laboratory, Vrije Universiteit Brussel, {firstname.lastname}@vub.be</p>
<h4>Abstract</h4>
<p>There is an increased interest in solving complex constrained problems where part of the input is not given as facts, but received as raw sensor data such as images or speech. We will use 'visual sudoku' as a prototype problem, where the given cell digits are handwritten and provided as an image thereof. In this case, one first has to train and use a classifier to label the images, so that the labels can be used for solving the problem. In this paper, we explore the hybridisation of classifying the images with the reasoning of a constraint solver. We show that pure constraint reasoning on predictions does not give satisfactory results. Instead, we explore the possibilities of a tighter integration, by exposing the probabilistic estimates of the classifier to the constraint solver. This allows joint inference on these probabilistic estimates, where we use the solver to find the maximum likelihood solution. We explore the tradeoff between the power of the classifier and the power of the constraint reasoning, as well as further integration through the additional use of structural knowledge. Furthermore, we investigate the effect of calibration of the probabilistic estimates on the reasoning. Our results show that such hybrid approaches vastly outperform a separate approach, which encourages a further integration of prediction (probabilities) and constraint solving.</p>
<p>Keywords: Constraint Reasoning, Visual sudoku, Joint Inference, Prediction and Optimisation</p>
<h2>1 Introduction</h2>
<p>Artificial intelligence (AI) is defined as "systems that display intelligent behaviour by analysing their environment and taking actions - with some degree of autonomy - to achieve specific goals." [28]. In that regard, recent advancements in deep neural network (DNN) architectures have achieved highly accurate performance in object and speech recognition and classification. However, many real life problems are relational, where inference on one instance is related to another through various constraints and logical reasoning. Attaining good performance in tasks which require reasoning over constraints and relations still remains elusive. The DNN architectures rely heavily on learning latent representation from the training datasets [18]. The main reason deep architectures struggle in constraint reasoning is that the nuances of the relationship between entities are</p>
<p>often lost in the latent representation. For instance, when solving a sudoku, a DNN model would take the partially filled sudoku as an input and would then be expected to produce the solved sudoku as output. In this process, the model fails to comprehend the interactions among different cells.</p>
<p>Moreover, the high quality performance of DNNs at complex tasks comes at a cost. As DNN models fail to comprehend the logical reasoning, they have to adjust to gradual feedback of the error signals. As a consequence, to be proficient in any simple task, a DNN needs an enormous amount of data. As an example, to be an efficient video-gamer, a DNN model has to play a game for more than 900 hours [9]. Motivated by such deficiencies, integrating logical and relational reasoning into DNN architecture has increasingly gained more attention.</p>
<p>In trying to bridge deep learning and logical reasoning, Wang et al. [30] propose SATNet, a differentiable satisfiability solver that can be used to learn both constraints and image classification through backpropagation. Internally, it uses a quadratic SDP relaxation of a MaxSAT model, and hence learns a relaxed representation of the constraints. We argue that in many cases, there is no need to learn everything end-to-end. Indeed, in a visual sudoku setting, while the constraints are easy to specify in a formal language, the image classification task is difficult for a machine to capture. Hence, we seek to bridge deep learning and logical reasoning by directly plugging the (probabilistic) output of the deep learning into a constraint solver that reasons over the relevant hard constraints.</p>
<p>In this work, we present a framework where we perform joint inference [24-26] over the different predictions, by integrating machine learning inference with first and second order logic. Specifically, instead of solving a constraint programming $(C P)$ problem over a set of independently predictied values, we use CP to do joint inference over a set of probability vectors. The training of the DNN happens on individual image instances, as is typically done. Effectively, our framework can be considered as a forward-only layer on top of the predictions of a pre-trained network.</p>
<p>Specifically, we consider the "visual sudoku" problem where images of digits of some cells in the sudoku grid are fed as input. We first predict the digits using a DNN model and then use a CP solver to solve the sudoku puzzle. A conventional approach would use the predictions of the DNN as inputs to the CP. As the DNN model is not aware of the constraints of the sudoku problem, it misses the opportunity to improve its prediction by taking the constraints into account. When the predictions of the DNN are directly fed into the CP solver, in case of any error, the CP model is bound to fail. Note that in this case, even one prediction error will result in the failure of the whole problem.</p>
<p>We improve the process by considering the predicted class probabilities instead of directly using the arg max prediction. The advantage of our approach is that by avoiding hard assignments prior to the CP solver, we enable the CP solver to correct the errors of the DNN model. In this way, we use CP to do joint inference, which ensures that the predictions will respect the constraints of the problem.</p>
<p>The contributions of the paper are as follows:</p>
<ul>
<li>We explore hybridisation of classification and constraint reasoning on the visual sudoku problem;</li>
<li>We show that constraint reasoning over the probabilistic predictions outperforms a pure reasoning approach, and that we can further improve by taking higher-order relations into account;</li>
<li>We investigate the increased computational cost of reasoning over the probabilities, and the trade-offs possible when limiting the reasoning to the top-k probabilities.</li>
<li>We experimentally explore the interaction of predictive power with the power of discrete reasoning, showing correction factors of $10 \%$ and more, as well as the effect of using calibrated probabilistic classifiers.</li>
</ul>
<h1>2 Related work</h1>
<p>Predict-and-optimize Our work is closely related to the growing body of research at the intersection of machine learning (ML) and combinatorial optimization $[7,8,17]$ where the predictions of an ML model is fed into a downstream optimization oracle. In most applications, feeding machine learning predictions directly into a combinatorial optimization problem may not be the most suitable approach. Bengio [2] compared two ML approaches for optimizing stock returns - one uses a neural network model for predicting financial prices, and the second model makes use of a task-based loss function. Experimental results show that the second model delivers better optimized return. The results also suggest a closer integration of ML and optimization.</p>
<p>In this regard, Wilder et al. [32] propose a framework which trains the weight of the ML model directly from the task-loss of the downstream combinatorial problem from its continuous relaxation. The end-to-end model of [30] learns the constraints of a satisfiability problem by considering a differentiable SDP relaxation of the problem. A similar work [14] trains an ML model by considering a convex surrogate of the task-loss.</p>
<p>Our work differs from these as we do not focus on end-to-end learning. Rather, we enhance the predictions of an ML model by using CP to do joint inference over the raw probability vectors. In this way, we are taking the constraint interaction of the combinatorial problem into account.</p>
<p>Joint inference Our work is also aligned with the research in joint inference. For example, Poon and Domingos [24] have shown its advantage for information extraction in the context of citation matching. Recent work in linguistic semantic analysis of Wang et al. [31] forms a factor graph from the DNN output by encoding it into logical predicates and performs a joint inference over the factor graph. Several other works $[3,11,12]$ focus on leveraging joint inference in DNN architecture for relation extraction from natural language. Our work differs from these, as we perform probabilistic inference on combinatorial constraint solving problem where one inference is linked with another by hard constraints.</p>
<p>Training with Constraints Various works have introduced methods to enforce constraints on the outputs of an NN. One of the earlier work [23] does this by optimizing the Lagrangian coefficients of the constraints at every parameter update of the network. But this would not be feasible in the context of deep neural network as very large dimension matrices must be numerically solved for each parameter update [16]. Pathak et al. [20] introduce CCNN for image segmentation with size constraints where they introduce latent probability distributions over the labels and impose constraints on the latent distribution enabling efficient Lagrangian dual optimization. However, one drawback is, this involves solving an optimization problem at each iteration. Márquez-Neila et al. [16] use a Lagrangian based Krylov subspace approach to enforce linear equality constraints on the output of an NN. But this approach is not found to be scalable to large problem instances. The proposed framework of [13] quantifies inconsistencies of the NN output with respect to the logic constraints and is able to significantly reduce inconsistent constraint violating outcomes by training the model to minimize inconsistency loss.</p>
<p>The closest work to ours is [25], where Punyakanok et al. train a multiclass classifier to identify the label of an argument in the context of semantic role labeling and then feed the prediction scores of each argument to an Integer Linear Programming solver so that the final inferences abide by some predefined linguistic constraints.</p>
<h1>3 Preliminaries</h1>
<p>CSP and COP The concept of a constraint satisfaction problem (CSP) is fundamental in constraint programming [27]. A CSP is formulated as a triplet $(V, D, C)$, where $V$ is a set of decision variables, each of which has its possible values in a domain contained in the set $D$, and $C$ is a set of constraints that need to be satisfied over the variables in $V$. In most cases, we are not only interested in knowing whether a constrained problem is solvable, but we want the best possible solution according to an objective.</p>
<p>A Constraint Optimization Problem $\operatorname{COP}(V, D, C, o)$ finds a feasible solution of optimum value with respect to an objective function $o$ over the variables. In case of a minimisation problem, we have: $S \in C O P(V, D, C, o)$ iff $S \in C S P(V, D, C)$ and $\nexists T \in C S P(V, D, C)$ with $o(T)&lt;o(S)$.</p>
<p>Sudoku In our work we consider a prototype CSP, namely the sudoku. Sudoku is a number puzzle, played on a partially filled 9 x 9 grid. The goal is to find the unique solution by filling in the empty grid cells with numbers from 1 to 9 in such a way that each row, each column and each of the nine 3 x 3 subgrids contain all the numbers from 1 to 9 once and only once.</p>
<p>Formally, the sudoku is a $\operatorname{CSP}(V, D, C)$ where $V$ is the set of variables $v_{i j}$ $(i, j \in{1, \ldots, 9})$ for every cell in the grid, and $D\left(v_{i j}\right)={1, \ldots, 9}$ for each $v_{i j} \in V$. We separate the sudoku constraints into two parts: the set of constraints $C_{\text {given }}$ defining the assignment of numbers in the filled cells (hereinafter referred to as</p>
<p>the givens) of the grid and the set of constraints $C_{\text {rules }}$ defined by the rules of sudoku.</p>
<p>Formally, $C_{\text {rules }}$ consists of the following constraints:</p>
<p>$$
\begin{array}{rll}
\forall i \in{1, \ldots, 9} &amp; \text { alldifferent }\left{v_{i 1}, \ldots, v_{i 9}\right} \
\forall j \in{1, \ldots, 9} &amp; \text { alldifferent }\left{v_{1 j}, \ldots, v_{9 j}\right} \
\forall i, j \in{1,4,7} &amp; \text { alldifferent }\left{v_{i j}, \ldots, v_{(i+2) j}, v_{i(j+1)}, \ldots, v_{(i+2)(j+1)}\right. \
&amp; \left.v_{i(j+2)}, \ldots, v_{(i+2)(j+2)}\right}
\end{array}
$$</p>
<p>For the given cells, $C_{\text {given }}$ is simply an assignment: $D\left(v_{i j}\right)=y_{i j}, \quad \forall v_{i j} \in$ $\left{v_{i j}\right}^{\text {given }} \subset V$ where the $\left{y_{i j}\right}^{\text {given }}$ are known. Because $V$ and $D$ are obvious from the constraints, we will write $C S P\left(C_{\text {rules }} \wedge C_{\text {given }}\right)$ or alternatively $C S P\left(C_{\text {rules }},\left{y_{i j}\right}^{\text {given }}\right)$ to represent a solution of a sudoku specification.</p>
<p>Sudoku has one additional property, namely that for a set of givens, the solution is unique: $S \in C S P\left(C_{\text {rules }} \wedge C_{\text {given }}\right), \nexists T \in C S P\left(C_{\text {rules }} \wedge C_{\text {given }}\right)$, with $T \neq S$.</p>
<p>ML Classifier We will consider the visual sudoku problem, where the given cells are not provided as facts, but each given cell will be an image of a handwritten digit. We will hence first use Machine Learning (ML) to classify what digit each of the images represents.</p>
<p>Given a dataset of size $n,\left{\left(X_{i}, y_{i}\right)\right}<em i="i">{i=1}^{n}$ with $X</em>} \in \mathbb{R}^{d}$ (denoting that each element is a feature vector of $d$ real numbers) and $y_{i}$ the corresponding class label, the goal of an ML classifier is to learn a function approximator $f_{\theta}\left(X_{i}\right)$ (with $\theta$ the trainable parameters of the learning function), such that $f_{\theta}\left(X_{i}\right) \approx y_{i}$ for all $\left(X_{i}, y_{i}\right)$ pairs. In case of a probabilistic classifier, the predicted class label is $\hat{y<em _theta="\theta">{i}=f</em>\right)=\arg \max }\left(X_{i<em _theta="\theta">{k} P</em>$ belongs to class $k$ [4].}\left(y_{i}=k \mid X_{i}\right)$ with $P_{\theta}\left(y_{i}=k \mid X_{i}\right)$ the predicted probability that $X_{i</p>
<p>Formally, the goal of training is to compute $\arg \min <em _theta="\theta">{\theta} \mathcal{L}\left(f</em>(.,$.$) is a loss function measuring how well the function approximates the target$. An example of a loss function for probabilistic classifiers with $C$ possible classes is the cross-entropy loss, defined as:}\left(X_{i}\right), y_{i}\right)$, where $\mathcal{L</p>
<p>$$
\mathcal{L}=-\frac{1}{n} \sum_{i=1}^{n} \sum_{k=1}^{C} \mathbb{1}\left[y_{i}=k\right] \log P_{\theta}\left(y_{i}=k \mid X_{i}\right)
$$</p>
<p>where $\mathbb{1}\left[y_{i}=k\right]$ is the indicator function having the value 1 only when $y_{i}$ has value $k$, i.e., belongs to class $k$.</p>
<h1>4 Visual sudoku and solution methods</h1>
<p>We first introduce the visual sudoku problem as an example of an image-based constraint solving problem, and then propose three different approaches to solving it by combining classification and reasoning.</p>
<p>Visual sudoku In visual sudoku, the given cells of the sudoku are provided as unlabeled images of handwritten digits. We are also given a large dataset of labeled handwritten digits (the MNIST dataset [10]). It is inspired by an experiment in [30], although we consider the case where the constraints are known and can be used for reasoning.</p>
<p>Formally, $\operatorname{VizSudoku}\left(C_{\text {rules }},\left{X_{i j}\right}^{\text {given }}\right)$ consists of the rules of sudoku (Eq 1), and a set of given images $\left{X_{i j}\right}^{\text {given }}$ each one consisting of a pixel representation of the handwritten digit. The goal is to use a classifier $f_{\theta}$ on $\left{X_{i j}\right}^{\text {given }}$ such that the predicted labels $\left{\hat{y}<em _theta="\theta">{i j}\right}^{\text {given }}=\left{f</em>}\left(X_{i j}\right) \mid X_{i j} \in\left{X_{i j}\right}^{\text {given }}\right}$ lead to the solution of the sudoku, that is: $C S P\left(C_{\text {rules }},\left{\hat{y<em _rules="{rules" _text="\text">{i j}\right}^{\text {given }}\right)=C S P\left(C</em>$ the true labels of the given images if known.}},\left{y_{i j}\right}^{\text {given }}\right)$ with $y_{i j</p>
<h1>4.1 Separate classification and reasoning</h1>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1: Architecture of separate classification and reasoning approach</p>
<p>The most straightforward approach to solving the visual sudoku problem is to consider the classification and reasoning problems separately. In this approach, first, the most likely digit for each of the given cells are predicted, after which the puzzle is solved using the resulting grid. This will be our baseline approach.</p>
<p>The baseline approach, explained on Fig. 1, is composed of a separate convolutional neural network and a CP solver. The process begins with the training of the DNN on the MNIST training set ${(X, y)}$ to obtain a handwritten digit classifier $f_{\theta}$. Then for each visual sudoku instance, we use the classifier to predict the value of each given cell's image. This takes us from a visual to a purely digital representation of the problem, which is then fed into the CP sudoku solver. Note, that training is separate from the concept of sudoku, and done on individual images as is standard in image recognition tasks.</p>
<p>Once the model is trained, we use it to solve $\operatorname{VizSudoku}\left(C_{\text {rules }},\left{X_{i j}\right}^{\text {given }}\right)$. For that, we first predict the digit for each of the given images $\left{X_{i j}\right}^{\text {given }}$. For each $X_{i j}$ given, the trained DNN computes a class probability for each digit $k$ $P_{\theta}\left(y_{i j}=k \mid X_{i j}\right)$ and predicts the value with the highest probability:</p>
<p>$$
\hat{y}<em _theta="\theta">{i j}=f</em>\right)
$$}\left(X_{i j}\right)=\underset{k \in{0, . ., 9}}{\arg \max } P_{\theta}\left(y_{i j}=k \mid X_{i j</p>
<p>Once all the given images are predicted, the CP component finds a solution $S \in \operatorname{CSP}\left(C_{\text {rules }},\left{\hat{y}_{i j}\right}^{\text {given }}\right)$ as visualised in Fig. 1.</p>
<p>From an inference standpoint, the above approach commits to the independent predictions made by the classifier and tries to use them as best as possible.</p>
<h1>4.2 Hybrid1: reasoning over class probabilities</h1>
<p>In this approach, we will use the same DNN architecture for digit classification as before. However, instead of using the hard labels from the DNN model, we will make use of the class probabilities of each of the given cells. Hence the outputs of the DNN, i.e., the inputs to the CP solver for each of the given cells, are 9 probabilities - one for each digit that can appear in a sudoku cell. The idea is to completely solve a sudoku grid by solving a COP. See Fig 2 for a visual representation of the architecture.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2: Architecture of class-probability reasoning approach</p>
<p>Note that here, we make a joint inference over all the predictions, including their effect and relation to the a-priori empty cells. In the resulting solution, the digits of both given and non-given cells are obtained at once, while satisfying all the sudoku constraints.</p>
<p>First, the DNN is trained on images of single handwritten digits as before. After training, we store the DNN computed probabilities $P_{\theta}\left(y_{i j}=k \mid X_{i j}\right)$ for each of the given $X_{i j}$. We wish to make the CP solver reason (do inference) over these probabilities directly, hence the sudoku problem formulation of Eq 1 needs to be modified to accommodate the probabilities. Instead of only satisfying the regular sudoku constraints of Eq 1, we seek to find a solution which optimizes the likelihood of the solution, given the probabilities obtained from the classifier.</p>
<p>More specifically, as each image is predicted on its own, we assume each to be an observation of an independent random variable, and hence the most likely solution is the one that maximizes the joint probability over the given images $\max \prod_{\text {given }(i, j)} \prod_{k \in{1, \ldots, 9}}\left(P_{\theta}\left(y_{i j}=k \mid X_{i j}\right)\right)^{\mathbb{1}\left[s_{i j}=k\right]}$ for a solution $s$. We would like to find the most likely solution that also satisfies all constraints. After a log-transform, we can write the joint probability as a weighted sum objective function as follows:</p>
<p>$$
\min \sum_{\substack{(i, j) \in \ \text { given }{1, \ldots, 9}}}\sum_{\substack{k \in \-\log \left(P_{\theta}\left(y_{i j}=k \mid X_{i j}\right)\right) * \mathbb{1}\left[s_{i j}=k\right]}}
$$</p>
<p>Treating $-\log \left(P_{i j}\right)$ as a $k$-dimensional vector, one can see that the inner sum could be formulated with a traditional element constraint in a CP solver. We must emphasize that the log-likelihood is maximized only over the given cells and not for the whole grid due to the fact that we have the classifier provided probability vector only for these cells with given images.</p>
<p>Note that in this approach, the CP solver has to solve a more complex problem with larger domains for the given cells, and hence a larger search space. Contrary to the approach in section 4.1 where the problem was a CSP, here the problem is a COP. The advantage of this approach is that it makes use of the constraint relationships of the sudoku problem. Moreover, it improves the prediction of the ML classifier by reasoning over these constraint relationships.</p>
<h1>4.3 Hybrid2: Higher-order knowledge exploitation</h1>
<p>As mentioned before, a sudoku must have a unique solution for a set of givens. For traditional sudoku puzzles this is the case by construction, as otherwise, a human solver would be faced with having to choose among two or more options, rather than reasoning up to a full solution.</p>
<p>In the approach of section 4.2 , we simply find one solution and treat that as the solution, without verifying whether it is unique with respect to the set of givens. When projecting the solution of the entire sudoku back to only the assignment to the 'given' cells, e.g. those for which an image is given, then this assignment to the givens should have one and only one unique solution. If not, this assignment to the givens, and hence the entire sudoku solution, can not be the intended solution.</p>
<p>Therefore, we can use the (non) existence of a unique solution as an additional relational property that can steer the joint inference. The pseudo-code of this approach is shown in Algorithm 1. We start with finding the most likely solution sol as in the hybrid1 approach described in the previous section. We will write $\left{\operatorname{sol}_{i j}\right}^{\text {given }}$ to represent the projected part of the solution, that is, only the part of the assignment of the cells with an image given.</p>
<p>Instead of counting all solutions given $\left{\operatorname{sol}_{i j}\right}^{\text {given }}$, it is sufficient (and computationally cheaper) to only check whether any other solution exists. Hence, we will search for any sudoku solution (line 3) that is different from the sol solution that we already know exists (line 2).</p>
<p>If there does not exist such other solution, i.e. the assignment is an empty set (line 4), then the solution is unique and there is nothing more we can infer. If there is another solution, we reject $\left{\operatorname{sol}<em i="i" j="j">{i j}\right}^{\text {given }}$ for not being unique. That is, we add a nogood ensuring that no completion of $\left{\operatorname{sol}</em>$ will be found anymore (line 5), and repeat the procedure.}\right}^{\text {given }</p>
<p>This use of a nogood, or a blocking clause, is common in solving such secondorder logic problems. It can be seen as an instantiation of solution dominance [5].</p>
<div class="codehilite"><pre><span></span><code>Algorithm 1: Higher-order COP of \(\operatorname{VizSudoku}\left(C_{\text {rules }},\left\{X_{i j}\right\}^{\text {given }}\right)\) using
a trained DNN \(f_{\theta}(X)\)
\(s o l \leftarrow \operatorname{VizSudoku}\left(C_{\text {rules }},\left\{X_{i j}\right\}^{\text {given }}\right) \quad / /\) as in hybrid1
\(C_{\text {rules }}^{\prime} \leftarrow C_{\text {rules }} \wedge \neg(V=s o l)) \quad / /\) temporarily forbid this solution
\(\operatorname{sol}^{\prime} \leftarrow \operatorname{CSP}\left(C_{\text {rules }}^{\prime},\left\{\operatorname{sol}_{i j}\right\}^{\text {given }}\right) \quad / /\) check for other solutions having these
    given
while \(\operatorname{sol}^{\prime} \neq \emptyset\) do
        \(C_{\text {rules }} \leftarrow C_{\text {rules }} \wedge \neg\left(V^{\text {given }}=\operatorname{sol}^{\text {given }}\right) \quad / /\) add nogood on given
        \(\operatorname{sol} \leftarrow \operatorname{VizSudoku}\left(C_{\text {rules }},\left\{X_{i j}\right\}^{\text {given }}\right) \quad / /\) as in hybrid1
        \(C_{\text {rules }}^{\prime} \leftarrow C_{\text {rules }} \wedge \neg(V=s o l)) \quad / /\) temporarily forbid this solution
        \(\operatorname{sol}^{\prime} \leftarrow \operatorname{CSP}\left(C_{\text {rules }}^{\prime},\left\{\operatorname{sol}_{i j}\right\}^{\text {given }}\right)\)
    end
    return sol
</code></pre></div>

<h1>5 Class probability calibration</h1>
<p>In a machine learning context, calibration is the process of modifying the predicted probabilities so that they match the expected distribution of probabilities for each class [6]. We will investigate the effect of calibration on our joint inference approach. Our method reasons over all 9 probability estimates $\left{\left(P_{\theta}(y=1 \mid X), \ldots, P_{\theta}(y=p \mid X)\right}, p o s\right}$ and actively trades-off the probability of a prediction of one image to the prediction of another image in its objective function. Hence, it is not just a method of getting the top-predicted value right, but rather of getting all predicted probabilities correctly. Our reasoning approach hence assumes real (calibrated) probabilities and could be hampered by over- or under-confident class probability estimations.</p>
<p>In a multi-class setting, for a given handwritten digit a neural probabilistic classifier computes a vector $\boldsymbol{z}$ containing raw scores for each class (i. e. a digit value), $\boldsymbol{z}_{\boldsymbol{k}}$ being the score assigned to class $k$. The SoftMax function is then applied to convert these raw scores into probabilities:</p>
<p>$$
\sigma_{\text {SoftMax }}\left(\boldsymbol{z}<em k="k">{k}, \boldsymbol{z}\right)=\frac{\exp \left(\boldsymbol{z}</em>
$$}\right)}{\sum_{i} \exp \left(\boldsymbol{z}_{i}\right)</p>
<p>such that $P_{\theta}(y=k \mid X)=\sigma_{\text {SoftMax }}\left(\boldsymbol{z}_{k}, \boldsymbol{z}\right)$ is the output of the neural network.
While this output is normalized across classes to sum up to 1 , the values are not real probabilities. More specifically, it has been shown that especially neural networks tend to overestimate the probability that an item belongs to its maximum likelihood class [6].</p>
<p>Post-processing methods such as Platt scaling [22] aim at calibrating the probabilistic output of a pre-trained classifier. Guo et al. [6] describe three variants of Platt scaling in the multi-class setting. In matrix scaling, a weight matrix $\boldsymbol{W}$ and a bias vector $\boldsymbol{b}$ apply a linear transform to the input vector of the softmax layer $\boldsymbol{z}_{i}$ such that the calibrated probabilities become:</p>
<p>$$
\widetilde{P}<em i="i">{\theta}\left(y</em>}=k \mid X_{i}\right)=\sigma_{\text {SoftMax }}\left(\boldsymbol{W<em _boldsymbol_k="\boldsymbol{k">{\boldsymbol{k}} \boldsymbol{z}</em>\right)
$$}}+\boldsymbol{b}_{\boldsymbol{k}}, \boldsymbol{W} \boldsymbol{z}+\boldsymbol{b</p>
<p>where $\boldsymbol{W}$ and $\boldsymbol{b}$ are parameters, learned by minimizing the Negative Log Likelihood loss on a validation set. Vector scaling applies the same linear transform, except that $\boldsymbol{W}$ is a diagonal matrix, that is, only the diagonal is non-zero. Finally, Temperature scaling considers a single scalar value $T$ to calibrate the probability such that:</p>
<p>$$
\widetilde{P}<em i="i">{\theta}\left(y</em>\right)
$$}=k \mid X_{i}\right)=\sigma_{\text {SoftMax }}\left(\frac{z_{k}}{T}, \frac{z}{T</p>
<p>To calibrate the predictions, we train a model $f_{\theta, \boldsymbol{W}, \boldsymbol{b}}(X)$ where $\left{\left(\widetilde{P}<em _theta="\theta">{\theta}(y=\right.\right.$ $\left.1 \mid X), \ldots, \widetilde{P}</em>$.}(y=p \mid X)\right}\right}$ is calibrated on a validation set $\left{X_{i}, y_{i}\right}_{\text {validation }}$. More specifically, we will do calibration on top of a pre-trained neural network, so $\theta$ is pre-trained and the calibration learns the best $\boldsymbol{W}, \boldsymbol{b</p>
<p>We will evaluate whether better calibrated probabilities lead to better joint inference reasoning in the experiments.</p>
<h1>6 Experiments</h1>
<p>Numerical experiments were done on a subset of the Visual Sudoku Dataset used in [30]. The subset contains 3000 sudoku boards whose givens are represented by MNIST digits. The average number of givens per sudoku grid is 36.2. Unless stated otherwise, the MNIST train data was split into $80 \%-20 \%$ train and validation set.</p>
<p>The DNN architecture for the digit classification task is the LeNet architecture [10] which uses two convolutional layers followed by two fully connected layers. The network is trained for 10 epochs to minimize cross-entropy loss, and is optimized via Adam with a learning rate of $10^{-5}$. Once trained on the MNIST train data, we use the same model for both separate and hybrid approaches. The neural network and CP model were implemented using PyTorch 1.3.0 [19] and OR-tools 7.4.7247 [21], respectively. All experiments were run on a laptop with $8 \times$ Intel ${ }^{\circledR}$ Core $^{\mathrm{TM}}$ i7-8565U CPU @ 1.80 GHz and 16 Gb of RAM.</p>
<p>To test the performance of our proposed frameworks, we define the following evaluation measures:
img accuracy $=$ percentage of givens correctly labeled by the classifier
cell accuracy $=$ percentage of cells matching the true solution
grid accuracy $=$ percentage of correctly solved sudokus. A sudoku is correctly solved if its true solution was found. That is, if</p>
<p>$$
\begin{gathered}
s_{1} \in \operatorname{VizSudoku}\left(C_{\text {rules }},\left{X_{i j}\right}^{\text {given }}\right) \
s_{2} \in \operatorname{CSP}\left(C_{\text {rules }},\left{y_{i j}\right}^{\text {given }}\right) \Longrightarrow s_{1} \equiv s_{2}
\end{gathered}
$$</p>
<p>failure rate grid $=$ percentage of sudokus without a solution. A sudoku has no solution if $\operatorname{VizSudoku}\left(C_{\text {rules }},\left{X_{i j}\right}^{\text {given }}\right)=\emptyset$
In the subsequent experiments, we denote as baseline the separated classification and reasoning approach, whereas we refer to our proposed approaches as hybrid1 and hybrid2.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">$\mathbf{i m g}$</th>
<th style="text-align: center;">$\mathbf{a c c u r a c y}$ <br> $\mathbf{c e l l}$</th>
<th style="text-align: center;">$\mathbf{g r i d}$</th>
<th style="text-align: right;">$\mathbf{f a i l u r e ~ r a t e}$ <br> $\mathbf{g r i d}$</th>
<th style="text-align: right;">$\mathbf{t i m e}$ <br> $\mathbf{a v e r a g e} \mathbf{( s )}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">baseline</td>
<td style="text-align: center;">$94.75 \%$</td>
<td style="text-align: center;">$15.51 \%$</td>
<td style="text-align: center;">$14.67 \%$</td>
<td style="text-align: right;">$84.43 \%$</td>
<td style="text-align: right;">0.01</td>
</tr>
<tr>
<td style="text-align: left;">hybrid1</td>
<td style="text-align: center;">$99.69 \%$</td>
<td style="text-align: center;">$99.38 \%$</td>
<td style="text-align: center;">$92.33 \%$</td>
<td style="text-align: right;">$0 \%$</td>
<td style="text-align: right;">0.79</td>
</tr>
<tr>
<td style="text-align: left;">hybrid2</td>
<td style="text-align: center;">$99.72 \%$</td>
<td style="text-align: center;">$99.44 \%$</td>
<td style="text-align: center;">$92.93 \%$</td>
<td style="text-align: right;">$0 \%$</td>
<td style="text-align: right;">0.83</td>
</tr>
</tbody>
</table>
<p>Table 1: Comparison of hybrid solving approaches</p>
<h1>6.1 Separate vs Hybrid Approaches</h1>
<p>First we compare the result of the three approaches described in section 4. As displayed on Table 1, the ability of the baseline approach to handle the image classification task with an accuracy of $94.75 \%$ translates to a meagre success rate of only $14.67 \%$ at the level of sudoku grids correctly solved. This is because the constraints relationships are not translated to the DNN model. As a consequence there is no way to ensure that the predictions would respect the constraints. Even a single mistake in predictions out of all the given images may result in an unsolvable puzzle. As an example, if one prediction error makes the same number appear twice in a row then the whole puzzle will be unsolvable even if the rest of the predictions are accurate.</p>
<p>On the other hand the hybrid approaches do not consider the model predictions as final and by using the constraints relationships, hybrid2, for instance, brings the classifier to correctly label 5361 additional images. As a result we observed an increase in overall accuracy of the predictions. The advantage of our frameworks is more prominent from the grid perspective, where we can see that more than $92 \%$ of the sudokus are now correctly solved. This is a huge improvement from the baseline approach which solves only $14.67 \%$ of the grids.</p>
<p>In terms of final performance hybrid2 is more accurate as it exploits one more sudoku property; namely that sudoku must have a unique solution. By this mechanism we are able to further rectify more predictions and 18 additional puzzles are solved accurately.</p>
<p>However, from a computational standpoint, our hybrid approaches solve a COP instead of a CSP in the pure reasoning case. Hence they are almost a 100 times more time consuming (only the average per sudoku is shown). The average computation time is slightly higher for hybrid2 as we need to prove that predicted givens only have a unique solution, or optimize again with a forbidden assignments if that is not the case; this situation happens 18 times in our experiments.</p>
<h3>6.2 Reasoning Over Top- $k$ Probable Digits</h3>
<p>We are curious to know how the hybrid approaches outperform the separate approach. So we investigate when a digit is chosen by the hybrid approaches, how, on average, it is ranked by the ML classifier when ranking by probability.</p>
<p>Table 2 reveals, among the instances where we find the correct solution, that the top-ranked value is chosen in most cases, with a quick decline in how often</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3: Strength of hybrid with less accurate predictions
the other values are chosen. Remarkably, in 42 cases (i.e. $0.02 \%$ of predictions) hybrid2 actually uses a digit which is ranked 8 or lower by the classifier.</p>
<p>From a combinatorial optimisation perspective, one can also consider that this allows to trade-off the size of the search space with the accuracy of the resulting solutions by only taking the $k$ highest probable digits into account and removing the others from the domains. In this regard the experiment in the previous section considered two extremes: the baseline uses only the maximum probable digit, and the hybrid approaches use all 9 digits.</p>
<p>Therefore, we investigate the effect of considering the top-k probability ranked digits on computational time and accuracy. Table 3 shows the effect of using only reasoning over the top- $k$ predicted values of the classifier:</p>
<p>When considering top-1 to top-4 values, we see that the image accuracy steadily goes up as does the grid correctness, and grid failure reaches 0 for top-4. As we consider 4 or more digits, both grid and image values slowly increase, with the best results obtained using all possible values; which makes the difference for 8 sudoku instances when using hybrid2.</p>
<p>This shows that there is indeed a trade-off between computational time of the joint inference and accuracy of the result, with runtime performance gains possible at low accuracy cost if needed.</p>
<h1>6.3 Classifier strength versus reasoning strength</h1>
<p>So far, we have used a fairly accurate model. We have also seen that joint inference by constraint solving could indeed correct many of the wrong predictions. In this experiment, we investigate the limits of this 'correcting' power of the reasoning. That is, for increasingly worse predictive models, we compare the accuracy of the baseline with our hybrid approaches.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">rank-0 rank-1 rank-2 rank-3 rank-4 rank-5 rank-6 rank-7 rank-8</th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">hybrid1</td>
<td style="text-align: left;">$94.85 \%$</td>
<td style="text-align: left;">$3.68 \%$</td>
<td style="text-align: left;">$0.93 \%$</td>
<td style="text-align: left;">$0.32 \%$</td>
<td style="text-align: left;">$0.12 \%$</td>
<td style="text-align: left;">$0.07 \%$</td>
<td style="text-align: left;">$0.02 \%$</td>
<td style="text-align: left;">$0.01 \%$</td>
</tr>
<tr>
<td style="text-align: left;">hybrid2</td>
<td style="text-align: left;">$94.84 \%$</td>
<td style="text-align: left;">$3.68 \%$</td>
<td style="text-align: left;">$0.92 \%$</td>
<td style="text-align: left;">$0.33 \%$</td>
<td style="text-align: left;">$0.12 \%$</td>
<td style="text-align: left;">$0.06 \%$</td>
<td style="text-align: left;">$0.02 \%$</td>
<td style="text-align: left;">$0.01 \%$</td>
</tr>
</tbody>
</table>
<p>Table 2: Rank distribution for cell values in correctly solved sudokus</p>
<p>Results in Figure 3 show that even after 2 epochs, with an accuracy of approximately $88 \%$, the reasoning is able to correct this to $98 \%$, i.e., a correction factor of $10 \%$. Hence, with weaker predictive models, the reasoning has even more potential for correcting.</p>
<p>Results on Table 4 show that this trend remains true even with a stronger classifier, obtained by considering a learning rate of $2 \times 10^{-3}$. In the stronger classifier case, hybrid2 correctly classifies 654 more images than the baseline.</p>
<p>Also noteworthy is that the average runtime goes up by a significant factor, e.g., it is 10 times slower as the predictions become less accurate. Further investigation shows that the predicted values are less skewed at lower accuracy levels, e.g., the softmax probabilities are more similar and hence the branch-and-bound search takes more time in finding and proving optimality.</p>
<h1>6.4 Effect of calibration</h1>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4: Calibration curve, mean of probabilities over 15 equally-sized intervals</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">accuracy <br> cell</th>
<th style="text-align: center;">grid</th>
<th style="text-align: right;">failure rate <br> grid</th>
<th style="text-align: right;">time <br> average (s)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">top- $k$</td>
<td style="text-align: center;">img</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr>
<td style="text-align: left;">top-1</td>
<td style="text-align: center;">$94.75 \%$</td>
<td style="text-align: center;">$15.36 \%$</td>
<td style="text-align: center;">$14.67 \%$</td>
<td style="text-align: right;">$84.60 \%$</td>
<td style="text-align: right;">0.03</td>
</tr>
<tr>
<td style="text-align: left;">top-2</td>
<td style="text-align: center;">$96.15 \%$</td>
<td style="text-align: center;">$63.63 \%$</td>
<td style="text-align: center;">$55.43 \%$</td>
<td style="text-align: right;">$34.20 \%$</td>
<td style="text-align: right;">0.03</td>
</tr>
<tr>
<td style="text-align: left;">top-3</td>
<td style="text-align: center;">$96.63 \%$</td>
<td style="text-align: center;">$94.73 \%$</td>
<td style="text-align: center;">$77.17 \%$</td>
<td style="text-align: right;">$0.20 \%$</td>
<td style="text-align: right;">0.06</td>
</tr>
<tr>
<td style="text-align: left;">top-4</td>
<td style="text-align: center;">$98.78 \%$</td>
<td style="text-align: center;">$98.04 \%$</td>
<td style="text-align: center;">$86.33 \%$</td>
<td style="text-align: right;">$0 \%$</td>
<td style="text-align: right;">0.12</td>
</tr>
<tr>
<td style="text-align: left;">top-5</td>
<td style="text-align: center;">$99.35 \%$</td>
<td style="text-align: center;">$98.86 \%$</td>
<td style="text-align: center;">$89.67 \%$</td>
<td style="text-align: right;">$0 \%$</td>
<td style="text-align: right;">0.26</td>
</tr>
<tr>
<td style="text-align: left;">top-6</td>
<td style="text-align: center;">$99.57 \%$</td>
<td style="text-align: center;">$99.21 \%$</td>
<td style="text-align: center;">$91.60 \%$</td>
<td style="text-align: right;">$0 \%$</td>
<td style="text-align: right;">0.38</td>
</tr>
<tr>
<td style="text-align: left;">top-7</td>
<td style="text-align: center;">$99.67 \%$</td>
<td style="text-align: center;">$99.36 \%$</td>
<td style="text-align: center;">$92.33 \%$</td>
<td style="text-align: right;">$0 \%$</td>
<td style="text-align: right;">0.55</td>
</tr>
<tr>
<td style="text-align: left;">top-8</td>
<td style="text-align: center;">$99.69 \%$</td>
<td style="text-align: center;">$99.40 \%$</td>
<td style="text-align: center;">$92.63 \%$</td>
<td style="text-align: right;">$0 \%$</td>
<td style="text-align: right;">0.66</td>
</tr>
<tr>
<td style="text-align: left;">top-9</td>
<td style="text-align: center;">$99.71 \%$</td>
<td style="text-align: center;">$99.43 \%$</td>
<td style="text-align: center;">$92.90 \%$</td>
<td style="text-align: right;">$0 \%$</td>
<td style="text-align: right;">0.80</td>
</tr>
</tbody>
</table>
<p>Table 3: Rank experiment using hybrid2 for joint inference</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">accuracy</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">failure rate</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">img</td>
<td style="text-align: center;">cell</td>
<td style="text-align: center;">grid</td>
<td style="text-align: center;">grid</td>
</tr>
<tr>
<td style="text-align: center;">baseline</td>
<td style="text-align: center;">$99.384 \%$</td>
<td style="text-align: center;">$80.380 \%$</td>
<td style="text-align: center;">$80.100 \%$</td>
<td style="text-align: center;">$19.6 \%$</td>
</tr>
<tr>
<td style="text-align: center;">hybrid1</td>
<td style="text-align: center;">$99.984 \%$</td>
<td style="text-align: center;">$99.966 \%$</td>
<td style="text-align: center;">$99.500 \%$</td>
<td style="text-align: center;">$0 \%$</td>
</tr>
<tr>
<td style="text-align: center;">hybrid2</td>
<td style="text-align: center;">$99.986 \%$</td>
<td style="text-align: center;">$99.972 \%$</td>
<td style="text-align: center;">$99.600 \%$</td>
<td style="text-align: center;">$0 \%$</td>
</tr>
</tbody>
</table>
<p>Table 4: Comparison of separate and hybrid approach with a stronger classifier</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">uncalibrated</th>
<th style="text-align: left;">Temp. scaling</th>
<th style="text-align: left;">Vector scaling</th>
<th style="text-align: left;">Matrix scaling</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">NLL</td>
<td style="text-align: left;">12.07</td>
<td style="text-align: left;">11.61</td>
<td style="text-align: left;">11.38</td>
<td style="text-align: left;">$\mathbf{1 0 . 1 2}$</td>
</tr>
<tr>
<td style="text-align: left;">test acc.</td>
<td style="text-align: left;">$96.75 \%$</td>
<td style="text-align: left;">$96.75 \%$</td>
<td style="text-align: left;">$96.70 \%$</td>
<td style="text-align: left;">$\mathbf{9 6 . 9 3 \%}$</td>
</tr>
</tbody>
</table>
<p>Table 5: NLL loss on validation set and test accuracy for Platt scaling variants
As the joint inference reasons over the probabilities, we will investigate the effect of calibration on the reasoning. The first step towards that goal is to compare the different calibration methods we presented in section 5, namely Matrix scaling, Vector scaling, and Temperature scaling. As described earlier, for each of these methods, calibration parameters are learned by minimizing the Negative Log Likelihood loss on the validation set (while remaining parameters of the network are fixed). Table 5 shows the validation NLL and the test accuracy before and after calibrating of the network. This table suggests that Matrix scaling produces the most calibrated classifier. Figure 4 shows how the classifier, although already quite well calibrated, is brought closer to a perfectly calibrated model.</p>
<p>Figure 5 displays the effect of using a more calibrated model by running the top-k experiment with the hybrid2 framework, with calibrated and uncalibrated classifiers. It shows that calibration improves the accuracy of our framework. This is true when considering not only less accurate, but also more accurate, neural networks, as reasoning over all 9 probabilities leads a calibrated classifier used within the hybrid2 framework to an img rate of $99.80 \%$, an accuracy cell rate of $99.62 \%$ and $94.30 \%$ of correctly solved grids.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 5: Performance measures for joint inference from calibrated classifier and comparison with uncalibrated counterpart</p>
<h1>7 Conclusions</h1>
<p>In this paper we study a prototype application of hybrid prediction and constraint optimisation, namely the visual sudoku. Although deep neural networks have achieved unprecedented success in classification and reinforcement learning, they still fail at directly predicting the result of a combinatorial optimisation problem, due to the hard constraints and combinatorial optimisation aspect.</p>
<p>We propose a framework for solving challenging combinatorial problems like this, by adding a constraint programming layer on top of a neural network, which does joint inference over a set of predictions. We argue that reasoning over the actual predictions is limited as it ignores the probabilistic nature of the classification task, as confirmed by the experimental results. Instead, we can optimize the most likely joint solution over the classification probabilities which respects the hard constraints. Higher-order relations, such as that a solution must be unique, can also be taken into account to further improve the results.</p>
<p>Our proposed approach always finds a solution that satisfies the constraints, and corrects the underlying neural network output up to $10 \%$ in accuracy, for example transforming the output of a $94.8 \%$ accurate classifier into a $99.7 \%$ accurate joint inference classifier.</p>
<p>More broadly, we believe that this work is a notable path to incorporate domain-specific expertise in ML models. Practitioners often feel that they can help to make a ML model better by infusing their expertise into the model. However, incorporating such structured knowledge is often not feasible in a DNN setting. Our work proposes one way to impart human knowledge, namely on top of the neural network architecture and independent of the learning.</p>
<p>An interesting direction for future work is to look at differential classifica-tion+optimisation techniques, such as OptNet [1], and investigate whether it is possible to train better models end-to-end for this kind of hard constrained problems. In this respect, there is also a link with probabilistic programming techniques, which often use knowledge compilation to embed (typically simpler) constraints in a satisfaction setting [15]. Finally, we are keen to apply this technique on applications involving classification tasks, such as manhole maintenance [29] and more.</p>
<p>Acknowledgements. This research received funding from the Flemish Government under the "Onderzoeksprogramma Artificiële Intelligentie (AI) Vlaanderen" programme.</p>
<h2>References</h2>
<ol>
<li>Amos, B., Kolter, J.Z.: Optnet: Differentiable optimization as a layer in neural networks. In: Proceedings of the 34th International Conference on Machine LearningVolume 70. pp. 136-145. JMLR. org (2017)</li>
<li>
<p>Bengio, Y.: Using a financial training criterion rather than a prediction criterion. International Journal of Neural Systems 8(04), 433-443 (1997)</p>
</li>
<li>
<p>Chen, L., Feng, Y., Huang, S., Luo, B., Zhao, D.: Encoding implicit relation requirements for relation extraction: A joint inference approach. Artificial Intelligence 265, 45-66 (2018)</p>
</li>
<li>Goodfellow, I., Bengio, Y., Courville, A.: Deep Learning. MIT Press (2016)</li>
<li>Guns, T., Stuckey, P.J., Tack, G.: Solution dominance over constraint satisfaction problems. CoRR abs/1812.09207 (2018)</li>
<li>Guo, C., Pleiss, G., Sun, Y., Weinberger, K.Q.: On calibration of modern neural networks (2017)</li>
<li>Ifrim, G., O'Sullivan, B., Simonis, H.: Properties of energy-price forecasts for scheduling. In: International Conference on Principles and Practice of Constraint Programming. pp. 957-972. Springer (2012)</li>
<li>Kool, W., van Hoof, H., Welling, M.: Attention, learn to solve routing problems! In: ICLR 2019 : 7th International Conference on Learning Representations (2019)</li>
<li>Lake, B.M., Ullman, T.D., Tenenbaum, J.B., Gershman, S.J.: Building machines that learn and think like people. Behavioral and brain sciences 40 (2017)</li>
<li>LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., et al.: Gradient-based learning applied to document recognition. Proceedings of the IEEE 86(11), 2278-2324 (1998)</li>
<li>Li, Q., Anzaroot, S., Lin, W.P., Li, X., Ji, H.: Joint inference for cross-document information extraction. In: Proceedings of the 20th ACM international conference on Information and knowledge management. pp. 2225-2228. ACM (2011)</li>
<li>Li, Q., Ji, H., Huang, L.: Joint event extraction via structured prediction with global features. In: Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). pp. 73-82 (2013)</li>
<li>Li, T., Gupta, V., Mehta, M., Srikumar, V.: A logic-driven framework for consistency of neural models. arXiv preprint arXiv:1909.00126 (2019)</li>
<li>Mandi, J., Demirović, E., Stuckey, P., Guns, T., et al.: Smart predict-and-optimize for hard combinatorial optimization problems. arXiv preprint arXiv:1911.10092 (2019)</li>
<li>Manhaeve, R., Dumancic, S., Kimmig, A., Demeester, T., De Raedt, L.: Deepproblog: Neural probabilistic logic programming. In: Advances in Neural Information Processing Systems. pp. 3749-3759 (2018)</li>
<li>Márquez-Neila, P., Salzmann, M., Fua, P.: Imposing hard constraints on deep networks: Promises and limitations. arXiv preprint arXiv:1706.02025 (2017)</li>
<li>Mukhopadhyay, A., Vorobeychik, Y., Dubey, A., Biswas, G.: Prioritized allocation of emergency responders based on a continuous-time incident prediction model. adaptive agents and multi agents systems pp. 168-177 (2017)</li>
<li>van den Oord, A., Vinyals, O., et al.: Neural discrete representation learning. In: Advances in Neural Information Processing Systems. pp. 6306-6315 (2017)</li>
<li>Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., Lerer, A.: Automatic differentiation in PyTorch. In: NeurIPS Autodiff Workshop (2017)</li>
<li>Pathak, D., Krahenbuhl, P., Darrell, T.: Constrained convolutional neural networks for weakly supervised segmentation. In: Proceedings of the IEEE international conference on computer vision. pp. 1796-1804 (2015)</li>
<li>Perron, L., team: Google's or-tools</li>
<li>Platt, J.C.: Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods. In: ADVANCES IN LARGE MARGIN CLASSIFIERS. pp. 61-74. MIT Press (1999)</li>
<li>
<p>Platt, J.C., Barr, A.H.: Constrained differential optimization. In: Neural Information Processing Systems. pp. 612-621 (1988)</p>
</li>
<li>
<p>Poon, H., Domingos, P.: Joint inference in information extraction. In: AAAI. vol. 7, pp. 913-918 (2007)</p>
</li>
<li>Punyakanok, V., Roth, D., Yih, W.t., Zimak, D.: Semantic role labeling via integer linear programming inference. In: Proceedings of the 20th International Conference on Computational Linguistics. p. 1346-es. COLING '04, Association for Computational Linguistics, USA (2004)</li>
<li>Riedel, S.: Improving the accuracy and efficiency of map inference for markov logic. arXiv preprint arXiv:1206.3282 (2012)</li>
<li>Rossi, F., Van Beek, P., Walsh, T.: Handbook of constraint programming. Elsevier (2006)</li>
<li>The High-Level Expert Group on Artificial Intelligence (AI HLEG): A definition of ai (2017)</li>
<li>Tulabandhula, T., Rudin, C.: Machine learning with operational costs. The Journal of Machine Learning Research 14(1), 1989-2028 (2013)</li>
<li>Wang, P.W., Donti, P., Wilder, B., Kolter, Z.: Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver. In: ICML 2019 : Thirtysixth International Conference on Machine Learning. pp. 6545-6554 (2019)</li>
<li>Wang, Y., Chen, Q., Ahmed, M., Li, Z., Pan, W., Liu, H.: Joint inference for aspect-level sentiment analysis by deep neural networks and linguistic hints. IEEE Transactions on Knowledge and Data Engineering (2019)</li>
<li>Wilder, B.: Melding the data-decisions pipeline: Decision-focused learning for combinatorial optimization. In: Proceedings of the 33rd AAAI Conference on Artificial Intelligence (2019)</li>
</ol>            </div>
        </div>

    </div>
</body>
</html>