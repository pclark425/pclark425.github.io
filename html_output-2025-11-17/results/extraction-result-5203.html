<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5203 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5203</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5203</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-109.html">extraction-schema-109</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <p><strong>Paper ID:</strong> paper-198138287</p>
                <p><strong>Paper Title:</strong> The Explanatory Role of Concepts</p>
                <p><strong>Paper Abstract:</strong> Machery (Doing without concepts, Oxford University Press, New York, 2009) and Weiskopf (Synthese 169:145–173, 2009) argue that the kind concept is a natural kind if and only if it plays an explanatory role in cognitive scientific explanations. In this paper, we argue against this explanationist approach to determining the natural kind-hood of concept. We first demonstrate that hybrid, pluralist, and eliminativist theories of concepts afford the kind concept different explanatory roles. Then, we argue that we cannot decide between hybrid, pluralist, and eliminativist theories of concepts, because each endorses a different, but equally viable, specification of the explananda of cognitive science. It follows that an explanationist approach to determining the natural kind-hood of concept fails, because there is no consensus about whether or not concept should be afforded an explanatory role in our best cognitive scientific explanations. We conclude by considering what our critique of explanationism could imply for further discussions about the explanatory role of concepts in cognitive science. 1 The Explanatory Challenge to concept According to the “received view,” all concepts have a number of properties in common: they all store a single kind of information, they all have the same functional properties, and they are all acquired by the same type of learning process, etc. (Machery and Seppälä 2011, p.  99). On this view, a theory of concepts aims to describe these properties and so to account for the formation and application of concepts. Moreover, from the perspective of the received view, concepts are of one kind—the kind concept—and they “explain the properties of our higher cognitive competences”; that is, the properties of higher cognition that are operative in * Samuel D. Taylor sam.taylor@hhu.de; samuel.da.taylor@gmail.com Gottfried Vosgerau vosgerau@hhu.de 1 Department of Philosophy, Heinrich-Heine-University Düsseldorf, Universitätsstraße 1, 40225 Düsseldorf, Germany S. D. Taylor, G. Vosgerau 1 3 cognitive tasks such as categorisation, meaning extraction, and inductive and deductive reasoning (Machery and Seppälä 2011, p. 99).1 In recent years, however, psychologists have identified several distinct types of categorisation judgements, several distinct operations of meaning extraction, and several distinct episodes of inductive/deductive reasoning, and so have been forced to posit a number of different representational kinds, with incommensurable properties, to do the required explanatory work. For example, prototypes (Rosch 1973; Lakoff 1987), bundles of exemplars (Nosofsky 1988), theory-like structures (Carey 1985; Gopnik and Meltzoff 1997; Rehder 2003), perceptual ‘proxytypes’ (Prinz 2002), and unstructured atomic symbols (Fodor 1994) have all been posited to explain, say, categorisation and reasoning. As a result, it has been argued that the received view of concepts cannot be correct, because the explanatory work is not done by the single kind concept, but by a set of representational kinds that do not store the same kinds of information or have the same functional properties (BlochMullins 2018). To make the explanatory challenge to the received view concrete, consider explanations of categorisation judgements. In some cases, psychologists explain the categorisation of an individual c in a category C in terms of a correspondence between the properties of c and the typical properties of members of C. In cases such as these, psychologists posit the kind prototype to do the required explanatory work. However, in other cases psychologists explain the categorisation of an individual c in a category C in terms of a judgement that c is sufficiently similar to salient members of C. In cases such as these, psychologists posit the kind exemplar to do the required explanatory work. According to the explanatory challenge, because psychologists are required to posit different representational kinds with different properties and functions to explain these different types of categorisation judgements, the kind concept is redundant in explanations of categorisation. And because the received view of concept fails to predict this explanatory diversity it is argued that it cannot be correct (cf. Machery and Seppälä 2011, p. 99).2 In this paper, we argue against one possible interpretation of the explanatory challenge: that the explanatory challenge demonstrates that concept is not a natural kind. This involves rejecting what we will call an explanationist approach for determining the natural kind-hood of concept, whereby concept is taken to be a natural kind iff concept features in a proposition best explaining some explananda of 1 In this paper, we denote kinds with small caps. 2 One quick and easy way to respond to the explanatory challenge to the received view is to argue that all posited representational kinds are of the super-kind concept in virtue of the fact that they are all constituents of thought. According to this response, all of the representational kinds posited to do explanatory work in cognitive science fall under the concept of concept in virtue of being conceptual in kind (Weiskopf 2009, pp. 147–148). Many philosophers have been quick to accept this view as part of their response to the explanatory challenge. However, even if one thinks that this response is broadly correct, this still leaves open a further question: what are the defining properties of the super-kind concept that make it the case that all representations doing explanatory work in cognitive science can be classified as concepts? Providing an answer to this question has proven to be controversial and remains the central issue of contention between competing theories of concepts that we discuss in sections three, four, and five below.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5203.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5203.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype theory (Rosch)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented as prototypes — stored summaries of typical properties — and categorization is explained by correspondence between an item's properties and the prototype's typical features.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Natural categories</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>At the functional level, conceptual knowledge is stored as a summary or averaged representation (a prototype) that encodes the typical/central features of a category; categorization is performed by comparing inputs to these prototypical summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>prototype / summary representation (abstraction over exemplars)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Abstraction (averaging over instances), graded membership (typicality), fast similarity-based matching, context-sensitivity via shifting typicality</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Classic typicality and family-resemblance findings (Rosch-style): faster, more confident categorization for more prototypical items; typicality gradients across members; perceptual and categorization experiments showing prototype-consistent responses.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Cases where similarity-to-exemplars or rule/theory-based reasoning predicts behavior better (e.g., exemplar effects, causal or essence-based judgements), developmental evidence of shifts, and cases requiring explicit inferential structure not captured by prototypes.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization, typicality judgments, some aspects of semantic memory and rapid classification tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasted with exemplar models (individual-matching) and theory-theory (causal/essentialist explanations); strengths in explaining typicality effects and parsimony, weaknesses in explaining rule-like inference and exceptions.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Form prototypes by abstraction across instances; compute similarity between input and prototype to drive categorization; typicality influences recognition speed and confidence.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How prototypes are formed from varied instances, how they support compositional or causal inference, and how to reconcile prototype effects with exemplar or theory-based effects in same tasks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5203.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5203.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar model (Nosofsky)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented as collections of stored individual exemplars; categorization is performed by comparing new items to remembered exemplars and aggregating similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exemplar-based accounts of relations between classification, recognition, and typicality</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Exemplar model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functionally, conceptual representation consists of stored tokens of past examples; categorization is achieved by similarity-based retrieval of and vote/weighting over relevant exemplars rather than by comparing to an abstracted prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>exemplar / instance-based representation</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Memory-based storage of instances, similarity-weighted retrieval, high flexibility for exceptions, sensitivity to frequency and recency, no single summary abstraction required.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Fits to categorization and recognition data showing effects of specific exemplars, ability to capture effects of distributional frequency and fine-grained similarity structure, dissociations between similarity judgments and categorization observed (Ahn & Dennis).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Scalability and parsimony concerns, difficulty accounting for fast generalization to novel exemplars or for abstract inferential patterns that look rule-like, and some developmental or causal reasoning findings better captured by theory-like representations.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization, recognition memory, similarity-based judgments, exemplar transfer tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Explains fine-grained similarities better than prototype models but may be less economical; contrasted with prototype (summary) and theory-theory (causal/structured) approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Store tokens of encountered exemplars; on categorization compute similarity of input to stored exemplars and aggregate similarity-weighted evidence to select category.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How exemplar stores scale and get pruned/organized, how exemplar representations support composition or abstraction, and how exemplar and prototype influences combine in behavior.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5203.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5203.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Theory-theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Theory-like structures / theory-theory (Carey; Rehder)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts include structured, causal/essence-like information (mini-theories) used for explanation, prediction, and some forms of categorization and inference.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Conceptual change in childhood</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Theory-theory / theory-like structures</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>At the functional level, conceptual knowledge is represented as structured causal or explanatory frameworks ('theory-like' structures) that encode essences, causal relations and inferential roles, and are used for explanation-based generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>theory-like / structured / causal-model representation</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Structured (parts and relations), causal/essential information, supports explanation and prediction, supports principle-based inference and sometimes hierarchical taxonomies.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Evidence from developmental conceptual change (Carey), causal-model accounts of categorization and concept use (Rehder), and tasks where causal/essence information governs category-based inference rather than surface similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Difficulty explaining rapid typicality effects and similarity-driven categorization, and cases where participants rely on prototypes or exemplars rather than explicit causal structure.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Causal induction, explanation-driven categorization, conceptual development, inductive reasoning about kinds.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Captures inferential and explanatory aspects that prototypes/exemplars miss; often invoked where essence/causal information determines judgments, but weaker for immediate perceptual similarity phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Maintain causal/essence knowledge that can be applied to infer properties of category members; explanation and prediction are driven by activating theory-relevant relations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How theory-like structures interface with fast, similarity-based processes; how they are acquired from experience; and how they are represented at a computational level alongside exemplar/prototype information.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5203.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5203.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Perceptual proxytypes</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Perceptual proxytypes (Prinz)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts derive from perceptual representations ('proxytypes'): perceptual episodes or schemata that serve as the basis for conceptual content and categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Furnishing the mind: Concepts and their perceptual basis</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Perceptual proxytypes</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functionally, conceptual representations are grounded in perceptual representations that act as proxies; conceptual judgments draw on perceptual feature clusters and their activation patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>perceptually grounded / proxy perceptual representations</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Perceptual grounding, modality-specific information, captures perceptually-driven categorization and typicality, links perception and conceptual content.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Evidence that perceptual features strongly influence categorization and typicality judgments; compatibility with findings that perceptual similarity predicts category membership in many tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Struggles to account for abstract concepts or knowledge that is not easily tied to perceptual episodes; causal or theory-driven inferences may not be explained by purely perceptual bases.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Perceptually-driven categorization, concept acquisition from sensory experience, rapid recognition tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Closer to prototype/exemplar accounts in grounding similarity, differing by emphasizing modality-specific perceptual encodings vs. abstract summaries or stored instances.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Activate perceptual schemata or episodes as proxies for category membership; categorization proceeds via matching to active perceptual proxies.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How non-perceptual and abstract conceptual content is represented and integrated with perceptual proxies; how proxytypes support compositional semantics.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5203.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5203.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Atomic/symbolic symbols</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Unstructured atomic symbols (Fodor)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are atomic, language-like symbols with syntactic/semantic roles; representational format is symbol-based rather than structured feature clusters or exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Concepts: A potboiler</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Atomic/symbolic representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functionally, concepts are discrete, unstructured symbols (atoms) that serve as syntactic elements in thought and inference; composition and inference operate over these symbolic tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>symbolic / atomic tokens</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Compositionality (via symbolic combination), language-like syntax, discrete individuation, supports rule-governed inference but lacks internal structured content.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Theoretical strengths for explaining compositional productivity and systematicity of thought; used in symbolic models of reasoning and language-related tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Difficulty accounting for graded typicality, similarity effects, and many empirical patterns in categorization that suggest structured internal content rather than purely atomic symbols.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Deductive reasoning, symbolic inference, compositional semantics, language processing models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Offers strong compositional and syntactic explanations compared to prototype/exemplar accounts, but lacks straightforward mechanisms for graded similarity and typicality phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Operate as discrete tokens combined by syntactic rules; retrieval and inference via rule application over symbol tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How atomic symbols are linked to perception and graded similarity, how learning acquires atomic concepts, and how symbolic tokens map onto embodied/graded information.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5203.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5203.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Concept pluralism</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Concept pluralism (Weiskopf)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Multiple representational kinds (prototype, exemplar, theory-like) co-exist but share higher-order functional properties (inferential role, combinability, acquisition, memory operations), making 'concept' a meaningful super-kind.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The plurality of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Concept pluralism (CONCEPT_P)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functionally, distinct representational subkinds exist but all instantiate shared superordinate functional roles (logical/inferential form, combinatorial capacity, acquisition mechanisms, storage/retrieval), enabling unified explanations at a higher level.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>plural (prototype, exemplar, theory-like as subformats under a shared functional role)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Superordinate functional roles (inferential/combinatorial/storage/acquisition), allows heterogeneity at the lower level but unity at the functional-theoretic level, supports unifying explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Explains why diverse experimental phenomena (typicality, similarity-based categorization, causal reasoning) can be studied under one conceptual framework by appealing to common computational/functional roles.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Must show that the posited shared functional properties actually obtain across disparate representational formats; critics argue shared descriptions may be superficial and risk hiding explanatory differences.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization, meaning extraction, inferential reasoning — used to unify explananda across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Offers a middle path between eliminativism and hybridism: unlike eliminativism it endorses a higher-level explanatory role for 'concept', unlike hybridism it doesn't require integrated single-token multi-aspect representations.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Postulates higher-order processes sensitive to shared inferential/combinatorial structures across subkinds (e.g., general inferential operators, acquisition routines, memory linking processes).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to operationalize and empirically validate the claimed superordinate functional properties; whether pluralism is explanatorily distinct from hybrid/integrative accounts.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5203.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5203.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Concept eliminativism</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Concept eliminativism (Machery)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The term 'concept' should be eliminated because cognitive science posits multiple representational kinds (prototype, exemplar, theory-like) that do non-overlapping explanatory work; a single kind 'concept' is redundant.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Doing without concepts</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Concept eliminativism (CONCEPT_E)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>At functional level, there is no single superordinate representational format; instead, multiple distinct formats each explain specific cognitive tasks, so 'concept' as a unified explanans is eliminated.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>plural but non-unified (distinct prototype/exemplar/theory-like kinds treated as independent)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Modularity of representational kinds, task- or domain-specific explanatory formats, lack of a unifying functional property across formats.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Draws support from empirical diversity: different experiments and tasks best explained by different representational formats (prototype effects, exemplar effects, theory-driven reasoning), suggesting non-unity.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Evidence for cross-format integration, co-activation or switching that suggests a unified representational token (chronometric coactivation data, hybrid-model fits) challenge pure eliminativism.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Used to interpret domain-specific findings in categorization, reasoning, and meaning extraction as evidence for distinct sub-systems rather than one concept kind.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasts with pluralism (which admits a unifying functional role) and hybridism (which posits integrated tokens); eliminativism denies higher-level unity.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Different modules or representational systems operate independently depending on task demands; explanations are given at level of specific representational formats rather than a 'concept' super-kind.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to account for tasks that appear to require integration across formats (e.g., concept combination, rapid switching without cost), and how to adjudicate when apparent integrative phenomena are genuine or epiphenomenal.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5203.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e5203.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Concept hybridism</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Concept hybridism / integrated representations (Vicente & Martínez Manrique)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Individual concept tokens are richly structured and can simultaneously contain prototype-like, exemplar-like, and theory-like information, which can be functionally co-activated or selectively used depending on context.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The big concepts paper: A defence of hybridism</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Concept hybridism (CONCEPT_H)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functionally, each token concept is an integrated representation composed of multiple kinds of information (prototypical features, stored exemplars, causal/theoretical structure); cognitive processing involves selecting, weighting, or co-activating these parts.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>integrated / multi-aspect representations combining prototype, exemplar, and theory-like parts</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Multi-aspect composition, functional integration/co-activation, context-sensitive selection/weighting, can account for both graded and inferential phenomena within single tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Accounts for mixed empirical patterns (e.g., typicality effects and causal inferences in the same judgement); hybrid or integrated models of categorization (Erickson & Kruschke; Anderson & Betz) fit data showing interplay between rule-like and exemplar processes.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Empirical difficulty in distinguishing integrated-token explanations from fast switching between independent systems; requires evidence of simultaneous activation or binding across representational types (chronometry, neurocognitive signatures).</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization (explaining typicality and rule-based choices), meaning extraction, concept combination, context-dependent inference.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Combines strengths of prototype, exemplar, and theory-theory accounts; differs from pluralism in positing token-level integration rather than only shared functional roles, and differs from eliminativism by positing unity at token level.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Single concept tokens include multiple representational subcomponents which can be co-activated; task/context signals determine which subcomponents drive behavior (selection, weighting, binding mechanisms).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How exactly parts are integrated and accessed in processing, how integration is learned, and whether observed behavioral data truly require token-integration vs. rapid coordination between distinct systems.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5203.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e5203.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hybrid/hybrid computational models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hybrid models of categorization (Anderson & Betz; Erickson & Kruschke)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Computational models that combine exemplar-like mechanisms with rule/prototype components to account for mixed empirical patterns in categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A hybrid model of categorization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Hybrid computational categorization models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functionally, these models implement multiple mechanisms (e.g., exemplar retrieval plus rule abstraction or prototype matching) that can be weighted or switched to explain a range of categorization behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>mixed: exemplar + prototype/rule components (computational hybrid)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Mechanistic combination of storage-based and rule/summary-based processes, flexible weighting/switching, can capture both exceptions and generalizations.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Model fits showing superior fits to categorization data that display both exemplar and rule-like patterns; empirical studies demonstrating situations where hybrid models predict behavior better than pure exemplar or pure prototype models.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Model complexity and identifiability issues (different parameterizations can mimic others), and debates whether hybrid behavior reflects unitary integrated tokens or multiple cooperating systems.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Category learning experiments, transfer and generalization tasks, mixed-evidence categorization datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Empirically intermediate between pure exemplar and pure prototype models; supports the empirical claim that multiple mechanisms underlie categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Parallel or competitive processes: exemplar similarity votes vs. abstracted rules/prototypes; arbitration mechanisms determine which process controls response on a trial.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How arbitration is implemented, whether hybrid fits reflect genuine psychological integration, and generalization to non-categorization conceptual tasks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5203.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e5203.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Typicality / prototype empirical findings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype / typicality effects (Rosch and related work)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical findings that members of a category vary in typicality and that prototypical items are processed faster and judged as better category members.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Natural categories</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Empirical typicality / prototype effects</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functional-level empirical pattern: graded category membership where more prototypical members are recognized and categorized faster and influence generalization more strongly.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>evidence for prototype/summary representations (but also compatible with exemplar accounts under some analyses)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Graded membership, reaction-time advantages for prototypical items, prototypicality predicts property generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Classic experimental results reported by Rosch and others showing typicality gradients, faster verification/categorization for prototypical items, and systematicity in feature distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Some results showing exemplar memory effects or rule-based behavior that prototype accounts alone cannot capture; overlap with exemplar and hybrid explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization tasks, property verification, similarity/typicality ratings.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Often cited as hallmark evidence for prototype theories; exemplar models can sometimes mimic patterns; hybrid models incorporate typicality as one component.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Typicality arises from central tendency of stored instances or from density in exemplar space; guides similarity-based matching and retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Whether typicality reflects prototype abstraction or exemplar distribution density, and how typicality interacts with causal/theory-based inference.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5203.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e5203.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar/categorization dissociations</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dissociation between categorization and similarity judgement (Ahn & Dennis)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical findings showing that categorization decisions sometimes diverge from simple similarity judgments, e.g., when causal status changes feature weighting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dissociation between categorization and similarity judgement: Differential effect of causal status on feature weights</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Categorization vs. similarity dissociation findings</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functionally, some categorization judgments are influenced by factors (causal status, feature diagnosticity) that do not align with raw perceptual similarity, indicating multiple determinants of conceptual judgments.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>evidence for contribution of causal/diagnostic information beyond pure exemplar similarity</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Feature weighting sensitive to causal/directional status, dissociation between similarity and category assignment, context-sensitive weighting.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Experimental manipulations where causal importance of features alters categorization independently of similarity metrics (Ahn & Kim; Ahn & Dennis).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Interpreting whether such dissociations require structured causal representations (theory-theory) or can be modeled by adjusted exemplar/prototype weighting.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization tasks with manipulated feature causal status and similarity judgments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Supports theory-like or hybrid accounts that include causal/diagnostic weighting; challenges pure similarity-only models unless they incorporate causal weighting.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Feature-weighted similarity computations where weights can be modulated by causal beliefs or learned diagnosticity.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How causal status is learned and represented functionally, and how it interacts with exemplar/prototype computations.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5203.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e5203.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Content effect (Wason)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Content effect in conditional reasoning (Wason Selection Task)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical finding that human conditional reasoning performance depends heavily on content: abstract formulations yield poor performance, content-rich (social rule) formulations yield much better performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Reasoning about a rule</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Content effect in conditional reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functionally, the ability to reason with conditionals is modulated by content-sensitive mechanisms (e.g., domain-specific reasoning modules or pragmatic/contextual knowledge) rather than by a single abstract logical operator representation.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>evidence for content-sensitive / domain-tuned representational formats for reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Context-dependence, domain specificity, variability in performance based on content familiarity or social framing.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Wason selection task experiments showing large differences in accuracy between abstract and concrete/social rule versions (Wason & Shapiro).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Debate whether content effects reflect domain-specific modules versus pragmatics/strategy differences; whether representational format is specialized or uses general mechanisms tuned by experience.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Conditional reasoning, social norms reasoning, logic tasks with varied content.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Used as evidence against purely formal-symbolic accounts of reasoning and in favor of content-sensitive or hybrid accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Task/context triggers retrieval of domain-specific schemas or heuristics that guide selection and evaluation of evidence rather than pure formal logical operators.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Whether content effects imply distinct representational formats or flexible application of general mechanisms; how such domain-sensitivity is implemented.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5203.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e5203.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chronometric switching / coactivation evidence</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chronometric task-switching and coactivation evidence (general literature cited)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Timing data (reaction-time/chronometry) used to test whether different pieces of conceptual information (prototype vs theory-like) are coactivated within a single token or require costly switching between separate systems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Chronometric evidence for coactivation vs switching</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functionally, task reaction times inform whether conceptual pieces are simultaneously available (fast/no-switch cost) or require sequential activation (switch costs), bearing on whether representations are integrated or modular.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>method for adjudicating integrated token vs multiple-systems representations (applies across prototype/exemplar/theory distinctions)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Measures processing latency, switch-costs, task-dependent availability of information, context-sensitivity.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>If minimal switch costs are observed when tasks require different representational aspects, this supports integrated token/hybrid accounts; conversely, reliable switch costs support modular/eliminativist accounts (discussion in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Ambiguity in interpreting null switch-costs (could be due to parallel processes, priming, or task strategies); lack of direct canonical chronometric paradigms fully decisive for representational format.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Task-switching paradigms, categorization tasks requiring different information types, reaction-time studies of meaning extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Proposed as empirical test between eliminativist (expect switch costs if separate systems) and hybridist (expect low switch costs if integrated) accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Use latency and switch-cost patterns to infer whether a single representation supplies multiple information types or multiple representations must be sequentially accessed.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Empirical design challenges, alternative process explanations for timing data, and difficulty isolating representational format from control and retrieval processes.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5203.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e5203.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Working memory capacity findings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Working memory capacity and architecture (Miller; Baddeley)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Findings about limitations and subcomponents of working memory (e.g., 7±2 chunks; articulatory loop ~2s) which influence how conceptual representations can be stored and processed.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The magical number seven, plus or minus two: Some limits on our capacity for processing information</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Working memory capacity findings</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functionally relevant constraints from working memory research (capacity and subsystem structure) inform how many items or how much information can be actively represented and combined during conceptual tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>constraints on short-term storage and manipulation of representational formats (applies to prototypes, exemplars, symbolic tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Limited capacity, time-limited traces (phonological loop), possible chunking, subsystem differentiation supporting different representational contents.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Classic capacity estimates (Miller) and multi-component model evidence (Baddeley) showing constraints that shape how information is encoded, retrieved, and combined.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Debate over exact capacity metrics, unit of chunking, and how working memory constraints map onto long-term conceptual representational formats.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Any task requiring online combination or retrieval of multiple conceptual elements (reasoning, complex categorization, language comprehension).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provides task-processing constraints that any model of conceptual representation must respect; not a representational theory itself but relevant for functional implementations.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Limits on active maintenance and processing (temporal and capacity constraints) affect which representational subcomponents can be used simultaneously.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How working memory mechanisms interact with long-term representational formats (prototype/exemplar/theory/hybrid) during complex cognitive tasks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5203.14">
                <h3 class="extraction-instance">Extracted Data Instance 14 (e5203.14)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Causal-model theory of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal-model theory of conceptual representation and categorization (Rehder)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A model proposing that concepts are organized as causal models which guide categorization and property induction by representing causal relations among features.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A causal-model theory of conceptual representation and categorization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Causal-model theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functionally, concepts include causal-model structure that encodes relations among features; categorization and induction depend on causal relevance and mediated inference rather than raw similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>structured causal-model representations</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Explicit causal relations, feature diagnosticity determined by causal role, supports causal-based induction and explanation.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Accounts for cases where causal relations determine category membership or property projection better than similarity-based metrics; experimental work showing causal knowledge influences categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Integration with perceptual similarity effects and cases where causal information is absent; learning of causal structure can be resource-demanding.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Causal induction, categorization when causal relations are relevant, property projection tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Shares features with theory-theory accounts but formalizes causal relations explicitly; contrasts with exemplar/prototype models focused on similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Use causal links to weight features and predict properties; inference performed by traversing causal structure to project properties.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How causal structures are acquired from noisy data and how they coexist or compete with similarity-based representations in real-time tasks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Natural categories <em>(Rating: 2)</em></li>
                <li>Exemplar-based accounts of relations between classification, recognition, and typicality <em>(Rating: 2)</em></li>
                <li>Conceptual change in childhood <em>(Rating: 2)</em></li>
                <li>Furnishing the mind: Concepts and their perceptual basis <em>(Rating: 2)</em></li>
                <li>Concepts: A potboiler <em>(Rating: 2)</em></li>
                <li>The plurality of concepts <em>(Rating: 2)</em></li>
                <li>Doing without concepts <em>(Rating: 2)</em></li>
                <li>The big concepts paper: A defence of hybridism <em>(Rating: 2)</em></li>
                <li>A hybrid model of categorization <em>(Rating: 2)</em></li>
                <li>Rules and exemplars in category learning <em>(Rating: 1)</em></li>
                <li>A causal-model theory of conceptual representation and categorization <em>(Rating: 2)</em></li>
                <li>Dissociation between categorization and similarity judgement: Differential effect of causal status on feature weights <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5203",
    "paper_id": "paper-198138287",
    "extraction_schema_id": "extraction-schema-109",
    "extracted_data": [
        {
            "name_short": "Prototype theory",
            "name_full": "Prototype theory (Rosch)",
            "brief_description": "Concepts are represented as prototypes — stored summaries of typical properties — and categorization is explained by correspondence between an item's properties and the prototype's typical features.",
            "citation_title": "Natural categories",
            "mention_or_use": "use",
            "theory_or_model_name": "Prototype theory",
            "theory_or_model_description": "At the functional level, conceptual knowledge is stored as a summary or averaged representation (a prototype) that encodes the typical/central features of a category; categorization is performed by comparing inputs to these prototypical summaries.",
            "representation_format_type": "prototype / summary representation (abstraction over exemplars)",
            "key_properties": "Abstraction (averaging over instances), graded membership (typicality), fast similarity-based matching, context-sensitivity via shifting typicality",
            "empirical_support": "Classic typicality and family-resemblance findings (Rosch-style): faster, more confident categorization for more prototypical items; typicality gradients across members; perceptual and categorization experiments showing prototype-consistent responses.",
            "empirical_challenges": "Cases where similarity-to-exemplars or rule/theory-based reasoning predicts behavior better (e.g., exemplar effects, causal or essence-based judgements), developmental evidence of shifts, and cases requiring explicit inferential structure not captured by prototypes.",
            "applied_domains_or_tasks": "Categorization, typicality judgments, some aspects of semantic memory and rapid classification tasks.",
            "comparison_to_other_models": "Contrasted with exemplar models (individual-matching) and theory-theory (causal/essentialist explanations); strengths in explaining typicality effects and parsimony, weaknesses in explaining rule-like inference and exceptions.",
            "functional_mechanisms": "Form prototypes by abstraction across instances; compute similarity between input and prototype to drive categorization; typicality influences recognition speed and confidence.",
            "limitations_or_open_questions": "How prototypes are formed from varied instances, how they support compositional or causal inference, and how to reconcile prototype effects with exemplar or theory-based effects in same tasks.",
            "uuid": "e5203.0"
        },
        {
            "name_short": "Exemplar model",
            "name_full": "Exemplar model (Nosofsky)",
            "brief_description": "Concepts are represented as collections of stored individual exemplars; categorization is performed by comparing new items to remembered exemplars and aggregating similarity.",
            "citation_title": "Exemplar-based accounts of relations between classification, recognition, and typicality",
            "mention_or_use": "use",
            "theory_or_model_name": "Exemplar model",
            "theory_or_model_description": "Functionally, conceptual representation consists of stored tokens of past examples; categorization is achieved by similarity-based retrieval of and vote/weighting over relevant exemplars rather than by comparing to an abstracted prototype.",
            "representation_format_type": "exemplar / instance-based representation",
            "key_properties": "Memory-based storage of instances, similarity-weighted retrieval, high flexibility for exceptions, sensitivity to frequency and recency, no single summary abstraction required.",
            "empirical_support": "Fits to categorization and recognition data showing effects of specific exemplars, ability to capture effects of distributional frequency and fine-grained similarity structure, dissociations between similarity judgments and categorization observed (Ahn & Dennis).",
            "empirical_challenges": "Scalability and parsimony concerns, difficulty accounting for fast generalization to novel exemplars or for abstract inferential patterns that look rule-like, and some developmental or causal reasoning findings better captured by theory-like representations.",
            "applied_domains_or_tasks": "Categorization, recognition memory, similarity-based judgments, exemplar transfer tasks.",
            "comparison_to_other_models": "Explains fine-grained similarities better than prototype models but may be less economical; contrasted with prototype (summary) and theory-theory (causal/structured) approaches.",
            "functional_mechanisms": "Store tokens of encountered exemplars; on categorization compute similarity of input to stored exemplars and aggregate similarity-weighted evidence to select category.",
            "limitations_or_open_questions": "How exemplar stores scale and get pruned/organized, how exemplar representations support composition or abstraction, and how exemplar and prototype influences combine in behavior.",
            "uuid": "e5203.1"
        },
        {
            "name_short": "Theory-theory",
            "name_full": "Theory-like structures / theory-theory (Carey; Rehder)",
            "brief_description": "Concepts include structured, causal/essence-like information (mini-theories) used for explanation, prediction, and some forms of categorization and inference.",
            "citation_title": "Conceptual change in childhood",
            "mention_or_use": "use",
            "theory_or_model_name": "Theory-theory / theory-like structures",
            "theory_or_model_description": "At the functional level, conceptual knowledge is represented as structured causal or explanatory frameworks ('theory-like' structures) that encode essences, causal relations and inferential roles, and are used for explanation-based generalization.",
            "representation_format_type": "theory-like / structured / causal-model representation",
            "key_properties": "Structured (parts and relations), causal/essential information, supports explanation and prediction, supports principle-based inference and sometimes hierarchical taxonomies.",
            "empirical_support": "Evidence from developmental conceptual change (Carey), causal-model accounts of categorization and concept use (Rehder), and tasks where causal/essence information governs category-based inference rather than surface similarity.",
            "empirical_challenges": "Difficulty explaining rapid typicality effects and similarity-driven categorization, and cases where participants rely on prototypes or exemplars rather than explicit causal structure.",
            "applied_domains_or_tasks": "Causal induction, explanation-driven categorization, conceptual development, inductive reasoning about kinds.",
            "comparison_to_other_models": "Captures inferential and explanatory aspects that prototypes/exemplars miss; often invoked where essence/causal information determines judgments, but weaker for immediate perceptual similarity phenomena.",
            "functional_mechanisms": "Maintain causal/essence knowledge that can be applied to infer properties of category members; explanation and prediction are driven by activating theory-relevant relations.",
            "limitations_or_open_questions": "How theory-like structures interface with fast, similarity-based processes; how they are acquired from experience; and how they are represented at a computational level alongside exemplar/prototype information.",
            "uuid": "e5203.2"
        },
        {
            "name_short": "Perceptual proxytypes",
            "name_full": "Perceptual proxytypes (Prinz)",
            "brief_description": "Concepts derive from perceptual representations ('proxytypes'): perceptual episodes or schemata that serve as the basis for conceptual content and categorization.",
            "citation_title": "Furnishing the mind: Concepts and their perceptual basis",
            "mention_or_use": "use",
            "theory_or_model_name": "Perceptual proxytypes",
            "theory_or_model_description": "Functionally, conceptual representations are grounded in perceptual representations that act as proxies; conceptual judgments draw on perceptual feature clusters and their activation patterns.",
            "representation_format_type": "perceptually grounded / proxy perceptual representations",
            "key_properties": "Perceptual grounding, modality-specific information, captures perceptually-driven categorization and typicality, links perception and conceptual content.",
            "empirical_support": "Evidence that perceptual features strongly influence categorization and typicality judgments; compatibility with findings that perceptual similarity predicts category membership in many tasks.",
            "empirical_challenges": "Struggles to account for abstract concepts or knowledge that is not easily tied to perceptual episodes; causal or theory-driven inferences may not be explained by purely perceptual bases.",
            "applied_domains_or_tasks": "Perceptually-driven categorization, concept acquisition from sensory experience, rapid recognition tasks.",
            "comparison_to_other_models": "Closer to prototype/exemplar accounts in grounding similarity, differing by emphasizing modality-specific perceptual encodings vs. abstract summaries or stored instances.",
            "functional_mechanisms": "Activate perceptual schemata or episodes as proxies for category membership; categorization proceeds via matching to active perceptual proxies.",
            "limitations_or_open_questions": "How non-perceptual and abstract conceptual content is represented and integrated with perceptual proxies; how proxytypes support compositional semantics.",
            "uuid": "e5203.3"
        },
        {
            "name_short": "Atomic/symbolic symbols",
            "name_full": "Unstructured atomic symbols (Fodor)",
            "brief_description": "Concepts are atomic, language-like symbols with syntactic/semantic roles; representational format is symbol-based rather than structured feature clusters or exemplars.",
            "citation_title": "Concepts: A potboiler",
            "mention_or_use": "use",
            "theory_or_model_name": "Atomic/symbolic representation",
            "theory_or_model_description": "Functionally, concepts are discrete, unstructured symbols (atoms) that serve as syntactic elements in thought and inference; composition and inference operate over these symbolic tokens.",
            "representation_format_type": "symbolic / atomic tokens",
            "key_properties": "Compositionality (via symbolic combination), language-like syntax, discrete individuation, supports rule-governed inference but lacks internal structured content.",
            "empirical_support": "Theoretical strengths for explaining compositional productivity and systematicity of thought; used in symbolic models of reasoning and language-related tasks.",
            "empirical_challenges": "Difficulty accounting for graded typicality, similarity effects, and many empirical patterns in categorization that suggest structured internal content rather than purely atomic symbols.",
            "applied_domains_or_tasks": "Deductive reasoning, symbolic inference, compositional semantics, language processing models.",
            "comparison_to_other_models": "Offers strong compositional and syntactic explanations compared to prototype/exemplar accounts, but lacks straightforward mechanisms for graded similarity and typicality phenomena.",
            "functional_mechanisms": "Operate as discrete tokens combined by syntactic rules; retrieval and inference via rule application over symbol tokens.",
            "limitations_or_open_questions": "How atomic symbols are linked to perception and graded similarity, how learning acquires atomic concepts, and how symbolic tokens map onto embodied/graded information.",
            "uuid": "e5203.4"
        },
        {
            "name_short": "Concept pluralism",
            "name_full": "Concept pluralism (Weiskopf)",
            "brief_description": "Multiple representational kinds (prototype, exemplar, theory-like) co-exist but share higher-order functional properties (inferential role, combinability, acquisition, memory operations), making 'concept' a meaningful super-kind.",
            "citation_title": "The plurality of concepts",
            "mention_or_use": "use",
            "theory_or_model_name": "Concept pluralism (CONCEPT_P)",
            "theory_or_model_description": "Functionally, distinct representational subkinds exist but all instantiate shared superordinate functional roles (logical/inferential form, combinatorial capacity, acquisition mechanisms, storage/retrieval), enabling unified explanations at a higher level.",
            "representation_format_type": "plural (prototype, exemplar, theory-like as subformats under a shared functional role)",
            "key_properties": "Superordinate functional roles (inferential/combinatorial/storage/acquisition), allows heterogeneity at the lower level but unity at the functional-theoretic level, supports unifying explanations.",
            "empirical_support": "Explains why diverse experimental phenomena (typicality, similarity-based categorization, causal reasoning) can be studied under one conceptual framework by appealing to common computational/functional roles.",
            "empirical_challenges": "Must show that the posited shared functional properties actually obtain across disparate representational formats; critics argue shared descriptions may be superficial and risk hiding explanatory differences.",
            "applied_domains_or_tasks": "Categorization, meaning extraction, inferential reasoning — used to unify explananda across tasks.",
            "comparison_to_other_models": "Offers a middle path between eliminativism and hybridism: unlike eliminativism it endorses a higher-level explanatory role for 'concept', unlike hybridism it doesn't require integrated single-token multi-aspect representations.",
            "functional_mechanisms": "Postulates higher-order processes sensitive to shared inferential/combinatorial structures across subkinds (e.g., general inferential operators, acquisition routines, memory linking processes).",
            "limitations_or_open_questions": "How to operationalize and empirically validate the claimed superordinate functional properties; whether pluralism is explanatorily distinct from hybrid/integrative accounts.",
            "uuid": "e5203.5"
        },
        {
            "name_short": "Concept eliminativism",
            "name_full": "Concept eliminativism (Machery)",
            "brief_description": "The term 'concept' should be eliminated because cognitive science posits multiple representational kinds (prototype, exemplar, theory-like) that do non-overlapping explanatory work; a single kind 'concept' is redundant.",
            "citation_title": "Doing without concepts",
            "mention_or_use": "use",
            "theory_or_model_name": "Concept eliminativism (CONCEPT_E)",
            "theory_or_model_description": "At functional level, there is no single superordinate representational format; instead, multiple distinct formats each explain specific cognitive tasks, so 'concept' as a unified explanans is eliminated.",
            "representation_format_type": "plural but non-unified (distinct prototype/exemplar/theory-like kinds treated as independent)",
            "key_properties": "Modularity of representational kinds, task- or domain-specific explanatory formats, lack of a unifying functional property across formats.",
            "empirical_support": "Draws support from empirical diversity: different experiments and tasks best explained by different representational formats (prototype effects, exemplar effects, theory-driven reasoning), suggesting non-unity.",
            "empirical_challenges": "Evidence for cross-format integration, co-activation or switching that suggests a unified representational token (chronometric coactivation data, hybrid-model fits) challenge pure eliminativism.",
            "applied_domains_or_tasks": "Used to interpret domain-specific findings in categorization, reasoning, and meaning extraction as evidence for distinct sub-systems rather than one concept kind.",
            "comparison_to_other_models": "Contrasts with pluralism (which admits a unifying functional role) and hybridism (which posits integrated tokens); eliminativism denies higher-level unity.",
            "functional_mechanisms": "Different modules or representational systems operate independently depending on task demands; explanations are given at level of specific representational formats rather than a 'concept' super-kind.",
            "limitations_or_open_questions": "How to account for tasks that appear to require integration across formats (e.g., concept combination, rapid switching without cost), and how to adjudicate when apparent integrative phenomena are genuine or epiphenomenal.",
            "uuid": "e5203.6"
        },
        {
            "name_short": "Concept hybridism",
            "name_full": "Concept hybridism / integrated representations (Vicente & Martínez Manrique)",
            "brief_description": "Individual concept tokens are richly structured and can simultaneously contain prototype-like, exemplar-like, and theory-like information, which can be functionally co-activated or selectively used depending on context.",
            "citation_title": "The big concepts paper: A defence of hybridism",
            "mention_or_use": "use",
            "theory_or_model_name": "Concept hybridism (CONCEPT_H)",
            "theory_or_model_description": "Functionally, each token concept is an integrated representation composed of multiple kinds of information (prototypical features, stored exemplars, causal/theoretical structure); cognitive processing involves selecting, weighting, or co-activating these parts.",
            "representation_format_type": "integrated / multi-aspect representations combining prototype, exemplar, and theory-like parts",
            "key_properties": "Multi-aspect composition, functional integration/co-activation, context-sensitive selection/weighting, can account for both graded and inferential phenomena within single tokens.",
            "empirical_support": "Accounts for mixed empirical patterns (e.g., typicality effects and causal inferences in the same judgement); hybrid or integrated models of categorization (Erickson & Kruschke; Anderson & Betz) fit data showing interplay between rule-like and exemplar processes.",
            "empirical_challenges": "Empirical difficulty in distinguishing integrated-token explanations from fast switching between independent systems; requires evidence of simultaneous activation or binding across representational types (chronometry, neurocognitive signatures).",
            "applied_domains_or_tasks": "Categorization (explaining typicality and rule-based choices), meaning extraction, concept combination, context-dependent inference.",
            "comparison_to_other_models": "Combines strengths of prototype, exemplar, and theory-theory accounts; differs from pluralism in positing token-level integration rather than only shared functional roles, and differs from eliminativism by positing unity at token level.",
            "functional_mechanisms": "Single concept tokens include multiple representational subcomponents which can be co-activated; task/context signals determine which subcomponents drive behavior (selection, weighting, binding mechanisms).",
            "limitations_or_open_questions": "How exactly parts are integrated and accessed in processing, how integration is learned, and whether observed behavioral data truly require token-integration vs. rapid coordination between distinct systems.",
            "uuid": "e5203.7"
        },
        {
            "name_short": "Hybrid/hybrid computational models",
            "name_full": "Hybrid models of categorization (Anderson & Betz; Erickson & Kruschke)",
            "brief_description": "Computational models that combine exemplar-like mechanisms with rule/prototype components to account for mixed empirical patterns in categorization.",
            "citation_title": "A hybrid model of categorization",
            "mention_or_use": "use",
            "theory_or_model_name": "Hybrid computational categorization models",
            "theory_or_model_description": "Functionally, these models implement multiple mechanisms (e.g., exemplar retrieval plus rule abstraction or prototype matching) that can be weighted or switched to explain a range of categorization behaviors.",
            "representation_format_type": "mixed: exemplar + prototype/rule components (computational hybrid)",
            "key_properties": "Mechanistic combination of storage-based and rule/summary-based processes, flexible weighting/switching, can capture both exceptions and generalizations.",
            "empirical_support": "Model fits showing superior fits to categorization data that display both exemplar and rule-like patterns; empirical studies demonstrating situations where hybrid models predict behavior better than pure exemplar or pure prototype models.",
            "empirical_challenges": "Model complexity and identifiability issues (different parameterizations can mimic others), and debates whether hybrid behavior reflects unitary integrated tokens or multiple cooperating systems.",
            "applied_domains_or_tasks": "Category learning experiments, transfer and generalization tasks, mixed-evidence categorization datasets.",
            "comparison_to_other_models": "Empirically intermediate between pure exemplar and pure prototype models; supports the empirical claim that multiple mechanisms underlie categorization.",
            "functional_mechanisms": "Parallel or competitive processes: exemplar similarity votes vs. abstracted rules/prototypes; arbitration mechanisms determine which process controls response on a trial.",
            "limitations_or_open_questions": "How arbitration is implemented, whether hybrid fits reflect genuine psychological integration, and generalization to non-categorization conceptual tasks.",
            "uuid": "e5203.8"
        },
        {
            "name_short": "Typicality / prototype empirical findings",
            "name_full": "Prototype / typicality effects (Rosch and related work)",
            "brief_description": "Empirical findings that members of a category vary in typicality and that prototypical items are processed faster and judged as better category members.",
            "citation_title": "Natural categories",
            "mention_or_use": "use",
            "theory_or_model_name": "Empirical typicality / prototype effects",
            "theory_or_model_description": "Functional-level empirical pattern: graded category membership where more prototypical members are recognized and categorized faster and influence generalization more strongly.",
            "representation_format_type": "evidence for prototype/summary representations (but also compatible with exemplar accounts under some analyses)",
            "key_properties": "Graded membership, reaction-time advantages for prototypical items, prototypicality predicts property generalization.",
            "empirical_support": "Classic experimental results reported by Rosch and others showing typicality gradients, faster verification/categorization for prototypical items, and systematicity in feature distributions.",
            "empirical_challenges": "Some results showing exemplar memory effects or rule-based behavior that prototype accounts alone cannot capture; overlap with exemplar and hybrid explanations.",
            "applied_domains_or_tasks": "Categorization tasks, property verification, similarity/typicality ratings.",
            "comparison_to_other_models": "Often cited as hallmark evidence for prototype theories; exemplar models can sometimes mimic patterns; hybrid models incorporate typicality as one component.",
            "functional_mechanisms": "Typicality arises from central tendency of stored instances or from density in exemplar space; guides similarity-based matching and retrieval.",
            "limitations_or_open_questions": "Whether typicality reflects prototype abstraction or exemplar distribution density, and how typicality interacts with causal/theory-based inference.",
            "uuid": "e5203.9"
        },
        {
            "name_short": "Exemplar/categorization dissociations",
            "name_full": "Dissociation between categorization and similarity judgement (Ahn & Dennis)",
            "brief_description": "Empirical findings showing that categorization decisions sometimes diverge from simple similarity judgments, e.g., when causal status changes feature weighting.",
            "citation_title": "Dissociation between categorization and similarity judgement: Differential effect of causal status on feature weights",
            "mention_or_use": "use",
            "theory_or_model_name": "Categorization vs. similarity dissociation findings",
            "theory_or_model_description": "Functionally, some categorization judgments are influenced by factors (causal status, feature diagnosticity) that do not align with raw perceptual similarity, indicating multiple determinants of conceptual judgments.",
            "representation_format_type": "evidence for contribution of causal/diagnostic information beyond pure exemplar similarity",
            "key_properties": "Feature weighting sensitive to causal/directional status, dissociation between similarity and category assignment, context-sensitive weighting.",
            "empirical_support": "Experimental manipulations where causal importance of features alters categorization independently of similarity metrics (Ahn & Kim; Ahn & Dennis).",
            "empirical_challenges": "Interpreting whether such dissociations require structured causal representations (theory-theory) or can be modeled by adjusted exemplar/prototype weighting.",
            "applied_domains_or_tasks": "Categorization tasks with manipulated feature causal status and similarity judgments.",
            "comparison_to_other_models": "Supports theory-like or hybrid accounts that include causal/diagnostic weighting; challenges pure similarity-only models unless they incorporate causal weighting.",
            "functional_mechanisms": "Feature-weighted similarity computations where weights can be modulated by causal beliefs or learned diagnosticity.",
            "limitations_or_open_questions": "How causal status is learned and represented functionally, and how it interacts with exemplar/prototype computations.",
            "uuid": "e5203.10"
        },
        {
            "name_short": "Content effect (Wason)",
            "name_full": "Content effect in conditional reasoning (Wason Selection Task)",
            "brief_description": "Empirical finding that human conditional reasoning performance depends heavily on content: abstract formulations yield poor performance, content-rich (social rule) formulations yield much better performance.",
            "citation_title": "Reasoning about a rule",
            "mention_or_use": "use",
            "theory_or_model_name": "Content effect in conditional reasoning",
            "theory_or_model_description": "Functionally, the ability to reason with conditionals is modulated by content-sensitive mechanisms (e.g., domain-specific reasoning modules or pragmatic/contextual knowledge) rather than by a single abstract logical operator representation.",
            "representation_format_type": "evidence for content-sensitive / domain-tuned representational formats for reasoning",
            "key_properties": "Context-dependence, domain specificity, variability in performance based on content familiarity or social framing.",
            "empirical_support": "Wason selection task experiments showing large differences in accuracy between abstract and concrete/social rule versions (Wason & Shapiro).",
            "empirical_challenges": "Debate whether content effects reflect domain-specific modules versus pragmatics/strategy differences; whether representational format is specialized or uses general mechanisms tuned by experience.",
            "applied_domains_or_tasks": "Conditional reasoning, social norms reasoning, logic tasks with varied content.",
            "comparison_to_other_models": "Used as evidence against purely formal-symbolic accounts of reasoning and in favor of content-sensitive or hybrid accounts.",
            "functional_mechanisms": "Task/context triggers retrieval of domain-specific schemas or heuristics that guide selection and evaluation of evidence rather than pure formal logical operators.",
            "limitations_or_open_questions": "Whether content effects imply distinct representational formats or flexible application of general mechanisms; how such domain-sensitivity is implemented.",
            "uuid": "e5203.11"
        },
        {
            "name_short": "Chronometric switching / coactivation evidence",
            "name_full": "Chronometric task-switching and coactivation evidence (general literature cited)",
            "brief_description": "Timing data (reaction-time/chronometry) used to test whether different pieces of conceptual information (prototype vs theory-like) are coactivated within a single token or require costly switching between separate systems.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_or_model_name": "Chronometric evidence for coactivation vs switching",
            "theory_or_model_description": "Functionally, task reaction times inform whether conceptual pieces are simultaneously available (fast/no-switch cost) or require sequential activation (switch costs), bearing on whether representations are integrated or modular.",
            "representation_format_type": "method for adjudicating integrated token vs multiple-systems representations (applies across prototype/exemplar/theory distinctions)",
            "key_properties": "Measures processing latency, switch-costs, task-dependent availability of information, context-sensitivity.",
            "empirical_support": "If minimal switch costs are observed when tasks require different representational aspects, this supports integrated token/hybrid accounts; conversely, reliable switch costs support modular/eliminativist accounts (discussion in paper).",
            "empirical_challenges": "Ambiguity in interpreting null switch-costs (could be due to parallel processes, priming, or task strategies); lack of direct canonical chronometric paradigms fully decisive for representational format.",
            "applied_domains_or_tasks": "Task-switching paradigms, categorization tasks requiring different information types, reaction-time studies of meaning extraction.",
            "comparison_to_other_models": "Proposed as empirical test between eliminativist (expect switch costs if separate systems) and hybridist (expect low switch costs if integrated) accounts.",
            "functional_mechanisms": "Use latency and switch-cost patterns to infer whether a single representation supplies multiple information types or multiple representations must be sequentially accessed.",
            "limitations_or_open_questions": "Empirical design challenges, alternative process explanations for timing data, and difficulty isolating representational format from control and retrieval processes.",
            "uuid": "e5203.12"
        },
        {
            "name_short": "Working memory capacity findings",
            "name_full": "Working memory capacity and architecture (Miller; Baddeley)",
            "brief_description": "Findings about limitations and subcomponents of working memory (e.g., 7±2 chunks; articulatory loop ~2s) which influence how conceptual representations can be stored and processed.",
            "citation_title": "The magical number seven, plus or minus two: Some limits on our capacity for processing information",
            "mention_or_use": "use",
            "theory_or_model_name": "Working memory capacity findings",
            "theory_or_model_description": "Functionally relevant constraints from working memory research (capacity and subsystem structure) inform how many items or how much information can be actively represented and combined during conceptual tasks.",
            "representation_format_type": "constraints on short-term storage and manipulation of representational formats (applies to prototypes, exemplars, symbolic tokens)",
            "key_properties": "Limited capacity, time-limited traces (phonological loop), possible chunking, subsystem differentiation supporting different representational contents.",
            "empirical_support": "Classic capacity estimates (Miller) and multi-component model evidence (Baddeley) showing constraints that shape how information is encoded, retrieved, and combined.",
            "empirical_challenges": "Debate over exact capacity metrics, unit of chunking, and how working memory constraints map onto long-term conceptual representational formats.",
            "applied_domains_or_tasks": "Any task requiring online combination or retrieval of multiple conceptual elements (reasoning, complex categorization, language comprehension).",
            "comparison_to_other_models": "Provides task-processing constraints that any model of conceptual representation must respect; not a representational theory itself but relevant for functional implementations.",
            "functional_mechanisms": "Limits on active maintenance and processing (temporal and capacity constraints) affect which representational subcomponents can be used simultaneously.",
            "limitations_or_open_questions": "How working memory mechanisms interact with long-term representational formats (prototype/exemplar/theory/hybrid) during complex cognitive tasks.",
            "uuid": "e5203.13"
        },
        {
            "name_short": "Causal-model theory of concepts",
            "name_full": "Causal-model theory of conceptual representation and categorization (Rehder)",
            "brief_description": "A model proposing that concepts are organized as causal models which guide categorization and property induction by representing causal relations among features.",
            "citation_title": "A causal-model theory of conceptual representation and categorization",
            "mention_or_use": "mention",
            "theory_or_model_name": "Causal-model theory",
            "theory_or_model_description": "Functionally, concepts include causal-model structure that encodes relations among features; categorization and induction depend on causal relevance and mediated inference rather than raw similarity.",
            "representation_format_type": "structured causal-model representations",
            "key_properties": "Explicit causal relations, feature diagnosticity determined by causal role, supports causal-based induction and explanation.",
            "empirical_support": "Accounts for cases where causal relations determine category membership or property projection better than similarity-based metrics; experimental work showing causal knowledge influences categorization.",
            "empirical_challenges": "Integration with perceptual similarity effects and cases where causal information is absent; learning of causal structure can be resource-demanding.",
            "applied_domains_or_tasks": "Causal induction, categorization when causal relations are relevant, property projection tasks.",
            "comparison_to_other_models": "Shares features with theory-theory accounts but formalizes causal relations explicitly; contrasts with exemplar/prototype models focused on similarity.",
            "functional_mechanisms": "Use causal links to weight features and predict properties; inference performed by traversing causal structure to project properties.",
            "limitations_or_open_questions": "How causal structures are acquired from noisy data and how they coexist or compete with similarity-based representations in real-time tasks.",
            "uuid": "e5203.14"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Natural categories",
            "rating": 2,
            "sanitized_title": "natural_categories"
        },
        {
            "paper_title": "Exemplar-based accounts of relations between classification, recognition, and typicality",
            "rating": 2,
            "sanitized_title": "exemplarbased_accounts_of_relations_between_classification_recognition_and_typicality"
        },
        {
            "paper_title": "Conceptual change in childhood",
            "rating": 2,
            "sanitized_title": "conceptual_change_in_childhood"
        },
        {
            "paper_title": "Furnishing the mind: Concepts and their perceptual basis",
            "rating": 2,
            "sanitized_title": "furnishing_the_mind_concepts_and_their_perceptual_basis"
        },
        {
            "paper_title": "Concepts: A potboiler",
            "rating": 2,
            "sanitized_title": "concepts_a_potboiler"
        },
        {
            "paper_title": "The plurality of concepts",
            "rating": 2,
            "sanitized_title": "the_plurality_of_concepts"
        },
        {
            "paper_title": "Doing without concepts",
            "rating": 2,
            "sanitized_title": "doing_without_concepts"
        },
        {
            "paper_title": "The big concepts paper: A defence of hybridism",
            "rating": 2,
            "sanitized_title": "the_big_concepts_paper_a_defence_of_hybridism"
        },
        {
            "paper_title": "A hybrid model of categorization",
            "rating": 2,
            "sanitized_title": "a_hybrid_model_of_categorization"
        },
        {
            "paper_title": "Rules and exemplars in category learning",
            "rating": 1,
            "sanitized_title": "rules_and_exemplars_in_category_learning"
        },
        {
            "paper_title": "A causal-model theory of conceptual representation and categorization",
            "rating": 2,
            "sanitized_title": "a_causalmodel_theory_of_conceptual_representation_and_categorization"
        },
        {
            "paper_title": "Dissociation between categorization and similarity judgement: Differential effect of causal status on feature weights",
            "rating": 2,
            "sanitized_title": "dissociation_between_categorization_and_similarity_judgement_differential_effect_of_causal_status_on_feature_weights"
        }
    ],
    "cost": 0.02213475,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Kent Academic Repository Full text document (pdf) Versions of research Citation for published version Link to record in KAR The Explanatory Role of Concepts</p>
<p>Samuel D Taylor sam.taylor@hhu.de 
Department of Philosophy
Heinrich-Heine-University Düsseldorf
Universitätsstraße 140225DüsseldorfGermany</p>
<p>· Gottfried Vosgerau 
Department of Philosophy
Heinrich-Heine-University Düsseldorf
Universitätsstraße 140225DüsseldorfGermany</p>
<p>Samuel D Taylor samuel.da.taylor@gmail.com 
Department of Philosophy
Heinrich-Heine-University Düsseldorf
Universitätsstraße 140225DüsseldorfGermany</p>
<p>Vosgerau Vosgerau@hhu Gottfried 
Department of Philosophy
Heinrich-Heine-University Düsseldorf
Universitätsstraße 140225DüsseldorfGermany</p>
<p>De 
Department of Philosophy
Heinrich-Heine-University Düsseldorf
Universitätsstraße 140225DüsseldorfGermany</p>
<p>S D Taylor 
Department of Philosophy
Heinrich-Heine-University Düsseldorf
Universitätsstraße 140225DüsseldorfGermany</p>
<p>G Vosgerau 
Department of Philosophy
Heinrich-Heine-University Düsseldorf
Universitätsstraße 140225DüsseldorfGermany</p>
<p>Kent Academic Repository Full text document (pdf) Versions of research Citation for published version Link to record in KAR The Explanatory Role of Concepts
10.1007/s10670-019-00143-0Received: 6 August 2018 / Accepted: 17 June 2019The version in the Kent Academic Repository may differ from the final published version. Users are advised to check http://kar.kent.ac.uk for the status of the paper. Users should always cite the published version of record. Enquiries For any further enquiries regarding the licence status of this document, please contact: researchsupport@kent.ac.uk If you believe this document infringes copyright then please contact the KAR admin team with the take-down information provided at http://kar.kent.ac.uk/contact.html Taylor, Samuel D. and Vosgerau, Gottfried (2019) The explanatory role of concepts. Erkenntnis . ISSN 0165-0106. https://kar.kent.ac.uk/83123/ Document Version Publisher pdf Vol.:(0123456789) Erkenntnis 1 3 ORIGINAL RESEARCH
Machery (Doing without concepts, Oxford University Press, New York, 2009) and Weiskopf (Synthese 169:145-173, 2009) argue that the kind concept is a natural kind if and only if it plays an explanatory role in cognitive scientific explanations. In this paper, we argue against this explanationist approach to determining the natural kind-hood of concept. We first demonstrate that hybrid, pluralist, and eliminativist theories of concepts afford the kind concept different explanatory roles. Then, we argue that we cannot decide between hybrid, pluralist, and eliminativist theories of concepts, because each endorses a different, but equally viable, specification of the explananda of cognitive science. It follows that an explanationist approach to determining the natural kind-hood of concept fails, because there is no consensus about whether or not concept should be afforded an explanatory role in our best cognitive scientific explanations. We conclude by considering what our critique of explanationism could imply for further discussions about the explanatory role of concepts in cognitive science.</p>
<p>The Explanatory Challenge to concept</p>
<p>According to the "received view," all concepts have a number of properties in common: they all store a single kind of information, they all have the same functional properties, and they are all acquired by the same type of learning process, etc. (Machery and Seppälä 2011, p. 99). On this view, a theory of concepts aims to describe these properties and so to account for the formation and application of concepts. Moreover, from the perspective of the received view, concepts are of one kind-the kind concept-and they "explain the properties of our higher cognitive competences"; that is, the properties of higher cognition that are operative in 1 3 cognitive tasks such as categorisation, meaning extraction, and inductive and deductive reasoning (Machery and Seppälä 2011, p. 99). 1 In recent years, however, psychologists have identified several distinct types of categorisation judgements, several distinct operations of meaning extraction, and several distinct episodes of inductive/deductive reasoning, and so have been forced to posit a number of different representational kinds, with incommensurable properties, to do the required explanatory work. For example, prototypes (Rosch 1973;Lakoff 1987), bundles of exemplars (Nosofsky 1988), theory-like structures (Carey 1985;Gopnik and Meltzoff 1997;Rehder 2003), perceptual 'proxytypes' (Prinz 2002), and unstructured atomic symbols (Fodor 1994) have all been posited to explain, say, categorisation and reasoning. As a result, it has been argued that the received view of concepts cannot be correct, because the explanatory work is not done by the single kind concept, but by a set of representational kinds that do not store the same kinds of information or have the same functional properties (Bloch-Mullins 2018).</p>
<p>To make the explanatory challenge to the received view concrete, consider explanations of categorisation judgements. In some cases, psychologists explain the categorisation of an individual c in a category C in terms of a correspondence between the properties of c and the typical properties of members of C. In cases such as these, psychologists posit the kind prototype to do the required explanatory work. However, in other cases psychologists explain the categorisation of an individual c in a category C in terms of a judgement that c is sufficiently similar to salient members of C. In cases such as these, psychologists posit the kind exemplar to do the required explanatory work. According to the explanatory challenge, because psychologists are required to posit different representational kinds with different properties and functions to explain these different types of categorisation judgements, the kind concept is redundant in explanations of categorisation. And because the received view of concept fails to predict this explanatory diversity it is argued that it cannot be correct (cf. Machery and Seppälä 2011, p. 99). 2 In this paper, we argue against one possible interpretation of the explanatory challenge: that the explanatory challenge demonstrates that concept is not a natural kind. This involves rejecting what we will call an explanationist approach for determining the natural kind-hood of concept, whereby concept is taken to be a natural kind iff concept features in a proposition best explaining some explananda of 1 In this paper, we denote kinds with small caps. 2 One quick and easy way to respond to the explanatory challenge to the received view is to argue that all posited representational kinds are of the super-kind concept in virtue of the fact that they are all constituents of thought. According to this response, all of the representational kinds posited to do explanatory work in cognitive science fall under the concept of concept in virtue of being conceptual in kind (Weiskopf 2009, pp. 147-148). Many philosophers have been quick to accept this view as part of their response to the explanatory challenge. However, even if one thinks that this response is broadly correct, this still leaves open a further question: what are the defining properties of the super-kind concept that make it the case that all representations doing explanatory work in cognitive science can be classified as concepts? Providing an answer to this question has proven to be controversial and remains the central issue of contention between competing theories of concepts that we discuss in sections three, four, and five below.</p>
<p>3</p>
<p>The Explanatory Role of Concepts cognitive science. For example, according to an explanationist approach for determining the natural kind-hood of concept, if concept features in a proposition best explaining some aspects of categorisation-e.g., 'categorisation judgements involve the comparison of some individual c with some concept C'-, then concept is a natural kind.</p>
<p>Our argument against this explanationist approach to determining the natural kind-hood of concept runs as follows. In Sect. 2, we introduce the explanationist approach to determining whether or not concept is a natural kind. In Sects. 3 and 4, we introduce eliminativist, pluralist, and hybrid theories of concepts, and demonstrate that they each endorse different views of the explanatory role concept in cognitive science. In Sect. 5, we argue that the reason that eliminativist, pluralist, and hybrid theories of concepts endorse different views of the explanatory role concept is because they endorse different specifications of the explananda of cognitive science. We defend this claim from possible objections in Sect. 6. Then, in Sect. 7, we argue that because the explananda of cognitive science cannot be pre-theoretically specified, we cannot decide between eliminativist, pluralist, and hybrid interpretations of the explanatory role of concept. It follows that an explanationist approach for determining the natural kind-hood of concept cannot be made to work. We conclude by considering what our critique of explanationism could imply for further discussions about the explanatory role of concepts in cognitive science.</p>
<p>Explanationism About concept</p>
<p>The debate about how best to determine the natural kind-hood of theoretical posits is long and convoluted. 3 However, one approach that has found favour in recent times has been an explanationist approach to natural kind-hood determination. Explanationism holds that "a person's evidence supports a proposition just in case that proposition is part of the best available explanation for the person's evidence" (Byerly 2013). In this way, explanationism dictates that one must assent to the truth of a proposition-say, 'water is H 2 O ' or 'electrons have an intrinsic angular momentum (spin) of 1 2 '-iff that proposition is part of the best available explanation for some relevant evidence-say, that water has a boiling point of 100 • or that paramagnetic substances (e.g., aluminium and oxygen) are weakly attracted to an applied magnetic field. Taken at the level of the truth-conditions alone, explanationism concerns only the validity of our beliefs and so appears to have nothing to say about the natural 3 Much of the debate about theoretical posits has focused on the issue of our epistemic commitment to the putative referents of theoretical terms. A number of formal representations of the semantics of theoretical terms have been developed, which aim to make explicit the role of such terms in scientific theories. Perhaps the most famous of these formal frameworks are Ramsey sentences, which introduce a division between the set V o of observational terms and the set V t of theoretical terms in a theory (Ketland 2004;Ramsey 1931). The framework of Ramsey sentences trades on the idea that theories are syntactic structures that can be parsed in terms of a language L(V o , V t ) . However, it is also possible to formally represent the role of theoretical terms on a semantic conception of theories, albeit then in terms of, e.g., partial structures or modal relations (cf. Suppes 1967Suppes , 2002Van Fraassen 1980). kind-hood of theoretical posits. However, the explanationist line of argument can be taken further in light of the notion that our best explanations are "the only workable criterion of reality" (Ellis 2001).</p>
<p>Explanationism can be seen as imposing a condition on the reality of any entity posited in scientific explanation, because our commitment to any posit x can be assessed in accordance with whether or not x features in a proposition that best explains some piece of evidence (Saatsi 2017). When tied to a broadly scientistic picture, this kind of explanationism proposes that we should be committed to all posits x that feature in propositions that best explain the evidence to be accounted for by science. So, on this view, we should be committed to the posits H 2 O and Electron, because H 2 O and Electron feature in at least one proposition that best explains some subset of the evidence to be accounted for by science. However, we should not be committed to the posit Witches , because Witches does not feature in any proposition that best explains any evidence to be accounted for by science. Thus, this application of explanationism holds that "something is real if its positing plays an indispensable role in the explanation of well-founded phenomena" (Psillos 2005, p. 398). In a slogan: some posit x exists iff taking x to exist helps us to formulate scientific explanations of something that would otherwise be puzzling (Suppes 2008, p. 16). 4 An explanationist approach to natural kind-hood determination purports to identify those posits that are the best candidates for the kinds that carve reality at its joints. So, by applying the explanationist approach to natural kind-hood determination, we expect to arrive at some principled demarcation of the kinds that are 'natural'-say, the kinds gold and electron-and the kinds that are not-say, phlogiston and griffin (Kitcher 1993). 5 The difficulty, however, is that in order to successfully apply the explanationist approach to natural kind-hood determination, we first have to specify the evidence that is to be explained. The question of how to specify the relevant 'evidential explananda' is the root cause of much philosophical wrangling about, for instance, the reduction of the special sciences to the fundamental sciences or the reality of abstract and/or fictional objects. But putting aside these large and cumbersome questions, one thing can be made clear: if we can agree that there are some evidential explananda to be explained by science, then it follows that an explanationist approach to natural kind-hood determination ought be able to sort out the 1 3</p>
<p>The Explanatory Role of Concepts natural from non-natural kinds according to which kinds are posited in explanatory propositions that best explain the evidential explananda. 6 Our concern in this paper is with the evidential explananda of cognitive science. We assume, therefore, that there is something for cognitive science to explain. In short, we hold that the evidential explananda of cognitive science is any evidential explananda that reveals the functioning and operation of cognition or the achievement or undertaking of cognitive competencies more generally. That is, we assume that the evidential explananda of cognitive science are any evidential explananda that concern the operations of the mind. With this proviso out of the way, we can apply the explanationist approach to natural kind-hood determination to the kinds commonly associated with cognitive science. For example, we can apply the explanationist approach to natural kind-hood determination to kinds such as representation, neuron, or module. What's more, we can apply the explanationist approach to natural kind-hood determination to perhaps the most prominent kind associated with cognitive science: the kind concept. An explanationist approach to determining the natural kind-hood of concept holds that the kind concept is a natural kind if and only if there is a proposition featuring concept that is part of the best available explanation for some relevant evidence to be explained by cognitive science. For example, if the proposition, 'concept's are constituents of thought,' is part of the best explanation of some relevant evidence to be explained by cognitive science, then we would be justified in supposing that concept is a natural kind. In this way, the explanationist approach to determining the natural kind-hood of concept indexes the natural kind-hood of concept to concept's explanatory role in cognitive science.</p>
<p>In recent debates about concepts, an explanationist approach to determining natural kind-hood of concept has come to fore. For example, both Machery (2009) and Weiskopf (2009) endorse an explanationist approach to determining the natural kindhood of concept, even if they have not phrased their views in exactly these terms. Weiskopf (2009, p. 147) argues that the kind concept-like all other kinds that are worthy of our interest-is to be understood as a "groupings of entities that participate in a body of empirically discovered reliable generalizations, and which participate in those generalizations due to some set of properties they have in common." Similarly, Machery (2009, p. 232) argues that a class C of entities-for instance, the class C that constitutes the kind concept-"is a natural kind if and only if there is a large set of scientifically relevant properties such that C is the maximal class whose members tend to share these properties because of some causal mechanism"; where "scientifically relevant" is to be read as saying that the C is a class about which many explanatory generalizations can be formulated (cf. Machery 2009, p. 232, for further discussion of Machery's "Scientific Eliminativism" about natural kinds). 7 In the remainder of this paper, we want to build the case against such an explanationist approach to determining natural kind-hood of concept.</p>
<p>Theories of concept</p>
<p>In the current literature about concepts, there is an ongoing discussion about how to conceive of the explanatory role of the kind concept given the explanatory challenge to the received view. In this section, we will use the notation of set theory to elucidate and compare the different theories of concept's explanatory role. Take concept eliminativism to start with (Machery 2009(Machery , 2010. For the eliminativist, there are potentially many different representations of one and the same thing. For example, for cats there could potentially be a cat-prototype representation, a cat-exemplar representation, and a cattheory-like-structure representation. Thus, there could be at least three different tokens of mental representations standing for cats; namely p CAT (the cat-prototype), e CAT (the cat-exemplar), and t CAT (the cat-theory-like-structure). The kind prototype, for instance, can then be described as the set of all prototype tokens, where the defining property of this set is the (complex) property P of being a prototype, whatever that might be in detail:</p>
<p>The eliminativist interpretation of the kind concept can then be construed in one of two ways: either as the set of all representational kinds with the defining property of figuring in scientific explanations of higher order cognitive capacities; or as the set of all representations with the complex property C E , where C E is no more than the exclusive disjunction of the different defining properties of the explanatorily valuable kinds. or The first set CONCEPT E 1 is simply the set that contains all the different representational kinds as sets, which are in our example the set of all prototypes, the set of all exemplars, and the set of all theory-like structures. The second set CONCEPT E 2 is the set that contains all tokens of the different representational kinds; so, it contains all prototypes (but not the set of all prototypes), all exemplars (but not the
PROTOTYPE = {x | P(x)} = {p CAT , p DOG , …} CONCEPT E 1 ={x | x figuring in scientific explanations} = ={{x 1 | P(x 1 )}, {x 2 | E(x 2 )}, {x 3 | T(x 3 )}} CONCEPT E 2 ={x | C E (x), where ∀y C E (y) ↔ (P(y) ∨ E(y) ∨ T(y)) } = ={p CAT , e CAT , t CAT , p DOG , e DOG , t DOG , …}
Footnote 7 (continued) have those properties" (Machery 2009, pp. 232-233). Moreover, following Boyd, Machery holds that a class constituting a natural kind cannot be a subset of a larger class about which the same generalisations could be formulated, because then the class in question could be subsumed by a larger-and, hence, more explanatory-class.</p>
<p>3</p>
<p>The Explanatory Role of Concepts set of all exemplars), and all theory-like structures (but not the set of all theorylike structures). P CAT is meant to stand for the cat-prototype, and the idea is that all such token prototypes are in CONCEPT E 2 as well as all token exemplars and all token theory-like structures. In both cases, CONCEPT E x cannot play an additional explanatory role in cognitive science: in the first case, because the defining property x is nothing more than a property of all the sets that play an explanatory role in cognitive science, and so does not play an explanatory role additional to the roles already played by its members. In the second case, because the complex property C E is no more than the exclusive disjunction of the different defining properties of the explanatorily valuable kinds and so does nothing to further explain cognitive capacities. It follows that eliminativism affords concept no explanatory role, because all of the explanatory work is done on the level of representational kinds like prototype, exemplar, and theory-like structure (Machery 2009(Machery , 2010. Now consider concept pluralism, which also assumes that there can be different kinds of representation for one thing, but that all explanatory representations have certain properties in common:</p>
<p>Concept pluralism reacts to the explanatory challenge by arguing that CONCEPT P does have an explanatory role, because the defining properties C P of CONCEPT P have an explanatory role that cannot be reduced to the explanatory roles of the properties P, E, and T. The defining properties C P of CONCEPT P are the functional properties of having (i) a logical form that allows for inferential processing; (ii) an ability to be combined; (iii) an ability to be acquired; and, finally, (iv) an ability to be stored, linked together, and retrieved by a set of memory processes (Weiskopf 2009, pp. 163-167). All of the representational kinds that are members of the set CONCEPT P are taken to possess these functional properties; i.e., the "superordinate functional roles" that all members of CONCEPT P share and that are the defining properties of CONCEPT P as a set.</p>
<p>According to Weiskopf (2009, p. 167):</p>
<p>the existence of a set of common overarching processes and generalizations indicates that these subkinds are a more coherent and systematic object of study than their differences might otherwise lead us to think.</p>
<p>Thus, concept pluralism takes the kind CONCEPT P to have a unifying explanatory role, because by positing CONCEPT P we are able to explain-by reference to "functionalist considerations"-how the representational kinds posited in cognitive scientific explanation "do not belong to autonomous, disjoint systems", but rather "constitute different aspects of the human conceptual system" (Weiskopf 2009, p. 170). 8 This unifying role, however, is not played by any of the defining properties P, E, or
CONCEPT P = x | C P (x) ∶ where ∀y (P(y) → C P (y)) ∧ (E(y) → C P (y)) ∧ (T(y) → C P (y)) = ={p CAT , e CAT , t CAT , p DOG , e DOG , t DOG , …}
T of the more fine-grained kinds of mental representations nor can it be reduced to them. Finally, consider concept hybridism. Concept hybridism concurs with concept pluralism that the kind concept has an explanatory role to play in cognitive science. However, hybridism doubts that prototype, exemplar, and theory-like structure constitute disjunctive kinds. Whereas eliminativism and pluralism assume that every mental representation falls into exactly one of the three categories, hybridism assumes that a single mental representation can fall into two or even three categories at the same time. Thus, the elements of CONCEPT H do not necessarily possess only one of the three properties P, E or T; they may possess all three at the same time. Accordingly, CONCEPT H is a set of "integrated representations" that have prototype-like, exemplar-like, and theory-like structure-like pieces of information as their parts. Thus, the elements of the set denoted by CONCEPT H are not taken to be the finer-grained representational kinds prototype, exemplar, and theory-like structure, but, rather, are taken to be richly structured representations that have the potential to encode all of the pieces of information ordinarily taken to be encoded by the disjoint set of representational kinds. In the case of hybridism, therefore, our example would read:</p>
<p>As Vicente and Martnez Manrique (2014, p. 61) put it: 9</p>
<p>In a nutshell, the idea [of concept hybridism] is that different structures can be regarded as constituting a common representation when they are activated concurrently, in a way that is functionally significant for the task at hand, and in patterns that remain substantially stable along different tasks related to the same category.</p>
<p>From the perspective of concept hybridism, the explanatory relevance of the kind concept cannot lie in an additional property that mental representations share. 10
CONCEPT H = {x | C H (x)} = {x CAT , x DOG , …} {x | P(x)}, {x | E(x)}, {x | T(x)} ⊆ CONCEPT H Footnote 8 (continued)
states that "For any category that can be conceptually represented, there is such a thing as the unique concept of that category"; and the uniformity assumption states that "All concepts belong to a single psychological kind." 9 Since some concepts might not have all different kinds of aspects, the set of, say, prototypes might be only a subset of the set of concepts. 10 Indeed, the defining property C H of CONCEPT H might be nothing but the disjunctive property of the properties of prototype, exemplar and theory-like-structure, such that ∀x(
C H (x) ↔ (P(x) ∨ E(x) ∨ T(x))) .
The decisive difference between CONCEPT H and CONCEPT E , therefore, is that the ∨ is to be understood as exclusive in the case of eliminativism, but as inclusive in the case of hybridism. Therefore, the two sets CONCEPT H and CONCEPT E contain very different elements. The first contains mental representations that have different functionally integrated aspects; namely, prototype-aspects, exemplar-aspects and theorylike structural aspects. The second contains prototypes, exemplars, and theory-like structures that have no common aspects. Moreover, the inclusive disjunction endorsed by concept hybridism makes it the case that while two elements of CONCEPT H need not share a single property, some may share two and some may share all three. For example, the concept electron might have only a theory-like structural aspect, while the concept dwarf might have only a prototype-aspect. However, it is likely that most representations that are the elements of CONCEPT H will have multiple aspects in common.</p>
<p>Rather, CONCEPT H is relevant to explanation because it makes transparent the interplay of different properties or aspects of individual mental representations in cognitive tasks according to patterns of functional integration. Thus, for the hybridist, it does not make sense to assume that prototype, exemplar and theory-like-structure are mutually exclusive kinds with no overlap. Instead, a single representational token is posited-as exhibited by the members of CONCEPT H -that possesses all of the different properties of the kinds prototype, exemplar, and theory-like-structure at once without enforcing an internal hierarchy. It follows as a matter of course that explanations in cognitive science need not be confined to one specific aspect, but can appeal to the different aspects that are functionally integrated in members of CONCEPT H . The explanatory role of CONCEPT H is to make this distinction clear.</p>
<p>Explanationism About CONCEPT E,P,H</p>
<p>In this section, we will consider explanationism about the natural kind-hood of concept in the light of the different theories of concept's explanatory role introduced above. Our purpose here is to show that the explanationist approach to determining the natural kind-hood of concept stalls, because there is no consensus about what explanatory role should be afforded to the kind concept.</p>
<p>Explanationism About CONCEPT E</p>
<p>According to our analysis, concept eliminativism can be read in one of two ways: either as taking the defining property x of CONCEPT E x to be the property of figuring in scientific explanations of higher order cognitive capacities ( CONCEPT E 1 ); or as taking the defining property C E of CONCEPT E x to be the property of being a set of different explanatorily valuable kinds with (potentially) distinct defining properties ( CONCEPT E 2 ). On either reading, however, concept eliminativism denies that CONCEPT E x has an explanatory role in cognitive science. From the perspective of the explanationist approach to determining the natural kind-hood of CONCEPT E x , therefore, the conclusion is clear: CONCEPT E x is not a natural kind.</p>
<p>To illustrate why this is the case, consider the weird set that contains electron, gene, and animal population as members. This set thus contains only kinds posited in scientific explanations:</p>
<p>In this toy-example, whilst it may be the case that all of the members of the set either have the property of figuring in scientific explanation or have some defining properties of their own, it does not follow that the set {ELECTRON, GENE, ANIMAL POPULATION} is itself explanatory. Analogously for concept eliminativism, whilst it may be the case that prototype, exemplar, theorylike structure all either have the property of figuring in scientific explanations {ELECTRON, GENE, ANIMAL POPULATION} 1 3 or have some defining properties of their own, it does not follow that the defining properties C E of the set of these representations-e.g., the set CONCEPT E x -is itself explanatory. This holds because prototype, exemplar, and theory-like structure are all taken to figure in non-overlapping scientific explanations of different cognitive processes, because their defining properties afford them different explanatory roles (cf. Machery 2009, p. 251). 11 The eliminativist, therefore, argues that the kind CONCEPT E x does not yield to scientific generalisations and so is redundant in cognitive science (cf. Machery 2009, Ch. 8). In other words, because we cannot form a proposition that both features CONCEPT E x and is apt to do explanatory work in cognitive science-e.g., 'all representations are a in virtue of being members of CONCEPT E x '-, the kind CONCEPT E x cannot be said to have an explanatory role in cognitive science.</p>
<p>Explanationism About CONCEPT P</p>
<p>In contrast to concept eliminativism, concept pluralism argues that the kind CONCEPT P does have an explanatory role to play in cognitive science, because the defining properties C P of CONCEPT P are apt for explaining aspects of higher cognition that cannot be explained by the defining properties of the members of CONCEPT P taken individually. Thus, from the perspective of an explanationist approach to determining the natural kind-hood of CONCEPT P the conclusion is once again clear: CONCEPT P is a natural kind because it has an explanatory role to play in cognitive science, albeit to answer to "top-level [explanatory] demands" that "tend to favor unification" (Weiskopf 2009, p. 167). 12 To make perspicuous why an explanationist approach to determining the natural kind-hood of concept will conclude that CONCEPT P is a natural kind, consider the explanatory role that CONCEPT P is afforded in virtue of possessing the defining, functional property (i): having a logical form that allows for inferential processing. According to concept pluralism, if it can be shown that all representational kinds that are member of CONCEPT P have an internal, logical structure, "then it is reasonable to suppose that there are mental processes that are sensitive to that structure, rather than to the particular concepts that are being combined in that structure" (Weiskopf 2009, p. 163). By then identifying formal inference processes that generalise over different representational kinds-e.g., the inference process that runs from 'dogs are mammals and canines' to 'dogs are mammals' and 'dogs are canines'-concept 1 3</p>
<p>The Explanatory Role of Concepts pluralists argue that the different representational kinds do, in fact, share the functional property of playing the same syntactic role in inferential thought.</p>
<p>Therefore, the explanatory import of CONCEPT P is justified by concept pluralists, because it is only by formulating propositions featuring CONCEPT P -e.g., 'all representations have the same inferential role in thought in virtue of being members of CONCEPT P '-that we can explain the inferential nature of thought in general, instead of having to formulate as many different explanations of inferential processing as there are representational kinds in the set CONCEPT P . The same reasoning applies to concept pluralism's discussion of the functional properties (ii), (iii), and (iv) above. For example, in the case of (iii), concept pluralism argues that modes of acquisition are not sensitive to representational subkinds, because the acquisition of different representational kinds can involve abstraction over experienced exemplars and can involve the use of language and other public representational media. Therefore, the explanatory import of CONCEPT P is that it makes possible the formulation of propositions-e.g., 'all representation are acquired in processes involving x, y, z in virtue of being members of CONCEPT P '-that explain the acquisition of mental states in general, instead of having to formulate as many different explanations of the acquisition of mental states as there are representational kinds in the set CONCEPT P . It follows that the kind CONCEPT P has a higher-order explanatory role in cognitive science.</p>
<p>Explanationism About CONCEPT H</p>
<p>Concept hybridists argue that their theory supports better-that is, more powerful-explanations of cognition, because we can explain efficiency and variability in cognitive tasks in terms of a switching between the different kinds of information encoded by members of the set CONCEPT H . This follows because the members of the set CONCEPT H are thought of as being "integrated concepts" instead of as representations belonging to only one representational kind P, E, or T. So, from the perspective of an explanationist approach to determining the natural kind-hood of CONCEPT H , the conclusion is yet again clear: CONCEPT H is a natural kind because it is only by formulating explanatory propositions in terms of integrated representations that we can give the best possible cognitive scientific explanations.</p>
<p>To make this idea explicit, consider the claim by concept hybridists that we fare better in explaining categorisation if we presuppose CONCEPT H and so posit integrated representation that have prototype-like, exemplar-like, and theory-like structure-like parts. According to the hybridist, we fare better in explaining categorisation because we can appeal to the interrelated and complementary functional roles played by the integrated parts of representations in CONCEPT H , depending on background factors and the task at hand (Vicente and Martnez Manrique 2014, p. 73). For instance, we can appeal to typicality effects associated with the prototype-like part to explain why a four-legged, barking object is categorised as a dog; but, equally, we can appeal to essences associated with the theory-like structure-like part to explain why we categorise 'Bobby' as a dog after hearing the sentence, 'we left Bobby in the garden to play with his chew-toy.' 13 The point, then, is that CONCEPT H must have an explanatory role in cognitive science, because without CONCEPT H we could not formulate explanatory propositions-e.g., 'categorisation involves comparing input with a dog concept, DOG H , across various pieces of information'-that best explain the explananda of cognitive science.</p>
<p>In a similar vein, concept hybridists argue that their theory supports better explanations of meaning extraction. In this case, concept hybridists hold that we fare better if we posit integrated representations, because we can then provide explanations of the linguistic comprehension of lexical items in terms of our switching between different pieces of encoded information depending on context (Vicente and Martnez Manrique 2014, p. 77). For instance, we can formulate explanations that account for the processing of the lexical item 'dog' in terms of accessing the single rich concept DOG H , even if only some parts of this concept come to be selected. In this way, the explanation can appeal to the survey and selection of the best suited information for a given task in a given context, because all information is "active and functional in meaning extraction," even if only some pieces are selected for processing to a greater or lesser extent (Vicente and Martnez Manrique 2014, p. 81). And, again, the fact that such better explanations of meaning extraction are possible only if we endorse CONCEPT H is enough for the hybridist to assert that CONCEPT H must have an explanatory role in cognitive science.</p>
<p>In sum, eliminativist, pluralist, and hybrid theories of concepts all have different conceptions of the kind concept: CONCEPT E , CONCEPT P , and CONCEPT H respectively. Moreover, eliminativist, pluralist, and hybrid theories of concept all take their conceptions of the kind concept to support the ascription of different explanatory roles to concept. And it follows from this state of affairs that each theory provides different justifications for why concept either does (pluralism and hybridism) or does not (eliminativism) feature in propositions that best explain the explananda of cognitive science. As a result, the explanationist approach to determining the natural kind-hood of concept risks being rendered impotent, because in order to decide if concept plays a role in our best cognitive scientific explanations we first require a working consensus about which theory of concept to favour.</p>
<p>CONCEPT E,P,H and the Explananda of Cognitive Science</p>
<p>Having now introduced eliminativist, pluralist, and hybrid theories of concept and elaborated on their respective conceptions of the explanatory role of the kind concept, one point becomes apparent: that there exists a tension between these theories as to whether or not concept has an explanatory role to play in cognitive science (eliminativism vs. pluralism/hybridism) and, if it does have an explanatory role, why 1 3</p>
<p>The Explanatory Role of Concepts it has a role to play (pluralism vs. hybridism). Here we want to argue that the reason that these two tensions obtain is as a result of eliminativist, pluralist, and hybrid theories of concept endorsing different specifications of the explananda of cognitive science.</p>
<p>At a superficial level, eliminativist, pluralist, and hybrid theories of concept all take cognitive science to have the same explananda: (the operations of) cognition. As a result, all three theories seem to accept that the relevant explananda associated with the positing of concept are, for instance, the kinds of category judgements and inferential processing taking place in the mind. One may suppose, therefore, that there is significant overlap between eliminativist, pluralist, and hybrid theories of concept with regards to their specifications of the explananda of cognitive science. If we dig a little deeper, however, fissures begin to appear in the descriptions of the explananda favoured by eliminativist, pluralist, and hybrid theories. For while it may be true that each view attempts to best explain particular patterns in the data; each view may also suppose that the patterns manifest in the data point to different specifications of what there is to be explained.</p>
<p>Consider the explanandum of category judgements as an illustration of this idea. All theories of concept will begin from the same patterns in data; typically, data that evidences particular behaviours including, but not limited to, the identification and discrimination of objects according to diagnostic features and/or properties. For the eliminativist, however, category judgements must come in a diverse number of kinds. There will be category judgements involving at least the kinds prototype, exemplar, and theory-like structure; each different with respect to the salient properties identified and processed in any instance of categorising an individual c in a category C. It follows, for the eliminativist, that category judgements is not one explanandum, but several. Like the eliminativist, the pluralist will accept that category judgements come in a diverse number of kinds. For the pluralist, however, category judgements will only constitute one explanandum, because any given kind of category judgement involving any given kind of representation can be explained by our general (and entirely conceptual) ability to categorise. The hybridist concurs with the pluralist that there is only one explanandum of category judgements, but for different reasons. For the hybridist, the explanandum of category judgements does not even divide into a diverse number of different kinds of category judgements involving different representational kinds. This is the case because the hybridist takes all category judgements to involve only one representational kind: integrated and richly structured representations. Thus, the explanandum of category judgements is specified in three different ways by eliminativist, pluralist, and hybrid theories of concept even where the data to be explained-the evidence of people undertaking categorisation tasks-is the same.</p>
<p>The same pattern can be observed in the way eliminativist, pluralist, and hybrid theories of concept specify the explananda of inferential processing and the combination of mental representations in response to data evidencing cognitive behaviours of, e.g., reasoning and language production. In the case of the explanandum of inferential processing, for instance, eliminativists specify that there are as many different explananda of inferential processsing as there are representational kinds; pluralist specify that even if there are many different kinds of inferential processing, all can be subsumed under the single explanandum of our general (and conceptual) ability to inferentially process; and hybridists specify that there is only one kind of inferential processing (involving integrated representations) and so there is only one explanandum of inferential processing for cognitive science to explain. The same is true of their respective specifications of the explanandum of the combination of mental representations. Here again, then, we find that eliminativist, pluralist, and hybrid theories of concept specify the explananda of cognitive science differently even when they agree on the data to be explained.</p>
<p>Moreover, it is not always the case that there is cross-theoretical agreement about the data to be explained. An example of this state of affairs is the relevance of chronometric data for cognitive science. The eliminativist, for instance, will likely deny that timing in task switching scenarios is an explanandum of cognitive science and so will eschew the relevance of chronometric data. 14 The reason for this likely denial is that chronometric data could speak against an eliminativist position in the following way: if chronometric data demonstrate that switching between different kinds of concepts is fast and easy-i.e., reliable-, then we would have reason to think that there is no additional cognitive mechanism that responds to context-specific processes that activate other concepts. For example, if two kinds of concepts are needed for the comprehension of a single sentence, such as in "Linda can afford to keep Bobby the dog, because chew-toys and dog licence fees are not too expensive," then hearers should need additional time to activate T DOG related to the dog licence fee after having already activated P DOG related to the chew-toy. If not, we have good reasons to think that theory-like structural and the prototypical pieces of information are functionally coactivated within a single dog-representation. In short, then, acknowledging chronometric data in cognitive science would ipso facto be an acknowledgement of the possibility of deciding if there are some processes that simultaneously involve-and, hence, unify-the objects grouped into the kind concept.</p>
<p>Of course, another possibility is that the eliminativist merely overlooks such chronometric data, but is ready to concede their relevance. In this case, the data would turn into empirical counter-evidence to eliminativism. Still another possibility is to find another explanation of such chronometric data that is consistent with eliminativism. Our purpose in discussing chronometric data is not to deny these possibilities, but rather to provide an example of how the interaction between a theory and its explananda could influence the interpretation of the data favoured. To make this point concrete, consider first the explananda of working memory. Prima facie, the data regarding working memory limitation seems to be shared by all cognitive scientists. However, we find competing explanations of working memory limitations. 14 One will certainly not find any explicit rejection of the relevance of chronometric data in the writings of eliminativists such as Machery, but this is unsurprising. To mention such data would be to concede that such data is relevant for cognitive science, which serves only to undermine the eliminativist's position with respect to competing theories of concept. So even though the existence of chronometric data does not depend on the theory of concept one adopts, one's conception of what cognitive science aims to explain can cause such data to be irrelevant. In this sense, the data in question become "invisible" as explananda. Miller (1956), for instance, argued that the capacity of working memory is 7 ± 2 objects (or chunks of information). Later, however, Baddeley (1992) proposed a more detailed account of working memory with different sub-systems; among them the "phonological loop" of about 2 s, the average time needed to speak about seven words in English (see also Baddeley 1996). This difference in the description of the explananda of working memory has further implications for the evaluation of each theory: while an information-theoretic approach measuring amounts of information is the obvious choice for Miller, such accounts could not explain the phenomenon as described by Baddeley; within Baddeley's model, explanations based on the articulatory apparatus are much more promising. 15 The upshot is that the data to be explained-e.g., data regarding learned responses to stimuli-are interpreted differently by the two theories: one takes it as evidence for limitations on the storage of chunks of information; the other as evidence for limitation on the storage of auditory memory traces.</p>
<p>Another example concerns our capacity to reason with conditionals as tested in the famous Wason Selection Task (Wason 1968;Wason and Shapiro 1971). If the conditional rule that is to be tested is formulated in an abstract way (e.g., "if there is a vowel on the one side of a card, there is an even number on the other side"), subjects perform poorly when compared to the solution that is correct according to standard sentential logic of the if-then-operator interpreted as material implication. However, if the rule is more concrete (e.g., "if a person is drinking alcohol, he must be older than 21 years"), the accuracy of subjects' reasoning improves dramatically. This is sometimes referred to as the "content effect." Given this data, one possibility is to describe the explanandum of cognitive science as the capacity of conditional reasoning, which is modulated by another factor; namely, the content of the rule. Another possibility-taken by, e.g., Cosmides and Tooby (1992)-is to deny that there is such a thing as the capacity of conditional reasoning at all, but only a capacity to deal with social rules. Thus, even though both would agree that data about the "content effect" is something that has to be taken into account in the explanation of the phenomena, they still interpret that same data in different ways: one takes it as evidence for the interaction of the capacity of conditional reasoning with some other aspect of cognition; that other takes it as evidence that the capacity of conditional reasoning should be eschewed altogether as an explanandum of cognitive science.</p>
<p>The problem, therefore, is that cross-theoretical agreement about the data (or the description of the data) to be explained is not always apparent. In the context of our discussion about theories of concept, the eliminativist will likely reject any interpretations of chronometric data that makes such data relevant for cognitive science. This can be seen as analogous to Baddeley's (1992) refusal to interpret the data as showing that people remember a certain amount of information; and Cosmides and Tooby's (1992) refusal to interpret that data as evidence for a general capacity of conditional reasoning that is modulated by other factors. And where there is no cross-theoretical agreement about the data to be explained or how to describe them, we find ourselves at a loss when it comes to evaluating which of the available explanations is the best. This is also true in the context of the dispute between eliminativist, pluralist, and hybrid theories of concept. For instance, if one thinks that the explanandum of category judgements ought appeal to only one representational kind, then one has good reason for endorsing CONCEPT H . But if one thinks that the explanandum of category judgements ought appeal to many representational kinds, then one has good reason for endorsing either CONCEPT E or CONCEPT P ; depending, that is, on one's views about the superordinate unity of those kinds. Thus, we find that one's view on the explananda of cognitive science-and, hence, on the interpretation and (ir)relevance of certain bodies of data (or their description)-bias one towards a certain theory of concept and towards a certain view of concept's explanatory role.</p>
<p>Capacities and Effects</p>
<p>Now, one may think that our conclusion in the previous section is too quick, because we ourselves have not provided a specification of the explananda of cognitive science. Plausibly, then, one may think that it is at least possible to specify the explananda of cognitive science in such a way that would undermine the apparent disagreements between eliminativist, pluralist, and hybrid theories of concept. For example, one may think it is possible to follow Cummins (2000, p. 120) and argue that the explananda of cognitive science should be divided into primary and undiscovered capacities-e.g., "to see depth, to learn and speak a language, to plan, to predict the future, to empathize, to fathom the mental states of others" (Cummins 2000, pp. 124-125)-and secondary and discovered effects-e.g., well confirmed regularities that can be specified as laws in situ that "restate the phenomenon in more general terms" (Cummins 2000, p. 120). 16 Working from this premise, one could argue that: the explanation of incidental effects [...] have little interest in their own right: no one would construct a theory just to explain them. But their successful explanation can often be crucial to the assessment of theories or models designed to explain the core capacities that are the primary targets of psychological inquiry (Cummins 2000, p. 128).</p>
<p>Accordingly, one could submit the following counter-argument to our claim: the disagreement between eliminativist, pluralist, and hybrid theories of concept is about the effects identified by cognitive science and not about the capacities that cognitive science aims to explain. If this counter-argument were right, then the dispute between these theories would not be about the explananda of cognitive science tout court, but would be about fine-grained explanatory issues found at the level of 1 3</p>
<p>The Explanatory Role of Concepts effects; for instance, the speed of categorisation and shifts in categorisation when different aspects of the stimuli are emphasised (Ahn and Kim 2000;Ahn and Dennis 2001). In Cummins' terms, the dispute would be about "what happens" and not "why or how"; and this would lead us to be more optimistic about finding a specification of the explananda that could be shared by all theories of concept.</p>
<p>This counter-argument, however, fails to appreciate the difficulty in differentiating between capacities and effects when we factor in the contradictory viewpoints endorsed by the different theories of concept. For it is clear that specifying the explananda of cognitive science in terms of both capacities and effects is highly nontrivial. Cummins (2000, p. 127) himself states that "it can be a matter of substantive controversy whether we are looking at an exercise of a capacity or an incidental effect." This controversy is heightened in the case of the debate between different theories of concept, because the question of how to draw the line between capacities and effects cannot be conveniently segregated from a deeper question about what the capacities are in the first place. 17 For example, one could argue-in accord with the pluralist-that differences in categorisation judgements involving different kinds of representations are merely effects incidental to the exercise of a single capacity to categorise. But, equally, one could take the eliminativist view that there are as many different capacities to categorise as there are representational kinds operative in cognition. And this highlights an important point; namely, that there will be no agreement between eliminativists, pluralists, and hybridists about how to enact a functional analysis that delivers a demarcation between capacities and effects. And thus there will be no agreement about which explanations best explain either capacities or effects, or about the structure of the system giving rise to both capacities and effects. 18 The same point can be made against those who argue that we do not consider in enough detail the explanatory targets of working cognitive scientists. For example, those who insist that working cognitive scientists could never get on board with concept eliminativism, because the kind concept is to them an indispensable explanatory tool. Keil (2010, p. Keil), for instance, argues that there will be "a strong tendency to resist" the claim that there are "an indefinitely large number" of representations operative in cognition (e.g., p DOG , e DOG , t DOG , p CAT , e CAT , t CAT … ). Underlying this claim is the worry articulated by Hampton (Hampton 2010, p. 212) that: the term "concept" is needed as part of an account of the many situations in which PET systems [(e.g., prototypes, exemplars, and theory-like structures representations)] interact. How does one discuss concept combination, including the formation of composite prototypes, the importing of exemplar knowledge, and the coherence checking of the result through background theory, if one cannot have the integrative term "concept" to specify just what it is that is 1 3 being combined. The combination occurs at the concept level, and the description of the processes involved then requires elaboration in terms of the PET systems.</p>
<p>The counter-argument, therefore, is that given the state of cognitive scientific research there are some explananda-e.g., explananda that require cross-representational processing such as "concept combination"-that demand that concept be afforded an explanatory role in cognitive science. The problem, however, is that one need not endorse the claim that putative explananda involving cross-representational processing are part of the explanatory remit of cognitive science. Instead, one may think that the composition of prototypes is distinct from the composition of exemplars and theory-like structures; the use of exemplar knowledge is distinct from the use of prototype and theory-like structure knowledge; and that coherence checking is limited to one representation kind at a time. Thus, in terms of Cummins' distinction, one may hold that the capacities associated with each kind of representation are distinct and that the specification of an effect of cross-representational processing fails to pick out a regular behavioural patterns characteristic of the structure of cognition. This strictly modular view of cognitive structure may strike some as unappealing, but it will dovetail with the specification of the explananda favoured by the eliminativist and with the eliminativist's view on concept's explanatory role. 19 The upshot is that the appeal to the working explanatory interests of cognitive scientists underdetermines the specification of the explananda. For while it is true that many cognitive scientists have been willing to characterise behavioural patterns as characteristic of a particular kind of structure responsible for cross-representational processing, it is also true that all cognitive scientists need not characterise the same behavioural patterns in the same way. For instance, one may characterise an infant's switch from prototype-based categorisation judgements to theory-like structure-based categorisation judgements in terms of a kind of structure responsible for cross-representational processing (Keil 1989). But, equally, one may characterise the same switch as a binary change in the operation of two, distinct capacities: the capacity to categorise using prototypes and the capacity to categorise using theory-like structures. The point, then, is that one cannot assume ex ante what the capacity or capacities for conceptual change consists in, because it is possible that the switch in development from categorising with prototypes to categorising with theory-like structures is a mere incidental effect. Our argument is that the view one takes on these matters will cohere with the theory of concept and of concept's explanatory role one favours.</p>
<p>3</p>
<p>The Explanatory Role of Concepts</p>
<p>To sum up, we do not argue that a unification of cognitive science is, in principle, impossible. Rather, we argue that we do not currently have a unified specification of what cognitive science aims to explain, as evidenced by the fact that different theories of concept take cognitive science to be targeting different explananda. Although it is clear that are overlaps in what different theories of concept take cognitive science to be in the business of explaining, there is also enough disagreement to undermine the search for a definitive account of concept's explanatory role. Thus, to make progress in this regard we would first have to arrive at a unified specification of the explananda of cognitive science. In the next section, however, we will argue that the presence of the divergent theories of concept makes it doubtful that any unified specification could be attained, which serves to undermine the explanationist approach to determining the natural kind-hood of concept.</p>
<p>concept, Explananda, and Explanationism</p>
<p>In Sect. 4, we argued that eliminativist, pluralist, and hybrid theories of concept disagree about the explanatory role of concept in virtue of endorsing three different interpretations of the concept of concept; that is, in virtue of endorsing CONCEPT E , CONCEPT P , and CONCEPT H respectively. And in section five and six, we argued that the tension between eliminativist, pluralist, and hybrid theories of concept is due to each theory endorsing different specifications of the explananda of cognitive science. The remaining question, however, is how this undermines an explanationist approach to determining the natural kind-hood of concept.</p>
<p>Even given what we have said above, an advocate of an explanationist approach to natural kind-hood determination may hold that the natural kind-hood of CONCEPT can be determined by evaluating whether or not it participates in the best cognitive scientific explanations-it is just that we do not know what these explanations are yet or, crucially, what these explanations purport to explain. As we have argued above, however, the tension between the three theories about the explanatory role of concept arises from different interpretations of what the best explanations of cognitive science set out to explain. 20 Therefore, we contend that in order for the explanationist approach to determining the natural kind-hood of concept to be viable, we must first decide what the explananda of cognitive science are; which-according to our argument-amounts to the same thing as deciding between eliminativist, pluralist, and hybrid theories of concept. Thus, there is circle built into explanationism that prevents it from being a viable method to determine whether concept is a natural kind.</p>
<p>In principle, we can always disagree about the best cognitive scientific explanations for a given explanandum. However, as we demonstrated in Sects. 5 and 6, the dispute between eliminativist, pluralist, and hybrid theories of concept is at an even deeper level, for they do not even agree about the explananda to be explained by cognitive science in the first place. For example, in one case the kind CONCEPT P is taken to explain the unity of all category judgements (concept pluralism); but, in another case, the kind CONCEPT E is taken to explain nothing at all such that the unity of all category judgements is explicitly rejected. In this way, one theory cites explananda that are not cited or even countenanced by the other. Thus, we cannot even say that in all cases one theory of concept rejects the cognitive scientific explanations favoured by another as bad or superfluous explanations. Instead, we must say that in at least some cases one theory rejects the interpretation of cognitive scientific explanations favoured by another as bad or superfluous interpretations. The point, then, is that because eliminativist, pluralist, and hybrid theories of concept do not agree on the explananda for which we seek cognitive scientific explanations, they cannot agree on what counts as the best cognitive scientific explanations.</p>
<p>It is clear that all sciences must begin with a specification of their explananda. For example, the phenomenon of lightning was specified as an explanandum of physics, and consequently physics has formulated an explanation for this phenomenon. But we must also keep in mind that the possibility of progress depends upon there being better specifications of the explananda, which serve to restrict the number of acceptable explanations that the science can formulate. It follows that the act of specifying the explananda of a certain science is not independent of the progress of that science-in fact, the progress of a science feeds into a process by which better specifications of the explananda are made and new explananda are brought into the purview of explanation. 21 For sure, it is not an easy question why certain phenomena belong to the subject matter of a certain science. Moreover, during the development of a science, the range of phenomena belonging to the subject matter of this science is liable to change. Not only are new phenomena identified (e.g., quantum effects), but known phenomena might 'change sides' (e.g., some 'chemical' facts about the reactivity of substances turned out to be better explainable by atomic physics). We are thus confronted with a situation that is sometimes called a "virtuous circle," where the explanatory goals of a science (its explananda) and the explanations that the science provides are mutually constitutive. Schematically:</p>
<ol>
<li>The explananda of a science are (partly) determined by specifying them. 2. The terms used to specify the explananda are determined by the theory (i.e., they are theoretical terms). 3. As the theory develops, new explanations are found. 4. As new explanations are found, new terms are introduced and existing terms are refined. 5. With new and refined terms, the explananda of the science change. 22 21 It is clear that a science evolves and develops as it tries to improve upon its best current explanations. So-called "theoretical terms" are introduced into science for the very reason of making something explainable (i.e., by abduction or inference to the best explanation). By parsing scientific theories in terms of, e.g., Ramsey-sentences or partial structures, such terms and their defining place within a theory can be made explicit (cf. Andreas 2017;Lewis 1970;Van Fraassen 1980). 22 To be sure: the phenomena to be explained do not change, but their descriptions do, which essentially involve scientific terms. Since the explananda (as understood here) are not the phenomena themselves but the specific descriptions of the phenomena, the explananda change. E.g., the explanandum of why all objects fall with the same speed in a vacuum was not available before Galileo.</li>
</ol>
<p>In the current debate about the natural kind-hood of concept, a positive portrayal of the virtuous circle has been presupposed, where explananda-specification takes us first to viable explanations, then we move from viable explanations to refined specifications of the explananda, and finally from refined specifications of the explananda back again to better explanations. On this picture, the explanationist approach to determining the natural kind-hood of concept can seem to make some sense: concept is a natural kind only insofar as it features in the better explanations arrived at following the interchange between explananda-specification and cognitive scientific explanation. This view, however, is brought into question when we recognise that any answer to the question of what constitutes a 'better' cognitive scientific explanations must presuppose an answer to the question of what explananda are to be explained by cognitive science in the first place. Thus, we are forced to accept that a specification of the explananda of cognitive science is never theoretically innocent, because it serves to constrain the process of formulating 'better' explanantions and 'better' explananda-specifications further down the line. It follows that one's view of what counts as the best explanation will be influenced by one's view of the explananda in need of explanation.</p>
<p>To decide between theories of concept, it seems therefore that we would first have to find a way to settle the explananda of cognitive science. But this cannot be easily achieved. To illustrate this point, consider the following two explananda: (a) a stick half under water that looks bent even though it is not; and (b) two lines of the same length, one with inward pointing arrow heads, the other with outward pointing arrow heads, which look like they are of different length even though they are not (the "Müller-Lyer-Illusion"). The first explanandum is one of optics, the second is one of psychology of perception. Accordingly, the first is easily explained by the laws of optics, whereas the second is not; to explain the second phenomenon, we need to appeal to basic psychological principles of perception that are not related to the laws of optics. However, why (a) and (b) belong to the subject matter of different disciplines is not prima facie obvious, and we doubt that there could be a specification of the explananda that would make the difference clear, unless that specification already presupposes the difference between optics and psychology. For example, one could try to specify that (a) is an explanandum belonging to the subject matter of optics and (b) an explanandum belonging to psychology by arguing that everything in front of the retina is optics; and since (the image of) the stick is bent on the retina but (the images of) the two lines are not of different sizes on the retina, the first would be specified as an optical phenomenon and the second not. However, this specification already presupposes that optics is confined to certain visual phenomena and psychology to the processing of visual phenomena, which presupposes a certain understanding of the disciplines and their subject matter, which then biases our specifications of the explanandum itself. 23</p>
<p>As with our example of the specification of explananda (a) and (b), eliminativist, pluralist, and hybrid theories of concept endorse specifications of the explananda of cognitive science that dovetail with their understanding of the discipline and its subject matter. This point has been made at length in Sect. 5. With this in mind, we can draw one final conclusion for our discussion of the different theories of concept: we cannot decide which specification of the explananda of cognitive science to endorse by simply looking at the kinds of explanations formulated in cognitive science. The reason for this state of affairs is because every specification of the explananda will be validated by those explanations that are taken to explain the explananda specified. That is, by those explanations that can be interpreted as explaining, say, the unity of cognitive systems (concept pluralism), the modularity of cognitive systems (concept eliminativism), or the functional integration of the representations operative in cognitive systems (concept hybridism). And this bias runs both ways, because no comparison of cognitive scientific explanations will be possible where there is disagreement about what it is that cognitive science ought to be in the business of explaining. We thus seem to lose the basis for a comparison of theories of concept that is not ad hoc, since different theories presuppose different specifications of the explananda of cognitive science, and so each has reasons to find different cognitive scientific explanations more or less successful. 24 If we couple this argument with our claim in Sects. 3 and 4 that different theories of concept afford concept different explanatory roles, then it is evident that an explanationist approach to determining the natural kind-hood of concept cannot be made to work. This follows because we cannot hope to decide between the different theories of concept's explanatory role (e.g., CONCEPT E x , CONCEPT P , and CONCEPT H respectively) when we cannot even agree about what cognitive science aims to explain. 25</p>
<p>Outlook for Discussions About concept</p>
<p>Our conclusion, if correct, appears to leave the naturalistically-inclined philosopher of cognitive science in a difficult spot. For it seems that the explanations formulated in cognitive science can no longer be taken as a reliable guide to the natural 24 Our argument here has certain parallels with the idea of "experimenter's regress" put forward by Collins (1981) and Collins (1992) in his discussion of Joseph Weber's apparatus for gravitational wave detection. According to Collins, there is a circle between judgements of the validity of a measurement device and judgement of the validity of a measurement result. More specifically, he argues that "we don't know if we have built a good detector until we have tried it and obtained the correct outcome! But we don't know what the correct outcome is until...and so on ad infinitum" (Collins 1992, p. 84). Thus, a regress obtains when "scientists try to justify their judgements about a given outcome or about the quality of their data" (Feest 2016, p. 35). We accept that our claim that there is no way to compare explananda across theoretical contexts is analogous to Collins' claim that there is no way to adjudicate disagreements over whether a particular empirical test has captured a certain phenomenon. However, we will set aside further discussion of the relation between the two positions-and of the viability of Collins' claims (cf. Franklin 1999, for criticism of Collins' position)-due to lack of space. 25 To prevent misunderstanding: our argument does not exclude a future specification of the explananda of cognitive science that incorporates all the different explananda of eliminativism, pluralism, and hybridism, and so is able to offer a unified account with respect to these three theories of concept. However, this new overarching specification of the explananda would be just another specification, possibly kind-hood of concept. One may suppose, therefore, that the kind concept-and perhaps other similar kinds featuring in cognitive scientific explanation-cannot be said to be natural kinds at all. This line of reasoning, however, is much too quick. For whilst it may be true that the kind concept ought be thought of as a mind-dependent, social kind in Hacking's (1995; sense; it does not follow that concept cannot also be a natural kind (Hacking 1995(Hacking , 1999Khalidi 2009). This is the case because even if the classification of concept is interactive and can change in response to our attitudes towards cognitive scientific explanations, this does not make the concept ontologically subjective. The crucial point here has been put clearly by Khalidi (2015) as follows:</p>
<p>Mind-dependence is a red herring when it comes to ontological objectivity. There are various phenomena that depend on the human mind (both causally and constitutively) yet are not non-real, at least not in the same sense as fictional entities. Still, isn't there a sense in which all social kinds are ontologically subjective, as Searle claims? Doesn't the fact that they would not have existed without the existence of human minds render them ontologically different from other kinds? Some perspective on these questions may be gained by reflecting further on the analogy between mind and life. Consider biological kinds like tiger, larva, and metabolism. It is safe to say that these biological kinds are life-dependent, in the sense that they would not have existed without life. But that does not seem to impugn their ontological objectivity, and nor should the mind-dependence of social (and psychological) kinds (Khalidi 2015, 111).</p>
<p>The central message of this paper, then, is not that concept is not a natural kind. Rather, we hope to have shown that any approach to determining the natural kind-hood of concept must pay attention to the mind-dependence of the kind concept as a tool in the ongoing, non-monotonic practice of explanation-giving and explananda-specification in cognitive science. The explanationist approach to determining the natural kind-hood of concept fails to recognise this point, because even where explanationism accepts the plasticity of explanations and explanatory methods, it must assume that the best explanations-and, hence, the 'correct' specifications of the explananda-can always be agreed upon (Poston 2016). But since there are no theory-neutral standards of epistemic justification by which to compare explanations and explananda-specification, this assumption is misguided (Appley and Stoutenburg 2017;Stoutenburg 2015). As a result, there can be no straightforward explanationist determination of the natural kind-hood of concept.</p>
<p>Having made this point, we need not go as far as to say that discussion of concept's natural kind-hood should be divorced from cognitive science altogether. We must, however, pay attention to the fact that progress is only possible when there is the possibility of tractable disagreement about the best cognitive scientific explanations and Footnote 25 (continued) rivalling a second future specification, which could then go on to rival a third future specification, and so on ad infinitum. So, our argument in this paper would apply equally to all such hypothetical future specification of the explananda of cognitive science. explananda-specifications. In this way, we must recognise that the results of cognitive science can only come to bear on discussions about the natural kind-hood of concept when we are able, in principle, to come to an agreement about what constitutes the best cognitive scientific explanations and explananda-specifications. We are not convinced that any such agreement is possible. But, if it is, then it is most likely to be found in the case of those explanations that account for explananda specified in accordance with our shared, pre-theoretic understanding of the world; that is, the sui generis explananda specified by attending to our common experiences. If there could be a set of best explanations of these explananda, then we could implement a revised explanationist approach to natural kind-hood determination, whereby we determine natural kindhood by identifying those kinds that play a role in explanations that best explain prereflectively specified explanada. But the promise of using such a revised explanationist approach to determine the natural kind-hood of concept depends, counter-intuitively, on a pre-theoretic specification of what there is for cognitive science to explain.
 Consider hereBird and Tobin's (2017) general definition of a natural kind as a kind that "corresponds to a grouping that reflects the structure of the natural world rather than the interests and actions of human beings".4  One may argue that an explanationist approach to natural kind-hood determination is inadequate, because best explanations often invoke categories that are not to be thought of as natural kinds, even where these categories are useful, causally significant, partially explanatory, etc. This concern, however, is with the explanationist idea that natural kinds can be somehow read off of our best explanations. Although this concern may well be valid, our approach in this paper puts this potential problem with explanationism to one side. We accept-for the purposes of our argument-the explanationist claim that all posits in our best explanations are natural kinds. However, we question the viability of this explanationist methodology with respect to determining the natural kind-hood of concept. Thus, as we will demonstrate below, our argument does not turn on the question of whether or not concept can be thought of as natural kind when posited in our best explanations, but, rather, whether or not we can be sure that concept will be posited in our best explanations at all.
We assume that the explananda of any given science are the phenomena that belong to the subject matter of that science. We accept, however, that the question of which science a phenomenon belongs to seems to be interconnected with the possibility that a given science has to explain the phenomenon in question. We discuss these points in greater detail in Sect. 7 below. 7 It is relevant here to note that Machery endorses a specific characterisation of natural kinds as borrowed from, e.g.,(Boyd 1991(Boyd ,1999. On this "causal notion of natural kind," a natural kind is "a class about which many generalizations can be formulated," because "its members tend to have many properties in common" and "there is at least one causal mechanism that explains why its members tend to
Both concept pluralism and concept eliminativism reject "monolithic theories" of concepts that adhere to the singularity and uniformity assumptions(Weiskopf 2009, pp. 149-150). The singularity assumption
This view is consistent with the claim that prototype, exemplar, and theory-like structure are domain-specific representational kinds that are suited to explain only particular domains of higher cognition. And, if this is the right way of thinking, then eliminativism is right to argue that focusing on the explanatory role of concept only distracts us from developing more accurate and empirical verified explanations of the modular-that is, the encapsulated, dissociable, automatic, neurally localized, and centrally inaccessible-operation of components of cognitive systems(Carruthers 2006, p. 62).12  Consider the explanatory value of the kind mammal, which answers to top-level explanatory demands in the same way that, e.g., rodents, ungulates, and primates answer to bottom-level explanatory demands.
In cognitive science, a number of models of categorisation have already been developed that account for categorisation effects by appealing to the interplay of more than one kind of representational structure (cf.Erickson and Kruschke 1998;Anderson and Betz 2001).
This example is only meant to be illustrative. Our intention, therefore, is not to evaluate the two theories or to decide between them.
A good example of an effect would be the McGurk effect, which can be paraphrased as a law that states that one will have the illusion of hearing a particular sound when the auditory component of another sound is paired with the visual component of yet another sound.
This point connects to our discussion of the putative capacities of working memory and conditional reasoning in the previous section. 18 Note that we do not want to take a stand on how we should specify the explananda of cognition. Rather, we only want to show that different specifications are possible but will be mutually contradictory. This, in turn, problematises the appeal to cognitive science by theories of concept.
It is worth making explicit at this point that we do not want to argue that there are no reasons to accept one or another theory of concept. Of course, one could find any number of reasons; for example, reasons concerned with putative theoretical virtues such as beauty, simplicity, and coherency (cf. Keas 2018, for a good summary of such virtues); or sociological reasons concerned with one's experience with and preference for distinct explanatory tools or one's institutional embedding. Our only argument, then, is that the explanatory success of theoretical terms like concept cannot be determined independent of a theory, and thus there is no out-of-theory reason to accept this or that ontological claim about the existence of such things as concepts.
Note that all three theories aim to account for why cognitive science does or does not need to employ concept in explanation; and since we do not have reason to assume that they speak about three different cognitive sciences, there must be some reason for their divergent perspectives in this regard.
One can see clearly here how finding better specifications of the explananda is part of the remit of science. For example, as soon as the the "Müller-Lyer-Illusion" is identified as a psychological explanandum, psychology will find better specifications of the phenomenon giving rise to the explanandum; that is, that it is a phenomenon made manifest by a default heuristic in the visual system that processes the configuration of angled lines so as to optimise judgements about depth and distance(Gregory 1966).
AcknowledgementsWe would like to thank both anonymous reviewers for their helpful recommendations and advice about how the paper could be improved. Thanks also to participants of the Concepts and Explanation conference in Düsseldorf for their insightful and constructive comments and critique. Finally, thanks to all our colleagues in the CRC and the philosophy department at Heinrich-Heine-University for their support. This work was funded by the DFG (German Research Foundation) as part of the Collaborative Research Centre 991: The Structure of Representations in Language, Cognition, and Science.Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.
Dissociation between categorization and similarity judgement: Differential effect of causal status on feature weights. W Ahn, M J Dennis, Similarity and categorization. U. Hahn, &amp; M. RamscarAhn, W., &amp; Dennis, M. J. (2001). Dissociation between categorization and similarity judgement: Dif- ferential effect of causal status on feature weights. In U. Hahn, &amp; M. Ramscar (Eds.), Similarity and categorization (pp. 87-107).</p>
<p>The causal status effect in categorization. W Ahn, N S Kim, Advances in Research and Theory. 4023Ahn, W., &amp; Kim, N. S. (2000). The causal status effect in categorization. Psychology of Learning and Motivation: Advances in Research and Theory, 40, 23.</p>
<p>A hybrid model of categorization. J R Anderson, J Betz, Psychonomic Bulletin and Review. 8Anderson, J. R., &amp; Betz, J. (2001). A hybrid model of categorization. Psychonomic Bulletin and Review, 8, 629-647.</p>
<p>Theoretical terms in science. H Andreas, The stanford encyclopedia of philosophy. E. N. ZaltaAndreas, H. (2017). Theoretical terms in science. In E. N. Zalta (Ed.), The stanford encyclopedia of phi- losophy (Spring 2018 Edition). http://plato .stanf ord.edu/archi ves/sum20 13/entri es/theor etica l-terms -scien ce/. Accessed July 2018.</p>
<p>Two new objections to explanationism. B C Appley, G Stoutenburg, Synthese. 1948Appley, B. C., &amp; Stoutenburg, G. (2017). Two new objections to explanationism. Synthese, 194(8), 3069-3084.</p>
<p>Working memory. A Baddeley, Science. 2555044Baddeley, A. (1992). Working memory. Science, 255(5044), 556-559.</p>
<p>Exploring the central executive. A Baddeley, The Quarterly Journal of Experimental Psychology Section A. 491Baddeley, A. (1996). Exploring the central executive. The Quarterly Journal of Experimental Psychology Section A, 49(1), 5-28.</p>
<p>Natural kinds. A Bird, E Tobin, The Stanford Encyclopedia of Philosophy. Zalta, E. N.SpringBird, A., &amp; Tobin, E. (2017). Natural kinds. In Zalta, E. N. (Ed.), The Stanford Encyclopedia of Phi- losophy (Spring 2018 Edition). https ://plato .stanf ord.edu/archi ves/spr20 18/entri es/natur al-kinds /. Accessed July 2018.</p>
<p>Bridging the gap between similarity and causality: An integrated approach to concepts. C L Bloch-Mullins, British Journal for the Philosophy of Science. 693Bloch-Mullins, C. L. (2018). Bridging the gap between similarity and causality: An integrated approach to concepts. British Journal for the Philosophy of Science, 69(3), 605-632.</p>
<p>The Explanatory Role of Concepts. The Explanatory Role of Concepts</p>
<p>Realism, anti-foundationalism and the enthusiasm for natural kinds. Philosophical studies. R Boyd, 61Boyd, R. (1991). Realism, anti-foundationalism and the enthusiasm for natural kinds. Philosophical stud- ies, 61(1-2), 127-148.</p>
<p>Kinds, complexity and multiple realization. R Boyd, Philosophical Studies. 951-2Boyd, R. (1999). Kinds, complexity and multiple realization. Philosophical Studies, 95(1-2), 67-98.</p>
<p>Explanationism and justified beliefs about the future. T R Byerly, Erkenntnis. 781Byerly, T. R. (2013). Explanationism and justified beliefs about the future. Erkenntnis, 78(1), 229-243.</p>
<p>Conceptual change in childhood. S Carey, Oxford University PressCambridge; Carruthers, P.; OxfordThe architecture of the mindCarey, S. (1985). Conceptual change in childhood. Cambridge: Cambridge University Press. Carruthers, P. (2006). The architecture of the mind. Oxford: Oxford University Press.</p>
<p>Son of seven sexes: The social destruction of a physical phenomenon. H Collins, Social Studies of Science. 111Collins, H. (1981). Son of seven sexes: The social destruction of a physical phenomenon. Social Studies of Science, 11(1), 33-62.</p>
<p>Changing order: Replication and induction in scientific practice. H Collins, University of Chicago PressChicagoCollins, H. (1992). Changing order: Replication and induction in scientific practice. Chicago: University of Chicago Press.</p>
<p>Cognitive adaptations for social exchange. The Adapted Mind: Evolutionary Psychology and the Generation of Culture. L Cosmides, J Tooby, 163Cosmides, L., &amp; Tooby, J. (1992). Cognitive adaptations for social exchange. The Adapted Mind: Evolu- tionary Psychology and the Generation of Culture, 163, 163-228.</p>
<p>How does it work?" versus" what are the laws?. R C Cummins, Explanation and cognition. F. Keil &amp; R. A. WilsonMIT PressTwo conceptions of psychological explanationCummins, R. C. (2000). "How does it work?" versus" what are the laws?" Two conceptions of psycho- logical explanation. In F. Keil &amp; R. A. Wilson (Eds.), Explanation and cognition (pp. 117-144). MIT Press.</p>
<p>Scientific essentialism. B Ellis, Cambridge University PressCambridgeEllis, B. (2001). Scientific essentialism. Cambridge: Cambridge University Press.</p>
<p>Rules and exemplars in category learning. M A Erickson, J K Kruschke, Journal of Experimental Psychology. 127Erickson, M. A., &amp; Kruschke, J. K. (1998). Rules and exemplars in category learning. Journal of Experi- mental Psychology, 127, 107-140.</p>
<p>The experimenters' regress reconsidered: Replication, tacit knowledge, and the dynamics of knowledge generation. U Feest, Studies in History and Philosophy of Science Part A. 58Feest, U. (2016). The experimenters' regress reconsidered: Replication, tacit knowledge, and the dynam- ics of knowledge generation. Studies in History and Philosophy of Science Part A, 58, 34-45.</p>
<p>Concepts: A potboiler. J A Fodor, Cognition. 50Fodor, J. A. (1994). Concepts: A potboiler. Cognition, 50, 95-113.</p>
<p>How to avoid the experimenters' regress. A Franklin, Can that be right? (pp. A. FranklinBerlinSpringerFranklin, A. (1999). How to avoid the experimenters' regress. In A. Franklin (Ed.), Can that be right? (pp. 13-38). Berlin: Springer.</p>
<p>Words, thoughts, and theories. A Gopnik, A N Meltzoff, MIT PressCambridge, MAGopnik, A., &amp; Meltzoff, A. N. (1997). Words, thoughts, and theories. Cambridge, MA: MIT Press.</p>
<p>Eye and brain. R Gregory, McGraw-HillNew YorkGregory, R. (1966). Eye and brain. New York: McGraw-Hill.</p>
<p>The looping effects of human kinds. I Hacking, Causal cognition: A multidisciplinary approach. D. Sperber, D. Premack, &amp; A. J. PremackOxfordOxford University PressHacking, I. (1995). The looping effects of human kinds. In D. Sperber, D. Premack, &amp; A. J. Premack (Eds.), Causal cognition: A multidisciplinary approach. Oxford: Oxford University Press.</p>
<p>The social construction of what. I Hacking, Harvard University PressCambridge, MAHacking, I. (1999). The social construction of what?. Cambridge, MA: Harvard University Press.</p>
<p>Concept talk cannot be avoided. J A Hampton, Behavioral and Brain Sciences. 332-3Hampton, J. A. (2010). Concept talk cannot be avoided. Behavioral and Brain Sciences, 33(2-3), 212-213.</p>
<p>Systematizing the theoretical virtues. M N Keas, Synthese. 1956Keas, M. N. (2018). Systematizing the theoretical virtues. Synthese, 195(6), 2761-2793.</p>
<p>F C Keil, Concepts, kinds, and cognitive development. Cambridge, MAMIT PressKeil, F. C. (1989). Concepts, kinds, and cognitive development. Cambridge, MA: MIT Press.</p>
<p>Hybrid vigor and conceptual structure. F C Keil, Behavioral and Brain Sciences. 332-3Keil, F. C. (2010). Hybrid vigor and conceptual structure. Behavioral and Brain Sciences, 33(2-3), 215-216.</p>
<p>Empirical adequacy and ramsification. J Ketland, The British Journal for the Philosophy of Science. 552Ketland, J. (2004). Empirical adequacy and ramsification. The British Journal for the Philosophy of Sci- ence, 55(2), 287-300.</p>
<p>Interactive kinds. The British Journal for the Philosophy of. M A Khalidi, Science. 612Khalidi, M. A. (2009). Interactive kinds. The British Journal for the Philosophy of Science, 61(2), 335-360.</p>
<p>Three kinds of social kinds. M A Khalidi, Philosophy and Phenomenological Research. 901Khalidi, M. A. (2015). Three kinds of social kinds. Philosophy and Phenomenological Research, 90(1), 96-112.</p>
<p>The advancement of science: Science without legend, objectivity without illusions. P Kitcher, Oxford University PressOxfordKitcher, P. (1993). The advancement of science: Science without legend, objectivity without illusions. Oxford: Oxford University Press.</p>
<p>Cognitive models and prototype theory. G Lakoff, Concepts and conceptual development. U. NeisserCambridgeCambridge University PressLakoff, G. (1987). Cognitive models and prototype theory. In U. Neisser (Ed.), Concepts and conceptual development (pp. 63-100). Cambridge: Cambridge University Press.</p>
<p>How to define theoretical terms. D Lewis, The Journal of Philosophy. 6713Lewis, D. (1970). How to define theoretical terms. The Journal of Philosophy, 67(13), 427-446.</p>
<p>Doing without concepts. E Machery, Oxford University PressNew YorkMachery, E. (2009). Doing without concepts. New York: Oxford University Press.</p>
<p>Precis of doing without concepts. E Machery, Behavioral and Brain Sciences. 33Machery, E. (2010). Precis of doing without concepts. Behavioral and Brain Sciences, 33, 195244.</p>
<p>Against hybrid theories of concepts. E Machery, S Seppälä, Anthropology and Philosophy. 10Machery, E., &amp; Seppälä, S. (2011). Against hybrid theories of concepts. Anthropology and Philosophy, 10, 99-126.</p>
<p>The magical number seven, plus or minus two: Some limits on our capacity for processing information. G A Miller, Psychological Review. 63281Miller, G. A. (1956). The magical number seven, plus or minus two: Some limits on our capacity for pro- cessing information. Psychological Review, 63(2), 81.</p>
<p>Exemplar-based accounts of relations between classification, recognition, and typicality. R M Nosofsky, Journal of Experimental Psychology: Learning, Memory, and Cognition. 14Nosofsky, R. M. (1988). Exemplar-based accounts of relations between classification, recognition, and typicality. Journal of Experimental Psychology: Learning, Memory, and Cognition, 14, 700-708.</p>
<p>Explanationist plasticity and the problem of the criterion. T Poston, Philosophical Papers. 403Poston, T. (2016). Explanationist plasticity and the problem of the criterion. Philosophical Papers, 40(3), 395-419.</p>
<p>Furnishing the mind: Concepts and their perceptual basis. J J Prinz, Ratio. 184MIT PressScientific realism and metaphysicsPrinz, J. J. (2002). Furnishing the mind: Concepts and their perceptual basis. Cambridge: MIT Press. Psillos, S. (2005). Scientific realism and metaphysics. Ratio, 18(4), 385-404.</p>
<p>Theories. F P Ramsey, The Foundations of Mathematics. London: RoutledgeRamsey, F. P. (1931). Theories. In The Foundations of Mathematics (pp. 212-236). London: Routledge.</p>
<p>A causal-model theory of conceptual representation and categorization. B Rehder, Journal of Experimental Psychology: Learning, Memory, and Cognition. 29Rehder, B. (2003). A causal-model theory of conceptual representation and categorization. Journal of Experimental Psychology: Learning, Memory, and Cognition, 29, 1141-1159.</p>
<p>Natural categories. E H Rosch, Cognitive Psychology. 43Rosch, E. H. (1973). Natural categories. Cognitive Psychology, 4(3), 328-350.</p>
<p>Explanation and explanationism in science and metaphysics. J Saatsi, Metaphysics and the philosophy of science: New essays. M. Slater &amp; Z. YudellOxfordOxford University PressSaatsi, J. (2017). Explanation and explanationism in science and metaphysics. In M. Slater &amp; Z. Yudell (Eds.), Metaphysics and the philosophy of science: New essays (pp. 163-192). Oxford: Oxford Uni- versity Press.</p>
<p>Best explanationism and justification for beliefs about the future. G Stoutenburg, Episteme. 124Stoutenburg, G. (2015). Best explanationism and justification for beliefs about the future. Episteme, 12(4), 429-437.</p>
<p>What is a scientific theory. P Suppes, Philosophy of science today. S. MorgenbesserNew YorkBasic BooksSuppes, P. (1967). What is a scientific theory? In S. Morgenbesser (Ed.), Philosophy of science today (pp. 55-67). New York: Basic Books.</p>
<p>Representation and invariance of scientific structures. P Suppes, CSLI PublicationsStanfordSuppes, P. (2002). Representation and invariance of scientific structures. Stanford: CSLI Publications.</p>
<p>Abstract entities. P Suppes, Contemporary debates in metaphysics. T. Sider, J. Hawthorne, &amp; D. W. ZimmermanOxfordBlackwellSuppes, P. (2008). Abstract entities. In T. Sider, J. Hawthorne, &amp; D. W. Zimmerman (Eds.), Contempo- rary debates in metaphysics (pp. 11-31). Oxford: Blackwell.</p>
<p>The scientific image. B C Van Fraassen, Oxford University PressOxfordVan Fraassen, B. C. (1980). The scientific image. Oxford: Oxford University Press.</p>
<p>The big concepts paper: A defence of hybridism. A Vicente, F Martnez Manrique, The British Journal for the Philosophy of Science. 671Vicente, A., &amp; Martnez Manrique, F. (2014). The big concepts paper: A defence of hybridism. The Brit- ish Journal for the Philosophy of Science, 67(1), 59-88.</p>
<p>Reasoning about a rule. P C Wason, Quarterly Journal of Experimental Psychology. 203Wason, P. C. (1968). Reasoning about a rule. Quarterly Journal of Experimental Psychology, 20(3), 273-281.</p>
<p>Natural and contrived experience in a reasoning problem. P C Wason, D Shapiro, The Quarterly Journal of Experimental Psychology. 231Wason, P. C., &amp; Shapiro, D. (1971). Natural and contrived experience in a reasoning problem. The Quar- terly Journal of Experimental Psychology, 23(1), 63-71.</p>
<p>The plurality of concepts. D A Weiskopf, Synthese. 169Weiskopf, D. A. (2009). The plurality of concepts. Synthese, 169, 145-173.</p>
<p>Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>            </div>
        </div>

    </div>
</body>
</html>