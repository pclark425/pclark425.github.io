<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3563 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3563</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3563</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-79.html">extraction-schema-79</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate or design novel chemicals for specific applications, including details of the model, the application, the generation method, evaluation metrics, results, and any reported limitations or challenges.</div>
                <p><strong>Paper ID:</strong> paper-161f4f53cbddaa7523c11cb7173789f1bb567559</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/161f4f53cbddaa7523c11cb7173789f1bb567559" target="_blank">Bidirectional generation of structure and properties through a single molecular foundation model</a></p>
                <p><strong>Paper Venue:</strong> Nature Communications</p>
                <p><strong>Paper TL;DR:</strong> A multimodal molecular pre-trained model that incorporates the modalities of structure and biochemical properties that has the capabilities to solve various meaningful chemical challenges, including conditional molecule generation, property prediction, molecule classification, and reaction prediction.</p>
                <p><strong>Paper Abstract:</strong> Recent successes of foundation models in artificial intelligence have prompted the emergence of large-scale chemical pre-trained models. Despite the growing interest in large molecular pre-trained models that provide informative representations for downstream tasks, attempts for multimodal pre-training approaches on the molecule domain were limited. To address this, here we present a multimodal molecular pre-trained model that incorporates the modalities of structure and biochemical properties, drawing inspiration from recent advances in multimodal learning techniques. Our proposed model pipeline of data handling and training objectives aligns the structure/property features in a common embedding space, which enables the model to regard bidirectional information between the molecules’ structure and properties. These contributions emerge synergistic knowledge, allowing us to tackle both multimodal and unimodal downstream tasks through a single model. Through extensive experiments, we demonstrate that our model has the capabilities to solve various meaningful chemical challenges, including conditional molecule generation, property prediction, molecule classification, and reaction prediction. Multimodal pre-training approaches on the molecule domain were limited. Here, authors propose a multimodal molecular pre-trained model including molecular structure and biochemical properties and apply it to downstream tasks related with both molecule structure and properties.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3563.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3563.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate or design novel chemicals for specific applications, including details of the model, the application, the generation method, evaluation metrics, results, and any reported limitations or challenges.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SPMM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structure-Property Multi-Modal foundation Model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transformer-based multimodal molecular foundation model that jointly encodes SMILES (structure) and a vector of 53 molecular properties (property modality) to enable bidirectional generation between molecular structure and properties and to provide a unimodal SMILES representation enhanced by property information.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SPMM (Structure-Property Multi-Modal foundation Model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based dual-stream architecture inspired by vision-language pretraining: separate unimodal encoders for SMILES and a 53-dimensional property vector (PV), a fusion encoder that performs cross-attention, and projection heads for contrastive alignment. Pre-trained on ~20 million molecules with 50% random property masking; training objectives include contrastive alignment between SMILES and PV, Next Word Prediction (NWP) for SMILES, Next Property Prediction (NPP), and SMILES-Property Matching (SPM). The paper reports using 6 BERT encoder layers for experiments (SMILES encoder configuration shown in benchmarks). Exact parameter count/hidden sizes are not reported in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Autoregressive sequence-to-sequence generation: PV-to-SMILES (properties as a 53-token 'sentence' -> SMILES tokens), using deterministic (greedy) and stochastic token sampling from the model's next-token distribution. SMILES-to-PV is likewise autoregressive predicting the 53 properties sequentially. Fusion encoder uses cross-attention between modalities after contrastive alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>De novo molecule design / inverse-QSAR and general molecular generation conditioned on multiple properties; also used for property prediction (SMILES-to-PV), molecule editing, and reaction prediction (forward and retrosynthesis), with emphasis on drug-discovery-relevant properties.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>For PV-to-SMILES generation: validity (fraction of syntactically valid SMILES), uniqueness (fraction of non-duplicate valid SMILES), novelty (fraction of unique SMILES not in pre-training data), normalized RMSE between input PV and generated molecules' properties (RMSE computed on properties normalized by training mean/std). For SMILES-to-PV: per-property R^2 and normalized RMSE. For unimodal downstream tasks: MoleculeNet metrics (regression RMSE, classification AUROC), DILI classification metrics (accuracy, selectivity, specificity, AUROC). For reaction tasks: top-k accuracy (k=1,2,3,5 for forward; k=1,5,10 for retrosynthesis).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>PV-to-SMILES generation (examples reported): deterministic generation on 1,000 unseen PubChem PVs: validity = 0.982 ± 0.003, uniqueness = 0.830 ± 0.077, novelty = 0.954 ± 0.004, normalized RMSE = 0.194 ± 0.006. Stochastic generation conditioned on a full PV: validity = 0.882 ± 0.004, uniqueness ≈ 0.999, novelty = 1.000, normalized RMSE = 0.189 ± 0.007. Other stochastic scenarios (single-property control, partial property masking) produced validity typically between 0.75 and 0.9 and near-100% uniqueness. SMILES-to-PV prediction on 1,000 ZINC15 molecules: mean R^2 across 53 properties = 0.932, mean normalized RMSE = 0.118. As a unimodal foundation model (SMILES encoder finetuned): competitive/superior performance on multiple MoleculeNet tasks (e.g., SPMM achieved best reported results on Clearance, BBBP, and Clintox in the table) and strong DILI classification (Accuracy 84.7%, AUROC 91.2%). Reaction prediction: forward top-1 accuracy = 91.5% (comparable or better than many baselines) and retrosynthesis top-1 = 53.0% (second-best among listed string-based models).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>The paper compares SPMM to several prior models: SPMM performed comparably or better on many downstream tasks. Examples: on MoleculeNet benchmarks SPMM outperformed the same architecture without pretraining and matched or exceeded several prior graph- and transformer-based approaches (e.g., D-MPNN, GROVER variants, ChemBERTa-2, ChemRL-GEM) on multiple tasks; forward reaction prediction top-1 accuracy (91.5%) was at or above many listed baselines (Molecular Transformer, Chemformer, LocalTransform). Where reported, the paper gives numeric comparisons in Tables 2 and 4.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Reported limitations include: (1) representation choice — use of SMILES has implicit adjacency encoding and small structural changes can cause large SMILES edits; graph representations might be preferable for some tasks. (2) stereochemistry — the 53 properties used are invariant to stereochemistry so the model cannot learn stereochemical distinctions; this likely lowered performance on some MoleculeNet tasks. (3) combinatorial coverage — although the model uses 50% random property masking during pretraining, it cannot see the vast majority of 2^53 possible property combinations; generalization to arbitrary combinations relies on treating PV as a 53-word language but remains a challenge. (4) dataset scale — pretraining used ~20M molecules, smaller than some other foundation models (e.g., 100M), so scaling could further improve performance. (5) validation — authors note wet-lab validation of generated molecules' properties was not performed. (6) generation validity varied by feasibility of input conditions (validity dropped to ~0.75 in some stochastic setups).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bidirectional generation of structure and properties through a single molecular foundation model', 'publication_date_yy_mm': '2022-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction <em>(Rating: 2)</em></li>
                <li>Chemformer: A Pretrained Transformer for Computational Chemistry <em>(Rating: 2)</em></li>
                <li>ChemBERTa-2: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3563",
    "paper_id": "paper-161f4f53cbddaa7523c11cb7173789f1bb567559",
    "extraction_schema_id": "extraction-schema-79",
    "extracted_data": [
        {
            "name_short": "SPMM",
            "name_full": "Structure-Property Multi-Modal foundation Model",
            "brief_description": "A transformer-based multimodal molecular foundation model that jointly encodes SMILES (structure) and a vector of 53 molecular properties (property modality) to enable bidirectional generation between molecular structure and properties and to provide a unimodal SMILES representation enhanced by property information.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "SPMM (Structure-Property Multi-Modal foundation Model)",
            "model_description": "Transformer-based dual-stream architecture inspired by vision-language pretraining: separate unimodal encoders for SMILES and a 53-dimensional property vector (PV), a fusion encoder that performs cross-attention, and projection heads for contrastive alignment. Pre-trained on ~20 million molecules with 50% random property masking; training objectives include contrastive alignment between SMILES and PV, Next Word Prediction (NWP) for SMILES, Next Property Prediction (NPP), and SMILES-Property Matching (SPM). The paper reports using 6 BERT encoder layers for experiments (SMILES encoder configuration shown in benchmarks). Exact parameter count/hidden sizes are not reported in the paper.",
            "generation_method": "Autoregressive sequence-to-sequence generation: PV-to-SMILES (properties as a 53-token 'sentence' -&gt; SMILES tokens), using deterministic (greedy) and stochastic token sampling from the model's next-token distribution. SMILES-to-PV is likewise autoregressive predicting the 53 properties sequentially. Fusion encoder uses cross-attention between modalities after contrastive alignment.",
            "application_domain": "De novo molecule design / inverse-QSAR and general molecular generation conditioned on multiple properties; also used for property prediction (SMILES-to-PV), molecule editing, and reaction prediction (forward and retrosynthesis), with emphasis on drug-discovery-relevant properties.",
            "evaluation_metrics": "For PV-to-SMILES generation: validity (fraction of syntactically valid SMILES), uniqueness (fraction of non-duplicate valid SMILES), novelty (fraction of unique SMILES not in pre-training data), normalized RMSE between input PV and generated molecules' properties (RMSE computed on properties normalized by training mean/std). For SMILES-to-PV: per-property R^2 and normalized RMSE. For unimodal downstream tasks: MoleculeNet metrics (regression RMSE, classification AUROC), DILI classification metrics (accuracy, selectivity, specificity, AUROC). For reaction tasks: top-k accuracy (k=1,2,3,5 for forward; k=1,5,10 for retrosynthesis).",
            "results_summary": "PV-to-SMILES generation (examples reported): deterministic generation on 1,000 unseen PubChem PVs: validity = 0.982 ± 0.003, uniqueness = 0.830 ± 0.077, novelty = 0.954 ± 0.004, normalized RMSE = 0.194 ± 0.006. Stochastic generation conditioned on a full PV: validity = 0.882 ± 0.004, uniqueness ≈ 0.999, novelty = 1.000, normalized RMSE = 0.189 ± 0.007. Other stochastic scenarios (single-property control, partial property masking) produced validity typically between 0.75 and 0.9 and near-100% uniqueness. SMILES-to-PV prediction on 1,000 ZINC15 molecules: mean R^2 across 53 properties = 0.932, mean normalized RMSE = 0.118. As a unimodal foundation model (SMILES encoder finetuned): competitive/superior performance on multiple MoleculeNet tasks (e.g., SPMM achieved best reported results on Clearance, BBBP, and Clintox in the table) and strong DILI classification (Accuracy 84.7%, AUROC 91.2%). Reaction prediction: forward top-1 accuracy = 91.5% (comparable or better than many baselines) and retrosynthesis top-1 = 53.0% (second-best among listed string-based models).",
            "comparison_to_baselines": "The paper compares SPMM to several prior models: SPMM performed comparably or better on many downstream tasks. Examples: on MoleculeNet benchmarks SPMM outperformed the same architecture without pretraining and matched or exceeded several prior graph- and transformer-based approaches (e.g., D-MPNN, GROVER variants, ChemBERTa-2, ChemRL-GEM) on multiple tasks; forward reaction prediction top-1 accuracy (91.5%) was at or above many listed baselines (Molecular Transformer, Chemformer, LocalTransform). Where reported, the paper gives numeric comparisons in Tables 2 and 4.",
            "limitations_challenges": "Reported limitations include: (1) representation choice — use of SMILES has implicit adjacency encoding and small structural changes can cause large SMILES edits; graph representations might be preferable for some tasks. (2) stereochemistry — the 53 properties used are invariant to stereochemistry so the model cannot learn stereochemical distinctions; this likely lowered performance on some MoleculeNet tasks. (3) combinatorial coverage — although the model uses 50% random property masking during pretraining, it cannot see the vast majority of 2^53 possible property combinations; generalization to arbitrary combinations relies on treating PV as a 53-word language but remains a challenge. (4) dataset scale — pretraining used ~20M molecules, smaller than some other foundation models (e.g., 100M), so scaling could further improve performance. (5) validation — authors note wet-lab validation of generated molecules' properties was not performed. (6) generation validity varied by feasibility of input conditions (validity dropped to ~0.75 in some stochastic setups).",
            "uuid": "e3563.0",
            "source_info": {
                "paper_title": "Bidirectional generation of structure and properties through a single molecular foundation model",
                "publication_date_yy_mm": "2022-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction",
            "rating": 2
        },
        {
            "paper_title": "Chemformer: A Pretrained Transformer for Computational Chemistry",
            "rating": 2
        },
        {
            "paper_title": "ChemBERTa-2: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction",
            "rating": 1
        }
    ],
    "cost": 0.00999575,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Bidirectional Generation of Structure and Properties Through a Single Molecular Foundation Model</h1>
<p>Jinho Chang ${ }^{1}$ and Jong Chul $\mathrm{Ye}^{1, \dagger}$<br>${ }^{1}$ Graduate School of AI, KAIST, Daejeon, South Korea<br>${ }^{\dagger}$ Correspondence should be addressed to J.C.Y. (jong.ye@kaist.ac.kr)</p>
<h4>Abstract</h4>
<p>The recent success of large foundation models in artificial intelligence has prompted the emergence of chemical pre-trained models. Despite the growing interest in large molecular pre-trained models that provide informative representations for downstream tasks, attempts for multimodal pre-training approaches on the molecule domain were limited. To address this, we present a novel multimodal molecular pre-trained model that incorporates the modalities of structure and biochemical properties, drawing inspiration from recent advances in multimodal learning techniques. Our proposed model pipeline of data handling and training objectives aligns the structure/property features in a common embedding space, which enables the model to regard bidirectional information between the molecules' structure and properties. These contributions emerge synergistic knowledge, allowing us to tackle both multimodal and unimodal downstream tasks through a single model. Through extensive experiments, we demonstrate that our model shows remarkable capabilities in solving various meaningful chemical challenges, including conditional molecule generation, property prediction, molecule classification, and reaction prediction.</p>
<h1>Introduction</h1>
<p>Capturing complex relations between chemical objects and their properties is the essence of numerous chemical challenges. During the last decade, artificial intelligence has emerged as a promising tool in chemistry research for estimating many biochemical properties and interactions between molecules, polymers, and proteins, which are difficult to obtain experimentally ${ }^{1-3}$. Various deep learning-based approaches in the chemical domain employed deep neural networks to extract desired characteristics like intrinsic properties, biochemical activities, and chemical reactions from raw molecule data ${ }^{4-6}$. Especially, de novo molecule design has been extensively studied using recurrent networks ${ }^{7}$, variational autoencoders ${ }^{8,9}$, graph networks ${ }^{10}$, etc ${ }^{11-13}$. More recently, unsupervised learning approaches of learning better representations of the chemical inputs have been suggested ${ }^{14-16}$ to overcome the limitation of learning separate features for each task in a supervised manner. These recent approaches are on the same track as the concept of the foundation models that are trained with large datasets and are often considered as a new paradigm of deep learning ${ }^{17,18}$.</p>
<p>Specifically, a concept of pre-training a neural network in a self-supervised manner for a better feature representation has been adapted for various chemical fields ${ }^{14-16}$. N-Gram Graph ${ }^{19}$ and GROVER $^{20}$ used a graph neural network and a graph transformer network, respectively, to obtain a pre-trained model from the molecular graph. ChemBERTa-2 ${ }^{21}$ trained a roBERTa model with 77 million molecules to build a molecular foundation model, by training the model to predict 200 different chemical property values.</p>
<p>Meanwhile, in the computer vision field, multimodal pre-training methods like Vision-Language Pre-training (VLP) ${ }^{22}$ have achieved outstanding performance in downstream tasks that require an understanding of both image and text. Most of the modern VLP models utilize Transformer ${ }^{23}$ archi-</p>
<p>tecture and its cross-attention mechanism to learn the correlation between different modalities ${ }^{24,25}$. Moreover, several works introduced contrastive learning, which assimilates features with the same context and distances semantically unrelated features, to align image and language features in the common feature space ${ }^{26-28}$. VLP enables various tasks such as visual question answering ${ }^{29}$, imagetext retrieval ${ }^{30}$, text-driven image generation ${ }^{31}$, image-driven text generation ${ }^{32}$, etc., which are not possible using single modality foundation models.</p>
<p>Inspired by the success of multimodal learning, several recent works tried to obtain a better feature of a molecule by leveraging knowledge from different data representations. Winter et al. trained a translation model between Simplified Molecular-Input Line-Entry System (SMILES) and International Chemical Identifier (InChI) key to get a feature vector with meaningful information that both molecular representations have in common ${ }^{33}$. Zhu et al. used a self-supervised training method of BYOL ${ }^{34}$ between different molecule representations of SMILES and molecular graphs to build a dual-view model ${ }^{35}$. However, these works introduced multimodality only for the enhancement of a molecule feature for unimodal tasks, not for the interplay between those different modalities. Furthermore, since SMILES, InChI, and graph representations contain almost identical information about the connection between atoms in a molecule, it is unlikely to expect new emergence properties by multimodal learning between these different molecule representations.</p>
<p>In this work, we are interested in the cross-modal comprehension between molecule structure and the associate properties, which facilitates solving meaningful tasks in many applications like property predictions, conditional molecule design ${ }^{36,37}$, etc. Taking a step further from multi-task learning methods ${ }^{38}$ which use the prepared properties as labels to extract general features ${ }^{21}$, our approach regards a set of properties as a stand-alone modality that represents the input molecule and suggests that multimodal learning for molecules with this property modality can provide much more informative features. Specifically, we propose a novel molecule Structure-Property Multi-</p>
<p>Modal foundation model(SPMM) which allows various chemistry experiments in silico, which is pre-trained with a wide range of molecules' structures and a vector of its properties. By employing a Transformer architecture ${ }^{23}$, the intramodal feature extraction and intermodal fusion can be done with self-attention and cross-attention mechanisms, respectively.</p>
<p>Our experimental results show that simultaneous learning of structural features with information from the associate properties through a single foundation model gives us a better representation that can be fine-tuned for various downstream tasks. Specifically, by treating both structure and property symmetrically, the model can perform bidirectional generation and prediction with a single pre-trained model, which was not possible before.</p>
<p>Fig. 1(a) illustrates the overall model architecture and training objectives for SPMM. The framework of SPMM extends the structure of the dual-stream VLP models ${ }^{27,28,39}$. Dual-stream VLP models encode the input for each modality with a unimodal encoder, then use another encoder module to perform cross-attention by using one modality feature as a query and the other modality feature as a key/value. When a training molecule is given, SPMM takes the molecule's SMILES string and its property vector (PV) as multimodal data inputs as shown in Fig. 1(a). The SMILES and PV are passed through their corresponding unimodal encoders, which perform selfattention where embedded inputs become the key, query, and value. After two unimodal features are obtained, contrastive learning aligns the SMILES and PV features into the same embedding space by assimilating the features that contain the same context. This is known to improve the model performance by making cross-modal encoding easier and guiding the unimodal encoded features to reflect more semantics of the input ${ }^{27}$. Then, the encoded SMILES and PV features are passed through the fusion encoders, which perform cross-attention between SMILES and PV features. This single fusion encoder can perform cross-attention with an alternation of its query and key/value input because the contrastive learning aligns the output of the SMILES encoder and</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: (a) Overview of the model architecture and pre-training objectives of SPMM. The contrastive loss aligns the output feature of two unimodal encoders into the same embedding space. The fusion encoder learns the relations between two modalities, trained with Next Word Prediction (NWP), Next Property Prediction (NPP), and SMILES-Property Matching loss (SPM). (b) Downstream tasks that require multimodal comprehension: i) PV-to-SMILES generation, ii) SMILES-to-PV generation. (c) Downstream tasks for single modality inputs: i) property prediction, ii) forward and retro reaction prediction.
the PV encoder into the same feature space. ${ }^{39}$ The fusion encoder is pre-trained with Next Word Prediction (NWP) for SMILES, Next Property Prediction (NPP), and SMILES-PV Matching loss (SPM). Prediction of the next component from the given transformer input is a commonly used self-supervised learning objective, and our NWP and NPP tasks make the model learn the contextual relationship between SMILES tokens and properties with the aid of the other modality's semantic feature. Additionally, SPM predicts whether a given pair of SMILES and PV represents the same molecule or not.</p>
<p>Once trained, SPMM can be used for various bidirectional downstream tasks that require</p>
<p>an understanding of both SMILES and properties like property prediction (SMILES-to-properties) and property-conditioned molecule generation (properties-to-SMILES, also referred to as inverseQSAR $\left.{ }^{37}\right)$ as shown in Fig. 1(b). Furthermore, the pre-training objectives that we've used allow the pre-trained SPMM to be applied for single-modality tasks as well, such as molecule classification and reaction predictions (see Fig. 1(c)). The pre-trained SPMM showed comparable performances to state-of-the-art models in these unimodal tasks, which suggests the model's generalization ability as a foundation model.</p>
<h1>Results</h1>
<p>The model learns bidirectional comprehension between SMILES and properties. Once SPMM was pre-trained, we made the model generate SMILES with given PV inputs only, which is a crucial challenge for many chemical tasks such as de novo molecule design. As one of the major approaches for drug discovery, various methods have been suggested for generating molecules with desired properties ${ }^{9-11,13}$. In the approaches presented so far, the maximum number of simultaneously controllable properties wasn't very large. Also, the length of the input property vector cannot be changed. Whenever the target properties change, the model needs to be trained again for the new wanted conditions. In contrast, the pre-trained SPMM can take 53 properties used in pre-training as input conditions and generate molecules that satisfy all of them, without separate additional training for each property combination. Moreover, for the properties that we don't want to control, we can let the model ignore those conditions by replacing them with the [UNK] token that we used in pre-training. This is very useful because controlling all 53 input properties is not a usual scenario in practice, and is also not easy since the properties are correlated and entangled ( $e$. g., ' 5 atoms \&amp; 30 bonds' or ' 2 rings \&amp; 5 aromatic rings' is unlikely to be a valid PV input).</p>
<p>To demonstrate the molecule generation capability of SPMM, we prepared a number of PV-</p>
<p>to-SMILES generation scenarios and let the pre-trained SPMM autoregressively generate SMILES using the input properties. This process of SPMM is very similar to the sequence-to-sequence translation tasks in terms of the model pipeline (see Figure S3-(a) for details), from the property sentence of PV to the molecular structure sentence of SMILES.</p>
<p>The validity, uniqueness, and novelty of the generated molecules are the quantitative metrics of SPMM's molecule generation, defined as follows:</p>
<p>$$
\begin{gathered}
\text { validity }=\frac{\text { #SMILES with valid syntax }}{\text { #generated SMILES }} \
\text { uniqueness }=\frac{\text { #non-duplicate valid SMILES }}{\text { #valid SMILES }} \
\text { novelty }=\frac{\text { #unique SMILES not in the pre-training data }}{\text { #unique SMILES }}
\end{gathered}
$$</p>
<p>Additionally, as a qualitative metric to see how the generated SMILES match the property input, we measured the normalized Root Mean Square Error (normalized RMSE) between the input conditions and the generated molecules' properties. More specifically, we calculate the average of the RMSE of all controlled properties, after those values are normalized with the corresponding property's mean and standard deviation in the pre-training dataset. We note that RMSE was calculated on the normalized scale of each property because the values of the properties span multiple orders of magnitude.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">sampling <br> deterministic</th>
<th style="text-align: center;">input PV</th>
<th style="text-align: center;">validity</th>
<th style="text-align: center;">uniqueness</th>
<th style="text-align: center;">novelty</th>
<th style="text-align: center;">normalized RMSE</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">1,000 unseen PubChem SMILES' PV</td>
<td style="text-align: center;">$0.982 \pm 0.003$</td>
<td style="text-align: center;">$0.830 \pm 0.077$</td>
<td style="text-align: center;">$0.954 \pm 0.004$</td>
<td style="text-align: center;">$0.194 \pm 0.006$</td>
</tr>
<tr>
<td style="text-align: center;">stochastic</td>
<td style="text-align: center;">full PV of the molecule $\mathbf{1}$</td>
<td style="text-align: center;">$0.882 \pm 0.004$</td>
<td style="text-align: center;">$0.999 \pm 0.001$</td>
<td style="text-align: center;">$1.000 \pm 0.000$</td>
<td style="text-align: center;">$0.189 \pm 0.007$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Molecular weight $=150$</td>
<td style="text-align: center;">$0.913 \pm 0.008$</td>
<td style="text-align: center;">$0.999 \pm 0.000$</td>
<td style="text-align: center;">$0.932 \pm 0.005$</td>
<td style="text-align: center;">$0.262 \pm 0.004$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">#ring=2, #aromatic ring=1, TPSA=30, QED=0.8</td>
<td style="text-align: center;">$0.933 \pm 0.007$</td>
<td style="text-align: center;">$0.999 \pm 0.001$</td>
<td style="text-align: center;">$0.979 \pm 0.005$</td>
<td style="text-align: center;">$0.343 \pm 0.009$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">no property control</td>
<td style="text-align: center;">$0.751 \pm 0.008$</td>
<td style="text-align: center;">$1.000 \pm 0.000$</td>
<td style="text-align: center;">$0.998 \pm 0.002$</td>
<td style="text-align: center;">-</td>
</tr>
</tbody>
</table>
<p>Table 1: Quantitative and qualitative results on various scenarios of PV-to-SMILES generation tasks, with the mean value and standard deviations. For deterministic sampling, we ran the experiment with four different random sets of 1,000 unseen PVs. In the case of stochastic scenarios, four different random seeds were used for each experiment.</p>
<p>For the first PV-to-SMILES generation scenario, we prepared 1,000 PVs of SMILES from PubChem ${ }^{40}$ that are not contained in the pre-training dataset and fed them to the pre-trained SPMM to generate appropriate SMILES. Here, the sampling process was done in a deterministic manner (greedy sampling): starting from the SMILES [CLS] token ([CLS] $]_{S}$ ), the model predicts the probability distribution of the next token and chooses the option with the highest probability. The first row of Table 1 shows its results. Among the output of deterministic PV-to-SMILES generation for 1,000 PVs, $98.2 \%$ of the generated output were valid SMILES. The mean RMSE of the 53 normalized properties was 0.194 , which implies that the properties of the generated samples agree with the property input.</p>
<p>Application fields like drug discovery often require generating multiple molecules for a single wanted target property condition. This can be done by sampling the next token stochastically from the modeled probability distribution instead of using a token with the highest probability. To verify our model's ability to generate multiple molecules from a single PV input, we generated 1,000 SMILES with stochastic sampling on a fixed PV. Figure 2 shows the property distributions of 1,000 molecules generated from a single PV input. The mode of each property distribution lands on the input property value (Fig. 2-(a)). In the situation when only some of the properties are given, the model only regards the known properties while the other masked properties are not restricted (Fig. 2-(b), Fig. 2-(c)). SPMM can generate molecules even with no property information at all; when all input properties are replaced with [UNK] token (Fig. 2-(d)), the model performs an unconditional molecule generation, and the output follows the distribution of the pre-training dataset. The validity, uniqueness, and novelty of the generated molecules under conditions in Figure 2 are listed in the "stochastic" rows of Table 1. The validity fluctuated depending on how feasible or difficult the property input is, and it was between 0.75 and 0.9 in most cases. The uniqueness, the ratio between the number of unique molecules against the number of validly generated molecules, was almost $100 \%$ in every condition we have experimented with. More examples of the generated</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Property distribution of the generated molecules with different PV inputs and [UNK] token masking. The red vertical dotted lines are the input property values, and the grey vertical lines are the mean of that property in the pre-training dataset. The controlled properties are colored in red, and uncontrolled properties (=masked with [UNK] token) are colored in blue. Due to the lack of space, only 12 out of 53 properties are shown for each case. For each PV-to-SMILES scenario, we included the structure of two of the generated molecules. (a) All 53 properties are controlled, without using the [UNK] token. The input PV was obtained from the molecule 1. (b) Molecular Weight to 150, and the other property inputs are masked. (c) #ring, #aromatic ring, TPSA, and QED are controlled to 2, 1, 30, and 0.8. The other property inputs are masked. (d) Every property is replaced with [UNK] token.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Examples of molecule editing, by changing specific values from the original PV and performing PV-to-SMILES generation with it. The colored output values correspond to the changed properties from the original PV. (1) The output of the same PV of the source molecule. (2) The output when #aromatic_ring is changed to 0. (3) The output when #ring is changed to 2 and #aromatic_ring is changed to 1. (4) The output when $\log P$ is changed to 7. (5) The output when #rotatable_bond is changed to 12. For the generation, the other 41 property conditions are masked by the [UNK] token.
molecule can be found in Supplementary result S1.</p>
<p>The aforementioned results demonstrate that SPMM can perform molecule generation with arbitrary PV inputs, which enables simple molecule designing and editing. Figure 3 contains the output of the SPMM's stochastic molecule generation for five PV inputs, which all originated from the PV of the molecule $\mathbf{1}$ but four of them had certain values changed. The generated molecules follow the input modification while maintaining unmodified properties similarly. SPMM is even able to generate molecules with the out-of-domain conditions such as $\log P=7$ (note that $\sim 5 \%$ of the pre-training dataset has $\log P&gt;7$ ).</p>
<p>Regarding the overall molecule generation performance of SPMM, we want to emphasize that SPMM can generate suitable SMILES for many property conditions that the model has not</p>
<p>seen in its pre-training. When we trained SPMM without 50% of random property masking with [UNK] token, the model only worked when all 53 properties are given since the model has not seen the partially-given properties. However, even with the technique of [UNK] token masking, the model cannot face most of the $2^{53}$ possible property combination during the pre-training process. The SPMM's ability to handle arbitrary property conditions for SMILES generation comes from treating PV as a 'language with 53 words' and focusing on each property separately, not simply considering the entire property input as a single condition. This innovative approach for conditional molecule generation has never been demonstrated with the existing methods and thus can be used for many important chemical fields.</p>
<p>With the same approach as SMILES generation, the pre-trained SPMM can also be used to generate a PV with SMILES input only. This task is equivalent to performing 53 property predictions of a given SMILES at once. Similar to the PV-to-SMILES generation, properties are predicted in an autoregressive manner: the model predicts the first property value using only the property [CLS] token ([CLS]_{P}), then takes all previous outputs again to get the next prediction value, and so on (see Figure S3-(b)). Although 53 properties that we've used can be calculated using the Python module, the purpose of this experiment is to verify that the data-driven way of property estimation coincides with the analytic approach.</p>
<p>Specifically, we fed 1,000 SMILES from the ZINC15 dataset41, which are not contained in the pre-training dataset, to the pre-trained SPMM and generated their corresponding PV. Figure 4 is the scatter plot of the real property value against the generated output for 12 selected properties out of 53 that we used for pre-training. It is clear that SPMM's predicted property is very close to the actual value, and most of the data point lies on the y = x line. Although the model virtually has never seen a full-filled PV in the pre-training due to the 50% of random property masking, the model could autoregressively predict all 53 properties as a whole. The mean r² score of the 53</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Scatter plots of the 1,000 ZINC15 molecules' real property value against the generated output, for 12 selected properties. The $x$-axis is the real property value, and the $y$-axis is the model output. The grey dotted line is the $y=x$ line.
properties was 0.932 . The mean of the normalized RMSE for 53 properties was 0.118 . The full scatter plot for all 53 properties with each $r^{2}$ score and raw RMSE is in the Supplementary Figure S2.</p>
<p>To provide an interpretation of the pre-trained SPMM's performance presented so far, we further analyzed the learned cross-modal comprehension between SMILES and property vectors by visualizing the attention scores from the pre-trained SPMM. Transformer-based models have the benefit of intuitive attention visualization that shows how the model considers the relation</p>
<p>between the input queries and keys, by providing cross-attention scores between them.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: The mean attention score from the attention heads in the SPMM fusion encoder's final crossattention layer for two sample molecules. A darker green means a higher attention score. For the attention process, the property features were used as queries, and the SMILES features are used as keys and values. The corresponding fragments for each token are indicated with ivory boxes on the molecular structure, while fragments for duplicated tokens are color-coded with purple. We have calculated cross-attention scores for all 53 properties and SMILES tokens, but only 12 of those properties are shown.</p>
<p>In Figure 5, we plotted the cross-attention score from the last fusion layer of our pre-trained SPMM when SMILES and its property vector inputs were given. Since there are multiple heads for the cross-attention, we took the mean of their attention scores. It is interesting that the aspect of cross-attention scores followed the intuitive relations between chemical properties and molecular fragments. The properties related to hydrogen bonding (NumHDonors, NumHAcceptors) show high attention scores for tokens with oxygen and nitrogen atoms. The property RingCount focuses on the tokens that are involved with rings while showing weak attention to side groups, and the property NumAromaticRings only gives high attention score to the components of aromatic rings. When different SMILES tokens played a similar role in the molecule such as 'c1ccccc1)' and 'c1ccccc1' in the molecule 15, their attention patterns were similar as well. This result demon-</p>
<p>strated that SPMM could capture the relations between molecule structures and chemical properties without explicitly-given supervision between them.</p>
<p>Generalization ability as a molecular foundation model. So far, we have demonstrated that the pre-trained SPMM can be applied to tasks that require an understanding of the relationship between SMILES and properties. However, we can also employ the pre-trained SPMM for challenges that only use SMILES data, such as molecular property prediction. One advantage of having a dualstream VLP model structure is that the SPMM's multimodal pre-training process includes adjusting the output of one unimodal encoder to contain contextual information from the other modality, by aligning it with the other unimodal encoder's output. This implies that the SMILES encoder output is a unimodal representation vector, that not only embeds the input molecule's structural information but it's also enhanced by its property information.</p>
<p>We have analyzed if our pre-trained model had learned an informative representation that can be readily used for other tasks, even for a single modality. So we only utilized the SMILES encoder of pre-trained SPMM (see Supplementary Figure S3-(c)) and made a benchmark study on nine MoleculeNet ${ }^{42}$ downstream tasks and a Drug-Induced Liver Injury (DILI) prediction task. Each MoleculeNet task is a regression or classification task for pharmaceutical/biochemical applications like solubility, toxicity, and brain penetrability. The DILI classification task was done to overcome the potential limitation of open databases ${ }^{43,44}$ and verify if SPMM could be extended to more complex endpoints. The task is to classify whether the given molecule has a risk of causing liver injury. Since many proposed DILI machine learning models have built their dataset rather than using common benchmarks, we took the dataset preparations from a known publication ${ }^{45}$ and compared the performance with it for a fair evaluation.</p>
<p>Table 2 contains the performance of SPMM and other models for MoleculeNet. Using only</p>
<p>6 BERT encoder layers, SPMM showed comparable performances with state-of-the-art models for all tasks. It achieved the best performance for Clearance, BBBP, and Clintox tasks, showing its capability as a foundation model. We've also observed that the score of our model dramatically decreased without pre-training. SPMM also outperformed the proposed 5-ensemble models on the DILI classification task under the same data preparation, which was not the case for the naive BERT layers without SPMM pre-training.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Dataset <br> #data <br> #task</th>
<th style="text-align: center;">regression[RMSE, $\downarrow$ ]</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">classification[AUROC in $\%$, $\uparrow$ ]</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Delaney ESOL</td>
<td style="text-align: center;">LIPO</td>
<td style="text-align: center;">Freesolv</td>
<td style="text-align: center;">BACE</td>
<td style="text-align: center;">Clearance</td>
<td style="text-align: center;">BBBP</td>
<td style="text-align: center;">BACE</td>
<td style="text-align: center;">Clintox</td>
<td style="text-align: center;">SIDER</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">1128</td>
<td style="text-align: center;">4200</td>
<td style="text-align: center;">642</td>
<td style="text-align: center;">1513</td>
<td style="text-align: center;">837</td>
<td style="text-align: center;">2039</td>
<td style="text-align: center;">1513</td>
<td style="text-align: center;">1478</td>
<td style="text-align: center;">1427</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">27</td>
</tr>
<tr>
<td style="text-align: center;">D-MPNN ${ }^{46}$</td>
<td style="text-align: center;">$1.050 \pm 0.008$</td>
<td style="text-align: center;">$0.683 \pm 0.016$</td>
<td style="text-align: center;">$2.082 \pm 0.082$</td>
<td style="text-align: center;">$2.253^{*}$</td>
<td style="text-align: center;">$49.754^{*}$</td>
<td style="text-align: center;">$71.0 \pm 0.3$</td>
<td style="text-align: center;">$80.9 \pm 0.6$</td>
<td style="text-align: center;">$90.6 \pm 0.6$</td>
<td style="text-align: center;">$57.0 \pm 0.7$</td>
</tr>
<tr>
<td style="text-align: center;">N-GramRF ${ }^{45}$</td>
<td style="text-align: center;">$1.074 \pm 0.107$</td>
<td style="text-align: center;">$0.812 \pm 0.028$</td>
<td style="text-align: center;">$2.688 \pm 0.085$</td>
<td style="text-align: center;">$1.318^{*}$</td>
<td style="text-align: center;">$52.077^{*}$</td>
<td style="text-align: center;">$69.7 \pm 0.6$</td>
<td style="text-align: center;">$77.9 \pm 1.5$</td>
<td style="text-align: center;">$77.5 \pm 4.0$</td>
<td style="text-align: center;">$66.8 \pm 0.7$</td>
</tr>
<tr>
<td style="text-align: center;">N-GramXGB ${ }^{35}$</td>
<td style="text-align: center;">$1.083 \pm 0.082$</td>
<td style="text-align: center;">$2.072 \pm 0.030$</td>
<td style="text-align: center;">$5.061 \pm 0.744$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$69.1 \pm 0.8$</td>
<td style="text-align: center;">$79.1 \pm 1.3$</td>
<td style="text-align: center;">$87.5 \pm 2.7$</td>
<td style="text-align: center;">$65.5 \pm 0.7$</td>
</tr>
<tr>
<td style="text-align: center;">PretrainGNN ${ }^{47}$</td>
<td style="text-align: center;">$1.100 \pm 0.006$</td>
<td style="text-align: center;">$0.739 \pm 0.003$</td>
<td style="text-align: center;">$2.764 \pm 0.002$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$68.7 \pm 1.3$</td>
<td style="text-align: center;">$84.5 \pm 0.7$</td>
<td style="text-align: center;">$72.6 \pm 1.5$</td>
<td style="text-align: center;">$62.7 \pm 0.8$</td>
</tr>
<tr>
<td style="text-align: center;">GROVER $_{\text {Geogr. }}{ }^{30}$</td>
<td style="text-align: center;">$0.895 \pm 0.017$</td>
<td style="text-align: center;">$0.823 \pm 0.010$</td>
<td style="text-align: center;">$2.272 \pm 0.051$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$69.5 \pm 0.1$</td>
<td style="text-align: center;">$81.0 \pm 1.4$</td>
<td style="text-align: center;">$76.2 \pm 3.7$</td>
<td style="text-align: center;">$65.4 \pm 0.1$</td>
</tr>
<tr>
<td style="text-align: center;">ChemRL-GEM ${ }^{48}$</td>
<td style="text-align: center;">$0.798 \pm 0.029$</td>
<td style="text-align: center;">$0.660 \pm 0.008$</td>
<td style="text-align: center;">$1.877 \pm 0.094$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$72.4 \pm 0.4$</td>
<td style="text-align: center;">$85.6 \pm 1.1$</td>
<td style="text-align: center;">$90.1 \pm 1.3$</td>
<td style="text-align: center;">$67.2 \pm 0.4$</td>
</tr>
<tr>
<td style="text-align: center;">ChemBERTa-2 ${ }_{\text {cMTR-77M }}{ }^{27}$</td>
<td style="text-align: center;">$0.889^{*}$</td>
<td style="text-align: center;">$0.798^{*}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$1.363^{*}$</td>
<td style="text-align: center;">$48.515^{*}$</td>
<td style="text-align: center;">$72.8^{*}$</td>
<td style="text-align: center;">$79.9^{*}$</td>
<td style="text-align: center;">$56.3^{*}$</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">MolFormer ${ }^{149}$</td>
<td style="text-align: center;">$0.880 \pm 0.028$</td>
<td style="text-align: center;">$0.700 \pm 0.012$</td>
<td style="text-align: center;">$2.342 \pm 0.052$</td>
<td style="text-align: center;">$1.047 \pm 0.029$</td>
<td style="text-align: center;">$43.175 \pm 1.537$</td>
<td style="text-align: center;">$73.6 \pm 0.8$</td>
<td style="text-align: center;">$86.3 \pm 0.6$</td>
<td style="text-align: center;">$91.2 \pm 1.4$</td>
<td style="text-align: center;">$65.5 \pm 0.2$</td>
</tr>
<tr>
<td style="text-align: center;">SPMM(w/o pre-train)</td>
<td style="text-align: center;">$1.272 \pm 0.015$</td>
<td style="text-align: center;">$1.009 \pm 0.021$</td>
<td style="text-align: center;">$3.018 \pm 0.179$</td>
<td style="text-align: center;">$1.675 \pm 0.010$</td>
<td style="text-align: center;">$53.544 \pm 0.312$</td>
<td style="text-align: center;">$66.6 \pm 0.3$</td>
<td style="text-align: center;">$78.7 \pm 2.6$</td>
<td style="text-align: center;">$76.3 \pm 1.5$</td>
<td style="text-align: center;">$57.1 \pm 1.6$</td>
</tr>
<tr>
<td style="text-align: center;">SPMM</td>
<td style="text-align: center;">$0.818 \pm 0.008$</td>
<td style="text-align: center;">$0.692 \pm 0.008$</td>
<td style="text-align: center;">$1.907 \pm 0.058$</td>
<td style="text-align: center;">$1.096 \pm 0.011$</td>
<td style="text-align: center;">$42.841 \pm 1.251$</td>
<td style="text-align: center;">$74.9 \pm 0.8$</td>
<td style="text-align: center;">$84.8 \pm 0.3$</td>
<td style="text-align: center;">$91.8 \pm 0.9$</td>
<td style="text-align: center;">$65.5 \pm 0.9$</td>
</tr>
</tbody>
</table>
<p>Table 2: Benchmark results on MoleculeNet downstream tasks. The best performance for each task was written in bold, and the second-best performance was underlined. For each task, we fine-tuned our model in four random seeds and recorded the mean and the standard deviation of those results. The benchmark model results were taken from ChemRL-GEM and ChemBERTa-2. *The standard deviation cannot be found in the source of the benchmark results. ${ }^{\dagger}$ Unofficial results, obtained from the official checkpoint under our data preparation.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">model</th>
<th style="text-align: center;">Acc in \%[ $\uparrow$ ]</th>
<th style="text-align: center;">Selectivity in \%[ $\uparrow$ ]</th>
<th style="text-align: center;">Specificity in \%[ $\uparrow$ ]</th>
<th style="text-align: center;">AUROC in \%[ $\uparrow$ ]</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Ai et al. ${ }^{45}$ (best single model on training set)</td>
<td style="text-align: center;">81.1</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">81.5</td>
<td style="text-align: center;">89.6</td>
</tr>
<tr>
<td style="text-align: center;">Ai et al. (5-ensemble)</td>
<td style="text-align: center;">84.3</td>
<td style="text-align: center;">86.9</td>
<td style="text-align: center;">75.4</td>
<td style="text-align: center;">90.4</td>
</tr>
<tr>
<td style="text-align: center;">SPMM(w/o pre-train)</td>
<td style="text-align: center;">72.6</td>
<td style="text-align: center;">70.6</td>
<td style="text-align: center;">79.2</td>
<td style="text-align: center;">82.0</td>
</tr>
<tr>
<td style="text-align: center;">SPMM</td>
<td style="text-align: center;">84.7</td>
<td style="text-align: center;">85.7</td>
<td style="text-align: center;">81.6</td>
<td style="text-align: center;">91.2</td>
</tr>
</tbody>
</table>
<p>Table 3: The DILI classification task performance of Ai et al. ${ }^{45}$ and SPMM. The best performance for each metric was written in bold.</p>
<p>We also trained SPMM for the forward and retro-reaction prediction tasks, which require the model to predict the product SMILES from the reactant SMILES and vice versa. Regarding both tasks as sequence-to-sequence generation, the model pipeline for these reaction prediction tasks is the same as the PV-to-SMILES generation tasks, except the PV encoder is replaced with the SMILES encoder (see Supplementary Figure S3-(d)). The detailed task definition and dataset preparation are described in the Methods section.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">forward prediction</th>
<th style="text-align: center;">molecule modality</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">top-k accuracy in \% [ $\uparrow$ ]</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">string-based graph-based</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{k}=1$</td>
<td style="text-align: center;">$\mathrm{k}=2$</td>
<td style="text-align: center;">$\mathrm{k}=3$</td>
<td style="text-align: center;">$\mathrm{k}=5$</td>
</tr>
<tr>
<td style="text-align: center;">Molecular Transformer ${ }^{50}$</td>
<td style="text-align: center;">O</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">88.7</td>
<td style="text-align: center;">92.1</td>
<td style="text-align: center;">93.1</td>
<td style="text-align: center;">94.2</td>
</tr>
<tr>
<td style="text-align: center;">Augmented Transformer ${ }^{51}$</td>
<td style="text-align: center;">O</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">90.6</td>
<td style="text-align: center;">94.4</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">96.1</td>
</tr>
<tr>
<td style="text-align: center;">Chemformer ${ }_{\text {large }}{ }^{52}$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">91.3</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">93.7</td>
</tr>
<tr>
<td style="text-align: center;">Graph2SMILES ${ }^{53}$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">90.3</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">94.8</td>
</tr>
<tr>
<td style="text-align: center;">MEGAN ${ }^{54}$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">86.3</td>
<td style="text-align: center;">90.3</td>
<td style="text-align: center;">92.4</td>
<td style="text-align: center;">94.0</td>
</tr>
<tr>
<td style="text-align: center;">LocalTransform ${ }^{6}$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">90.8</td>
<td style="text-align: center;">94.8</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">96.3</td>
</tr>
<tr>
<td style="text-align: center;">SPMM</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">91.5</td>
<td style="text-align: center;">93.4</td>
<td style="text-align: center;">94.6</td>
<td style="text-align: center;">95.3</td>
</tr>
<tr>
<td style="text-align: center;">retro-reaction prediction</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">top-k accuracy in \% [ $\uparrow$ ]</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{k}=1$</td>
<td style="text-align: center;">$\mathrm{k}=5$</td>
<td style="text-align: center;">$\mathrm{k}=10$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">SCROP ${ }^{55}$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">43.7</td>
<td style="text-align: center;">65.2</td>
<td style="text-align: center;">68.7</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Two-way Transformer ${ }^{56}$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">47.1</td>
<td style="text-align: center;">73.1</td>
<td style="text-align: center;">76.3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Augmented Transformer ${ }^{51}$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">48.3</td>
<td style="text-align: center;">73.4</td>
<td style="text-align: center;">77.4</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Chemformer ${ }_{\text {large }}{ }^{52}$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">54.3</td>
<td style="text-align: center;">62.3</td>
<td style="text-align: center;">63.0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">SPMM</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">53.0</td>
<td style="text-align: center;">67.4</td>
<td style="text-align: center;">70.3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 4: The performance of SPMM and other works on the forward and retro-reaction prediction task. For the retro-reaction prediction task, we only prepared the benchmark results of string-based models. The highest accuracy is written in bold, and the performance of the runner-up model is underlined. The benchmark model results are from the paper of LocalTransform ${ }^{6}$ and Chemformer ${ }^{52}$.</p>
<p>Table 4 shows the performances of SPMM and other benchmark models on forward and retro-reaction prediction tasks. Although the reaction prediction tasks are not the best scenario for the property-emergence features to play significant roles, SPMM showed the highest top-1 accuracy in the forward-reaction task with a relatively small pre-training data size (i.e. 20M molecules, compared to 100M molecules of Chemformer). SPMM also achieved the second-best top-1 accuracy among the string-based retro-reaction task models.</p>
<h1>Discussion</h1>
<p>In this work, we proposed a transformer-based multimodal chemical foundation model SPMM. The proposed model allows for bidirectional generation/prediction of molecular structure and properties, as well as unimodal tasks like reaction prediction. During the process, we introduced a method of treating property collections as a language so that the model could learn the relationship between SMILES tokens and each property independently. We demonstrated that pre-trained SPMM</p>
<p>showed remarkable performances in problems for interactions between SMILES and PV domains. And not only for multimodal challenges but even its unimodal feature for SMILES, SPMM also provides a useful representation that can be fine-tuned for many molecular downstream tasks. It is important to note that all of these results were obtained with a pre-training of 20 million molecules, which is relatively small compared to other large pre-training approaches and still has room for better performance with more data and parameters. We also note that we've gathered our 53 properties to let them cover the widest range possible, rather than paying the best effort to select the most effective combination of properties. This implies the proposed structure-property multimodal training can be flexibly adopted with different property selections, according to the given specified scenarios.</p>
<p>Despite the noticeable performances of SPMM, it has several chances for improvement. One of those comes from using the SMILES notation. Although SMILES can contain full details about the 2D structure of the molecule, the information on how atoms and bonds are connected only exists implicitly. Also, a slight modification in molecular structure can be a drastic change in SMILES. Graph format is another widely used modality for molecule representation that contains the explicit information of the adjacency matrix, which can be an alternative for SMILES. Another limitation in our current SPMM is that the 53 properties we used happen to be invariant with the changes in the stereochemistry of the given molecule. It is known that considering stereochemistry plays a crucial part in various biochemical tasks. However, the 53 properties we used cannot provide any knowledge about stereochemical information since their values are unchanged in different stereoisomers. This makes the SMILES encoder output of different stereoisomers converge since the contrastive loss aligns them to the same PV feature. We believe this is the prominent factor that lowered the performance of SPMM in MoleculeNet tasks, which could be resolved by using more properties that reflect the molecule's stereochemistry. Moreover, validation through wet-lab experiments to verify the model's predicted/generated properties is another possible further study.</p>
<p>Overcoming these drawbacks of the current study and making the model more applicable to other chemical tasks could be the works for the future.</p>
<p>Nevertheless, we believe that our approach can provide a pre-trained model capable of encompassing each input domain and their multimodal domain simultaneously, which has a vast potential utility. We expect this approach to be applied to more various and practical chemical situations by using broader and richer molecular modalities, and possibly, different biochemical domains like polymers and proteins.</p>
<h1>Methods</h1>
<p>Handling SMILES and property values as a language. Molecules can be represented with various formats such as fingerprints, strings like SMILES, InChI, or a molecular graph. Since these different notations contain almost the same information about complete molecular structure, we employed SMILES to describe a molecule structure. SMILES is a sequence of characters that represents the connection structure of the molecule. Many researchers treat SMILES as a variant of language data and utilize a concept of language models for chemical tasks on SMILES data ${ }^{11,21,57}$.</p>
<p>Figure 6-(a) illustrates our embedding procedure for the input SMILES. The raw SMILES string is tokenized by the tokenizer and embedded by the SMILES encoder with the $[\mathrm{CLS}]_{S}$ token and the [SEP] token. Here, [CLS] token is a special token attached to the beginning of every input sequence ${ }^{58}$. Although the [CLS] token itself doesn't contain any meaning, the bidirectional attention mechanism of the model allows the [CLS] token to contain contextual information of the entire input. Once the model is pre-trained, the [CLS] token output of the given sequence can be considered as an input representation vector and be used for classification/regression downstream tasks, as in many BERT variations for images ${ }^{59,60}$ and VLP ${ }^{27}$.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Embedding process for SMILES and the corresponding PV.</p>
<p>In the SMILES tokenization, our tokenizer tokenizes a given SMILES into fragments that are contained in a prepared token dictionary of 300 subwords. This dictionary was obtained from the pre-training data SMILES corpus by the BPE algorithm ${ }^{61}$, which starts from a set of simple characters and iteratively appends the most frequent token pairs as a merged subword. Being widely adopted for various language models ${ }^{62,63}$, the BPE algorithm has provided a subword dictionary containing common functional groups and substructures like benzene rings, carbonyl groups, twoletter atoms, and amino groups. Compared to naive character-wise tokenization which considers each character as a separate token, the merged subwords help the model's chemical inference for chemical groups and reduce the total number of tokens.</p>
<p>Meanwhile, a set of chemical properties does not change its carrying information by changing the internal order, but they certainly have correlations between the properties. And it is known that a transformer architecture also performs well for different modalities like images, by giving</p>
<p>specific order to its components and treating them as a sequence. For this work, we built a PV for each molecule that contains 53 molecular properties and considered this as a sentence with a length of 53. These properties from the RDKit python module ${ }^{64}$ cover a wide range from simple ones, such as the number of rings and molecular weight, to complex properties like solubility, TPSA, and druggability.</p>
<p>The transformer architecture of our model considers each element of PV as a token to perform the attention mechanism, which is equivalent to regarding PV as a semi-sentence of 53 properties. Although the size of the vocabulary is more limited and their order is fixed compared to natural language, it provides much more precise and compact information about the 53 properties. One benefit of regarding PV as a language is that we do not have to collect all elements to build a valid PV. In contrast to a simple vector input, some property elements can be removed or masked in our approach.</p>
<p>Figure 6-(b) shows our embedding procedure for the input PV. Each property element in the PV is a numerical value and normalized with the mean and standard deviation of that property. The order of these 53 properties is predetermined. Each value in the PV is encoded to a feature vector using a linear layer as a value encoding. Then we randomly replace $50 \%$ of the property features into the [UNK] token, which is the special token utilized to simulate that the property is unknown. This is possible since there is no problem in describing a molecule using only a part of these properties. Random property feature masking prevents the model from overly dependent on the specific property, has the effect of data augmentation, and improves the model's generalization ability. Although every property we used in this work can be easily and thoroughly prepared by the computer, this might not be the case for other properties in real-world situations. SPMM still can be trained when some properties for certain training molecules are not known, by replacing those unknown properties with the [UNK] token. On top of the randomly-masked value encoding,</p>
<p>we added a positional encoding similar to that in BERT. Since a PV explicitly contains the values only, this positional embedding provides information about what property each value corresponds to. Also, because of the pre-defined order of these properties, this position embedding is equivalent to giving a unique index for each property and adding an embedding of that corresponding index. Then we pass the final result to the PV encoder with the $[\mathrm{CLS}]_{P}$ token.</p>
<p>Pre-training objectives. Contrastive learning aims to learn better unimodal representation by aligning the features from different modalities into the same feature space ${ }^{26}$. When the encoded features of [CLS] tokens of SMILES $S$ and PV $P$ are given as $S_{c l s}$ and $P_{c l s}$, we calculate the similarity function $\operatorname{sim}(S, P)$ and $\operatorname{sim}(P, S)$ as:</p>
<p>$$
\operatorname{sim}(S, P)=\left(h_{S}\left(S_{c l s}\right)\right)^{\top} h_{P}\left(P_{c l s}\right), \quad \operatorname{sim}(P, S)=\left(h_{P}\left(P_{c l s}\right)\right)^{\top} h_{S}\left(S_{c l s}\right)
$$</p>
<p>where $h_{S}$ and $h_{P}$ are the linear projection + normalization layer for SMILES and property vector, respectively. Now, for a given pair of $S$ and $P$, we calculate the SMILES-to-PV and PV-toSMILES intermodal similarities as follows ${ }^{26,27}$ :</p>
<p>$$
s_{s 2 p}=\frac{\exp (\operatorname{sim}(S, P) / \tau)}{\sum_{n=1}^{N} \exp \left(\operatorname{sim}\left(S, P_{n}\right) / \tau\right)}, \quad s_{p 2 s}=\frac{\exp (\operatorname{sim}(P, S) / \tau)}{\sum_{m=1}^{M} \exp \left(\operatorname{sim}\left(P, S_{m}\right) / \tau\right)}
$$</p>
<p>where $M$ and $N$ are the total numbers of SMILES and PV used in the loss calculation. Here, $\tau$ is a learnable temperature parameter, which has a sharpening effect by exaggerating the similarity difference. The intramodal similarities can be calculated in the same way.</p>
<p>$$
s_{s 2 s}=\frac{\exp (\operatorname{sim}(S, S) / \tau)}{\sum_{m=1}^{M} \exp \left(\operatorname{sim}\left(S, S_{m}\right) / \tau\right)}, \quad s_{p 2 p}=\frac{\exp (\operatorname{sim}(P, P) / \tau)}{\sum_{n=1}^{N} \exp \left(\operatorname{sim}\left(P, P_{n}\right) / \tau\right)}
$$</p>
<p>The overall contrastive loss is defined using the cross-entropy loss $H$ and one-hot similarity</p>            </div>
        </div>

    </div>
</body>
</html>