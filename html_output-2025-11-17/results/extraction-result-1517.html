<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1517 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1517</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1517</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-29.html">extraction-schema-29</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <p><strong>Paper ID:</strong> paper-a2e951b43b41df4316b6ffd4a56549b04dae5b77</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/a2e951b43b41df4316b6ffd4a56549b04dae5b77" target="_blank">A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS</a></p>
                <p><strong>Paper Venue:</strong> Front. Neurorobot.</p>
                <p><strong>Paper TL;DR:</strong> This paper proposes an implementation of a modern physics engine, which can differentiate control parameters, which is implemented for both CPU and GPU, and shows how such an engine speeds up the optimization process, even for small problems.</p>
                <p><strong>Paper Abstract:</strong> One of the most important fields in robotics is the optimization of controllers. Currently, robots are often treated as a black box in this optimization process, which is the reason why derivative-free optimization methods such as evolutionary algorithms or reinforcement learning are omnipresent. When gradient-based methods are used, models are kept small or rely on finite difference approximations for the Jacobian. This method quickly grows expensive with increasing numbers of parameters, such as found in deep learning. We propose an implementation of a modern physics engine, which can differentiate control parameters. This engine is implemented for both CPU and GPU. Firstly, this paper shows how such an engine speeds up the optimization process, even for small problems. Furthermore, it explains why this is an alternative approach to deep Q-learning, for using deep learning in robotics. Finally, we argue that this is a big step for deep learning in robotics, as it opens up new possibilities to optimize robots, both in hardware and software.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1517.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1517.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Degrave et al. differentiable physics engine</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>A Differentiable Physics Engine implemented in Theano (Degrave et al., this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A custom 3D rigid-body physics engine implemented as a Theano computational graph that is fully differentiable end-to-end (including dynamics and a renderer), designed to backpropagate gradients through physics for training neural-network controllers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Custom differentiable 3D rigid-body physics engine (Theano)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>3D rigid-body engine implemented as algebraic expressions in Theano, compiled for CPU/GPU; simulates rigid bodies with constraints solved as a linear complementarity problem (LCP), semi-implicit Euler integration, soft constraints, servo motor models, and a differentiable ray-tracing renderer for cameras.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotics (with differentiable rendering for vision)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-to-high fidelity rigid-body dynamics with several simplifying restrictions (supports impulse-based rigid-body dynamics and accurate servo models, but constrained collision representation and limited branching).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Models 6-DOF rigid bodies, constraint solving via LCP + Gauss-Seidel projection, semi-implicit Euler integration, softened constraints; explicit servo motor model (gain, max torque, max velocity); uses sphere-based collision primitives and renormalized rotation matrices; differentiable ray-tracing renderer with bilinear texture interpolation; discrete time steps (examples used 0.01 s). Limitations: no general branching on GPU (restricted Theano operations), collision detection limited to spheres/plane (not arbitrary polyhedra), some operations approximated to remain in differentiable operator set.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Neural-network controllers (various sizes) trained via BPTT through the differentiable engine</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Deep neural network controllers (feedforward and recurrent variants) of sizes from ~17k to >2M parameters; also convolutional networks for vision inputs; trained with gradient-based optimizers (Adam) using backpropagation through time through the physics engine and renderer.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Control/scientific reasoning tasks in simulated robotics: e.g., ball-throw initial condition optimization, robot arm reaching (fixed and random targets), quadruped gait optimization, inverted pendulum swing-up from visual (pixel) input.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td>Ball throwing: gradient descent reached target in 88 iterations (16.3 s) vs CMA-ES 2,422 iterations (59.9 s); Robot arm fixed reach: within 4 cm in 100 evaluations, 1 cm in 150 evaluations; Robot arm random reach (2.1M-param controller, batch 128): 576 updates to <10 cm, 2,563 updates to <5 cm; Quadruped gait: 500 model evaluations -> 1.17 m/s; Pendulum with camera: swing-up learned after 2,420 episodes of 3 s (training took 15 h on 1 GPU), resulting controller keeps pendulum stable >1 min.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real-world physical counterparts (discussed as transfer target; no executed physical transfer experiments in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Authors conjecture that model gradients are noisy but still informative for real-world transfer; they recommend averaging gradients over batches of slightly different simulated robots to improve transfer and avoid bifurcations, and emphasize that differentiable rendering is necessary when training vision-based controllers.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Practical limitations noted: restricted collision shapes (sphere approximations) may miss geometric fidelity; Theano GPU restrictions required removing branching which constrains expressiveness; no empirical sim-to-real transfer reported, so potential failures on real hardware are discussed qualitatively (no quantitative failure cases).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS', 'publication_date_yy_mm': '2016-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1517.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1517.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Differentiable camera / renderer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ray-tracing differentiable camera renderer (implemented in the custom engine)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A differentiable ray-tracing renderer that projects 3D scene geometry and textures to 2D image frames with bilinear texture interpolation so image pixels have non-zero gradients w.r.t. scene and robot state; used as the sole sensor for a vision-based controller.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Differentiable ray-tracing renderer (part of the custom engine)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Pinhole camera model with ray casting; intersects rays with scene geometry and samples textures with bilinear interpolation to produce differentiable pixel outputs usable as inputs to convolutional neural networks.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>computer vision / robotics (vision-based control)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-fidelity visual rendering sufficient for learning vision-based control tasks; not a photorealistic renderer but provides continuous differentiable pixel outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Uses ray casting per pixel, chooses nearest intersection, bilinear interpolation of texture arrays to ensure non-zero derivatives; designed for differentiability rather than full photorealism; integrated with dynamics so gradients flow through renderer to state.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Vision-based deep controller for inverted pendulum</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Convolutional neural network (part of a memoryless deep controller using current image plus two past frames) with ~1,065,888 parameters trained end-to-end with gradients through renderer and dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>From-pixels control: swing up and stabilize an inverted pendulum using only camera frames as sensor input (learning from pixels).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td>Controller learned to swing up and stabilize after 2,420 episodes of 3 s each; total optimization took 15 h on 1 GPU; resulting controller kept pendulum stable for >1 minute in simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real-world pendulum-cart system (discussed; the camera model was built to match laboratory system), but no real-world transfer experiments reported.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper emphasizes that differentiable renderer is necessary to learn vision-based controllers end-to-end (states-to-pixels gradients would be zero with pixelated zero-order textures), implying a minimum requirement of continuous interpolation in renderer.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>No empirical failure reported; authors note that non-differentiable rasterization or zero-order textures would yield zero gradients and prevent learning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS', 'publication_date_yy_mm': '2016-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1517.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1517.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MuJoCo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MuJoCo: a physics engine for model-based control (Todorov et al., 2012)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A modern rigid-body physics engine used in robotics and control that can provide gradients through state transitions but (as discussed) cannot provide derivatives w.r.t. model parameters or differentiate through external renderers in the way the authors implement.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>mujoco: a physics engine for modelbased control</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>MuJoCo</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A high-performance rigid-body physics engine for model-based control and optimization; widely used in robotics research for simulated dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>high-fidelity rigid-body dynamics specialized for control and optimization; accurate contact and actuator models relative to common engines.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Implements contact dynamics and can compute gradients between actions and states (per authors' summary), but (per paper) does not provide analytic derivatives w.r.t. model parameters and does not differentiate through renderers.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper contrasts MuJoCo's limited gradient capabilities (actions->states but not model parameters) with the authors' fully differentiable approach; no quantitative fidelity comparison performed.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Noted limitation: cannot find derivatives w.r.t. model parameters and can't differentiate through renderers (so end-to-end vision+physics training is not possible in standard MuJoCo per authors).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS', 'publication_date_yy_mm': '2016-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1517.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1517.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Standard 3D rigid-body engines (PhysX/Bullet/Havok/ODE)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PhysX, Bullet, Havok, ODE (3D rigid-body engines derived from MathEngine principles)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Common general-purpose rigid-body simulation engines used in robotics and games; they implement impulse-based contact, constraint solving (LCP), and semi-implicit integration but are generally treated as non-differentiable black boxes for controller optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Simulation tools for model-based robotics: comparison of bullet, havok, mujoco, ode, and physx</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>PhysX / Bullet / Havok / ODE (general-purpose 3D rigid-body engines)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>3D rigid-body simulators where bodies have 6 DOF, constraints define relations, impulses applied and positions constrained to prevent penetration; LCP solved, integrated with semi-implicit Euler; commonly used in robotics and game engines.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>varied (typically medium-to-high fidelity for rigid-body and contact dynamics depending on configuration), but usually non-differentiable for optimization of model parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Impulse-based velocity stepping, constraint softening to maintain numerical stability, Gauss-Seidel projection solvers for LCP, semi-implicit Euler integration; collision detection for general geometry (often involving branching), actuator approximations vary by engine.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Authors note these engines are typically non-differentiable and used as black boxes for derivative-free optimization; they motivated building a differentiable engine to enable gradient-based training.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Paper describes the general limitation for gradient-based optimization: inability to compute derivatives w.r.t. model parameters limits use of gradient methods for controller/hardware optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS', 'publication_date_yy_mm': '2016-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1517.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1517.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adjoint optimization (thermodynamics)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>A general optimization method using adjoint equation for solving multidimensional inverse heat conduction (Jarny et al., 1991)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Adjoint-based optimization methods (cited) used in thermodynamics inverse problems to compute gradients efficiently with respect to many parameters; referenced as prior art similar in spirit to differentiable simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A general optimization method using adjoint equation for solving multidimensional inverse heat conduction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Adjoint-based PDE solvers (thermodynamics inverse heat conduction applications)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Adjoint-method frameworks that compute gradients of PDE-constrained objectives (e.g., heat conduction) enabling efficient parameter optimization in thermodynamics problems.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>thermodynamics / inverse heat conduction</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>high-fidelity PDE-based simulation typically used in adjoint optimization for thermodynamic problems (domain-specific numerical solvers).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Solves PDEs for heat conduction and their adjoint equations to obtain gradients; high numerical fidelity dependent on PDE discretization and solver accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Inverse heat conduction / optimization of thermodynamic systems (as referenced by authors).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Referenced as an established adjoint optimization application in thermodynamics; no details in this paper about minimal fidelity or transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS', 'publication_date_yy_mm': '2016-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1517.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1517.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adjoint optimization (fluid dynamics)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>An aerodynamic optimization method based on the inverse problem adjoint equations (Iollo et al., 2001)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Adjoint methods applied to fluid-dynamics (aerodynamic) optimization problems are cited as related approaches for computing analytic gradients through complex physics solvers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An aerodynamic optimization method based on the inverse problem adjoint equations</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Adjoint-method based fluid-dynamics solvers</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>PDE-based fluid dynamics solvers that use adjoint equations to obtain gradients for aerodynamic optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>fluid dynamics / aerodynamics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>high-fidelity PDE-based simulation (Navierâ€“Stokes or reduced models) used with adjoint gradient methods in CFD optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Adjoint solutions of fluid PDEs provide gradients; fidelity depends on solver, turbulence models, discretization; paper only references the technique as prior art.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Aerodynamic optimization via inverse/adjoint problem formulations (as referenced).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Referenced as related methodology; no further discussion in this paper about minimal fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS', 'publication_date_yy_mm': '2016-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1517.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1517.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Spring-damper differentiable models (prior)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Differentiable spring-damper simulation approaches (Hermans et al., 2014 and prior work)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior differentiable simulation approaches based on spring-damper systems in 2D and 3D are cited as earlier examples of differentiable physics modeling for optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Automated design of complex dynamic systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Spring-damper differentiable simulators</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Simpler physics models using spring-damper dynamics that had been implemented with differentiability to enable gradient-based optimization of dynamic systems.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotics / dynamical systems</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>lower/medium fidelity compared to rigid-body engines (spring-damper abstractions rather than impulse-based rigid-body contact), but fully differentiable.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Spring-damper approximations to contacts and dynamics; likely simpler collision/interaction models enabling analytic gradients with less complexity than full rigid-body LCP solvers.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Automated design and optimization of dynamic systems (prior examples cited).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper notes these prior approaches are similar in spirit but modern robotics engines are not based on spring-damper systems; no quantitative fidelity comparison in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS', 'publication_date_yy_mm': '2016-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>mujoco: a physics engine for modelbased control <em>(Rating: 2)</em></li>
                <li>Simulation tools for model-based robotics: comparison of bullet, havok, mujoco, ode, and physx <em>(Rating: 2)</em></li>
                <li>Automated design of complex dynamic systems <em>(Rating: 2)</em></li>
                <li>A general optimization method using adjoint equation for solving multidimensional inverse heat conduction <em>(Rating: 1)</em></li>
                <li>An aerodynamic optimization method based on the inverse problem adjoint equations <em>(Rating: 1)</em></li>
                <li>Transfer from simulation to real world through learning deep inverse dynamics model <em>(Rating: 1)</em></li>
                <li>Resilient machines through continuous self-modeling <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1517",
    "paper_id": "paper-a2e951b43b41df4316b6ffd4a56549b04dae5b77",
    "extraction_schema_id": "extraction-schema-29",
    "extracted_data": [
        {
            "name_short": "Degrave et al. differentiable physics engine",
            "name_full": "A Differentiable Physics Engine implemented in Theano (Degrave et al., this paper)",
            "brief_description": "A custom 3D rigid-body physics engine implemented as a Theano computational graph that is fully differentiable end-to-end (including dynamics and a renderer), designed to backpropagate gradients through physics for training neural-network controllers.",
            "citation_title": "here",
            "mention_or_use": "use",
            "simulator_name": "Custom differentiable 3D rigid-body physics engine (Theano)",
            "simulator_description": "3D rigid-body engine implemented as algebraic expressions in Theano, compiled for CPU/GPU; simulates rigid bodies with constraints solved as a linear complementarity problem (LCP), semi-implicit Euler integration, soft constraints, servo motor models, and a differentiable ray-tracing renderer for cameras.",
            "scientific_domain": "mechanics / robotics (with differentiable rendering for vision)",
            "fidelity_level": "medium-to-high fidelity rigid-body dynamics with several simplifying restrictions (supports impulse-based rigid-body dynamics and accurate servo models, but constrained collision representation and limited branching).",
            "fidelity_characteristics": "Models 6-DOF rigid bodies, constraint solving via LCP + Gauss-Seidel projection, semi-implicit Euler integration, softened constraints; explicit servo motor model (gain, max torque, max velocity); uses sphere-based collision primitives and renormalized rotation matrices; differentiable ray-tracing renderer with bilinear texture interpolation; discrete time steps (examples used 0.01 s). Limitations: no general branching on GPU (restricted Theano operations), collision detection limited to spheres/plane (not arbitrary polyhedra), some operations approximated to remain in differentiable operator set.",
            "model_or_agent_name": "Neural-network controllers (various sizes) trained via BPTT through the differentiable engine",
            "model_description": "Deep neural network controllers (feedforward and recurrent variants) of sizes from ~17k to &gt;2M parameters; also convolutional networks for vision inputs; trained with gradient-based optimizers (Adam) using backpropagation through time through the physics engine and renderer.",
            "reasoning_task": "Control/scientific reasoning tasks in simulated robotics: e.g., ball-throw initial condition optimization, robot arm reaching (fixed and random targets), quadruped gait optimization, inverted pendulum swing-up from visual (pixel) input.",
            "training_performance": "Ball throwing: gradient descent reached target in 88 iterations (16.3 s) vs CMA-ES 2,422 iterations (59.9 s); Robot arm fixed reach: within 4 cm in 100 evaluations, 1 cm in 150 evaluations; Robot arm random reach (2.1M-param controller, batch 128): 576 updates to &lt;10 cm, 2,563 updates to &lt;5 cm; Quadruped gait: 500 model evaluations -&gt; 1.17 m/s; Pendulum with camera: swing-up learned after 2,420 episodes of 3 s (training took 15 h on 1 GPU), resulting controller keeps pendulum stable &gt;1 min.",
            "transfer_target": "Real-world physical counterparts (discussed as transfer target; no executed physical transfer experiments in this paper)",
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "Authors conjecture that model gradients are noisy but still informative for real-world transfer; they recommend averaging gradients over batches of slightly different simulated robots to improve transfer and avoid bifurcations, and emphasize that differentiable rendering is necessary when training vision-based controllers.",
            "failure_cases": "Practical limitations noted: restricted collision shapes (sphere approximations) may miss geometric fidelity; Theano GPU restrictions required removing branching which constrains expressiveness; no empirical sim-to-real transfer reported, so potential failures on real hardware are discussed qualitatively (no quantitative failure cases).",
            "uuid": "e1517.0",
            "source_info": {
                "paper_title": "A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS",
                "publication_date_yy_mm": "2016-11"
            }
        },
        {
            "name_short": "Differentiable camera / renderer",
            "name_full": "Ray-tracing differentiable camera renderer (implemented in the custom engine)",
            "brief_description": "A differentiable ray-tracing renderer that projects 3D scene geometry and textures to 2D image frames with bilinear texture interpolation so image pixels have non-zero gradients w.r.t. scene and robot state; used as the sole sensor for a vision-based controller.",
            "citation_title": "here",
            "mention_or_use": "use",
            "simulator_name": "Differentiable ray-tracing renderer (part of the custom engine)",
            "simulator_description": "Pinhole camera model with ray casting; intersects rays with scene geometry and samples textures with bilinear interpolation to produce differentiable pixel outputs usable as inputs to convolutional neural networks.",
            "scientific_domain": "computer vision / robotics (vision-based control)",
            "fidelity_level": "medium-fidelity visual rendering sufficient for learning vision-based control tasks; not a photorealistic renderer but provides continuous differentiable pixel outputs.",
            "fidelity_characteristics": "Uses ray casting per pixel, chooses nearest intersection, bilinear interpolation of texture arrays to ensure non-zero derivatives; designed for differentiability rather than full photorealism; integrated with dynamics so gradients flow through renderer to state.",
            "model_or_agent_name": "Vision-based deep controller for inverted pendulum",
            "model_description": "Convolutional neural network (part of a memoryless deep controller using current image plus two past frames) with ~1,065,888 parameters trained end-to-end with gradients through renderer and dynamics.",
            "reasoning_task": "From-pixels control: swing up and stabilize an inverted pendulum using only camera frames as sensor input (learning from pixels).",
            "training_performance": "Controller learned to swing up and stabilize after 2,420 episodes of 3 s each; total optimization took 15 h on 1 GPU; resulting controller kept pendulum stable for &gt;1 minute in simulation.",
            "transfer_target": "Real-world pendulum-cart system (discussed; the camera model was built to match laboratory system), but no real-world transfer experiments reported.",
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "Paper emphasizes that differentiable renderer is necessary to learn vision-based controllers end-to-end (states-to-pixels gradients would be zero with pixelated zero-order textures), implying a minimum requirement of continuous interpolation in renderer.",
            "failure_cases": "No empirical failure reported; authors note that non-differentiable rasterization or zero-order textures would yield zero gradients and prevent learning.",
            "uuid": "e1517.1",
            "source_info": {
                "paper_title": "A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS",
                "publication_date_yy_mm": "2016-11"
            }
        },
        {
            "name_short": "MuJoCo",
            "name_full": "MuJoCo: a physics engine for model-based control (Todorov et al., 2012)",
            "brief_description": "A modern rigid-body physics engine used in robotics and control that can provide gradients through state transitions but (as discussed) cannot provide derivatives w.r.t. model parameters or differentiate through external renderers in the way the authors implement.",
            "citation_title": "mujoco: a physics engine for modelbased control",
            "mention_or_use": "mention",
            "simulator_name": "MuJoCo",
            "simulator_description": "A high-performance rigid-body physics engine for model-based control and optimization; widely used in robotics research for simulated dynamics.",
            "scientific_domain": "mechanics / robotics",
            "fidelity_level": "high-fidelity rigid-body dynamics specialized for control and optimization; accurate contact and actuator models relative to common engines.",
            "fidelity_characteristics": "Implements contact dynamics and can compute gradients between actions and states (per authors' summary), but (per paper) does not provide analytic derivatives w.r.t. model parameters and does not differentiate through renderers.",
            "model_or_agent_name": null,
            "model_description": null,
            "reasoning_task": null,
            "training_performance": null,
            "transfer_target": null,
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "Paper contrasts MuJoCo's limited gradient capabilities (actions-&gt;states but not model parameters) with the authors' fully differentiable approach; no quantitative fidelity comparison performed.",
            "failure_cases": "Noted limitation: cannot find derivatives w.r.t. model parameters and can't differentiate through renderers (so end-to-end vision+physics training is not possible in standard MuJoCo per authors).",
            "uuid": "e1517.2",
            "source_info": {
                "paper_title": "A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS",
                "publication_date_yy_mm": "2016-11"
            }
        },
        {
            "name_short": "Standard 3D rigid-body engines (PhysX/Bullet/Havok/ODE)",
            "name_full": "PhysX, Bullet, Havok, ODE (3D rigid-body engines derived from MathEngine principles)",
            "brief_description": "Common general-purpose rigid-body simulation engines used in robotics and games; they implement impulse-based contact, constraint solving (LCP), and semi-implicit integration but are generally treated as non-differentiable black boxes for controller optimization.",
            "citation_title": "Simulation tools for model-based robotics: comparison of bullet, havok, mujoco, ode, and physx",
            "mention_or_use": "mention",
            "simulator_name": "PhysX / Bullet / Havok / ODE (general-purpose 3D rigid-body engines)",
            "simulator_description": "3D rigid-body simulators where bodies have 6 DOF, constraints define relations, impulses applied and positions constrained to prevent penetration; LCP solved, integrated with semi-implicit Euler; commonly used in robotics and game engines.",
            "scientific_domain": "mechanics / robotics",
            "fidelity_level": "varied (typically medium-to-high fidelity for rigid-body and contact dynamics depending on configuration), but usually non-differentiable for optimization of model parameters.",
            "fidelity_characteristics": "Impulse-based velocity stepping, constraint softening to maintain numerical stability, Gauss-Seidel projection solvers for LCP, semi-implicit Euler integration; collision detection for general geometry (often involving branching), actuator approximations vary by engine.",
            "model_or_agent_name": null,
            "model_description": null,
            "reasoning_task": null,
            "training_performance": null,
            "transfer_target": null,
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "Authors note these engines are typically non-differentiable and used as black boxes for derivative-free optimization; they motivated building a differentiable engine to enable gradient-based training.",
            "failure_cases": "Paper describes the general limitation for gradient-based optimization: inability to compute derivatives w.r.t. model parameters limits use of gradient methods for controller/hardware optimization.",
            "uuid": "e1517.3",
            "source_info": {
                "paper_title": "A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS",
                "publication_date_yy_mm": "2016-11"
            }
        },
        {
            "name_short": "Adjoint optimization (thermodynamics)",
            "name_full": "A general optimization method using adjoint equation for solving multidimensional inverse heat conduction (Jarny et al., 1991)",
            "brief_description": "Adjoint-based optimization methods (cited) used in thermodynamics inverse problems to compute gradients efficiently with respect to many parameters; referenced as prior art similar in spirit to differentiable simulation.",
            "citation_title": "A general optimization method using adjoint equation for solving multidimensional inverse heat conduction",
            "mention_or_use": "mention",
            "simulator_name": "Adjoint-based PDE solvers (thermodynamics inverse heat conduction applications)",
            "simulator_description": "Adjoint-method frameworks that compute gradients of PDE-constrained objectives (e.g., heat conduction) enabling efficient parameter optimization in thermodynamics problems.",
            "scientific_domain": "thermodynamics / inverse heat conduction",
            "fidelity_level": "high-fidelity PDE-based simulation typically used in adjoint optimization for thermodynamic problems (domain-specific numerical solvers).",
            "fidelity_characteristics": "Solves PDEs for heat conduction and their adjoint equations to obtain gradients; high numerical fidelity dependent on PDE discretization and solver accuracy.",
            "model_or_agent_name": null,
            "model_description": null,
            "reasoning_task": "Inverse heat conduction / optimization of thermodynamic systems (as referenced by authors).",
            "training_performance": null,
            "transfer_target": null,
            "transfer_performance": null,
            "compares_fidelity_levels": null,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "Referenced as an established adjoint optimization application in thermodynamics; no details in this paper about minimal fidelity or transfer.",
            "failure_cases": "",
            "uuid": "e1517.4",
            "source_info": {
                "paper_title": "A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS",
                "publication_date_yy_mm": "2016-11"
            }
        },
        {
            "name_short": "Adjoint optimization (fluid dynamics)",
            "name_full": "An aerodynamic optimization method based on the inverse problem adjoint equations (Iollo et al., 2001)",
            "brief_description": "Adjoint methods applied to fluid-dynamics (aerodynamic) optimization problems are cited as related approaches for computing analytic gradients through complex physics solvers.",
            "citation_title": "An aerodynamic optimization method based on the inverse problem adjoint equations",
            "mention_or_use": "mention",
            "simulator_name": "Adjoint-method based fluid-dynamics solvers",
            "simulator_description": "PDE-based fluid dynamics solvers that use adjoint equations to obtain gradients for aerodynamic optimization.",
            "scientific_domain": "fluid dynamics / aerodynamics",
            "fidelity_level": "high-fidelity PDE-based simulation (Navierâ€“Stokes or reduced models) used with adjoint gradient methods in CFD optimization.",
            "fidelity_characteristics": "Adjoint solutions of fluid PDEs provide gradients; fidelity depends on solver, turbulence models, discretization; paper only references the technique as prior art.",
            "model_or_agent_name": null,
            "model_description": null,
            "reasoning_task": "Aerodynamic optimization via inverse/adjoint problem formulations (as referenced).",
            "training_performance": null,
            "transfer_target": null,
            "transfer_performance": null,
            "compares_fidelity_levels": null,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "Referenced as related methodology; no further discussion in this paper about minimal fidelity.",
            "failure_cases": "",
            "uuid": "e1517.5",
            "source_info": {
                "paper_title": "A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS",
                "publication_date_yy_mm": "2016-11"
            }
        },
        {
            "name_short": "Spring-damper differentiable models (prior)",
            "name_full": "Differentiable spring-damper simulation approaches (Hermans et al., 2014 and prior work)",
            "brief_description": "Prior differentiable simulation approaches based on spring-damper systems in 2D and 3D are cited as earlier examples of differentiable physics modeling for optimization.",
            "citation_title": "Automated design of complex dynamic systems",
            "mention_or_use": "mention",
            "simulator_name": "Spring-damper differentiable simulators",
            "simulator_description": "Simpler physics models using spring-damper dynamics that had been implemented with differentiability to enable gradient-based optimization of dynamic systems.",
            "scientific_domain": "mechanics / robotics / dynamical systems",
            "fidelity_level": "lower/medium fidelity compared to rigid-body engines (spring-damper abstractions rather than impulse-based rigid-body contact), but fully differentiable.",
            "fidelity_characteristics": "Spring-damper approximations to contacts and dynamics; likely simpler collision/interaction models enabling analytic gradients with less complexity than full rigid-body LCP solvers.",
            "model_or_agent_name": null,
            "model_description": null,
            "reasoning_task": "Automated design and optimization of dynamic systems (prior examples cited).",
            "training_performance": null,
            "transfer_target": null,
            "transfer_performance": null,
            "compares_fidelity_levels": null,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "Paper notes these prior approaches are similar in spirit but modern robotics engines are not based on spring-damper systems; no quantitative fidelity comparison in this paper.",
            "failure_cases": "",
            "uuid": "e1517.6",
            "source_info": {
                "paper_title": "A DIFFERENTIABLE PHYSICS ENGINE FOR DEEP LEARNING IN ROBOTICS",
                "publication_date_yy_mm": "2016-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "mujoco: a physics engine for modelbased control",
            "rating": 2
        },
        {
            "paper_title": "Simulation tools for model-based robotics: comparison of bullet, havok, mujoco, ode, and physx",
            "rating": 2
        },
        {
            "paper_title": "Automated design of complex dynamic systems",
            "rating": 2
        },
        {
            "paper_title": "A general optimization method using adjoint equation for solving multidimensional inverse heat conduction",
            "rating": 1
        },
        {
            "paper_title": "An aerodynamic optimization method based on the inverse problem adjoint equations",
            "rating": 1
        },
        {
            "paper_title": "Transfer from simulation to real world through learning deep inverse dynamics model",
            "rating": 1
        },
        {
            "paper_title": "Resilient machines through continuous self-modeling",
            "rating": 1
        }
    ],
    "cost": 0.015426249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>A Differentiable Physics Engine for Deep Learning in Robotics</h1>
<p>Jonas Degrave ${ }^{1 * *}$, Michiel Hermans ${ }^{2 \dagger}$, Joni Dambre ${ }^{1}$ and Francis wyffels ${ }^{1}$<br>${ }^{1}$ IDLab-AIRO, Department of Electronics and Information Systems, Ghent University - imec, Ghent, Belgium, ${ }^{2}$ Independent Researcher, Ghent, Belgium</p>
<h2>OPEN ACCESS</h2>
<p>Edited by:
Florian RÃ¶hrbein,
Technische UniversitÃ¤t MÃ¼nchen, Germany
Reviewed by:
Eiji Uchibe,
Advanced Telecommunications
Research Institute International (ATR),
Japan
Keyan Ghazi-Zahedi,
Max-Planck-Institut fÃ¼r Mathematik in den Naturwissenschaften, Germany
Jose De Jesus Rubio,
Instituto PolitÃ©cnico Nacional, Mexico
*Correspondence:
Jonas Degrave
jonas.degrave@ugent.be
â€  Present Address: Jonas Degrave, Deepmind, London, United Kingdom Michiel Hermans, ScriptBook NV, Antwerp, Belgium</p>
<p>Received: 07 June 2018
Accepted: 11 February 2019
Published: 07 March 2019
Citation:
Degrave J, Hermans M, Dambre J and wyffels $F$ (2019) A Differentiable Physics Engine for Deep Learning in Robotics. Front. Neurorobot. 13:6. doi: 10.3389/fnbot. 2019.00006</p>
<p>An important field in robotics is the optimization of controllers. Currently, robots are often treated as a black box in this optimization process, which is the reason why derivative-free optimization methods such as evolutionary algorithms or reinforcement learning are omnipresent. When gradient-based methods are used, models are kept small or rely on finite difference approximations for the Jacobian. This method quickly grows expensive with increasing numbers of parameters, such as found in deep learning. We propose the implementation of a modern physics engine, which can differentiate control parameters. This engine is implemented for both CPU and GPU. Firstly, this paper shows how such an engine speeds up the optimization process, even for small problems. Furthermore, it explains why this is an alternative approach to deep Q-learning, for using deep learning in robotics. Finally, we argue that this is a big step for deep learning in robotics, as it opens up new possibilities to optimize robots, both in hardware and software.</p>
<p>Keywords: differentiable physics engine, deep learning, gradient descent, neural network controller, robotics</p>
<h2>1. INTRODUCTION</h2>
<p>To solve tasks efficiently, robots require an optimization of their control system. This optimization process can be done in automated testbeds (Degrave et al., 2015), but typically these controllers are optimized in simulation. Standard methods (Aguilar-IbaÃ±ez, 2017; Meda-Campana, 2018) to optimize these controllers include particle swarms, reinforcement learning, genetic algorithms, and evolutionary strategies. These are all derivative-free methods.</p>
<p>A recently popular alternative approach is to use deep Q-learning, a reinforcement learning algorithm. This method requires a lot of evaluations in order to train the many parameters (Levine et al., 2018). However, deep learning experience has taught us that optimizing with a gradient is often faster and more efficient. This fact is especially true when there are a lot of parameters, as is common in deep learning. However, in the optimization processes for control systems, the robot is almost exclusively treated as a non-differentiable black box. The reason for this is that the robot in hardware is not differentiable, nor are current physics engines able to provide the gradient of the robot models. The resulting need for derivative-free optimization approaches limits both the optimization speed and the number of parameters in the controllers. One could tackle this issue by fitting a neural network model and using its gradient (Grzeszczuk et al., 1998), but those gradients tend to be poor a approximations for the gradient of the original system.</p>
<p>Recent physics engines, such as mujoco (Todorov et al., 2012), can derive gradients through the model of a robot. However, they can at most evaluate gradients between actions and states in the transitions of the model, and cannot find the derivatives with respect to model parameters.</p>
<p>In this paper, we suggest an alternative approach, by introducing a differentiable physics engine with analytical gradients. This idea is not novel. It has been done before with spring-damper models in 2D and 3D (Hermans et al., 2014). This technique is also similar to adjoint optimization, a method widely used in various applications such as thermodynamics (Jarny et al., 1991) and fluid dynamics (Iollo et al., 2001). However, modern engines to model robotics are not based on springdamper systems. The most commonly used ones are 3D rigid body engines, which rely on impulse-based velocity stepping methods (Erez et al., 2015). In this paper, we test whether these engines are also differentiable and whether this gradient is computationally tractable. We will show how this method does speed up the optimization process tremendously, and give some examples where we optimize deep learned neural network controllers with millions of parameters.</p>
<h2>2. MATERIALS AND METHODS</h2>
<h3>2.1. A 3D Rigid Body Engine</h3>
<p>The goal is to implement a modern 3D rigid body engine, in which parameters can be differentiated with respect to the fitness a robot achieves in a simulation, such that these parameters can be optimized with methods based on gradient descent.</p>
<p>The most frequently used simulation tools for model-based robotics, such as PhysX, Bullet, Havok, and ODE, go back to MathEngine (Erez et al., 2015). These tools are all 3D rigid body engines, where bodies have 6 degrees of freedom, and the relations between them are defined as constraints. These bodies exert impulses on each other, but their positions are constrained, e.g., to prevent the bodies from penetrating each other. The velocities, positions and constraints of the rigid bodies define a linear complementarity problem (LCP) (Chappuis, 2013), which is then solved using a Gauss-Seidel projection (GSP) method (Jourdan et al., 1998). The solution of this problem are the new velocities of the bodies, which are then integrated by semi-implicit Euler integration to get the new positions (Stewart and Trinkle, 2000). This system is not always numerically stable. Therefore, the constraints are usually softened (Catto, 2009).</p>
<p>The recent growth of automatic differentiation libraries, such as Theano (Al-Rfou et al., 2016), Caffe (Jia et al., 2014), and Tensorflow (Abadi et al., 2016), has allowed for efficient differentiation of remarkably complex functions before (Degrave et al., 2016a). Therefore, we implemented such a physics engine from scratch as a mathematical expression in Theano, a software library which does automatic evaluation and differentiation of expressions with a focus on deep learning. The resulting computational graph to evaluate this expression is then compiled for both CPU and GPU. To be able to compile for GPU however, we had to limit our implementation to a restricted set of elementary operations. The range of implementable functions is therefore severely capped. However, since the analytic gradient is determined automatically, the complexity of correctly implementing the differentiation is removed entirely.</p>
<p>One of these limitations with this restricted set of operations, is the limited support for conditionals. Therefore, we needed to implement our physics engine without branching, as this is
not yet available in Theano for GPU. Note that newer systems for automatic differentiation such as PyTorch (Paszke et al., 2017) do allow branching. Therefore, we made sacrificed some abilities of our system. For instance, our system only allows for contact constraints between different spheres or between spheres and the ground plane. Collision detection algorithms for cubes typically have a lot of branching (Mirtich, 1998). However, this sphere based approach can in principle be extended to any other shape (Hubbard, 1996). On the other hand, we did implement a rather accurate model of servo motors, with gain, maximal torque, and maximal velocity parameters.</p>
<p>Another design choice was to use rotation matrices rather than the more common quaternions for representing rotations. Consequently, the states of the bodies are larger, but the operations required are matrix multiplications. This design reduced the complexity of the graph. However, cumulative operations on a rotation matrix might move the rotation matrix away from orthogonality. To correct for this, we renormalize our matrix with the update equation (Premerlani and Bizard, 2009):</p>
<p>$$
A^{\prime}=\frac{3 A-A \circ(A \cdot A)}{2}
$$</p>
<p>where $A^{\prime}$ is the renormalized version of the rotation matrix A. "â—‹" denotes the elementwise multiplication, and "." the matrix multiplication.</p>
<p>These design decisions are the most important aspects of difference with the frequently used simulation tools. In the following section, we will evaluate our physics simulator on some different problems. We take a look at the speed of computation and the number of evaluations required before the parameters of are optimized.</p>
<h3>2.1.1. Throwing a Ball</h3>
<p>To test our engine, we implemented the model of a giant soccer ball in the physics engine, as shown in Figure 3A. The ball has a 1 m diameter, a friction of $\mu=1.0$ and restitution $e=0.5$. The ball starts off at position $(0,0)$. After 5 s it should be at position $(10,0)$ with zero velocity $v$ and zero angular velocity $\omega$. We optimized the initial velocity $v_{0}$ and angular velocity $\omega_{0}$ at time $t=0 \mathrm{~s}$ until the errors at $t=5 \mathrm{~s}$ are $&lt;0.01 \mathrm{~m}$ and $0.01 \mathrm{~m} / \mathrm{s}$ respectively.</p>
<p>Since the quantity we optimize is only know at the end of the simulation, but we need to optimize the parameters at the beginning of the simulation, we need to backpropagate our error through time (BPTT) (Sutskever, 2013). This approach is similar to the backpropagation through time method used for optimizing recurrent neural networks (RNN). In our case, every time step in the simulation can be seen as one pass through a neural network, which transforms the inputs from this timestep to inputs for the next time step. For finding the gradient, this RNN is unfolded completely, and the gradient can be obtained by differentiating this unfolded structure. This analytic differentiation is done automatically by the Theano library.</p>
<p>Optimizing the six parameters in $v_{0}$ and $\omega_{0}$ took only 88 iterations with gradient descent and backpropagation through time. Optimizing this problem with CMA-ES (Hansen, 2006),</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>FIGURE 1 | Illustration of how a closed loop neural network controller would be used to actuate a robot. The neural network receives sensor signals from the sensors on the robot and uses these to generate motor signals which are sent to the servo motors. The neural network can also generate a signal which it can use at the next timestep to control the robot.</p>
<p>A state of the art derivative-free optimization method, took 2,422 iterations. Even when taking the time to compute the gradient into account, the optimization with gradient descent takes 16.3 s, compared to 59.9 s with CMA-ES. This result shows that gradient-based optimization of kinematic systems can in some cases already outperform gradient-free optimization algorithms from as little as six parameters.</p>
<h3>2.2. Policy Search</h3>
<p>To evaluate the relevance of our differentiable physics engine, we use a neural network as a general controller for a robot, as shown in Figure 1. We consider a general robot model in a discrete-time dynamical system <strong>x</strong><sup>t+1</sup> = <em>f</em><sub>ph</sub>(<strong>x</strong><sup>t</sup>, <strong>u</strong><sup>t</sup>) with a task cost function of <em>l</em>(<strong>x</strong><sup>t</sup>, <strong>p</strong>), where <strong>x</strong><sup>t</sup> is the state of the system at time <em>t</em> and <strong>u</strong><sup>t</sup> is the input of the system at time <em>t</em>. <strong>p</strong> provides some freedom in parameterizing the loss. If <em>X</em><sup>t</sup> is the trajectory of the state up to time <em>t</em> âˆ’ 1, the goal is to find a policy <em>u</em><sup>t</sup> = <em>Ï€</em>(<em>X</em><sup>t</sup>) such that we minimize the loss L<sub>Ï€</sub>.</p>
<p>$$
\mathcal{L}<em t="0">{\pi} = \sum</em>)
$$}^{T} l(\mathbf{x}^{t}, \mathbf{p</p>
<p>s.t. <strong>x</strong><sup>t+1</sup> = <em>f</em><sub>ph</sub>(<strong>x</strong><sup>t</sup>, <em>Ï€</em>(<em>X</em><sup>t</sup>)) and <strong>x</strong><sup>0</sup> = <em>x</em><sup>init</sup></p>
<p>In previous research, finding a gradient for this objective has been described as presenting challenges (Mordatch and Todorov, 2014). An approximation to tackle these issues has been discussed in Levine and Koltun (2013).</p>
<p>We implement this equation into an automatic differentiation library, ignoring these challenges in finding the analytic gradient altogether. The automatic differentiation library, Theano in our case, analytically derives this equation and compiles code to evaluate both the equation and its gradient.</p>
<p>Unlike in previous approaches such as iLQR (Todorov and Li, 2005) and DDP (Bertsekas et al., 2005), we propose not to use this gradient to optimize a trajectory, but to use the gradient obtained to optimize a general controller parameterized by a neural network. This limits the amount of computation at execution time, but requires the optimization of a harder problem with more parameters.</p>
<p>We define our controller as a deep neural network <em>g</em><sub>deep</sub> with weights <strong>W</strong>. We do not pass all information <em>X</em><sup>t</sup> to this neural network, but only a vector of values <strong>s</strong><sup>t</sup> observed by the modeled sensors <em>s</em>(<strong>x</strong><sup>t</sup>). We also provide our network with (some of the) task-specific parameters <strong>p</strong><sup>0</sup>. Finally, we add a recurrent connection to the controller in the previous timestep <strong>h</strong><sup>t</sup>. Therefore, our policy is the following:</p>
<p>$$
\pi(X^t) = g_{\text{deep}}(s(\mathbf{x}^t), \mathbf{h}^t, \mathbf{p}' | \mathbf{W})
$$</p>
<p>s.t. <strong>h</strong><sup>t</sup> = <em>h</em><sub>deep</sub>(<em>s</em>(<strong>x</strong><sup>tâˆ’1</sup>), <strong>h</strong><sup>tâˆ’1</sup>, <strong>p</strong><sup>0</sup> | <strong>W</strong>) and <strong>h</strong><sup>0</sup> = 0</p>
<p>Notice the similarity between Equations (2) and (3). Indeed, the equations for recurrent neural networks (RNN) in Equation (3) are very similar to the ones of the loss of a physical model in Equation (2). Therefore, we optimize this entire system as an RNN unfolded over time, as illustrated in Figure 2. The weights <strong>W</strong> are optimized with stochastic gradient descent. The gradient required for that is the Jacobian <em>dL</em>/<em>d</em><em>W</em>, which is found with automatic differentiation software.</p>
<p>We have now reduced the problem to a standard deep learning problem. We need to train our network <em>g</em><sub>deep</sub> on a sufficient amount of samples <em>x</em><sup>init</sup> and for a sufficient amount of sampled tasks <strong>p</strong> in order to get adequate generalization. Standard RNN regularization approaches could also improve this generalization. We reckon that generalization of <em>g</em><sub>deep</sub> to more models <em>f</em><sub>ph</sub>, in order to ease the transfer of the controller from the model to the real system, is also possible (Hermans et al., 2014), but it is outside the scope of this paper.</p>
<h1>3. RESULTS</h1>
<h2>3.1. Quadrupedal Robot: Computing Speed</h2>
<p>To verify the speed of our engine, we also implemented a small quadrupedal robot model, as illustrated in Figure 3B. This model has a total of 81 sensors, e.g., encoders and an inertial measurement unit (IMU). The servo motors are controlled in a closed loop by a small neural network <em>g</em><sub>deep</sub> with a number of parameters, as shown in Figure 2. The gradient is the Jacobian of <em>L</em>, the total traveled distance of the robot in 10 s, differentiated with respect to all the parameters of the controller <strong>W</strong>. This Jacobian is found by using BPTT and propagating all 10 s back. The time it takes to compute this traveled distance and the accompanying Jacobian is shown in Table 1. We include both the computation time with and without the gradient, i.e., both the forward and backward pass and the forward pass alone. This way, the numbers can be compared to other physics engines, as those only calculate without gradient. Our implementation and our model can probably be made more efficient, and evaluating the gradient can probably be made faster a similar factor.</p>
<p>When only a single controller is optimized, our engine runs more slowly on GPU than on CPU. To tackle this issue, we implemented batch gradient descent, which is commonly used in complex optimization problems. In this case, by batching our robot models, we achieve significant acceleration on GPU. Although backpropagating the gradient through physics slows</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>FIGURE 2 | Illustration of the dynamic system with the robot and controller, after unrolling over time. The neural networks gdeep and hdeep with weights W receive sensor signals s<sup>f</sup> from the sensors on the robot and use these to generate motor signals u<sup>f</sup> which are used by the physics engine fph to find the next state of the robot in the physical system. These neural networks also have a memory, implemented with recurrent connections h<sup>f</sup>. From the state x<sup>f</sup> of these robots, the loss L can be found. In order to find dL/dW, every block in this chart needs to be differentiable. The contribution of this paper is to implement a differentiable fph, which allows us to optimize W to minimize L more efficiently than was possible before.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>FIGURE 3 | (A) Illustration of the ball model used in the first task. (B) Illustration of the quadruped robot model with 8 actuated degrees of freedom, 1 in each shoulder, 1 in each elbow. The spine of the robot can collide with the ground, through 4 spheres in the inside of the cuboid. (C) Illustration of the robot arm model with 4 actuated degrees of freedom.</p>
<p>Down the computations by roughly a factor 10, this factor only barely increases with the number of parameters in our controller.</p>
<p>Combining this with our previous observation that fewer iterations are needed when using gradient descent, our approach can enable the use of gradient descent through physics for highly complex deep neural network controllers with millions of parameters. Also note that by using a batch method, a single GPU can simulate about 864,000 model seconds per day, or 86,400,000 model states. This should be plenty for deep learning. It also means that a single simulation step of a single robot, which includes collision detection, solving the LCP problem, integrating the velocities and backpropagating the gradient through it all, takes about 1 ms on average. Without the backpropagation, this process is only about seven times faster.</p>
<h3>3.2. 4 Degree of Freedom Robot Arm</h3>
<p>As a first test of optimizing robot controllers, we implemented a four degree of freedom robotic arm, as depicted in Figure 3C.</p>
<p>The bottom of the robot has a 2 degrees of freedom actuated universal joint; the elbow has a 2 degree of freedom actuated joint as well. The arm is 1 m long, and has a total mass of 32 kg. The servos have a gain of 30 s<sup>âˆ’1</sup>, a torque of 30 Nm and a velocity of 45Â° s<sup>âˆ’1</sup>.</p>
<p>For this robot arm, we train controllers for a task with a gradually increasing amount of difficulty. To be able to train our parameters, we have to use a couple of tricks often used in the training of recurrent neural networks.</p>
<ul>
<li>We choose an objective which is evaluated at every time step and then averaged, rather than at specific points of the simulation. This approach vastly increases the number of samples over which the gradient is averaged, which in turn makes the gradient direction more reliable (SjÃ¶berg et al., 1995).</li>
<li>The value of the gradient is decreased by a factor Î± &lt; 1 at every time step. This trick has the effect of a prior. Namely, events further in the past are less important for influencing</li>
</ul>
<p>current events, because intermediate events might diminish their influence altogether. It also improves robustness against exploding gradients (Hermans et al., 2014).</p>
<ul>
<li>We initialize the controller intelligently. We do not want the controller to shake the actuators violently and explore outside the accurate domain of our simulation model. Therefore, our controllers are initialized with zeros such that they only output zeros at the start of the simulation. The initial policy is the zero policy.</li>
<li>We constraint the size of the gradient to an L2-norm of 1. This makes sure that gradients close to discontinuities in the fitness landscape do not push the parameter values too far away, such that everything which was learned is forgotten (Sutskever, 2013).</li>
</ul>
<h3>3.2.1. Reaching a Fixed Point</h3>
<p>A first simple task, is to have a small neural net controller learn to move the controller to a certain fixed point in space, at coordinates $(0.5 \mathrm{~m} ; 0.5 \mathrm{~m} ; 0.5 \mathrm{~m})$. The objective we minimize for this task, is the distance between the end effector and the target point, averaged over the 8 s we simulate our model.</p>
<p>We provide the controller with a single sensor input, namely the current distance between the end effector and the target point. Input is not required for this task, as there are solutions for which the motor signals are constant in time. However, this would not necessarily be the optimal approach for minimizing the average distance over time, it only solves the distance at the end of the simulation, but does not minimize the distance during the trajectory to get at the final position.</p>
<p>As a controller, we use a dense neural network with 1 input, 2 hidden layers of 128 units with a rectifier activation function, and 4 outputs with an identity activation function. Each unit in the neural network also has a bias parameter. This controller has 17,284 parameters in total. We disabled the recurrent connections $\mathbf{h}^{i}$.</p>
<p>We use gradient descent with a batch size of 1 robot for optimization, as the problem is not stochastic in nature. The parameters are optimized with Adam's rule (Kingma and Ba, 2014) with a learning rate of 0.001 . Every update step with this method takes about 5 s on CPU. We find that the controller comes within 4 cm of the target in 100 model evaluations, and within 1 cm in 150 model evaluations, which is small compared to the 1 m arm of the robot. Moreover, the controller does find a more optimal trajectory which takes into account the sensor information.</p>
<p>Solving problems like these in fewer iteration steps than the number of parameters, is unfeasible with derivative free methods (SjÃ¶berg et al., 1995). Despite that, we did try to optimize the same problem with CMA-ES. After a week of computing and 60,000 model evaluations, CMA-ES did not show any sign of improvement nor convergence, as it cannot handle the sheer amount of parameters. In performance, the policy went from a starting performance of $0.995 \pm 0.330 \mathrm{~m}$ to a not significantly different $0.933 \pm 0.369 \mathrm{~m}$ after the optimization. For this reason, we did not continue using CMA-ES as a benchmark in the further experiments.</p>
<h3>3.2.2. Reaching a Random Point</h3>
<p>As a second task, we sample a random target point in the reachable space of the end effector. We give this point as input $v^{\prime}$ to the controller, and the task is to again minimize the average distance between the end effector and the target point $v$. Our objective $\mathcal{L}$ is this distance averaged over all timesteps.</p>
<p>As a controller, we use a dense neural network comparable to the previous section, but this time with 3 inputs. Note that this is an open loop controller, which needs to control the system to a set point given as input. We used 3 hidden layers with 1,024 units each, so the controller has 2,107,396 parameters in total. This is not necessary for this task, but we do it like this to demonstrate the power of this approach. In order to train for this task, we use a batch size of 128 robots, such that every update step takes 58 s on GPU. Each simulation takes 8 s with a simulation step of 0.01 s . Therefore, the gradient on the parameters of the controllers has been averaged over 51,200 timesteps at every update step. We update the parameters with Adam's rule, where we scale the learning rate with the average error achieved in the previous step.</p>
<p>We find that it takes 576 update steps before the millions of parameters are optimized, such that the end effector of the robot is on average $&lt;10 \mathrm{~cm}$ of target, 2,563 update steps before the error is $&lt;5 \mathrm{~cm}$.</p>
<h3>3.3. A Quadrupedal Robot: Revisited</h3>
<p>Optimizing a gait for a quadrupedal robot is a problem of a different order, something the authors have extensive experience with Degrave et al. (2013, 2015) and Sproewitz et al. (2013). The problem is way more challenging and allows for a broad range of possible solutions. In nature, we find a wide variety of gaits, from hopping over trotting, walking and galloping. With hand tuning on the robot model shown in Figure 3B, we were able to obtain a trotting motion with an average forward speed of $0.7 \mathrm{~m} / \mathrm{s}$. We found it tricky to find a gait where the robot did not end up like an upside down turtle, as $75 \%$ of the mass of the robot is located in its torso.</p>
<p>As a controller for our quadrupedal robot, we use a neural network with 2 input signals $\mathbf{s}^{i}$, namely a sine and a cosine signal with a frequency of 1.5 Hz . On top of this, we added 2 hidden layers of 128 units and a rectifier activation function. As output layer, we have a dense layer with 8 units and a linear activation function, which has as input both the input layer and the top layer of the hidden layers. In total, this controller has 17,952 parameters. Since the problem is not stochastic in nature, we use a batch size of 1 robot. We initialize the output layer with zero weights, so the robot starts the optimization in a stand still position.</p>
<p>We optimize these parameters to maximize the average velocity of the spine over the course of 10 s of time in simulation. This way, the gradient used in the update step is effectively an average of the 1,000 time steps after unrolling the recurrent connections. This objective does not take into account energy use, or other metrics typically employed in robotic problems.</p>
<p>In only 500 model evaluations or about 1 h of optimizing on CPU, the optimization with BPTT comes up with a solution with a speed of $1.17 \mathrm{~m} / \mathrm{s}$. This solution is a hopping gait, with</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p><strong>FIGURE 4</strong> | A frame captured by the differentiable camera looking at the model of the pendulum-cart system. The resolution used is 288 by 96 pixels. All the textures are made from pictures of the actual system.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p><strong>FIGURE 5</strong> | The camera model used to convert the three dimensional point <em>P</em> into a two dimensional pixel on the projection plane (<em>u</em>, <em>v</em>).</p>
<p>A summersault every 3 stepsÂ¹, despite limiting the torque of the servos to 4 Nm on this 28.7 kg robot. For more life-like gaits, energy efficiency could be used as a regularization method. Evaluating these improvements are however outside the scope of this paper.</p>
<h3>3.4. The Inverted Pendulum With a Camera as Sensor</h3>
<p>As a fourth example, we implemented a model of the pendulum-cart system we have in our laboratorium. This pendulum-cart system is used for the classic control task of the underactuated inverted pendulum (Vaccaro, 1995). In this example however, a camera which is set up in front of the system is the only available information for the controller. It therefore has to observe the system it controls using vision, i.e., learning from pixels. A frame captured by this camera is shown in <strong>Figure 4</strong>.</p>
<p>In order to build this model, we implemented a renderer in our physics engine which converts the three dimensional scene into a two dimensional color image, as illustrated in <strong>Figure 5</strong>. In order to perform this operation in a differentiable way, we use a ray tracing approach rather than the more conventional rasterization pipeline. First we cast a set of lines from the point of our camera <em>C</em> in the direction <em>dÌ‚</em> of the optical axis of the camera.</p>
<p>These vectors are then converted with the pinhole camera model into a line going through the center of the pixel with the image coordinates (<em>u</em>, <em>v</em>) on the projection plane. Each of these rays is then intersected with every object in the scene to find the texture and corresponding sample location to sample from in the scene's texture array. From all intersections a single ray makes, all but the one closest in front of the projection plane is kept.</p>
<p>Each of the intersections is then converted to a color by bilinearly interpolating the scene's texture array, in a way similar to the approach used for the spatial transform layer (Jaderberg et al., 2015; Degrave et al., 2016a). This bilinear interpolation is necessary to make the frame captured by the camera differentiable to the state of the robot with non-zero derivatives. If the textures would have been a zero-order, pixelated approximation, then all the gradients would be zero analytically.</p>
<p>Using the above ray-tracing approach, we minimize the distance from the end of the pendulum to the desired point and regularize the speed of the pendulum. The memoryless deep controller receives the current image of the camera, in addition to two images from the past such that it can estimate velocity and acceleration. We observe that a controller with 1,065,888 parameters is able to learn to swing up and keep the pendulum stable after only 2,420 episodes of 3 model seconds. The complete optimization process took 15 h on 1 GPU. The resulting controller keeps the pendulum stable for more than 1 minÂ². In order to do this, the controller has learned to interpret the frames it receives from the camera and found a suitable control strategy.</p>
<p>Note that this would not have been possible using a physics engine such as muloco, as these engines only allow differentiation through the action and the state, but does not allow to differentiate through the renderer. We want to stress that in this setup we solved the problem by backpropagating through both the computer vision in the form of the convolutional neural network, and the renderer in the form of the differentiable camera.</p>
<h3>4. DISCUSSION</h3>
<p>We implemented a modern engine which can run a 3D rigid body model, using the same algorithm as other engines commonly used to simulate robots, but we can additionally differentiate control parameters with BPTT. Our implementation also runs on GPU, and we show that using GPUs to simulate the physics can speed up the process for large batches of robots. We show that even complex sensors such as cameras, can be implemented and differentiated through, allowing for computer vision to be learned together with a control policy.</p>
<p>When initially addressing the problem, we did not know whether finding the gradient would be computationally tractable, let alone whether evaluating it would be fast enough to be beneficial for optimization. In this paper, we have demonstrated that evaluating the gradient is tractable enough to speed up optimization on problems with as little as six parameters. The</p>
<p><sup>1</sup>A video is available at https://goo.gl/5ykZZe</p>
<p><sup>2</sup>https://twitter.com/317070/status/821062814798331905</p>
<p>speed of this evaluation mainly depends on the complexity of the physics model and only slightly on the number of parameters to optimize. Therefore, our results suggest that this cost is dominated by the gain achieved from the combination of using batch gradient descent and GPU acceleration. Consequently, by using gradient descent with BPTT one can speed up the optimization processes often found in robotics, even for rather small problems, due to the reduced number of model evaluations required. Furthermore, this improvement in speed scales to problems with a lot of parameters. By using the proposed engine, finding policies for robot models can be done faster and in a more straightforward way. This method should allow for a new approach to apply deep learning techniques in robotics.</p>
<p>Optimizing the controller of a robot model with gradientbased optimization is equivalent to optimizing an RNN. After all, the gradient passes through each parameter at every time step. The parameter space is therefore very noisy. Consequently, training the parameters of this controller is a highly non-trivial problem, as it corresponds to training the parameters of an RNN. On top of that, exploding and vanishing signals and gradients cause far more challenging problems compared to feed forward networks.</p>
<p>In section 3.2, we already discussed some of the tricks used for optimizing RNNs. Earlier research shows that these methods can be extended to more complicated tasks than the ones discussed here (Sutskever, 2013; Hermans et al., 2014). Hence, we believe that this approach toward learning controllers for robotics applies to more complex problems than the illustrative examples in this paper.</p>
<p>TABLE 1 | Evaluation of the computing speed of our engine on a robot model controlled by a closed loop controller with a variable number of parameters.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th>With gradient</th>
<th></th>
<th>Without gradient</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td>CPU</td>
<td>GPU</td>
<td>CPU</td>
<td>GPU</td>
</tr>
<tr>
<td>SECONDS OF COMPUTING TIME REQUIRED TO SIMULATE A BATCH OF ROBOTS FOR 10 s</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>1 robot</td>
<td>1,296 parameters</td>
<td>8.17</td>
<td>69.6</td>
<td>1.06</td>
<td>9.69</td>
</tr>
<tr>
<td></td>
<td>1,147,904 parameters</td>
<td>13.2</td>
<td>75.0</td>
<td>2.04</td>
<td>9.69</td>
</tr>
<tr>
<td>128 robots</td>
<td>1,296 parameters</td>
<td>263</td>
<td>128</td>
<td>47.7</td>
<td>17.8</td>
</tr>
<tr>
<td></td>
<td>1,147,904 parameters</td>
<td>311</td>
<td>129</td>
<td>50.4</td>
<td>18.3</td>
</tr>
<tr>
<td>MILLISECONDS OF COMPUTING TIME REQUIRED TO PERFORM ONE TIME STEP OF ONE ROBOT.</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>1 robot</td>
<td>1,296 parameters</td>
<td>8.17</td>
<td>69.6</td>
<td>1.06</td>
<td>9.69</td>
</tr>
<tr>
<td></td>
<td>1,147,904 parameters</td>
<td>13.2</td>
<td>75.0</td>
<td>2.04</td>
<td>9.69</td>
</tr>
<tr>
<td>128 robots</td>
<td>1,296 parameters</td>
<td>2.05</td>
<td>1.00</td>
<td>0.372</td>
<td>0.139</td>
</tr>
<tr>
<td></td>
<td>1,147,904 parameters</td>
<td>2.43</td>
<td>1.01</td>
<td>0.394</td>
<td>0.143</td>
</tr>
</tbody>
</table>
<p>We evaluated both on CPU (i7 5930K) and GPU (GTX 1080), both for a single robot optimization and for batches of multiple robots in parallel. The numbers are the time required in seconds for simulating the quadruped robot(s) for 10 s , with and without updating the controller parameters through gradient descent. Shorter times are colored in green, longer in red. The gradient calculated here is the Jacobian of the total traveled distance of the robot in 10 s , differentiated with respect to all the parameters of the controller. For comparison, the model has 102 states. It is built from 17 rigid bodies, each having 6 degrees of freedom. These states are constrained by exactly 100 constraints.</p>
<p>All of the results in this paper will largely depend on showing how these controllers will work on the physical counterparts of our models. Nonetheless, we would like to conjecture that to a certain extent, this gradient of a model is close to the gradient of the physical system. The gradient of the model is more susceptible to high-frequency noise introduced by modeling the system, than the imaginary gradient of the system itself. Nonetheless, it contains information which might be indicative, even if it is not perfect. We would theorize that using this noisy gradient is still better than optimizing in the blind and that the transferability to real robots can be improved by evaluating the gradients on batches of (slightly) different robots in (slightly) different situations and averaging the results. This technique has already been applied in Hermans et al. (2014) as a regularization method to avoid bifurcations during online learning. If the previous proves to be correct, our approach can offer an addition or possibly even an alternative to deep Q-learning for deep neural network controllers in robotics.</p>
<p>We can see the use of this extended approach for a broad range of applications in robotics. Not only do we think there are multiple ways where recent advances in deep learning could be applied to robotics more efficiently with a differentiable physics engine, we also see various ways in which this engine could improve existing angles at which robotics are currently approached:</p>
<ul>
<li>In this paper, we added memory by introducing recurrent connections in the neural network controller. We reckon that advanced, recurrent connections such as ones with a memory made out of LSTM cells (Hochreiter and Schmidhuber, 1997) can allow for more powerful controllers than the controllers described in this paper.</li>
<li>Having general differentiable models should allow for an efficient system identification process (Bongard et al., 2006; Ha and Schmidhuber, 2018). The physics engine can find analytic derivatives to all model parameters. This includes masses and lengths, but also parameters which are not typically touched in system identification, such as the textures of the rigid body. As the approach could efficiently optimize many parameters simultaneously, it would be conceivable to find state dependent model parameters using a neural network to map the current state onto e.g., the friction coefficient in that state.</li>
<li>
<p>Using a differentiable physics engine, we reckon that knowledge of a model can be distilled more efficiently into a forward or backward model in the form of a neural network, similar to methods such as used in Johnson et al. (2016) and Dumoulin et al. (2017). By differentiating through an exact model and defining a relevant error on this model, it should be possible to transfer knowledge from a forward or backward model in the differentiable physics engine to a forward or backward neural network model. Neural network models trained this way might be more robust than the ones learned from generated trajectories (Christiano et al., 2016). In turn, this neural model could then be used for faster but approximate evaluation of the model.</p>
</li>
<li>
<p>Although we did not address this in this paper, there is no reason why only control parameters could be optimized in the process. Hardware parameters of the robot have been optimized the same way before (Jarny et al., 1991; Iollo et al., 2001; Hermans et al., 2014). The authors reckon that the reverse process is also true. A physics engine can provide a strong prior, which can be used for robots to learn (or adjust) their robot models based on their hardware measurements faster than today. You could optimize the model parameters with gradient descent through physics, to have the model better mimic the actual observations.</p>
</li>
<li>Where adversarial networks are already showing their use in generating image models, we believe adversarial robotics training (ART) will create some inventive ways to design and control robots. Like in generative adversarial nets (GAN) (Goodfellow et al., 2014), where the gradient is pulled through two competing neural networks, the gradient could be pulled through multiple competing robots as well. It would form an interesting approach for swarm robotics, similar to previous results in evolutionary robotics (Sims, 1994; Pfeifer and Bongard, 2006; Cheney et al., 2014), but possibly faster.</li>
</ul>
<h2>REFERENCES</h2>
<p>Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., et al. (2016). TensorFlow: large-scale machine learning on heterogeneous systems. arXiv [Preprint]. arXiv:1603.04467. Available online at: https://arxiv.org/abs/1603. 04467
Aguilar-IbaÃ±ez, C. (2017). Stabilization of the pvtol aircraft based on a sliding mode and a saturation function. Int. J. Robust Nonlinear Control 27, 843-859. doi: $10.1002 /$ rnc. 3601
Al-Rfou, R., Alain, G., Almahairi, A., Angermueller, C., Bahdanau, D., Ballas, N., et al. (2016). Theano: a Python framework for fast computation of mathematical expressions. arXiv [Preprint]. arXiv:1605.02688. Available online at: https://arxiv.org/abs/1605.02688
Bertsekas, D. P., Bertsekas, D. P., Bertsekas, D. P., and Bertsekas, D. P. (2005). Dynamic Programming and Optimal Control, Vol. 1. Belmont, MA: Athena scientific.
Bongard, J., Zykov, V., and Lipson, H. (2006). Resilient machines through continuous self-modeling. Science 314, 1118-1121. doi: 10.1126/science. 1133687
Catto, E. (2009). "Modeling and solving constraints," in Game Developers Conference (Cologne).
Chappuis, D. (2013). Constraints derivation for rigid body simulation in 3D. Available online at: https://danielchappuis.ch/download/ ConstraintsDerivationRigidBody3D.pdf
Cheney, N., Clune, J., and Lipson, H. (2014). Evolved electrophysiological soft robots. ALIFE 14, 222-229. doi: 10.7551/978-0-262-32621-6-ch037
Christiano, P., Shah, Z., Mordatch, I., Schneider, J., Blackwell, T., Tobin, J., et al. (2016). Transfer from simulation to real world through learning deep inverse dynamics model. arXiv [Preprint]. arXiv:1610.03518.
Degrave, J., Burm, M., Kindermans, P. J., Dambre, J., and wyffels, F. (2015). Transfer learning of gaits on a quadrupedal robot. Adapt. Behav. 23, 69-82. doi: 10.1177/1059712314563620
Degrave, J., Burm, M., Waegeman, T., wyffels, F., and Schrauwen, B. (2013). "Comparing trotting and turning strategies on the quadrupedal oncilla robot," in 2013 IEEE International Conference on Robotics and Biomimetics (ROBIO) (Shenzhen: IEEE), 228-233.
Degrave, J., Dieleman, S., Dambre, J., and wyffels, F. (2016a). Spatial chirp-Z transformer networks. in European Symposium on Artificial Neural Networks (ESANN) (Bruges).</p>
<h2>AUTHOR CONTRIBUTIONS</h2>
<p>The experiments were conceived by JDe, MH, JDa, and FW. Experiments were designed by JDe and MH. The data were analyzed by JDe with help of FW and JDa. The manuscript was mostly written by JDe, with comments and corrections from FW and JDa.</p>
<h2>FUNDING</h2>
<p>The research leading to these results has received funding from the Agency for Innovation by Science and Technology in Flanders (IWT). The NVIDIA Corporation donated the GTX 1080 used for this research.</p>
<h2>ACKNOWLEDGMENTS</h2>
<p>Special thanks to David Pfau for pointing out relevant prior art we were previously unaware of, and Iryna Korshunova for proofreading the paper. The original version of this article was previously published in preprint on arXiv (Degrave et al., 2016b).</p>
<p>Degrave, J., Hermans, M., Dambre, J., and Wyffels, F. (2016b). A differentiable physics engine for deep learning in robotics. arXiv [Preprint]. arXiv:1611.01652. Available online at: https://arxiv.org/abs/1611.01652
Dumoulin, V., Shlens, J., and Kudlur, M. (2017). "A learned representation for artistic style," in International Conference on Learning Representations (ICLR).
Erez, T., Tassa, Y., and Todorov, E. (2015). "Simulation tools for model-based robotics: comparison of bullet, havok, mujoco, ode, and physx," in International Conference on Robotics and Automation (ICRA) (Seattle, WA: IEEE), 43974404.</p>
<p>Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., et al. (2014). "Generative adversarial nets," in Advances in Neural Information Processing Systems (Montreal, QC), 2672-2680.
Grzeszczuk, R., Terzopoulos, D., and Hinton, G. (1998). "Neuroanimator: fast neural network emulation and control of physics-based models," in Proceedings of the 25th Annual Conference on Computer Graphics and Interactive Techniques (Orlando, FL: ACM), 9-20.
Ha, D., and Schmidhuber, J. (2018). World models Version 1.1. arXiv [Preprint]. arXiv:1803.10122. doi: 10.5281/zenodo. 1207631
Hansen, N. (2006). "The cma evolution strategy: a comparing review," in Towards a New Evolutionary Computation (Berlin; Heidelberg: Springer ), 75-102. .
Hermans, M., Schrauwen, B., Bienstman, P., and Dambre, J. (2014). Automated design of complex dynamic systems. PLoS ONE 9:e86696. doi: 10.1371/journal.pone. 0086696
Hochreiter, S., and Schmidhuber, J. (1997). Long short-term memory. Neural Comput. 9, 1735-1780.
Hubbard, P. M. (1996). Approximating polyhedra with spheres for time-critical collision detection. ACM Trans. Graph. 15, 179-210.
Iollo, A., Ferlauto, M., and Zannetti, L. (2001). An aerodynamic optimization method based on the inverse problem adjoint equations. J. Comput. Phys. 173, 87-115. doi: 10.1006/jcph. 2001.6845
Jaderberg, M., Simonyan, K., Zisserman, A., and Kavukcuoglu, K. (2015). "Spatial transformer networks," in Advances in Neural Information Processing Systems (Montreal, QC), 2017-2025.
Jarny, Y., Ozisik, M., and Bardon, J. (1991). A general optimization method using adjoint equation for solving multidimensional inverse heat conduction. Int. J. Heat Mass Trans. 34, 2911-2919.
Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., et al. (2014). Caffe: convolutional architecture for fast feature embedding. arXiv [Preprint]. arXiv:1408.5093. Available online at: https://arxiv.org/abs/1408. 5093</p>
<p>Johnson, J., Alahi, A., and Fei-Fei, L. (2016, October). "Perceptual losses for realtime style transfer and super-resolution," in European Conference on Computer Vision (Cham: Springer), 694-711.
Jourdan, F., Alart, P., and Jean, M. (1998). A gauss-seidel like algorithm to solve frictional contact problems. Comp. Methods Appl. Mech. Engin. 155, 31-47.
Kingma, D. P., and Ba, J. (2014). "Adam: a method for stochastic optimization," in Proceedings of the 3rd International Conference on Learning Representations (ICLR) (Banff).
Levine, S., and Koltun, V. (2013). Variational policy search via trajectory optimization. in Advances in Neural Information Processing Systems (Lake Tahoe, NV), 207-215.
Levine, S., Pastor, P., Krizhevsky, A., Ibarz, J., and Quillen, D. (2018). Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection. Int. J. Robot. Res. 37, 421-436. doi: 10.1177/0278364917710318
Meda-Campana, J. A. (2018). Estimation of complex systems with parametric uncertainties using a jssf heuristically adjusted. IEEE Latin Am. Trans. 16, $350-357$.
Mirtich, B. (1998). V-clip: Fast and robust polyhedral collision detection. ACM Trans. Graph. 17, 177-208.
Mordatch, I., and Todorov, E. (2014). "Combining the benefits of function approximation and trajectory optimization," in Robotics: Science and Systems (RSS) (Rome).
Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., et al. (2017). "Automatic differentiation in pytorch," in Autodiff Workshop.
Pfeifer, R., and Bongard, J. (2006). How the Body Shapes the Way we Think: A New View of Intelligence. Cambridge: MIT press.
Premerlani, W., and Bizard, P. (2009). "Direction cosine matrix IMU: theory," in DIY Drone: USA (Evendale), 13-15.
Sims, K. (1994). Evolving 3d morphology and behavior by competition. Artif. Life $1,353-372$.
SjÃ¶berg, J., Zhang, Q., Ljung, L., Benveniste, A., Delyon, B., Glorennec, P.-Y., et al. (1995). Nonlinear black-box modeling in system identification: a unified overview. Automatica 31, 1691-1724.</p>
<p>Sproewitz, A., Tuleu, A., D'Haene, M., MÃ¶ckel, R., Degrave, J., Vespignani, M., et al. (2013). "Towards dynamically running quadruped robots: performance, scaling, and comparison," in Adaptive Motion of Animals and Machines (Darmstadt), 133-135.
Stewart, D., and Trinkle, J. C. (2000). An implicit time-stepping scheme for rigid body dynamics with coulomb friction. in International Conference on Robotics and Automation (ICRA), Vol. 1, (IEEE), $162-169$.
Sutskever, I. (2013). Training Recurrent Neural Networks. PhD thesis, University of Toronto.
Todorov, E., Erez, T., and Tassa, Y. (2012). "Mujoco: a physics engine for modelbased control," in 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems (IEEE), 5026-5033.
Todorov, E., and Li, W. (2005). "A generalized iterative lqg method for locally-optimal feedback control of constrained nonlinear stochastic systems," in American Control Conference, 2005. Proceedings of the 2005 (IEEE), $300-306$.
Vaccaro, R. J. (1995). Digital Control: A State-Space Approach, Vol. 196. New York, NY: McGraw-Hill.</p>
<p>Conflict of Interest Statement: JD is currently employed at Deepmind.
The remaining authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
<p>Copyright Â© 2019 Degrave, Hermans, Dambre and wyffels. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</p>            </div>
        </div>

    </div>
</body>
</html>