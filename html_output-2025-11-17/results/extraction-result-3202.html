<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3202 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3202</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3202</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-74.html">extraction-schema-74</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <p><strong>Paper ID:</strong> paper-a53c8ba374d430d6c3786d13c04edb200d547750</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/a53c8ba374d430d6c3786d13c04edb200d547750" target="_blank">A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Learning Representations</p>
                <p><strong>Paper TL;DR:</strong> WebAgent is introduced, an LLM-driven agent that learns from self-experience to complete tasks on real websites following natural language instructions, and HTML-T5, new pre-trained LLMs for long HTML documents using local and global attention mechanisms and a mixture of long-span denoising objectives, for planning and summarization.</p>
                <p><strong>Paper Abstract:</strong> Pre-trained large language models (LLMs) have recently achieved better generalization and sample efficiency in autonomous web automation. However, the performance on real-world websites has still suffered from (1) open domainness, (2) limited context length, and (3) lack of inductive bias on HTML. We introduce WebAgent, an LLM-driven agent that learns from self-experience to complete tasks on real websites following natural language instructions. WebAgent plans ahead by decomposing instructions into canonical sub-instructions, summarizes long HTML documents into task-relevant snippets, and acts on websites via Python programs generated from those. We design WebAgent with Flan-U-PaLM, for grounded code generation, and HTML-T5, new pre-trained LLMs for long HTML documents using local and global attention mechanisms and a mixture of long-span denoising objectives, for planning and summarization. We empirically demonstrate that our modular recipe improves the success on real websites by over 50%, and that HTML-T5 is the best model to solve various HTML understanding tasks; achieving 18.7% higher success rate than the prior method on MiniWoB web automation benchmark, and SoTA performance on Mind2Web, an offline task planning evaluation.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3202.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3202.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>WebAgent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>WebAgent (modular LLM-driven web automation system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A modular autonomous web agent that combines a domain-specialist LLM (HTML-T5) for closed-loop planning and HTML summarization with a generalist LLM (Flan-U-PaLM) for conditional program (Python/Selenium) synthesis to perform multi-step tasks on real websites.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>WebAgent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Two-stage modular agent: (1) HTML-T5 predicts next sub-instruction (planning) and extracts task-relevant HTML snippets (summarization) in a closed-loop iterative process conditioned on the instruction, raw HTML, and history; (2) Flan-U-PaLM consumes the sub-instruction + snippet and generates executable Python (Selenium) code to act on the website. The loop repeats until episode termination.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>contextual history + snippet retrieval (context-window / short-term episodic memory)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>At runtime the agent maintains the history of past sub-instructions and actions which are fed back into HTML-T5 as part of the model input (closed-loop planning). HTML-T5 also extracts and returns data-ref IDs to retrieve task-relevant HTML snippets (retrieval from the current page). These histories and retrieved snippets are concatenated into the LLM context to condition subsequent planning and program synthesis; this functions as an episodic short-term memory limited by the model context window. Additionally, WebAgent is trained with a corpus of self-experience demonstrations (offline dataset) used for finetuning, which serves as a learned long-term experience but is not a runtime external memory store.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Real-world web automation (real-estate, social-media, map websites)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Instruction-following navigation and manipulation on real websites requiring decomposition into sub-steps, extraction of task-relevant parts of long HTML pages, and generation of open-ended browser actions via code; challenges include long context HTML, open-ended action space, and long-horizon planning.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>tool use / planning (web automation)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>WebAgent (with HTML-T5 planning+summarization modules + Flan-U-PaLM program synthesis): success rates — real-estate 65.0% (score 87.6%), social-media 70.0% (score 85.8%), map 80.0% (score 93.8%) (Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Single prompted Flan-U-PaLM baseline (open-loop planning, regex summarization): success rates — real-estate 10.0% (score 55.3%), social-media 20.0% (score 25.0%), map 10.0% (score 51.3%) (Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Closed-loop planning that conditions on sub-instruction history plus HTML summarization (i.e., maintaining and using episodic history and retrieved snippets in the LLM context) significantly improves real-world web automation success (WebAgent outperforms single open-loop prompted LLM baseline by ~50+ percentage points in success on the evaluated sites). Coupling planning and summarization in a finetuned domain model is critical for task success.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Memory is constrained to the LLM context window and snippet extraction; failures still concentrate in planning (incorrect sub-instructions accumulate over long horizons). There is additional computational cost and latency from modular approach. Summarization/retriever errors and programming errors (code generation) remain failure modes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3202.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3202.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HTML-T5</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HTML-T5 (domain-expert pre-trained encoder-decoder for long HTML documents)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pre-trained encoder-decoder LLM specialized for HTML that uses local and transient global attention to capture hierarchical HTML structure and is pre-trained with a mixture of long-span denoising objectives on a large CommonCrawl-derived HTML corpus; used for planning and conditional HTML summarization within WebAgent.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>HTML-T5</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Encoder-decoder model with local attention windows plus transient global attention ('global memory representation') in the encoder to model hierarchical HTML structure; pre-trained with long-span denoising (span lengths mu in {8,64}) and fine-tuned for sub-instruction prediction and snippet extraction (summarization) as part of WebAgent. Operates over extended context lengths (pretraining used 4096 inputs, downstream finetuning used up to 16K tokens when possible).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>model-internal compressed global memory (transient global attention) + extended context window (long-context processing)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Local attention restricts token attention to neighbors; transient global attention compresses and aggregates token representations per block into a global memory representation that tokens can attend to beyond their local window, effectively providing a compressed cross-block memory. The model also uses a large context window to include sub-instruction history and extracted snippets, enabling short-term episodic conditioning.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MiniWoB++ (56 simulated web tasks), Mind2Web (offline web action prediction), WebSRC (HTML QA), and real-world web automation tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>HTML understanding and planning tasks: extract task-relevant elements, predict next actions/elements/operations, summarize long HTML into snippets, and generate structured outputs for web automation; challenges include hierarchical HTML structure, very long HTML sequences, and instruction-conditioned extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>document understanding / planning / action prediction</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>MiniWoB++: HTML-T5-XL outperforms prior WebN-T5 by 18.7% average success on 56 tasks; with large finetuning (347K demos) HTML-T5-XL achieves 85.6% success. Architecture ablation (Table 2): local+global attention LongT5-base achieves ~53.1% success vs Flan-T5-base (dense) 34.0% (an ~19% absolute improvement) on MiniWoB-like evaluation. Mind2Web: HTML-T5-XL shows substantial gains vs baselines (paper reports element accuracy +5-8%, operation F1 +6-8%, step success rate +4-8% relative improvements over prior methods).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Dense-attention (Flan-T5 base) baseline: ~34.0% success (Table 2, MiniWoB++), Local-only attention: ~43.4% success; these are ablations showing removal of transient global attention (i.e., the compressed global memory) reduces performance by ~9-19 percentage points depending on setting.</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Incorporating a model-internal global memory mechanism (transient global attention) together with long-span HTML-denoising pretraining and a large context window substantially improves HTML understanding and downstream web action prediction/planning, enabling better generalization across websites and benchmarks (MiniWoB++, Mind2Web, WebSRC).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Processing very long documents requires large context windows and compute; the transient global attention and long-context training increase computational/resource requirements. Also, while HTML-T5 improves element/action prediction, planning over long horizons still remains challenging when used alone (planning benefits from the modular WebAgent design).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3202.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3202.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Flan-U-PaLM (baseline agent)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Flan-U-PaLM (prompted large generalist LLM used for open-loop planning and code generation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large instruction-tuned generalist LLM used in this work as the program-synthesis module; when used alone (prompted) it performs open-loop planning and regex-based summarization, serving as a baseline agent for web tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Flan-U-PaLM (prompted)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A single LLM approach where Flan-U-PaLM is prompted per role (plan, summarize, act) in an open-loop fashion, and simple regex-based retrieval is used to summarize HTML; used both as the program generator in WebAgent and as a single-LLM baseline performing entire pipeline by prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>none (operates via prompt/context only; open-loop planning in baselines, no external or structured memory beyond normal LLM context)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>As used as a baseline, planning is open-loop via prompting and summarization is regex-based; no iterative closed-loop history conditioning or specialized snippet retrieval/finetuned summarizer is used.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Real-world web automation (baseline comparison in Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same web automation tasks as WebAgent but performed by a single prompted LLM without modular planning+summarization modules (open-loop).</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>planning / tool use (web automation)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Baseline prompted Flan-U-PaLM (no specialized memory/modules): success rates — real-estate 10.0% (55.3% score), social-media 20.0% (25.0% score), map 10.0% (51.3% score) (Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Open-loop prompting of a single generalist LLM without finetuned planning and summarization modules performs poorly on real websites; closed-loop memory-conditioned modules yield substantial gains.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Open-loop planning accumulates errors over long horizons; regex-based summarization is brittle on long/complex HTML. Lack of a specialized memory or retriever leads to poor performance on real web tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3202.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3202.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MindAct (related work)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MindAct (a two-module approach for web tasks referenced from Deng et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Related prior system that finetunes a language model to summarize raw HTML into task-relevant snippets and uses another model to predict web actions in a multiple-choice QA format; referenced for comparison in offline evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mind2web: Towards a generalist agent for the web</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MindAct</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Two-stage pipeline: a finetuned summarizer produces task-relevant HTML snippets and a separate actor model predicts actions (often presented as multi-choice QA) based on those snippets. MindAct evaluated in Mind2Web offline benchmark and used DeBERTa/Flan-T5 in original work.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>none (relies on snippet summarization and immediate context rather than a dedicated memory beyond context window)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Uses a finetuned summarization model to extract snippets from the presented candidate elements, then conditions the actor on those snippets; no explicit external or episodic memory mechanism beyond the context is described.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Mind2Web (offline action prediction / planning benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Offline action prediction across many websites and tasks: given snippets, instruction, and history, predict the element and operation (click/type/select) to perform; challenges include cross-task and cross-website generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>action prediction / planning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Reported baselines in the paper: MindAct (Flan-T5-XL) and MindAct (GPT-4) show lower element accuracy / operation F1 / step success compared to HTML-T5-XL; paper states HTML-T5 increases element accuracy by ~5-8%, operation F1 by ~6-8%, and step success by ~4-8% over MindAct variants (Table 4).</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>MindAct-style summarization + actor pipelines are effective offline baselines, but HTML-T5 (with its architectural and pretraining choices) outperforms MindAct variants on Mind2Web according to the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>MindAct in original form used DeBERTa/Flan-T5 and was evaluated offline; it may be limited by model choice and by not using HTML-specialized pretraining or global-local attention mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Mind2web: Towards a generalist agent for the web <em>(Rating: 2)</em></li>
                <li>Synapse: Leveraging few-shot exemplars for humanlevel computer control <em>(Rating: 2)</em></li>
                <li>Understanding html with large language models <em>(Rating: 2)</em></li>
                <li>Toolformer: Language models can teach themselves to use tools <em>(Rating: 1)</em></li>
                <li>LongT5: Efficient text-to-text transformer for long sequences <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3202",
    "paper_id": "paper-a53c8ba374d430d6c3786d13c04edb200d547750",
    "extraction_schema_id": "extraction-schema-74",
    "extracted_data": [
        {
            "name_short": "WebAgent",
            "name_full": "WebAgent (modular LLM-driven web automation system)",
            "brief_description": "A modular autonomous web agent that combines a domain-specialist LLM (HTML-T5) for closed-loop planning and HTML summarization with a generalist LLM (Flan-U-PaLM) for conditional program (Python/Selenium) synthesis to perform multi-step tasks on real websites.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "WebAgent",
            "agent_description": "Two-stage modular agent: (1) HTML-T5 predicts next sub-instruction (planning) and extracts task-relevant HTML snippets (summarization) in a closed-loop iterative process conditioned on the instruction, raw HTML, and history; (2) Flan-U-PaLM consumes the sub-instruction + snippet and generates executable Python (Selenium) code to act on the website. The loop repeats until episode termination.",
            "memory_used": true,
            "memory_type": "contextual history + snippet retrieval (context-window / short-term episodic memory)",
            "memory_mechanism_description": "At runtime the agent maintains the history of past sub-instructions and actions which are fed back into HTML-T5 as part of the model input (closed-loop planning). HTML-T5 also extracts and returns data-ref IDs to retrieve task-relevant HTML snippets (retrieval from the current page). These histories and retrieved snippets are concatenated into the LLM context to condition subsequent planning and program synthesis; this functions as an episodic short-term memory limited by the model context window. Additionally, WebAgent is trained with a corpus of self-experience demonstrations (offline dataset) used for finetuning, which serves as a learned long-term experience but is not a runtime external memory store.",
            "task_name": "Real-world web automation (real-estate, social-media, map websites)",
            "task_description": "Instruction-following navigation and manipulation on real websites requiring decomposition into sub-steps, extraction of task-relevant parts of long HTML pages, and generation of open-ended browser actions via code; challenges include long context HTML, open-ended action space, and long-horizon planning.",
            "task_type": "tool use / planning (web automation)",
            "performance_with_memory": "WebAgent (with HTML-T5 planning+summarization modules + Flan-U-PaLM program synthesis): success rates — real-estate 65.0% (score 87.6%), social-media 70.0% (score 85.8%), map 80.0% (score 93.8%) (Table 1).",
            "performance_without_memory": "Single prompted Flan-U-PaLM baseline (open-loop planning, regex summarization): success rates — real-estate 10.0% (score 55.3%), social-media 20.0% (score 25.0%), map 10.0% (score 51.3%) (Table 1).",
            "has_performance_comparison": true,
            "key_findings": "Closed-loop planning that conditions on sub-instruction history plus HTML summarization (i.e., maintaining and using episodic history and retrieved snippets in the LLM context) significantly improves real-world web automation success (WebAgent outperforms single open-loop prompted LLM baseline by ~50+ percentage points in success on the evaluated sites). Coupling planning and summarization in a finetuned domain model is critical for task success.",
            "limitations_or_challenges": "Memory is constrained to the LLM context window and snippet extraction; failures still concentrate in planning (incorrect sub-instructions accumulate over long horizons). There is additional computational cost and latency from modular approach. Summarization/retriever errors and programming errors (code generation) remain failure modes.",
            "uuid": "e3202.0",
            "source_info": {
                "paper_title": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "HTML-T5",
            "name_full": "HTML-T5 (domain-expert pre-trained encoder-decoder for long HTML documents)",
            "brief_description": "A pre-trained encoder-decoder LLM specialized for HTML that uses local and transient global attention to capture hierarchical HTML structure and is pre-trained with a mixture of long-span denoising objectives on a large CommonCrawl-derived HTML corpus; used for planning and conditional HTML summarization within WebAgent.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "HTML-T5",
            "agent_description": "Encoder-decoder model with local attention windows plus transient global attention ('global memory representation') in the encoder to model hierarchical HTML structure; pre-trained with long-span denoising (span lengths mu in {8,64}) and fine-tuned for sub-instruction prediction and snippet extraction (summarization) as part of WebAgent. Operates over extended context lengths (pretraining used 4096 inputs, downstream finetuning used up to 16K tokens when possible).",
            "memory_used": true,
            "memory_type": "model-internal compressed global memory (transient global attention) + extended context window (long-context processing)",
            "memory_mechanism_description": "Local attention restricts token attention to neighbors; transient global attention compresses and aggregates token representations per block into a global memory representation that tokens can attend to beyond their local window, effectively providing a compressed cross-block memory. The model also uses a large context window to include sub-instruction history and extracted snippets, enabling short-term episodic conditioning.",
            "task_name": "MiniWoB++ (56 simulated web tasks), Mind2Web (offline web action prediction), WebSRC (HTML QA), and real-world web automation tasks",
            "task_description": "HTML understanding and planning tasks: extract task-relevant elements, predict next actions/elements/operations, summarize long HTML into snippets, and generate structured outputs for web automation; challenges include hierarchical HTML structure, very long HTML sequences, and instruction-conditioned extraction.",
            "task_type": "document understanding / planning / action prediction",
            "performance_with_memory": "MiniWoB++: HTML-T5-XL outperforms prior WebN-T5 by 18.7% average success on 56 tasks; with large finetuning (347K demos) HTML-T5-XL achieves 85.6% success. Architecture ablation (Table 2): local+global attention LongT5-base achieves ~53.1% success vs Flan-T5-base (dense) 34.0% (an ~19% absolute improvement) on MiniWoB-like evaluation. Mind2Web: HTML-T5-XL shows substantial gains vs baselines (paper reports element accuracy +5-8%, operation F1 +6-8%, step success rate +4-8% relative improvements over prior methods).",
            "performance_without_memory": "Dense-attention (Flan-T5 base) baseline: ~34.0% success (Table 2, MiniWoB++), Local-only attention: ~43.4% success; these are ablations showing removal of transient global attention (i.e., the compressed global memory) reduces performance by ~9-19 percentage points depending on setting.",
            "has_performance_comparison": true,
            "key_findings": "Incorporating a model-internal global memory mechanism (transient global attention) together with long-span HTML-denoising pretraining and a large context window substantially improves HTML understanding and downstream web action prediction/planning, enabling better generalization across websites and benchmarks (MiniWoB++, Mind2Web, WebSRC).",
            "limitations_or_challenges": "Processing very long documents requires large context windows and compute; the transient global attention and long-context training increase computational/resource requirements. Also, while HTML-T5 improves element/action prediction, planning over long horizons still remains challenging when used alone (planning benefits from the modular WebAgent design).",
            "uuid": "e3202.1",
            "source_info": {
                "paper_title": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Flan-U-PaLM (baseline agent)",
            "name_full": "Flan-U-PaLM (prompted large generalist LLM used for open-loop planning and code generation)",
            "brief_description": "A large instruction-tuned generalist LLM used in this work as the program-synthesis module; when used alone (prompted) it performs open-loop planning and regex-based summarization, serving as a baseline agent for web tasks.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "Flan-U-PaLM (prompted)",
            "agent_description": "A single LLM approach where Flan-U-PaLM is prompted per role (plan, summarize, act) in an open-loop fashion, and simple regex-based retrieval is used to summarize HTML; used both as the program generator in WebAgent and as a single-LLM baseline performing entire pipeline by prompting.",
            "memory_used": false,
            "memory_type": "none (operates via prompt/context only; open-loop planning in baselines, no external or structured memory beyond normal LLM context)",
            "memory_mechanism_description": "As used as a baseline, planning is open-loop via prompting and summarization is regex-based; no iterative closed-loop history conditioning or specialized snippet retrieval/finetuned summarizer is used.",
            "task_name": "Real-world web automation (baseline comparison in Table 1)",
            "task_description": "Same web automation tasks as WebAgent but performed by a single prompted LLM without modular planning+summarization modules (open-loop).",
            "task_type": "planning / tool use (web automation)",
            "performance_with_memory": null,
            "performance_without_memory": "Baseline prompted Flan-U-PaLM (no specialized memory/modules): success rates — real-estate 10.0% (55.3% score), social-media 20.0% (25.0% score), map 10.0% (51.3% score) (Table 1).",
            "has_performance_comparison": true,
            "key_findings": "Open-loop prompting of a single generalist LLM without finetuned planning and summarization modules performs poorly on real websites; closed-loop memory-conditioned modules yield substantial gains.",
            "limitations_or_challenges": "Open-loop planning accumulates errors over long horizons; regex-based summarization is brittle on long/complex HTML. Lack of a specialized memory or retriever leads to poor performance on real web tasks.",
            "uuid": "e3202.2",
            "source_info": {
                "paper_title": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "MindAct (related work)",
            "name_full": "MindAct (a two-module approach for web tasks referenced from Deng et al., 2023)",
            "brief_description": "Related prior system that finetunes a language model to summarize raw HTML into task-relevant snippets and uses another model to predict web actions in a multiple-choice QA format; referenced for comparison in offline evaluations.",
            "citation_title": "Mind2web: Towards a generalist agent for the web",
            "mention_or_use": "mention",
            "agent_name": "MindAct",
            "agent_description": "Two-stage pipeline: a finetuned summarizer produces task-relevant HTML snippets and a separate actor model predicts actions (often presented as multi-choice QA) based on those snippets. MindAct evaluated in Mind2Web offline benchmark and used DeBERTa/Flan-T5 in original work.",
            "memory_used": false,
            "memory_type": "none (relies on snippet summarization and immediate context rather than a dedicated memory beyond context window)",
            "memory_mechanism_description": "Uses a finetuned summarization model to extract snippets from the presented candidate elements, then conditions the actor on those snippets; no explicit external or episodic memory mechanism beyond the context is described.",
            "task_name": "Mind2Web (offline action prediction / planning benchmark)",
            "task_description": "Offline action prediction across many websites and tasks: given snippets, instruction, and history, predict the element and operation (click/type/select) to perform; challenges include cross-task and cross-website generalization.",
            "task_type": "action prediction / planning",
            "performance_with_memory": null,
            "performance_without_memory": "Reported baselines in the paper: MindAct (Flan-T5-XL) and MindAct (GPT-4) show lower element accuracy / operation F1 / step success compared to HTML-T5-XL; paper states HTML-T5 increases element accuracy by ~5-8%, operation F1 by ~6-8%, and step success by ~4-8% over MindAct variants (Table 4).",
            "has_performance_comparison": true,
            "key_findings": "MindAct-style summarization + actor pipelines are effective offline baselines, but HTML-T5 (with its architectural and pretraining choices) outperforms MindAct variants on Mind2Web according to the paper.",
            "limitations_or_challenges": "MindAct in original form used DeBERTa/Flan-T5 and was evaluated offline; it may be limited by model choice and by not using HTML-specialized pretraining or global-local attention mechanisms.",
            "uuid": "e3202.3",
            "source_info": {
                "paper_title": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",
                "publication_date_yy_mm": "2023-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Mind2web: Towards a generalist agent for the web",
            "rating": 2
        },
        {
            "paper_title": "Synapse: Leveraging few-shot exemplars for humanlevel computer control",
            "rating": 2
        },
        {
            "paper_title": "Understanding html with large language models",
            "rating": 2
        },
        {
            "paper_title": "Toolformer: Language models can teach themselves to use tools",
            "rating": 1
        },
        {
            "paper_title": "LongT5: Efficient text-to-text transformer for long sequences",
            "rating": 1
        }
    ],
    "cost": 0.017402,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>A Real-World WebAgent With Planning, Long CONTEXT UNDERSTANDING, AND Program Synthesis</h1>
<p>Izzeddin Gur ${ }^{1 *}$ Hiroki Furuta ${ }^{1,2 * \dagger}$ Austin Huang ${ }^{1}$ Mustafa Safdari ${ }^{1}$ Yutaka Matsuo ${ }^{2}$<br>Douglas Eck ${ }^{1}$ Aleksandra Faust ${ }^{1}$<br>${ }^{1}$ Google DeepMind, ${ }^{2}$ The University of Tokyo<br>izzeddin@google.com, furuta@weblab.t.u-tokyo.ac.jp</p>
<h4>Abstract</h4>
<p>Pre-trained large language models (LLMs) have recently achieved better generalization and sample efficiency in autonomous web automation. However, the performance on real-world websites has still suffered from (1) open domainness, (2) limited context length, and (3) lack of inductive bias on HTML. We introduce WebAgent, an LLM-driven agent that learns from self-experience to complete tasks on real websites following natural language instructions. WebAgent plans ahead by decomposing instructions into sub-instructions, summarizes long HTML documents into task-relevant snippets, and acts on websites via Python programs generated from those. We design WebAgent with Flan-U-PaLM, for grounded code generation, and HTML-T5, a new pre-trained LLM for long HTML documents using local and global attention mechanisms and a mixture of long-span denoising objectives, for planning and summarization. We empirically demonstrate that our modular recipe improves the success on real websites by over $50 \%$, and that HTMLT5 is the best model to solve various HTML understanding tasks; achieving $18.7 \%$ higher success rate than the prior method on MiniWoB web automation benchmark, and SoTA performance on Mind2Web, an offline task planning evaluation.</p>
<h2>1 INTRODUCTION</h2>
<p>Large language models (LLM) (Brown et al., 2020; Chowdhery et al., 2022; OpenAI, 2023) can solve a variety of natural language tasks, such as arithmetic, commonsense, logical reasoning, question answering, text generation (Brown et al., 2020; Kojima et al., 2022; Wei et al., 2022), and even interactive decision making tasks (Ahn et al., 2022; Yao et al., 2022b). Recently, LLMs have also demonstrated success in autonomous web navigation by controlling computers or browsers to follow natural language instructions through multi-step reasoning and decision making (Furuta et al., 2023; Gur et al., 2022; Kim et al., 2023).</p>
<p>However, web automation on real-world websites has still suffered from (1) the lack of pre-defined action space, (2) much longer HTML documents than simulated observations, and (3) the absence of domain-specific knowledge for understanding HTML documents (Figure 1). Considering the open-endedness of real-world websites and the complexity of instructions, defining appropriate action spaces in advance is challenging. In addition, although several works have argued that recent LLMs with instruction-finetuning or reinforcement learning from human feedback improve HTML understanding and web automation accuracy (Furuta et al., 2023; Kim et al., 2023), their architectures are not always suitable to process real-world HTML documents; as presented in Figure 2, HTML tokens of real websites are much longer than those of simulators, and most LLMs have shorter context lengths than the average HTML tokens in real websites. It is prohibitively costly to treat such long documents as inputs directly, or adopt prior techniques such as text-XPath alignment (Li et al., 2021b) or text-HTML token separation (Wang et al., 2022a). To prioritize broader task generalization and model-size scaling, such domain knowledge for HTML documents is ignored in recent LLMs.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Challenges in real-world web automation. Recent language model agents (Furuta et al., 2023; Gur et al., 2022; Kim et al., 2023; Yao et al., 2022b) can navigate simulated websites (Shi et al., 2017; Yao et al., 2022a), where the agents manipulate pre-defined actions and receive simplified HTML documents that are easy to parse. In contrast, language model agents continue to face challenges in navigating real-world websites, where they must interact with dynamic environments, handle open-ended actions (actions that cannot be pre-determined), and process lengthy HTML documents containing significant amounts of task-irrelevant information.</p>
<p>In this work, we introduce WebAgent, an LLM-driven autonomous agent that learns from self-experience to complete user instructions on real websites by combining canonical web actions in a program space (Figure 3). WebAgent (i) plans sub-instructions for each step by decomposing natural language instructions, (ii) summarizes long HTML documents into task-relevant snippets based on the plan, and (iii) acts via programming on real websites by grounding sub-instructions and HTML snippets into executable Python codes. We combine two LLMs to form WebAgent: newly introduced HTML-T5, a domain-expert pre-trained language model, for task planning and conditional HTML summarization and Flan-UPaLM (Chowdhery et al., 2022; Chung et al., 2022) for grounded code generation. HTML-T5 has an encoder-decoder architecture and is specialized to capture the structure of long HTML documents better by adopting local and global attention mechanisms (Guo et al., 2022). It is pre-trained using a mixture of long-span denoising objective (Tay et al., 2022) on a large-scale HTML corpus extracted from CommonCrawl. To ground language model agents into real websites, we introduce self-experience supervision, where the domain-expert language models are finetuned with data generated by scripted planning/summarization and self-generated programming.</p>
<p>Existing LLM-driven agents often solve decision making tasks with a single LLM conditioned on different prompts per role (Kim et al., 2023; Sun et al., 2023; Zheng et al., 2023), which is, however, not enough for real-world tasks whose complexity is higher than that of simulators. The empirical evaluations reveal that our method incorporating self-bootstrapped specialist language models improves HTML understanding and grounding, and achieves better generalization than single LLM agent. In real-world web automation, WebAgent significantly increases the success rate by 50%, and error analysis emphasizes that coupling task planning with HTML summarization in specialized language models is essential for task success. Moreover, HTML-T5 not only works as a core module for WebAgent but also achieves strong results by itself on the web-based tasks. On MiniWoB++ (Liu et al., 2018; Shi et al., 2017), HTML-T5 achieves 18.7% higher success than previous language model agent (Gur et al., 2022) while also outperforming competitive baselines, such as naive local-global attention models (Guo et al., 2022) and its instruction-finetuned ones (Chung et al., 2022). On the Mind2Web (Deng et al., 2023), an offline task planning dataset, HTML-T5 achieves SoTA performance among Synapse (Zheng et al., 2023) with GPT-3.5, and MindAct with FLan-T5-XL and GPT-4 (OpenAI, 2023). In summary, our key contributions are:</p>
<ul>
<li>We propose WebAgent, integration of two modular LLMs under self-supervision for real-world web automation. The domain-expert language model handles planning and HTML summarization, and a generalist language model generates executable Python programs.</li>
<li>We newly introduce HTML-T5 – a language model with local-global attention mechanism that is pre-trained with a mixture of long-span denoising objective on a large-scale HTML corpus, curated from CommonCrawl, to capture the syntax and semantics of HTML better.</li>
</ul>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Statistics of HTML tokens among real websites. Compared to simulator (about 0.5K tokens on average), HTML tokens of real websites are much longer (from 7K to 14K), which takes up the context length of large language models. As preprocessing, we remove the irrelevant tags (e.g. <script>, <meta>) and keep necessary attributes (e.g. id, type, value).</p>
<ul>
<li>WebAgent notably improves the success rate by over $50 \%$ in real websites. When fine-tuned on downstream demonstrations, HTML-T5 itself outperforms prior language model agent by $18.7 \%$ in MiniWoB++, and achieves SoTA performance in Mind2Web, even surpassing GPT-4.</li>
</ul>
<h1>2 Related Works</h1>
<p>Web Automation Web automation is a sequential decision making task where agents manipulate browsers following given instructions (Shi et al., 2017), such as form filling (Diaz et al., 2013) or information retrieval (Adolphs et al., 2022) through the sequence of computer actions (Li et al., 2020; Mazumder \&amp; Riva, 2020; Shvo et al., 2021). Prior works have realized the web automation via reinforcement learning (Gur et al., 2019; Humphreys et al., 2022; Jia et al., 2019; Shaw et al., 2023), finetuned (Furuta et al., 2023; Gur et al., 2022) or prompted LLMs (Kim et al., 2023; Sun et al., 2023; Yao et al., 2022b; Zheng et al., 2023) on the simulated websites (Shi et al., 2017; Toyama et al., 2021; Yao et al., 2022a). However, there are still huge gaps between simplified simulators and real web environments; for instance, the average tokens for HTML pages are about 15 times larger (Figure 2), and pre-defined action space for specific websites is a strong assumption that may harm the generalization to out-of-distribution web pages or instructions.</p>
<p>MindAct (Deng et al., 2023) could be the most relevant work, where finetuned language model summarizes the raw HTML document into task-relevant snippets, and another model predicts the web actions in a multi-choice QA format. While MindAct also combines several language models, it has just adopted DeBERTa (He et al., 2021) and Flan-T5 (Chung et al., 2022) for summarization and actor modules, and evaluated it on the offline dataset. In contrast, we design HTML-T5, specialized for web-based tasks, to handle long HTML documents. WebAgent leverages HTML-T5 finetuned with self-experience for summarization and planning, and Flan-U-PaLM as a capable programmer, which enables it to generate open-ended web actions and to act on online real-world websites.</p>
<p>Program Synthesis In addition to common LLMs (Brown et al., 2020; Chowdhery et al., 2022; Touvron et al., 2023), several works have proposed programming-focused language models (Chen et al., 2021a; Feng et al., 2020; Li et al., 2022; Wang et al., 2021) and their benchmarks (Austin et al., 2021; Hendrycks et al., 2021a; Lu et al., 2021). Another line of work has investigated the tool augmentation of LLMs (Parisi et al., 2022) by decoding API calls (Schick et al., 2023) or Python snippets to be parsed with the interpreter (Gao et al., 2023). Most works deal with the program synthesis on the static dataset, except for the attempts in robotics (Liang et al., 2023) and game (Trivedi et al., 2022; Wang et al., 2023a), where LLMs output Python or JavaScript snippets to command the agents. Similarly, we leverage the ability of code generation as an open-ended action space for web-based agents to manipulate the real website, and demonstrate LLMs can sequentially decode Python selenium codes considering the given sub-instructions and HTML in the prompts.</p>
<p>See extended related works on document understanding and LLM for task planning in Appendix B.</p>
<h2>3 WebAgent</h2>
<p>WebAgent is a new architecture that combines two LLMs to achieve efficient real-world web automation. HTML-T5, a domain-expert LLM, is responsible for predicting the next sub-instruction (planning) and generating related HTML snippets (summarization). Flan-U-PaLM (540B) (Chowdhery et al., 2022; Chung et al., 2022), is prompted to generate executable Python programs based on the planning and summarization provided by HTML-T5 (Figure 3). This modular two-stage approach enables WebAgent to effectively navigate and process HTML documents.</p>
<p>Workflow Users initiate natural language interactions with a clear intent, such as apartment searching. Upon receiving the initial request, HTML-T5 formulates a "go to <URL>" sub-instruction, triggering Flan-U-PaLM to generate a corresponding Python program that navigates to the specified website. The raw HTML content of the newly opened page is extracted and fed into HTML-T5 along with the</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 4: HTML-T5 consists of (1) local and global attention mechanisms (Ainslie et al., 2020; Guo et al., 2022) and (2) a mixture of denoising objectives (Tay et al., 2022) with longer-span corruption on large-scale HTML corpus. The local and global attention mechanisms are suitable for the hierarchical tree structures of HTML documents. Because of the sparsity of content tokens in HTML, short mean span length (e.g. $\mu=3$ ), often used in prior works (Raffel et al., 2020), only masks less meaningful chunks. Employing longer span length (e.g. $\mu=8$ ) helps pre-trained language models to capture the syntax and semantics of HTML better.
user's instruction and previous planning steps. This information is utilized to predict the next subinstruction and identify relevant reference IDs for extractive HTML summarization. Flan-U-PaLM, in turn, generates a Python program based on these sub-instructions and combined HTML snippets. This iterative process of planning, summarization, and program synthesis continues until a designated end-of-episode sub-instruction is predicted or the maximum number of iterations is reached.</p>
<h1>3.1 HTML-T5</h1>
<p>Prior research has shown that general-purpose LLMs, such as T5 (Raffel et al., 2020), Flan-T5 (Chung et al., 2022), and InstructGPT (Ouyang et al., 2022), can effectively navigate web environments (Furuta et al., 2023; Gur et al., 2022; Kim et al., 2023). However, unlike specialist transformer models (Li et al., 2021b; Wang et al., 2022a; Zhao et al., 2022), these general-purpose LLMs do not fully utilize the HTML-specific information that could otherwise lead to better understanding of HTML content. To address this limitation, we introduce HTML-T5, a pre-trained encoder-decoder language model specifically designed for HTML-based web automation tasks. HTML-T5 carefully merges the generalist and specialist characteristics of language models. It processes HTML in a text-to-text manner and employs local and global attention mechanisms (Ainslie et al., 2020) in the encoder to capture the hierarchical structure of long HTML inputs. HTML-T5 is pre-trained on a large-scale HTML corpus curated from CommonCrawl using a mixture of long-span denoising objectives (Tay et al., 2022), and then finetuned it for each downstream task. For WebAgent, we employ the self-experience supervision approach to align the model with real websites.</p>
<p>Model Architecture Unlike natural language, HTML documents possess an explicit hierarchical structure. This structure comprises elements such as <input>, <label>, and <button>, along with their associated attributes like class, label, and id. These elements are defined locally and combined hierarchically to create HTML documents. To model this inherent hierarchy, we replace the common dense attention (Vaswani et al., 2017) with local and global attention mechanisms (Ainslie et al., 2020). Local attention restricts each token to only attend to neighboring tokens within a window. Additionally, transient global attention allows each token to attend to tokens beyond its immediate window. This is achieved through the aggregation and normalization of token representations within each window, resulting in a global memory representation. Figure 4 describes the concepts of HTMLT5; leaf elements in HTML (green) could be processed by local attention, and internal elements (purple) could be compressed into transient global attention, which naturally fits the hierarchical structure of HTML. Following LongT5 (Guo et al., 2022), we use dense attention in the decoder.</p>
<p>Pre-Training with Mixture of Long-Span Denoising Our pre-training approach for HTML-T5 utilizes a span denoising objective. This involves randomly masking spans of tokens within an HTML document, with span lengths drawn from a Gaussian distribution with a mean of $\mu$. The objective is then to predict the masked spans using the remaining tokens in the HTML document (Raffel</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Modules</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">real-estate</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">social-media</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">map</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Error Ratio (\%)</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Plan</td>
<td style="text-align: center;">Sum</td>
<td style="text-align: center;">Success</td>
<td style="text-align: center;">Score</td>
<td style="text-align: center;">Success</td>
<td style="text-align: center;">Score</td>
<td style="text-align: center;">Success</td>
<td style="text-align: center;">Score</td>
<td style="text-align: center;">Program</td>
<td style="text-align: center;">Plan</td>
<td style="text-align: center;">Sum</td>
</tr>
<tr>
<td style="text-align: center;">Flan-U-PaLM</td>
<td style="text-align: center;">$\mathscr{F}$</td>
<td style="text-align: center;">$\mathscr{F}$</td>
<td style="text-align: center;">10.0</td>
<td style="text-align: center;">55.3</td>
<td style="text-align: center;">20.0</td>
<td style="text-align: center;">25.0</td>
<td style="text-align: center;">10.0</td>
<td style="text-align: center;">51.3</td>
<td style="text-align: center;">$36 / 58 / 11$</td>
<td style="text-align: center;">$38 / 0 / 78$</td>
<td style="text-align: center;">$26 / 12 / 11$</td>
</tr>
<tr>
<td style="text-align: center;">Flan-U-PaLM+P</td>
<td style="text-align: center;">$\boldsymbol{\sim}$</td>
<td style="text-align: center;">$\mathscr{F}$</td>
<td style="text-align: center;">50.0</td>
<td style="text-align: center;">79.5</td>
<td style="text-align: center;">20.0</td>
<td style="text-align: center;">38.3</td>
<td style="text-align: center;">30.0</td>
<td style="text-align: center;">73.8</td>
<td style="text-align: center;">$39 / 65 / 14$</td>
<td style="text-align: center;">$56 / 30 / 29$</td>
<td style="text-align: center;">$5 / 5 / 57$</td>
</tr>
<tr>
<td style="text-align: center;">Flan-U-PaLM+S</td>
<td style="text-align: center;">$\mathscr{F}$</td>
<td style="text-align: center;">$\boldsymbol{\sim}$</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">45.7</td>
<td style="text-align: center;">25.0</td>
<td style="text-align: center;">62.1</td>
<td style="text-align: center;">15.0</td>
<td style="text-align: center;">46.3</td>
<td style="text-align: center;">$30 / 67 / 0$</td>
<td style="text-align: center;">$40 / 13 / 100$</td>
<td style="text-align: center;">$30 / 20 / 0$</td>
</tr>
<tr>
<td style="text-align: center;">WebAgent</td>
<td style="text-align: center;">$\boldsymbol{\sim}$</td>
<td style="text-align: center;">$\boldsymbol{\sim}$</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">87.6</td>
<td style="text-align: center;">70.0</td>
<td style="text-align: center;">85.8</td>
<td style="text-align: center;">80.0</td>
<td style="text-align: center;">93.8</td>
<td style="text-align: center;">$20 / 33 / 25$</td>
<td style="text-align: center;">$70 / 50 / 50$</td>
<td style="text-align: center;">$10 / 17 / 25$</td>
</tr>
</tbody>
</table>
<p>Table 1: Success rate of real-world web automation on real estate, social media and map websites. The score stands for the percentage of covered attributes specified in given instructions. WebAgent, with language model modules for planning and summarization, achieves the best success ( $65 \%, 70 \%, 80 \%$, respectively), surpassing other baselines, such as a single Flan-U-PaLM, that with a planning language model (Flan-U-PaLM+P), and that with a summarization language model (Flan-U-PaLM+S). Without language model modules, prompted Flan-U-PaLM plans in an open-loop manner (Plan: $\mathscr{F}$ ) and regular-expression-based retrieval summarizes HTML inputs (Sum: $\mathscr{F}$ ). The results imply that self-experience supervision notably improves the performance, and task planning should be learned by finetuning domain language models for closed-loop planning, rather than by prompting single LLM for open-loop planning. The error analysis describes the ratio across three types of errors in (real-estate) / (social-media) / (map) domains, which also points out that better adaptive planner to decompose the given instructions would contribute to further improvements of WebAgent.
et al., 2020; Tay et al., 2022; Ainslie et al., 2023). While a span length of $\mu=3$ is commonly used, such short spans often mask less meaningful chunks in HTML documents, such as $&lt;/$, id $=$, or " $&gt;$ (Figure 4), where the signal-to-noise ratio can be significantly lower than natural language text. In contrast, longer spans can contain more semantically meaningful chunks, such as <form class=" or type="submit">. Our empirical findings indicate that setting $\mu \in{8,64}$ yields the optimal mixture for HTML documents (Section 4.2).
We adopt 4096 input sequence length and 910 output sequence length during pre-training. In total, $15 \%$ of input tokens are randomly masked in the denoising objective. For the pre-training dataset, we collect 100 WARC files (April 2019) from the CommonCrawl corpus and remove the non-Unicode or alphanumeric-only HTML documents. We then extract subtrees around <label> elements that have a special attribute called for that associates the corresponding label with a unique input element in the same HTML document. This pre-processing step improves the quality of the pre-training corpus by focusing only on HTML that is relevant for instruction following and grounding. Our final dataset has 3.41 M examples. We pre-train HTML-T5 for 100K iterations following the practice in other T5 models (Chung et al., 2022; Lester et al., 2021). See Appendix C for further details.</p>
<h1>3.2 Self-Experience Supervision for Alignment with Real Websites</h1>
<p>Gathering example demonstrations for LLMs to understand websites poses a significant obstacle in real-world web automation. While humans can effortlessly execute instruction following on actual websites, manually annotating every planning, summarization, and program synthesis step as detailed above is impractical. To address this issue, we propose self-experience supervision, a semi-supervised approach that necessitates minimal human involvement. In this method, manually curated scripts generate planning and summarization steps, while Flan-U-PaLM is tasked with generating Python programs. Our WebAgent aligns domain-specific language models, such as HTML-T5, with these self-gathered real-world experiences through fine-tuning (Wang et al., 2022b). This enables the generalization and alignment of agents to complex real-world tasks.</p>
<p>Instruction Templates We maintain a collection of instruction templates that incorporate placeholders such as "Show me the way from <start> to <goal> by <n-th> <transportation> at map website". We sample instructions by randomly assigning values to placeholders from pre-defined key-value pairs.</p>
<p>Scripted Planning and Prompted Programming We employ a rule-based parser to decompose instructions into sequences of sub-instructions; corresponding reference IDs are retrieved from HTML using regular expressions. At each step of the process, Flan-U-PaLM is provided with the sub-instruction and the associated HTML snippets to generate navigation programs that are executed through Selenium WebDriver. The success of recorded demonstrations varies, and automating success criteria for real-world tasks remains challenging. To refine the learning experience, we utilize environmental feedback to eliminate critical failures, such as program execution errors, retriever errors, and clearly erroneous URL prefixes (Ni et al., 2023).</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 5: Example episodes of real-world web automation in map domain. Considering the given instruction and HTML, WebAgent predicts the next sub-instruction and task-relevant snippet, and then synthesizes the Python script (gray), while treating the sub-instruction as a comment in the script. See Appendix G for extended figure.</p>
<p>Finetuning for Planning and Summarization HTML-T5, a core component of WebAgent, is fine-tuned using self-experience demonstrations gathered through instruction sampling, scripted planning, and prompted program synthesis, as detailed earlier. It utilizes task instructions (e.g. please search 2 bedroom and 2+ bathroom houses in new york, ny with a max price of $\$ 7500$ on real estate website), sub-instruction histories (e.g. go to real estate website, type in new york into search, click on search, click on price, click on max rent), and raw HTML as inputs. Subsequently, it generates the next sub-instruction (e.g. type in 7500 into max rent) and extracts the relevant data-ref attributes used for retrieving HTML snippets. Section 4.1 demonstrates the significance of integrating HTML summarization into sub-instruction prediction for enhancing real-world web automation performance.</p>
<h1>3.3 Grounded Program Synthesis</h1>
<p>Web automation on real-world websites faces challenges due to the open-ended action spaces, unlike simplified simulators (Shi et al., 2017; Yao et al., 2022a). In contrast to previous approaches (Gur et al., 2019; Humphreys et al., 2022; Jia et al., 2019; Liu et al., 2018), real-world web agents cannot pre-define a categorical action space to specify the interactive elements on the websites. To address this open-domain challenge, we introduce the act via programming paradigm in web automation by utilizing the conditional code generation capabilities of LLMs (Chen et al., 2021a; Liang et al., 2023). Provided with few-shot generic examples (such as selecting checkboxes, entering text into inputs, clicking on options, and scrolling etc.) for program generation, the next sub-instruction, and the extracted HTML snippet from HTML-T5, Flan-U-PaLM (Chowdhery et al., 2022; Chung et al., 2022) decodes an Python program (Figure 3) executable with Selenium WebDriver, a library for browser automation. This conditional program synthesis requires LLMs to not only generate code to follow natural language instructions but also understand the semantics and functionality of HTML elements. We provide several Python snippet examples generated by Flan-U-PaLM as follows (sub-instructions are treated as comments in the script):</p>
<div class="codehilite"><pre><span></span><code><span class="err">#</span><span class="w"> </span><span class="nx">Type</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">walnut</span><span class="w"> </span><span class="nx">creek</span><span class="p">,</span><span class="w"> </span><span class="nx">ca</span><span class="w"> </span><span class="nx">into</span><span class="w"> </span><span class="nx">search</span>
<span class="nx">driver</span><span class="p">.</span><span class="nx">find_element</span><span class="p">(</span><span class="nx">By</span><span class="p">.</span><span class="nx">CSS_SELECTOR</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="p">[</span><span class="nx">data</span><span class="o">-</span><span class="nx">ref</span><span class="p">=</span><span class="s">&quot;175&quot;</span><span class="o">|</span><span class="err">&#39;</span><span class="p">).</span><span class="nx">clear</span><span class="p">()</span>
<span class="nx">driver</span><span class="p">.</span><span class="nx">find_element</span><span class="p">(</span><span class="nx">By</span><span class="p">.</span><span class="nx">CSS_SELECTOR</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="p">[</span><span class="nx">data</span><span class="o">-</span><span class="nx">ref</span><span class="p">=</span><span class="s">&quot;175&quot;</span><span class="o">|</span><span class="err">&#39;</span><span class="p">).</span><span class="nx">send_keys</span><span class="p">(</span><span class="s">&quot;walnut creek, ca&quot;</span><span class="p">)</span>
<span class="err">#</span><span class="w"> </span><span class="nx">Submit</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">search</span>
<span class="nx">driver</span><span class="p">.</span><span class="nx">find_element</span><span class="p">(</span><span class="nx">By</span><span class="p">.</span><span class="nx">CSS_SELECTOR</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="p">[</span><span class="nx">data</span><span class="o">-</span><span class="nx">ref</span><span class="p">=</span><span class="s">&quot;175&quot;</span><span class="o">|</span><span class="err">&#39;</span><span class="p">).</span><span class="nx">submit</span><span class="p">()</span>
<span class="err">#</span><span class="w"> </span><span class="nx">Click</span><span class="w"> </span><span class="nx">on</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">apartments</span>
<span class="nx">driver</span><span class="p">.</span><span class="nx">find_element</span><span class="p">(</span><span class="nx">By</span><span class="p">.</span><span class="nx">CSS_SELECTOR</span><span class="p">,</span><span class="w"> </span><span class="err">&#39;</span><span class="p">[</span><span class="nx">data</span><span class="o">-</span><span class="nx">ref</span><span class="p">=</span><span class="s">&quot;572&quot;</span><span class="o">|</span><span class="err">&#39;</span><span class="p">).</span><span class="nx">click</span><span class="p">()</span>
<span class="err">#</span><span class="w"> </span><span class="nx">Scroll</span><span class="w"> </span><span class="nx">down</span><span class="w"> </span><span class="nx">housing</span><span class="w"> </span><span class="k">type</span><span class="w"> </span><span class="nx">by</span><span class="w"> </span><span class="mi">200</span><span class="nx">px</span>
<span class="nx">driver</span><span class="p">.</span><span class="nx">execute_script</span><span class="p">(</span><span class="err">&#39;</span><span class="nx">getScrollParent</span><span class="p">(</span><span class="nx">document</span><span class="p">.</span><span class="nx">querySelector</span><span class="p">(</span><span class="s">&quot;#type-of-housing&quot;</span><span class="p">)).</span><span class="nx">scrollBy</span><span class="p">((</span><span class="nx">top</span><span class="p">:</span><span class="w"> </span><span class="mi">200</span><span class="p">))</span><span class="err">&#39;</span><span class="p">)</span>
</code></pre></div>

<h2>4 EXPERIMENTAL RESULTS</h2>
<p>To study how a modular combination of LLMs under self-supervision enables real-world web automation by overcoming open-endedness and long context documents, we execute instruction-following tasks on real websites (Section 4.1). In Appendix E, we also test WebAgent on WebSRC (Chen et al., 2021b), a static HTML comprehension benchmark, compared to prior transformer models specialized for structured documents (Li et al., 2021b; Zhao et al., 2022). In addition, we quantify the performance of HTML-T5 itself on simulated web benchmark, MiniWoB++, and offline task planning benchmark, Mind2Web (Section 4.2).</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: right;">Span Length $\boldsymbol{\mu}$</th>
<th style="text-align: right;">real-estate</th>
<th style="text-align: right;">MiniWoB++</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Architectures</td>
<td style="text-align: left;">Attention Type</td>
<td style="text-align: right;">$\boldsymbol{L}=\mathbf{2 0 4 8}$</td>
<td style="text-align: right;">$\boldsymbol{L}=\mathbf{4 0 9 6}$</td>
<td style="text-align: right;">(no HTML-denoising)</td>
</tr>
<tr>
<td style="text-align: left;">Flan-T5-Base</td>
<td style="text-align: left;">Dense</td>
<td style="text-align: right;">$34.0 \%$</td>
<td style="text-align: right;">$35.3 \%$</td>
<td style="text-align: right;">$3,8,64$ Prefix</td>
</tr>
<tr>
<td style="text-align: left;">Long-T5-Base</td>
<td style="text-align: left;">Local</td>
<td style="text-align: right;">$43.4 \%$</td>
<td style="text-align: right;">$44.0 \%$</td>
<td style="text-align: right;">$3,8,64$</td>
</tr>
<tr>
<td style="text-align: left;">Long-T5-Base</td>
<td style="text-align: left;">Local \&amp; Global</td>
<td style="text-align: right;">$\mathbf{5 3 . 1 \%}$</td>
<td style="text-align: right;">$\mathbf{5 3 . 6 \%}$</td>
<td style="text-align: right;">$8,64$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">$82.46$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">$8,32,64$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">$8,64,96$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">$16,64$</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">78.07</th>
<th style="text-align: center;">53.8\%</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">80.56</td>
<td style="text-align: center;">55.2\%</td>
</tr>
<tr>
<td style="text-align: center;">80.56</td>
<td style="text-align: center;">55.4\%</td>
</tr>
<tr>
<td style="text-align: center;">82.46</td>
<td style="text-align: center;">57.0\%</td>
</tr>
<tr>
<td style="text-align: center;">82.16</td>
<td style="text-align: center;">55.6\%</td>
</tr>
<tr>
<td style="text-align: center;">81.29</td>
<td style="text-align: center;">53.6\%</td>
</tr>
<tr>
<td style="text-align: center;">79.97</td>
<td style="text-align: center;">55.2\%</td>
</tr>
</tbody>
</table>
<p>Table 2: (Left) Architecture comparison on MiniWoB++ 12K dataset (Liu et al., 2018) with average success rate over 56 tasks. Local and global attention matches to the hierarchical tree structure of HTML, and then improves the success rate by over 18\%, compared to the instruction-finetuned dense attentions (Chung et al., 2022; Furuta et al., 2023). (Right) HTML-denoising comparison with different mixtures of span length (Raffel et al., 2020; Tay et al., 2022). We use LongT5-Base models for pre-training. HTML-denoising generally improves the performance on offline task planning on real estate website and MiniWoB benchmark. Especially, using longer span lengths $(\mu \in{8,6})$ outperforms other choices, including the popular configuration in natural language domain ( $\mu \in{3,8,64}+$ Prefix LM objective), which can reduce the less meaningful prediction from shorter spans (e.g. $\mu=3$ ), and inject the structural bias of HTML better.</p>
<h1>4.1 Real-World Web Automation</h1>
<p>Evaluation Methodology We first evaluate WebAgent with the real-world navigation performance under human supervision, at real estate website (a platform for housing), social media website (a network of communities), and map website. These three websites have different properties. real-estate requires long-horizon planning (about 20 steps per episode) for complex formfilling with a few page transitions (at least 2 pages), and social-media needs shorter plans (about 10 steps per episode) with many page transitions (at least 4 pages) by selecting appropriate hyperlinks on the page. map is the easiest domain with shorter plans and a few page transitions. WebAgent receives natural language instructions (e.g. Can you search for a studio bedroom, 1+ bathroom apartments in oroville, ca for corporate housing on real estate website?, or Could you present the most new thread of Python community filtered by Tutorial tag on social media website?), and acts via planning, summarizing by HTML-T5, and then programming by Flan-U-PaLM (Figure 5). Through the self-experience supervision process, we curate 260 episodes on real estate website, 230 episodes on social media website, and 410 episodes on map website to finetune HTML-T5.</p>
<p>We prepare 20 different natural language instructions (see Appendix F for the full list), and measure the success rate and score for the evaluation. The score represents the percentage of required attributes covered during the episode (Yao et al., 2022a); for instance, (1) apartments for (2) corporate housing with (3) studio bedroom and (4) 1+ bathroom located in (5) oroville, ca, can be specified in the instruction. When the agents could search the housing satisfying (1), (2), (5) and not (3), (4), the score is $60(=100 \times 3 / 5)$. If the agents achieve 100 score, that episode will mark as success.</p>
<p>Results For comparison, we prepare three baselines, consisting of language model modules and a single LLM conditioned on different prompts per role, such as Flan-U-PaLM (Chung et al., 2022), that with a planning language model (Flan-U-PaLM+P), and that with a summarization language model (Flan-U-PaLM+S). If they do not use language model modules, prompted Flan-U-PaLM plans in an open-loop manner (Plan: $\neq$ ), and regular-expression-based retrieval summarizes given raw HTML (Sum: $\neq$ ). Table 1 shows that by leveraging planning and summarization language model modules, WebAgent achieves best $65 \%$ success and $87.6 \%$ score on real-estate, $70 \%$ success and $85.8 \%$ score on social-media, and $80 \%$ success and $93.8 \%$ score on map, significantly outperforming single Flan-U-PaLM, or with partial language model modules (most of those achieve about 10 - $30 \%$ success). This result suggests that self-experience supervision notably improves the performance, and closed-loop planning grounded on HTML observations via finetuned domain language models is more suitable for open-ended web automation than open-loop planning with few-shot LLMs. This trend is remarkable in real-estate (even Flan-U-PaLM+P achieves 50\% success), where the longer planning horizon is needed to fulfill instructions. We also observe that coupling sub-instruction prediction with HTML summarization in language model modules plays a critical role in task success. The development of more capable planning modules to decompose the given instructions adaptively and accurately could help WebAgent improve the performance further.</p>
<p>Error Analysis We also analyze the reason of failures by categorizing them into programming, planning, and summarization errors (Table 1). Programming error does not satisfy the given subinstructions or HTML snippet. Planning error predicts sub-instructions conflicting with user instruc-</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Cross-Task</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Cross-Website</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Cross-Semals</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Train</td>
<td style="text-align: center;">Ele. Acc</td>
<td style="text-align: center;">Op. F1</td>
<td style="text-align: center;">Step SR</td>
<td style="text-align: center;">SR</td>
<td style="text-align: center;">Ele. Acc</td>
<td style="text-align: center;">Op. F1</td>
<td style="text-align: center;">Step SR</td>
<td style="text-align: center;">SR</td>
<td style="text-align: center;">Ele. Acc</td>
<td style="text-align: center;">Op. F1</td>
<td style="text-align: center;">Step SR</td>
<td style="text-align: center;">SR</td>
</tr>
<tr>
<td style="text-align: center;">Synapse (GPT-3.5)</td>
<td style="text-align: center;">ICL</td>
<td style="text-align: center;">34.4</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">30.6</td>
<td style="text-align: center;">2.0</td>
<td style="text-align: center;">28.8</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">23.4</td>
<td style="text-align: center;">1.1</td>
<td style="text-align: center;">29.4</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">25.9</td>
<td style="text-align: center;">1.6</td>
</tr>
<tr>
<td style="text-align: center;">MindAct (Flan-T5-XL)</td>
<td style="text-align: center;">SL</td>
<td style="text-align: center;">55.1</td>
<td style="text-align: center;">75.7</td>
<td style="text-align: center;">52.0</td>
<td style="text-align: center;">5.2</td>
<td style="text-align: center;">42.0</td>
<td style="text-align: center;">65.2</td>
<td style="text-align: center;">38.9</td>
<td style="text-align: center;">5.1</td>
<td style="text-align: center;">42.1</td>
<td style="text-align: center;">66.5</td>
<td style="text-align: center;">39.6</td>
<td style="text-align: center;">2.9</td>
</tr>
<tr>
<td style="text-align: center;">MindAct (GPT-4)</td>
<td style="text-align: center;">ICL</td>
<td style="text-align: center;">41.6</td>
<td style="text-align: center;">60.6</td>
<td style="text-align: center;">36.2</td>
<td style="text-align: center;">2.0</td>
<td style="text-align: center;">35.8</td>
<td style="text-align: center;">51.1</td>
<td style="text-align: center;">30.1</td>
<td style="text-align: center;">2.0</td>
<td style="text-align: center;">37.1</td>
<td style="text-align: center;">46.5</td>
<td style="text-align: center;">26.4</td>
<td style="text-align: center;">2.0</td>
</tr>
<tr>
<td style="text-align: center;">HTML-T5-XL (ours)</td>
<td style="text-align: center;">SL</td>
<td style="text-align: center;">60.6</td>
<td style="text-align: center;">81.7</td>
<td style="text-align: center;">57.8</td>
<td style="text-align: center;">10.3</td>
<td style="text-align: center;">47.6</td>
<td style="text-align: center;">71.9</td>
<td style="text-align: center;">42.9</td>
<td style="text-align: center;">5.6</td>
<td style="text-align: center;">50.2</td>
<td style="text-align: center;">74.9</td>
<td style="text-align: center;">48.3</td>
<td style="text-align: center;">5.1</td>
</tr>
</tbody>
</table>
<p>Table 4: Offline action prediction performance in Mind2Web dataset. We leverage the cached candidate generation results and direct QA formulation by following Deng et al. (2023). HTML-T5 significantly outperforms MindAct with Flan-T5 or GPT-4, and Synapse (Zheng et al., 2023) with GPT-3.5, across task/website/domain generalization in terms of all the metrics (element accuracy, operation F1, and success rates).
tions, and summarization error fails to extract the relevant HTML snippets for given sub-instructions. From the website perspective, the failures on real-estate concentrate in planning because of its long-horizon nature. map also fails in planning when confusing starting point and destination. In contrast, social-media tends to fail in programming due to the ambiguous sub-instructions or summarization including redundant hyperlinks, which results in transiting wrong pages or clicking unexecutable elements. From the method perspective, WebAgent often fails in planning by predicting incorrect sub-instructions (for instance, in real-estate, WebAgent generates incorrect plans in $70 \%$ of failure episodes), while other baselines more fail in programming or summarization steps. This observation indicates that, through the self-experience supervision, the ratio of programming and summarization errors has decreased while the fundamental difficulty of planning, which requires consistent and accurate prediction over long horizon without error accumulation, still remains.</p>
<h1>4.2 Ablation of HTML-T5</h1>
<p>In addition to the evaluation as WebAgent system, we extensively examine HTML-T5 about (i) the generalization to other websites with Mind2Web (Deng et al., 2023), (ii) the performance on MiniWoB++, a standard web automation benchmark (Liu et al., 2018; Shi et al., 2017), and (iii) its architecture and pre-training objective. We adopt 16 K tokens for the context window unless otherwise mentioned. We present results on offline task planning, and description generation (Gur et al., 2022) to test HTML understanding on static dataset in Appendix H.</p>
<p>Mind2Web Mind2Web (Deng et al., 2023) is an action-annotated real-world dataset with over 2 K instructions collected from 137 websites. It provides action prediction tasks that measure the generalization of LLMs across the tasks, websites, and their domains (e.g. travel, shopping). Similar to real-world evaluation, the input is a set of HTML snippets, a task instruction, and an action history. The output comprises a target element to interact with, along with the operation, such as click, type, or select an option. We finetune HTML-T5-XL with the training dataset. The performance is evaluated with element accuracy, operation F1, and step success rate that cares for both element and operation correctness. Table 4 reveals that HTML-T5 significantly outperforms baselines with Flan-T5-XL or GPT-4 (OpenAI, 2023) across task/website/domain generalization, which increases element accuracy by 5-8\%, operation F1 by $6-8 \%$, and step success rate by $4-8 \%$. This highlights that HTML-T5 can handle real-world web automation tasks better and shows generalization beyond our real-world evaluation with 3 websites.</p>
<p>MiniWoB++ We here evaluate HTML-T5 on 56 simulated tasks in MiniWoB++ using 100 evaluation episodes per task. Inputs are analogous to real-world evaluation, utilizing HTML documents, while outputs are adhering to a pre-defined format by the simulator such as $\operatorname{click}($ ref $=X)$. We finetune HTML-T5 with 12 K human demonstrations (Liu et al., 2018), and compare the average success rate to prior supervised-learned agents (Gur et al., 2022; Humphreys et al., 2022), LongT5, and its instruction-finetuned variants (Chung et al., 2022) ${ }^{1}$. Table 3 shows that HTML-T5-XL significantly</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>outperforms WebN-T5, the prior best model, by 18.7\%. Notably, we demonstrate HTML-denoising consistently improves the performance on top of LongT5 in all the model sizes, better than instructionfinetuning introduced in prior work (Furuta et al., 2023). Furthermore, we finetune HTML-T5-XL with 347 K demonstrations from Furuta et al. (2023), which performs better than 11B-parameter Flan-T5-XXL even with 3B parameters, achieving $85.6 \%$ success. These prove we successfully incorporate domain knowledge on HTML comprehension for web automation into pre-trained language models.</p>
<p>Architecture and Objective We hypothesize that local and global attention mechanisms can capture the hierarchical structures of HTML documents better than dense attention. We compare the web automation performance among 56 MiniWoB++ tasks (Gur et al., 2022), by finetuning HTML-T5 with public 12K-episode dataset (Liu et al., 2018). We adopt 2048 and 4096 tokens as input length and prepare Base-size architectures. Table 2 (left) reveals that the combination of local and global attentions achieves the superior success rate by over $18 \%$ compared to the instruction-finetuned dense attentions (Chung et al., 2022; Raffel et al., 2020) and local attention only. Surprisingly, local attention only still surpasses the dense attention by about $9 \%$, which suggests local relation between elements and attributes in HTML are essential for web tasks.</p>
<p>As for pre-training objective in Table 2 (right), HTML-denoising generally improves the performance on offline task planning on real estate website and MiniWoB. Especially, using only longer span lengths $(\mu \in{8,64})$ outperforms other choices, including the popular configuration in natural language domain ( $\mu \in{3,8,64}+$ Prefix LM objective), which can reduce the less meaningful prediction from shorter spans (e.g. $\mu=3$ ), and inject the structural bias of HTML into language models better. See Appendix H. 2 for further results with model scaling.</p>
<h1>5 DISCUSSION AND LIMITATION</h1>
<p>Modular Approach with Specialist Language Models We demonstrate it is beneficial to divide web automation into planning, HTML summarization, and code generation, and to combine domainexpert language models aligned with self-experience data. Such modular approaches have also been adopted to support the inference of LLMs (Xu et al., 2023), multimodal tasks (Zeng et al., 2022), and robotics (Ahn et al., 2022), which, however, might cause additional computational costs and latency.</p>
<p>Broad Generalization across the Internet Because open-loop planning with prompted Flan-UPaLM achieves at most 10 - 30\% success, we have demonstrated that self-experience supervision on real websites is essential for planning modules. As we demonstrated in Mind2Web, our method could generalize across the internet if we have enough data. It would be expected to collect demonstrations at scale and align larger domain-expert models with them in future works.</p>
<p>Feedback for Program Synthesis We leverage Flan-U-PaLM with 540B parameters, as a capable program synthesis module via few-shot prompting. Such a large model, however, makes it challenging to reflect the feedback about the errors in generated code, compared to smaller models. We leave it as future direction to incorporate the feedback for program synthesis into larger language models.</p>
<p>Evaluation for Real-world Web Automation Beyond the simulated web environments (Shi et al., 2017; Yao et al., 2022a), we have exhibited WebAgent can follow given complex and sometimes ambiguous instructions on real estate, social media and map websites. On the other hand, it is costly to evaluate the performance of autonomous agents in the real world. Automated evaluation with minimal human intervention would be helpful for the scalable development of real-world web agents.</p>
<h2>6 CONCLUSION</h2>
<p>We build a system for real-world web automation, combining HTML-T5 for planning and HTML summarization and Flan-U-PaLM for grounded program synthesis. Our proposed WebAgent achieves around 70-80\% success on real websites via self-experience supervision, outperforming single LLM approach by over $50 \%$, which suggests dividing the sequence of sub-problems with multiple language models can increase the entire task success. We also propose a scalable recipe for HTML-specialized language models where we train local and global attention mechanisms with a mixture of long-span denoising objectives to capture the hierarchical structures of HTML documents. HTML-T5 not only plays an essential role in WebAgent but also can achieve the best results on a variety of HTML-based benchmarks such as Mind2Web and MiniWoB++. We hope our work contributes to getting us one-step closer to the practical deployment of autonomous web agent systems.</p>
<h1>ETHICS STATEMENT</h1>
<p>This paper presents encouraging evidence of autonomous agents' potential for deployment on real websites, extending beyond simulated environments. In the foreseeable future, this technology could lead to the development of sophisticated AI assistant tools for computers and smartphones, enhancing productivity and accessibility for society.
While we recognize the promising aspects of autonomous agents, we must also consider the potential for misuse and unintended consequences in their development. As our proposed system is based on LLMs, there is a risk of prompt injection. The improper use of web automation could pose cybersecurity threats and expose users to scams. To mitigate these risks, it is crucial for researchers, policymakers, and industry stakeholders to collaborate on establishing guidelines and regulations for the development of autonomous agents. Additionally, security research focused on LLM agents will become an essential domain for society.</p>
<h2>ACKNOWLEDGMENTS</h2>
<p>We thank Heiga Zen, Yingjie Miao, Yusuke Iwasawa, Joshua Ainslie, Santiago Ontanon, Quoc V. Le, Zoubin Ghahramani, Jeff Dean, Tris Warkentin for the supports and advises on this work. HF was supported by JSPS KAKENHI Grant Number JP22J21582.</p>
<h2>REFERENCES</h2>
<p>Leonard Adolphs, Benjamin Boerschinger, Christian Buck, Michelle Chen Huebscher, Massimiliano Ciaramita, Lasse Espeholt, Thomas Hofmann, Yannic Kilcher, Sascha Rothe, Pier Giuseppe Sessa, and Lierni Sestorain Saralegui. Boosting search engines with interactive agents. In Transactions on Machine Learning Research, 2022.</p>
<p>Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Daniel Ho, Jasmine Hsu, Julian Ibarz, Brian Ichter, Alex Irpan, Eric Jang, Rosario Jauregui Ruano, Kyle Jeffrey, Sally Jesmonth, Nikhil J Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Kuang-Huei Lee, Sergey Levine, Yao Lu, Linda Luu, Carolina Parada, Peter Pastor, Jornell Quiambao, Kanishka Rao, Jarek Rettinghouse, Diego Reyes, Pierre Sermanet, Nicolas Sievers, Clayton Tan, Alexander Toshev, Vincent Vanhoucke, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu, Mengyuan Yan, and Andy Zeng. Do as i can, not as i say: Grounding language in robotic affordances. arXiv preprint arxiv:2204.01691, 2022.</p>
<p>Joshua Ainslie, Santiago Ontanon, Chris Alberti, Vaclav Cvicek, Zachary Fisher, Philip Pham, Anirudh Ravula, Sumit Sanghai, Qifan Wang, and Li Yang. Etc: Encoding long and structured inputs in transformers. arXiv preprint arXiv:2004.08483, 2020.</p>
<p>Joshua Ainslie, Tao Lei, Michiel de Jong, Santiago Ontañón, Siddhartha Brahma, Yury Zemlyanskiy, David Uthus, Mandy Guo, James Lee-Thorp, Yi Tay, Yun-Hsuan Sung, and Sumit Sanghai. Colt5: Faster long-range transformers with conditional computation. arXiv preprint arXiv:2303.09752, 2023.</p>
<p>Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey, Yanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan Botha, James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng, Colin Cherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, Clément Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark Díaz, Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, Guy Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey Hui, Jeremy Hurwitz, Michael Isard, Abe Ittycheriah, Matthew Jagielski, Wenhao Jia, Kathleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni,</p>
<p>Aroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric Ni, Andrew Nystrom, Alicia Parrish, Marie Pellat, Martin Polacek, Alex Polozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel, Renee Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng, Ce Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu. Palm 2 technical report. arXiv preprint arXiv:2305.10403, 2023.</p>
<p>Srikar Appalaraju, Bhavan Jasani, Bhargava Urala Kota, Yusheng Xie, and R. Manmatha. Docformer: End-to-end transformer for document understanding. In International Conference on Computer Vision, 2021.</p>
<p>Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis with large language models. arXiv preprint arXiv:2108.07732, 2021.</p>
<p>Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. arXiv preprint arXiv:2005.14165, 2020.</p>
<p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021a.</p>
<p>Xingyu Chen, Zihan Zhao, Lu Chen, JiaBao Ji, Danyang Zhang, Ao Luo, Yuxuan Xiong, and Kai Yu. WebSRC: A dataset for web-based structural reading comprehension. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 4173-4185, 2021b.</p>
<p>Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.</p>
<p>Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. Scaling instruction-finetuned language models. arXiv preprint arxiv:2210.11416, 2022.</p>
<p>Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.</p>
<p>Arman Cohan, Franck Dernoncourt, Doo Soon Kim, Trung Bui, Seokhwan Kim, Walter Chang, and Nazli Goharian. A discourse-aware attention model for abstractive summarization of long documents. arXiv preprint arXiv:1804.05685, 2018.</p>
<p>Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and Yu Su. Mind2web: Towards a generalist agent for the web. arXiv preprint arXiv:2306.06070, 2023.</p>
<p>Oscar Diaz, Itziar Otaduy, and Gorka Puente. User-driven automation of web form filling. In International Conference on Web Engineering, 2013.</p>
<p>Alexander R. Fabbri, Irene Li, Tianwei She, Suyi Li, and Dragomir R. Radev. Multi-news: a largescale multi-document summarization dataset and abstractive hierarchical model. arXiv preprint arXiv:1906.01749, 2019.</p>
<p>Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou. Codebert: A pre-trained model for programming and natural languages. arXiv preprint arXiv:2002.08155, 2020.</p>
<p>Hiroki Furuta, Ofir Nachum, Kuang-Huei Lee, Yutaka Matsuo, Shixiang Shane Gu, and Izzeddin Gur. Multimodal web navigation with instruction-finetuned foundation models. arXiv preprint arxiv:2305.11854, 2023.</p>
<p>Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. Pal: Program-aided language models. arXiv preprint arXiv:2211.10435, 2023.</p>
<p>Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. arXiv preprint arXiv:2101.02235, 2021.</p>
<p>Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, and Yinfei Yang. LongT5: Efficient text-to-text transformer for long sequences. In Findings of the Association for Computational Linguistics: NAACL 2022, pp. 724-736, 2022.</p>
<p>Izzeddin Gur, Ulrich Rueckert, Aleksandra Faust, and Dilek Hakkani-Tur. Learning to navigate the web. In International Conference on Learning Representations, 2019.</p>
<p>Izzeddin Gur, Ofir Nachum, Yingjie Miao, Mustafa Safdari, Austin Huang, Aakanksha Chowdhery, Sharan Narang, Noah Fiedel, and Aleksandra Faust. Understanding html with large language models. arXiv preprint arxiv:2210.03945, 2022.</p>
<p>Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. Deberta: Decoding-enhanced bert with disentangled attention. In International Conference on Learning Representations, 2021.</p>
<p>Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas Mazeika, Akul Arora, Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song, and Jacob Steinhardt. Measuring coding challenge competence with apps. arXiv preprint arXiv:2105.09938, 2021a.</p>
<p>Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. In International Conference on Learning Representations, 2021b.</p>
<p>Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. arXiv preprint arXiv:2201.07207, 2022.</p>
<p>Peter C Humphreys, David Raposo, Toby Pohlen, Gregory Thornton, Rachita Chhaparia, Alistair Muldal, Josh Abramson, Petko Georgiev, Alex Goldin, Adam Santoro, and Timothy Lillicrap. A data-driven approach for learning to control computers. In International Conference on Machine Learning, 2022.</p>
<p>Sheng Jia, Jamie Ryan Kiros, and Jimmy Ba. DOM-q-NET: Grounded RL on structured language. In International Conference on Learning Representations, 2019.</p>
<p>Geunwoo Kim, Pierre Baldi, and Stephen McAleer. Language models can solve computer tasks. arXiv preprint arxiv:2303.17491, 2023.</p>
<p>Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. In Advances In Neural Information Processing Systems, 2022.</p>
<p>Taku Kudo and John Richardson. Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing. arXiv preprint arXiv:1808.06226, 2018.</p>
<p>Brian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efficient prompt tuning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 3045-3059, November 2021.</p>
<p>Chenliang Li, Bin Bi, Ming Yan, Wei Wang, Songfang Huang, Fei Huang, and Luo Si. Structurallm: Structural pre-training for form understanding. arXiv preprint arXiv:2105.11210, 2021a.</p>
<p>Junlong Li, Yiheng Xu, Lei Cui, and Furu Wei. Markuplm: Pre-training of text and markup language for visually-rich document understanding. arXiv preprint arxiv:2110.08518, 2021b.</p>
<p>Peizhao Li, Jiuxiang Gu, Jason Kuen, Vlad I. Morariu, Handong Zhao, Rajiv Jain, Varun Manjunatha, and Hongfu Liu. Selfdoc: Self-supervised document representation learning. In Conference on Computer Vision and Pattern Recognition, 2021c.</p>
<p>Yang Li, Jiacong He, Xin Zhou, Yuan Zhang, and Jason Baldridge. Mapping natural language instructions to mobile ui action sequences. In Annual Conference of the Association for Computational Linguistics, 2020.</p>
<p>Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Remi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de, Masson dAutume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, and Oriol Vinyals. Competition-level code generation with alphacode, 2022.</p>
<p>Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman, Brian Ichter, Pete Florence, and Andy Zeng. Code as policies: Language model programs for embodied control. arXiv preprint arXiv:2209.07753, 2023.</p>
<p>Chin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. In Text Summarization Branches Out, pp. 74-81. Association for Computational Linguistics, July 2004.</p>
<p>Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, and Peter Stone. Llm+p: Empowering large language models with optimal planning proficiency. arXiv preprint arXiv:2304.11477, 2023.</p>
<p>Evan Zheran Liu, Kelvin Guu, Panupong Pasupat, and Percy Liang. Reinforcement learning on web interfaces using workflow-guided exploration. In International Conference on Learning Representations, 2018.</p>
<p>Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V. Le, Barret Zoph, Jason Wei, and Adam Roberts. The flan collection: Designing data and methods for effective instruction tuning. arXiv preprint arXiv:2301.13688, 2023.</p>
<p>Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, Ge Li, Lidong Zhou, Linjun Shou, Long Zhou, Michele Tufano, Ming Gong, Ming Zhou, Nan Duan, Neel Sundaresan, Shao Kun Deng, Shengyu Fu, and Shujie Liu. Codexglue: A machine learning benchmark dataset for code understanding and generation. arXiv preprint arXiv:2102.04664, 2021.</p>
<p>Sahisnu Mazumder and Oriana Riva. Flin: A flexible natural language interface for web navigation. arXiv preprint arXiv:2010.12844, 2020.</p>
<p>Shen-Yun Miao, Chao-Chun Liang, and Keh-Yih Su. A diverse corpus for evaluating and developing english math word problem solvers. arXiv preprint arXiv:2106.15772, 2021.</p>
<p>Ramesh Nallapati, Feifei Zhai, and Bowen Zhou. Summarunner: A recurrent neural network based sequence model for extractive summarization of documents. arXiv preprint arXiv:1611.04230, 2016.</p>
<p>Ansong Ni, Srini Iyer, Dragomir Radev, Ves Stoyanov, Wen-tau Yih, Sida I Wang, and Xi Victoria Lin. Lever: Learning to verify language-to-code generation with execution. In International Conference on Machine Learning, 2023.</p>
<p>Kolby Nottingham, Prithviraj Ammanabrolu, Alane Suhr, Yejin Choi, Hannaneh Hajishirzi, Sameer Singh, and Roy Fox. Do embodied agents dream of pixelated sheep: Embodied decision making using language guided world modelling. In International Conference on Machine Learning, 2023.</p>
<p>OpenAI. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. Training language models to follow instructions with human feedback. arXiv preprint arxiv:2203.02155, 2022.</p>
<p>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311-318, Philadelphia, Pennsylvania, USA, July 2002. Association for Computational Linguistics.</p>
<p>Aaron Parisi, Yao Zhao, and Noah Fiedel. Talm: Tool augmented language models. arXiv preprint arXiv:2205.12255, 2022.</p>
<p>Arkil Patel, Satwik Bhattamishra, and Navin Goyal. Are nlp models really able to solve simple math word problems? arXiv preprint arXiv:2103.07191, 2021.</p>
<p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1-67, 2020.</p>
<p>Adam Roberts, Hyung Won Chung, Anselm Levskaya, Gaurav Mishra, James Bradbury, Daniel Andor, Sharan Narang, Brian Lester, Colin Gaffney, Afroz Mohiuddin, Curtis Hawthorne, Aitor Lewkowycz, Alex Salcianu, Marc van Zee, Jacob Austin, Sebastian Goodman, Livio Baldini Soares, Haitang Hu, Sasha Tsvyashchenko, Aakanksha Chowdhery, Jasmijn Bastings, Jannis Bulian, Xavier Garcia, Jianmo Ni, Andrew Chen, Kathleen Kenealy, Jonathan H. Clark, Stephan Lee, Dan Garrette, James Lee-Thorp, Colin Raffel, Noam Shazeer, Marvin Ritter, Maarten Bosma, Alexandre Passos, Jeremy Maitin-Shepard, Noah Fiedel, Mark Omernick, Brennan Saeta, Ryan Sepassi, Alexander Spiridonov, Joshua Newlan, and Andrea Gesmundo. Scaling up models and data with t 5 x and seqio. arXiv preprint arXiv:2203.17189, 2022.</p>
<p>Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. arXiv preprint arXiv:2302.04761, 2023.</p>
<p>Eva Sharma, Chen Li, and Lu Wang. Bigpatent: A large-scale dataset for abstractive and coherent summarization. arXiv preprint arXiv:1906.03741, 2019.</p>
<p>Peter Shaw, Mandar Joshi, James Cohan, Jonathan Berant, Panupong Pasupat, Hexiang Hu, Urvashi Khandelwal, Kenton Lee, and Kristina Toutanova. From pixels to ui actions: Learning to follow instructions via graphical user interfaces. arXiv preprint arXiv:2306.00245, 2023.</p>
<p>Tianlin Shi, Andrej Karpathy, Linxi Fan, Jonathan Hernandez, and Percy Liang. World of bits: An open-domain platform for web-based agents. In International Conference on Machine Learning, 2017.</p>
<p>Maayan Shvo, Zhiming Hu, Rodrigo Toro Icarte, Iqbal Mohomed, Allan D. Jepson, and Sheila A. McIlraith. Appbuddy: Learning to accomplish tasks in mobile apps via reinforcement learning. In Canadian Conference on Artificial Intelligence, 2021.</p>
<p>Tom Silver, Soham Dan, Kavitha Srinivas, Joshua B. Tenenbaum, Leslie Pack Kaelbling, and Michael Katz. Generalized planning in pddl domains with pretrained large language models. arXiv preprint arXiv:2305.11014, 2023.</p>
<p>Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, and Animesh Garg. ProgPrompt: Generating situated robot task plans using large language models. arXiv preprint arXiv:2209.11302, 2022.</p>
<p>Haotian Sun, Yuchen Zhuang, Lingkai Kong, Bo Dai, and Chao Zhang. Adaplanner: Adaptive planning from feedback with language models. arXiv preprint arXiv:2305.16653, 2023.</p>
<p>Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi, Denny Zhou, and Jason Wei. Challenging bigbench tasks and whether chain-of-thought can solve them. arXiv preprint arXiv:2210.09261, 2022.</p>
<p>Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. Commonsenseqa: A question answering challenge targeting commonsense knowledge. arXiv preprint arXiv:1811.00937, 2019.</p>
<p>Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Denny Zhou, Neil Houlsby, and Donald Metzler. Ul2: Unifying language learning paradigms. arXiv preprint arXiv:2205.05131, 2022.</p>
<p>Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Pranesh Srinivasan, Laichee Man, Kathleen Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed Chi, and Quoc Le. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239, 2022.</p>
<p>Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation language models. arXiv preprint arxiv:2302.13971, 2023.</p>
<p>Daniel Toyama, Philippe Hamel, Anita Gergely, Gheorghe Comanici, Amelia Glaese, Zafarali Ahmed, Tyler Jackson, Shibl Mourad, and Doina Precup. Androidenv: A reinforcement learning platform for android. arXiv preprint arXiv:2105.13231, 2021.</p>
<p>Dweep Trivedi, Jesse Zhang, Shao-Hua Sun, and Joseph J. Lim. Learning to synthesize programs as interpretable and generalizable policies. arXiv preprint arXiv:2108.13643, 2022.</p>
<p>Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, and Subbarao Kambhampati. Large language models still can't plan (a benchmark for llms on planning and reasoning about change). arXiv preprint arXiv:2206.10498, 2023.</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems, 2017.</p>
<p>Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. arXiv preprint arXiv:2305.16291, 2023a.</p>
<p>Qifan Wang, Yi Fang, Anirudh Ravula, Fuli Feng, Xiaojun Quan, and Dongfang Liu. Webformer: The web-page transformer for structure information extraction. arXiv preprint arXiv:2202.00217, 2022a.</p>
<p>Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. Self-instruct: Aligning language model with self generated instructions. arXiv preprint arXiv:2212.10560, 2022b.</p>
<p>Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 8696-8708, 2021.</p>
<p>Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao Liang. Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents. In International Conference on Machine Learning, 2023b.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022.</p>
<p>Canwen Xu, Yichong Xu, Shuohang Wang, Yang Liu, Chenguang Zhu, and Julian McAuley. Small models are valuable plug-ins for large language models. arXiv preprint arXiv:2305.08848, 2023.</p>
<p>Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, and Ming Zhou. LayoutLM: Pretraining of text and layout for document image understanding. arXiv preprint arxiv:1912.13318, 2019 .</p>
<p>Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan. Webshop: Towards scalable real-world web interaction with grounded language agents. arXiv preprint arxiv:2207.01206, 2022a.</p>
<p>Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022b.</p>
<p>Andy Zeng, Maria Attarian, Brian Ichter, Krzysztof Choromanski, Adrian Wong, Stefan Welker, Federico Tombari, Aveek Purohit, Michael Ryoo, Vikas Sindhwani, Johnny Lee, Vincent Vanhoucke, and Pete Florence. Socratic models: Composing zero-shot multimodal reasoning with language. arXiv preprint arXiv:2204.00598, 2022.</p>
<p>Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. Pegasus: Pre-training with extracted gap-sentences for abstractive summarization. In International Conference on Machine Learning, 2020.</p>
<p>Zihan Zhao, Lu Chen, Ruisheng Cao, Hongshen Xu, Xingyu Chen, and Kai Yu. TIE: Topological information enhanced structural reading comprehension on web pages. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1808-1821, 2022.</p>
<p>Longtao Zheng, Rundong Wang, and Bo An. Synapse: Leveraging few-shot exemplars for humanlevel computer control. arXiv preprint arXiv:2306.07863, 2023.</p>
<p>Chenguang Zhu, Yang Liu, Jie Mei, and Michael Zeng. Mediasum: A large-scale media interview dataset for dialogue summarization. arXiv preprint arXiv:2103.06410, 2021.</p>
<h1>APPENDIX</h1>
<h2>A Note for Real-World Evaluation</h2>
<p>The development of autonomous agents should consider the security and safety aspects. In the real website evaluation, we have carefully conducted the experiments under human supervision in case undesired behaviors happen. We use Selenium WebDriver ${ }^{2}$, a popular library for browser automation, and limit the access per second not to stress the server. We have anonymized the real websites we tested on for safety and privacy concerns.</p>
<h2>B EXTENDED RELATED WORKS</h2>
<p>Document Understanding Understanding structural documents has been a practical challenge for transformer-based language models. Prior works employ layout-informed tokens (Xu et al., 2019) or even multimodal tokens from visual inputs (Appalaraju et al., 2021; Li et al., 2021a;c). Especially, for the documents written in markup languages, text-XPath alignment (Li et al., 2021b), token separation between text and HTML (Wang et al., 2022a), or extra topological information of HTML (Zhao et al., 2022) are proposed to leverage their syntax better. On the other hand, such a domain knowledge conflicts with recent generalist and scaling trends around LLMs (Anil et al., 2023; OpenAI, 2023). Because web agents require the instruction-conditioned HTML understanding, it also would be desirable to reconcile specialist aspects for HTML documents with generalist capabilities for natural language tasks. In this work, we design HTML-T5 to incorporate the structural bias of HTML by combining local-global attention for the encoder and a mixture of long-span denoising, while it can solve instruction-following better in downstream web-based tasks.
LLM for Task Planning The prior knowledge of commonsense in LLMs has allowed us to leverage them for a variety of task planning. For instance, Huang et al. (2022) propose LLM agent that generates natural language plans in an open-loop manner. Nottingham et al. (2023) and Wang et al. (2023b) perform sequential closed-loop planning on MineCraft. Singh et al. (2022) decode robotic plans with pythonic text, and several works incorporate planning definition and domain language into the outputs (Liu et al., 2023; Silver et al., 2023; Valmeekam et al., 2023). On the other hand, our WebAgent leverages finetuned specialist language models and performs closed-loop planning coupled with HTML summarization by decomposing given instructions. We empirically prove that our system is superior to open-loop planning with a single generalist LLM with prompting.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>C IMPLEMENTATION DETAILS OF HTML-T5</h1>
<p>We use the implementation of local and global attentions released by Guo et al. (2022) ${ }^{3}$. Following Guo et al. (2022), we set the local radius to $r=127$, and block size for transient global attention to $k=16$. For the pre-training objective, similar to Tay et al. (2022), we construct the mixtures and then use long mean span lengths: $\mu \in{8,64}$, and all the denoising ratio (percentage of masked tokens in the input sequence) is set to 0.15 . We adopt 4096 input sequence length and 910 output sequence length during the pre-training. The batch size for training is set to 128 . We train the models with 100 K iterations following other pre-training strategies for T5 families (Chung et al., 2022; Lester et al., 2021). We leverage SeqIO (Roberts et al., 2022) and T5X (Roberts et al., 2022) library to manage the training pipeline. We also use SentencePiece (Kudo \&amp; Richardson, 2018) with 32K tokens from C4 dataset (Raffel et al., 2020) as a tokenizer. During the downstream finetuning, we adopt 16 K tokens for the context window unless otherwise mentioned. We have used cloud TPU-v3, which has a 32 GiB HBM memory space, with 128 cores for the experiments.
For the dataset, we prepare 100 WARC files (April 2019) from CommonCrawl ${ }^{4}$, and pre-process the raw HTML by removing non-Unicode and alphanumeric documents and extracting subtrees around <label> elements that have for attribute, to reduce the noise in training corpus, which results in about 3.41 M examples (Table 5).</p>
<table>
<thead>
<tr>
<th style="text-align: center;"># of examples</th>
<th style="text-align: center;"># of tokens</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Average</td>
<td style="text-align: center;">90th</td>
<td style="text-align: center;">Max</td>
</tr>
<tr>
<td style="text-align: center;">3.41 M</td>
<td style="text-align: center;">1020</td>
<td style="text-align: center;">4566</td>
<td style="text-align: center;">7627</td>
</tr>
</tbody>
</table>
<p>Table 5: Statistics of CommonCrawl HTML corpus for self-supervised denoising pre-training of HTML-T5. Input lengths are measured in tokens by Kudo \&amp; Richardson (2018).</p>
<h2>D WebAgent Example Flow in real-Estate Website</h2>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 6: An example flow with planning, summarization, and grounded program synthesis in the real estate website. HTML-T5 iteratively predicts a decomposed sub-instruction and task-relevant snippet (orange) in a closed-loop manner, conditioning on the HTML documents, instruction (yellow), and history of past predictions (green). Flan-U-PaLM is prompted with sub-instruction and snippet (orange) to decode python programs (blue).</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>E WebSRC: Static HTML Comprehension</h1>
<p>To emphasize the advantage of our modular approach, we test WebAgent on a static website comprehension benchmark, WebSRC (Chen et al., 2021b), which is a contextual QA dataset with HTML documents. The questions require an understanding of the spatial and logical structure of websites, and the answers are either text span on HTML or yes/no. For the comprehensive evaluation, WebSRC has three different types of websites, $K V$, Comparison, and Table. KV task is a value extraction from the attribute key. Comparison task has several entities with the same attributes. Table task requires a structural understanding with header columns and values in the row. We finetune HTML-T5 for snippet extraction to predict data-ref corresponding to the answer and use dev set for the evaluation.</p>
<p>As did in real-world web automation, HTML-T5 first predicts data-ref attribute of task-relevant snippet from the input HTML document. To make sure there is enough context, we extract the snippet from the predicted element to the two-level-up via XPath. If it exceeds the context length of Flan-U-PaLM, we limit it into parent elements. If it still does not work, we truncate the end of extracted snippet to fit within the token budget. Because snippet extraction in table structure often loses the context to solve question-answering, we just truncate HTML documents for Table tasks. Flan-U-PaLM predicts the answers seeing 5 -shot examples.</p>
<p>As shown in Table 6, single LLM, such as Flan-U-PaLM or HTML-T5, has struggled to the limited context length or model capacity. In contrast, WebAgent, our LLM-collaborative approach, enhances the performance from both single generalist and specialist LLMs, and shows competitive results with strong baselines. This demonstrates that modular LLMs work complementarily to each other. Figure 7 presents the performance comparison on different types of websites (KV, Comparison, Table) among MarkupLM (Li et al., 2021b), TIE (Zhao et al., 2022), and WebAgent. WebAgent is better at Comparison tasks, but inferior to structural understanding for KV and Table tasks, compared to other baselines, which suggest that generalist LLMs are still not suitable for recognizing structural data such as table.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Models</th>
<th style="text-align: center;">EM</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">T-PLM (Chen et al., 2021b)</td>
<td style="text-align: center;">61.67</td>
<td style="text-align: center;">69.85</td>
</tr>
<tr>
<td style="text-align: left;">H-PLM (Chen et al., 2021b)</td>
<td style="text-align: center;">70.12</td>
<td style="text-align: center;">74.14</td>
</tr>
<tr>
<td style="text-align: left;">V-PLM (Chen et al., 2021b)</td>
<td style="text-align: center;">73.22</td>
<td style="text-align: center;">76.16</td>
</tr>
<tr>
<td style="text-align: left;">MarkupLM-Large (Li et al., 2021b)</td>
<td style="text-align: center;">74.43</td>
<td style="text-align: center;">80.54</td>
</tr>
<tr>
<td style="text-align: left;">TIE-Large (Zhao et al., 2022)</td>
<td style="text-align: center;">$\mathbf{8 1 . 6 6}$</td>
<td style="text-align: center;">$\mathbf{8 6 . 2 4}$</td>
</tr>
<tr>
<td style="text-align: left;">Flan-U-PaLM</td>
<td style="text-align: center;">40.01</td>
<td style="text-align: center;">47.56</td>
</tr>
<tr>
<td style="text-align: left;">HTML-T5-Large</td>
<td style="text-align: center;">73.09</td>
<td style="text-align: center;">76.66</td>
</tr>
<tr>
<td style="text-align: left;">HTML-T5-XL</td>
<td style="text-align: center;">74.73</td>
<td style="text-align: center;">78.73</td>
</tr>
<tr>
<td style="text-align: left;">WebAgent</td>
<td style="text-align: center;">75.50</td>
<td style="text-align: center;">85.75</td>
</tr>
<tr>
<td style="text-align: left;">WebAgent (oracle)</td>
<td style="text-align: center;">76.91</td>
<td style="text-align: center;">$\mathbf{8 6 . 6 4}$</td>
</tr>
</tbody>
</table>
<p>Table 6: Evaluation on WebSRC (Chen et al., 2021b) with dev set. WebAgent, our collaborative LLMs, enhances the performance from both single generalist (Flan-U-PaLM) or specialist LLMs (HTML-T5). WebAgent (oracle) uses oracle snippets that are guaranteed to include the answers, instead of those predicted by finetuned HTML-T5.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 7: The performance comparison on different types of websites in WebSRC dev set.</p>
<h1>F List of Language Instructions for Real-world Web Automation</h1>
<h2>real-estate</h2>
<ol>
<li>can you search for a studio bedroom, $1+$ bathroom houses in escondido, ca for corporate housing and price less than 12100 on real estate website.</li>
<li>can you find me a studio bedroom, $1+$ bathroom townhomes in hollywood, ca and price less than 14600 on real estate website.</li>
<li>can you search for a studio bedroom, $1+$ bathroom condos in inglewood, ca for senior housing and price less than 8700 on real estate website.</li>
<li>I would like to search for a studio bedroom, $1+$ bathroom houses in compton, ca and price more than 1200 for corporate housing on real estate website.</li>
<li>can you search for a studio bedroom, $1+$ bathroom apartments in oroville, ca for corporate housing on real estate website.</li>
<li>find me a studio bedroom, $1+$ bathroom houses in modesto, ca on real estate website.</li>
<li>can you search for a studio bedroom, $1+$ bathroom condos in redwood city, ca for student and price more than 1900 on real estate website.</li>
<li>find me a 1 bedroom condos in santa clara, ca and price between 1600 and 7400 on real estate website.</li>
<li>find me a 1 bedroom, $3+$ bathroom apartments in martinez, ca with min price 1800 on real estate website.</li>
<li>can you find me a 2 bedroom, $2+$ bathroom townhomes in concord, ca and price more than 600 on real estate website.</li>
<li>can you find me a studio bedroom, $2+$ bathroom apartments in san diego, ca and price less than 9300 on real estate website.</li>
<li>find me a studio bedroom houses in novato, ca and price between 1500 and 6700 on real estate website.</li>
<li>can you find me a studio bedroom, any bathroom townhomes in petaluma, ca and price more than 1000 on real estate website.</li>
<li>search for a 1 bedroom apartments in modesto, ca and price more than 1000 on real estate website.</li>
<li>find me a 1 bedroom, $2+$ bathroom apartments in watts, ca for senior housing less than 6300 on real estate website.</li>
<li>can you find me a 1 bedroom houses in victorville, ca that have dog friendly, furnished and price more than 700 on real estate website.</li>
<li>I need a 2 bedroom, any bathroom condos in inglewood, ca and price more than 1000 on real estate website.</li>
<li>find me a 2 bedroom, $2+$ bathroom apartments in livermore, ca on real estate website.</li>
<li>can you find me a 2 bedroom apartments in santa clara, ca that has parking and price less than 10300 on real estate website.</li>
<li>can you search for a 2 bedroom condos in oakland, ca on real estate website.</li>
</ol>
<h2>social-media</h2>
<ol>
<li>Show me the most hot thread in r/google at social media website.</li>
<li>Can you point out the most hot thread in r/learnpython at social media website.</li>
<li>Could you check the 1st hot thread in r/artificial at social media website.</li>
<li>Can I check the most hot thread in Taiwan on social media website.</li>
<li>Show me the first new thread in r/facebook at social media website.</li>
<li>Present the most new thread of r/Python filtered by Tutorial flair on social media website.</li>
<li>Could you check the 1st new thread in r/facebook at social media website.</li>
<li>I want to read the 1st hot thread from r/Python tagged as Daily Thread at social media website.</li>
<li>Present the most hot thread of r/google filtered by Info I Mod Post flair on social media website.</li>
<li>Show me the most new thread in r/learnmachinelearning filtered by Help flair at social media website.</li>
<li>Can you point out the first hot thread in r/deeplearning at social media website.</li>
<li>Could you check the 1st hot thread in r/machinelearningnews at social media website.</li>
<li>Present the most hot thread of r/artificial filtered by News flair on social media website.</li>
<li>Please find me the first hot thread in r/facebook at social media website.</li>
<li>Present the most new thread of r/machinelearningnews filtered by Startup News flair on social media website.</li>
<li>Show me the most hot thread in r/artificial filtered by AI Art flair at social media website.</li>
<li>Could you check the first new thread in r/facebook at social media website.</li>
<li>I want to read the most top thread from r/google tagged as Info I Mod Post at social media website.</li>
<li>Show me the most new thread in r/startups filtered by Share Your Startup flair at social media website.</li>
<li>Could you check the 2nd new thread in r/facebook at social media website.</li>
</ol>
<h1>map</h1>
<ol>
<li>Show me the way from San Jose to Mountain View by 2nd Cycling at map website.</li>
<li>Please show me the way from The Painted Ladies to San Francisco Zoo with 3rd Best option at map website.</li>
<li>Could you tell me the path from California Academy of Sciences to de Young Museum by 1st Transit at map website.</li>
<li>Could you tell me the way from Union Square to The Painted Ladies with 2nd Cycling option at map website.</li>
<li>Please present the way from Chappell Hayes Observation Tower to San Jose with 2nd Walking option at map website.</li>
<li>Please present the path from Jack London Square to Emeryville by 2nd Cycling at map website.</li>
<li>I'd like to move The Midway from Children's Fairyland by 1st Cycling at map website.</li>
<li>I'd like to move Chase Center from San Francisco - Oakland Bay Bridge with 2nd Transit option at map website.</li>
<li>I want to move Pier 39 from Berkeley by 3rd Cycling at map website.</li>
<li>I want to go to Emeryville from Mountain View with 2nd Cycling option at map website.</li>
<li>Can you point out the way from San Mateo to Stanford University by 2nd Cycling at map website.</li>
<li>Could you point out the way from Palace of Fine Arts to UC Berkeley by 1st Cycling at map website.</li>
<li>Point out the way from The Painted Ladies to San Francisco Museum of Modern Art by 2nd Driving at map website.</li>
<li>Could you find the path from Union Square to Palo Alto by 1st Cycling at map website.</li>
<li>Please check the way from San Jose to San José Mineta International Airport with 1st Walking at map website.</li>
<li>Check the path from San Francisco Zoo to Berkeley with 1st Cycling at map website.</li>
<li>I'd like to check Parking Lots along the way from Stanford University to The Painted Ladies with Best option at map website.</li>
<li>Check Gas stations along the way from de Young Museum to Oakland with Driving option at map website.</li>
<li>Please show me Hotels along the way from Palace of Fine Arts to Berkeley by Transit at map website.</li>
<li>Check Gas stations along the way from Bay Area Discovery Museum to Santa Cruz with Best option at map website.</li>
</ol>
<h2>G Example Episode in Real-World Web Automation</h2>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ https://github.com/google-research/longt5
${ }^{4}$ https://commoncrawl.org/&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>