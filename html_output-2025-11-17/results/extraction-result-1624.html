<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1624 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1624</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1624</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-31.html">extraction-schema-31</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <p><strong>Paper ID:</strong> paper-53061463</p>
                <p><strong>Paper Title:</strong> Automatic Generation of Programs</p>
                <p><strong>Paper Abstract:</strong> Automatic generation of program is definitely an alluring problem. Over the years many approaches emerged, which try to smooth away parts of programmers’ work. One approach already widely used today is colloquially known as code generation (or code generators). This approach includes many methods and tools, therefore many different terms are used to describe this concept. The very basic tools are included in various available Integrated Development Environments (IDE). These include templates, automatic code completion, macros and other tools. On a higher level, code generation is performed by tools, which create program source code from metadata or data. Again, there are thousands of such tools available both commercial and open source. Generally available are programs for generating source code from relational or object database schema, object or class diagrams, test cases, XML schema, XSD schema, design patterns or various formalized descriptions of the problem domain. These tools mainly focus on the generation of a template or skeleton for an application or application module, which is then filled with actual algorithms by a programmer. The great advantage of such tools is that they lower the amount of tedious, repetitive and boring (thus error-prone) work. Commonly the output is some form of data access layer (or data access objects) or object relational mapping (ORM) or some kind of skeleton for an application for example interface for creating, reading, updating and deleting objects in database (CRUD operations). Further, this approach leads to generative programming domain, which includes concepts such as aspect-oriented programming (Gunter & Mitchell, 1994), generic programming, meta-programming etc. (Czarnecki & Eisenecker, 2000). These concepts are now available for general use – for example the AspectJ extension to Java programming language is considered stable since at least 2003 (Ladad, 2009). However, they are not still mainstream form of programming according to TIOBE Index (TIOBE, 2010). A completely different approach to the problem is an actual generation of algorithms of the program. This is a more complex then code generation as described above, since it involves actual creation of algorithms and procedures. This requires either extremely complex tools or artificial intelligence. The former can be probably represented by two most successful (albeit completely different) projects – Lyee project (Poli, 2002) and Specware project (Smith, 1999). Unfortunately, the Lyee project was terminated in 2004 and the latest version of Specware is from 2007. As mentioned above, another option is to leverage artificial intelligence methods (particularly evolutionary algorithms) and use them to create code evolution. We use the term</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1624.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1624.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Genetic Algorithms</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Population-based stochastic optimisation methods using selection, crossover and mutation on encoded genomes to search large state spaces; in this paper GAs are the underlying search mechanism directing grammar-driven program generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Genetic Algorithms (steady-state GA)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Standard GA framework described and used conceptually: initialize population of genomes, evaluate with a fitness function, apply selection, crossover to recombine parent genomes, mutation to introduce random perturbations, replace individuals and iterate until termination (max iterations or target fitness). In this work GA is the top-level engine that evolves sequences of integers (chromosomes) which map via a grammar to program source code.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>genome of grammar rule indices (maps to code/programs)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Generic GA crossover: parents' chromosomes (sequences of integer genes) are recombined to produce offspring genomes. Paper discusses crossover as the 'critical operation' but does not define a single fixed operator — it is implemented on the genomes that encode grammar-rule choices (e.g. one-point or multi-point style operations are implied).</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Random distortion of genomes: each gene may be changed to a random value with a small probability (standard per-gene random mutation). Mutation is used to escape local optima.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Executability/functionality evaluated by interpreting the generated source and running unit-test examples; fitness is computed from test outcomes (points per test: result assigned, result is numeric, non-negative, equals expected value) and sum-of-points is the fitness.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Reported generation counts for successful synthesis tasks: absolute-value function synthesized in average 47.6 population cycles (population size 300); another simple function synthesized in ~10 generations in an earlier example; comparator function synthesis took 75.1 population cycles on average. No numeric success rates for GA alone provided.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>Qualitative: increasing grammar expressivity (more variability) raises state-space complexity and makes finding executable solutions harder; GAs require appropriately granular fitness signals to guide toward executable solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Program synthesis / automatic program generation (PHP functions/classes) driven by example/unit-tests</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Genetic Programming, Grammatical Evolution, two-level GE variants, gene expression programming (discussed as alternatives or related work)</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>GAs are suitable as the search backbone for grammar-directed program generation, but the success critically depends on representation (grammar encoding) and fitness granularity; naive genomes risk producing syntactic/semantic errors unless grammar or representation constraints are used.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1624.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1624.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Genetic Programming</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Tree-based evolutionary method that evolves programs (parse trees) directly using subtree crossover and mutation; noted for early successes but practical issues when generating syntactically/semantically valid code.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Genetic Programming (tree-based GP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Programs are represented as concrete syntax trees and genetic operators (subtree crossover and mutation) operate directly on those trees; automatically defined functions (ADFs) can be used to factor subroutines. GP directly evolves program structure but can create syntactically or semantically invalid offspring if operators swap incompatible subtrees.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs / parse trees</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Subtree crossover: two parent parse-trees exchange subtrees (can swap functions/expressions). Paper highlights that naive subtree crossover can create syntactically invalid offspring when arities/types mismatch.</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Tree mutation: random subtree replacement or random alteration within the parse tree; used to introduce variation and escape local optima.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Not experimentally quantified in this paper; discussion notes GP's tendency to require large populations and building blocks to avoid invalid programs.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>Qualitative: GP's direct tree operators give high structural novelty but risk producing non-executable code; to maintain executability GP relies on large populations and building-block preservation (e.g. ADFs, grammars).</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Automatic generation of algorithms / programs (historical baseline and comparison point)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Grammatical evolution (as grammar-constrained alternative), gene expression programming, automatically defined functions (ADF) methods</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>GP can synthesize algorithms but faces two practical problems: creation of syntactically/semantically invalid programs via crossover and reduced evolutionary variability; grammar-based approaches were developed to address these issues.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1624.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1624.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Grammatical Evolution</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An evolutionary automatic programming method that evolves linear genomes of integers which are mapped via a context-free grammar (CFG) to syntactically correct programs in any target language.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Grammatical Evolution (original GE)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Individuals are integer sequences; translation uses the CFG production rules, selecting rule alternatives via gene values (typically using modulo). This guarantees syntactically valid outputs (terminals only after full mapping). A GA directs evolution of genomes to locate genomes which map to programs satisfying fitness (e.g., unit-tests).</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>code/programs (generated via CFG mappings)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Crossover on the linear integer genome (e.g., one-point/multi-point crossover on gene sequences). The paper notes crossover operates on genome rather than phenotype; original GE's left-to-right rule application leads to genes affecting disparate parts of phenotype.</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Per-gene random changes in integer values (small probability), which change selection among grammar alternatives during mapping.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Executability assessed by interpreting generated PHP fragments and running test-cases; fitness sums points per test (e.g. result assigned, numeric, sign, equality).</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Examples: simple functions synthesized (abs, comparator) with reported generation counts (see GA entry). Using original GE with very generic grammars failed to find error-free programs within 150 generations in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>Qualitative: mapping guarantees syntactic correctness (improves executability) but original GE can have lowered variability and issues optimizing parameters (e.g. real numbers); grammar design (specific vs generic) strongly affects searchability and ability to find executable solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Program synthesis / program generation in PHP using grammar-constrained generation</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Standard GP, gene expression programming, two-level GE variants (backward processing, block marking)</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>GE's grammar constraint ensures syntactic correctness and portability to mainstream languages, but original GE suffers from poor parameter (real number) optimization and mapping-order issues that reduce robustness of crossover and mutation on phenotype structure.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1624.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1624.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>2L-GE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Two-level Grammatical Evolution (backward processing / block marking)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extension of GE that reverses rule-processing order (backward processing) and marks contiguous gene blocks (B/I/E) corresponding to grammar-derived subexpressions, enabling homologous-style crossover that preserves syntactic building blocks and improves stability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Two-level Grammatical Evolution with Backward Processing and Block Marking</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The genome-to-phenotype mapping scans nonterminals from right-to-left (backward processing). Genes used to generate a single grammar rule and its parameters are contiguous; block-marking (B = begin, I = inside, E = end) annotates gene ranges corresponding to logical subexpressions. Crossover can exchange whole marked blocks between parents (homologous crossover-like), improving preservation of syntactic/semantic building blocks while keeping all operators applied at genome level.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>code/programs (generated via CFG mappings)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Block-preserving crossover: logical gene blocks (B/I/E contiguous ranges corresponding to grammar subexpressions) are exchanged between parents so that subexpressions remain intact; this resembles subtree/homologous crossover but operates on the genome with block boundaries defined by backward processing.</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Standard genome mutation (gene value changes), but block marking allows insertions/removals at genome level without breaking rule-local coherence; mutation can target whole blocks or individual genes within blocks (implementation details not fully specified).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Same executable evaluation as GE: interpret generated PHP code and run unit-test examples; syntactic correctness is guaranteed by grammar plus block-preserving operations that reduce invalid offspring.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Authors report better stability and performance vs. standard GE: examples and figures show crossover exchanging marked blocks produces valid offspring (Fig.5). No formal quantitative improvement percentages are provided in this paper, but experiments synthesize simple functions (abs, comparator) within tens of generations (see GA/GE entries).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>Described qualitatively: grouping genes into blocks increases offspring stability (improves executability) while maintaining the ability to insert/remove genes (maintains variability); addresses GP's invalid-offspring problem without requiring tree-level operators.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Program synthesis / grammar-constrained code generation (PHP), used in experiments to generate small functions and class bodies</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Original Grammatical Evolution (left-to-right mapping), Gene Expression Programming (alternative approach to block/segment grouping), homologous crossover concepts (Francone et al. 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Backward processing + block marking groups genes corresponding to grammar subexpressions into contiguous blocks; exchanging these blocks during crossover preserves syntactic and semantic units, yielding greater stability of solutions and improved performance relative to standard GE (qualitatively demonstrated).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1624.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1624.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>2L-GE+DE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Two-level Grammatical Evolution with Differential Evolution (second-level numeric optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A two-level approach that separates structural search (GE) from numeric parameter optimization (Differential Evolution) by generating symbolic constants in the grammar and optimizing them with DE per individual to improve numeric accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Two-level Grammatical Evolution + Differential Evolution</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>First level: grammatical evolution generates program structure but inserts symbolic constants (a, b, c) instead of numeric terminals. Second level: for each individual, Differential Evolution (DE) optimizes the vector of real-valued symbolic constants to maximize fitness on training data. Hundreds of DE cycles are run inside each GE generation for parameter tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>code/programs with symbolic numeric parameters</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>GE-level crossover as per two-level GE (block-preserving on genome); DE-level uses differential mutation/recombination on numeric parameter vectors (classical DE operators: differential mutation + crossover between parameter vectors to generate trial vectors).</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>GE-level: integer gene mutations; DE-level: DE's variation (mutation via scaled difference vectors) and crossover (binomial/uniform) to explore numeric parameter space.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Executability is same as other GE variants: generated code is interpreted and run on test patterns; numeric accuracy of symbolic constants is measured by fitness computed from unit test performance (sum-of-points).</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Paper states this approach 'greatly improves' GE performance for real-number parameters and reports that DE cycles are executed per GE individual, but provides no tight quantitative comparison metrics; experiments synthesize functions requiring numeric constants more reliably under two-level approach (no numeric success-rate numbers provided).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>Qualitative: separating structure and parameter search reduces difficulty of optimizing real-valued constants and maintains structural novelty because structure search is still driven by GE, while DE ensures executability/accuracy of numerical parts.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Program synthesis with real-valued numeric parameters (mathematical expressions, numeric-function synthesis); experiments on function generation tasks in PHP and symbolic regression-like tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Original GE (without two-level separation), standard parameter embedding via <num> nonterminal</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Two-level scheme (GE for structure + DE for numeric parameters) significantly improves GE's ability to optimize real numbers and evaluate candidate programs accurately; it trades extra compute per individual (many DE cycles) for better numeric executability.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1624.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1624.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeformationGrammar</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deformation Grammars (enhanced CFGs with deformation/error rules)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Grammar augmentation technique that adds weighted 'deformation' production rules (modeled on string-distance metrics like Levenshtein) to a base grammar so the parser can recognize syntactically deformed inputs and recover nearest canonical derivations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Deformation Grammars with Weighted Deformation Rules</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Given a base regular or context-free grammar G, construct an enhanced ambiguous CFG G' by adding deformation rules (insertions, deletions, substitutions with weights derived from a chosen string metric, e.g., Levenshtein). A modified Earley parser accumulates weights to find the minimal-weight derivation, effectively performing error-correcting parsing and enabling recognition of deformed/generated strings.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>text/strings (syntactic representations of objects) — could be applied to code fragments</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Not used as an evolutionary fitness metric in this paper; the enhanced grammar's weights produce a distance d (sum of deformation rule weights) indicating distance from a canonical template, which can be used to select nearest valid derivation.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Qualitative: when word length is sufficient (words >10 chars and deformation ≤ ~20%), deformation grammar yields correct recognition and no false positives; no quantitative rates given.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>Suggested use: deformation grammars could be used to refine grammars for GE to avoid premature returns or control-flow issues (improving executability) at the cost of more complex, ambiguous grammars (potentially increasing search difficulty).</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Syntactic analysis and object recognition; proposed application to deriving more tolerant grammars for program generation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Standard CFG parsing and string-distance methods (Levenshtein, Needleman-Wunsch); modified Earley parser</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Deformation grammars enable robust parsing/recognition of deformed input strings using weighted rules and a modified Earley parser; authors propose these grammars as a way to derive or relax generation grammars for program synthesis to reduce invalid constructs, though no evolutionary experiments using them are reported here.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1624.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1624.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GEP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gene Expression Programming</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An alternative evolutionary approach that encodes programs as linear chromosomes with expression trees (ETs) decoded from fixed-length genes; mentioned as an alternative that also groups genome parts corresponding to subexpressions but with grammar restrictions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Gene Expression Programming (GEP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GEP represents programs with linear chromosomes that decode into expression trees; this mapping enforces syntactic validity and groups genome regions corresponding to subtrees, enabling genomic operators while maintaining legal phenotypes. Paper cites GEP as an alternative to backward-processing GE for grouping subexpressions.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs / encoded expressions</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Chromosome-level crossover that respects gene boundaries corresponding to expression-tree structure (specific GEP operators not detailed in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Gene-level mutations within linear chromosome following GEP rules; specifics not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>Not discussed in detail here; GEP flagged as solving grouping-of-subexpressions problem but limited in grammar expressivity.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Mentioned as an alternative method for evolving expressions/program fragments</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared qualitatively to two-level GE: GEP solves similar block/grouping problems but imposes stronger grammar constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>GEP offers another way to preserve syntactic building blocks during recombination, but the authors consider it more limited in allowable grammar forms compared to their backward-processing GE approach.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Genetic Programming: On the Programming of Computers by Means of Natural Selection <em>(Rating: 2)</em></li>
                <li>Grammatical Evolution: Evolutionary Automatic Programming in an Arbitrary Language <em>(Rating: 2)</em></li>
                <li>Parallel Grammatical Evolution with Backward Processing <em>(Rating: 2)</em></li>
                <li>Two-level optimization using parallel grammatical evolution and differential evolution <em>(Rating: 2)</em></li>
                <li>Gene Expression Programming: Mathematical Modelling by an Artificial Intelligence <em>(Rating: 2)</em></li>
                <li>Homologous Crossover in Genetic Programming <em>(Rating: 1)</em></li>
                <li>An Introduction to Genetic Algorithms <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1624",
    "paper_id": "paper-53061463",
    "extraction_schema_id": "extraction-schema-31",
    "extracted_data": [
        {
            "name_short": "GA",
            "name_full": "Genetic Algorithms",
            "brief_description": "Population-based stochastic optimisation methods using selection, crossover and mutation on encoded genomes to search large state spaces; in this paper GAs are the underlying search mechanism directing grammar-driven program generation.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Genetic Algorithms (steady-state GA)",
            "system_description": "Standard GA framework described and used conceptually: initialize population of genomes, evaluate with a fitness function, apply selection, crossover to recombine parent genomes, mutation to introduce random perturbations, replace individuals and iterate until termination (max iterations or target fitness). In this work GA is the top-level engine that evolves sequences of integers (chromosomes) which map via a grammar to program source code.",
            "input_type": "genome of grammar rule indices (maps to code/programs)",
            "crossover_operation": "Generic GA crossover: parents' chromosomes (sequences of integer genes) are recombined to produce offspring genomes. Paper discusses crossover as the 'critical operation' but does not define a single fixed operator — it is implemented on the genomes that encode grammar-rule choices (e.g. one-point or multi-point style operations are implied).",
            "mutation_operation": "Random distortion of genomes: each gene may be changed to a random value with a small probability (standard per-gene random mutation). Mutation is used to escape local optima.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Executability/functionality evaluated by interpreting the generated source and running unit-test examples; fitness is computed from test outcomes (points per test: result assigned, result is numeric, non-negative, equals expected value) and sum-of-points is the fitness.",
            "executability_results": "Reported generation counts for successful synthesis tasks: absolute-value function synthesized in average 47.6 population cycles (population size 300); another simple function synthesized in ~10 generations in an earlier example; comparator function synthesis took 75.1 population cycles on average. No numeric success rates for GA alone provided.",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "Qualitative: increasing grammar expressivity (more variability) raises state-space complexity and makes finding executable solutions harder; GAs require appropriately granular fitness signals to guide toward executable solutions.",
            "frontier_characterization": null,
            "benchmark_or_domain": "Program synthesis / automatic program generation (PHP functions/classes) driven by example/unit-tests",
            "comparison_baseline": "Genetic Programming, Grammatical Evolution, two-level GE variants, gene expression programming (discussed as alternatives or related work)",
            "key_findings": "GAs are suitable as the search backbone for grammar-directed program generation, but the success critically depends on representation (grammar encoding) and fitness granularity; naive genomes risk producing syntactic/semantic errors unless grammar or representation constraints are used.",
            "uuid": "e1624.0"
        },
        {
            "name_short": "GP",
            "name_full": "Genetic Programming",
            "brief_description": "Tree-based evolutionary method that evolves programs (parse trees) directly using subtree crossover and mutation; noted for early successes but practical issues when generating syntactically/semantically valid code.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Genetic Programming (tree-based GP)",
            "system_description": "Programs are represented as concrete syntax trees and genetic operators (subtree crossover and mutation) operate directly on those trees; automatically defined functions (ADFs) can be used to factor subroutines. GP directly evolves program structure but can create syntactically or semantically invalid offspring if operators swap incompatible subtrees.",
            "input_type": "programs / parse trees",
            "crossover_operation": "Subtree crossover: two parent parse-trees exchange subtrees (can swap functions/expressions). Paper highlights that naive subtree crossover can create syntactically invalid offspring when arities/types mismatch.",
            "mutation_operation": "Tree mutation: random subtree replacement or random alteration within the parse tree; used to introduce variation and escape local optima.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Not experimentally quantified in this paper; discussion notes GP's tendency to require large populations and building blocks to avoid invalid programs.",
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "Qualitative: GP's direct tree operators give high structural novelty but risk producing non-executable code; to maintain executability GP relies on large populations and building-block preservation (e.g. ADFs, grammars).",
            "frontier_characterization": null,
            "benchmark_or_domain": "Automatic generation of algorithms / programs (historical baseline and comparison point)",
            "comparison_baseline": "Grammatical evolution (as grammar-constrained alternative), gene expression programming, automatically defined functions (ADF) methods",
            "key_findings": "GP can synthesize algorithms but faces two practical problems: creation of syntactically/semantically invalid programs via crossover and reduced evolutionary variability; grammar-based approaches were developed to address these issues.",
            "uuid": "e1624.1"
        },
        {
            "name_short": "GE",
            "name_full": "Grammatical Evolution",
            "brief_description": "An evolutionary automatic programming method that evolves linear genomes of integers which are mapped via a context-free grammar (CFG) to syntactically correct programs in any target language.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Grammatical Evolution (original GE)",
            "system_description": "Individuals are integer sequences; translation uses the CFG production rules, selecting rule alternatives via gene values (typically using modulo). This guarantees syntactically valid outputs (terminals only after full mapping). A GA directs evolution of genomes to locate genomes which map to programs satisfying fitness (e.g., unit-tests).",
            "input_type": "code/programs (generated via CFG mappings)",
            "crossover_operation": "Crossover on the linear integer genome (e.g., one-point/multi-point crossover on gene sequences). The paper notes crossover operates on genome rather than phenotype; original GE's left-to-right rule application leads to genes affecting disparate parts of phenotype.",
            "mutation_operation": "Per-gene random changes in integer values (small probability), which change selection among grammar alternatives during mapping.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Executability assessed by interpreting generated PHP fragments and running test-cases; fitness sums points per test (e.g. result assigned, numeric, sign, equality).",
            "executability_results": "Examples: simple functions synthesized (abs, comparator) with reported generation counts (see GA entry). Using original GE with very generic grammars failed to find error-free programs within 150 generations in experiments.",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "Qualitative: mapping guarantees syntactic correctness (improves executability) but original GE can have lowered variability and issues optimizing parameters (e.g. real numbers); grammar design (specific vs generic) strongly affects searchability and ability to find executable solutions.",
            "frontier_characterization": null,
            "benchmark_or_domain": "Program synthesis / program generation in PHP using grammar-constrained generation",
            "comparison_baseline": "Standard GP, gene expression programming, two-level GE variants (backward processing, block marking)",
            "key_findings": "GE's grammar constraint ensures syntactic correctness and portability to mainstream languages, but original GE suffers from poor parameter (real number) optimization and mapping-order issues that reduce robustness of crossover and mutation on phenotype structure.",
            "uuid": "e1624.2"
        },
        {
            "name_short": "2L-GE",
            "name_full": "Two-level Grammatical Evolution (backward processing / block marking)",
            "brief_description": "An extension of GE that reverses rule-processing order (backward processing) and marks contiguous gene blocks (B/I/E) corresponding to grammar-derived subexpressions, enabling homologous-style crossover that preserves syntactic building blocks and improves stability.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Two-level Grammatical Evolution with Backward Processing and Block Marking",
            "system_description": "The genome-to-phenotype mapping scans nonterminals from right-to-left (backward processing). Genes used to generate a single grammar rule and its parameters are contiguous; block-marking (B = begin, I = inside, E = end) annotates gene ranges corresponding to logical subexpressions. Crossover can exchange whole marked blocks between parents (homologous crossover-like), improving preservation of syntactic/semantic building blocks while keeping all operators applied at genome level.",
            "input_type": "code/programs (generated via CFG mappings)",
            "crossover_operation": "Block-preserving crossover: logical gene blocks (B/I/E contiguous ranges corresponding to grammar subexpressions) are exchanged between parents so that subexpressions remain intact; this resembles subtree/homologous crossover but operates on the genome with block boundaries defined by backward processing.",
            "mutation_operation": "Standard genome mutation (gene value changes), but block marking allows insertions/removals at genome level without breaking rule-local coherence; mutation can target whole blocks or individual genes within blocks (implementation details not fully specified).",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Same executable evaluation as GE: interpret generated PHP code and run unit-test examples; syntactic correctness is guaranteed by grammar plus block-preserving operations that reduce invalid offspring.",
            "executability_results": "Authors report better stability and performance vs. standard GE: examples and figures show crossover exchanging marked blocks produces valid offspring (Fig.5). No formal quantitative improvement percentages are provided in this paper, but experiments synthesize simple functions (abs, comparator) within tens of generations (see GA/GE entries).",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "Described qualitatively: grouping genes into blocks increases offspring stability (improves executability) while maintaining the ability to insert/remove genes (maintains variability); addresses GP's invalid-offspring problem without requiring tree-level operators.",
            "frontier_characterization": null,
            "benchmark_or_domain": "Program synthesis / grammar-constrained code generation (PHP), used in experiments to generate small functions and class bodies",
            "comparison_baseline": "Original Grammatical Evolution (left-to-right mapping), Gene Expression Programming (alternative approach to block/segment grouping), homologous crossover concepts (Francone et al. 1999)",
            "key_findings": "Backward processing + block marking groups genes corresponding to grammar subexpressions into contiguous blocks; exchanging these blocks during crossover preserves syntactic and semantic units, yielding greater stability of solutions and improved performance relative to standard GE (qualitatively demonstrated).",
            "uuid": "e1624.3"
        },
        {
            "name_short": "2L-GE+DE",
            "name_full": "Two-level Grammatical Evolution with Differential Evolution (second-level numeric optimization)",
            "brief_description": "A two-level approach that separates structural search (GE) from numeric parameter optimization (Differential Evolution) by generating symbolic constants in the grammar and optimizing them with DE per individual to improve numeric accuracy.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Two-level Grammatical Evolution + Differential Evolution",
            "system_description": "First level: grammatical evolution generates program structure but inserts symbolic constants (a, b, c) instead of numeric terminals. Second level: for each individual, Differential Evolution (DE) optimizes the vector of real-valued symbolic constants to maximize fitness on training data. Hundreds of DE cycles are run inside each GE generation for parameter tuning.",
            "input_type": "code/programs with symbolic numeric parameters",
            "crossover_operation": "GE-level crossover as per two-level GE (block-preserving on genome); DE-level uses differential mutation/recombination on numeric parameter vectors (classical DE operators: differential mutation + crossover between parameter vectors to generate trial vectors).",
            "mutation_operation": "GE-level: integer gene mutations; DE-level: DE's variation (mutation via scaled difference vectors) and crossover (binomial/uniform) to explore numeric parameter space.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Executability is same as other GE variants: generated code is interpreted and run on test patterns; numeric accuracy of symbolic constants is measured by fitness computed from unit test performance (sum-of-points).",
            "executability_results": "Paper states this approach 'greatly improves' GE performance for real-number parameters and reports that DE cycles are executed per GE individual, but provides no tight quantitative comparison metrics; experiments synthesize functions requiring numeric constants more reliably under two-level approach (no numeric success-rate numbers provided).",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "Qualitative: separating structure and parameter search reduces difficulty of optimizing real-valued constants and maintains structural novelty because structure search is still driven by GE, while DE ensures executability/accuracy of numerical parts.",
            "frontier_characterization": null,
            "benchmark_or_domain": "Program synthesis with real-valued numeric parameters (mathematical expressions, numeric-function synthesis); experiments on function generation tasks in PHP and symbolic regression-like tasks.",
            "comparison_baseline": "Original GE (without two-level separation), standard parameter embedding via &lt;num&gt; nonterminal",
            "key_findings": "Two-level scheme (GE for structure + DE for numeric parameters) significantly improves GE's ability to optimize real numbers and evaluate candidate programs accurately; it trades extra compute per individual (many DE cycles) for better numeric executability.",
            "uuid": "e1624.4"
        },
        {
            "name_short": "DeformationGrammar",
            "name_full": "Deformation Grammars (enhanced CFGs with deformation/error rules)",
            "brief_description": "Grammar augmentation technique that adds weighted 'deformation' production rules (modeled on string-distance metrics like Levenshtein) to a base grammar so the parser can recognize syntactically deformed inputs and recover nearest canonical derivations.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Deformation Grammars with Weighted Deformation Rules",
            "system_description": "Given a base regular or context-free grammar G, construct an enhanced ambiguous CFG G' by adding deformation rules (insertions, deletions, substitutions with weights derived from a chosen string metric, e.g., Levenshtein). A modified Earley parser accumulates weights to find the minimal-weight derivation, effectively performing error-correcting parsing and enabling recognition of deformed/generated strings.",
            "input_type": "text/strings (syntactic representations of objects) — could be applied to code fragments",
            "crossover_operation": null,
            "mutation_operation": null,
            "uses_literature": false,
            "uses_code": null,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Not used as an evolutionary fitness metric in this paper; the enhanced grammar's weights produce a distance d (sum of deformation rule weights) indicating distance from a canonical template, which can be used to select nearest valid derivation.",
            "executability_results": "Qualitative: when word length is sufficient (words &gt;10 chars and deformation ≤ ~20%), deformation grammar yields correct recognition and no false positives; no quantitative rates given.",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "Suggested use: deformation grammars could be used to refine grammars for GE to avoid premature returns or control-flow issues (improving executability) at the cost of more complex, ambiguous grammars (potentially increasing search difficulty).",
            "frontier_characterization": null,
            "benchmark_or_domain": "Syntactic analysis and object recognition; proposed application to deriving more tolerant grammars for program generation.",
            "comparison_baseline": "Standard CFG parsing and string-distance methods (Levenshtein, Needleman-Wunsch); modified Earley parser",
            "key_findings": "Deformation grammars enable robust parsing/recognition of deformed input strings using weighted rules and a modified Earley parser; authors propose these grammars as a way to derive or relax generation grammars for program synthesis to reduce invalid constructs, though no evolutionary experiments using them are reported here.",
            "uuid": "e1624.5"
        },
        {
            "name_short": "GEP",
            "name_full": "Gene Expression Programming",
            "brief_description": "An alternative evolutionary approach that encodes programs as linear chromosomes with expression trees (ETs) decoded from fixed-length genes; mentioned as an alternative that also groups genome parts corresponding to subexpressions but with grammar restrictions.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Gene Expression Programming (GEP)",
            "system_description": "GEP represents programs with linear chromosomes that decode into expression trees; this mapping enforces syntactic validity and groups genome regions corresponding to subtrees, enabling genomic operators while maintaining legal phenotypes. Paper cites GEP as an alternative to backward-processing GE for grouping subexpressions.",
            "input_type": "programs / encoded expressions",
            "crossover_operation": "Chromosome-level crossover that respects gene boundaries corresponding to expression-tree structure (specific GEP operators not detailed in this paper).",
            "mutation_operation": "Gene-level mutations within linear chromosome following GEP rules; specifics not detailed here.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "Not discussed in detail here; GEP flagged as solving grouping-of-subexpressions problem but limited in grammar expressivity.",
            "frontier_characterization": null,
            "benchmark_or_domain": "Mentioned as an alternative method for evolving expressions/program fragments",
            "comparison_baseline": "Compared qualitatively to two-level GE: GEP solves similar block/grouping problems but imposes stronger grammar constraints.",
            "key_findings": "GEP offers another way to preserve syntactic building blocks during recombination, but the authors consider it more limited in allowable grammar forms compared to their backward-processing GE approach.",
            "uuid": "e1624.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Genetic Programming: On the Programming of Computers by Means of Natural Selection",
            "rating": 2,
            "sanitized_title": "genetic_programming_on_the_programming_of_computers_by_means_of_natural_selection"
        },
        {
            "paper_title": "Grammatical Evolution: Evolutionary Automatic Programming in an Arbitrary Language",
            "rating": 2,
            "sanitized_title": "grammatical_evolution_evolutionary_automatic_programming_in_an_arbitrary_language"
        },
        {
            "paper_title": "Parallel Grammatical Evolution with Backward Processing",
            "rating": 2,
            "sanitized_title": "parallel_grammatical_evolution_with_backward_processing"
        },
        {
            "paper_title": "Two-level optimization using parallel grammatical evolution and differential evolution",
            "rating": 2,
            "sanitized_title": "twolevel_optimization_using_parallel_grammatical_evolution_and_differential_evolution"
        },
        {
            "paper_title": "Gene Expression Programming: Mathematical Modelling by an Artificial Intelligence",
            "rating": 2,
            "sanitized_title": "gene_expression_programming_mathematical_modelling_by_an_artificial_intelligence"
        },
        {
            "paper_title": "Homologous Crossover in Genetic Programming",
            "rating": 1,
            "sanitized_title": "homologous_crossover_in_genetic_programming"
        },
        {
            "paper_title": "An Introduction to Genetic Algorithms",
            "rating": 1,
            "sanitized_title": "an_introduction_to_genetic_algorithms"
        }
    ],
    "cost": 0.01553825,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Automatic Generation of Programs</p>
<p>Ondřej Popelka 
Mendel University in Brno Czech Republic</p>
<p>Jiří Štastný 
Mendel University in Brno Czech Republic</p>
<p>Automatic Generation of Programs
AA1CD7D15E0B1E954EE631FA7EAB2F8D</p>
<p>Introduction</p>
<p>Automatic generation of program is definitely an alluring problem.Over the years many approaches emerged, which try to smooth away parts of programmers' work.One approach already widely used today is colloquially known as code generation (or code generators).This approach includes many methods and tools, therefore many different terms are used to describe this concept.The very basic tools are included in various available Integrated Development Environments (IDE).These include templates, automatic code completion, macros and other tools.On a higher level, code generation is performed by tools, which create program source code from metadata or data.Again, there are thousands of such tools available both commercial and open source.Generally available are programs for generating source code from relational or object database schema, object or class diagrams, test cases, XML schema, XSD schema, design patterns or various formalized descriptions of the problem domain.These tools mainly focus on the generation of a template or skeleton for an application or application module, which is then filled with actual algorithms by a programmer.The great advantage of such tools is that they lower the amount of tedious, repetitive and boring (thus error-prone) work.Commonly the output is some form of data access layer (or data access objects) or object relational mapping (ORM) or some kind of skeleton for an application -for example interface for creating, reading, updating and deleting objects in database (CRUD operations).Further, this approach leads to generative programming domain, which includes concepts such as aspect-oriented programming (Gunter &amp; Mitchell, 1994), generic programming, meta-programming etc. (Czarnecki &amp; Eisenecker, 2000).These concepts are now available for general use -for example the AspectJ extension to Java programming language is considered stable since at least 2003 (Ladad, 2009).However, they are not still mainstream form of programming according to TIOBE Index (TIOBE, 2010).A completely different approach to the problem is an actual generation of algorithms of the program.This is a more complex then code generation as described above, since it involves actual creation of algorithms and procedures.This requires either extremely complex tools or artificial intelligence.The former can be probably represented by two most successful (albeit completely different) projects -Lyee project (Poli, 2002) and Specware project (Smith, 1999).Unfortunately, the Lyee project was terminated in 2004 and the latest version of Specware is from 2007.As mentioned above, another option is to leverage artificial intelligence methods (particularly evolutionary algorithms) and use them to create code evolution.We use the term code evolution as an opposite concept to code generation (as described in previous paragraphs) and later we will describe how these two concepts can be coupled.When using code generation, we let the programmer specify program metadata and automatically generate skeleton for his application, which he then fills with actual algorithms.When using code evolution, we let the programmer specify sample inputs and outputs of the program and automatically generate the actual algorithms fulfilling the requirements.We aim to create a tool which will aid human programmers by generating working algorithms (not optimal algorithms) in programming language of their choice.In this chapter, we describe evolutionary methods usable for code evolution and results of some experiments with these.Since most of the methods used are based on genetic algorithms, we will first briefly describe this area of artificial intelligence.Then we will move on to the actual algorithms for automatic generation of programs.Furthermore, we will describe how these results can be beneficial to mainstream programming techniques.</p>
<p>Methods used for automatic generation of programs</p>
<p>Genetic algorithms</p>
<p>Genetic algorithms (GA) are a large group of evolutionary algorithms inspired by evolutionary mechanisms of live nature.Evolutionary algorithms are non-deterministic algorithms suitable for solving very complex problems by transforming them into state space and searching for optimum state.Although they originate from modelling of natural process, most evolutionary algorithms do not copy the natural processes precisely.The basic concept of genetic algorithms is based on natural selection process and is very generic, leaving space for many different approaches and implementations.The domain of GA is in solving multidimensional optimisation problems, for which analytical solutions are unknown (or extremely complex) and efficient numerical methods are unavailable or their initial conditions are unknown.A genetic algorithm uses three genetic operatorsreproduction, crossover and mutation (Goldberg, 2002).Many differences can be observed in the strategy of the parent selection, the form of genes, the realization of crossover operator, the replacement scheme, etc.A basic steady-state genetic algorithm involves the following steps.Initialization.In each step, a genetic algorithm contains a number of solutions (individuals) in one or more populations.Each solution is represented by genome (or chromosome).Initialization creates a starting population and sets all bits of all chromosomes to an initial (usually random) value.Crossover.The crossover is the main procedure to ensure progress of the genetic algorithm.The crossover operator should be implemented so that by combining several existing chromosomes a new chromosome is created, which is expected to be a better solution to the problem.Mutation.Mutation operator involves a random distortion of random chromosomes; the purpose of this operation is to overcome the tendency of genetic algorithm in reaching the local optimum instead of global optimum.Simple mutation is implemented so that each gene in each chromosome can be randomly changed with a certain very small probability.Finalization.The population cycle is repeated until a termination condition is satisfied.There are two basic finalization variations: maximal number of iterations and the quality of the best solution.Since the latter condition may never be satisfied both conditions are usually used.</p>
<p>The critical operation of genetic algorithm is crossover which requires that it is possible to determine what a "better solution" is.This is determined by a fitness function (criterion function or objective function).The fitness function is the key feature of genetic algorithm, since the genetic algorithm performs the minimization of this function.The fitness function is actually the transformation of the problem being solved into a state space which is searched using genetic algorithm (Mitchell, 1999).</p>
<p>Genetic programming</p>
<p>The first successful experiments with automatic generation of algorithms were using Genetic Programming method (Koza, 1992).Genetic programming (GP) is a considerably modified genetic algorithm and is now considered a field on its own.GP itself has proven that evolutionary algorithms are definitely capable of solving complex problems such as automatic generation of programs.However, a number of practical issues were discovered.These later lead to extending GP with (usually context-free) grammars to make this method more suitable to generate program source code (Wong &amp; Leung, 1995) and (Patterson &amp; Livesey, 1997).Problem number one is the overwhelming complexity of automatic generation of a program code.The most straightforward approach is to split the code into subroutines (functions or methods) the same way as human programmers do.In genetic programming this problem is generally being solved using Automatically Defined Functions (ADF) extension to GP.When using automatically defined function each program is split into definitions of one or more functions, an expression and result producing branch.There are several methods to create ADFs, from manual user definition to automatic evolution.Widely recognized approaches include generating ADFs using genetic programing (Koza, 1994), genetic algorithms (Ahluwalia &amp; Bull, 1998), logic grammars (Wong &amp; Leung, 1995) or gene expression programming (Ferreira, 2006a).Second very difficult problem is actually creating syntactically and semantically correct programs.In genetic programming, the program code itself is represented using a concrete syntax tree (parse tree).An important feature of GP is that all genetic operations are applied to the tree itself, since GP algorithms generally lack any sort of genome.This leads to problems when applying the crossover or mutation operators since it is possible to create a syntactically invalid structure and since it limits evolutionary variability.A classic example of the former is exchanging (within crossover operation) a function with two parameters for a function with one parameter and vice versa -part of the tree is either missing or superfluous.The latter problem is circumvented using very large initial populations which contain all necessary prime building blocks.In subsequent populations these building blocks are only combined into correct structure (Ferreira, 2006a).Despite these problems, the achievements of genetic programming are very respectable; as of year 2003 there are 36 human-competitive results known (Koza et al, 2003).These results include various successful specialized algorithms or circuit topologies.However we would like to concentrate on a more mainstream problems and programming languages.Our goal are not algorithms competitive to humans, rather we focus on creating algorithms which are just working.We are also targeting mainstream programming languages.</p>
<p>Grammatical evolution</p>
<p>The development of Grammatical Evolution (GE) algorithm (O'Neill &amp; Ryan, 2003) can be considered a major breakthrough when solving both problems mentioned in the previous paragraph.This algorithm directly uses a generative context-free grammar (CFG) to generate structures in an arbitrary language defined by that grammar.A genetic algorithm is used to direct the structure generation.The usage of a context-free grammar to generate a solution ensures that a solution is always syntactically correct.It also enables to precisely and flexibly define the form of a solution without the need to alter the algorithm implementation.</p>
<p>Fig. 1. Production rules of grammar for generating arithmetic expressions</p>
<p>In grammatical evolution each individual in the population is represented by a sequence of rules of a defined (context-free) grammar.The particular solution is then generated by translating the chromosome to a sequence of rules which are then applied in specified order.A context-free grammar G is defined as a tuple G = (Π,Σ,P,S) where Π is set of nonterminals, Σ is set of terminals, S is initial non-terminal and P is table of production rules.The non-terminals are items, which appear in the individuals' body (the solution) only before or during the translation.After the translation is finished all non-terminals are translated to terminals.Terminals are all symbols which may appear in the generated language, thus they represent the solution.Start symbol is one non-terminal from the nonterminals set, which is used to initialize the translation process.Production rules define the laws under which non-terminals are translated to terminals.Production rules are key part of the grammar definition as they actually define the structure of the generated solution (O'Neill &amp; Ryan, 2003).We will demonstrate the principle of grammatical evolution and the backward processing algorithm on generating algebraic expressions.The grammar we can use to generate arithmetic expressions is defined by equations ( 1 The beginning of the process of the translation is shown on Figure 2. At the beginning we have a chromosome which consists of randomly generated integers and a non-terminal <expr> (expression).Then all rules which can rewrite this non-terminal are selected and rule is chosen using modulo operation and current gene value.Non-terminal <expr> is rewritten to non-terminal <var> (variable).Second step shows that if only one rule is available for rewriting the non-terminal, it is not necessary to read a gene and the rule is applied immediately.This illustrates how the genome (chromosome) can control the generation of solutions.This process is repeated for every solution until no non-terminals are left in its' body.Then each solution can be evaluated and a genetic algorithm population cycle can start and determine best solutions and create new chromosomes.</p>
<p>Other non-terminals used in this grammar can be <fnc> (function) and <num> (number).</p>
<p>Here we consider standard arithmetic operators as functions, the rules on Figure 1 are divided by the number of arguments for a function ("u-" stands for unary minus).</p>
<p>Two-level grammatical evolution</p>
<p>In the previous section, we have described original grammatical evolution algorithm.We have further developed the original grammatical evolution algorithm by extending it with Backward Processing algorithm (Ošmera, Popelka &amp; Pivoňka, 2006).The backward processing algorithm just uses different order of processing the rules of the context free grammar than the original GE algorithm.Although the change might seem subtle, the consequences are very important.When using the original algorithm, the rules are read left-to-right and so is the body of the individual scanned left-to-right for untranslated non-terminals.•(<expr > , <expr>)</p>
<p>•(<f nc> (<expr>), <expr>)</p>
<p>•(cos (<expr>), <expr>)</p>
<p>•(cos(<fnc>(<num>,<expr>)), <expr >)</p>
<p>•(cos(+(<num><expr>)), <expr >)</p>
<p>•(cos(+(2,<expr>)), <expr >)</p>
<p>•(cos(+(2,<var>)), <expr>)</p>
<p>•(cos(+(2,x)), <expr>)
•(cos(+(2,x)), <f nc> (<expr>))
•(cos(+(2,x)),sin (<expr > ))</p>
<p>•(cos(+(2,x)),sin(<fnc>(<num>,<exp >))) cos(2
•(cos(+(2,x)),sin(•(<num > ,<exp>))) •(cos(+(2,x)),) sin(3 ) xx + ⋅⋅ (4)
The backward processing algorithm scans the solution string for non-terminals in right-toleft direction.Figure 4 shows the translation process when this mode is used.Note that the genes in the chromosome are the same; they just have been rearranged in order to create same solution, so that the difference between both algorithms can be demonstrated.Now that we are able to determine type of the rule used, we can define gene marks.In step c) at figure 4 a <expr> non-terminal is translated into a <fnc>(<num>, <expr>) expression.This is further translated until step g), where it becomes 3 x ⋅ .In other words -in step c) we knew that the solution will contain a function with two arguments; in step g) we realized that it is multiplication with arguments 3 and x.The important feature of backward processing algorithm that all genes which define this sub-expression including all its' parameters are in a single uninterrupted block of genes.To explicitly mark this block we use Block marking algorithm which marks: -all genes used to select N-rule with mark B (Begin) -all genes used to select T-rule except the last one with mark I (Inside) -all genes used to select last T-rule of currently processed rule with mark E (End).The B and E marks determine begin and end of logical blocks generated by the grammar.This works independent of the structure generated provided that the grammar consists only of N-nonterminals and T-nonterminals.These logical blocks can then be exchanged the same way as in genetic programming (figure 5) (Francone et al, 1999).Compared to genetic programing, all the genetic algorithm operations are still performed on the genome (chromosome) and not on the actual solution.This solves the second problem described in section 2.2 -the generation of syntactically incorrect solutions.Also the problem of lowered variability is solved since we can always insert or remove genes in case we need to remove or add parts of the solution.This algorithm also solves analogical problems existing in standard grammatical evolution (O'Neill et al, 2001).
42B B B B B E I E I E E B B B E I E E E 7 B B B B E I E E B B E E E 1. child cos(2 + x) • sin(3 • (2 + x)) 2. child cos (x) • sin(3 • x )</p>
<p>Fig. 5. Example of crossing over two chromosomes with marked genes</p>
<p>The backward processing algorithm of two-level grammatical evolution provides same results as original grammatical evolution.However in the underlying genetic algorithm, the genes that are involved in processing a single rule of grammar are grouped together.This grouping results in greater stability of solutions during crossover and mutation operations and better performance (Ošmera &amp; Popelka, 2006).An alternative to this algorithm is Gene expression programming method (Cândida Ferreira, 2006b) which solves the same problem but is quite limited in the form of grammar which can be used.</p>
<p>Second level generation in two-level grammatical evolution</p>
<p>Furthermore, we modified grammatical evolution to separate structure generation and parameters optimization (Popelka, 2007).This is motivated by poor performance of grammatical evolution when optimizing parameters, especially real numbers (Dempsey et al., 2007).With this approach, we use grammatical evolution to generate complex structures.Instead of immediately generating the resulting string (as defined by the grammar), we store the parse tree of the structure and use it in second level of optimization.For this second level of optimization, a Differential evolution algorithm (Price, 1999) is used.This greatly improves the performance of GE, especially when real numbers are required (Popelka &amp; Šťastný, 2007) Initialization The first level of the optimization is performed using grammatical evolution.According to the grammar, the output can be a function containing variables (x in our case); and instead of directly generating numbers using the <num> nonterminal we add several symbolic constants (a, b, c) into to grammar.The solution expression cannot be evaluated and assigned a fitness value since the values of symbolic constants are unknown.In order to evaluate the generated function a secondary optimization has to be performed to find values for constants.Input for the second-level of optimization is the function with symbolic constants which is transformed to a vector of variables.These variables are optimized using the differential evolution and the output is a vector of optimal values for symbolic constants for a given solution.Technically in each grammatical evolution cycle there are hundreds of differential evolution cycles executed.These optimize numeric parameters of each generated individual (Popelka, 2007).Figure 6 shows the schematic flowchart of the two-level grammatical evolution.</p>
<p>Deformation grammars</p>
<p>Apart from generating the solution we also need to be able to read and interpret the solutions (section 4.2).For this task a syntactic analysis is used.Syntactic analysis is a process which decides if the string belongs to a language generated by a given grammar, this can be used for example for object recognition (Šťastný &amp; Minařík, 2006) (Aycock &amp; Horspool, 2002), which executes all ways of analysis to combine gained partial results.</p>
<p>The time of analysis is proportional to third power of string length; in case of unambiguous grammars the time is only quadratic.This algorithm was used in simulation environment.When designing a syntactic analyser, it is useful to assume random influences, e.g.image deformation.This can be done in several ways.For example, the rules of given grammar can be created with rules, which generate alternative string, or for object recognition it is possible to use some of the methods for determination of distance between attribute description of images (string metric).Finally, deformation grammars can be used.Methods for determination of distance between attribute descriptions of images (string metric) determine the distance between attribute descriptions of images, i.e. the distance between strings which correspond to the unknown object and the object class patterns.Further, determined distances are analysed and the recognized object belongs to the class from which the string has the shortest distance.Specific methods (Levenshtein distance Ld(s, t), Needleman-Wunsch method) can be used to determine the distance between attribute descriptions of image (Gusfield, 1997).Results of these methods are mentioned e.g. in (Minařík, Šťastný &amp; Popelka, 2008).If the parameters of these methods are correctly set, these methods provide good rate of successful identified objects with excellent classification speed.However, false object recognition or non-recognized objects can occur.From the previous paragraphs it is clear that recognition of non-deformed objects with structural method is without problems, it offers excellent speed and 100% classification rate.However, recognition of randomly deformed objects is nearly impossible.If we conduct syntactic analysis of a string which describes a structural deformed object, it will apparently www.intechopen.comnot be classified into a given class because of its structural deformation.Further, there are some methods which use structural description and are capable of recognizing randomly deformed objects with good rate of classification and speed.The solution to improve the rate of classification is to enhance the original grammar with rules which describe errorsdeformation rules, which cover up every possible random deformation of object.Then the task is changed to finding a non-deformed string, which distance from analysed string is minimal.Compared to the previous method, this is more informed method because it uses all available knowledge about the classification targets -it uses grammar.Original grammar may be regular or context-free, enhanced grammar is always context-free and also ambiguous, so the syntactic analysis, according to the enhanced grammar, will be more complex.Enhanced deformation grammar is designed to reliably generate all possible deformations of strings (objects) which can occur.Input is context-free or regular grammar G = (VN, VT, P, S).Output of the processing is enhanced deformation grammar G' = (VN', VT', P', S'), where P' is set of weighted rules.The generation process can be described using the following steps: Step1:
{ } { } ' ' NN B T VV S E b V =∈ ∪∪ │ (5) ' TT VV ⊆(6)
Step 2: If holds:
'' 01 12 1 1 ... ; 0; ; 1,2,..., ; 0,1,..., mm m N i T Ab b bm V b V i m l m αα α α α − →≥ ∈ ∧ ∈ = =(7)
Then add new rule into P' with weight 0:
01 12 1 ... bbm b m m AE E E α αα α − →(8)
Step 3: Into P'add the rules in table 1 with weight according to chosen metric.In this example Levenshtein distance is used.In the table header L is Levenshtein distance, w is weighted Levenshtein distance and W is weighted metric.
Rule L w W Rule for ' SS → 0 0 0 - ' SS a → 1 l w '( ) Ia ' T aV ∈ a Ea → 0 0 0 T aV ∈ a Eb → 1 S w (,) Sab ' ,, TT aVbVa b ∈ ∈≠ a E δ → 1 D w () Da T aV ∈ aa Eb E → 1 l w (,) Iab ' , TT aVbV ∈∈
Table 1.Rules of enhanced deformation grammar</p>
<p>These types of rules are called deformation rules.Syntactic analyser with error correction works with enhanced deformation grammar.This analyser seeks out such deformation of input string, which is linked with the smallest sum of weight of deformation rules.G' is ambiguous grammar, i.e. its syntactic analysis is more complicated.A modified Earley parser can be used for syntactic analyses with error correction.Moreover, this parser accumulates appropriate weight of rules which were used in deformed string derivation according to the grammar G'.</p>
<p>Modified Early algorithm</p>
<p>Modified Early parser accumulates weights of rules during the process of analysis so that the deformation grammar is correctly analysed (Minařík, Šťastný &amp; Popelka, 2008).The input of the algorithms is enhanced deformation grammar G' and input string w.</p>
<p>12 ... _ wb b bm
= (9)
Output of the algorithm is lists 01 ,, . . .m II I for string w (equation 9) and distance d of input string from a template string defined by the grammar.</p>
<p>Step is in m I , then string w is accepted with distance weight x.String w (or its derivation tree) is obtained by omitting all deformation rules from derivation of string w.</p>
<p>Designed deformation grammar reliably generates all possible variants of randomly deformed object or string.It enables to use some of the basic methods of syntactic analysis for randomly deformed objects.Compared to methods for computing the distance between attribute descriptions of objects it is more computationally complex.Its effectiveness depends on effectiveness of the used parser or its implementation respectively.This parses is significantly are more complex than the implementation of methods for simple distance measurement between attribute descriptions (such as Levenshtein distance).However, if it is used correctly, it does not produce false object recognition, which is the greatest advantage of this method.It is only necessary to choose proper length of words describing recognized objects.If the length of words is too short, excessive deformation (by applying only a few deformation rules) may occur, which can lead to occurrence of description of completely different object.If the length is sufficient (approximately 20% of deformed symbols in words longer than 10 symbols), this method gives correct result and false object recognition will not occur at all.Although deformed grammars were developed mainly for object recognition (where an object is represented by a string of primitives), it has a wider use.The main feature is that it can somehow adapt to new strings and it can be an answer to the problem described in section 4.2.</p>
<p>Experiments</p>
<p>The goal of automatic generation of programs is to create a valid source code of a program, which will solve a given problem.Each individual of a genetic algorithm is therefore one variant the program.Evaluation of an individual involves compilation (and building) of the source code, running the program and inputting the test values.Fitness function then compares the actual results of the running program with learning data and returns the fitness value.It is obvious that the evaluation of fitness becomes very time intensive operation.For the tests we have chosen the PHP language for several reasons.Firstly it is an interpreted language which greatly simplifies the evaluation of a program since compiling and building can be skipped.Secondly a PHP code can be interpreted easily as a string using either command line or library API call, which simplified implementation of the fitness function into our system.Last but not least, PHP is a very popular language with many tools available for programmers.</p>
<p>Generating simple functions</p>
<p>When testing the two-level grammatical evolution algorithm we stared with very simple functions and a very limited grammar:  (Salsi, 2007) or (Zend, 2010).To further simplify the task, the actual generated source code was only a body of a function.Before the body of the function, a header is inserted, which defines the function name, number and names of its arguments.After the function body, the return command is inserted.After the complete function definition, a few function calls with learning data are inserted.The whole product is then passed to PHP interpreter and the text result is compared with expected results according to given learning data.The simplest experiment was to generate function to compute absolute value of a number (without using the abs() function).The input for this function is one integer number; output is absolute value of that number.1)) { $result = $a; }; return $result; } While the result looks unintelligible, it must be noted that this piece of source code is correct algorithm.The last line and first two lines are the mandatory header which was added automatically for the fitness evaluation.Apart from that it has not been processed, it is also important to note that it was generated in all 20 runs from only eight sample values in average of 47.6 population cycles (population size was 300 individuals).(compared to approximately 10 in the first example).This way we obtain grammar to generate example class BankAccount.This can now be fed to the unit test, which will return number of errors and failures.This experiment was only half successful.We used the concrete grammar described abovethat is grammar specifically designed to generate BankAccount class with all its' public methods.Within average of 65.6 generations (300 individuals in generation) we were able to create individuals without errors (using only initialized variables, without infinite loops, etc.).Then the algorithm remained in local minimum and failed to find a solution with functionally correct method bodies.After some investigation, we are confident that the problem lies in the return statement of a function.We have analyzed hundreds of solution and found that the correct code is present, but is preceded with return statement which exits from the function.The solution is to use predefined function footer and completely stop using the return statement (as described in section 4.1).This however requires further refinement of the grammar, and again deformation grammars might be the answer.We are also confident that similar problems will occur with other control-flow statements.We have also tested a very generic production rules, such as: <class_declaration_statement> :== "class BankAccount {" {<class_statement>} "}" <class_statement> :== <visibility_modifier> "function ("<parameter_list>"){" <statement_list> "}" | <visibility_modifier> <variable_without_objects> ";" ... When such generic rules were used, no solution without errors was found within 150 allowed generations.This was expected as the variability of solutions and state space complexity rises extremely quickly.</p>
<p>Conclusion</p>
<p>In this chapter, we have presented several methods and concepts suitable for code evolution a fully automated generation of working source code using evolutionary algorithms.In the above paragraphs, we described how code evolution could work together with code generation.Code generation tools can be used to create a skeleton or template for an application, while code evolution can fill in the actual algorithms.This way, the actual generated functions can be kept short enough, so that the code evolution is finished within reasonable time.Our long term goal is to create a tool which would be capable of generating some code from unit tests.This can have two practical applications -creating application prototypes and crosschecking the tests.This former is the case where the code quality is not an issue.What matters most is that the code is created with as little effort (money) as possible.The latter is the case where a programmer would like to know what additional possible errors might arise from a class.The method we focused on in this chapter is unique in that its' output is completely controlled by a context-free grammar.Therefore this method is very flexible and without any problems or modifications it can be used to generate programs in mainstream programing languages.We also tried to completely remove the fitness function of the genetic algorithm and replace it with standardized unit-tests.This can then be thought of as an extreme form of test-driven development.</p>
<p>Fig. 2 .
2
Fig. 2. Process of the translation of the genotype to a solution (phenotype)</p>
<p>Fig. 3 .
3
Fig. 3. Translation process of an expression specified by equation (4)</p>
<p>Fig. 4 .
4
Fig. 4. Translation of an expression (equation (4)) using the backward processing algorithm</p>
<p>Fig. 6 .
6
Fig. 6.Flowchart of two-level grammatical evolution</p>
<p><operator> ::= &lt; | &gt; | != | == | &gt;= | &lt;= <var> ::= $a | $b | $result <const> ::= 0 | 1| -1 <function> ::= + | -| * | / <begin> ::= {} <if> ::= if {} <assign> ::= = This grammar represents a very limited subset of the PHP language grammar</p>
<p>The following set of training patterns was used: P = {(−3, 3);(43, 43); (3, 3); (123, 123);(−345, 345);(−8, 8);(−11, 11); (0, 0)}.Fitness function is implemented so that for each pattern it assigns points according to achieved result (result is assigned, result is number, result is not negative, result is equal to training value).Sum of the points then represents the achieved fitness.Following are two selected examples of generated functions: function absge($a) { $result = null; $result = $a; if (($a) &lt;= (((-(-((-($result)) + ((-($a)) -(1))))) -(-1)) -(0))) { $result = -($result); } return $result; } function absge($a) { $result = null; $result = -($a); if ((-($result)) &gt;= (</p>
<p>Another example is a classic function for comparing two integers.Input values are two integer numbers a and b.Output value is integer c, which meets the conditions c &gt; 0, for a &gt; b; c = 0, for a = b; c &lt; 0, for a &lt; b.Training data is a set of triples (a, b, c): P = {(−3, 5,−1); (43, 0, 1); (8, 8, 0); (3, 4,−1); (−3,−4, 1);}</p>
<p>(Kasami, 1965)analysed string to initial symbol.The analysis begins with empty stack.In case of successful acceptance only initial symbol remains in the stack, e.g.Cocke-Younger-Kasami algorithm(Kasami, 1965), which grants that the time of analysis is proportional to third power of string length; -Top-down parsing -We begin from initial symbol and we are trying to generate analysed string.String generated so far is saved in the stack.Every time a terminal symbol appears on the top of the stack, it is compared to actual input symbol of the analysed string.If symbols are identical, the terminal symbol is removed from the top of the stack.If not, the algorithm returns to a point where a different rule can be chosen (e.g.
. It is possible touse:-Regular grammar -Deterministic finite state automaton is sufficient to analyse regulargrammar. This automaton is usually very simple in hardware and software realization.-Context-free grammar -To analyse context-free grammar a nondeterministic finite stateautomaton with stack is generally required.-Context grammar -"Useful and sensible" syntactic analysis can be done with context-free grammar with controlled re-writing.There are two basic methods of syntactic analysis:-Bottom-up parsing -
with help of backtracking).Example of top down parser is Earley's Parser</p>
<p>www.intechopen.com
AcknowledgementThis work was supported by the grants: MSM 6215648904/03 and IG1100791 Research design of Mendel Univeristy in Brno.The environment was the same like in the first example; generation took 75.1 population cycles on average.Although these tests are quite successful, it is obvious, that this is not very practical.For each simple automatically generated function a programmer would need to specify a very specific test, function header, function footer.Tests for genetic algorithms need to be specific in the values they return.A fitness function which would return just "yes" or "no" is insufficient in navigating the genetic algorithm in the state space -such function cannot be properly optimized.The exact granularity of the fitness function values is unknown, but as little as 5 values can be sufficient if they are evenly distributed (as shown in the first example in this section).Generating classes and methodsTo make this system described above practical, we had to use standardized tests and not custom made fitness functions.Also we wanted to use object oriented programming, because it is necessary to keep the code complexity very low.Therefore we need to stick with the paradigm of small simple "black box" objects.This is a necessity and sometimes an advantage.Such well-defined objects are more reliable, but it is a bit harder to maintain their connections(Büchi &amp; Weck, 1999).Writing class tests before the actual source code is already a generally recognized approach test-driven development.In test-driven development, programmers start off by writing tests for the class they are going to create.Once the tests are written, the class is implemented and tested.If all tests pass, a coverage analysis is performed to check whether the tests do cover all the newly written source code(Beck, 2002)Now we can use a PHP parser to read the class skeleton and import it as a template grammar rule into grammatical evolution.This task is not as easy as it might seem.The class declaration is incomplete -it is missing function parameters and private members of the class.Function parameters can be determined from the tests by static code analysis, provided that we refrain from variable function parameters.Function parameter completion can be solved by extending the PHPUnit framework.Private members completion is more problematic, since it should be always unknown to the unit test (per the black box principle).Currently we created grammar rule for grammatical evolution by hand.In future, however, we would like to use deformed grammar (as described in section 3.3) to derive initial rule for grammatical evolution.We use <class_declaration_statement> as starting symbol, then we can define first (and only) rewriting rule for that symbol as (in EBNF notation): <class_declaration_statement> :== "class BankAccount {" <class_variable_declarations> "public function depositMoney("<variable_without_objects>") {" <statement_list> "} public function getBalance() {" <statement_list> "} public function withdrawMoney("<variable_without_objects>") {" &lt;statement_list "} }" This way we obtain the class declaration generated by the unit test, plus space for private class members (only variables in this case) and function parameters.It is important to note that the grammar used to generate a functional class needs at least about 20 production rules www.intechopen.com
Co-evolving functions in genetic programming: Dynamic ADF creation using GliB. References Ahluwalia, M Bull, L , Proceedings of Evolutionary Programming VII -7th International Conference, EP98 San Diego. Evolutionary Programming VII -7th International Conference, EP98 San DiegoUSASpringer1998. 19981447</p>
<p>Practical Early Parsing. J Aycock, R N Horspool, DOI: 45:6:620-630The Computer Journal. 4562002British Computer Society</p>
<p>K Beck, Test Driven Development: By Example. USAAddison-Wesley Professional2002</p>
<p>Automatically Defined Functions in Gene Expression Programming in Genetic Systems Programming: Theory and Experiences. M Büchi, W Weck, : TUCS-TR-297Studies in Computational Intelligence. 131999. 2006aTurku Centre for Computer Science, Finland Cândida FerreiraTechnical ReportThe Greybox Approach: When Blackbox Specifications Hide Too Much</p>
<p>Gene Expression Programming: Mathematical Modelling by an Artificial Intelligence (Studies in Computational Intelligence. Cândida Ferreira, 2006bSpringerUSA</p>
<p>Constant creation in grammatical evolution. K Czarnecki, U Eisenecker, I Canada Dempsey, M O'neill, A Brabazon, Generative Programming: Methods, Tools, and Applications. Addison-Wesley Professional2000. 20071</p>
<p>Homologous Crossover in Genetic Programming. D F Francone, M Conrads, W Banzhaf, P Nordin, Proceedings of the Genetic and Evolutionary Computation Conference (GECCO). the Genetic and Evolutionary Computation Conference (GECCO)Orlando, USA1999</p>
<p>The Design of Innovation: Lessons from and for Competent Genetic Algorithms. D E Goldberg, 2002Kluwer Academic PublishersBoston, USA</p>
<p>Theoretical Aspects of Object-Oriented Programming: Types, Semantics, and Language Design. C A Gunter, J C Mitchell, 1994The MIT PressCambridge, Massachusetts, USA</p>
<p>Algorithms on strings, trees, and sequences: computer science and computational biology. D Gusfield, Dan Gusfield, 1997. 1997Cambridge University PressCambridge, UK</p>
<p>An efficient recognition and syntax-analysis algorithm for context-free languages. T Kasami, 1965Bedford, MA, USAAir Force Cambridge Research LabScientific report AFCRL-65-758</p>
<p>Genetic Programming: On the Programming of Computers by Means of Natural Selection. J R Koza, 1992The MIT PressCambridge, Massachusetts, USA</p>
<p>Gene Duplication to Enable Genetic Programming to Concurrently Evolve Both the Architecture and Work-Performing Steps of a Computer Program, IJCAIwww.intechopen.com Automatic Generation of Programs. J R Koza, Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence. J R , the Fourteenth International Joint Conference on Artificial IntelligenceUSA Koza; USASpringer1994. 20-25 August 1995. 200335Genetic Programming IV: Routine Human-Competitive Machine Intelligence</p>
<p>R Laddad, Aspectj in Action: Enterprise AOP with Spring Applications, Manning Publications, ISBN 978-1933988054. Greenwich, Connecticut, USA2009</p>
<p>An Introduction to Genetic Algorithms. M Mitchell, 1999MIT Press162Cambridge MA, USA</p>
<p>Grammatical Evolution: Evolutionary Automatic Programming in an Arbitrary Language. M Minařík, J Šťastný, O Popelka, M Neill, C Ryan, M O'neill, C Ryan, M Keijzer, M Cattolico, Proceedings of International Conference on Soft Computing Applied in Computer and Economic Environment ICSC. International Conference on Soft Computing Applied in Computer and Economic Environment ICSCKunovice, Czech Republic O'; Norwell, Massachusetts, USA; Lake Como, Italy Ošmera; Zittau, GermanySpringer2008. 2003. 2001. 2006Proceedings of: 13th Zittau Fuzzy Colloquium</p>
<p>Parallel Grammatical Evolution with Backward Processing. P Ošmera, O Popelka, P Pivoňka, Proceedings of ICARCV 2006, 9th International Conference on Control, Automation, Robotics and Vision. ICARCV 2006, 9th International Conference on Control, Automation, Robotics and VisionSingapore; SingaporeIEEE Press2006. December 2006</p>
<p>Automatic generation of programs: An overview of Lyee methodology. N Patterson, M ; Livesey, Morgan Kaufmann Poli, R , Proceedings of 6th world multiconference on systemics, cybernetics and informatics. 6th world multiconference on systemics, cybernetics and informaticsSan Francisco, California, USA; Orlando, Florida, USA1997. 1997. 2002. July 2002Iproceedings -information systems development I</p>
<p>Two-level optimization using parallel grammatical evolution and differential evolution. O Popelka, Proceedings of MENDEL 2007, International Conference on Soft Computing. MENDEL 2007, International Conference on Soft ComputingPraha, Czech Republic2007. August 2007</p>
<p>Generation of mathematic models for environmental data analysis. O Popelka, J Šťastný, Management si Inginerie Economica. 1583-624X62007</p>
<p>An Introduction to Differential Evolution. K Price, New Ideas in. Optimization, D Corne, M Dorigo, F Glover, London (UKMcGraw-Hill1999</p>
<p>PHP 5.2.0 EBNF Syntax. U Salsi, 2007</p>
<p>Mechanizing the development of software. D R Smith, Nato Advanced Science Institutes Series. Broy M. &amp; Steinbruggen R.1999IOS Press</p>
<p>Object Recognition by Means of New Algorithms. J Šťastný, M Minařík, Proceedings of International Conference on Soft Computing Applied in Computer and Economic Environment ICSC. International Conference on Soft Computing Applied in Computer and Economic Environment ICSCKunovice, Czech Republic TIOBE Software2006. 2010. June 2010TIOBE Programming Community Index for</p>
<p>Applying logic grammars to induce sub-functions in genetic programming. M L Wong, K S Leung, Proceedings of 1995 IEEE International Conference on Evolutionary Computation (ICEC 95). 1995 IEEE International Conference on Evolutionary Computation (ICEC 95)Perth, AustraliaIEEE Press Zend Technologies1995. November 1995. 2010Zend Engine -Zend Language Parser</p>            </div>
        </div>

    </div>
</body>
</html>