<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2865 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2865</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2865</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-71.html">extraction-schema-71</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-22d34b881d64523da54f13d01fc3c6d93a8412e3</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/22d34b881d64523da54f13d01fc3c6d93a8412e3" target="_blank">Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence</a></p>
                <p><strong>Paper Venue:</strong> Conference on Empirical Methods in Natural Language Processing</p>
                <p><strong>Paper TL;DR:</strong> This paper frames D&D specifically as a dialogue system challenge, where the tasks are to both generate the next conversational turn in the game and predict the state of the game given the dialogue history, and creates a gameplay dataset consisting of nearly 900 games.</p>
                <p><strong>Paper Abstract:</strong> AI researchers have posited Dungeons and Dragons (D&D) as a challenge problem to test systems on various language-related capabilities. In this paper, we frame D&D specifically as a dialogue system challenge, where the tasks are to both generate the next conversational turn in the game and predict the state of the game given the dialogue history. We create a gameplay dataset consisting of nearly 900 games, with a total of 7,000 players, 800,000 dialogue turns, 500,000 dice rolls, and 58 million words. We automatically annotate the data with partial state information about the game play. We train a large language model (LM) to generate the next game turn, conditioning it on different information. The LM can respond as a particular character or as the player who runs the game—i.e., the Dungeon Master (DM). It is trained to produce dialogue that is either in-character (roleplaying in the fictional world) or out-of-character (discussing rules or strategy). We perform a human evaluation to determine what factors make the generated output plausible and interesting. We further perform an automatic evaluation to determine how well the model can predict the game state given the history and examine how well tracking the game state improves its ability to produce plausible conversational output.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2865.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2865.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-Dialog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LaMDA baseline dialogue model (LLM-Dialog)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Baseline pre-trained LaMDA dialogue model (no Dungeons & Dragons fine-tuning or control/state conditioning); used as a non-D&D baseline for next-utterance prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LLM-Dialog</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A pretrained LaMDA conversational transformer used as the baseline agent. For next-utterance prediction it is given the seven most recent conversational turns as input and is trained to generate the 8th turn. It was not fine-tuned on the D&D play-by-post data and does not receive D&D-specific control features/state variables.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td>LaMDA (dialogue model), 64B parameter version (as stated in the paper)</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td>Not applicable (baseline generic dialogue model); used for comparison to D&D-finetuned models on Dungeons & Dragons play-by-post data</td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>No explicit memory system used. Acts as a baseline showing lower quality on D&D next-utterance prediction compared to models fine-tuned on D&D data.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2865.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2865.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-DND</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LaMDA fine-tuned on Dungeons & Dragons play-by-post data (LLM-DND)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>LaMDA finetuned on the D&D play-by-post corpus to predict next utterances, without conditioning on explicit control/state features for the current turn.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LLM-DND</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A LaMDA model finetuned on the scraped D&D Beyond play-by-post dataset. Input: seven most recent conversational turns (history). Output: generated next utterance. This variant does not receive the auxiliary control features/state variables as explicit conditioning; it learns from raw finetuning on the D&D corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td>LaMDA (dialogue model), 64B parameter version</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td>Dungeons & Dragons play-by-post dataset (D&D Beyond forum transcripts)</td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td>Multi-party, long history dependent dialog; mix of in-character (narrative) and out-of-character (rules/mechanics) text; episodic combats, dice rolls, explicit game state variables (character class, race, pronouns, inventory, combat flag, actions). Large scale: 896 campaigns, 815k turns, 58M words.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>No explicit memory module; fine-tuning on D&D data substantially improves next-utterance prediction metrics over the generic baseline (see perplexity/token accuracy differences in the paper). However, explicit state conditioning (control features) yields further improvements (see other variants).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2865.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2865.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-DND-PREV-CTRL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LaMDA finetuned on D&D data with control features for previous turns only (LLM-DND-PREV-CTRL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>LaMDA finetuned on D&D data and conditioned on control/state features for all previous dialog turns but not for the current turn being predicted.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LLM-DND-PREV-CTRL</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>This variant augments the seven-turn history input with explicit control features/state variables (player ID, IC/OOC flag, character name/class/race/pronouns, combat flag, actions, etc.) for all previous dialog turns. The model generates the next utterance without being provided the control features for the current (target) turn. The architecture is finetuned LaMDA taking concatenated history+control features as input.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td>LaMDA (dialogue model), 64B parameter version</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td>Dungeons & Dragons play-by-post dataset (D&D Beyond)</td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td>Same multi-party, narrative and mechanics-mixed dialog described for the D&D dataset; history-conditioned generation benefits from per-turn control/state variables.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>Conditioning on previous turns' control features gives modest improvements in human-rated metrics (sense, specific, interesting) compared to finetuning without control features, but this is not an explicit memory system.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2865.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2865.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-DND-CURR-CTRL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LaMDA finetuned on D&D data with control features for the current turn only (LLM-DND-CURRENT-CTRL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>LaMDA finetuned on D&D data and explicitly conditioned on control/state features for only the current turn being predicted; achieved the best perplexity and token accuracy on dev.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LLM-DND-CURRENT-CTRL</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A finetuned LaMDA model that receives the seven-turn history plus explicit control features for the current (target) turn (player ID, IC/OOC flag, character attributes, combat flag, action) as conditioning signals. The control features are formatted and concatenated with text history similar to control codes, enabling conditional generation tailored to character/class/ic state.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td>LaMDA (dialogue model), 64B parameter version</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td>Dungeons & Dragons play-by-post dataset (D&D Beyond)</td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td>Multi-party, long context, mixed IC/OOC turns, combat dynamics and dice outcomes; control features represent per-turn state signals.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>This model obtained the best dev-set perplexity (2.34) and highest token accuracy (49.67%) among variants reported in the paper, showing that conditioning on explicit state/control features (not a memory module) improves next-utterance prediction. The paper interprets the control features as enabling role-play specificity and higher interestingness for in-character outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2865.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2865.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-DND-ALL-CTRL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LaMDA finetuned on D&D data with control features for all turns (LLM-DND-ALL-CTRL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>LaMDA finetuned on D&D data and conditioned on control/state features for all dialog turns including the current turn; achieves near-best perplexity and token accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LLM-DND-ALL-CTRL</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Finetuned LaMDA that is provided explicit control/state features for each turn in the history and for the current turn being predicted. Control features include player ID, IC/OOC flag, character attributes (name, class, race, pronouns), combat flag, and action. The model concatenates these features with the textual history and generates the next utterance.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td>LaMDA (dialogue model), 64B parameter version</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td>Dungeons & Dragons play-by-post dataset (D&D Beyond)</td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td>Same dataset characteristics: multi-party, long narratives, episodic combats, explicit game-state signals; control features provide structured state information per turn.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>Model produced low perplexity (2.37) and high token accuracy (49.02%). Control features (structured state conditioning) improved generation quality relative to models without these features; nevertheless, the model does not implement an explicit memory module for long-term episodic/semantic memory.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2865.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2865.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-DND-GST</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LaMDA finetuned for Game State Tracking (LLM-DND-GST)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A LaMDA-based model finetuned to perform slot-filling style game state tracking on D&D play-by-post turns, predicting state variables (character class, name, race, pronouns, combat flag, actions) given history and current text.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LLM-DND-GST</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>This model is a LaMDA variant finetuned for the Game State Tracking task. Input: all previous dialog turns along with their (heuristically extracted) state variables and the text of the current turn. Output: slot-filling predictions for the current turn's state variables (character, class, race, pronouns, in-combat flag, action, etc.). The model is used to recover structured state from raw text, not to provide an external memory store.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td>LaMDA (dialogue model), 64B parameter version</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td>Dungeons & Dragons play-by-post dataset (D&D Beyond) — state tracking on forum turns</td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td>Slot-filling style state variables with varying temporal dynamics: static (class, race), periodic (in combat), and turn-by-turn (action). Heuristically annotated labels present on ~60% of turns; the dataset contains thousands of campaigns and hundreds of thousands of turns.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>LLM-DND-GST outperforms a majority-class baseline on average slot accuracy (.82 vs .73); individual slot accuracies reported (e.g., pronouns 0.89, combat 0.82). However, joint accuracy is only 58%, and the authors conclude that accurately tracking full game state likely requires additional machinery beyond finetuning a single LLM (i.e., dedicated memory/state-tracking systems).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Keep CALM and Explore: Language Models for Action Generation in Text-based Games <em>(Rating: 2)</em></li>
                <li>How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and Act in Fantasy Worlds <em>(Rating: 2)</em></li>
                <li>Learning to Speak and Act in a Fantasy Text Adventure Game <em>(Rating: 2)</em></li>
                <li>Learning How Not to Act in Text-Based Games <em>(Rating: 1)</em></li>
                <li>Playing Text-Based Games with Common Sense <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2865",
    "paper_id": "paper-22d34b881d64523da54f13d01fc3c6d93a8412e3",
    "extraction_schema_id": "extraction-schema-71",
    "extracted_data": [
        {
            "name_short": "LLM-Dialog",
            "name_full": "LaMDA baseline dialogue model (LLM-Dialog)",
            "brief_description": "Baseline pre-trained LaMDA dialogue model (no Dungeons & Dragons fine-tuning or control/state conditioning); used as a non-D&D baseline for next-utterance prediction.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "LLM-Dialog",
            "agent_description": "A pretrained LaMDA conversational transformer used as the baseline agent. For next-utterance prediction it is given the seven most recent conversational turns as input and is trained to generate the 8th turn. It was not fine-tuned on the D&D play-by-post data and does not receive D&D-specific control features/state variables.",
            "base_llm": "LaMDA (dialogue model), 64B parameter version (as stated in the paper)",
            "uses_memory": false,
            "memory_type": null,
            "memory_architecture": null,
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": null,
            "text_game_benchmark": "Not applicable (baseline generic dialogue model); used for comparison to D&D-finetuned models on Dungeons & Dragons play-by-post data",
            "game_characteristics": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": false,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "No explicit memory system used. Acts as a baseline showing lower quality on D&D next-utterance prediction compared to models fine-tuned on D&D data.",
            "uuid": "e2865.0",
            "source_info": {
                "paper_title": "Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "LLM-DND",
            "name_full": "LaMDA fine-tuned on Dungeons & Dragons play-by-post data (LLM-DND)",
            "brief_description": "LaMDA finetuned on the D&D play-by-post corpus to predict next utterances, without conditioning on explicit control/state features for the current turn.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "LLM-DND",
            "agent_description": "A LaMDA model finetuned on the scraped D&D Beyond play-by-post dataset. Input: seven most recent conversational turns (history). Output: generated next utterance. This variant does not receive the auxiliary control features/state variables as explicit conditioning; it learns from raw finetuning on the D&D corpus.",
            "base_llm": "LaMDA (dialogue model), 64B parameter version",
            "uses_memory": false,
            "memory_type": null,
            "memory_architecture": null,
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": null,
            "text_game_benchmark": "Dungeons & Dragons play-by-post dataset (D&D Beyond forum transcripts)",
            "game_characteristics": "Multi-party, long history dependent dialog; mix of in-character (narrative) and out-of-character (rules/mechanics) text; episodic combats, dice rolls, explicit game state variables (character class, race, pronouns, inventory, combat flag, actions). Large scale: 896 campaigns, 815k turns, 58M words.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": false,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "No explicit memory module; fine-tuning on D&D data substantially improves next-utterance prediction metrics over the generic baseline (see perplexity/token accuracy differences in the paper). However, explicit state conditioning (control features) yields further improvements (see other variants).",
            "uuid": "e2865.1",
            "source_info": {
                "paper_title": "Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "LLM-DND-PREV-CTRL",
            "name_full": "LaMDA finetuned on D&D data with control features for previous turns only (LLM-DND-PREV-CTRL)",
            "brief_description": "LaMDA finetuned on D&D data and conditioned on control/state features for all previous dialog turns but not for the current turn being predicted.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "LLM-DND-PREV-CTRL",
            "agent_description": "This variant augments the seven-turn history input with explicit control features/state variables (player ID, IC/OOC flag, character name/class/race/pronouns, combat flag, actions, etc.) for all previous dialog turns. The model generates the next utterance without being provided the control features for the current (target) turn. The architecture is finetuned LaMDA taking concatenated history+control features as input.",
            "base_llm": "LaMDA (dialogue model), 64B parameter version",
            "uses_memory": false,
            "memory_type": null,
            "memory_architecture": null,
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": null,
            "text_game_benchmark": "Dungeons & Dragons play-by-post dataset (D&D Beyond)",
            "game_characteristics": "Same multi-party, narrative and mechanics-mixed dialog described for the D&D dataset; history-conditioned generation benefits from per-turn control/state variables.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": false,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "Conditioning on previous turns' control features gives modest improvements in human-rated metrics (sense, specific, interesting) compared to finetuning without control features, but this is not an explicit memory system.",
            "uuid": "e2865.2",
            "source_info": {
                "paper_title": "Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "LLM-DND-CURR-CTRL",
            "name_full": "LaMDA finetuned on D&D data with control features for the current turn only (LLM-DND-CURRENT-CTRL)",
            "brief_description": "LaMDA finetuned on D&D data and explicitly conditioned on control/state features for only the current turn being predicted; achieved the best perplexity and token accuracy on dev.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "LLM-DND-CURRENT-CTRL",
            "agent_description": "A finetuned LaMDA model that receives the seven-turn history plus explicit control features for the current (target) turn (player ID, IC/OOC flag, character attributes, combat flag, action) as conditioning signals. The control features are formatted and concatenated with text history similar to control codes, enabling conditional generation tailored to character/class/ic state.",
            "base_llm": "LaMDA (dialogue model), 64B parameter version",
            "uses_memory": false,
            "memory_type": null,
            "memory_architecture": null,
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": null,
            "text_game_benchmark": "Dungeons & Dragons play-by-post dataset (D&D Beyond)",
            "game_characteristics": "Multi-party, long context, mixed IC/OOC turns, combat dynamics and dice outcomes; control features represent per-turn state signals.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": false,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "This model obtained the best dev-set perplexity (2.34) and highest token accuracy (49.67%) among variants reported in the paper, showing that conditioning on explicit state/control features (not a memory module) improves next-utterance prediction. The paper interprets the control features as enabling role-play specificity and higher interestingness for in-character outputs.",
            "uuid": "e2865.3",
            "source_info": {
                "paper_title": "Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "LLM-DND-ALL-CTRL",
            "name_full": "LaMDA finetuned on D&D data with control features for all turns (LLM-DND-ALL-CTRL)",
            "brief_description": "LaMDA finetuned on D&D data and conditioned on control/state features for all dialog turns including the current turn; achieves near-best perplexity and token accuracy.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "LLM-DND-ALL-CTRL",
            "agent_description": "Finetuned LaMDA that is provided explicit control/state features for each turn in the history and for the current turn being predicted. Control features include player ID, IC/OOC flag, character attributes (name, class, race, pronouns), combat flag, and action. The model concatenates these features with the textual history and generates the next utterance.",
            "base_llm": "LaMDA (dialogue model), 64B parameter version",
            "uses_memory": false,
            "memory_type": null,
            "memory_architecture": null,
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": null,
            "text_game_benchmark": "Dungeons & Dragons play-by-post dataset (D&D Beyond)",
            "game_characteristics": "Same dataset characteristics: multi-party, long narratives, episodic combats, explicit game-state signals; control features provide structured state information per turn.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": false,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "Model produced low perplexity (2.37) and high token accuracy (49.02%). Control features (structured state conditioning) improved generation quality relative to models without these features; nevertheless, the model does not implement an explicit memory module for long-term episodic/semantic memory.",
            "uuid": "e2865.4",
            "source_info": {
                "paper_title": "Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "LLM-DND-GST",
            "name_full": "LaMDA finetuned for Game State Tracking (LLM-DND-GST)",
            "brief_description": "A LaMDA-based model finetuned to perform slot-filling style game state tracking on D&D play-by-post turns, predicting state variables (character class, name, race, pronouns, combat flag, actions) given history and current text.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "LLM-DND-GST",
            "agent_description": "This model is a LaMDA variant finetuned for the Game State Tracking task. Input: all previous dialog turns along with their (heuristically extracted) state variables and the text of the current turn. Output: slot-filling predictions for the current turn's state variables (character, class, race, pronouns, in-combat flag, action, etc.). The model is used to recover structured state from raw text, not to provide an external memory store.",
            "base_llm": "LaMDA (dialogue model), 64B parameter version",
            "uses_memory": false,
            "memory_type": null,
            "memory_architecture": null,
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": null,
            "text_game_benchmark": "Dungeons & Dragons play-by-post dataset (D&D Beyond) — state tracking on forum turns",
            "game_characteristics": "Slot-filling style state variables with varying temporal dynamics: static (class, race), periodic (in combat), and turn-by-turn (action). Heuristically annotated labels present on ~60% of turns; the dataset contains thousands of campaigns and hundreds of thousands of turns.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": false,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "LLM-DND-GST outperforms a majority-class baseline on average slot accuracy (.82 vs .73); individual slot accuracies reported (e.g., pronouns 0.89, combat 0.82). However, joint accuracy is only 58%, and the authors conclude that accurately tracking full game state likely requires additional machinery beyond finetuning a single LLM (i.e., dedicated memory/state-tracking systems).",
            "uuid": "e2865.5",
            "source_info": {
                "paper_title": "Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence",
                "publication_date_yy_mm": "2022-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Keep CALM and Explore: Language Models for Action Generation in Text-based Games",
            "rating": 2
        },
        {
            "paper_title": "How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and Act in Fantasy Worlds",
            "rating": 2
        },
        {
            "paper_title": "Learning to Speak and Act in a Fantasy Text Adventure Game",
            "rating": 2
        },
        {
            "paper_title": "Learning How Not to Act in Text-Based Games",
            "rating": 1
        },
        {
            "paper_title": "Playing Text-Based Games with Common Sense",
            "rating": 1
        }
    ],
    "cost": 0.01438075,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence</h1>
<p>Chris Callison-Burch*<br>University of Pennsylvania<br>ccb@upenn.edu<br>Daphne Ippolito<br>University of Pennsylvania<br>Google Research</p>
<p>Gaurav Singh Tomar*<br>Google Research<br>gtomar@google.com<br>Lara J. Martin<br>University of Pennsylvania<br>David Reitter<br>Google Research</p>
<h2>Abstract</h2>
<p>AI researchers have posited Dungeons and Dragons (D\&amp;D) as a challenge problem to test systems on various language-related capabilities. In this paper, we frame D\&amp;D specifically as a dialogue system challenge, where the tasks are to both generate the next conversational turn in the game and predict the state of the game given the dialogue history. We create a gameplay dataset consisting of nearly 900 games, with a total of 7,000 players, 800,000 dialogue turns, 500,000 dice rolls, and 58 million words. We automatically annotate the data with partial state information about the game play. We train a large language model (LM) to generate the next game turn, conditioning it on different information. The LM can respond as a particular character or as the player who runs the game-i.e., the Dungeon Master (DM). It is trained to produce dialogue that is either in-character (roleplaying in the fictional world) or out-of-character (discussing rules or strategy). We perform a human evaluation to determine what factors make the generated output plausible and interesting. We further perform an automatic evaluation to determine how well the model can predict the game state given the history and examine how well tracking the game state improves its ability to produce plausible conversational output.</p>
<h2>1 Introduction</h2>
<p>Artificial Intelligence has a long and rich history of using games as challenge problems that lead to advances in the field. In many cases, AI game-playing systems have gone on to rival human champions of the game. Dungeons and Dragons has been identified as an appropriate challenge for the next stage of artificial intelligence (Ellis and Hendler, 2017; Louis and Sutton, 2018; Martin et al., 2018b). Ellis and Hendler (2017) proposed open-ended creative games like D\&amp;D as the next challenge for AI after the human-level successes of AI at Chess and</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Go, which are zero-sum, deterministic, sequential two-player games with perfect information. Louis and Sutton (2018) understood the importance of narrative in natural language processing (NLP) and generation (NLG). In particular, they saw how cooperative story generation between humans already exists in these games and can be used for automated generation. Martin et al. (2018b) outlined some of the specific challenges D\&amp;D presents to the NLP community; such as a state of the game world distributed across the Dungeon Master (DM) and other players or dealing with the intrinsic rewards players get from taking certain actions that would not necessarily provide them with points in the game.</p>
<p>D\&amp;D involves multiple players who roleplay characters in a fantasy setting, guided by a Dungeon Master who sets obstacles and adventures and plays as monsters. In roleplaying games like Dungeons and Dragons, the gameplay happens through language rather than moves on a game board, making it an interesting domain for NLP research. To have an AI successfully play D\&amp;D , it would require abilities like</p>
<ul>
<li>Language generation (multi-party dialog, generating descriptions of the world/actions, storytelling)</li>
<li>Language understanding (knowledge acquisition and representation, state tracking, automated reasoning)</li>
<li>Planning / strategic play during battles (similar to chess or go)
Appendix A gives an example of D\&amp;D gameplay and the AI challenges presented by it.</li>
</ul>
<p>Is it possible to design an AI system that is capable of playing a game of D\&amp;D either as a character in the game or as the Dungeon Master using current AI technology? We argue that now is the perfect time for this challenge, since large scale neural language models like GPT have shown impressive generation results (Brown et al., 2020), and since</p>
<p>incorporating neural LMs into a game setting both exercises their strengths and exposes their weaknesses.</p>
<p>In this paper, we introduce a new dataset of "actual play" game transcripts. Each turn is labeled with game state variables like character information and whether the conversational turn was incharacter or out-of-character. Our data is a novel, large scale, real-world conversational dataset. It is unique in that the dialog turns are generated entirely through player collaboration and written interaction in a multi-player game. We propose our dataset as a challenge for dialogue systems for the following reasons:</p>
<ul>
<li>It is naturally occurring conversational dialog that covers a spectrum of task oriented and non-task oriented (e.g. chit chat) dialog.</li>
<li>It is strongly history dependent - a substantive criticism of recent dialog datasets is their history independence (Mosig et al., 2020).</li>
<li>It has many participants in the conversation, since there are several players in the game.</li>
<li>It conveys narrative elements including descriptions of events that denote changes in the state of the game.
Unlike existing dialog datasets, our data reflects the challenging nature of the D\&amp;D game as a multiparty dialogue with creative roleplaying and underlying game states.</li>
</ul>
<h2>2 Tasks</h2>
<p>We trained a large language model (LLM) to perform two tasks: Next Utterance Prediction and Game State Tracking.</p>
<p>Next Utterance Prediction. We trained our language model on a corpus of human conversations (see Section 3) to predict the next utterance. We varied the conditioning information to examine the effects on the quality of predicted next utterance. In all variations, we included the conversational history as input. Given the conversational input (and other input in the variant models), the LLM must generate the next utterance, such that it is both interesting and a plausible next turn in the D\&amp;D game.</p>
<p>Game State Tracking. In this task, rather than producing the next utterance, we had the model predict the game state for a given dialogue turn in the conversation. We have kept the state definition similar to task-oriented dialogue state tracking</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Play-By-Post Corpus</th>
<th style="text-align: right;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Number of campaigns</td>
<td style="text-align: right;">896</td>
</tr>
<tr>
<td style="text-align: left;">Average players per campaign</td>
<td style="text-align: right;">8</td>
</tr>
<tr>
<td style="text-align: left;">Average turns per campaign</td>
<td style="text-align: right;">910</td>
</tr>
<tr>
<td style="text-align: left;">Average words per campaign</td>
<td style="text-align: right;">64,941</td>
</tr>
<tr>
<td style="text-align: left;">Total turns</td>
<td style="text-align: right;">815,106</td>
</tr>
<tr>
<td style="text-align: left;">Total words</td>
<td style="text-align: right;">$58,187,526$</td>
</tr>
<tr>
<td style="text-align: left;">Average dice rolls per campaign</td>
<td style="text-align: right;">594</td>
</tr>
<tr>
<td style="text-align: left;">Total dice rolls</td>
<td style="text-align: right;">532,270</td>
</tr>
</tbody>
</table>
<p>Table 1: Statistics for our play-by-post corpus
(DST). In DST, the dialogue state is a collection of slot-value pairs. In our case, each slot is a state variable feature related to D\&amp;D games. Our target slot values do not need to appear as a word in the dialogue context. We track several game states aspects including some that remain relatively static throughout the game (character attributes like their pronouns, class, fantasy race, and their inventory), some that change periodically (like being in combat or out of combat), and some that change from turn to turn (like what action the player is taking).</p>
<h2>3 Dataset</h2>
<p>For this paper, we have created a novel dataset for our dialogue-oriented test of AI's ability to play Dungeons \&amp; Dragons. We scraped Play-By-Post data from a web forum ${ }^{1}$ where people play by taking turns posting on the forum to describe their move.</p>
<p>Figure 1 shows an example of part of the gameplay from the play-by-post forums from D\&amp;D Beyond. D\&amp;D Beyond provides a mechanism in its forum to roll dice using a "roll" tag. Their dice roller allows players to conduct the rolls that are used for D\&amp;D ability checks and in combat.</p>
<p>Table 1 summarizes the amount of play-by-post data that we collected from the D\&amp;D Beyond website (with permission from the company).</p>
<h3>3.1 Heuristic annotation of game states</h3>
<p>We designed a set of rule-based heuristics to extract game state information from the play by post. These were implemented using regular expressions and NLP tools like named entity recognizers (Gardner et al., 2018). Although this heuristically extracted information is not perfect, it provides a reasonable approximation of the game state. It is</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Example of 3 turns in the D\&amp;D Beyond play-by-post forum
useful for testing whether large language models can benefit from inclusion of complex state information for next utterance prediction and whether LLMs can be used for state tracking. We designed rules to extract state information relating to character properties, combat and player actions.</p>
<h2>Character properties</h2>
<ul>
<li>Name: Perform NER on all the player's turns in a campaign. The character's name is assigned to be the player's most frequently mentioned name, on the assumption that they tend to describe their own character's actions.</li>
<li>Class: Count how many times each D\&amp;D class ${ }^{2}$ is mentioned by each player. Most frequently mentioned class is their character's class.</li>
<li>Race: On a player's first turn, check whether any of the D\&amp;D fantasy races ${ }^{3}$ are mentioned. Assign it to character. If not, guess based on the most frequently mentioned race.</li>
<li>Pronouns: Count pronouns mentioned by a player. Assign their character's pronouns to be the most frequent pronouns used by the player.</li>
<li>Inventory: Use regex to match items occurring after character's personal pronouns (e.g. her sword).</li>
</ul>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>- Spells known: Regex that matches cast followed by a spell name
The DM is assumed to be the player who has the first post in the game. The DM's entries in the dataset are scrubbed of other character properties, since they play multiple NPCs (non-player characters) and monsters.</p>
<h2>Combat</h2>
<ul>
<li>We detect the start of combat when there is a roll for initiative, or when there are attack rolls before initiative (from surprise attacks).</li>
<li>Combat continues while there are attack rolls happening.</li>
<li>Combat concludes after there are no rolls for a number of turns.</li>
<li>In a combat span, we extract a list of monsters mentioned, and heuristically guess the number of each kind of monster.</li>
</ul>
<h2>Actions</h2>
<ul>
<li>Dice rolls are marked in D\&amp;D Beyond posts. We detect the associated actions based on the kind of die used ( $\mathrm{D} 20=$ a check, other dice are used for calculating damage if an attack check is successful)</li>
<li>We use a regex to match the nearest pattern, which includes attack or a list of abilities like acrobatics, animal handling, arcana, athletics, etc.</li>
<li>Damage rolls are matched with damage, $d m g$</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: center;">Control Feature</th>
<th style="text-align: center;">Description</th>
<th style="text-align: center;">Expected Impact on Model's Output</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Player ID</td>
<td style="text-align: center;">Player writing a given dialog turn</td>
<td style="text-align: center;">Connects the current turn to the player's previous turns, which is important in multi-party conversations.</td>
</tr>
<tr>
<td style="text-align: center;">IC versus OOC</td>
<td style="text-align: center;">Whether a player is in-character or out-ofcharacter for a given dialog turn</td>
<td style="text-align: center;">Changes whether the generated text is more like descriptive text found in a novel, or more like a discussion of rules and strategies.</td>
</tr>
<tr>
<td style="text-align: center;">Character Name</td>
<td style="text-align: center;">Name of the character being played by the player of a given dialog turn</td>
<td style="text-align: center;">IC descriptions use the character's name.</td>
</tr>
<tr>
<td style="text-align: center;">Character Class</td>
<td style="text-align: center;">D\&amp;D classes</td>
<td style="text-align: center;">Character classes perform different actions (e.g. wizards cast spells, thieves pick locks)</td>
</tr>
<tr>
<td style="text-align: center;">Character Race</td>
<td style="text-align: center;">D\&amp;D fantasy races</td>
<td style="text-align: center;">Different physical characteristics (e.g. halflings are small, dragonborn have scales).</td>
</tr>
<tr>
<td style="text-align: center;">Character <br> Pronouns</td>
<td style="text-align: center;">The character's pronouns</td>
<td style="text-align: center;">Uses the correct pronouns when describing the character.</td>
</tr>
<tr>
<td style="text-align: center;">Character <br> Actions</td>
<td style="text-align: center;">List of actions taken by the character in the current turn</td>
<td style="text-align: center;">Allows a description to be generated for a given action. The action can be thought of as a goal for the description.</td>
</tr>
<tr>
<td style="text-align: center;">Combat</td>
<td style="text-align: center;">Whether the players are currently engaged in combat or not during a given dialog turn</td>
<td style="text-align: center;">Affects the likelihood of actions (e.g. attacks are more likely during combat and investigations checks are more likely outside of combat)</td>
</tr>
</tbody>
</table>
<p>Table 2: Our LLMs are conditioned on a variety of control features that allow the models to better learn what kind of text to generate for the next utterance prediction task
cure, heal, healing, points.
Our heuristics resulted in features for around $60 \%$ of all conversational turns. We train a convolutional neural network classifier using these conversational turns to predict all of the above control features for each conversational turn in training data. Appendix C estimates the accuracy of the model's prediction on these state features.</p>
<h3>3.2 In-Character Versus Out-Of-Character Text</h3>
<p>In addition to labeling the game states in our Play by Post data, we also labeled the text of each turn as being either spoken in-character (IC) or out-ofcharacter (OOC). To do so, we crawled another Play by Post forum hosted at Giant in the Playground ${ }^{4}$, where play happens on two discussion boards - one in-character and one out-of-characters. For example, here is an IC post:</p>
<p>Kuros pulls the feathered shaft of the arrow back to his cheek winning easily against the resistance of the bowstring. He pulls a lungful of air to keep himself steady, takes aim at the Bandit with the deer, and lets fly.</p>
<p>And here is its corresponding OOC post:
Surprise round so only 1 standard or move action. Shoot the bow:</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>(1d20+6)[20] vs Flat Footed AC at Bandit 1. Damage: $(1 \mathrm{~d} 8+2)[10]$</p>
<p>We train a classifier to predict IC versus OOC text, and then apply it to each paragraph in our D\&amp;D Beyond forum data.</p>
<h2>4 Models</h2>
<p>For our large language model, we use a 64B parameter version of Google's LaMDA language model (Thoppilan et al., 2022), which was trained on conversations. LaMDA is similar to other Transformerbased pre-trained language models like GPT-3. As with other pre-trained language models (Howard and Ruder, 2018), LaMDA can be finetuned to different tasks. The two tasks that we finetune LaMDA to perform are game state tracking and response generation. In both cases, the LLM can be thought of as a function that maps inputs onto an output. For instance, game state tracking is a language understanding task where the function takes in inputs like $f$ (current utterance, previous state, history) $\rightarrow$ new state, and response generation is a language generation task where $f$ (current state, history) $\rightarrow$ next utterance. The LLM functions are trained via the fine tuning process.</p>
<p>In our experiments we try a variety of different inputs to our LLM functions to see how they enable better learning of the tasks. We train our LLMs on the conversation history (which is typical in dialog modeling) and we also augment the conversations by conditioning other explicit signals. These</p>
<p>conditioning signals can be thought of as sophisticated "control features", inspired by the CTRL language model (Keskar et al., 2019). During training, the model learns a relationship between the control features and appropriate responses. In turn, during inference, one can explicitly influence dimensions of the conversation - enabling more compelling dialogue - by setting the values of control features. These control features can be set dynamically, without necessitating finetuning or additional post-processing. Table 2 describes the control features we have proposed and describes how they could steer generation. Note that we use the terms 'control features' and 'state variables' interchangeably when referring to our next utterance prediction models.</p>
<h3>4.1 Baseline Pre-Training Data</h3>
<p>LaMDA is trained on turn-based conversational data. For a conversation of length $n$, LaMDA takes as input the first $n-1$ turns, and the $n$th turn as the target. For all models, we used the 7 most recent conversational turns as input, and predict turn 8 .</p>
<h3>4.2 D\&amp;D FineTuning Data</h3>
<p>Here is an example of the data used in our versions of LaMDA that are finetuned to on our D\&amp;D data.</p>
<h2>TURN 1:</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Text</th>
<th style="text-align: left;">You attack. You launch some fire onto the <br> goblin closest to the wagon. And with that, <br> he looks like he is on death's door. And <br> the other goblin that you can see, the one <br> that's not in the brush somewhere, just sort <br> of stops in his tracks. What do you do next?</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Player ID</td>
<td style="text-align: left;">0</td>
</tr>
<tr>
<td style="text-align: left;">Character</td>
<td style="text-align: left;">Dungeon Master</td>
</tr>
<tr>
<td style="text-align: left;">Race</td>
<td style="text-align: left;">N/A</td>
</tr>
<tr>
<td style="text-align: left;">Class</td>
<td style="text-align: left;">Dungeon Master</td>
</tr>
<tr>
<td style="text-align: left;">Pronouns</td>
<td style="text-align: left;">N/A</td>
</tr>
<tr>
<td style="text-align: left;">Inventory</td>
<td style="text-align: left;">N/A</td>
</tr>
<tr>
<td style="text-align: left;">In combat?</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr>
<td style="text-align: left;">In character?</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr>
<td style="text-align: left;">Action</td>
<td style="text-align: left;">Attack</td>
</tr>
</tbody>
</table>
<p>TURN 2:
Text I grab my axe and bring it down on the wounded goblin.
Player ID 1
Character Magnus
Race Human
Class Fighter
Pronouns he/him
Inventory Axe
In combat? Yes
In character? Yes
Action Attack
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Negative Log Perplexity of our models after pretraining on generic dialogue data for 600 k steps, and then finetuning to our data for a further 60k steps. Colors correspond to the models in Table 3.</p>
<h3>4.3 Next Utterance Prediction Models</h3>
<p>LLM-Dialog: We call our baseline model LLMDialog. It is a LaMDA dialogue model that does not use not use any D\&amp;D data.</p>
<p>LLM-DND: LLM-Dialog that has been finetuned on Play-by-post D\&amp;D gameplay dataset using no control features</p>
<p>LLM-DND-ALL-CTRL: LLM-Dialog that has been finetuned on Play-by-post D\&amp;D gameplay dataset using control features (state variables) for all dialog turns including the state variables for the current turn the utterance is being predicted for.</p>
<p>LLM-DND-PREV-CTRL: LLM-Dialog that has been finetuned on Play-by-post D\&amp;D gameplay dataset using control features for all previous dialog turns, not including the current turn.</p>
<h2>LLM-DND-CURRENT-CTRL: LLM-Dialog</h2>
<p>that has been finetuned on Play-by-post D\&amp;D gameplay dataset using control features (state variables) for only the current turn the utterance is being predicted for.</p>
<h3>4.4 Dev Set Perplexity During Training</h3>
<p>Each of our models starts from a pretrained LaMDA model trained for 600 K steps and then is finetuned for a further 60 K steps. Figure 2 plots the Negative log perplexity on our development set, and Table 3 shows the final perpexity and token accuracies on the dev set. At the end of finetuning, the models with the best perplexity scores and the best token accuracy scores were LLM-DND-CURRENT-CTRL and LLM-DND-ALL-CTRL, which used our control features.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Perplexity</th>
<th style="text-align: center;">Token Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">LLM-Dialog</td>
<td style="text-align: center;">2.65</td>
<td style="text-align: center;">44.61</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND</td>
<td style="text-align: center;">2.50</td>
<td style="text-align: center;">46.92</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND-PREV-CTRL</td>
<td style="text-align: center;">2.51</td>
<td style="text-align: center;">46.84</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND-CURR-CTRL</td>
<td style="text-align: center;">$\mathbf{2 . 3 4}$</td>
<td style="text-align: center;">$\mathbf{4 9 . 6 7}$</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND-ALL-CTRL</td>
<td style="text-align: center;">2.37</td>
<td style="text-align: center;">49.02</td>
</tr>
</tbody>
</table>
<p>Table 3: Perplexity and token accuracy of our models after finetuning to our data.</p>
<h2>5 Manual Evaluation</h2>
<p>To evaluate the quality of our models for the task of next utterance prediction in D\&amp;D, we perform a human evaluation. We recruited professional raters to perform a manual evaluation. They read a version of the content that was provided to the models - the seven turns of conversational history plus a list of players and the names/classes of the characters that they played. Then they were shown several model outputs for the context (or the "gold", which was the actual next turn in the game), The annotators asked to rate each output along the three dimensions, following the evaluation procedure used for the Meena LM (Adiwardana et al., 2020):</p>
<ul>
<li>Does the response make sense? (yes/no)</li>
<li>Is the response specific? (yes/no)</li>
<li>How interesting is the response? (10 point scale)
The full annotator instructions and the annotation interface are given in Appendix D.</li>
</ul>
<h3>5.1 Raters</h3>
<p>Because of the specialized nature of the D\&amp;D domain, we recruited 6 professional raters rather than crowd workers to perform the task. The raters were selected based on their professed interest in the fantasy genre, and on their background with D\&amp;D. All raters were fantasy fans, and 5 of the 6 had played D\&amp;D. 3 raters had been the DM in a game before.</p>
<h3>5.2 Inter-Rater Agreement</h3>
<p>Our raters annotated 500 system outputs with 3way redundancy on each output. For the binary sense and specific scores, pairwise annotator agreement was 0.8 , with a chance-adjusted Randolph Kappa score of 0.6 . For the scalar interestingness scores, the Kendall's Tau correlation was 0.46 .</p>
<h3>5.3 Analysis</h3>
<p>Model Comparison. Table 4 shows the average sense, specific and interestingness scores for the systems, and for the human-written gold response. All of the D\&amp;D adapted systems outperform the</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Sense</th>
<th style="text-align: center;">Specific</th>
<th style="text-align: center;">Interest</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">LLM-Dialog</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">3.57</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND</td>
<td style="text-align: center;">$\mathbf{0 . 9}$</td>
<td style="text-align: center;">$\mathbf{0 . 9}$</td>
<td style="text-align: center;">3.91</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND-PREV-CTRL</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">$\mathbf{3 . 9 6}$</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND-CURR-CTRL</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">$\mathbf{0 . 9}$</td>
<td style="text-align: center;">$\mathbf{3 . 9 6}$</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND-ALL-CTRL</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">3.92</td>
</tr>
<tr>
<td style="text-align: left;">GOLD</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">4.17</td>
</tr>
</tbody>
</table>
<p>Table 4: Average sense, specific and interestingness scores for our systems, and for human-written gold responses
vanilla dialogue system. On average, the adapted systems make sense $6.75 \%$ more often than the baseline, are specific $4 \%$ more often, and are 0.37 points more interesting. However, the added control features do not seem to differ substantially from the LLM that is adapted to the D\&amp;D data without any control features. Why then use the control features at all?</p>
<p>Control Features. One reason is that the control features are useful to allow the model to role-play. For example, we can ask the model to play an elf wizard via the control features. Table 5 gives a qualitative example of this. The Table shows outputs from two LLMs without control features, plus 3 outputs from our LLM-DND-CURRENT-CTRL model roleplaying different characters. As input, we gave the models the final seven turns in the game play example from Appendix A -from "With his eagle eyes, Magnus spots two dead horses. . ." to "... What do you do next?", and then generate what each model thinks the next utterance ought to be. The vanilla dialogue system with no D\&amp;D data generates an irrelevant reply about Discord. The dialogue system fine-tuned on D\&amp;D data without control feature generates a relevant response. The dialgoue system that adds conditioning control features allows the model to generate specific replies for each of the different characters. These replies are relevant to the character classes - the wizard casts a spell, and the Dwarf cleric shouts a battle cry by invoking the name of a Dwarf god.</p>
<p>In-Character Turns Are More Interesting. Among our most impactful control features was the one that allowed systems to generate in-character (IC) versus out-of-character (OOC) turns. Table 6 shows that control models' scores substantially increased on IC turns compared to when their output was generated OOC. The pronounced increase in intersestingness makes sense because IC turns are ones where the players describe their characters in</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: left;">Output</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">LLM-Dialog</td>
<td style="text-align: left;">moon_monk you can just join our discord conversation. it's free and easier to deal with</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND</td>
<td style="text-align: left;">I cast Ice Knife (I'm assuming this is not one of the ones I can't do?)</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND-CURRENT-CTRL</td>
<td style="text-align: left;">I turn from the goblin and go to help Merle and Taako with getting this wagon moving</td>
</tr>
<tr>
<td style="text-align: left;">Responding as Magnus (human</td>
<td style="text-align: left;">again. Magnus can't see them anymore with such a dense forest. They're likely in a</td>
</tr>
<tr>
<td style="text-align: left;">fighter, inventory: axe) In combat</td>
<td style="text-align: left;">battle right now... I have to find them as fast as I can!</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND-CURRENT-CTRL</td>
<td style="text-align: left;">If the goblins still don't look like they're getting closer, Taako will yell, "Alright you</td>
</tr>
<tr>
<td style="text-align: left;">Responding as Taako (elf wizard, in-</td>
<td style="text-align: left;">little monsters! Let's see what ya got!" And he'll cast Chill Touch on one of the goblins</td>
</tr>
<tr>
<td style="text-align: left;">ventory: spellbook) In combat</td>
<td style="text-align: left;">that isn't dead/on its doorstep. Attack: 22 Damage: 6</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND-CURRENT-CTRL</td>
<td style="text-align: left;">Merle steps away from the wagon. He draws his sword and takes aim at the hidden</td>
</tr>
<tr>
<td style="text-align: left;">Responding as Mearle (dwarf cleric,</td>
<td style="text-align: left;">goblin! Attack: 27 Damage: 8 He puts his free hand on the pommel of his sword and</td>
</tr>
<tr>
<td style="text-align: left;">inventory: holy symbol) In combat</td>
<td style="text-align: left;">shouts his battle cry, "For Clanggeddin!" His eyes glow brightly red as he strikes!</td>
</tr>
</tbody>
</table>
<p>Table 5: Example model outputs for the next utterance prediction task, given the sample gameplay from Table 8 as input. The 3 LLM-DND-CURRENT-CTRL examples use the same model with different control features (in red).</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Sense</th>
<th style="text-align: center;">Specific</th>
<th style="text-align: center;">Interest</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">LLM-Dialog</td>
<td style="text-align: center;">-0.01</td>
<td style="text-align: center;">-0.01</td>
<td style="text-align: center;">+0.06</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND</td>
<td style="text-align: center;">-0.02</td>
<td style="text-align: center;">+0.03</td>
<td style="text-align: center;">+0.4</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND-PREV-CTRL</td>
<td style="text-align: center;">+0.02</td>
<td style="text-align: center;">+0.02</td>
<td style="text-align: center;">+0.6</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND-CURR-CTRL</td>
<td style="text-align: center;">+0.06</td>
<td style="text-align: center;">$\mathbf{+ 0 . 0 6}$</td>
<td style="text-align: center;">$\mathbf{+ 0 . 9 3}$</td>
</tr>
<tr>
<td style="text-align: left;">LLM-DND-ALL-CTRL</td>
<td style="text-align: center;">$\mathbf{+ 0 . 0 7}$</td>
<td style="text-align: center;">$\mathbf{+ 0 . 0 6}$</td>
<td style="text-align: center;">+0.81</td>
</tr>
<tr>
<td style="text-align: left;">GOLD</td>
<td style="text-align: center;">+0.07</td>
<td style="text-align: center;">+0.05</td>
<td style="text-align: center;">+1.02</td>
</tr>
</tbody>
</table>
<p>Table 6: Improvements by generating in-character (IC) text rather than out-of-character (OOC) text. Numbers are IC scores minus OOC scores.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">State variable</th>
<th style="text-align: left;">Majority</th>
<th style="text-align: left;">LLM-DND-GST</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">All</td>
<td style="text-align: left;">.73</td>
<td style="text-align: left;">.82</td>
</tr>
<tr>
<td style="text-align: left;">Combat</td>
<td style="text-align: left;">.89</td>
<td style="text-align: left;">.82</td>
</tr>
<tr>
<td style="text-align: left;">Character Class</td>
<td style="text-align: left;">.58</td>
<td style="text-align: left;">.76</td>
</tr>
<tr>
<td style="text-align: left;">Character Name</td>
<td style="text-align: left;">.58</td>
<td style="text-align: left;">.78</td>
</tr>
<tr>
<td style="text-align: left;">Character Race</td>
<td style="text-align: left;">.75</td>
<td style="text-align: left;">.79</td>
</tr>
<tr>
<td style="text-align: left;">Character Pronouns</td>
<td style="text-align: left;">.58</td>
<td style="text-align: left;">.89</td>
</tr>
<tr>
<td style="text-align: left;">Character Actions</td>
<td style="text-align: left;">.80</td>
<td style="text-align: left;">.85</td>
</tr>
</tbody>
</table>
<p>Table 7: Average accuracy for our Game State Tracking LLM on the slot-filling our state variables, compared to a majority class baseline.
the fictional world often with evocative language, whereas OOC turns usually discuss rules or mechanics. Our control features allowed the system to intentionally generate IC responses, resulting in substantially improved interestingness scores for those in-character turns.</p>
<h2>6 Game State Tracking Model</h2>
<p>We conducted an experiment to evaluate whether a LLM could be finetuned to perform game state tracking for D\&amp;D using our heuristically annotated game state features. We trained a new model LLM-DND-GST (Game State Tracking). It is a LLMDialog that has been finetuned on our Play-by-post D\&amp;D gameplay dataset. As input, it takes all previous dialog turns and their state variables, plus the text of the current turn, and then it outputs the
corresponding state variables for the current turn.
We analyzed the accuracy of the LLM-DNDGST model its ability to do slot-filling for each of the individual game states, and compared its performance to a simple baseline that always output the the majority class. The results are shown in Table 7. The average accuracy of the dialogue state tracker is better than the majority class baseline, but likely falls short of being useful when it comes to joint accuracy. The joint accuracy for LLM-DND-GST is $58 \%$. This suggests that accurately tracking the full game state may require additional machinery beyond a finetuned LLM.</p>
<h2>7 Related Work</h2>
<p>Previous work has examined AI to play text adventures games (Haroush et al., 2018; Yao et al., 2020; Dambekodi et al., 2020). These games are simpler than D\&amp;D because they have a limited vocabulary and more straightforward game states. Creating text adventure games (Ammanabrolu et al., 2020a; Fan et al., 2020) is more challenging than playing them, and is similar to the world-building job of the DM in D\&amp;D . There has also been work on persona/character generation in stories (Prabhumoye et al., 2019), and within D\&amp;D itself (Louis and Sutton, 2018). Others (Urbanek et al., 2019; Ammanabrolu et al., 2020b) have realized that NPCs are lacking in their abilities to speak and act in text games.</p>
<p>Findings of the automated story generation community are relevant for D\&amp;D AI systems. Neural language models have become increasingly more popular for story generation (Roemmele, 2018; Martin et al., 2018a; Mathewson et al., 2019; Hou et al., 2019). We have also started to see storytelling with transformers (See et al., 2019; Peng et al., 2021; Branch et al., 2021). Transformer-</p>
<p>based storytelling systems have even been introduced to the general public thanks to the popularity of AI Dungeon (Walton, 2019). Although neural networks possess a lot of power in terms of what text they generate, they are still limited in their ability to produce longer spans of coherent text. Many (Fan et al., 2018; Yao et al., 2019; Ippolito et al., 2019; Tambwekar et al., 2019; Ammanabrolu et al., 2020b; Rashkin et al., 2020) have improved the coherence of neural storytellers by splitting the generation into two steps: ideation of the story plot, followed by the realization of sentences. This controllable story generation is the focus of a lot of current work in neural automated story generation.</p>
<p>Due to the conversational nature of D\&amp;D , we decided to use a dialog-based system. Deep neural networks have been used for dialog agents for a while (Serban et al., 2016), with a shift toward using transformers in recent years (Zhang et al., 2019; Ghazarian et al., 2021). Like in automated story generation and other neural text generation tasks, we are also seeing controllability being an important factor being integrated into systems. This includes using deep reinforcement learning techniques to guide the dialog toward a goal (Li et al., 2016; Saleh et al., 2020) or controlling for style (Zhang et al., 2018; Smith et al., 2020).</p>
<p>In this paper, we use LaMDA, a transformerbased open-domain dialogue system that builds on the Meena model (Adiwardana et al., 2020). The original Meena model was an end-to-end model trained on public conversations found on social media. Controllable text generation with transformers has been seen before with CTRL (Keskar et al., 2019), a language model that is conditioned on a given "control code" in addition to the textual history. This work takes a similar approach. We integrate contextual information such as character descriptions, actions, and in- and out-of-character classifications.</p>
<p>We have finetuned our LaMDA models on data crawled from D\&amp;D Beyond. This data contains both in-character and out-of-character dialog and can be used in conjunction with Rameshkumar and Bailey (2020)'s dataset from Critical Role (a D\&amp;D podcast), Louis and Sutton (2018)'s dataset from roleplayerguild.com (a D\&amp;D forum), Urbanek et al. (2019)'s crowdsourced LIGHT dataset, and/or Akoury et al. (2020)'s STORIUM dataset for human+AI collaborative story generation.</p>
<h2>8 Discussion and Conclusions</h2>
<p>We have demonstrated that training on D\&amp;D data results in much higher quality outputs than a vanilla dialogue system (as expected), that controlling the model to generate in-character responses results in substantially more interesting output, and that conditioning on game state information qualitatively results in responses that are appropriate to the character class. Our preliminary experiments with using the large language models to perform game state tracking show low performance even after finetuning, suggesting that other models may be required for an AI to play D\&amp;D track the full state of the game.</p>
<p>Although our models are unable to play D\&amp;D fully autonomously by acting as the Dungeon Master, they could act as an aid for novice DMs. Since our models can generated evocative, in-character text that is appropriate for the context and the game state, DMs could use it as inspiration as they narrate the adventure to the other players.</p>
<p>Here is some model output to inspire your next adventure:</p>
<p>You get a much closer look than the other two... the sarcophagi have the inscriptions of some sort of magic, probably to keep the dead inside, but you can not read them to save your life.</p>
<p>What will you do next? Download our dataset ${ }^{5}$ to start your new adventure!</p>
<h2>9 Limitations</h2>
<p>One limitation of our human evaluation is that it is a static evaluation. The raters are simply reading the outputs of the model, and there is no interactive evaluation wherein they engage in gameplay with the system. An interactive user-study would be required before any claims could be made about how well AI is able to play D\&amp;D alongside human players.</p>
<p>Because our state information was created heuristically, it therefore potentially contains errors. It is also incomplete. There are several kinds of state tracking variables that would be useful to include, but were not possible to heuristically extract from our data. To address this problem in the future, we have begun a collaboration with the developer of Avrae, which is a Discord bot for playing</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>D\&amp;D online. Avrae contains many state variables that are missing from our current annotations, such as HIT points and slot-filler values for attacks.</p>
<h2>10 Acknowledgments</h2>
<p>We would like to thank Antony Pegg of Fandom for granting us permission to use D\&amp;D Beyond's forum data for research purposes.</p>
<p>Thank you to Rich Burlew and forum moderator truemane for granting us permission to crawl the Giant in the Playground forum and to build models using the forum posts.</p>
<p>We would like to thank the many Google Researchers who gave valuable input on this project, especially Dipanjan Das and Suma Bailis.</p>
<p>Chris Callison-Burch is grateful for having the opportunity to be a part-time visiting researcher at Google for two years. It was amazing to spend time among such incredibly smart people, and it was eye opening to see large LMs before they became widely available. Thanks!</p>
<h2>References</h2>
<p>Daniel Adiwardana, Minh-Thang Luong, David R So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu Quoc, and V Le. 2020. Towards a Human-like OpenDomain Chatbot. arXiv preprint arXiv:2001.09977.</p>
<p>Nader Akoury, Shufan Wang, Josh Whiting, Stephen Hood, Nanyun Peng, and Mohit Iyyer. 2020. STORIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6470-6484, Online. Association for Computational Linguistics.</p>
<p>Prithviraj Ammanabrolu, William Broniec, Alex Mueller, Jeremy Paul, and Mark O. Riedl. 2020a. Toward Automated Quest Generation in TextAdventure Games. In International Conference on Computational Creativity (ICCC).</p>
<p>Prithviraj Ammanabrolu, Jack Urbanek, Margaret Li, Arthur Szlam, Tim Rocktäschel, and Jason Weston. 2020b. How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and Act in Fantasy Worlds. In The North American Chapter of the Association for Computational Linguistics (NAACLHLT).</p>
<p>Boyd Branch, Piotr Mirowski, and Kory Mathewson. 2021. Collaborative Storytelling with Human Actors and AI Narrators. In International Conference on Computational Creativity (ICCC), pages 97-101.</p>
<p>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901.</p>
<p>Sahith Dambekodi, Spencer Frazier, Prithviraj Ammanabrolu, and Mark O Riedl. 2020. Playing TextBased Games with Common Sense. In Wordplay: When Language Meets Games Workshop (NeurIPS 2020).</p>
<p>Simon Ellis and James Hendler. 2017. Computers Play Chess, Computers Play Go...Humans Play Dungeons \&amp; Dragons. IEEE Intelligent Systems, 32(4):31-34.</p>
<p>Angela Fan, Mike Lewis, and Yann Dauphin. 2018. Hierarchical Neural Story Generation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pages 889-898.</p>
<p>Angela Fan, Jack Urbanek, Pratik Ringshia, Emily Dinan, Emma Qian, Siddharth Karamcheti, Shrimai Prabhumoye, Douwe Kiela, Tim Rocktäschel, Arthur Szlam, and Jason Weston. 2020. Generating Interactive Worlds with Text. In AAAI Conference on Artificial Intelligence (AAAI), pages 1693-1700.</p>
<p>Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson Liu, Matthew Peters, Michael Schmitz, and Luke Zettlemoyer. 2018. AllenNLP: A deep semantic natural language processing platform. arXiv preprint arXiv:1803.07640.</p>
<p>Sarik Ghazarian, Zixi Liu, Tuhin Chakrabarty, Xuezhe Ma, Aram Galstyan, and Nanyun Peng. 2021. DiSCoL: Toward Engaging Dialogue Systems through Conversational Line Guided Response Generation. arXiv preprint arXiv:2102.02191.</p>
<p>Matan Haroush, Tom Zahavy, Daniel J. Mankowitz, and Shie Mannor. 2018. Learning How Not to Act in Text-Based Games. In Workshop Track at ICLR 2018, pages 1-4.</p>
<p>Chenglong Hou, Chensong Zhou, Kun Zhou, Jinan Sun, and Sisi Xuanyuan. 2019. A survey of deep learning applied to story generation. In Smart Computing and Communication, pages 1-10. Springer International Publishing.</p>
<p>Jeremy Howard and Sebastian Ruder. 2018. Universal language model fine-tuning for text classification. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 328-339, Melbourne, Australia. Association for Computational Linguistics.</p>
<p>Daphne Ippolito, David Grangier, Chris CallisonBurch, and Douglas Eck. 2019. Unsupervised Hierarchical Story Infilling. In Proceedings of the First Workshop on Narrative Understanding, pages 3743.</p>
<p>Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, and Richard Socher. 2019. CTRL: A Conditional Transformer Language Model for Controllable Generation. arXiv preprint arXiv:1909.05858.</p>
<p>Jiwei Li, Will Monroe, Alan Ritter, and Dan Jurafsky. 2016. Deep Reinforcement Learning for Dialogue Generation. In Conference on Empirical Methods in Natural Language Processing, pages 1192-1202.</p>
<p>Annie Louis and Charles Sutton. 2018. Deep Dungeons and Dragons: Learning Character-Action Interactions from Role-Playing Game Transcripts. In Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), pages 708713.</p>
<p>Lara J. Martin, Prithviraj Ammanabrolu, Xinyu Wang, William Hancock, Shruti Singh, Brent Harrison, and Mark O. Riedl. 2018a. Event Representations for Automated Story Generation with Deep Neural Nets. In Thirty-Second AAAI Conference on Artificial Intelligence, pages 868-875, New Orleans, Louisiana.</p>
<p>Lara J. Martin, Srijan Sood, and Mark O. Riedl. 2018b. Dungeons and DQNs: Toward Reinforcement Learning Agents that Play Tabletop Roleplaying Games. In Joint Workshop on Intelligent Narrative Technologies and Workshop on Intelligent Cinematography and Editing (INT-WICED), Edmonton, AB, Canada.</p>
<p>Kory W. Mathewson, Pablo Samuel Castro, Colin Cherry, George Foster, and Marc G. Bellemare. 2019. Shaping the Narrative Arc: An InformationTheoretic Approach to Collaborative Dialogue. arXiv preprint arXiv:1901.11528, page 20.</p>
<p>Johannes E. M. Mosig, Vladimir Vlasov, and Alan Nichol. 2020. Where is the context? - A critique of recent dialogue datasets. CoRR, abs/2004.10473.</p>
<p>Xiangyu Peng, Siyan Li, Sarah Wiegreffe, and Mark Riedl. 2021. Inferring the Reader: Guiding Automated Story Generation with Commonsense Reasoning. In Workshop on Narrative Understanding at NAACL-HLT 2021.</p>
<p>Shrimai Prabhumoye, Khyathi Raghavi Chandu, Ruslan Salakhutdinov, and Alan W Black. 2019. "My Way of Telling a Story": Persona based Grounded Story Generation. In Storytelling Workshop at ACL 2019, pages 11-21.</p>
<p>Revanth Rameshkumar and Peter Bailey. 2020. Storytelling with Dialogue: A Critical Role Dungeons and Dragons Dataset. In Annual Meeting of the Association for Computational Linguistics (ACL), pages $5121-5134$.</p>
<p>Hannah Rashkin, Asli Celikyilmaz, Yejin Choi, and Jianfeng Gao. 2020. PlotMachines: OutlineConditioned Generation with Dynamic Plot State Tracking. In Conference on Empirical Methods in Natural Language Processing (EMNLP), pages $4274-4295$.</p>
<p>Melissa Roemmele. 2018. Neural Networks for Narrative Continuation. Ph.D. thesis, University of Southern California.</p>
<p>Abdelrhman Saleh, Natasha Jaques, Asma Ghandeharioun, Judy Hanwen Shen, and Rosalind Picard. 2020. Hierarchical Reinforcement Learning for Open-Domain Dialog. In AAAI Conference on Artificial Intelligence (AAAI), pages 8741-8748.</p>
<p>Abigail See, Aneesh Pappu, Rohun Saxena, Akhila Yerukola, and Christopher D. Manning. 2019. Do Massively Pretrained Language Models Make Better Storytellers? In Conference on Computational Natural Language Learning (CoNLL), pages 843-861.</p>
<p>Iulian Vlad Serban, Ryan Lowe, Laurent Charlin, and Joelle Pineau. 2016. Generative Deep Neural Networks for Dialogue: A Short Review. In Conference on Neural Information Processing Systems (NeurIPS), Workshop on Learning Methods for Dialogue, pages 1-6.</p>
<p>Eric Michael Smith, Diana Gonzalez-Rico, Emily Dinan, and Y-Lan Boureau. 2020. Controlling Style in Generated Dialogue. arXiv preprint arXiv:2009.10855.</p>
<p>Pradyumna Tambwekar, Murtaza Dhuliawala, Lara J. Martin, Animesh Mehta, Brent Harrison, and Mark O. Riedl. 2019. Controllable Neural Story Plot Generation via Reinforcement Learning. In International Joint Conference on Artificial Intelligence (IJCAI), Macau, China.</p>
<p>Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Kathleen S. Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed H. Chi, and Quoc Le. 2022. LaMDA: Language Models for Dialog Applications. CoRR, abs/2201.08239.</p>
<p>Jack Urbanek, Angela Fan, Siddharth Karamcheti, Saachi Jain, Samuel Humeau, Emily Dinan, Tim Rocktäschel, Douwe Kiela, Arthur Szlam, and Jason Weston. 2019. Learning to Speak and Act in a Fantasy Text Adventure Game. In Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages</p>
<p>673-683, Hong Kong, China. Association for Computational Linguistics.</p>
<p>Nick Walton. 2019. AI Dungeon.
Lili Yao, Nanyun Peng, Ralph Weischedel, Kevin Knight, Dongyan Zhao, and Rui Yan. 2019. Plan-And-Write: Towards Better Automatic Storytelling. In AAAI Conference on Artificial Intelligence (AAAI), volume 33(01), pages 7378-7385.</p>
<p>Shunyu Yao, Rohan Rao, Matthew Hausknecht, and Karthik Narasimhan. 2020. Keep CALM and Explore: Language Models for Action Generation in Text-based Games. In Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8736-8754.</p>
<p>Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. 2018. Personalizing Dialogue Agents: I have a dog, do you have pets too? In Annual Meeting of the Association for Computational Linguistics (ACL), pages 22042213, Melbourne, Australia.</p>
<p>Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, and Bill Dolan. 2019. DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation. arXiv preprint arXiv:1911.00536.</p>
<h2>A Example D\&amp;D Game Session</h2>
<p>Instead of the game being a series of moves on a game board, RPGs D\&amp;D are language-based. Players create characters that have a class (wizard, fighter, thief, etc.) that denotes their abilities, and a fantasy race (elf, dwarf, human, etc.). Players describe what they want their character to do and roll dice to determine if they are successful. The dungeon master (DM) acts as the narrator who shapes the overall story. The DM describes scenarios and locations, and takes on the role of non-player characters (NPCs), and monsters.</p>
<p>A common element to the game play is an encounter with monsters. Battles are governed by rules, and unfold in a turn-based fashion where the DM controls the monsters and each player controls their character. Each player and monster has a health meter (called their HIT points), an armor class (which indicates the threshold of the dice roll needed to damage them), and a set of possible attack or move actions.</p>
<p>Table 8 provides example dialogue from a game of D\&amp;D being played between 3 players - Travis (playing a human fighter named Magnus Burnsides), Clint (playing Merle Highchurch, a dwarf
cleric), Justin (playing Taako an elf wizard), and DM Griffin. We add comments about each dialogue turn to describe what is happening in the game, and to highlight the challenges that would need to be addressed if an AI system were to play the game either as a player or as the DM.</p>
<p>The game session is taken from the podcast The Adventure Zone. In this episode, the hosts are playing an adventure module called Lost Mine of Phadelver, an expert of which is given in Appendix B. In the first episode of the podcast ${ }^{6}$, the hosts explain the rules of D\&amp;D .</p>
<h2>B Lost Mine of Phadelver Adventure</h2>
<p>Here is an excerpt from the adventure book that the Dungeon Master was using in our example game play. The adventure book provides boxed text, which is descriptive text to be read aloud verbatim or to paraphrase. It also gives details about the combat that is about to ensure, and links to relevant game rules (like stealth checks, and statistics about the monsters that the characters will be in combat with).</p>
<p>The adventure begins as the player characters are escorting a wagon full of provisions and supplies from Neverwinter to Phandalin. The journey takes them south along the High Road to the Triboar Trail, which heads east (as shown on the overland map). When they're a half-day's march from Phandalin, they run into trouble with goblin raiders from the Cragmaw tribe.</p>
<p>Read the boxed text when you're ready to start. If you create a different adventure hook, skip to the second paragraph and adjust the details as necessary, ignoring the information about driving the wagon.</p>
<p>In the city of Neverwinter, a dwarf named Gundren Rockseeker asked you to bring a wagonload of provisions to the rough-and-tumble settlement of Phandalin, a couple of days' travel southeast of the city. Gundren was clearly excited and more than a little secretive about his reasons for the trip, saying only that he and his brothers had found "something big," and that he'd pay you ten gold pieces each for escorting his supplies safely to Barthen's Provisions, a trading post in Phandalin. He then set out ahead of you on horse, along with a warrior escort named Sildar Hallwinter, claiming he needed to arrive early to "take care of business."</p>
<p>You've spent the last few days following the High Road south from Neverwinter, and you've just recently veered east along the Triboar Trail. You've encountered no trouble so far, but this territory can be dangerous. Bandits and outlaws have been known to lurk along the trail.</p>
<p>You've been on the Triboar Trail for about half a day. As you come around a bend, you spot two</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Player <br> (character)</th>
<th style="text-align: center;">Game Dialogue</th>
<th style="text-align: center;">D\&amp;D Game Description and AI challenges</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Griffin (DM)</td>
<td style="text-align: center;">A dwarf named Gundren Rockseeker has hired you to transport a wagonload of provisions to the rough-and-tumble settlement of Phandalin, which is a couple days' travel to the southeast. A day and a half after leaving, you turn off the high road that connects the major cities on the coast onto a smaller trail that will lead you to Phandalin. This trail is not as well maintained, and bandits and outlaws have been known to lurk along the trail.</td>
<td style="text-align: center;">This game is based on the D\&amp;D starter adventure called "Lost Mine of Phadelver". The adventure book is a mixture of rules and "boxed text" which is descriptive text for the DM to read aloud or paraphrase. See the appendix for the text that the DM is consulting. AI challenges: Generation of stories and descriptive text</td>
</tr>
<tr>
<td style="text-align: center;">Griffin (DM)</td>
<td style="text-align: center;">Roll a perception check for me. Perception is a wisdom skill, so be sure to add your wisdom modifier.</td>
<td style="text-align: center;">The previous text was descriptive text. Here the DM is asking the players to perform a game mechanic and referencing a game rule. This is called "out of character" dialogue. AI challenges: Knowledge base population (extraction of rules from a rulebook)</td>
</tr>
<tr>
<td style="text-align: center;">Clint (out of character)</td>
<td style="text-align: center;">I got an eight.</td>
<td style="text-align: center;">Clint has rolled his dice. The number is low so his character fails the check. AI challenges: Multi-party dialogue</td>
</tr>
<tr>
<td style="text-align: center;">Justin (out of character)</td>
<td style="text-align: center;">I got a six.</td>
<td style="text-align: center;">Justin also fails. Neither character sees the thing that requires the perception check.</td>
</tr>
<tr>
<td style="text-align: center;">Travis (out of character)</td>
<td style="text-align: center;">I rolled a natural twenty plus my wisdom modifier is 23 .</td>
<td style="text-align: center;">Travis rolls high number and succeeds on the check. AI challenges: Understanding rules, determining success or failure</td>
</tr>
<tr>
<td style="text-align: center;">Griffin (DM)</td>
<td style="text-align: center;">With his eagle eyes, Magnus spots two dead horses lying in the middle of the road about 200 feet ahead of you.</td>
<td style="text-align: center;">The DM describes what happens as a result of the success. AI challenges: Reasoning about consequences of success or failure, descriptive text generation</td>
</tr>
<tr>
<td style="text-align: center;">Travis <br> (in-character as <br> Magnus)</td>
<td style="text-align: center;">I stop the wagon and motion silently to get the attention of Merle and Taako, and kinda pull them up towards the front of the wagon.</td>
<td style="text-align: center;">Travis is describing what he is doing using "in character" language. AI challenges: Personabased chat</td>
</tr>
<tr>
<td style="text-align: center;">Griffin (DM)</td>
<td style="text-align: center;">As you warn them that shit has gone south, you notice a few goblins crouching in a part of the shaded woods off to the side of the road. Two of the goblins begin charging your wagon.</td>
<td style="text-align: center;">The DM describes the start of a battle with several monsters. AI challenges: State tracking (in combat v. out of combat).</td>
</tr>
<tr>
<td style="text-align: center;">Travis (out of character)</td>
<td style="text-align: center;">How many goblins are there?</td>
<td style="text-align: center;">AI challenges: Question answering, state tracking (how many monsters).</td>
</tr>
<tr>
<td style="text-align: center;">Griffin (DM)</td>
<td style="text-align: center;">There are three goblins; two of them are rushing the group, one is pretty heavily obscured by the brush, probably about 40 feet out, sort of between you and the dead horses laying in the middle of the road.</td>
<td style="text-align: center;">AI challenges: Question answering, Descriptive text generation from game state.</td>
</tr>
<tr>
<td style="text-align: center;">Clint (Merle)</td>
<td style="text-align: center;">I will cast sacred flame at the nearest one. If it fails a dexterity saving throw, it takes 6 points of damage.</td>
<td style="text-align: center;">Clint chooses an action based on what is allowed for his character class. He describes the rule that governs the spell in an out-of-character fashion. AI challenges: Intent detection (perform attack action against a particular goblin)</td>
</tr>
<tr>
<td style="text-align: center;">Griffin (DM)</td>
<td style="text-align: center;">You attack. You launch some fire onto the goblin closest to the wagon. And with that, he looks like he is on death's door. And the other goblin that you can see, the one that's not in the brush somewhere, just sort of stops in his tracks. What do you do next?</td>
<td style="text-align: center;">The DM rolls for the monster, updates the state of its health meter, and describes the result of Merle's attack. AI challenges: Reasoning about rules, state tracking (monster's HIT points), descriptive text generation.</td>
</tr>
</tbody>
</table>
<p>Table 8: Example dialogue from a game of $\mathrm{D} \&amp; \mathrm{D}$ with explanations of what is happening and comments on potential challenges for AI</p>
<p>dead horses sprawled about fifty feet ahead of you, blocking the path. Each has several blackfeathered arrows sticking out of it. The woods press close to the trail here, with a steep embankment and dense thickets on either side.</p>
<p>Four goblins are hiding in the woods, two on each side of the road. They wait until someone approaches the bodies and then attack.</p>
<p>This will likely be the first of many combat encounters in the adventure. Here are the steps you should follow to run it effectively:</p>
<ul>
<li>Review the goblin stat block. Since the goblins are hiding, you'll need their Stealth skill modifier: +6 .</li>
<li>Check to see who, if anyone, is surprised. The party can't surprise the goblins, but the goblins might surprise some or all of the characters. Make a Dexterity (Stealth) check for the goblins: roll one d20 for all of them, add their Stealth skill modifier (+6) to the roll, and compare the total to the characters' passive Wisdom (Perception) scores. A character whose score is lower than the goblins' check total is surprised and therefore can't do anything on his or her first turn in the combat (see "Surprise" in the Basic Rules).</li>
<li>Use the initiative rules in the Basic Rules to determine who acts first, second, third, and so on. Keep track of everyone's initiative count on a piece of paper.</li>
<li>When the time comes for the goblins to act, two of them rush forward and make melee attacks while two goblins stand 30 feet away from the party and make ranged attacks. The goblins' stat block contains the information you need to resolve these attacks. For more information on what the goblins can do on their turn, see chapter 9, "Combat," in the Basic Rules. When three goblins are defeated, the last goblin attempts to flee, heading for the goblin trail</li>
</ul>
<h2>C Estimated accuracy of predicted state variables</h2>
<p>In addition to the heuristics that we used to recover state variables for each turn in the game (described in Section 3.1), we used a CNN to fill in state values when our heuristics did not fire. Table 9 estimates gives an estimate of the CNN's performance on filling in the state variables where the rule-based heuristic did not extract a value. The CNN classifier only uses current post text as input (no additional context).</p>
<h2>D Annotation Guidelines and Annotation Interface</h2>
<h2>D. 1 Annotation task</h2>
<p>In this task, you will see part of a conversation between a few people playing D\&amp;D. The players and their characters are listed at the beginning of the conversation. The conversations that are shown as context are real conversations from players. Your job is to read the context and then rate different responses for a player/character given conversational context. Please note that the context you are
given represents only a part of the players' past conversations/interactions with one another during the game.</p>
<p>For each response, you would be asked the following questions.</p>
<ul>
<li>Does the response make sense?</li>
<li>Use your common sense here. Is the response completely reasonable in terms of the rules of D\&amp;D ?</li>
<li>The response "makes sense" if it is cohesive as a standalone statement, consistent with the rules of the game, and the elements/entities mentioned are plausible, given the prior context.</li>
<li>If anything seems off-not fluent, confusing, illogical, out of context, or wrong according to the rules of D\&amp;D -then rate it as Does not make sense. If in doubt, choose Does not make sense.</li>
<li>Is the response specific?</li>
<li>You may be asked to assess whether the response is specific to a given context. In other words, do you think that the response represents a good thing for the character to do now?</li>
<li>The response is "specific" if it flows logically from the narrative established by the prior context.</li>
<li>Note: It is possible for a response to "make sense" (due to being cohesive, consistent and plausible in and of itself), but be marked "not specific" when it is not a logical next step in the overall game progression.</li>
<li>Note: "Specific" for the purposes of this task does not have to do with how detailed the response is per se; a response can be fairly general in its language, but still qualify as "specific" when it is a logical next step in the overall game progression.</li>
<li>How interesting is the response?</li>
<li>You may be asked to score the response for its interestingness on a scale of 10 . Choose a high score for "Interesting" if the response would likely catch someone's attention or arouse curiosity in the game; or it is insightful, creative, or witty with respect to the game. If the response is monotonous and predictable, or if you're unsure, then it is Less Inter-</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: center;">State variable</th>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Type</th>
<th style="text-align: center;">Multi-valued</th>
<th style="text-align: center;">Availability</th>
<th style="text-align: center;">Evaluation metric</th>
<th style="text-align: center;">Performance</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Character</td>
<td style="text-align: center;">Span labeller</td>
<td style="text-align: center;">Text</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">$42 \%$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">Race</td>
<td style="text-align: center;">Classifier</td>
<td style="text-align: center;">Text</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">$&gt;58 \%$</td>
<td style="text-align: center;">Macro AUC</td>
<td style="text-align: center;">0.45</td>
</tr>
<tr>
<td style="text-align: center;">Class</td>
<td style="text-align: center;">Classifier</td>
<td style="text-align: center;">Text</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">$&gt;75 \%$</td>
<td style="text-align: center;">Macro AUC</td>
<td style="text-align: center;">0.71</td>
</tr>
<tr>
<td style="text-align: center;">Pronous</td>
<td style="text-align: center;">Classifier</td>
<td style="text-align: center;">Text</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">$42 \%$</td>
<td style="text-align: center;">Macro AUC</td>
<td style="text-align: center;">0.92</td>
</tr>
<tr>
<td style="text-align: center;">Inventory</td>
<td style="text-align: center;">Span labeller</td>
<td style="text-align: center;">Text</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">$11 \%$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">In combat?</td>
<td style="text-align: center;">Classifier</td>
<td style="text-align: center;">Score</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">$100 \%$</td>
<td style="text-align: center;">Accuracy</td>
<td style="text-align: center;">0.91</td>
</tr>
<tr>
<td style="text-align: center;">Action</td>
<td style="text-align: center;">Classifier</td>
<td style="text-align: center;">Text</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">$20 \%$</td>
<td style="text-align: center;">Macro AUC</td>
<td style="text-align: center;">0.92</td>
</tr>
</tbody>
</table>
<p>Table 9: The estimated performance of our CNN classifier on predicting state values for turns where our rule-based heuristics did not predict a value
esting.</p>
<h1>D. 2 Annotation Interface</h1>
<p>A mock up of the annotation user interface is given in Figure 3.</p>
<h2>D. 3 Survey of Raters</h2>
<p>We recruited raters who had a background in role playing games and an understanding of the fantasy genre. We surveyed our raters, asking them the following questions:</p>
<ol>
<li>Have you ever played Dungeons and Dragons or another role playing game before?</li>
<li>
<p>If so,</p>
</li>
<li>
<p>roughly how many times have you played</p>
</li>
<li>
<p>were you a player or a game master or both</p>
</li>
<li>
<p>If not,</p>
</li>
<li>
<p>what kind of exposure do you have to Dungeons and Dragons? (For example, have you seen it referred to in TV or movies)</p>
</li>
<li>
<p>Are you a fan of the fantasy genre (like Lord of the Rings)?</p>
</li>
</ol>
<p>Our 6 raters responded to the survey as follows: 5 out of the 6 have played D\&amp;D or another role playing game before. All 5 of those who have played D\&amp;D /other role playing games before have played more than 6 times. Of the 5 who have played D\&amp;D /other role playing games before, 3 played as both Game Master and Player. For the one who had not played D\&amp;D /other role playing games, they indicated they had not had much exposure to D\&amp;D through TV or other channels. All 6 answered that they were fans of the fantasy genre.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Context</th>
<th style="text-align: center;">Player 10 - Del</th>
<th style="text-align: center;">Ratings</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Player 10 - Del (Barbarian) <br> Player 0 - Dungeon Master <br> Player 12 - Aramis (Bard) <br> Player 8 - Xavier (Bard)</td>
<td style="text-align: center;">Response 1 <br> Del quickly searches the store room, <br> grabbing whatever weapons he find useful. <br> He then heads back to the others "I found <br> another crossbow and arrows, and a <br> dagger. I have a short bow, but l'll leave it <br> here if someone else wants it. I also found <br> one of my javelins that I was missing."</td>
<td style="text-align: center;">Does this response make sense? <br> $\square$ Makes sense <br> Does not make sense <br> Is this response specific to the given context? <br> $\square$ Specific <br> $\square$ Not specific <br> How interesting is this response on a scale of 10 ?</td>
</tr>
<tr>
<td style="text-align: center;">Player 10 - Del (Barbarian): Del gives a final kick to the dead orc that he just killed then proceeds to hunt through the main room then the store room, looking for his axe and other gear</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Player 0 - Dungeon Master : Del - make an investigation check.</td>
<td style="text-align: center;">Response 2 <br> del takes the crowbar and tells xavier to <br> find hes "***en axe and ill keep good care <br> of him</td>
<td style="text-align: center;">Does this response make sense? <br> $\square$ Makes sense <br> Does not make sense <br> Is this response specific to the given context? <br> $\square$ Specific <br> $\square$ Not specific <br> How interesting is this response on a scale of 10 ?</td>
</tr>
<tr>
<td style="text-align: center;">Player 10 - Del (Barbarian): 3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Player 0 - Dungeon Master : The barbarian begins tossing things around, overturning tables and tearing crates and sacks open, though his still simmering rage at being locked up prevents him from undertaking a thorough search. He turns up a shortbow, a light crossbow, a few javelins, 2 quivers of arrows, 2 cases of crossbow bolts, a crate full of mismatched leather armour and a few sacks full of preveserved fruit and vegetables. There is no sign of the equipment that was taken from him last night.</td>
<td style="text-align: center;">Response 3 <br> Anyone see my axe, and leather?</td>
<td style="text-align: center;">Does this response make sense? <br> $\square$ Makes sense <br> Does not make sense <br> Is this response specific to the given context? <br> $\square$ Specific <br> $\square$ Not specific <br> How interesting is this response on a scale of 10 ?</td>
</tr>
<tr>
<td style="text-align: center;">Player 12 - Aramis (Bard) : ""anyone seen any keys? or my stuff?"* aramis calls out to everyone</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Player 8 - Xavier (Bard) : "quickly picking up the dead orcs cleaver so a better weapon Xavier turns to the rest of the party" ""fighting is not over, we are not sure whats to be found up there, raid the store room, we must be ready for more combat"" "I turn to del" ""would you stand with me to defend the rest while they re-erm?"""I offer the crowbar to del" "then turn back to the party" ""and if you find a shield and sword in there, i require a stronger defence and fiel""</td>
<td style="text-align: center;">Response 4 <br> Noticing Del is searching the same room. Del calls out to him "X, I just killed an orc you could use its stuff if you like."</td>
<td style="text-align: center;">Does this response make sense? <br> $\square$ Makes sense <br> Does not make sense <br> Is this response specific to the given context? <br> $\square$ Specific <br> $\square$ Not specific <br> How interesting is this response on a scale of 10 ?</td>
</tr>
</tbody>
</table>
<p>Figure 3: The user interface that our raters used to evaluate the quality of our model's next utterance prediction.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{6}$ https://maximumfun.org/
episodes/adventure-zone/
ep-1-here-there-be-gerblins-chapter-one/&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>