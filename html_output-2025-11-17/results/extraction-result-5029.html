<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5029 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5029</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5029</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-106.html">extraction-schema-106</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <p><strong>Paper ID:</strong> paper-4df7bbe3ca7806f39a490c99f17867a0ac299bc3</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/4df7bbe3ca7806f39a490c99f17867a0ac299bc3" target="_blank">Learning Explanatory Rules from Noisy Data</a></p>
                <p><strong>Paper Venue:</strong> Journal of Artificial Intelligence Research</p>
                <p><strong>Paper TL;DR:</strong> A Differentiable Inductive Logic framework (∂ILP) is proposed, which can not only solve tasks which traditional ILP systems are suited for, but shows a robustness to noise and error in the training data which ILP cannot cope with.</p>
                <p><strong>Paper Abstract:</strong> Artificial Neural Networks are powerful function

approximators capable of modelling solutions to

a wide variety of problems, both supervised and

unsupervised. As their size and expressivity increases,

so too does the variance of the model,

yielding a nearly ubiquitous overfitting problem.

Although mitigated by a variety of model regularisation

methods, the common cure is to seek

large amounts of training data—which is not necessarily

easily obtained—that sufficiently approximates

the data distribution of the domain we wish

to test on. In contrast, logic programming methods

such as Inductive Logic Programming offer an extremely

data-efficient process by which models can

be trained to reason on symbolic domains. However,

these methods are unable to deal with the variety

of domains neural networks can be applied to:

they are not robust to noise in or mislabelling of inputs,

and perhaps more importantly, cannot be applied

to non-symbolic domains where the data is

ambiguous, such as operating on raw pixels. In this

paper, we propose a Differentiable Inductive Logic

framework (∂ILP), which can not only solve tasks

which traditional ILP systems are suited for, but

shows a robustness to noise and error in the training

data which ILP cannot cope with. Furthermore,

as it is trained by backpropagation against a likelihood

objective, it can be hybridised by connecting

it with neural networks over ambiguous data in

order to be applied to domains which ILP cannot

address, while providing data efficiency and generalisation

beyond what neural networks on their own

can achieve.</p>
                <p><strong>Cost:</strong> 0.006</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5029",
    "paper_id": "paper-4df7bbe3ca7806f39a490c99f17867a0ac299bc3",
    "extraction_schema_id": "extraction-schema-106",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.005608999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Learning Explanatory Rules from Noisy Data</h1>
<p>Richard Evans<br>Edward Grefenstette<br>DeepMind, London, UK</p>
<p>RICHARDEVANS@GOOGLE.COM
ETG@GOOGLE.COM</p>
<h4>Abstract</h4>
<p>Artificial Neural Networks are powerful function approximators capable of modelling solutions to a wide variety of problems, both supervised and unsupervised. As their size and expressivity increases, so too does the variance of the model, yielding a nearly ubiquitous overfitting problem. Although mitigated by a variety of model regularisation methods, the common cure is to seek large amounts of training data-which is not necessarily easily obtained - that sufficiently approximates the data distribution of the domain we wish to test on. In contrast, logic programming methods such as Inductive Logic Programming offer an extremely data-efficient process by which models can be trained to reason on symbolic domains. However, these methods are unable to deal with the variety of domains neural networks can be applied to: they are not robust to noise in or mislabelling of inputs, and perhaps more importantly, cannot be applied to non-symbolic domains where the data is ambiguous, such as operating on raw pixels. In this paper, we propose a Differentiable Inductive Logic framework, which can not only solve tasks which traditional ILP systems are suited for, but shows a robustness to noise and error in the training data which ILP cannot cope with. Furthermore, as it is trained by backpropagation against a likelihood objective, it can be hybridised by connecting it with neural networks over ambiguous data in order to be applied to domains which ILP cannot address, while providing data efficiency and generalisation beyond what neural networks on their own can achieve.</p>
<h2>1. Introduction</h2>
<p>Inductive Logic Programming (ILP) is a collection of techniques for constructing logic programs from examples. Given a set of positive examples, and a set of negative examples, an ILP system constructs a logic program that entails all the positive examples but does not entail any of the negative examples. From a machine learning perspective, an ILP system can be interpreted as implementing a rule-based binary classifier over examples, mapping each example to an evaluation of its truth or falsehood according to the axioms provided to the system, alongside new rules inferred by the system during training.</p>
<p>ILP has a number of appealing features. First, the learned program is an explicit symbolic structure that can be inspected, understood ${ }^{1}$, and verified. Second, ILP systems tend to be impressively data-efficient, able to generalise well from a small handful of examples. The reason for this data-efficiency is that ILP imposes a strong language bias on the sorts of programs that can be learned: a short general program will be preferred to a program consisting of a large number of special-case ad-hoc rules that happen to cover the training</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>data. Third, ILP systems support continual and transfer learning. The program learned in one training session, being declarative and free of side-effects, can be copied and pasted into the knowledge base before the next training session, providing an economical way of storing learned knowledge.</p>
<p>The main disadvantage of traditional ILP systems is their inability to handle noisy, erroneous, or ambiguous data. If the positive or negative examples contain any mislabelled data, these systems will not be able to learn the intended rule. De Raedt and Kersting (2008) discuss this issue in depth, stressing the importance of building systems capable of applying relational learning to uncertain data.</p>
<p>A key strength of neural networks is that they are robust to noise and ambiguity. One way to overcome the brittleness of traditional ILP systems is to reimplement them in a robust connectionist framework. Garcez, Besold, de Raedt, Földiak, Hitzler, Icard, Kühnberger, Lamb, Miikkulainen, and Silver (2015) argue strongly for the importance of integrating robust connectionist learning with symbolic relational learning.</p>
<p>Recently, a different approach to program induction has emerged from the deep learning community (Graves, Wayne, \&amp; Danihelka, 2014; Reed \&amp; de Freitas, 2015; Neelakantan, Le, \&amp; Sutskever, 2015; Kaiser, 2015; Andrychowicz \&amp; Kurach, 2016; Graves, Wayne, Reynolds, Harley, Danihelka, Grabska-Barwińska, Colmenarejo, Grefenstette, Ramalho, Agapiou, et al., 2016). These neural network-based systems do not construct an explicit symbolic representation of a program. Instead, they learn an implicit procedure (distributed in the weights of the net) that produces the intended results. These approaches take a relatively low-level model of computation ${ }^{2}$ - a model that is much "closer to the metal" than the Horn clauses used in ILP-and produce a differentiable implementation of that low-level model. The implicit procedure that is learned is a way of operating within that low-level model of computation (by moving the tape head, reading and writing in the case of differentiable Turing machines; by pushing and popping in the case of differentiable pushdown automata).</p>
<p>There are two appealing features of this differentiable approach to program induction. First, these systems are robust to noise. Unlike ILP, a neural system will tolerate some bad (mis-labeled) data. Second, a neural program induction system can be provided with fuzzy or ambiguous data (from a camera, for example). Unlike traditional ILP systems (which have to be fed crisp, symbolic input), a differentiable induction system can start with raw, un-preprocessed pixel input.</p>
<p>However, the neural approaches to program induction have two disadvantages when compared to ILP. First, the implicit procedure learned by a neural network is not inspectable or human-readable. It is notoriously hard to understand what it has learned, or to what extent it has generalised beyond the training data. Second, the performance of these systems tails off sharply when the test data are significantly larger than the training data: if we train the neural system to add numbers of length 10 , they may also be successful when tested on numbers of length 20. But if we test them on numbers of length 100, the performance deteriorates (Kaiser, 2015; Reed \&amp; de Freitas, 2015). General-purpose neural architectures,</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>being universal function approximators, produce solutions with high variance. There is an ever-present danger of over-fitting ${ }^{3}$.</p>
<p>This paper proposes a system that addresses the limits of connectionist systems and ILP systems, and attempts to combine the strengths of both. Differentiable Inductive Logic Programming ( $\partial \mathrm{ILP}$ ) is a reimplementation of ILP in an an end-to-end differentiable architecture. It attempts to combine the advantages of ILP with the advantages of the neural network-based systems: a data-efficient induction system that can learn explicit human-readable symbolic rules, that is robust to noisy and ambiguous data, and that does not deteriorate when applied to unseen test data. The central component of this system is a differentiable implementation of deduction through forward chaining on definite clauses. We reinterpret the ILP task as a binary classification problem, and we minimise cross-entropy loss with regard to ground-truth boolean labels during training.</p>
<p>Our $\partial_{\text {ILP }}$ system is able to solve moderately complex tasks requiring recursion and predicate invention. For example, it is able to learn "Fizz-Buzz" using multiple invented predicates (see Section 5.3.3). Unlike the MLP described by Grus ${ }^{4}$, our learned program generalises robustly to test data outside the range of training examples.</p>
<p>Unlike symbolic ILP systems, $\partial_{\text {ILP }}$ is robust to mislabelled data. It is able to achieve reasonable performance with up to $20 \%$ of mislabelled training data (see Section 5.4). Unlike symbolic ILP systems, $\partial_{\text {ILP }}$ is also able to handle ambiguous or fuzzy data. We tested $\partial_{\text {ILP }}$ by connecting it to a convolutional net trained on MNIST digits, and it was still able to learn effectively (see Section 5.5).</p>
<p>The major limitation of our $\partial_{\text {ILP }}$ system is that it requires significant memory resources. This limits the range of benchmark problems on which our system has been tested ${ }^{5}$. We discuss this further in the introduction to Section 5.3 and in Section 5.3.4, and offer an analysis in Appendix E.</p>
<p>The structure of the paper is as follows. We begin, in Section 2, by giving an overview of logic programming as a field, and of the collection of learning methods known as Inductive Logic Programming. In Section 3, we re-cast learning under ILP as a satisfiability problem, and use this formalisation of the problem as the basis for introducing, in Section 4, a differentiable form of ILP where continuous representations of rules are learned through backpropagation against a likelihood objective. In Section 5, we evaluate our system against a variety of standard ILP tasks, we measure its robustness to noise by evaluating its performance under conditions where consistent errors exist in the data, and finally compare it to neural network baselines in tasks where logic programs are learned over ambiguous data such as raw pixels. We complete the paper by reviewing and contrasting with related work in Section 6 before offering our conclusions regarding the framework proposed here and its empirical validation.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>2. Background</h1>
<p>We first review Logic Programming and Inductive Logic Programming (ILP), before focusing on one particular approach to ILP, which turns the induction problem into a satisfiability problem.</p>
<h3>2.1 Logic Programming</h3>
<p>Logic programming is a family of programming languages in which the central component is not a command, or a function, but an if-then rule. These rules are also known as clauses.</p>
<p>A definite clause ${ }^{6}$ is a rule of the form</p>
<p>$$
\alpha \leftarrow \alpha_{1}, \ldots, \alpha_{m}
$$</p>
<p>composed of a head atom $\alpha$, and a body $\alpha_{1}, \ldots, \alpha_{m}$, where $m \geq 0$. These rules are read from right to left: if all of the atoms on the right are true, then the atom on the left is also true. If the body is empty, if $m=0$, we abbreviate $\alpha \leftarrow$ to just $\alpha$.</p>
<p>An atom $\alpha$ is a tuple $p\left(t_{1}, \ldots, t_{n}\right)$, where $p$ is a $n$-ary predicate and $t_{1}, \ldots, t_{n}$ are terms, either variables or constants. An atom is ground if it contains no variables. The set of all atoms, ground and unground, is denoted by $\mathcal{A}$. The set of ground atoms, also known as the Herbrand base, is $\mathcal{G}$.</p>
<p>In first-order logic, terms can also be constructed from function symbols. So, for example, if $c$ is a constant, and $f$ is a one place function, then $f(c), f(f(c)), f(f(f(c))), \ldots$ are all terms. In this paper, we impose the following restriction, found in systems like Datalog, on clauses: the only terms allowed are constants and variables, while function symbols are disallowed ${ }^{7}$.</p>
<p>For example, the following program defines the connected relation as the transitive closure of the edge relation:</p>
<p>$$
\begin{aligned}
\operatorname{connected}(X, Y) &amp; \leftarrow \operatorname{edge}(X, Y) \
\operatorname{connected}(X, Y) &amp; \leftarrow \operatorname{edge}(X, Z), \operatorname{connected}(Z, Y)
\end{aligned}
$$</p>
<p>We follow the logic programming convention of using upper case to denote variables and lower case for constants and predicates.</p>
<p>A ground rule is a clause in which all variables have been substituted by constants. For example:</p>
<p>$$
\operatorname{connected}(a, b) \leftarrow \operatorname{edge}(a, b)
$$</p>
<p>is a ground rule generated by applying the substitution $\theta={a / X, b / Y}$ to the clause:</p>
<p>$$
\operatorname{connected}(X, Y) \leftarrow \operatorname{edge}(X, Y)
$$</p>
<p>The consequences of a set $R$ of clauses is computed by repeatedly applying the rules in $R$ until no more consequences can be derived. More formally, define $c n_{R}(X)$ as the</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>immediate consequences of rules $R$ applied to ground atoms $X$ :</p>
<p>$$
c n_{R}(X)=X \cup\left{\gamma \mid \gamma \leftarrow \gamma_{1}, \ldots, \gamma_{m} \in \operatorname{ground}(R), \bigwedge_{i=1}^{m} \gamma_{i} \in X\right}
$$</p>
<p>where $\operatorname{ground}(R)$ are the ground rules of $R$. In other words, ground atom $\gamma$ is in $c n_{R}(X)$ if $\gamma$ is in $X$ or there exists a ground rule $\gamma \leftarrow \gamma_{1}, \ldots, \gamma_{m} \in \operatorname{ground}(R)$ such that each ground atom $\gamma_{1}, \ldots, \gamma_{m}$ is in $X$.</p>
<p>Alternatively, we can define $c n_{R}(X)$ using substitutions:</p>
<p>$$
c n_{R}(X)=X \cup\left{\alpha[\theta] \mid \alpha \leftarrow \alpha_{1}, \ldots, \alpha_{m} \in R, \bigwedge_{i=1}^{m} \alpha_{i}[\theta] \in X\right}
$$</p>
<p>where $\alpha[\theta]$ is the application of substitution $\theta$ to atom $\alpha$.
Now define a series of consequences $C_{R, 0}, C_{R, 1}, C_{R, 2}, \ldots$</p>
<p>$$
C_{R, 0}={ } \quad C_{R, i+1}=c n_{R}\left(C_{R, i}\right)
$$</p>
<p>Now define the consequences after $T$ time-steps as the union of this series:</p>
<p>$$
\operatorname{con}(R)=\bigcup_{i \geq 0}^{T} C_{R, i}
$$</p>
<p>Consider, for example, the program $R$ :</p>
<p>$$
\begin{array}{ll}
\operatorname{edge}(a, b) &amp; \operatorname{connected}(X, Y) \leftarrow \operatorname{edge}(X, Y) \
\operatorname{edge}(b, c) &amp; \operatorname{connected}(X, Y) \leftarrow \operatorname{edge}(X, Z), \operatorname{connected}(Z, Y) \
\operatorname{edge}(c, a) &amp; \text { for } \
&amp;
\end{array}
$$</p>
<p>The consequences are:</p>
<p>$$
\begin{aligned}
&amp; C_{R, 1}={\operatorname{edge}(a, b), \operatorname{edge}(b, c), \operatorname{edge}(c, a)} \
&amp; C_{R, 2}=C_{R, 1} \cup{\operatorname{connected}(a, b), \operatorname{connected}(b, c), \operatorname{connected}(c, a)} \
&amp; C_{R, 3}=C_{R, 2} \cup{\operatorname{connected}(a, c), \operatorname{connected}(b, a), \operatorname{connected}(c, b)} \
&amp; C_{R, 4}=C_{R, 3} \cup{\operatorname{connected}(a, a), \operatorname{connected}(b, b), \operatorname{connected}(c, c)} \
&amp; C_{R, 5}=C_{R, 4}=\operatorname{con}(R)
\end{aligned}
$$</p>
<p>Given a set $R$ of clauses, and a ground atom $\gamma$, we say $R$ entails $\gamma$, written $R \models \gamma$, if every model satisfying $R$ also satisfies $\gamma$. To test if $R \models \gamma$, we check if $\gamma \in \operatorname{con}(R)$. This technique is called forward chaining.</p>
<p>An alternative approach is backward chaining. To test if $R \models \gamma$, we work backwards from $\gamma$, looking for rules in $R$ whose head unifies with $\gamma$. For each such rule $\alpha \leftarrow \alpha_{1}, \ldots, \alpha_{m}$, where $\alpha[\theta]=\gamma$, we create a sub-goal to prove the body $\alpha_{1}[\theta], \ldots, \alpha_{m}[\theta]$. This procedure constructs a search tree, where nodes are lists of propositions to be proved, in left-to-right order, and edges are applications of rules with substitutions. The root of the tree is the node containing $\gamma$, and search terminates when we find a node with no atoms remaining to be proved.</p>
<p>A distinction we will need later is the difference between intensional and extensional predicates. An extensional predicate is a predicate that is wholly defined by a set of ground atoms. In our example above, edge is an extensional predicate defined by the set of atoms:</p>
<p>$$
{\operatorname{edge}(a, b), \operatorname{edge}(b, c), \operatorname{edge}(c, a)}
$$</p>
<p>An intensional predicate is defined by a set of clauses. In our example, connected is an intensional predicate defined by the clauses:</p>
<p>$$
\begin{aligned}
\operatorname{connected}(X, Y) &amp; \leftarrow \operatorname{edge}(X, Y) \
\operatorname{connected}(X, Y) &amp; \leftarrow \operatorname{edge}(X, Z), \operatorname{connected}(Z, Y)
\end{aligned}
$$</p>
<h1>2.2 Inductive Logic Programming (ILP)</h1>
<p>An ILP problem is a tuple $(\mathcal{B}, \mathcal{P}, \mathcal{N})$ of ground atoms, where:</p>
<ul>
<li>$\mathcal{B}$ is a set of background assumptions, a set of ground atoms ${ }^{8}$.</li>
<li>$\mathcal{P}$ is a set of positive instances - examples taken from the extension of the target predicate to be learned</li>
<li>$\mathcal{N}$ is a set of negative instances - examples taken outside the extension of the target predicate</li>
</ul>
<p>Consider, for example, the task of learning which natural numbers are even. We are given a minimal description of the natural numbers:</p>
<p>$$
\mathcal{B}={z e r o(0), \operatorname{succ}(0,1), \operatorname{succ}(1,2), \operatorname{succ}(2,3), \ldots}
$$</p>
<p>Here, zero $(X)$ is the unary predicate true of $X$ if $X=0$, and succ is the successor relation. The positive and negative examples of the even predicate are:</p>
<p>$$
\begin{aligned}
\mathcal{P} &amp; ={\operatorname{even}(0), \operatorname{even}(2), \operatorname{even}(4), \operatorname{even}(6), \ldots} \
\mathcal{N} &amp; ={\operatorname{even}(1), \operatorname{even}(3), \operatorname{even}(5), \operatorname{even}(7), \ldots}
\end{aligned}
$$</p>
<p>The aim of ILP is to construct a logic program that explains the positive instances and rejects the negative instances.</p>
<p>Given an ILP problem $(\mathcal{B}, \mathcal{P}, \mathcal{N})$, a solution is a set $R$ of definite clauses such that ${ }^{9}$ :</p>
<ul>
<li>$\mathcal{B}, R \models \gamma$ for all $\gamma \in \mathcal{P}$</li>
<li>$\mathcal{B}, R \nVdash \gamma$ for all $\gamma \in \mathcal{N}$</li>
</ul>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Induction is finding a set of rules $R$ such that, when they are applied deductively to the background assumptions $\mathcal{B}$, they produce the desired conclusions. Namely: positive examples are entailed, while negative examples are not.</p>
<p>In the example above, one solution is the set $R$ :</p>
<p>$$
\begin{aligned}
\operatorname{even}(X) &amp; \leftarrow \operatorname{zero}(X) \
\operatorname{even}(X) &amp; \leftarrow \operatorname{even}(Y), \operatorname{succ} 2(Y, X) \
\operatorname{succ} 2(X, Y) &amp; \leftarrow \operatorname{succ}(X, Z), \operatorname{succ}(Z, Y)
\end{aligned}
$$</p>
<p>Note that this simple toy problem is not entirely trivial. The solution requires both recursion and predicate invention: an auxiliary synthesised predicate succ2.</p>
<p>We first describe how the ILP problem can be transformed into a satisfiability problem (Section 3), and then provide the main contribution of the paper: a differentiable implementation of the satisfiability solving process (Section 4).</p>
<h1>3. ILP as a Satisfiability Problem</h1>
<p>There are, broadly speaking, two families of approaches to ILP. The bottom-up approaches ${ }^{10}$ start by examining features of the examples, extract specific clauses from those examples, and then generalise from those specific clauses. The top-down approaches ${ }^{11}$ use generate-and-test: they generate clauses from a language definition, and test the generated programs against the positive and negative examples.</p>
<p>Amongst the top-down approaches, one particular method is to transform the problem of searching for clauses into a satisfiability problem. Amongst these induction-via-satisfiability approaches, some ${ }^{12}$ use the Boolean flags to indicate which branches of the search space (defined by the language grammar) to explore. Others ${ }^{13}$ generate a large set of clauses according to a program template, and use the Boolean flags to determine which clauses are on and off.</p>
<p>In this paper, we also take a top-down, generate-and-test approach, in which clauses are generated from a language template. We assign each generated clause a Boolean flag indicating whether it is on or off. Now the induction problem becomes a satisfiability problem: choose an assignment to the Boolean flags such that the turned-on clauses together with the background facts together entail the positive examples and do not entail the negative examples. Our approach is an extension to this established approach to ILP: our contribution is to provide, via a continuous relaxation of satisfiability, a differentiable implementation of this architecture. This allows us to apply gradient descent to learn which clauses to turn on and off, even in the presence of noisy or ambiguous data.</p>
<p>We use the rest of this section (together with Appendix B) to explain ILP-as-satisfiability in detail.</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>3.1 Basic Concepts</h1>
<p>A language frame $\mathcal{L}$ is a tuple</p>
<p>$$
\left(\text { target }, P_{e}, \text { arity }_{e}, C\right)
$$</p>
<p>where:</p>
<ul>
<li>target is the target predicate, the intensional predicate we are trying to learn</li>
<li>$P_{e}$ is a set of extensional predicates</li>
<li>arity $<em e="e">{e}$ is a map $P</em>$ specifying the arity of each predicate} \cup{$ target $} \rightarrow \mathbb{N</li>
<li>$C$ is a set of constants</li>
</ul>
<p>An ILP problem is a tuple $(\mathcal{L}, \mathcal{B}, \mathcal{P}, \mathcal{N})$ where</p>
<ul>
<li>$\mathcal{L}$ is a language frame</li>
<li>$\mathcal{B}$ is a set of background assumptions, ground atoms formed from the predicates in $P_{e}$ and the constants in $C$</li>
<li>$\mathcal{P}$ is a set of positive examples, ground atoms formed from the target predicate and the constants in $C$</li>
<li>$\mathcal{N}$ is a set of negative examples, ground atoms formed from the target predicate and the constants in $C$</li>
</ul>
<p>Here, $\mathcal{P}$ are ground atoms where the target predicate holds. For example, in the case of even on natural numbers, $\mathcal{P}$ might be ${$ even $(0)$, even $(2)$, even $(4)$, even $(6)}$. The set $\mathcal{N}$ contains ground atoms where the target predicate does not hold, e.g.. ${$ even $(1)$, even $(3)$, even $(5)}$.</p>
<p>A rule template $\tau$ describes a range of clauses that can be generated. It is a pair $(v, i n t)$ where:</p>
<ul>
<li>$v \in \mathbb{N}$ specifies the number of existentially quantified variables allowed in the clause</li>
<li>int $\in{0,1}$ specifies whether the atoms in the body of the clause can use intensional predicates (int $=1$ ) or only extensional predicates (int $=0$ )</li>
</ul>
<p>A program template $\Pi$ describes a range of programs that can be generated. It is a tuple $\left(P_{a}\right.$, arity $_{a}$, rules, $\left.T\right)$ where:</p>
<ul>
<li>$P_{a}$ is a set of auxiliary (intensional) predicates; these are the additional invented predicates used to help define the target predicate</li>
<li>arity $<em a="a">{a}$ is a map $P</em>$ specifying the arity of each auxiliary predicate} \rightarrow \mathbb{N</li>
<li>rules is a map from each intensional predicate $p$ to a pair of rule templates $\left(\tau_{p}^{1}, \tau_{p}^{2}\right)$</li>
<li>$T \in \mathbb{N}$ specifies the max number of steps of forward chaining inference</li>
</ul>
<p>Note that rules defines each intensional predicate by a pair of rule templates. In our system, we insist, without loss of generality ${ }^{14}$ that each predicate can be defined by exactly two clauses.</p>
<p>Our program template is a tuple of hyperparameters constraining the range of programs that are used to solve the ILP problem. This template plays the same role as a collection of mode declarations (see Appendix C) or a set of metarules in Metagol (see Appendix D).</p>
<p>Assume, for the moment, that the program template is given to us as part of the ILP problem specification. Later, in Section 7.1, we shall discuss how to search through the space of program templates using iterative deepening.</p>
<p>We can combine the extensional predicates from the language-frame</p>
<p>$$
\mathcal{L}=\left(\text { target }, P_{e}, \text { arity }_{e}, C\right)
$$</p>
<p>with the intensional predicates from the program template</p>
<p>$$
\Pi=\left(P_{a}, \text { arity }_{a}, \text { rules }, T\right)
$$</p>
<p>into a language $\left(P_{e}, P_{i}\right.$, arity,$\left.C\right)$ where</p>
<ul>
<li>$P_{i}=P_{a} \cup{$ target $}$</li>
<li>arity $=$ arity $<em a="a">{e} \cup$ arity $</em>$</li>
</ul>
<p>Note that the target predicate is always one of the intensional predicates $P_{i}$.
Let $P$ be the complete set of predicates:</p>
<p>$$
P=P_{e} \cup P_{i}
$$</p>
<p>A language determines the set $G$ of all ground atoms. If we restrict ourselves to nullary, unary, and dyadic predicates, then the set of ground atoms is:</p>
<p>$$
\begin{aligned}
G=\left{\gamma_{i}\right}<em 1="1">{i=1}^{n}= &amp; {p() \mid p \in P, \operatorname{arity}(p)=0} \cup \
&amp; {p(k) \mid p \in P, \operatorname{arity}(p)=1, k \in C} \cup \
&amp; \left{p\left(k</em> \in C\right} \cup \
&amp; {\perp}
\end{aligned}
$$}, k_{2}\right) \mid p \in P, \operatorname{arity}(p)=2, k_{1}, k_{2</p>
<p>Note that $G$ includes the falsum atom $\perp$, the atom that is always false.</p>
<h1>3.2 Generating Clauses</h1>
<p>For each rule template $\tau$, we can generate a set $c l(\tau)$ of clauses that satisfy the template. To keep the set of generated clauses manageable, we make a number of restrictions. First, the only clauses we consider are those composed of atoms involving free variables. We do not allow any constants in any of our clauses. This may seem, initially, to be a severe</p>
<p><sup id="fnref7:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>restriction-but recall that our language has extensional predicates as well as intensional predicates. If we need a predicate whose meaning depends on particular constants, then we treat it as an extensional predicate, rather than an intensional predicate. For example, the predicate zero/1, which appears in the arithmetic examples later, is treated as an extensional predicate. We do not treat zero as an intensional predicate defined by a single rule with an empty body:</p>
<p>$$
\operatorname{zero}(0) \leftarrow
$$</p>
<p>Rather, we treat zero as an extensional predicate defined by the single background atom:</p>
<p>$$
\operatorname{zero}(0)
$$</p>
<p>The second restriction on generated clauses is that we only allow predicates of arity 0,1 , or 2 . We do not currently support ternary predicates or higher ${ }^{15}$.</p>
<p>Third, we insist that all clauses have exactly two atoms in the body. This restriction can also be made without loss of generality. For any logic program involving clauses with more than two atoms in the body of some clause, there is an equivalent logic program (with additional intensional predicates used as auxiliary functions) with exactly two atoms in the body of each clause ${ }^{16}$.</p>
<p>There are four additional restrictions on generated clauses. We rule out clauses that are (1) unsafe (a variable used in the head is not used in the body), (2) circular (the head atom appears in the body), (3) duplicated (equivalent to another clause with the body atoms permuted), and (4) those that do not respect the intensional flag int (i.e. those that contain an intensional predicate in the clause body, even though the int flag was set to 0 , i.e. False). We provide a worked example in Appendix B.</p>
<h1>3.3 Reducing Induction to Satisfiability</h1>
<p>Given a program template $\Pi$, let $\tau_{p}^{i}$ be the $i^{\prime}$ th rule template for intensional predicate $p$, where $i \in{1,2}$ indicates which of the two rule templates we are considering for $p$. Let $C_{p}^{i, j}$ be the $j^{\prime}$ th clause in $c l\left(\tau_{p}^{i}\right)$, the set of clauses generated for template $\tau_{p}^{i}$.</p>
<p>To turn the induction problem into a satisfiability problem, we define a set $\Phi$ of Boolean variables (i.e. atoms with nullary predicates) indicating which of the various clauses in $C_{p}^{i, j}$ are actually to be used in our program. Now a SAT solver can be used to find a truthassignment to the propositions in $\Phi$, and we can extract the induced rules from the subset of propositions in $\Phi$ that are set to True. The technical details behind this approach are described in Appendix B.</p>
<h2>4. A Differentiable Implementation of ILP</h2>
<p>In this section, we describe our core model: a continuous reimplementation of the ILP-assatisfiability approach described above. The discrete operations are replaced by differentiable operators, so the ILP problem can be solved by minimising a loss using stochastic</p>
<p><sup id="fnref8:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>gradient descent. In this case, the loss is the cross entropy of the correct label with regard to the predictions of the system.</p>
<p>Instead of the discrete semantics in which ground atoms are mapped to ${$ False, True $}$, we now use a continuous semantics ${ }^{17}$ which maps atoms to the real unit interval ${ }^{18}[0,1]$. Instead of using Boolean flags to choose a discrete subset of clauses, we now use continuous weights to determine a probability distribution over clauses.</p>
<p>This model, which we call $\partial$ ILP, implements differentiable deduction over continuous values. The gradient of the loss with regard to the rule weights, which we use to minimise classification loss, implements a continuous form of induction.</p>
<h1>4.1 Valuations</h1>
<p>Given a set $G$ of $n$ ground atoms, a valuation is a vector $[0,1]^{n}$ mapping each ground atom $\gamma_{i} \in G$ to the real unit interval.</p>
<p>Consider, for example, the language $L=\left(P_{e}, P_{i}\right.$, arity, $\left.C\right)$, where</p>
<p>$$
P_{e}={r / 2} \quad P_{i}={p / 0, q / 1} \quad C={a, b}
$$</p>
<p>One possible valuation on the ground atoms $G$ of $L$ is</p>
<table>
<thead>
<tr>
<th style="text-align: left;">$\perp \mapsto 0.0$</th>
<th style="text-align: left;">$p() \mapsto 0.0$</th>
<th style="text-align: left;">$q(a) \mapsto 0.1$</th>
<th style="text-align: left;">$q(b) \mapsto 0.3$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">$r(a, a) \mapsto 0.7$</td>
<td style="text-align: left;">$r(a, b) \mapsto 0.1$</td>
<td style="text-align: left;">$r(b, a) \mapsto 0.4$</td>
<td style="text-align: left;">$r(b, b) \mapsto 0.2$</td>
</tr>
</tbody>
</table>
<p>We insist that all valuations map $\perp$ to 0 . (The reason for including the $\perp$ atom will become clear in Section 4.5).</p>
<h3>4.2 Induction by Gradient Descent</h3>
<p>Given the sets $\mathcal{P}$ and $\mathcal{N}$ of positive and negative examples, we form a set $\Lambda$ of atom-label pairs:</p>
<p>$$
\Lambda={(\gamma, 1) \mid \gamma \in \mathcal{P}} \cup{(\gamma, 0) \mid \gamma \in \mathcal{N}}
$$</p>
<p>Each pair $(\gamma, \lambda)$ indicates whether atom $\gamma$ is in $\mathcal{P}$ (when $\lambda=1$ ) or $\mathcal{N}$ (when $\lambda=0$ ). This can be thought of as a dataset, used to learn a binary classifier that maps atoms $\gamma$ to their truth or falsehood.</p>
<p>Now given an ILP problem $(\mathcal{L}, \mathcal{B}, \mathcal{P}, \mathcal{N})$, a program template $\Pi$ and a set of clauseweights $W$, we construct a differentiable model that implements the conditional probability of $\lambda$ for a ground atom $\alpha$ :</p>
<p>$$
p(\lambda \mid \alpha, W, \Pi, \mathcal{L}, \mathcal{B})
$$</p>
<p>We want our predicted label $p(\lambda \mid \alpha, W, \Pi, \mathcal{L}, \mathcal{B})$ to match the actual label $\lambda$ in the pair $(\alpha, \lambda)$ we sample from $\Lambda$. We wish, in other words, to minimise the expected negative log likelihood when sampling uniformly $(\alpha, \lambda)$ pairs from $\Lambda$ :</p>
<p>$$
\text { loss }=-\underset{(\alpha, \lambda) \sim \Lambda}{\mathbb{E}}[\lambda \cdot \log p(\lambda \mid \alpha, W, \Pi, \mathcal{L}, \mathcal{B})+(1-\lambda) \cdot \log (1-p(\lambda \mid \alpha, W, \Pi, \mathcal{L}, \mathcal{B}))]
$$</p>
<p><sup id="fnref9:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>To calculate the probability of the label $\lambda$ given the atom $\alpha$, we infer the consequences of applying the rules to the background facts (using $T$ steps of forward chaining). In Figure 1 below, these consequences are called the "Conclusion Valuation". Then, we extract $\lambda$ as the probability of $\alpha$ in this valuation.</p>
<p>The probability $p(\lambda \mid \alpha, W, \Pi, \mathcal{L}, \mathcal{B})$ is defined as:</p>
<p>$$
p(\lambda \mid \alpha, W, \Pi, \mathcal{L}, \mathcal{B})=f_{\text {extract }}\left(f_{\text {infer }}\left(f_{\text {convert }}(\mathcal{B}), f_{\text {generate }}(\Pi, \mathcal{L}), W, T\right), \alpha\right)
$$</p>
<p>Here, $p(\lambda \mid \alpha, W, \Pi, \mathcal{L}, \mathcal{B})$ is computed using four auxiliary functions: $f_{\text {extract }}, f_{\text {infer }}, f_{\text {convert }}$, and $f_{\text {generate }}$. (See Figure 1). $f_{\text {extract }}$ and $f_{\text {infer }}$ are differentiable operations, while $f_{\text {convert }}$, and $f_{\text {generate }}$ are non-differentiable.</p>
<p>The function $f_{\text {extract }}:[0,1]^{n} \times G \rightarrow[0,1]$ takes a valuation $\mathbf{x}$ and an atom $\gamma$ and extracts the value for that atom:</p>
<p>$$
f_{\text {extract }}(\mathbf{x}, \gamma)=\mathbf{x}[\operatorname{index}(\gamma)]
$$</p>
<p>where index : $G \rightarrow \mathbb{N}$ is a function that assigns each ground atom a unique integer index. The function $f_{\text {convert }}: 2^{G} \rightarrow[0,1]^{n}$ takes a set of atoms and converts it into a valuation mapping the elements of $\mathcal{B}$ to 1 and all other elements of $G$ to 0 :</p>
<p>$$
f_{\text {convert }}(\mathcal{B})=\mathbf{y} \quad \text { where } \quad \mathbf{y}[i]= \begin{cases}1 \text { if } \gamma_{i} \in \mathcal{B} \ 0 \text { otherwise }\end{cases}
$$</p>
<p>and where $\gamma_{i}$ is the $i$ 'th ground atom in $G$ for $i=1 . . n$.
The function $f_{\text {generate }}$ produces a set of clauses from a program template $\Pi$ and a language $\mathcal{L}$ :</p>
<p>$$
f_{\text {generate }}(\Pi, \mathcal{L})=\left{c l\left(\tau_{p}^{i}\right) \mid p \in P_{i}, i \in{1,2}\right}
$$</p>
<p>This uses the $c l$ function defined in Section 3.2 above.
The $f_{\text {infer }}:[0,1]^{n} \times C \times W \times \mathbb{N} \rightarrow[0,1]^{n}$ function is where all the heavy-lifting takes place. It performs $T$ steps ${ }^{19}$ of forward-chaining inference using the generated clauses, amalgamating the various conclusions together using the clause weights $W$. It is described in detail below.</p>
<p>Figure 1 shows the architecture. The inputs to the network, the elements that are fed in every training step, are the atom $\alpha$ and the corresponding label $\lambda$. These are fed into the boxes labeled "Sampled Target Atom" and "Sampled Label". This input pair $(\alpha, \lambda)$ is sampled from the set $\Lambda$. The conditional probability $p(\lambda \mid \alpha, W, \Pi, \mathcal{L}, \mathcal{B})$ is the value in the "Predicted Label" box. The only trainable component is the set of clause weights $W$, shown in red. The differentiable operations are shown in green, while the non-differentiable operations are shown in orange. Note that, even though not all operations are differentiable, the operators between the loss and the clause weights $W$ are all differentiable, so we can compute $\frac{\partial l o s s}{\partial W}$, which in turn is used to update the clause weights by stochastic gradient descent (or any related optimisation method).</p>
<p>So far, we have described the high-level picture, but not the details. In Section 4.3, we explain how the rule weights are represented. In Section 4.4, we show how inference is performed over multiple time steps, by translating each clause $c$ into a function</p>
<p>$$
\mathcal{F}_{c}:[0,1]^{n} \rightarrow[0,1]^{n}
$$</p>
<ol>
<li>Recall that $T$ is a part of the program template $\Pi$.</li>
</ol>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The $\partial_{\text {ILP }}$ Architecture.</p>
<p>Finally, in Section 4.5, we describe how the $\mathcal{F}_{c}$ functions are computed.</p>
<h1>4.3 Rule Weights</h1>
<p>The weights $W$ are a set $\left{\mathbf{W}<em _left_P__i="\left|P_{i">{1}, \ldots, \mathbf{W}</em>}\right|}\right}$ of matrices, one matrix for each intensional predicate $p \in P_{i}$. The matrix $\mathbf{W<em p="p">{p}$ for predicate $p$ is of shape $\left(\left|c l\left(\tau</em>$ matrices are typically not of the same size, as the different rule templates produce different sized sets of clauses.}^{1}\right)\right|,\left|c l\left(\tau_{p}^{2}\right)\right|\right)$, where $\left|c l\left(\tau_{p}^{1}\right)\right|$ is the number of clauses generated by the first rule template $\tau_{p}^{1}$, and $\left|c l\left(\tau_{p}^{2}\right)\right|$ is the number of clauses generated by the second rule template $\tau_{p}^{2}$. Note that the various $\mathbf{W}_{\mathbf{p}</p>
<p>The weight $\mathbf{W}<em p="p">{p}[j, k]$ represents how strongly the system believes that the pair of clauses $\left(C</em>}^{1, j}, C_{p}^{2, k}\right)$ is the right way to define the intensional predicate $p$. (Recall from Section 3.3 that $C_{p}^{i, j}$ is the $j^{\prime}$ 'th clause of the $i$ 'th rule template $\tau_{p}^{i}$ for intensional predicate $p$. Here, as each predicate is defined by exactly two clauses, $i \in{1,2}$. Recall from Section 3.1 that we assume that each intensional predicate is defined by exactly two clauses). The weight matrix $\mathbf{W<em p="p">{p} \in \mathbb{R}^{\left|c l\left(\tau</em>}^{1}\right)\right| \times\left|c l\left(\tau_{p}^{2}\right)\right|}$ is a matrix of real numbers. We transform it into a probability distribution $\mathbf{W<em p="p">{p}^{*} \in[0,1]^{\left|c l\left(\tau</em>$ using softmax:}^{1}\right)\right| \times\left|c l\left(\tau_{p}^{2}\right)\right|</p>
<p>$$
\mathbf{W}<em p="p">{p}^{*}[j, k]=\frac{e^{\mathbf{W}</em>
$$}[j, k]}}{\sum_{j^{\prime}, k^{\prime}} e^{\mathbf{W}_{p}\left[j^{\prime}, k^{\prime}\right]}</p>
<p>Here, $\mathbf{W}<em p="p">{p}^{*}[j, k]$ represents the probability that the pair of clauses $\left(C</em>\right)$ is the right way to define the intensional predicate $p$.}^{1, j}, C_{p}^{2, k</p>
<p>Using matrices to store the weights of each pair of clauses requires a lot of memory. See Appendix E. An alternative, less memory-hungry approach would be to have a vector of weights for every set of clauses generated by every individual rule template. Unfortunately, this alternative is much less effective at the ILP tasks. See Appendix F for a fuller discussion.</p>
<h3>4.4 Inference</h3>
<p>The central idea behind our differentiable implementation of inference is that each clause $c$ induces a function $\mathcal{F}_{c}:[0,1]^{n} \rightarrow[0,1]^{n}$ on valuations. Consider, for example, the clause $c$ :</p>
<p>$$
p(X) \leftarrow q(X)
$$</p>
<p>Table 1 shows the results of applying the corresponding function $\mathcal{F}_{c}$ to two valuations on the set $G={p(a), p(b), q(a), q(b), \perp}$ of ground atoms.</p>
<p>The details of how the $F_{c}$ functions are generated is deferred to Section 4.5 below. The important point now is that we can automatically generate, from each clause $c$, a differentiable function $\mathcal{F}_{c}$ on valuations that implements a single step of forward chaining inference using $c$.</p>
<p>Recall that $C$ is an indexed set of generated clauses, where $C_{p}^{i, j}$ is the $j^{\prime}$ 'th clause of the $i$ 'th rule template $\tau_{p}^{i}$ for intensional predicate $p$. Define a corresponding indexed set of functions $\mathcal{F}$ where $\mathcal{F}<em p="p">{p}^{i, j}$ is the valuation function corresponding to the clause $C</em>$.}^{i, j</p>
<p>Now we define another indexed set of functions $\mathcal{G}<em p="p">{p}^{j, k}$ that combines the application of two functions $\mathcal{F}</em>$. Recall that each intensional predicate $p$ is defined by two}^{1, j}$ and $\mathcal{F}_{p}^{2, k</p>
<table>
<thead>
<tr>
<th style="text-align: left;">$G$</th>
<th style="text-align: left;">$\mathbf{a}_{0}$</th>
<th style="text-align: left;">$\mathcal{F}<em _mathbf_0="\mathbf{0">{c}\left(\mathbf{a}</em>\right)$}</th>
<th style="text-align: left;">$\mathbf{a}_{1}$</th>
<th style="text-align: left;">$\mathcal{F}<em 1="1">{c}\left(\mathbf{a}</em>\right)$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">$p(a)$</td>
<td style="text-align: left;">0.0</td>
<td style="text-align: left;">0.1</td>
<td style="text-align: left;">0.2</td>
<td style="text-align: left;">0.7</td>
</tr>
<tr>
<td style="text-align: left;">$p(b)$</td>
<td style="text-align: left;">0.0</td>
<td style="text-align: left;">0.3</td>
<td style="text-align: left;">0.9</td>
<td style="text-align: left;">0.4</td>
</tr>
<tr>
<td style="text-align: left;">$q(a)$</td>
<td style="text-align: left;">0.1</td>
<td style="text-align: left;">0.0</td>
<td style="text-align: left;">0.7</td>
<td style="text-align: left;">0.0</td>
</tr>
<tr>
<td style="text-align: left;">$q(b)$</td>
<td style="text-align: left;">0.3</td>
<td style="text-align: left;">0.0</td>
<td style="text-align: left;">0.4</td>
<td style="text-align: left;">0.0</td>
</tr>
<tr>
<td style="text-align: left;">$\perp$</td>
<td style="text-align: left;">0.0</td>
<td style="text-align: left;">0.0</td>
<td style="text-align: left;">0.0</td>
<td style="text-align: left;">0.0</td>
</tr>
</tbody>
</table>
<p>Table 1: Applying $c=p(X) \leftarrow q(X)$, treated as a function $\mathcal{F}<em 0="0">{c}$, to valuations $\mathbf{a}</em>}$ and $\mathbf{a<em p="p">{1}$
clauses generated from two rule templates $\tau</em>}^{1}$ and $\tau_{p}^{2}$. Now $\mathcal{G<em p="p">{p}^{j, k}$ is the result of applying both clauses $C</em>$ and taking the element-wise max:}^{1, j}$ and $C_{p}^{2, k</p>
<p>$$
\mathcal{G}<em p="p">{p}^{j, k}(\mathbf{a})=\mathbf{x} \quad \text { where } \quad \mathbf{x}[i]=\max \left(\mathcal{F}</em>)[i]\right)
$$}^{1, j}(\mathbf{a})[i], \mathcal{F}_{p}^{2, k}(\mathbf{a</p>
<p>Next, we will define a series of valuations of the form $\mathbf{a}<em t="t">{t}$. A valuation $\mathbf{a}</em>$ represents our conclusions after $t$ time-steps of inference.</p>
<p>The initial value $\mathbf{a}_{0}$ when $t=0$ is based on our initial set $\mathcal{B} \subseteq G$ of background axioms:</p>
<p>$$
\mathbf{a}<em x="x">{0}[x]= \begin{cases}1 &amp; \text { if } \gamma</em>
$$} \in \mathcal{B} \ 0 &amp; \text { otherwise }\end{cases</p>
<p>We now define $\mathbf{c}_{t}^{p, j, k}$ :</p>
<p>$$
\mathbf{c}<em p="p">{t}^{p, j, k}=G</em>\right)
$$}^{j, k}\left(\mathbf{a}_{t</p>
<p>Intuitively, $\mathbf{c}<em t="t">{t}^{p, j, k}$ is the result of applying one step of forward chaining inference to $\mathbf{a}</em> t h$ intensional predicate.}$ using clauses $C_{p}^{1, j}$ and $C_{p}^{2, k}$. Note that this only has non-zero values for one particular predicate: the $p^{\prime</p>
<p>We can now define the weighted average of the $\mathbf{c}_{t}^{p, j, k}$, using the softmax of the weights:</p>
<p>$$
\mathbf{b}<em j_="j," k="k">{t}^{p}=\sum</em>} \mathbf{c<em p="p">{t}^{p, j, k} \cdot \frac{e^{\mathbf{W}</em>
$$}[j, k]}}{\sum_{j^{\prime}, k^{\prime}} e^{\mathbf{W}_{p}\left[j^{\prime}, k^{\prime}\right]}</p>
<p>Intuitively, $\mathbf{b}<em p="p">{t}^{p}$ is the result of applying all the possible pairs of clauses that can jointly define predicate $p$, and weighting the results by the weights $\mathbf{W}</em>$ th intensional predicate.}$. Note that $\mathbf{b}_{t}^{p}$ is also zero everywhere except for the $p^{\prime</p>
<p>From this, we define the successor $\mathbf{a}<em t="t">{t+1}$ of $\mathbf{a}</em>$ :</p>
<p>$$
\mathbf{a}<em _amalgamate="{amalgamate" _text="\text">{t+1}=f</em>}}\left(\mathbf{a<em P__i="P_{i" _in="\in" p="p">{t}, \sum</em>\right)
$$}} \mathbf{b}_{t}^{p</p>
<p>The successor depends on the previous valuation $\mathbf{a}<em t="t">{t}$ and a weighted mixture of the clauses defining the other intensional predicates. Note that the valuations $\mathbf{b}</em>$ are disjoint for different $p$, so we can simply sum these valuations.}^{p</p>
<p>When amalgamating the previous valuation, $\mathbf{a}<em P__i="P_{i" _in="\in" p="p">{t}$, with the single-step consequences, $\sum</em>}} \mathbf{b<em _amalgamate="{amalgamate" _text="\text">{t}^{p}$, there are various functions we can use for $f</em>$. First we considered:}</p>
<p>$$
f_{\text {amalgamate }}(\mathbf{x}, \mathbf{y})=\max (\mathbf{x}, \mathbf{y})
$$</p>
<p>(Note this is element-wise max over the two valuation vectors). But the use of max here adversely affected gradient flow. The definition of $f_{\text {amalgamate }}$ we actually use is the probabilistic sum:</p>
<p>$$
f_{\text {amalgamate }}(\mathbf{x}, \mathbf{y})=\mathbf{x}+\mathbf{y}-\mathbf{x} \cdot \mathbf{y}
$$</p>
<p>This keeps valuations within the real unit interval $[0,1]$ while allowing gradients to flow through both $\mathbf{x}$ and $\mathbf{y}$. The two alternative ways of computing $f_{\text {amalgamate }}$ are compared in Table 2.</p>
<h1>4.5 Computing the $\mathcal{F}_{c}$ Functions</h1>
<p>We now explain the details of how the various $\mathcal{F}<em c="c">{c}$ functions are computed.
Each $\mathcal{F}</em>\right}}$ function can be computed as follows. Let $X_{c}=\left{x_{k<em k="k">{k=1}^{n}$ be a set of sets of pairs of indices of ground atoms for clause $c$. Each $x</em>$ according to the current clause $c$ :}$ contains all the pairs of indices of atoms that justify atom $\gamma_{k</p>
<p>$$
x_{k}=\left{(a, b) \mid \text { satisfies }<em a="a">{c}\left(\gamma</em>}, \gamma_{b}\right) \wedge \text { head <em a="a">{c}\left(\gamma</em>\right}
$$}, \gamma_{b}\right)=\gamma_{k</p>
<p>Note that we can restrict ourselves to pairs only (and don't have to worry about triples, etc) because we are restricting ourselves to rules with two atoms in the body.</p>
<p>Here, satisfies $c_{c}\left(\gamma_{1}, \gamma_{2}\right)$ if the pair of ground atoms $\left(\gamma_{1}, \gamma_{2}\right)$ satisfies the body of clause c. If $c=\alpha \leftarrow \alpha_{1}, \alpha_{2}$, then satisfies $c_{c}\left(\gamma_{1}, \gamma_{2}\right)$ is true if there is a substitution $\theta$ such that $\alpha_{1}[\theta]=\gamma_{1}$ and $\alpha_{2}[\theta]=\gamma_{2}$.</p>
<p>Also, head $<em 1="1">{c}\left(\gamma</em>$ then}, \gamma_{2}\right)$ is the head atom produced when applying clause $c$ to the pair of atoms $\left(\gamma_{1}, \gamma_{2}\right)$. If $c=\alpha \leftarrow \alpha_{1}, \alpha_{2}$ and $\alpha_{1}[\theta]=\gamma_{1}$ and $\alpha_{2}[\theta]=\gamma_{2</p>
<p>$$
\operatorname{head}<em 1="1">{c}\left(\gamma</em>\right)=\alpha[\theta]
$$}, \gamma_{2</p>
<p>For example, suppose $P={p, q, r}$ and $C={a, b}$. Then our ground atoms $G$ are:</p>
<table>
<thead>
<tr>
<th style="text-align: left;">$k$</th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">1</th>
<th style="text-align: left;">2</th>
<th style="text-align: left;">3</th>
<th style="text-align: left;">4</th>
<th style="text-align: left;">5</th>
<th style="text-align: left;">6</th>
<th style="text-align: left;">7</th>
<th style="text-align: left;">8</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">$\gamma_{k}$</td>
<td style="text-align: left;">$\perp$</td>
<td style="text-align: left;">$p(a, a)$</td>
<td style="text-align: left;">$p(a, b)$</td>
<td style="text-align: left;">$p(b, a)$</td>
<td style="text-align: left;">$p(b, b)$</td>
<td style="text-align: left;">$q(a, a)$</td>
<td style="text-align: left;">$q(a, b)$</td>
<td style="text-align: left;">$q(b, a)$</td>
<td style="text-align: left;">$q(b, b)$</td>
</tr>
<tr>
<td style="text-align: left;">$k$</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">11</td>
<td style="text-align: left;">12</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">$\gamma_{k}$</td>
<td style="text-align: left;">$r(a, a)$</td>
<td style="text-align: left;">$r(a, b)$</td>
<td style="text-align: left;">$r(b, a)$</td>
<td style="text-align: left;">$r(b, b)$</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>Suppose clause $c$ is:</p>
<p>$$
r(X, Y) \leftarrow p(X, Z), q(Z, Y)
$$</p>
<p>Then $X_{c}=\left{x_{k}\right}_{k=1}^{n}$ is:</p>
<table>
<thead>
<tr>
<th style="text-align: center;">$k$</th>
<th style="text-align: center;">$\gamma_{k}$</th>
<th style="text-align: center;">$x_{k}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$\perp$</td>
<td style="text-align: center;">$}$</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">$p(a, a)$</td>
<td style="text-align: center;">$}$</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">$p(a, b)$</td>
<td style="text-align: center;">$}$</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">$p(b, a)$</td>
<td style="text-align: center;">$}$</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">$p(b, b)$</td>
<td style="text-align: center;">$}$</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">$k$</th>
<th style="text-align: center;">$\gamma_{k}$</th>
<th style="text-align: center;">$x_{k}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$q(a, a)$</td>
<td style="text-align: center;">$}$</td>
</tr>
<tr>
<td style="text-align: center;">6</td>
<td style="text-align: center;">$q(a, b)$</td>
<td style="text-align: center;">$}$</td>
</tr>
<tr>
<td style="text-align: center;">7</td>
<td style="text-align: center;">$q(b, a)$</td>
<td style="text-align: center;">$}$</td>
</tr>
<tr>
<td style="text-align: center;">8</td>
<td style="text-align: center;">$q(b, b)$</td>
<td style="text-align: center;">$}$</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">$k$</th>
<th style="text-align: center;">$\gamma_{k}$</th>
<th style="text-align: center;">$x_{k}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">9</td>
<td style="text-align: center;">$r(a, a)$</td>
<td style="text-align: center;">${(1,5),(2,7)}$</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">$r(a, b)$</td>
<td style="text-align: center;">${(1,6),(2,8)}$</td>
</tr>
<tr>
<td style="text-align: center;">11</td>
<td style="text-align: center;">$r(b, a)$</td>
<td style="text-align: center;">${(3,5),(4,7)}$</td>
</tr>
<tr>
<td style="text-align: center;">12</td>
<td style="text-align: center;">$r(b, b)$</td>
<td style="text-align: center;">${(3,6),(4,8)}$</td>
</tr>
</tbody>
</table>
<p>Focusing on a particular row, the reason why $(2,7)$ is in $x_{9}$ is that $\gamma_{2}=p(a, b), \gamma_{7}=q(b, a)$, the pair of atoms $(p(a, b), q(b, a))$ satisfy the body of clause $c$, and the head of the clause $c$ (for this pair of atoms) is $r(a, a)$ which is $\gamma_{9}$.</p>
<p>We can transform $X_{c}$, a set of sets of pairs, into a three dimensional tensor: $\mathbf{X} \in \mathbb{N}^{n \times w \times 2}$. Here, $w$ is the maximum number of pairs for any $k$ in $1 \ldots n$. The width $w$ depends on the number of existentially quantified variables $v$ in the rule template. Each existentially quantified variable can take $|C|$ values, so $w=|C|^{v} . \mathbf{X}$ is constructed from $X_{c}$, filling in unused space with $(0,0)$ pairs that point to the pair of atoms $(\perp, \perp)$ :</p>
<p>$$
\mathbf{X}[k, m]= \begin{cases}x_{k}[m] \text { if } m&lt;\left|x_{k}\right| \ (0,0) \text { otherwise }\end{cases}
$$</p>
<p>This is why we needed to include the falsum atom $\perp$ in $G$, so that the null pairs have some atom to point to. In our running example, this yields:</p>
<table>
<thead>
<tr>
<th style="text-align: center;">$k$</th>
<th style="text-align: left;">$\gamma_{k}$</th>
<th style="text-align: left;">$\mathbf{X}[k]$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: left;">$\perp$</td>
<td style="text-align: left;">$\left[\begin{array}{l}(0,0) \ (0,0)\end{array}\right]$</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: left;">$p(a, a)$</td>
<td style="text-align: left;">$\left[\begin{array}{l}(0,0) \ (0,0)\end{array}\right]$</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: left;">$p(a, b)$</td>
<td style="text-align: left;">$\left[\begin{array}{l}(0,0) \ (0,0)\end{array}\right]$</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: left;">$p(b, a)$</td>
<td style="text-align: left;">$\left[\begin{array}{l}(0,0) \ (0,0)\end{array}\right]$</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: left;">$p(b, b)$</td>
<td style="text-align: left;">$\left[\begin{array}{l}(0,0) \ (0,0)\end{array}\right]$</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">$k$</th>
<th style="text-align: center;">$\gamma_{k}$</th>
<th style="text-align: center;">$\mathbf{X}[k]$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$q(a, a)$</td>
<td style="text-align: center;">$\left[\begin{array}{l}(0,0) \ (0,0)\end{array}\right]$</td>
</tr>
<tr>
<td style="text-align: center;">6</td>
<td style="text-align: center;">$q(a, b)$</td>
<td style="text-align: center;">$\left[\begin{array}{l}(0,0) \ (0,0)\end{array}\right]$</td>
</tr>
<tr>
<td style="text-align: center;">7</td>
<td style="text-align: center;">$q(b, a)$</td>
<td style="text-align: center;">$\left[\begin{array}{l}(0,0) \ (0,0)\end{array}\right]$</td>
</tr>
<tr>
<td style="text-align: center;">8</td>
<td style="text-align: center;">$q(b, b)$</td>
<td style="text-align: center;">$\left[\begin{array}{l}(0,0) \ (0,0)\end{array}\right]$</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">$k$</th>
<th style="text-align: center;">$\gamma_{k}$</th>
<th style="text-align: center;">$\mathbf{X}[k]$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">9</td>
<td style="text-align: center;">$r(a, a)$</td>
<td style="text-align: center;">$\left[\begin{array}{l}(1,5) \ (2,7)\end{array}\right]$</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">$r(a, b)$</td>
<td style="text-align: center;">$\left[\begin{array}{l}(1,6) \ (2,8)\end{array}\right]$</td>
</tr>
<tr>
<td style="text-align: center;">11</td>
<td style="text-align: center;">$r(b, a)$</td>
<td style="text-align: center;">$\left[\begin{array}{l}(3,5) \ (4,7)\end{array}\right]$</td>
</tr>
<tr>
<td style="text-align: center;">12</td>
<td style="text-align: center;">$r(b, b)$</td>
<td style="text-align: center;">$\left[\begin{array}{l}(3,6) \ (4,8)\end{array}\right]$</td>
</tr>
</tbody>
</table>
<p>Let $\mathbf{X}<em 2="2">{1}, \mathbf{X}</em>$, taking the first and second elements in each pair:} \in \mathbb{N}^{n \times w}$ be two slices of $\mathbf{X</p>
<p>$$
\mathbf{X}<em 2="2">{1}=\mathbf{X}[:,:, 0] \quad \mathbf{X}</em>[:,:, 1]
$$}=\mathbf{X</p>
<p>We shall use a function gather $_{2}: \mathbb{R}^{a} \times \mathbb{N}^{b \times c} \rightarrow \mathbb{R}^{b \times c}$ :</p>
<p>$$
\text { gather }_{2}(x, y)[i, j]=x[y[i, j]]
$$</p>
<p>Now we are ready to define $F_{c}(\mathbf{a})$. Let $\mathbf{Y}<em 2="2">{1}, \mathbf{Y}</em>} \in[0,1]^{n \times w}$ be the results of assembling the elements of $\mathbf{a}$ according to the matrix of indices in $\mathbf{X<em 2="2">{1}$ and $\mathbf{X}</em>$ :</p>
<p>$$
\mathbf{Y}<em 2="2">{1}=\text { gather }</em>}\left(\mathbf{a}, \mathbf{X<em 2="2">{1}\right) \quad \mathbf{Y}</em>}=\text { gather <em 2="2">{2}\left(\mathbf{a}, \mathbf{X}</em>\right)
$$</p>
<p>Now let $\mathbf{Z} \in[0,1]^{n \times w}$ contain the results of element-wise multiplying the elements of $\mathbf{Y}<em 2="2">{1}$ and $\mathbf{Y}</em>$ :</p>
<p>$$
\mathbf{Z}=\mathbf{Y}<em 2="2">{1} \odot \mathbf{Y}</em>
$$</p>
<p>Here, $\mathbf{Z}[k,:]$ is the vector of fuzzy conjunctions of all the pairs of atoms that contribute to the truth of $\gamma_{k}$, according to the current clause. Now we can define $F_{c}(\mathbf{a})$ by taking the max fuzzy truth values in $\mathbf{Z}$. Let $F_{c}(\mathbf{a})=\mathbf{a}^{\prime}$ where $\mathbf{a}^{\prime}[k]=\max (\mathbf{Z}[k,:])$.</p>
<p>The following table shows the calculation of $F_{c}(\mathbf{a})$ for a particular valuation a, using our running example $c=r(X, Y) \leftarrow p(X, Z), q(Z, Y)$. Here, since there is one existential variable $Z, v=1$, and $w=|{a, b}|^{v}=2$.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">$k$</th>
<th style="text-align: center;">$\gamma_{k}$</th>
<th style="text-align: center;">$\mathbf{a}[k]$</th>
<th style="text-align: center;">$\mathbf{X}_{1}[k]$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">$\mathbf{X}_{2}[k]$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">$\mathbf{Y}_{1}[k]$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">$\mathbf{Y}_{2}[k]$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">$\mathbf{Z}[k]$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">$F_{c}(\mathbf{a})[k]$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$\perp$</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">$p(a, a)$</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">$p(a, b)$</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">$p(b, a)$</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">$p(b, b)$</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$q(a, a)$</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">6</td>
<td style="text-align: center;">$q(a, b)$</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">7</td>
<td style="text-align: center;">$q(b, a)$</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">8</td>
<td style="text-align: center;">$q(b, b)$</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">9</td>
<td style="text-align: center;">$r(a, a)$</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">$[1$</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">$[5$</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">$[1.0$</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">$[0.1$</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">$[0.1$</td>
<td style="text-align: center;">0.18</td>
<td style="text-align: center;">0.18</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">$r(a, b)$</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">$[1$</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">$[6$</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">$[1.0$</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.72</td>
</tr>
<tr>
<td style="text-align: center;">11</td>
<td style="text-align: center;">$r(b, a)$</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">$[3$</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">$[5$</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0.1$</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">12</td>
<td style="text-align: center;">$r(b, b)$</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">$[3$</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">$[6$</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">$[0$</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.00</td>
</tr>
</tbody>
</table>
<p>Please note that the calculation of the indices in $\mathbf{X}$ is not a differentiable operation. Calculating $\mathbf{X}$ makes use of the discrete operations satisfies and head. The matrix $\mathbf{X}$ of indices is created, ahead of time, before the neural net is constructed. However, the function $F_{c}$ on valuations is differentiable. It takes the indices in $\mathbf{X}$ and applies differentiable operations such as gather ${ }_{2}$ and element-wise multiplication.</p>
<h1>4.5.1 Defining Fuzzy Conjunction</h1>
<p>Above, when computing $\mathbf{Z}$, we took the element-wise product:</p>
<p>$$
\mathbf{Z}=\mathbf{Y}<em 2="2">{1} \odot \mathbf{Y}</em>
$$</p>
<p>Now $\mathbf{Y}<em 2="2">{1}$ and $\mathbf{Y}</em>$ represents their conjunction.}$ represent the fuzzy truth values of the two atoms satisfying the body of the predicate, and $\mathbf{Z</p>
<p>Now there are many different ways of representing fuzzy conjunction. At a high level of generality, we need an operator $*:[0,1]^{2} \rightarrow[0,1]$ satisfying the conditions on a tnorm (Esteva \&amp; Godo, 2001):</p>
<ul>
<li>commutativity: $x * y=y * x$</li>
<li>associativity: $(x * y) * z=x *(y * z)$</li>
<li>monotonicity (i): $x_{1} \leq x_{2}$ implies $x_{1} * y \leq x_{2} * y$</li>
<li>
<p>monotonicity (ii): $y_{1} \leq y_{2}$ implies $x * y_{1} \leq x * y_{2}$</p>
</li>
<li>
<p>unit (i): $x * 1=x$</p>
</li>
<li>unit (ii): $x * 0=0$</li>
</ul>
<p>Now there are a number of operators satisfying these conditions:</p>
<ul>
<li>Godel t-norm: $x * y=\min (x, y)$</li>
<li>Lukasiewicz t-norm: $x * y=\max (0, x+y-1)$</li>
<li>Product t-norm: $x * y=x \cdot y$</li>
</ul>
<p>The reason we chose the product t-norm over the alternatives proposed by Godel and Lukasiewicz is that, when back-propagating from the loss to the clause weights, the gradients flow evenly between both $\mathbf{Y}<em 2="2">{1}$ and $\mathbf{Y}</em>}$. With Godel's t-norm, there is no gradient information sent to $\mathbf{Y<em 1="1">{1}$ when $\mathbf{Y}</em>}&gt;\mathbf{Y<em 1="1">{2}$. Similarly, with Lukasiewicz's t-norm, there is no gradient information sent to either $\mathbf{Y}</em>}$ or $\mathbf{Y<em 1="1">{2}$ when $\mathbf{Y}</em>&lt;1$.}+\mathbf{Y}_{2</p>
<p>Experimental evaluation bears this out. We tested all three t-norms on our dataset of 20 symbolic problems and found that the product t-norm consistently out-performed Godel's and Lukasiewicz's. See Section 5.3.4 below.</p>
<h1>5. Experiments</h1>
<p>ILP has a number of excellent features. But it has two main areas of weakness: intolerance to mis-labelled data, and inability to cope with fuzzy or ambiguous data. After first checking that $\partial_{\text {ILP }}$ is capable of learning standard ILP tasks with discrete error-free input, our experiments were largely focused on testing how $\partial_{\text {ILP }}$ compares with standard ILP in these two problem areas.</p>
<p>We implemented our model in TensorFlow (Abadi, Agarwal, Barham, Brevdo, Chen, Citro, Corrado, Davis, Dean, Devin, et al., 2016) and tested it with three types of experiment. First, we used standard symbolic ILP tasks, where $\partial_{\text {ILP }}$ is given discrete error-free input. Second, we modified the standard symbolic ILP tasks so that a certain proportion of the positive and negative examples are wilfully mis-labelled. Third, we tested it with fuzzy, ambiguous data, connecting $\partial_{\text {ILP }}$ to the output of a pretrained convolution neural network that classifies MNIST digits.</p>
<h3>5.1 Hyperparameters</h3>
<p>We first ran a grid search to find "reasonable" hyperparameters that could solve each of ten tasks in at least $5 \%$ of all random initialisations of weights ${ }^{20}$. We tried a range of optimisation algorithms: Stochastic Gradient Descent, Adam, AdaDelta, and RMSProp. We searched across a range of learning rates in ${0.5,0.2,0.1,0.05,0.01,0.001}$. Weights were initialised randomly from a normal distribution with mean 0 and a standard deviation that ranged between 0 and 2 (the standard deviation was a hyperparameter but the mean was fixed). For each configuration of hyperparameter settings, we ran 20 trials, each with different random seeds, for each of 10 tasks.</p>
<p><sup id="fnref10:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>We found that both RMSProp and Adam gave reasonable results: both were able to solve all 10 tasks for at least $5 \%$ of random weight initialisations. RMSProp was successful on a range of learning rates from 0.5 to 0.01 .</p>
<p>Hyperparameters were validated against training data, not held-out development data. Because of $\partial$ ILP's strong inductive bias towards universally quantified rules, programs with a low loss on the training data are also biased towards performing well on the test data.</p>
<p>In all the experiments described below, we stuck to a particular fixed set of hyperparameter settings: we used RMSProp with a learning rate of 0.5 , and initialised clause weights by sampling from a $\mathcal{N}(0,1)$ distribution.</p>
<h1>5.2 Experimental Method</h1>
<p>Before training, rule weights are initialised randomly by sampling from a $\mathcal{N}(0,1)$ distribution. We train for 6000 steps, adjusting rule weights to minimise cross entropy loss as described above.</p>
<p>During training, $\partial$ ILP is given multiple $(\mathcal{B}, \mathcal{P}, \mathcal{N})$ triples. Each triple represents a different possible world. Each training step, $\partial$ ILP first samples one of these $(\mathcal{B}, \mathcal{P}, \mathcal{N})$ triples, and then samples a mini-batch from $\mathcal{P} \cup \mathcal{N}$. Providing multiple alternative possible worlds helps the system to generalise correctly. It is less likely to focus on irrelevant aspects of one particular situation if it is forced to consider multiple situations.</p>
<p>Each step we sample a mini-batch from the positive and negative examples. Note that, instead of using the whole set of positive and negative examples each training step, we just take a random subset. This mini-batching gives the process a stochastic element and helps to escape local minima.</p>
<p>After 6000 steps, $\partial$ ILP produces a set of rule weights for each rule template. To validate this program, we run the model with the learned weights on an entirely new set of background facts. This is testing the system's ability to generalise to unseen data. We compute validation error as the sum of mean-squared difference between the actual label $\lambda$ and the predicted label $\hat{\lambda}$ :</p>
<p>$$
\text { loss }=\sum_{i=1}^{k}(\lambda-\hat{\lambda})^{2}
$$</p>
<p>Once $\partial$ ILP has finished training, we extract the rule weights, and take the soft-max. Interpreting the soft-maxed weights as a probability distribution over clauses, we measure the "fuzziness" of the solution by calculating the entropy of the distribution. On the discrete error-free tasks, $\partial$ ILP finds solutions with zero entropy, as long as it does not get stuck in a local minimum. To extract a human-readable logic program, we just take all clauses whose probability is over some constant threshold (currently set, arbitrarily, to 0.1 ).</p>
<h3>5.3 ILP Benchmark Tasks</h3>
<p>We tested $\partial$ ILP on 20 ILP tasks, taken from four domains: arithmetic, lists, group-theory, and family tree relations. Some of the arithmetic examples appeared in the work of Cropper and Muggleton (2016). The list examples are used by Feser, Chaudhuri, and Dillig (2015). The family tree dataset comes from Wang, Mazaitis, and Cohen (2015) and is also used by Yang, Yang, and Cohen (2016).</p>
<p>We emphasize that the 20 tasks we used have the following common feature: in each case, the program can be learned from a small amount of training data. $\partial_{\text {ILP }}$ is a memoryexpensive solution to ILP (see Appendix E), so only problems with small training sets have been tested. This is why we have not tested $\partial_{\text {ILP }}$ on the larger ILP datasets, such as Mutagenesis, WebKB, or IMDB. Although the 20 tasks we use are all quite small in the amount of training data needed to learn them, the programs needing to be synthesised in order to solve them are often complex, involving multiple recursive predicates and invented auxiliary predicates.</p>
<p>In this section, we shall focus on three examples in detail. The complete list of 20 examples is detailed in Appendix G.</p>
<h1>5.3.1 Learning Even/1 on Natural Numbers</h1>
<p>The task is to learn the even predicate on natural numbers. The language contains the monadic predicate zero and the successor relation succ. The background knowledge is the set of basic arithmetic facts defining the zero predicate and succ relation on numbers up to 10 :</p>
<p>$$
\mathcal{B}={\operatorname{zero}(0), \operatorname{succ}(0,1), \operatorname{succ}(1,2), \operatorname{succ}(2,3), \ldots, \operatorname{succ}(9,10)}
$$</p>
<p>The positive examples $\mathcal{P}$ are:</p>
<p>$$
\mathcal{P}={\operatorname{target}(0), \operatorname{target}(2), \operatorname{target}(4), \operatorname{target}(6), \operatorname{target}(8), \operatorname{target}(10)}}
$$</p>
<p>In all these examples, target is the name of the target predicate we are trying to learn. In this case, target $=$ even. The negative examples are</p>
<p>$$
\mathcal{N}={\operatorname{target}(1), \operatorname{target}(3), \operatorname{target}(5), \operatorname{target}(7), \operatorname{target}(9)}
$$</p>
<p>For validation and test, we use positive and negative examples of the even predicate on numbers greater than 10 .</p>
<p>One possible language template for this task is:</p>
<ul>
<li>$P_{e}:{z e r o / 1, s u c c / 2}$</li>
<li>$P_{i}:{\operatorname{target} / 1, \operatorname{pred} / 2}$</li>
</ul>
<p>Here, pred is an auxiliary binary predicate. The set $C$ of constants is just ${0,1, \ldots, 10}$.
One suitable program template ${ }^{21}$ for this tasks is:</p>
<p>$$
\begin{aligned}
\tau_{\text {target }, 1} &amp; =(h=\text { target }, n_{\exists}=0, \text { int }=\text { False }) \
\tau_{\text {target }, 2} &amp; =(h=\text { target }, n_{\exists}=1, \text { int }=\text { True }) \
\tau_{\text {pred }, 1} &amp; =(h=\text { pred }, n_{\exists}=1, \text { int }=\text { False }) \
\tau_{\text {pred }, 2} &amp; =\text { null }
\end{aligned}
$$</p>
<p>This template specifies two clauses for target, and one clause for the auxiliary predicate pred. The architecture assumes that every predicate is defined by exactly two clauses</p>
<p><sup id="fnref11:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<ol>
<li>There are other templates that work equally well.</li>
</ol>
<p><a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref7:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref8:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref9:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref10:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref11:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>