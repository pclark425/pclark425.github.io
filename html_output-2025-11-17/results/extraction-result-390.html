<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-390 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-390</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-390</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-16.html">extraction-schema-16</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <p><strong>Paper ID:</strong> paper-211829879</p>
                <p><strong>Paper Title:</strong> <a href="https://web.archive.org/web/20200215063805/https:/res.mdpi.com/d_attachment/algorithms/algorithms-13-00039/article_deploy/algorithms-13-00039.pdf" target="_blank">Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting †</a></p>
                <p><strong>Paper Abstract:</strong> : Transfer learning is a modern concept that focuses on the application of ideas, models, and algorithms, developed in one applied area, for solving a similar problem in another area. In this paper, we identify links between methodologies in two fields: video prediction and spatiotemporal traffic forecasting. The similarities of the video stream and citywide traffic data structures are discovered and analogues between historical development and modern states of the methodologies are presented and discussed. The idea of transferring video prediction models to the urban traffic forecasting domain is validated using a large real ‐ world traffic data set. The list of transferred techniques includes spatial filtering by predefined kernels in combination with time series models and spectral graph convolutional artificial neural networks. The obtained models’ forecasting performance is compared to the baseline traffic forecasting models: non ‐ spatial time series models and spatially regularized vector autoregression models. We conclude that the application of video prediction models and algorithms for urban traffic forecasting is effective both in terms of observed forecasting accuracy and development, and training efforts. Finally, we discuss problems and obstacles of transferring methodologies and present potential directions for further research.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e390.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e390.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SpX-kernels</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Spatial filtering by predefined kernels (weighted average and standard deviation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of classical image-processing spatial kernels (weighted average smoothing and local standard-deviation edge-detection) adapted as regressors for predicting a road segment's future traffic from its spatial neighborhood.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Spatial filtering by predefined kernels</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Compute local spatial features for each target spatial location by convolving a neighborhood (defined on the road network) with predefined kernels: a spatially weighted average (smoothing / Gaussian-like) and a local standard-deviation (edge/contrast detector). These kernel outputs (for one or more radii) are used as predictors/regressors in a forecasting model. Neighborhoods are defined not by pixel-grid adjacency but by travel-time-based reachable sets; multiple radii (e.g., 10 and 30 min travel time) and an optional horizon-dependent spatial inflation are used so kernel neighborhoods expand with forecast horizon. Kernel values are computed per time step and fed into either linear regression (SpX-lm) or non-linear regression (SpX-SVR).</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / data-analysis technique</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>computer vision / digital image and video processing</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>spatiotemporal urban traffic forecasting / transportation engineering</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Neighborhood definition changed from pixel grid to road-network travel-time neighborhoods; kernels applied to traffic-flow values instead of pixel intensities; two radii used simultaneously (local and wider); optional horizon-dependent spatial inflation implemented (neighborhood expands with forecast horizon); kernel outputs used as regressors rather than direct filtering of image intensities.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful — SpX variants produced reasonable forecasting accuracy but did not beat the best graph-regularized VAR models; quantitative one-step-ahead MAE: SpX-lm = 11.27, SpX-SVR = 10.54 (h=1); compared to ARIMA (9.02) and sparse VAR (8.88–8.92). SpX-ARIMAX (hybrid) achieved MAE = 8.85 (h=1), the best among transferred models.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Kernels are simplistic and ignore temporal history of the target location when used alone; performance depends on appropriate choice of radii and travel-time metric; spatial kernels alone underperform compared to more expressive multivariate/graph models for some horizons.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>High-level analogy between image patches and spatial neighborhoods of road network; availability of travel-time matrix and clear definition of neighborhoods; ability to compute kernel features cheaply for many nodes.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Need travel-time distances (or other road-network distance metric) to define neighborhoods, tuning of radii and decay parameters via cross-validation, detrended time series (background subtraction), rolling-window training, and feature computation at required temporal aggregation (5-min used in study).</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Moderately generalizable — the kernel-regressor approach can be applied to other traffic networks and other spatiotemporal data with a definable neighborhood metric, but requires retuning of radii/decay and may be limited when temporal history or node-specific features are critical.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps and computational method (algorithmic knowledge)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e390.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e390.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SpX-ARIMAX</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Spatial-kernel regressors combined with ARIMA (SpX-ARIMAX)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid model that augments classical ARIMA time-series forecasting for a target location with spatial kernel-derived regressors calculated from the target's travel-time neighborhood.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Hybrid spatial-kernel + ARIMA modeling (SpX-ARIMAX)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Combine spatial kernel regressors (weighted average and local stddev computed over travel-time-defined neighborhoods, possibly at multiple radii and expanded with forecast horizon) as exogenous regressors inside an ARIMAX model for the target node. ARIMA orders (p, d, q) are chosen (Hyndman-Khandakar algorithm used) for target-series stationarized residuals while spatial regressors capture cross-node information.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / hybrid modeling procedure</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>computer vision (image/video spatial filtering) and time-series analysis (ARIMA)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>spatiotemporal urban traffic forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>hybrid approach combining with existing methods</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Spatial kernels adapted to road-network neighborhoods (travel-time-based radii); kernel outputs used as exogenous regressors in ARIMA rather than as image filters; ARIMA hyperparameters automated per-node using time-series selection algorithms; neighborhoods allowed to expand with forecast horizon.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful — achieved the best forecasting accuracy among transferred models in experiments: MAE(h=1)=8.85, MAE(h=2)=9.56, MAE(h=3)=9.91, outperforming SpX-lm/SpX-SVR and comparable or slightly better than sparse VAR (SpVAR) baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Requires historical data at the target node to train ARIMA component; needs careful hyperparameter tuning (ARIMA orders, radii, decay); still relies on chosen kernel types which may not capture all spatial dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Combining temporal modeling strengths of ARIMA with spatial information from kernels leveraged complementary benefits; detrending (background subtraction analogy) improved performance; simple kernels sufficient to capture useful spatial signal.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Per-node historical time series for ARIMA component, travel-time matrix for neighborhoods, cross-validation/rolling-window for hyperparameter tuning, and preprocessing (detrending, outlier handling, interpolation).</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>High within traffic forecasting where per-node history exists; transfer to other spatiotemporal domains plausible if neighborhood metric and temporal dynamics are analogous (e.g., environmental sensors), but requires domain-specific tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>hybrid of explicit procedural steps and theoretical principles (time-series + spatial filtering)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e390.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e390.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SpX-SVR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Support Vector Regression with spatial kernel regressors (SpX-SVR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Non-linear regression approach that uses spatial kernel features (weighted average, stddev over travel-time neighborhoods) as inputs to an SVR model to predict traffic flow at a node.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Spatial-kernel based Support Vector Regression</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Compute spatial kernel features for one or more travel-time-based radii and use these features as input to a Support Vector Regression (SVR) model to predict one-step (and iterated multi-step) ahead traffic at a location. Hyperparameters of the SVR and neighborhood radii are selected by cross-validation using rolling windows.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / machine learning regression technique</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>computer vision / image-processing feature extraction + machine learning regression</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>spatiotemporal urban traffic forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Spatial kernels computed on road network neighborhoods (travel time) rather than image patches; features fed to SVR instead of image restoration/regression; radii expanded with forecast horizon; SVR hyperparameters tuned for traffic error metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>moderately successful — outperformed linear SpX-lm (MAE h=1: 10.54 vs 11.27), indicating non-linear spatial relationships; however, SpX-SVR did not reach the accuracy of hybrid SpX-ARIMAX or the best sparse VAR variants (SpVAR).</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Model ignores target node's own temporal history (when used purely with spatial regressors), limiting long-term temporal dependency capture; performance sensitive to SVR parameter tuning and choice of neighborhoods.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Nonlinear modeling capability of SVR captured spatial non-linearities; availability of spatial kernel features and travel-time neighborhoods enabled practical feature creation.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Same as SpX-kernels: travel-time distances, detrended data, rolling-window cross-validation, and selection of radii and SVR hyperparameters.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Generalizable to other networked spatiotemporal forecasting problems where non-linear spatial interactions exist, but success depends on choice of non-linear learner and feature engineering.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps and computational method (applied machine learning)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e390.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e390.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Spectral GCNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Spectral Graph Convolutional Neural Network (GCNN) applied to traffic graphs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Application of spectral graph convolutional neural networks — originally developed for graph-based video/pattern processing — to learn spatiotemporal representations on a road-network Laplacian for multi-step traffic forecasting, combined with pooling and LSTM temporal layers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Spectral graph convolutional neural network (GCNN) with temporal LSTM blocks</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Build a weighted directed graph of road segments with a weight matrix W and compute graph Laplacian; implement spectral graph convolution layers (filters parameterized in spectral domain using the Laplacian) to aggregate global/graph-level structure, followed by pooling and LSTM units to capture temporal dependencies. The study used the Yu et al. reference GCNN architecture (spectral approach) tuned for traffic forecasting and trained for 100 epochs with 3x3 spatial/temporal convolution windows on detrended traffic time series.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / deep learning architecture</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>computer vision / graph neural networks and video prediction research</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>spatiotemporal urban traffic forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context (reference implementation tuned and retrained)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Graph constructed from road-network travel-time weights instead of pixel-grid adjacency; Laplacian-based spectral filters used on traffic Laplacian; architecture combined graph convolution + pooling + LSTM blocks; hyperparameters (look-back interval, decay parameter, learning epochs) tuned by cross-validation; detrended data used analogous to background removal in video.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful — acceptable one-step-ahead MAE (9.77 for h=1) but unstable for longer horizons and produced high RMSE tails (extreme errors): RMSE values much larger than alternative spatiotemporal models for h=2,3 (e.g., RMSE h=3 = 25.95). Performance was inferior in stability compared to SpX-ARIMAX and SpVAR models in this experimental setup.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Possible insufficient look-back window for traffic's longer temporal dependencies (GCNN architectures tuned for video use short frame history); spectral convolution may be less appropriate than spatial/local convolution for traffic; model lacked traffic-specific auxiliary inputs (capacity, weather); sample specificity (arterial roads) may limit performance; expensive training and sensitivity to hyperparameters.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Shared graph-structured nature of video object relationships and road networks; availability of road-network Laplacian and prior spectral GCNN implementations (Yu et al.) eased adaptation; detrending (background subtraction analogy) improved learning.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Graph Laplacian computation from travel-time-weight matrix, sufficient training data, detrended time series, careful tuning of look-back interval and other hyperparameters, computational resources for GCNN training (GPU recommended), and possible inclusion of exogenous features for best results.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Potentially generalizable — GCNNs have been shown elsewhere to work well on different traffic datasets, but success depends on matching convolution paradigm (spectral vs spatial), look-back lengths, and inclusion of domain-specific features; further research required to identify best GCNN variants for traffic.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>computational method and explicit procedural steps (architecture adaptation and training protocol), plus theoretical principles (graph spectral convolution concepts)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e390.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e390.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Detrending (background subtraction)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Detrending / removal of periodic background patterns (analogous to background subtraction in video)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Preprocessing step that removes periodic/seasonal (periodical) patterns from traffic time series, analogous to removing a static background scene in video prediction, focusing modeling on deviations from regular conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Detrending via periodical-pattern subtraction (background removal analogy)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Compute median traffic value per node and per time-of-day interval over a long historical period (first 30 weeks in study) and subtract these periodical patterns from the target data for the forecasting interval. This yields detrended time series representing deviations from regular traffic conditions (analogous to removing static background in video), which are then modeled by downstream algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>data preprocessing technique</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>video processing (background subtraction) and time-series analysis</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>spatiotemporal urban traffic forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application without modification (conceptual transfer adapted to traffic time-series by using per-node periodic medians)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Compute per-node, per-5-minute-interval median from first 30 weeks and subtract from series for final 10-week analysis; used median rather than frame-difference specifics of video due to time-series nature.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful — detrended data improved model training and was preferred for GCNN and all other models in the study; authors explicitly state detrended time series yielded better GCNN performance and were used across models.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Requires sufficiently long historical record to estimate stable periodic patterns; improper detrending can remove relevant signal if seasonal pattern estimation is poor.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Direct analogy between static video background and regular periodic traffic patterns; availability of long historical dataset (30 weeks) enabled robust period pattern estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Long historical record for per-interval median estimation, consistent aggregation interval (5-min used), and prior removal of identified outliers before median computation.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Highly generalizable to other spatiotemporal forecasting tasks with stable periodic components (e.g., energy demand, environmental sensors); requires domain-appropriate period estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps (preprocessing protocol) and interpretive framework (background/deviation separation)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e390.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e390.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Travel-time neighborhood definition</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Travel-time-based spatial neighborhood definition and distance decay weighting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Replacement of image-grid locality with road-network reachable sets defined by uncongested travel time radii and continuous decay weighting (negative exponential or inverse) to define spatial adjacency/weights for kernels, VAR regularization, and graph Laplacian.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Travel-time-based neighborhood and spatial weighting</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Define for each node a local neighborhood as the set of nodes reachable within a travel-time radius r under uncongested conditions. Compute spatial weights using either a negative exponential decay function (Gaussian-like) or inverse decay proportional to 1/distance. Use these neighborhoods and weights for kernel computations, sparse VAR regularization masks (SpVAR-tt), and Laplacian construction for GCNN spectral convolutions.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>data representation / spatial metric adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>adapted from pixel-grid neighborhood concepts in image/video processing and spatial weighting functions (e.g., Gaussian kernels)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>road-network-based spatiotemporal modeling (traffic forecasting)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Neighborhood metric changed from Euclidean/pixel adjacency to travel-time (network) metric; used two decay functions (negative exponential and inverse) and tuned decay parameter; radius values tuned (tested 0, 10, 20, 30 minutes) and allowed to expand with forecast horizon.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful/enabling — travel-time neighborhoods allowed direct use of spatial-kernel and graph-convolution ideas on network data; produced neighborhoods used across SpX, SpVAR, and GCNN models and contributed to competitive forecasting performance (e.g., SpX-ARIMAX and SpVAR results).</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Requires reliable uncongested travel-time estimates and assumes travel times represent meaningful adjacency under varying congestion; choice of radius and decay strongly affects results and must be tuned.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Natural mapping between pixel neighborhood and reachable nodes in travel-time; availability of speed limits and network info allowed travel-time matrix computation.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Road network topology and travel-time estimates under uncongested conditions, parameter tuning infrastructure (cross-validation), and consistent temporal aggregation.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Generalizable to other networked domains where a meaningful travel-time or latency metric exists (e.g., logistics networks, sensor networks); requires domain-specific metric estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps and representational adaptation (conceptual transfer)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting <em>(Rating: 2)</em></li>
                <li>Traffic Graph Convolutional Recurrent Neural Network: A Deep Learning Framework for Network-Scale Traffic Learning and Forecasting <em>(Rating: 2)</em></li>
                <li>Learning Traffic as Images: A Deep Convolutional Neural Network for Large-Scale Transportation Network Speed Prediction <em>(Rating: 2)</em></li>
                <li>Understanding Network Traffic States using Transfer Learning <em>(Rating: 2)</em></li>
                <li>Spatial Interpolation Using Multiple Regression <em>(Rating: 1)</em></li>
                <li>Non-Local Kernel Regression for Image and Video Restoration <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-390",
    "paper_id": "paper-211829879",
    "extraction_schema_id": "extraction-schema-16",
    "extracted_data": [
        {
            "name_short": "SpX-kernels",
            "name_full": "Spatial filtering by predefined kernels (weighted average and standard deviation)",
            "brief_description": "Use of classical image-processing spatial kernels (weighted average smoothing and local standard-deviation edge-detection) adapted as regressors for predicting a road segment's future traffic from its spatial neighborhood.",
            "citation_title": "Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting",
            "mention_or_use": "use",
            "procedure_name": "Spatial filtering by predefined kernels",
            "procedure_description": "Compute local spatial features for each target spatial location by convolving a neighborhood (defined on the road network) with predefined kernels: a spatially weighted average (smoothing / Gaussian-like) and a local standard-deviation (edge/contrast detector). These kernel outputs (for one or more radii) are used as predictors/regressors in a forecasting model. Neighborhoods are defined not by pixel-grid adjacency but by travel-time-based reachable sets; multiple radii (e.g., 10 and 30 min travel time) and an optional horizon-dependent spatial inflation are used so kernel neighborhoods expand with forecast horizon. Kernel values are computed per time step and fed into either linear regression (SpX-lm) or non-linear regression (SpX-SVR).",
            "procedure_type": "computational method / data-analysis technique",
            "source_domain": "computer vision / digital image and video processing",
            "target_domain": "spatiotemporal urban traffic forecasting / transportation engineering",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Neighborhood definition changed from pixel grid to road-network travel-time neighborhoods; kernels applied to traffic-flow values instead of pixel intensities; two radii used simultaneously (local and wider); optional horizon-dependent spatial inflation implemented (neighborhood expands with forecast horizon); kernel outputs used as regressors rather than direct filtering of image intensities.",
            "transfer_success": "partially successful — SpX variants produced reasonable forecasting accuracy but did not beat the best graph-regularized VAR models; quantitative one-step-ahead MAE: SpX-lm = 11.27, SpX-SVR = 10.54 (h=1); compared to ARIMA (9.02) and sparse VAR (8.88–8.92). SpX-ARIMAX (hybrid) achieved MAE = 8.85 (h=1), the best among transferred models.",
            "barriers_encountered": "Kernels are simplistic and ignore temporal history of the target location when used alone; performance depends on appropriate choice of radii and travel-time metric; spatial kernels alone underperform compared to more expressive multivariate/graph models for some horizons.",
            "facilitating_factors": "High-level analogy between image patches and spatial neighborhoods of road network; availability of travel-time matrix and clear definition of neighborhoods; ability to compute kernel features cheaply for many nodes.",
            "contextual_requirements": "Need travel-time distances (or other road-network distance metric) to define neighborhoods, tuning of radii and decay parameters via cross-validation, detrended time series (background subtraction), rolling-window training, and feature computation at required temporal aggregation (5-min used in study).",
            "generalizability": "Moderately generalizable — the kernel-regressor approach can be applied to other traffic networks and other spatiotemporal data with a definable neighborhood metric, but requires retuning of radii/decay and may be limited when temporal history or node-specific features are critical.",
            "knowledge_type": "explicit procedural steps and computational method (algorithmic knowledge)",
            "uuid": "e390.0"
        },
        {
            "name_short": "SpX-ARIMAX",
            "name_full": "Spatial-kernel regressors combined with ARIMA (SpX-ARIMAX)",
            "brief_description": "A hybrid model that augments classical ARIMA time-series forecasting for a target location with spatial kernel-derived regressors calculated from the target's travel-time neighborhood.",
            "citation_title": "Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting",
            "mention_or_use": "use",
            "procedure_name": "Hybrid spatial-kernel + ARIMA modeling (SpX-ARIMAX)",
            "procedure_description": "Combine spatial kernel regressors (weighted average and local stddev computed over travel-time-defined neighborhoods, possibly at multiple radii and expanded with forecast horizon) as exogenous regressors inside an ARIMAX model for the target node. ARIMA orders (p, d, q) are chosen (Hyndman-Khandakar algorithm used) for target-series stationarized residuals while spatial regressors capture cross-node information.",
            "procedure_type": "computational method / hybrid modeling procedure",
            "source_domain": "computer vision (image/video spatial filtering) and time-series analysis (ARIMA)",
            "target_domain": "spatiotemporal urban traffic forecasting",
            "transfer_type": "hybrid approach combining with existing methods",
            "modifications_made": "Spatial kernels adapted to road-network neighborhoods (travel-time-based radii); kernel outputs used as exogenous regressors in ARIMA rather than as image filters; ARIMA hyperparameters automated per-node using time-series selection algorithms; neighborhoods allowed to expand with forecast horizon.",
            "transfer_success": "successful — achieved the best forecasting accuracy among transferred models in experiments: MAE(h=1)=8.85, MAE(h=2)=9.56, MAE(h=3)=9.91, outperforming SpX-lm/SpX-SVR and comparable or slightly better than sparse VAR (SpVAR) baselines.",
            "barriers_encountered": "Requires historical data at the target node to train ARIMA component; needs careful hyperparameter tuning (ARIMA orders, radii, decay); still relies on chosen kernel types which may not capture all spatial dynamics.",
            "facilitating_factors": "Combining temporal modeling strengths of ARIMA with spatial information from kernels leveraged complementary benefits; detrending (background subtraction analogy) improved performance; simple kernels sufficient to capture useful spatial signal.",
            "contextual_requirements": "Per-node historical time series for ARIMA component, travel-time matrix for neighborhoods, cross-validation/rolling-window for hyperparameter tuning, and preprocessing (detrending, outlier handling, interpolation).",
            "generalizability": "High within traffic forecasting where per-node history exists; transfer to other spatiotemporal domains plausible if neighborhood metric and temporal dynamics are analogous (e.g., environmental sensors), but requires domain-specific tuning.",
            "knowledge_type": "hybrid of explicit procedural steps and theoretical principles (time-series + spatial filtering)",
            "uuid": "e390.1"
        },
        {
            "name_short": "SpX-SVR",
            "name_full": "Support Vector Regression with spatial kernel regressors (SpX-SVR)",
            "brief_description": "Non-linear regression approach that uses spatial kernel features (weighted average, stddev over travel-time neighborhoods) as inputs to an SVR model to predict traffic flow at a node.",
            "citation_title": "Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting",
            "mention_or_use": "use",
            "procedure_name": "Spatial-kernel based Support Vector Regression",
            "procedure_description": "Compute spatial kernel features for one or more travel-time-based radii and use these features as input to a Support Vector Regression (SVR) model to predict one-step (and iterated multi-step) ahead traffic at a location. Hyperparameters of the SVR and neighborhood radii are selected by cross-validation using rolling windows.",
            "procedure_type": "computational method / machine learning regression technique",
            "source_domain": "computer vision / image-processing feature extraction + machine learning regression",
            "target_domain": "spatiotemporal urban traffic forecasting",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Spatial kernels computed on road network neighborhoods (travel time) rather than image patches; features fed to SVR instead of image restoration/regression; radii expanded with forecast horizon; SVR hyperparameters tuned for traffic error metrics.",
            "transfer_success": "moderately successful — outperformed linear SpX-lm (MAE h=1: 10.54 vs 11.27), indicating non-linear spatial relationships; however, SpX-SVR did not reach the accuracy of hybrid SpX-ARIMAX or the best sparse VAR variants (SpVAR).",
            "barriers_encountered": "Model ignores target node's own temporal history (when used purely with spatial regressors), limiting long-term temporal dependency capture; performance sensitive to SVR parameter tuning and choice of neighborhoods.",
            "facilitating_factors": "Nonlinear modeling capability of SVR captured spatial non-linearities; availability of spatial kernel features and travel-time neighborhoods enabled practical feature creation.",
            "contextual_requirements": "Same as SpX-kernels: travel-time distances, detrended data, rolling-window cross-validation, and selection of radii and SVR hyperparameters.",
            "generalizability": "Generalizable to other networked spatiotemporal forecasting problems where non-linear spatial interactions exist, but success depends on choice of non-linear learner and feature engineering.",
            "knowledge_type": "explicit procedural steps and computational method (applied machine learning)",
            "uuid": "e390.2"
        },
        {
            "name_short": "Spectral GCNN",
            "name_full": "Spectral Graph Convolutional Neural Network (GCNN) applied to traffic graphs",
            "brief_description": "Application of spectral graph convolutional neural networks — originally developed for graph-based video/pattern processing — to learn spatiotemporal representations on a road-network Laplacian for multi-step traffic forecasting, combined with pooling and LSTM temporal layers.",
            "citation_title": "Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting",
            "mention_or_use": "use",
            "procedure_name": "Spectral graph convolutional neural network (GCNN) with temporal LSTM blocks",
            "procedure_description": "Build a weighted directed graph of road segments with a weight matrix W and compute graph Laplacian; implement spectral graph convolution layers (filters parameterized in spectral domain using the Laplacian) to aggregate global/graph-level structure, followed by pooling and LSTM units to capture temporal dependencies. The study used the Yu et al. reference GCNN architecture (spectral approach) tuned for traffic forecasting and trained for 100 epochs with 3x3 spatial/temporal convolution windows on detrended traffic time series.",
            "procedure_type": "computational method / deep learning architecture",
            "source_domain": "computer vision / graph neural networks and video prediction research",
            "target_domain": "spatiotemporal urban traffic forecasting",
            "transfer_type": "adapted/modified for new context (reference implementation tuned and retrained)",
            "modifications_made": "Graph constructed from road-network travel-time weights instead of pixel-grid adjacency; Laplacian-based spectral filters used on traffic Laplacian; architecture combined graph convolution + pooling + LSTM blocks; hyperparameters (look-back interval, decay parameter, learning epochs) tuned by cross-validation; detrended data used analogous to background removal in video.",
            "transfer_success": "partially successful — acceptable one-step-ahead MAE (9.77 for h=1) but unstable for longer horizons and produced high RMSE tails (extreme errors): RMSE values much larger than alternative spatiotemporal models for h=2,3 (e.g., RMSE h=3 = 25.95). Performance was inferior in stability compared to SpX-ARIMAX and SpVAR models in this experimental setup.",
            "barriers_encountered": "Possible insufficient look-back window for traffic's longer temporal dependencies (GCNN architectures tuned for video use short frame history); spectral convolution may be less appropriate than spatial/local convolution for traffic; model lacked traffic-specific auxiliary inputs (capacity, weather); sample specificity (arterial roads) may limit performance; expensive training and sensitivity to hyperparameters.",
            "facilitating_factors": "Shared graph-structured nature of video object relationships and road networks; availability of road-network Laplacian and prior spectral GCNN implementations (Yu et al.) eased adaptation; detrending (background subtraction analogy) improved learning.",
            "contextual_requirements": "Graph Laplacian computation from travel-time-weight matrix, sufficient training data, detrended time series, careful tuning of look-back interval and other hyperparameters, computational resources for GCNN training (GPU recommended), and possible inclusion of exogenous features for best results.",
            "generalizability": "Potentially generalizable — GCNNs have been shown elsewhere to work well on different traffic datasets, but success depends on matching convolution paradigm (spectral vs spatial), look-back lengths, and inclusion of domain-specific features; further research required to identify best GCNN variants for traffic.",
            "knowledge_type": "computational method and explicit procedural steps (architecture adaptation and training protocol), plus theoretical principles (graph spectral convolution concepts)",
            "uuid": "e390.3"
        },
        {
            "name_short": "Detrending (background subtraction)",
            "name_full": "Detrending / removal of periodic background patterns (analogous to background subtraction in video)",
            "brief_description": "Preprocessing step that removes periodic/seasonal (periodical) patterns from traffic time series, analogous to removing a static background scene in video prediction, focusing modeling on deviations from regular conditions.",
            "citation_title": "Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting",
            "mention_or_use": "use",
            "procedure_name": "Detrending via periodical-pattern subtraction (background removal analogy)",
            "procedure_description": "Compute median traffic value per node and per time-of-day interval over a long historical period (first 30 weeks in study) and subtract these periodical patterns from the target data for the forecasting interval. This yields detrended time series representing deviations from regular traffic conditions (analogous to removing static background in video), which are then modeled by downstream algorithms.",
            "procedure_type": "data preprocessing technique",
            "source_domain": "video processing (background subtraction) and time-series analysis",
            "target_domain": "spatiotemporal urban traffic forecasting",
            "transfer_type": "direct application without modification (conceptual transfer adapted to traffic time-series by using per-node periodic medians)",
            "modifications_made": "Compute per-node, per-5-minute-interval median from first 30 weeks and subtract from series for final 10-week analysis; used median rather than frame-difference specifics of video due to time-series nature.",
            "transfer_success": "successful — detrended data improved model training and was preferred for GCNN and all other models in the study; authors explicitly state detrended time series yielded better GCNN performance and were used across models.",
            "barriers_encountered": "Requires sufficiently long historical record to estimate stable periodic patterns; improper detrending can remove relevant signal if seasonal pattern estimation is poor.",
            "facilitating_factors": "Direct analogy between static video background and regular periodic traffic patterns; availability of long historical dataset (30 weeks) enabled robust period pattern estimation.",
            "contextual_requirements": "Long historical record for per-interval median estimation, consistent aggregation interval (5-min used), and prior removal of identified outliers before median computation.",
            "generalizability": "Highly generalizable to other spatiotemporal forecasting tasks with stable periodic components (e.g., energy demand, environmental sensors); requires domain-appropriate period estimation.",
            "knowledge_type": "explicit procedural steps (preprocessing protocol) and interpretive framework (background/deviation separation)",
            "uuid": "e390.4"
        },
        {
            "name_short": "Travel-time neighborhood definition",
            "name_full": "Travel-time-based spatial neighborhood definition and distance decay weighting",
            "brief_description": "Replacement of image-grid locality with road-network reachable sets defined by uncongested travel time radii and continuous decay weighting (negative exponential or inverse) to define spatial adjacency/weights for kernels, VAR regularization, and graph Laplacian.",
            "citation_title": "Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting",
            "mention_or_use": "use",
            "procedure_name": "Travel-time-based neighborhood and spatial weighting",
            "procedure_description": "Define for each node a local neighborhood as the set of nodes reachable within a travel-time radius r under uncongested conditions. Compute spatial weights using either a negative exponential decay function (Gaussian-like) or inverse decay proportional to 1/distance. Use these neighborhoods and weights for kernel computations, sparse VAR regularization masks (SpVAR-tt), and Laplacian construction for GCNN spectral convolutions.",
            "procedure_type": "data representation / spatial metric adaptation",
            "source_domain": "adapted from pixel-grid neighborhood concepts in image/video processing and spatial weighting functions (e.g., Gaussian kernels)",
            "target_domain": "road-network-based spatiotemporal modeling (traffic forecasting)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Neighborhood metric changed from Euclidean/pixel adjacency to travel-time (network) metric; used two decay functions (negative exponential and inverse) and tuned decay parameter; radius values tuned (tested 0, 10, 20, 30 minutes) and allowed to expand with forecast horizon.",
            "transfer_success": "successful/enabling — travel-time neighborhoods allowed direct use of spatial-kernel and graph-convolution ideas on network data; produced neighborhoods used across SpX, SpVAR, and GCNN models and contributed to competitive forecasting performance (e.g., SpX-ARIMAX and SpVAR results).",
            "barriers_encountered": "Requires reliable uncongested travel-time estimates and assumes travel times represent meaningful adjacency under varying congestion; choice of radius and decay strongly affects results and must be tuned.",
            "facilitating_factors": "Natural mapping between pixel neighborhood and reachable nodes in travel-time; availability of speed limits and network info allowed travel-time matrix computation.",
            "contextual_requirements": "Road network topology and travel-time estimates under uncongested conditions, parameter tuning infrastructure (cross-validation), and consistent temporal aggregation.",
            "generalizability": "Generalizable to other networked domains where a meaningful travel-time or latency metric exists (e.g., logistics networks, sensor networks); requires domain-specific metric estimation.",
            "knowledge_type": "explicit procedural steps and representational adaptation (conceptual transfer)",
            "uuid": "e390.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting",
            "rating": 2,
            "sanitized_title": "spatiotemporal_graph_convolutional_networks_a_deep_learning_framework_for_traffic_forecasting"
        },
        {
            "paper_title": "Traffic Graph Convolutional Recurrent Neural Network: A Deep Learning Framework for Network-Scale Traffic Learning and Forecasting",
            "rating": 2,
            "sanitized_title": "traffic_graph_convolutional_recurrent_neural_network_a_deep_learning_framework_for_networkscale_traffic_learning_and_forecasting"
        },
        {
            "paper_title": "Learning Traffic as Images: A Deep Convolutional Neural Network for Large-Scale Transportation Network Speed Prediction",
            "rating": 2,
            "sanitized_title": "learning_traffic_as_images_a_deep_convolutional_neural_network_for_largescale_transportation_network_speed_prediction"
        },
        {
            "paper_title": "Understanding Network Traffic States using Transfer Learning",
            "rating": 2,
            "sanitized_title": "understanding_network_traffic_states_using_transfer_learning"
        },
        {
            "paper_title": "Spatial Interpolation Using Multiple Regression",
            "rating": 1,
            "sanitized_title": "spatial_interpolation_using_multiple_regression"
        },
        {
            "paper_title": "Non-Local Kernel Regression for Image and Video Restoration",
            "rating": 1,
            "sanitized_title": "nonlocal_kernel_regression_for_image_and_video_restoration"
        }
    ],
    "cost": 0.01558975,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting † Dmitry Pavlyuk
2020. June 2019</p>
<p>Transfer Learning: Video Prediction and Spatiotemporal Urban Traffic Forecasting † Dmitry Pavlyuk</p>
<p>Algorithms
the 6th International Conference on Models and Technologies for Intelligent Transportation Systems (MT-ITS)Cracow, Poland132020. June 201910.3390/a13020039Received: 9 January 2020; Accepted: 11 February 2020;Transport and Telecommunication Institute, LV-1019, Riga, Latvia; Dmitry.Pavlyuk@tsi.lv † This paper is an extended version of our paper published in theurban traffic flowsspatiotemporal modelsdata-drivengraph convolutional neural networksspatial filteringnetwork-wide forecasts
Transfer learning is a modern concept that focuses on the application of ideas, models, and algorithms, developed in one applied area, for solving a similar problem in another area. In this paper, we identify links between methodologies in two fields: video prediction and spatiotemporal traffic forecasting. The similarities of the video stream and citywide traffic data structures are discovered and analogues between historical development and modern states of the methodologies are presented and discussed. The idea of transferring video prediction models to the urban traffic forecasting domain is validated using a large real-world traffic data set. The list of transferred techniques includes spatial filtering by predefined kernels in combination with time series models and spectral graph convolutional artificial neural networks. The obtained models' forecasting performance is compared to the baseline traffic forecasting models: non-spatial time series models and spatially regularized vector autoregression models. We conclude that the application of video prediction models and algorithms for urban traffic forecasting is effective both in terms of observed forecasting accuracy and development, and training efforts. Finally, we discuss problems and obstacles of transferring methodologies and present potential directions for further research.</p>
<p>Introduction</p>
<p>Transfer learning (or domain adaptation) is a modern concept defined as application of principles and models, learned in one setting, for improving solutions in another setting -for example, application of models that developed for video prediction for forecasting of urban traffic flows [1,2]. In a machine learning context, transferring is usually implemented via adaptation of a trained model by transforming the input feature space to match domain inputs or by replacing the final layer of a model to produce domain-specific outputs. For example, a link between popular problems of text and image classification can be created by developing translator functions for converting text-and image-specific features into a common feature set [3]. Another example of transfer learning in image processing is a model (e.g., convolutional neural network) that is trained for the classification of animals and further fine-tuned for the classification of other types of objects [4]. In a more general context, transfer leaning is not limited by the application of pre-trained models in another area, but also extends to the application of general model architectures, widely used in one domain, for solving problems in another domain. The practical advantage of transfer learning is widely acknowledged: application of pre-trained models or carefully tested model architectures allows saving resources for model training. Resources for model training include both computational power and training data set collection (which can be limited in some not-data-rich domains). At the same time, transfer learning may sufficiently improve the scientific process of developing and testing new methodologies; the merging of models and principles from different domains leads to a faster and more focused research process.</p>
<p>One of the key issues for successful transfer learning is the similarity of the output results, input space, and background principles between domains. Although there are several statistical approaches to matching domain-specific features and problems [5], none of them guard against negative transfer effects that appear when information from another domain degrades the performance of a learner from another [1]. Additionally, manual matching of domain-specific features and outputs keep the feature set interpretable, which is highly important for decision makers.</p>
<p>In this paper, we provide successful evidence for merging methodologies of two emerging areas: video prediction and spatiotemporal urban traffic forecasting. Video prediction [6] is a popular problem of computer vision, which is devoted to the generation of future video frames on the base of the previous video stream. Recently, the problem has become extremely popular due to the spreading of autonomous robots and self-driving cars, growing computational power, and methodological advances. Spatiotemporal urban traffic forecasting [7] is another emerging domain, which is focused on the prediction of citywide traffic flows and road network states on the base of historical traffic information on linked roads (spatial dimensions), observed for a specified time period (temporal dimension). The problem of spatiotemporal structure identification and traffic forecasting plays a rising role in transport engineering [8]. We state that, despite different domains, methodologies developed for video prediction and spatiotemporal traffic forecasting and related data structures have a high level of similarity, which allows the transfer of them between domains. Further, we provide a brief overview of the historical development of video prediction and spatiotemporal traffic forecasting methodologies and summarize the links between them. In the experimental part of our study, we consider the transferring of video prediction principles and models to the domain of spatiotemporal traffic forecasting (asymmetric transferring). Several methods of video processing are selected and their performance for urban traffic flow forecasting is demonstrated for a large real-world data set.</p>
<p>Literature Review</p>
<p>Video Prediction Methodology</p>
<p>Video prediction methodology has roots in digital signal and image processing. The key concept of signal processing is filtering, that implements a convolution in temporal or spatial domains with specifically designed kernels [9]. An image (or one frame of a video stream) is usually coded as a bidimensional signal, and a wide range of kernels is developed for its spatial convolution. The list of popular kernels includes the Gaussian kernel for smoothing and restoration, first-and second-order kernels for edge and feature detection, and local adaptive kernels for denoising. In addition, several studies were devoted to the development of data-driven kernels, trained on the basis of temporal information [10,11]. These kernels are widely applied in the practice of image processing and have the perfectly developed theoretical background.</p>
<p>Although convolution with spatial kernels demonstrates good results for image processing, their application to video streams is limited due to the omitting of temporal information-each video frame is considered as an independent image and its segments are predicted using spatial information only. Thus, historically, the problem was mainly formulated not as a pure video prediction, but as image inpainting or as video segment restoration. The three-dimensional (3D) video stream (one temporal and two spatial dimensions) has a rich data structure that can be used for the detection of spatiotemporal features like a motion. At the same time, the processing and prediction of multivariate signals require significant computational power and advanced methodologies, hence, the video prediction problem was not closely addressed until the early 2000s. The development of artificial neural networks (ANN) and hardware improvements contributed to advances of video prediction-Sutskever et al. [12] applied a temporal restricted Boltzmann machine for video denoising, and Verma utilized a feed-forward ANN architecture [13] for pixel-wise video prediction. The input space for every pixel in the latter model included values of immediate vertical and horizontal neighbors for one or two temporal lags, so technically the model was based on datadriven spatiotemporal convolution kernels. Obviously, the simple architecture of a feed-forward ANN did not allow learning long-term temporal dependencies and complex spatial patterns.</p>
<p>The motion of objects is a practically important spatiotemporal pattern that needs to be recognized for video prediction. Global spatial kernels, applied to all pixels of a video frame, will not be able to learn object-specific movements, hence, several enhancements were introduced to capture the motion. Optical flow [14] is an approach to motion estimation that attempts to calculate a position change for every pixel between two consecutive video frames using differential methods. Due to the aperture problem, the solution of optical flow equations is not unique and usually requires additional conditions (e.g., phase correlation). Despite quite strict preconditions (constant brightness of pixels and smooth transitions), the optical flow method demonstrated good performance for the next-frame video prediction [15,16]. Later, the approach was enhanced by the incorporation of a physical model of the observed process. In many practical applications, the video stream represents a natural process that follows physical laws-for example, satellite imagery represents meteorological processes like cyclone movements and can be used for weather forecasting. The background process can be described by a physical model of fluids, based on advection and Navier-Stokes equations, which help to discover spatiotemporal patterns of the video stream's points and regions. Although the assumption on the presence of a physical theory behind the video stream lacks generalization capabilities due to significant specifics of the domain, this approach is widely used as a baseline for video prediction in other domains.</p>
<p>The recent advances of deep learning models allowed for the reduction of assumptions on background processes for video prediction and learning spatiotemporal patterns directly from data. Mainly, image processing is associated with convolutional ANN (CNN), which simultaneously train multiple spatial kernels for feature extraction. Several consecutive layers of trained spatial kernels are supplemented by pooling layers for dimension reduction, rectifier layers for capturing non-linear dependencies, and a fully connected layers for output production. For video processing, CNN architectures were extended for handling temporal dimensions with recurrent ANN architectures. The long short-term memory (LSTM) network is one of recurrent architectures, which, in conjunction with CNN, is widely used for video prediction. The list of developed deep learning models for video prediction includes PredNet [17], MCNet [18], generative adversarial net-based (GAN) [19], dual motion GAN [20], PredRNN [21], among a dozen other architectures. The key problem for ANN architecture development remains the same-the identification of objects and the spatiotemporal patterns of their motion, and the separate prediction of a video background and moving objects.</p>
<p>Classical spatial kernels and CNN architecture exploit the assumption of a fixed number of spatial neighbors for every pixel (usually defined by the grid structure). This assumption is too restrictive for spatiotemporal patterns in video streams-if a video frame contains several moving objects, then pixels that belong to each object are naturally more related to pixels of this object in previous frames than to pixels of other objects (even located within the spatial neighborhood). Thus, the structure of spatiotemporal relationships is better modeled by a graph than by a grid. The spatiotemporal graph contains vertices (individual pixels or regions on sequential video frames) and edges (relationships between vertices). The extension of CNN architecture that implements a convolution on a graph structure is named graph-based convolutional ANN (GCNN) and began emerging in 2019 [22]. Several GCNN architectures were proposed for video prediction: Bhattacharjee and Das [23] suggested an architecture with spatiotemporal graph convolution and the direction attention mechanism; Li et al. [24] developed a GCNN architecture with separate temporal and spatial routing; Shi et al. [25] proposed a two-stream GCNN architecture for skeleton-based motion on video.</p>
<p>Summarizing the historical outline of video prediction methodology, we concluded that the development of algorithms began from predefined spatial convolutions, utilized information from physical background processes, and have come to data-driven deep learning of complex spatial patterns in the form of spatiotemporal graphs.</p>
<p>Spatiotemporal Urban Traffic Forecasting Methodology</p>
<p>The key distinguishing feature of the spatiotemporal approach to urban traffic forecasting is the simultaneous utilization of information on spatial relationships between traffic flow at distant road segments that appear with temporal delays. Special cases of spatiotemporal models include traffic flow over a road network or temporal growing of congestion (usually in the opposite direction to traffic flow). Initially, the appearance of spatiotemporal relationships was explained by the natural features of traffic flow-vehicles observed at an upstream road segment, after a specific time period, will be observed at the downstream one. Later, the reasoning of spatiotemporal dependencies became more complex and now includes the behavior of informed drivers, the supplementary and competitive nature of road segments, and other reasons.</p>
<p>Historically, spatiotemporal urban traffic modeling began with dynamic models of traffic, inherited from the physics of fluids and the kinematic wave theory. Lighthill and Whitham [26] set up an analogy between liquid flows and traffic flows and demonstrated its utility for traffic flow forecasting. Later, using the same analogy, other physical mechanisms were tested for traffic modeling, e.g., Navier-Stokes equations [27]. At the same time, the analogy between flows of particles and vehicles is too restrictive to explain complex traffic phenomena.</p>
<p>From another perspective, a data-driven approach to traffic forecasting was developed on the basis of time series analysis [28]. As the time series models (like autoregressive integrated moving average, ARIMA) utilize temporal information only, their classical specification does not allow for identifying spatiotemporal relationships. Thus, significant efforts were made to enhance time series models with spatial information. In 1984, Okutani and Stephanedes [29] included adjacent roads into the Kalman filter for a given road segment to capture spatiotemporal relationships and utilize this information for forecasting. Despite a significant potential utility of spatiotemporal information, the following significant step in this direction was made in late 1990s only, when advanced time series and machine learning models were applied.</p>
<p>Time series models were enhanced with spatial information in two ways: incorporation of spatial covariates into classical univariate model specifications (e.g., ARIMA with explanatory variables, ARIMAX) and multivariate time series model specifications (vector autoregression, VAR). Williams [30] suggested the ARIMAX model with spatial explanatory variables, defined on the basis of road connectivity (upstream segments) and cross-correlation of traffic flows. Later, several other statistical approaches for the identification of spatial explanatory variables were suggested [31,32]. Another direction of methodological advances, the multivariate time series models, allows for the simultaneous modeling of many road segments and the data-driven identification of spatiotemporal relationships. The classical specification of VAR, the most popular multivariate time series model, is rarely applied to large spatial segments, due to its enormous number of parameters and the potential problem of overfitting. Thus, several sparse specifications of VAR were suggested based on road connectivity [33], cross-correlation [34], adaptive LASSO [35], among others. Drawing a parallel with video processing methodologies, the VAR model in spatial settings represents a linear pixel-specific data-driven spatial kernel, while the sparse VAR model specifications are based on a graph of spatiotemporal dependencies.</p>
<p>Similarly to video prediction, multiple ANN specifications were tested for urban traffic forecasting. The feed-forward ANN specifications were successfully applied to small spatial segments [36,37], but did not work well for large road segments with complex spatiotemporal patterns. Thus, advanced specifications like state-space ANN [38] and time delay ANN [39] were suggested. These specifications required the explicit specification of the spatial or spatiotemporal graph of dependencies. Later, deep learning models were utilized to learn spatiotemporal relationships in a data-driven way. Huang et al. [40] proposed the deep belief network for spatiotemporal feature learning; Cao [41] utilized the tensor-based convolution for model temporal and spatial relationships; and Liang et al. [42] applied the popular GAN architecture.</p>
<p>Recently developed graph-based convolutional ANN architecture quickly found its application in spatiotemporal traffic forecasting. Cui et al. [43] proposed GCNN with a higher order spatial graph convolution and tested its scalability for a citywide road network. Yu et al. [44] applied GCNN with spectral and spatial graph-based convolutions. Zhang et al. [45] extended GCNN by the learning of several kernels for every road segment and weighting them for construction of sparse locally connected networks.</p>
<p>Summarizing the development of spatiotemporal urban traffic forecasting methodologies, we state that the two most popular approaches, multivariate time series and machine learning models, have come to the data-driven learning of spatiotemporal graphs of dependencies, and are used for better forecasting performance and interpretability of solutions.</p>
<p>Transferring Methodologies between Video Prediction and Spatiotemporal Urban Traffic Forecasting</p>
<p>The brief discussion of video prediction and spatiotemporal urban traffic forecasting methodologies, presented above, reveals multiple similarities of data structures, emerging problems, and applied models and algorithms in these areas. We summarized these similarities in Table 1. A high level of data structure similarity between video and citywide traffic flows led to the development and application of similar models and algorithms. All of this creates favorable conditions for transfer learning between these applied areas-from the utilization of model specifications and algorithms, tested in one setting, in another area, to the direct application of pretrained models in both areas. Transfer learning between video prediction and traffic forecasting has significant practical potential. First, a researcher who is working on spatiotemporal traffic forecasting models gains a higher start and higher learning slope by utilizing developed video forecasting models instead of testing a wide set of potential model specifications. Second, there are special cases where both video prediction and traffic flow forecasting are required-for example, a traffic operations center serves city-level traffic forecasting and monitoring video streams from cameras for preventing road accidents, or a vehicle on-board system forecasts traffic flows for routing and predict video streams for autonomous driving. In such cases, it is more commercially attractive to operate and support one model for both tasks instead of having independent models.</p>
<p>Despite the significant advantages of transfer learning in terms of computational resources and scientific efforts, the number of studies at the intersection of video prediction and spatiotemporal urban traffic forecasting is extremely small. In 2017, Ma et al. [46] and Yu et al. [47] represented urban traffic data in the form of images and applied deep learning models, developed for image processing (with convolutional layers and LSTM components), for their forecasting. Ma et al. [46] represented traffic in a linear spatial setting (an arterial road) in the form of a two-dimensional spatiotemporal contour diagram; Yu et al. [47] utilized geographical coordinates of a citywide road network and traffic state color-coding for representing traffic at a specified time period as an image. Krishnakumari et al. [48] also represented traffic data as an image using geographical coordinates and color-coding traffic states, and tested the direct application of pre-trained image processing models for traffic state prediction (the models were fine-tuned after replacing the last fully connected layer of CNN). Finally, Pavlyuk [49] tested different approaches for representing traffic data in a video-like form and for the further application of existing ANN architectures for video prediction.</p>
<p>Methodology</p>
<p>This study is devoted to the validation of the concept of transfer learning from video prediction to spatiotemporal urban traffic forecasting areas. We arbitrarily selected popular methods of image and video processing and tested their performance for traffic flow data against state-of-the-art models.</p>
<p>Let us have spatial locations and as a 1 vector , , , , … , , ′ of traffic values at the spatial location i = 1, …, k during the time period t. We assumed that the one-period spatial structure is provided in the form of the weighted directed graph, where spatial locations are coded into vertices and relationships between them into edges. There is a wide set of approaches to the definition of the spatial structure [8]; in this study, we utilized travel time in uncongested traffic conditions as a primary relationship measure. In addition, we utilized cross-correlation definition of the spatial structure for the state-of-the-art regularized VAR model. We limited the complexity of the spatial structure by defining a local neighborhood for every spatial location i as
, : ,(1)
where is a travel time between spatial locations i and j, is an arbitrary selected radius of the neighborhood. The radius is normally defined as a maximum travel time of a direct flow within the road network (without loops and forward-backward movements). For some model specifications, we also simultaneously considered two neighborhoods of different radii.</p>
<p>There are several approaches for the calculation of spatial weights on the basis of observed distances. In this study, we tested two options, the negative exponential decay function and the inverse decay function / :
, , / , ∈ , , 0, ℎ ,(2)/ , / , 1 , ∈ , , 0, ℎ ,(3)
where is a decay parameter of . The negative exponential decay function corresponds to Gaussian smoothing, widely used for image processing.</p>
<p>Transferred Models</p>
<p>In this study, we tested two approaches of different levels of complexity that are widely used in video processing:</p>
<p></p>
<p>Spatial filtering by predefined kernels (SpX-model), both pure and in combination with the time series model (SpX-ARIMAX), and,  Graph-based convolutional ANN (GCNN).</p>
<p>Models Based on Spatial Kernels</p>
<p>Spatial filtering by predefined kernels is widely used in image processing due to its simplicity and clear results. Dozens of kernels are developed for image smoothing, sharpening, edge detection, interpolation, image inpainting, and other popular tasks. We selected a regression-based technique [10] that uses spatial kernel values as regressors for image inpainting as a base for our model. Following Ohashi and Torgo [10], we selected two spatial kernels for our experiments, weighted average and standard deviation:
, , , , ∈ ,(4)
, ,
1 | , | , , , ∈ ,(5)
The spatially weighted average is a popular kernel for smoothing, while the standard deviation is a variant of edge detection kernels. The key parameter of spatial filtering is a radius of convolution. Smaller radius values correspond to local area characteristics, and larger values to the characteristics of wider areas, and their combination allows the representation of the spatial dynamics of the process. Thus, for our model specification, we simultaneously utilized kernel values for neighborhoods (1) for two radii, and :</p>
<p>, and , . The sample neighborhoods are presented in Figure 1; neighborhood radii are tuned by the cross-validation procedure. Another potential issue with the definition of the spatial neighborhood is related to the forecasting horizon. Mostly, models are trained for one-step-ahead forecasts and further iteratively applied for longer forecasting horizons. Alternatively, models can be trained for a specified forecasting horizon. For the latter approach to longer forecasting horizons, the spatial neighborhood can be defined on the basis of the forecasting horizon value h. Assuming that the acting spatial neighborhood can be wider for longer forecasting horizons, we tested the following specification of expanding spatial neighborhoods: * ℎ</p>
<p>where is a constant speed of neighborhood expansion ( 0 corresponds to constant spatial neighborhood for all forecasting horizons). The resulting set of spatial kernels is defined as:</p>
<p>, , , , , , , , , , , , , , , , ,</p>
<p>Given the set of regressors , , we consider the model to predict the traffic flow:
, g , , , ε ,(8)
where and are the model function and a vector of its parameters, respectively, and ε , is a vector of random terms. Two specifications of functions are tested: linear and non-linear. The nonlinear model specification is implemented using the support vector regression (SVR) [50]. Corresponding specifications are further referred to as SpX-lm (linear) and SpX-SVR (SVR-based model).</p>
<p>Note that SpX-lm and SpX-SVR are based on spatial neighborhoods' states only, and do not include historical information on the spatial location itself. These specifications are fairly restrictive, but allow for transferring models between spatial locations-a model, trained for a spatial location with available historical information, can be applied for the forecasting of traffic flows at another spatial location where the historical information is not available. This approach corresponds to ideas of the cross-region transferring of traffic forecasting models, presented by Lin et al. [51]. In contrast to the mentioned study, our model specification is purely based on traffic data in neighborhoods and does not utilize information on road density, nearby points of interest, and other traffic-specific features.</p>
<p>If historical information on the spatial location is available, then the model specification can be enhanced by combining it with classical time series models. We include spatial regressors , into the popular ARIMA model, obtaining the SpX-ARIMAX model specification:
′ , ′ ,, , , , (9)
where ′ , is a stationarized time series , , p, q are model orders, and , , are model parameters.</p>
<p>Models Based on Graph Convolution</p>
<p>While SpX-model specification corresponds to well-established and widely used spatial filtering techniques for video processing, the following specification is based on one of the most recent techniques of video prediction-the graph convolutional neural networks (GCNN) [22]. One of the key reasons for the success of conventional CNNs is their ability to learn hierarchical patterns and extract high-level features from image and video data. The GCNN architecture extends CNN by introducing the convolution operator for non-Euclidean graph-based spaces. There are two popular approaches to the implementation of graph-based convolutions:</p>
<p> Spectral graph convolution [52], and,  Spatial graph convolution [53].</p>
<p>The spectral graph convolution is based on the spectral graph theory and is calculated via the Laplacian matrix of the graph. Conversely, the spatial graph convolution aggregates information from the local spatial neighborhood of every graph vertex (road segment). Thus, the spectral graph convolution deals with the entire graph are more computationally intensive, while the spatial convolution is local and potentially more effective. In this study, we arbitrarily selected the spectral graph convolution approach for testing.</p>
<p>Let W be the matrix of weights that defines the graph structure, and D be the diagonal matrix introduced as , where is the all-ones vector. Then, the spectral-based graph convolution is defined as [22]. * ,</p>
<p>where is an identity matrix, and is a filter, represented by the trained matrix . Given the graph convolution filter, the architecture of GCNN is similar to classical CNN and includes several sequentially connected convolutional and pooling layers and the final fully connected layer. The general architecture of GCNN is presented in Figure 2. In this study, we utilized the GCNN architecture, developed by Yu et al. [44], as a reference implementation of spectral GCNN and tuned it for our purposes. The resulting architecture includes two sequentially internal blocks of three layers: graph convolution, pooling, and LSTM; other parameters are tuned by cross-validation as described below.</p>
<p>Baseline Models</p>
<p>We utilized several popular traffic forecasting models for the estimation of the comparative performance of the transferred models. The list of baseline models includes the following:</p>
<p></p>
<p>Naïve forecasts,  Conventional ARIMA models,  Conventional VAR models,  Sparse VAR models in two specifications: with sparsity, controlled using travel time or crosscorrelation.</p>
<p>Naïve forecasts and conventional ARIMA models are widely used as univariate (non-spatial) baseline models in traffic forecasting. The conventional VAR model, applied to a vector of traffic values at spatial locations, is a data-driven approach to learn linear spatial relationships between time series:
Φ ,(11)
where Φ is a set of weight matrices for every lag ℎ 1, … , . The conventional VAR specification is extremely flexible and parameter-rich, so for a large dimensionality (citywide traffic forecasting) it suffered from the well-known curse of the dimensionality problem. Sparse VAR specifications, where some coefficients of Φ are forced to be 0, usually demonstrate better forecasting performance [54]. We utilized the sparse specification of VAR, based on local spatial neighborhoods defined above, and introduced it into the model as a set of matrices:
, 1, ∈ , , 0, ℎ ,(12)
Definition of spatial neighborhoods depends on the distance metric . In addition to the travel time-based metric, we utilized the cross-correlation:
, : , , , ,(13)
where is a trained threshold value. Given the set of regularizing matrices , the sparse VAR specification is expressed as
Φ ∘ ,(14)
where Φ ∘ is the entry-wise product of the matrices. Further, we refer the sparse VAR specification based on the travel time definition of spatial neighborhoods as SpVAR-tt, and the specification based on cross-correlations, as SpVAR-cc.</p>
<p>Experimental Results</p>
<p>Data Set</p>
<p>The performance of the discussed models was estimated on the basis of the large real-world data set, obtained from the archive of Minnesota Department of Transportation (MnDoT). The complete data set includes information for 40 weeks (1 January-8 October 2017) from 2676 detectors, deployed in the city center of Minneapolis. Detectors were uniformly distributed over the analyzed roads with a mean distance of 270 m. For calculation purposes, 100 detectors were randomly sampled from the complete data set for further analysis. A map of the case study area with the spatial distribution of the complete data set and the research sample is presented in Figure 3.  Obtained periodical patterns are subtracted from the flow values for the latest 10 weeks of the data set. As a result, we obtained detrended time series that are used for model training and testing. Thus, the models are focused on the forecasting of deviations from regular traffic conditions (in video prediction, this operation corresponds to the removal of a static background scene). </p>
<p>Outliers are identified using detector-and time period-specific interquartile ranges. The selected threshold value is selected as 0.01 and is fairly small, so only wrong observations are filtered out, while real traffic values for congested conditions are kept in place. The identified outliers are marked as missed values.  Linear interpolation is utilized for the imputation of missed values; detectors with more than 4 h of missed values in a row are excluded from the final data set.  100 detectors are randomly sampled from the complete data set for computational reasons.</p>
<p>As a result, the preprocessed data set includes a complete 10-week time series (20160 observations) for 100 detectors that represent deviations from regular traffic conditions. The data set is supplemented by a matrix of travel times between detectors, estimated using acting speed limits.</p>
<p>Spatial characteristics of the research sample are presented in Figure 4.  Figure 4a represents a graph of the spatial neighborhood, constructed for 10-min travel times (unconnected vertices correspond to the entrance points of the research road segment, which are not reachable from other nodes). Figure 4b represents the s-curved distribution of reachable nodes by travel time: percentage of nodes, reachable from a given spatial location within a specified time period under uncongested traffic conditions. The form of the curve closely matches for the complete data set and our research sample, so the characteristics of the sample spatial graph are similar to the complete one. Figure 4c contains a heatmap of the spatial Laplacian matrix, which is used for GCNN convolutions. The graph vertices are ordered by their geographical coordinates for better information on the spatial structure; zero-valued Laplacian rows and columns were excluded from the heatmap for smoother representation of the spatial graph structure.</p>
<p>Hyperparameter Tuning and Forecasting Accuracy</p>
<p>Empirical testing of the research models requires the selection of the performance metric and tuning of the hyperparameters. In this study, we focused on forecasting accuracy as the primary model performance characteristic. The forecasting accuracy is measured using two widely used metrics, mean absolute error (MAE) and root-mean-squared error (RMSE):
1 , , ,(15)1 , , ,(16)
where , is a predicted value for a spatial location i and time point t. The obtained MAE and RMSE values were aggregated by spatial and temporal dimensions, and their mean values used for model comparisons.</p>
<p>The models' hyperparameters were tuned for one-step-ahead forecasting accuracy, while the model performance was compared for longer forecasting horizons as well. We utilized the rolling window cross-validation technique [55] for the estimation of out-of-sample MAE and RMSE values. The list of tuned hyperparameters includes:</p>
<p></p>
<p>Radii of spatial neighborhoods , , and the spatial inflation for SpX-lm, SpX-SVR, and SpX-ARIMAX models;  Spatial weights' definition and distance decay parameter for SpX and GCNN models;  ARIMA orders for conventional ARIMA and SpX-ARIMAX models, tuned by Hyndman and Khandakar's algorithm [56];  Cross-correlation threshold for SpVAR-cc model; </p>
<p>Order p for VAR, SpVAR-tt, and SpVAR-cc models;  Size of the rolling window (the look-back interval) L for all models (gradually increased until the models' forecasting performance metrics are stabilized).</p>
<p>The hyperparameters and their tested sets are summarized in Table 2. The GCNN model was trained for 100 epochs and 3 × 3 windows for spatial and temporal convolutions. In addition, we tested the performance of the GCNN model for detrended and original time series and came to the preference of detrended data, which were also used in all other model specifications.</p>
<p>Estimation Results</p>
<p>The average performance of each model was estimated by the rolling window technique for 10 weeks of data. Given that the first five days were reserved for the look-back interval and the rolling step was selected as one hour ( 12), we trained every model specification for 1560 data subsets and obtained their short-term forecasts (ℎ 3). Further, the optimal set of hyperparameters for every model specification was selected on the basis of the average one-step-ahead forecasting accuracy. Obtained forecasting accuracy metrics for the optimal set of hyperparameters are summarized in Table 3 (model specifications with highest forecasting accuracy are marked by bold).  Table 3 provides average values of forecasting accuracy metrics, which could be misleading due to the significant heterogeneity of results over spatial and temporal dimensions. Figure 5 represents spatial and temporal kernel densities of MAE values for three model specifications: ARIMA, SpX-ARIMAX, and SpX-SVR (corresponding distributions for SpVAR-tt and SpVAR-cc models were omitted due to their high similarity to the SpX-ARIMAX model). </p>
<p>Reproducibility</p>
<p>To ensure the reproducibility of the obtained experimental results, we publicly provided the source codes for all executed routines at http://bit.ly/Algorithms2020 (R language markdown). The repository includes routines for downloading data from Dr. Kwon's archive of MnDoT traffic data [57], data preprocessing and sampling, and all experiments with model specifications. Table 3 and Figure 5 demonstrate the comparative forecasting performance of transferred and baseline models. We observed that the overall short-term forecasting performance of the transferred models was effective and comparable with the values of modern spatiotemporal traffic forecasting models. The non-spatial ARIMA model set up a good baseline for one-step-ahead forecasting performance (MAE = 9.02for h = 1), but its performance was degrading fast for longer forecasting horizons due to its inability to utilize spatial information from neighboring road segments. All spatiotemporal model specifications, except GCNN, demonstrated better stability of performance.</p>
<p>Discussion</p>
<p>The performances of SpX-lm and SpX-SVR models, based on spatial kernels, were the worst among the analyzed spatial model specifications (MAE = 11.27 for SpX-lm and 10.54 for SpX-SVR), but were still reasonable (e.g., better than the performance of the conventional VAR model specification, MAE = 12.61) Although these performance values were not optimal, the SpX-lm and SpX-SVR models had a significant advantage in terms of transferring-their specifications were based purely on the spatial information and did not include temporal information from the analyzed road segment. This means that the obtained models could potentially be transferred to traffic forecasting at spatial locations, where historical information is not available. The SpX-ARIMAX, which includes both temporal and spatial information, demonstrated one of the best performance values among all models (MAE = 8.85). Note that spatial information was included in the SpX-models in a very simple way-by two predefined spatial kernels-and this definition was good enough to successfully compete against the more detailed definition of the spatial structure, applied in SpVARmodels. Comparing SpX-lm and SpX-SVR model specifications, we observed a clear advantage of the SVR-based model, which indicates non-linear patterns of spatial relationships. These non-linearities were partially utilized by the simultaneous usage of two spatial neighborhoods of different radii, r1 and r2. The radii were tuned by cross-validation and set to 10 and 30 min of travel time for all model specifications. They gradually increased with step = 5 or longer forecasting horizons (e.g., for h = 3 the radii were equal to 20 and 40 min, respectively). Spatial and temporal distributions of MAE values, presented in Figure 5, also indicate the advantages of the SpX-model specifications: comparing the right tails of the distributions (extreme forecasting errors), we observed that the SpX-ARIMAX model provided significantly smaller values. For spatial distribution, it means that the SpX-ARIMAX model was appropriate for all detectors in the research area, while the ARIMA model worked worse for some of them. For temporal distribution, the implication was even more important-the SpX-ARIMAX model gave more stable results for all time periods, including free traffic flow at nights, regular traffic conditions during the day, and congested traffic conditions during peak hours. Overall, we concluded that the approach, based on predefined spatial kernels, widely used for image and video processing, works well for spatiotemporal traffic forecasting.</p>
<p>The direct application of the spectral GCNN model for traffic forecasting was not so successful. The performance of the GCNN model was appropriate for one-step-ahead forecasts (MAE = 9.77) but very unstable in terms of extreme error values (RMSE values were significantly higher, given comparable MAE values). There were several possible explanations for these results. First, the conventional GCNN architecture was used for our experiments, so any traffic-specific features were not taken into consideration (e.g., road capacity, weather conditions, etc.). Second, the training process of GCNN was also specific to video prediction and differed from the other models. For example, the effective look-back interval is limited to several previous frames, which is appropriate for video streams, but could be insufficient for traffic data with longer temporal patterns. Third, our results could be sample-specific (arterial roads), as there is a collection of evidence in the literature that indicates that the GCNN model works well for traffic data in different spatial settings [43][44][45].</p>
<p>Finally, the reason could alternatively be related to the spectral convolution of the graph, while another approach, spatial convolution, could be more appropriate for traffic data. The GCNN methodology itself is relatively new; hence, all these hypotheses require additional research.</p>
<p>Transferring ideas, models, and algorithms between applied areas of video prediction and traffic forecasting opens a wide range of future research directions. Methodological advances that are now implemented in these applied areas in parallel, should be merged and tested for data sets of different natures. In this study, we tested only a limited set of video processing ideas and models, while the modern modeling toolbox is rich and many other exiting models could be adopted. We also considered only one transfer direction, from video prediction to traffic forecasting, while the opposite transfer (application of popular traffic forecasting models to video prediction) is also available. Finally, we presented transferring at two deeper levels, utilizing the same ideas and the same model architectures, while upper-level transfer learning and the application of pretrained models in another application area has a huge research potential and practical utility.</p>
<p>Conclusions</p>
<p>This study promoted the idea of transfer learning between video prediction and spatiotemporal urban traffic forecasting areas. The transferring of ideas, algorithms, model structures, and pretrained models is an effective way of methodological enhancement, which allows the saving of computational resources in the practical aspect, and of intellectual and research resources in the scientific aspect. We identified similarities between data structures of video stream and citywide traffic data and discovered close links in historical development and the modern states of video prediction and urban traffic forecasting methodologies. The experimental part of the study was devoted to the application of popular video processing techniques (spatial filtering and convolutional networks) in the traffic forecasting domain. Experiments, executed for the citywide traffic data set, supported our hypothesis on the applicability of video prediction tools for urban traffic data. </p>
<p>Figure 1 .
1Two spatial neighborhoods.</p>
<p>Figure 2 .
2General architecture of graph convolutional neural networks (GCNN).</p>
<p>Figure 3 .
3Case study area-complete data set (blue circles) and research sample (red circles).The original data set includes information on traffic flow volumes, temporarily aggregated by 30-s periods. The executed data preprocessing routines include: Lane detectors' values are aggregated by road.  Values are aggregated in 5-min time intervals, widely used for short-term traffic forecasting.  Median traffic values are calculated for the first 30 weeks for every 5-min time interval and node, and used as periodical patterns of traffic flows.</p>
<p>Figure 4 .
4Spatial graph settings: (a) graph for the 10-min neighborhood; (b) percentage of achievable nodes within specified travel time (min); and (c) spatial graph Laplacian's heat map, ordered by geographical coordinates.</p>
<p>Figure 5 .
5Density of mean absolute error (MAE) values: (a) spatially aggregated and (b) temporarily aggregated. Spatial distributions were calculated by the averaging of the obtained time-specific MAE values by detectors, while temporal distributions were calculated by averaging the detector-specific MAE values over time of the day.</p>
<p>Funding:
The author was financially supported by the specific support objective activity 1.1.1.2. "Post-doctoral Research Aid" (Project id. N. 1.1.1.2/16/I/001) of the Republic of Latvia, funded by the European Regional Development Fund. Dmitry Pavlyuk's research project No. 1.1.1.2/VIAA/1/16/112 "Spatiotemporal urban traffic modelling using big data".</p>
<p>Table 1 .
1Matching video prediction and urban traffic forecasting methodologies.Huge spatial and temporal dimensions (e.g., 1920 × 1080 resolution of 24 frames per second) Huge spatial and temporal dimensions (e.g., thousands of road segments in a medium-sized city with 30-s aggregation)Physics of observed process (e.g., optical flow models)Feature 
Video Prediction 
Spatiotemporal Urban Traffic Forecasting 
Data structure 
Observation 
Pixel 
Road segment 
Spatial setting 
Video frame 
Citywide road network 
Temporal 
setting 
Sequence of video frames 
Sequence of temporally aggregated traffic states </p>
<p>Modeled 
variable </p>
<p>Multiple channels for every pixel 
(e.g., Red, Green, Blue) </p>
<p>Multiple traffic flow characteristics (e.g., flow 
value, speed, occupancy) </p>
<p>Problem 
dimension </p>
<p>Data 
availability 
Data-rich area 
Data-rich area </p>
<p>Dependencies 
Spatiotemporal graph 
Spatiotemporal graph 
Methodology 
Type 
Spatiotemporal 
Spatiotemporal </p>
<p>Forecasting 
features </p>
<p>Separate prediction of stable regions 
(backward scene) and dynamic 
objects (motion) </p>
<p>Separate prediction of normal and abnormal 
traffic conditions (congestion) </p>
<p>Attention 
Dynamic objects (recognition and 
prediction of motion) </p>
<p>Dynamic "objects" (congestion and prediction of 
its growth) 
Physical 
analogies </p>
<p>Analogy with physics of fluids (e.g., kinematic 
macroscopic traffic flow models) 
Potential 
grouping </p>
<p>Patches (stable regions of a video 
frame) </p>
<p>Clusters (road segments with similar traffic 
flows) or reservoirs </p>
<p>Emerging 
approaches 
Graph-based convolutional ANN </p>
<p>Graph-based convolutional ANN; Multivariate 
time series with a graph-based structure of 
dependencies </p>
<p>Table 2 .
2Hyperparameter overview.Hyperparameter 
Symbol 
Tested Values 
Used in Models 
Radii of spatial 
neighborhoods 
, 
[0, 10, 20, 30] 
SpX-lm, SpX-SVR, SpX-ARIMAX </p>
<p>Spatial inflation 
[0, 5] 
SpX-lm, SpX-SVR, SpX-ARIMAX </p>
<p>Spatial weights 
, / 
SpX-lm, SpX-SVR, SpX-ARIMAX, 
GCNN 
Distance decay 
speed for 
[10, 20] 
GCNN </p>
<p>Cross-correlation 
threshold 
[0.1, 0.2, 0.3] 
SpVAR-cc </p>
<p>Order of 
autoregression and 
moving average 
components </p>
<p>p, q </p>
<p>Hyndman and 
Khandakar's algorithm 
[56] </p>
<p>ARIMA, SpX-ARIMAX </p>
<p>Order of 
autoregression 
p 
[1, 3, 6] 
VAR, SpVAR-tt, SpVAR-cc </p>
<p>Look-back interval 
L 
[360, 720, 1440] 
All models </p>
<p>Table 3 .
3Forecasting accuracy of the research models.Model </p>
<p>Calibrated 
Hypermeters' 
Values </p>
<p>MAE by Forecasting Horizon 
RMSE by Forecasting Horizon </p>
<p>0-5 min 
(h = 1) </p>
<p>5-10 min 
(h = 2) </p>
<p>10-15 min 
(h = 3) </p>
<p>0-5 min 
(h = 1) </p>
<p>5-10 min 
(h = 2) </p>
<p>10-15 min 
(h = 3) 
Transferred models </p>
<p>SpX-lm </p>
<p>10 
11.27 
11.68 
11.90 
16.42 
17.04 
17.41 
30 
5 </p>
<p>SpX-SVR </p>
<p>10 
10.54 
10.83 
11.08 
15.78 
16.17 
16.51 
30 
5 </p>
<p>SpX-
ARIMAX </p>
<p>10 </p>
<p>8.85 
9.56 
9.91 
12.54 
13.75 
14.33 
30 
5 </p>
<p>/ </p>
<p>GCNN </p>
<p>/ </p>
<p>9.77 
10.57 
11.16 
18.62 
23.37 
25.95 
Baseline models 
SpVAR-
tt 
-
8.92 
9.42 
9.84 
12.58 
13.40 
14.09 </p>
<p>SpVAR-
cc 
0.1 
8.88 
9.35 
9.80 
12.51 
13.27 
14.02 </p>
<p>VAR 
6 
12.61 
12.66 
12.68 
17.40 
17.57 
17.72 </p>
<p>ARIMA 
detector-
specific p, q 
9.02 
9.80 
10.57 
12.74 
14.09 
15.56 </p>
<h2>Naïve</h2>
<p>16.21 
16.59 
16.83 
25.37 
25.85 
26.26 </p>
<p>© 2020 by the author. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).
Acknowledgments:We thank Taek Kwon for his public archive of MnDoT traffic data[57]. We also thank Yu, Yin, and Zhu for publicly available source codes for the spectral GCNN[44], which we used as a reference implementation.Conflicts of Interest:The authors declare no conflict of interest. The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript, or in the decision to publish the results.
Spatiotemporal Traffic Forecasting as a Video Prediction Problem. D Pavlyuk, Proceedings of the 2019 6th International Conference on Models and Technologies for Intelligent Transportation Systems (MT-ITS). the 2019 6th International Conference on Models and Technologies for Intelligent Transportation Systems (MT-ITS)Cracow, PolandPavlyuk, D. Spatiotemporal Traffic Forecasting as a Video Prediction Problem. In Proceedings of the 2019 6th International Conference on Models and Technologies for Intelligent Transportation Systems (MT-ITS), Cracow, Poland, 5-7 June 2019; pp. 1-7.</p>
<p>A survey of transfer learning. K Weiss, T M Khoshgoftaar, D Wang, J. Big Data. 39Weiss, K.; Khoshgoftaar, T.M.; Wang, D. A survey of transfer learning. J. Big Data 2016, 3, 9.</p>
<p>Towards semantic knowledge propagation from text corpus to web images. G.-J Qi, C Aggarwal, T Huang, Proceedings of the 20th International Conference on World Wide Web-WWW '11. the 20th International Conference on World Wide Web-WWW '11Hyderabad, India; Hyderabad, IndiaACM PressQi, G.-J.; Aggarwal, C.; Huang, T. Towards semantic knowledge propagation from text corpus to web images. In Proceedings of the 20th International Conference on World Wide Web-WWW '11, Hyderabad, India, 28 March-1 April 2011; ACM Press: Hyderabad, India, 2011; pp. 297-306.</p>
<p>Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks. M Oquab, L Bottou, I Laptev, J Sivic, Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition. the 2014 IEEE Conference on Computer Vision and Pattern RecognitionColumbus, OH, USAOquab, M.; Bottou, L.; Laptev, I.; Sivic, J. Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks. In Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition, Columbus, OH, USA, 23-28 June 2014; pp. 1717-1724.</p>
<p>Transfer Learning on Heterogenous Feature Spaces via Spectral Transformation. X Shi, Q Liu, W Fan, P S Yu, R Zhu, Proceedings of the 2010 IEEE International Conference on Data Mining. the 2010 IEEE International Conference on Data MiningSydney, AustraliaShi, X.; Liu, Q.; Fan, W.; Yu, P.S.; Zhu, R. Transfer Learning on Heterogenous Feature Spaces via Spectral Transformation. In Proceedings of the 2010 IEEE International Conference on Data Mining, Sydney, Australia, 13-17 December 2010; pp. 1049-1054.</p>
<p>A M Tekalp, 978-0-13- 399100-0Digital Video Processing. New York, NY, USAPrentice Hall2nd ed.Tekalp, A.M. Digital Video Processing, 2nd ed.; Prentice Hall: New York, NY, USA, 2015; ISBN 978-0-13- 399100-0.</p>
<p>Spatiotemporal traffic forecasting: Review and proposed directions. A Ermagun, D Levinson, Trans. Rev. 38Ermagun, A.; Levinson, D. Spatiotemporal traffic forecasting: Review and proposed directions. Trans. Rev. 2018, 38, 786-814.</p>
<p>Feature selection and extraction in spatiotemporal traffic forecasting: A systematic literature review. D Pavlyuk, Eur. Trans. Res. Rev. 116Pavlyuk, D. Feature selection and extraction in spatiotemporal traffic forecasting: A systematic literature review. Eur. Trans. Res. Rev. 2019, 11, 6.</p>
<p>Digital Filters Design for Signal and Image Processing. M Najim, Najim, M. Digital Filters Design for Signal and Image Processing;</p>
<p>Spatial Interpolation Using Multiple Regression. O Ohashi, L Torgo, Proceedings of the 2012 IEEE 12th International Conference on Data Mining. the 2012 IEEE 12th International Conference on Data MiningBrussels, BelgiumOhashi, O.; Torgo, L. Spatial Interpolation Using Multiple Regression. In Proceedings of the 2012 IEEE 12th International Conference on Data Mining, Brussels, Belgium, 10-13 December 2012; pp. 1044-1049.</p>
<p>Non-Local Kernel Regression for Image and Video Restoration. D Hutchison, T Kanade, J Kittler, J M Kleinberg, F Mattern, J C Mitchell, M Naor, O Nierstrasz, C Pandu Rangan, B Steffen, In Computer Vision-ECCV. Hutchison, D.; Kanade, T.; Kittler, J.; Kleinberg, J.M.; Mattern, F.; Mitchell, J.C.; Naor, M.; Nierstrasz, O.; Pandu Rangan, C.; Steffen, B.; et al. Non-Local Kernel Regression for Image and Video Restoration. In Computer Vision-ECCV 2010;</p>
<p>. K Daniilidis, P Maragos, N Paragios, 978-3-642-15557-4Springer6313BerlinBerlin/Heidelberg, GermanyDaniilidis, K., Maragos, P., Paragios, N., Eds.; Springer: BerlinBerlin/Heidelberg, Germany, 2010; Volume 6313, pp. 566-579; ISBN 978-3-642-15557-4.</p>
<p>Learning Multilevel Distributed Representations for High-Dimensional Sequences. I Sutskever, G Hinton, Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics. the Eleventh International Conference on Artificial Intelligence and StatisticsSan Juan, Puerto RicoSutskever, I.; Hinton, G. Learning Multilevel Distributed Representations for High-Dimensional Sequences. In Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics, San Juan, Puerto Rico, 21-24 March 2007; pp. 548-555.</p>
<p>Future image frame generation using Artificial Neural Network with selected features. N K Verma, Proceedings of the 2012 IEEE Applied Imagery Pattern Recognition Workshop (AIPR). the 2012 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)Washington, DC, USA, 9Verma, N.K. Future image frame generation using Artificial Neural Network with selected features. In Proceedings of the 2012 IEEE Applied Imagery Pattern Recognition Workshop (AIPR), Washington, DC, USA, 9-11 October 2012; pp. 1-8.</p>
<p>Performance of optical flow techniques. J L Barron, D J Fleet, S S Beauchemin, Int. J. Comput. 12Barron, J.L.; Fleet, D.J.; Beauchemin, S.S. Performance of optical flow techniques. Int. J. Comput. Vision 1994, 12, 43-77.</p>
<p>Spatio-Temporal Image Pattern Prediction Method Based on a Physical Model With Time-Varying Optical Flow. H Sakaino, IEEE Trans. Geosci. Remote Sens. 51Sakaino, H. Spatio-Temporal Image Pattern Prediction Method Based on a Physical Model With Time- Varying Optical Flow. IEEE Trans. Geosci. Remote Sens. 2013, 51, 3023-3036.</p>
<p>Shimaila Generation of Future image frames using Adaptive Network Based Fuzzy Inference System on spatiotemporal framework. N K Verma, Proceedings of the 2012 IEEE Applied Imagery Pattern Recognition Workshop (AIPR). the 2012 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)Washington, DC, USA, 9Verma, N.K. Shimaila Generation of Future image frames using Adaptive Network Based Fuzzy Inference System on spatiotemporal framework. In Proceedings of the 2012 IEEE Applied Imagery Pattern Recognition Workshop (AIPR), Washington, DC, USA, 9-11 October 2012; pp. 1-8.</p>
<p>Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning. W Lotter, G Kreiman, D Cox, Proceedings of the 5th International Conference on Learning Representations (ICLR 2017). the 5th International Conference on Learning Representations (ICLR 2017)Toulon, France18Lotter, W.; Kreiman, G.; Cox, D. Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning. In Proceedings of the 5th International Conference on Learning Representations (ICLR 2017), Toulon, France, 24-26 April 2017; p. 18.</p>
<p>Decomposing Motion and Content for Natural Video Sequence Prediction. R Villegas, J Yang, S Hong, X Lin, H Lee, Proceedings of the 5th International Conference on Learning Representations (ICLR 2017). the 5th International Conference on Learning Representations (ICLR 2017)Toulon, France22Villegas, R.; Yang, J.; Hong, S.; Lin, X.; Lee, H. Decomposing Motion and Content for Natural Video Sequence Prediction. In Proceedings of the 5th International Conference on Learning Representations (ICLR 2017), Toulon, France, 24-26 April 2017; p. 22.</p>
<p>Generating Videos with Scene Dynamics. C Vondrick, H Pirsiavash, A Torralba, D D Lee, M Sugiyama, U V Luxburg, I Guyon, R Garnett, Advances in Neural Information Processing Systems 29. NY, USACurran Associates, Inc.: DakisVondrick, C.; Pirsiavash, H.; Torralba, A. Generating Videos with Scene Dynamics. In Advances in Neural Information Processing Systems 29; Lee, D.D., Sugiyama, M., Luxburg, U.V., Guyon, I., Garnett, R., Eds.; Curran Associates, Inc.: Dakis, NY, USA, 2016; pp. 613-621.</p>
<p>Dual Motion GAN for Future-Flow Embedded Video Prediction. X Liang, L Lee, W Dai, E P Xing, Proceedings of the 2017 IEEE International Conference on Computer Vision (ICCV). the 2017 IEEE International Conference on Computer Vision (ICCV)Venice, ItalyLiang, X.; Lee, L.; Dai, W.; Xing, E.P. Dual Motion GAN for Future-Flow Embedded Video Prediction. In Proceedings of the 2017 IEEE International Conference on Computer Vision (ICCV), Venice, Italy, 22-29 October 2017; pp. 1762-1770.</p>
<p>Recurrent Neural Networks for Predictive Learning using Spatiotemporal LSTMs. Y Wang, M Long, J Wang, Z Gao, P S Yu, Predrnn, Advances in Neural Information Processing Systems. Wang, Y.; Long, M.; Wang, J.; Gao, Z.; Yu, P.S. PredRNN: Recurrent Neural Networks for Predictive Learning using Spatiotemporal LSTMs. In Advances in Neural Information Processing Systems 30;</p>
<p>. I Guyon, U V Luxburg, S Bengio, H Wallach, R Fergus, S Vishwanathan, R Garnett, Curran Associates, Inc.: DakisNY, USAGuyon, I., Luxburg, U.V., Bengio, S., Wallach, H., Fergus, R., Vishwanathan, S., Garnett, R., Eds.; Curran Associates, Inc.: Dakis, NY, USA, 2017; pp. 879-888.</p>
<p>Graph convolutional networks: A comprehensive review. S Zhang, H Tong, J Xu, R Maciejewski, Comput. Soc. Netw. 611Zhang, S.; Tong, H.; Xu, J.; Maciejewski, R. Graph convolutional networks: A comprehensive review. Comput. Soc. Netw. 2019, 6, 11.</p>
<p>Directional Attention based Video Frame Prediction using Graph Convolutional Networks. P Bhattacharjee, S Das, Proceedings of the 2019 International Joint Conference on Neural Networks (IJCNN). the 2019 International Joint Conference on Neural Networks (IJCNN)Budapest, HungaryBhattacharjee, P.; Das, S. Directional Attention based Video Frame Prediction using Graph Convolutional Networks. In Proceedings of the 2019 International Joint Conference on Neural Networks (IJCNN), Budapest, Hungary, 14-19 July 2019; pp. 1-10.</p>
<p>Spatio-Temporal Graph Routing for Skeleton-Based Action Recognition. B Li, X Li, Z Zhang, F Wu, Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19). the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19)Honolulu, HI, USA33Li, B.; Li, X.; Zhang, Z.; Wu, F. Spatio-Temporal Graph Routing for Skeleton-Based Action Recognition. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19), Honolulu, HI, USA, 27 January-1 February 2019; Volume 33, pp. 8561-8568.</p>
<p>Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action Recognition. L Shi, Y Zhang, J Cheng, H Lu, Proceedings of the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)Long Beach, CA, USA10Shi, L.; Zhang, Y.; Cheng, J.; Lu, H. Two-Stream Adaptive Graph Convolutional Networks for Skeleton- Based Action Recognition. In Proceedings of the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Long Beach, CA, USA, 15-21 June 2019; p. 10.</p>
<p>On kinematic waves II. A theory of traffic flow on long crowded roads. M J Lighthill, G B Whitham, Proc. R. Soc. Lond. Ser. A Math. Phys.Sci. 229Lighthill, M.J.; Whitham, G.B. On kinematic waves II. A theory of traffic flow on long crowded roads. Proc. R. Soc. Lond. Ser. A Math. Phys.Sci. 1955, 229, 317-345.</p>
<p>Navier-Stokes-like equations for traffic flow. R M Velasco, W Marques, Phys. Rev. E. 7246102Velasco, R.M.; Marques, W. Navier-Stokes-like equations for traffic flow. Phys. Rev. E 2005, 72, 046102.</p>
<p>Analysis of freeway traffic time series data by using Box-Jenkins techniques. M S Ahmed, A R Cook, Trans. Res. Rec. 722Ahmed, M.S.; Cook, A.R. Analysis of freeway traffic time series data by using Box-Jenkins techniques. Trans. Res. Rec. 1979, 722, 1-9.</p>
<p>Dynamic prediction of traffic volume through Kalman filtering theory. I Okutani, Y J Stephanedes, Trans. Res. Part B Methodol. 18Okutani, I.; Stephanedes, Y.J. Dynamic prediction of traffic volume through Kalman filtering theory. Trans. Res. Part B Methodol. 1984, 18, 1-11.</p>
<p>Multivariate vehicular traffic flow prediction: Evaluation of ARIMAX modeling. B Williams, Trans. Res. Rec. J. Trans. Res. Board. 1776Williams, B. Multivariate vehicular traffic flow prediction: Evaluation of ARIMAX modeling. Trans. Res. Rec. J. Trans. Res. Board 2001, 1776, 194-200.</p>
<p>Robust causal dependence mining in big data network and its application to traffic flow predictions. L Li, X Su, Y Wang, Y Lin, Z Li, Y Li, Trans. Res. Part C Emerg. Technol. 58Li, L.; Su, X.; Wang, Y.; Lin, Y.; Li, Z.; Li, Y. Robust causal dependence mining in big data network and its application to traffic flow predictions. Trans. Res. Part C Emerg. Technol. 2015, 58, 292-307.</p>
<p>Development and application of the network weight matrix to predict traffic flow for congested and uncongested conditions. A Ermagun, D M Levinson, Environ. Plan. B Urban Anal. City Sci. 46Ermagun, A.; Levinson, D.M. Development and application of the network weight matrix to predict traffic flow for congested and uncongested conditions. Environ. Plan. B Urban Anal. City Sci. 2018, 46, 1684-1705.</p>
<p>Forecasting Traffic Flow Conditions in an Urban Network: Comparison of Multivariate and Univariate Approaches. Y Kamarianakis, P Prastacos, Trans. Res. Rec. J. Trans. Res. Board. 1857Kamarianakis, Y.; Prastacos, P. Forecasting Traffic Flow Conditions in an Urban Network: Comparison of Multivariate and Univariate Approaches. Trans. Res. Rec. J. Trans. Res. Board 2003, 1857, 74-84.</p>
<p>Managing Spatial Graph Dependencies in Large Volumes of Traffic Data for Travel-Time Prediction. A Salamanis, D D Kehagias, C K Filelis-Papadopoulos, D Tzovaras, G A Gravvanis, IEEE Trans. Intell. Trans. Syst. 17Salamanis, A.; Kehagias, D.D.; Filelis-Papadopoulos, C.K.; Tzovaras, D.; Gravvanis, G.A. Managing Spatial Graph Dependencies in Large Volumes of Traffic Data for Travel-Time Prediction. IEEE Trans. Intell. Trans. Syst. 2016, 17, 1678-1687.</p>
<p>Real-time road traffic forecasting using regime-switching spacetime models and adaptive LASSO. Y Kamarianakis, W Shen, L Wynter, Appl. Stoch. Models Bus. Ind. 28Kamarianakis, Y.; Shen, W.; Wynter, L. Real-time road traffic forecasting using regime-switching space- time models and adaptive LASSO. Appl. Stoch. Models Bus. Ind. 2012, 28, 297-315.</p>
<p>The use of neural networks and time series models for short term traffic forecasting: A comparative study. S D Clark, M S Dougherty, H R Kirby, Proceedings of the PTRC European Transport, Highways and Planning 21st Summer Annual Meeting. the PTRC European Transport, Highways and Planning 21st Summer Annual MeetingManchester, UKClark, S.D.; Dougherty, M.S.; Kirby, H.R. The use of neural networks and time series models for short term traffic forecasting: A comparative study. In Proceedings of the PTRC European Transport, Highways and Planning 21st Summer Annual Meeting, Manchester, UK, 13-17 September 1993; pp. 151-162.</p>
<p>Forecasting freeway link travel times with a multilayer feedforward neural network. D Park, L R Rilett, Computer-Aided Civ. Infrastruct. Eng. 14Park, D.; Rilett, L.R. Forecasting freeway link travel times with a multilayer feedforward neural network. Computer-Aided Civ. Infrastruct. Eng. 1999, 14, 357-367.</p>
<p>Accurate freeway travel time prediction with statespace neural networks under missing data. J W C Van Lint, S P Hoogendoorn, H J Van Zuylen, Trans. Res. Part C Emerg. Technol. 13van Lint, J.W.C.; Hoogendoorn, S.P.; van Zuylen, H.J. Accurate freeway travel time prediction with state- space neural networks under missing data. Trans. Res. Part C Emerg. Technol. 2005, 13, 347-369.</p>
<p>Short-Term Traffic Flow Prediction Using Neuro-Genetic Algorithms. B Abdulhai, H Porwal, W Recker, J. Intell. Trans. Syst. 7Abdulhai, B.; Porwal, H.; Recker, W. Short-Term Traffic Flow Prediction Using Neuro-Genetic Algorithms. J. Intell. Trans. Syst. 2002, 7, 3-41.</p>
<p>Deep Architecture for Traffic Flow Prediction: Deep Belief Networks With Multitask Learning. W Huang, G Song, H Hong, K Xie, IEEE Trans. Intell. Trans. Syst. 15Huang, W.; Song, G.; Hong, H.; Xie, K. Deep Architecture for Traffic Flow Prediction: Deep Belief Networks With Multitask Learning. IEEE Trans. Intell. Trans. Syst. 2014, 15, 2191-2201.</p>
<p>Multiple Spatio-temporal Scales Traffic Forecasting Based on Deep Learning Approach. Q Cao, G Ren, D Li, Proceedings of the Compendium of Papers of the Transportation Research Board 97th Annual Meeting. the Compendium of Papers of the Transportation Research Board 97th Annual MeetingWashington, DC, USA18Cao, Q.; Ren, G.; Li, D. Multiple Spatio-temporal Scales Traffic Forecasting Based on Deep Learning Approach. In Proceedings of the Compendium of Papers of the Transportation Research Board 97th Annual Meeting, Washington, DC, USA, 7-11 January 2018; p. 18.</p>
<p>A Deep Generative Adversarial Architecture for Networkwide Spatial-Temporal Traffic State Estimation. Y Liang, Z Cui, Y Tian, H Chen, Y Wang, Proceedings of the Transportation Research Board 97th Annual Meeting. the Transportation Research Board 97th Annual MeetingWashington, DC, USA22Liang, Y.; Cui, Z.; Tian, Y.; Chen, H.; Wang, Y. A Deep Generative Adversarial Architecture for Network- wide Spatial-Temporal Traffic State Estimation. In Proceedings of the Transportation Research Board 97th Annual Meeting, Washington, DC, USA, 7-11 January 2018; p. 22.</p>
<p>Traffic Graph Convolutional Recurrent Neural Network: A Deep Learning Framework for Network-Scale Traffic Learning and Forecasting. Z Cui, K Henrickson, R Ke, Y Wang, 10.1109/TITS.2019.2950416IEEE Trans. Intell. Trans. Syst. 2019Cui, Z.; Henrickson, K.; Ke, R.; Wang, Y. Traffic Graph Convolutional Recurrent Neural Network: A Deep Learning Framework for Network-Scale Traffic Learning and Forecasting. IEEE Trans. Intell. Trans. Syst. 2019, 1-12, doi:10.1109/TITS.2019.2950416.</p>
<p>Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting. B Yu, H Yin, Z Zhu, Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence. the Twenty-Seventh International Joint Conference on Artificial IntelligenceStockholm, SwedenYu, B.; Yin, H.; Zhu, Z. Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting. In Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, Stockholm, Sweden, 13-19 July 2018; pp. 3634-3640.</p>
<p>Kernel-Weighted Graph Convolutional Network: A Deep Learning Approach for Traffic Forecasting. Q Zhang, Q Jin, J Chang, S Xiang, C Pan, Proceedings of the 2018 24th International Conference on Pattern Recognition (ICPR). the 2018 24th International Conference on Pattern Recognition (ICPR)Beijing, ChinaZhang, Q.; Jin, Q.; Chang, J.; Xiang, S.; Pan, C. Kernel-Weighted Graph Convolutional Network: A Deep Learning Approach for Traffic Forecasting. In Proceedings of the 2018 24th International Conference on Pattern Recognition (ICPR), Beijing, China, 20-24 August 2018; pp. 1018-1023.</p>
<p>Learning Traffic as Images: A Deep Convolutional Neural Network for Large-Scale Transportation Network Speed Prediction. X Ma, Z Dai, Z He, J Ma, Y Wang, Y Wang, 17818Ma, X.; Dai, Z.; He, Z.; Ma, J.; Wang, Y.; Wang, Y. Learning Traffic as Images: A Deep Convolutional Neural Network for Large-Scale Transportation Network Speed Prediction. Sensors 2017, 17, 818.</p>
<p>Spatiotemporal Recurrent Convolutional Networks for Traffic Prediction in Transportation Networks. H Yu, Z Wu, S Wang, Y Wang, X Ma, 171501Yu, H.; Wu, Z.; Wang, S.; Wang, Y.; Ma, X. Spatiotemporal Recurrent Convolutional Networks for Traffic Prediction in Transportation Networks. Sensors 2017, 17, 1501.</p>
<p>Understanding Network Traffic States using Transfer Learning. P Krishnakumari, A Perotti, V Pinto, O Cats, H Van Lint, Proceedings of the 2018 21st International Conference on Intelligent Transportation Systems (ITSC). the 2018 21st International Conference on Intelligent Transportation Systems (ITSC)Maui, HI, USAKrishnakumari, P.; Perotti, A.; Pinto, V.; Cats, O.; van Lint, H. Understanding Network Traffic States using Transfer Learning. In Proceedings of the 2018 21st International Conference on Intelligent Transportation Systems (ITSC), Maui, HI, USA, 4-7 November 2018; pp. 1396-1401.</p>
<p>Make It Flat: Multidimensional Scaling of Citywide Traffic Data. D Pavlyuk, RelStat 2019: Reliability and Statistics in Transportation and Communication. Pavlyuk, D. Make It Flat: Multidimensional Scaling of Citywide Traffic Data. In RelStat 2019: Reliability and Statistics in Transportation and Communication;</p>
<p>. I Kabashkin, I Jackiva, O Prentkovskis, Springer International PublishingCham, Switzerlandin pressKabashkin, I., Jackiva, I., Prentkovskis, O., Eds.; Springer International Publishing: Cham, Switzerland, 2020; in press.</p>
<p>Support Vector Regression Machines. H Drucker, C J C Burges, L Kaufman, A J Smola, V Vapnik, Advances in Neural Information Processing Systems 9. Drucker, H.; Burges, C.J.C.; Kaufman, L.; Smola, A.J.; Vapnik, V. Support Vector Regression Machines. In Advances in Neural Information Processing Systems 9;</p>
<p>. M C Mozer, M I Jordan, T Petsche, MIT PressCambridge, MA, USA,Mozer, M.C., Jordan, M.I., Petsche, T., Eds.; MIT Press: Cambridge, MA, USA, 1997; pp. 155-161.</p>
<p>Transfer Learning for Traffic Speed Prediction with Effective Spatiotemporal Features. B Y Lin, F F Xu, E Q Liao, K Q Zhu, Proceedings of the 31st Conference on Neural Information Processing Systems (NIPS 2017). the 31st Conference on Neural Information Processing Systems (NIPS 2017)Long Beach, CA, USA7Lin, B.Y.; Xu, F.F.; Liao, E.Q.; Zhu, K.Q. Transfer Learning for Traffic Speed Prediction with Effective Spatiotemporal Features. In Proceedings of the 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA, 4-9 December 2017; p. 7.</p>
<p>Spectral networks and locally connected networks on graphs. J Bruna, W Zaremba, A Szlam, Y Lecun, Proceedings of the International Conference on Learning Representations (ICLR2014). the International Conference on Learning Representations (ICLR2014)Banff, Canada14Bruna, J.; Zaremba, W.; Szlam, A.; Lecun, Y. Spectral networks and locally connected networks on graphs. In Proceedings of the International Conference on Learning Representations (ICLR2014), Banff, Canada, 14-16 April 2014; p. 14.</p>
<p>Neural Network for Graphs: A Contextual Constructive Approach. A Micheli, IEEE Trans. Neural Netw. 20Micheli, A. Neural Network for Graphs: A Contextual Constructive Approach. IEEE Trans. Neural Netw. 2009, 20, 498-511.</p>
<p>Topology-regularized universal vector autoregression for traffic forecasting in large urban areas. F Schimbinschi, L Moreira-Matias, V X Nguyen, J Bailey, Expert Syst. Appl. 82Schimbinschi, F.; Moreira-Matias, L.; Nguyen, V.X.; Bailey, J. Topology-regularized universal vector autoregression for traffic forecasting in large urban areas. Expert Syst. Appl. 2017, 82, 301-316.</p>
<p>Rolling Analysis of Time Series. E Zivot, J Wang, 978-0-387-27965-7In Modeling Financial Time Series with S-PLUS. SpringerZivot, E.; Wang, J. Rolling Analysis of Time Series. In Modeling Financial Time Series with S-PLUS; Springer: New York, NY, USA, 2006; pp. 313-360; ISBN 978-0-387-27965-7.</p>
<p>Automatic Time Series Forecasting: The forecast Package for R. R J Hyndman, Y Khandakar, 10.18637/jss.v027.i03J. Stat. Softw. 27Hyndman, R.J.; Khandakar, Y. Automatic Time Series Forecasting: The forecast Package for R. J. Stat. Softw. 2008, 27, doi:10.18637/jss.v027.i03.</p>
<p>. T Kwon, Rtmc <em>. Traffic, Data, 12Kwon, T. RTMC </em>. Traffic Data. Available online: http://www.d.umn.edu/~tkwon/TMCdata/TMCarchive.html (accessed on 12 January 2018).</p>            </div>
        </div>

    </div>
</body>
</html>