<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3461 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3461</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3461</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-80.html">extraction-schema-80</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <p><strong>Paper ID:</strong> paper-258866103</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2305.14356v1.pdf" target="_blank">Creativity as Variations on a Theme: Formalizations, Evidence, and Engineered Applications</a></p>
                <p><strong>Paper Abstract:</strong> There are many philosophies and theories on what creativity is and how it works, but one popular idea is that of variations on a theme and intersection of concepts. This literature review explores philosophical proposals of how creativity emerges from variations on a theme, and how formalizations of these proposals in human subject studies and computational methods result in creativity. Specifically, the philosophical idea of intangible clouds of concepts is analyzed with empirical studies of concept representation and mental model formation, and mathematical formalizations of such ideas. Empirical findings on emergent neural activity from neural network combinations are also examined for evidence of novel, emergent ideas from the collision of existing ones. Finally, work on human-AI co-creativity is used as a lens for concept collision and the effectiveness of this model of creativity. This paper also proposes directions for further research in studying creativity as variations on a theme.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3461.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3461.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype theory of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Functional-level theory that concepts are represented around a central prototype defined by a set of characteristic features; category membership and generalization arise from similarity to that prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Is There an Exemplar Theory of Concepts?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented as central tendency/averages of characteristic features (a prototype); membership, typicality, and inference derive from similarity to that prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Psychological phenomena summarized by Murphy (2016) that align with prototype representations: typicality effects, hierarchical structure of concepts, knowledge effects on categorization, and patterns of inductive generalization that are naturally explained by feature-based prototypes.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Prototype models can struggle with accounting for exemplar effects in some categorization tasks and for occasional reliance on specific remembered instances; Murphy notes exemplar influences but argues exemplar recall evidence is weak for concept-level representations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted directly with exemplar theory in Murphy (2016): prototype theory better explains hierarchical structure, knowledge effects, and induction, whereas exemplar models primarily explain some category-learning phenomena but not broader conceptual reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Open questions include how prototypes handle context-dependence and compositionality, individual differences in concept structure, and how prototype representations map to neural substrates; evidence is indirect and comes from behavioral studies rather than direct neural readout.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3461.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3461.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar theory of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Functional-level theory that concepts are represented as collections of stored individual instances (exemplars), and categorization/generalization arise from similarity to stored exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Is There an Exemplar Theory of Concepts?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented by sets of experienced exemplars; new stimuli are categorized by similarity comparisons to stored exemplars rather than to an abstracted prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Behavioral studies showing that salient exemplars can strongly influence categorization judgments and that recently encountered exemplars affect immediate decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Murphy (2016) reports lackluster evidence that people recall specific exemplars to make categorizations at the concept level and argues exemplar models mainly fit category learning phenomena, not the broader functions of concepts (reasoning, communication, conceptual change).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Directly compared to prototype theory: exemplar models explain some categorization effects but fail to account for hierarchical concept structure, knowledge effects, and inductive patterns that prototype (or theory-based) accounts capture.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Paper highlights that exemplar theory may not scale to explain concept use in reasoning and conceptual change; whether an exemplar account can be extended into a full theory of concepts remains unresolved.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3461.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3461.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Implicospheres (concept clouds)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Implicospheres / concept clouds (Hofstadter)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Philosophical functional model describing concepts as vague, high-dimensional 'clouds' of possibilities (with manipulable 'control knobs') whose intersections produce blended or novel concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>METAMAGICAL THEMAS.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>implicosphere (concept clouds)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented as fuzzy, context-sensitive possibility spaces (clouds) with many latent parameters (control knobs) that can be shifted by context; creative ideas arise from intersections/blending of these clouds.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Philosophical argumentation and anecdotal examples in Hofstadter (1982); behavioral and modeling work reviewed in the paper that is consistent with context-dependent, manipulable concept cores (e.g., alignment with prototype theory and mental model revision findings).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Hofstadter's original proposal is acknowledged as vague and lacking direct neuroscientific evidence; the paper notes a need for formalization and empirical grounding because implicospheres are primarily metaphoric.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Presented as compatible with prototype theory (both emphasize feature-centered, continuous variation) and contrasted with purely symbolic or exemplar accounts; later formalizations (Knowledge Geometry) operationalize implicosphere ideas into spatial representations.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Key open questions: how to operationalize implicospheres in neural terms, how intersections produce reliably 'creative' outputs, and how individual differences in control-knobs/filters are realized biologically; current support is indirect and formalization-dependent.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3461.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3461.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Knowledge Geometry</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge Geometry (three-plane spatial representation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A formal geometric model projecting Hofstadter's implicosphere onto three planes (real, conceptual, symbolic) with a cultural/contextual filter to map phenomena into conceptual spaces, enabling operations like reification and deduction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Knowledge Geometry</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>three-plane spatial knowledge representation (Knowledge Geometry)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Functional model that represents knowledge in a geometric space split into real, conceptual, and symbolic planes; a person-dependent cultural filter maps real-world inputs to conceptual representations that can be manipulated and intersected to yield new ideas.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>De Mello and de Carvalho (2015) demonstrate that this geometry can account for processes like reification, intuition, formalization, and interpretation, showing formal alignment with implicosphere metaphors and with behavioral observations of mental-model manipulation.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Model is a formalization but lacks direct neural-level validation; it's a geometric abstraction that may oversimplify how concepts are neurally encoded and how context filters operate biologically.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Frames implicospheres in a spatial, manipulable representation and is presented as compatible with prototype-style feature representations; contrasts with purely symbolic accounts by emphasizing continuous geometric transformations.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Open questions include mapping the planes and cultural filter onto brain mechanisms, empirical tests linking geometric operations to neural activity, and whether the three-plane decomposition captures all relevant cognitive subtleties.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3461.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3461.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Emergent binding / distributed vectors</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Emergent binding in distributed neural-vector representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Functional computational model where concepts are encoded as high-dimensional neural activity vectors and creative combination arises via convolution/binding of these vectors producing novel emergent activity patterns correlated with the 'Aha!' experience.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The AHA! Experience: Creativity through Emergent Binding in Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>distributed neural representations with emergent binding</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented as multidimensional vectors of neural activity; combinations are produced by operations (convolution/binding) on these vectors, yielding emergent patterns that can correspond to novel ideas and subjective discovery signals.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Thagard & Stewart (2010) simulated large populations of neurons, represented concepts as multi-dimensional activity vectors (to reduce stochasticity), and convolved multiple vectors to produce new activity patterns; simulations produced patterns associated with heightened emotion (the Aha! moment), supporting the plausibility of emergent creative binding.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Simulations are abstract and not direct neural recordings; authors acknowledge not every combination is creative, and it's unclear which neural operations map to convolution and how these operations scale to real brain complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasts distributed/neural-vector representations with prior symbolic/compositional models, arguing neural representations facilitate more fluid creative combination; aligns with implicosphere ideas but provides an algorithmic mechanism for binding.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Key open questions: empirical neural validation (recorded neural patterns showing convolution-like binding), identification of neural mechanisms implementing the vector operations, and criteria determining which combinations yield genuinely novel, valuable outcomes.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3461.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3461.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mental models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mental models theory (conceptual development)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Functional cognitive model that individuals construct internally coherent, manipulable mental models of domains which are used for reasoning, simulation, and conceptual change; models are revised with new information to resolve inconsistencies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mental Models in Conceptual Development</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>mental models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts and domain knowledge are represented as internal, structured models that can be mentally simulated and manipulated; conceptual change occurs by revising these models in response to new data and contextual queries.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Vosniadou (2002) developmental studies where children drew and answered generative questions about Earth's shape showed that participants construct and manipulate internal models; adults also revise mental models creatively when faced with inconsistencies, integrating explicit knowledge into models.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Mental models are often inferred from behavior (drawings, explanations) rather than directly observed in neural data; they can produce misconceptions when revisions are partial, and how they relate to prototypical or exemplar representations is not fully specified.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Compatible with prototype-style accounts (both allow manipulable internal structures) but emphasizes simulation and structured representation over purely feature-averaging or exemplar-storage accounts; complements implicosphere ideas by showing mechanistic use of internal models.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How mental models map to neural representations (distributed vectors vs symbolic structures) remains unresolved; scalability to highly creative, expert-level discoveries and inter-individual variability in model structure are open questions.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3461.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e3461.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Symbolic representation (contrast)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Symbolic / compositional representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Traditional functional model in cognitive science where concepts are represented by discrete, language-like symbols and rules for combining them; previous work shows symbolic combination can produce concept combinations but may be less fluid than neural distributed representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The AHA! Experience: Creativity through Emergent Binding in Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>symbolic representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are encoded as discrete symbols or explicit structured representations with syntactic combinatory rules; compositional reasoning proceeds by rule-based manipulation of these symbols.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Symbolic combination has been successful in some computational models of concept combination and high-level reasoning (historical AI and cognitive modeling literature referenced indirectly in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Thagard & Stewart (2010) argue symbolic representations are less conducive to fluid, emergent creative combinations compared to distributed neural-vector methods; symbolic systems may struggle to capture graded similarity and subtle blending.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted with distributed/neural-vector representations in Thagard & Stewart: symbolic approaches can perform explicit compositional operations but may lack the emergent, affect-linked properties (e.g., Aha! signals) produced by vector binding.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to reconcile symbolic and distributed accounts (hybrid architectures), and which aspects of human concept use are best captured by each, remain unresolved; empirical neural correlates favoring one format are indirect.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>METAMAGICAL THEMAS. <em>(Rating: 2)</em></li>
                <li>Is There an Exemplar Theory of Concepts? <em>(Rating: 2)</em></li>
                <li>The AHA! Experience: Creativity through Emergent Binding in Neural Networks <em>(Rating: 2)</em></li>
                <li>Knowledge Geometry <em>(Rating: 2)</em></li>
                <li>Mental Models in Conceptual Development <em>(Rating: 2)</em></li>
                <li>Mixed-initiative co- creativity <em>(Rating: 2)</em></li>
                <li>Plug-and-blend: a framework for plug-and-play controllable story generation with sketches <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3461",
    "paper_id": "paper-258866103",
    "extraction_schema_id": "extraction-schema-80",
    "extracted_data": [
        {
            "name_short": "Prototype theory",
            "name_full": "Prototype theory of concepts",
            "brief_description": "Functional-level theory that concepts are represented around a central prototype defined by a set of characteristic features; category membership and generalization arise from similarity to that prototype.",
            "citation_title": "Is There an Exemplar Theory of Concepts?",
            "mention_or_use": "mention",
            "theory_name": "prototype theory",
            "theory_description": "Concepts are represented as central tendency/averages of characteristic features (a prototype); membership, typicality, and inference derive from similarity to that prototype.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Psychological phenomena summarized by Murphy (2016) that align with prototype representations: typicality effects, hierarchical structure of concepts, knowledge effects on categorization, and patterns of inductive generalization that are naturally explained by feature-based prototypes.",
            "counter_evidence_or_challenges": "Prototype models can struggle with accounting for exemplar effects in some categorization tasks and for occasional reliance on specific remembered instances; Murphy notes exemplar influences but argues exemplar recall evidence is weak for concept-level representations.",
            "comparison_to_other_theories": "Contrasted directly with exemplar theory in Murphy (2016): prototype theory better explains hierarchical structure, knowledge effects, and induction, whereas exemplar models primarily explain some category-learning phenomena but not broader conceptual reasoning.",
            "notable_limitations_or_open_questions": "Open questions include how prototypes handle context-dependence and compositionality, individual differences in concept structure, and how prototype representations map to neural substrates; evidence is indirect and comes from behavioral studies rather than direct neural readout.",
            "uuid": "e3461.0"
        },
        {
            "name_short": "Exemplar theory",
            "name_full": "Exemplar theory of concepts",
            "brief_description": "Functional-level theory that concepts are represented as collections of stored individual instances (exemplars), and categorization/generalization arise from similarity to stored exemplars.",
            "citation_title": "Is There an Exemplar Theory of Concepts?",
            "mention_or_use": "mention",
            "theory_name": "exemplar theory",
            "theory_description": "Concepts are represented by sets of experienced exemplars; new stimuli are categorized by similarity comparisons to stored exemplars rather than to an abstracted prototype.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Behavioral studies showing that salient exemplars can strongly influence categorization judgments and that recently encountered exemplars affect immediate decisions.",
            "counter_evidence_or_challenges": "Murphy (2016) reports lackluster evidence that people recall specific exemplars to make categorizations at the concept level and argues exemplar models mainly fit category learning phenomena, not the broader functions of concepts (reasoning, communication, conceptual change).",
            "comparison_to_other_theories": "Directly compared to prototype theory: exemplar models explain some categorization effects but fail to account for hierarchical concept structure, knowledge effects, and inductive patterns that prototype (or theory-based) accounts capture.",
            "notable_limitations_or_open_questions": "Paper highlights that exemplar theory may not scale to explain concept use in reasoning and conceptual change; whether an exemplar account can be extended into a full theory of concepts remains unresolved.",
            "uuid": "e3461.1"
        },
        {
            "name_short": "Implicospheres (concept clouds)",
            "name_full": "Implicospheres / concept clouds (Hofstadter)",
            "brief_description": "Philosophical functional model describing concepts as vague, high-dimensional 'clouds' of possibilities (with manipulable 'control knobs') whose intersections produce blended or novel concepts.",
            "citation_title": "METAMAGICAL THEMAS.",
            "mention_or_use": "mention",
            "theory_name": "implicosphere (concept clouds)",
            "theory_description": "Concepts are represented as fuzzy, context-sensitive possibility spaces (clouds) with many latent parameters (control knobs) that can be shifted by context; creative ideas arise from intersections/blending of these clouds.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Philosophical argumentation and anecdotal examples in Hofstadter (1982); behavioral and modeling work reviewed in the paper that is consistent with context-dependent, manipulable concept cores (e.g., alignment with prototype theory and mental model revision findings).",
            "counter_evidence_or_challenges": "Hofstadter's original proposal is acknowledged as vague and lacking direct neuroscientific evidence; the paper notes a need for formalization and empirical grounding because implicospheres are primarily metaphoric.",
            "comparison_to_other_theories": "Presented as compatible with prototype theory (both emphasize feature-centered, continuous variation) and contrasted with purely symbolic or exemplar accounts; later formalizations (Knowledge Geometry) operationalize implicosphere ideas into spatial representations.",
            "notable_limitations_or_open_questions": "Key open questions: how to operationalize implicospheres in neural terms, how intersections produce reliably 'creative' outputs, and how individual differences in control-knobs/filters are realized biologically; current support is indirect and formalization-dependent.",
            "uuid": "e3461.2"
        },
        {
            "name_short": "Knowledge Geometry",
            "name_full": "Knowledge Geometry (three-plane spatial representation)",
            "brief_description": "A formal geometric model projecting Hofstadter's implicosphere onto three planes (real, conceptual, symbolic) with a cultural/contextual filter to map phenomena into conceptual spaces, enabling operations like reification and deduction.",
            "citation_title": "Knowledge Geometry",
            "mention_or_use": "mention",
            "theory_name": "three-plane spatial knowledge representation (Knowledge Geometry)",
            "theory_description": "Functional model that represents knowledge in a geometric space split into real, conceptual, and symbolic planes; a person-dependent cultural filter maps real-world inputs to conceptual representations that can be manipulated and intersected to yield new ideas.",
            "level_of_analysis": "functional",
            "supporting_evidence": "De Mello and de Carvalho (2015) demonstrate that this geometry can account for processes like reification, intuition, formalization, and interpretation, showing formal alignment with implicosphere metaphors and with behavioral observations of mental-model manipulation.",
            "counter_evidence_or_challenges": "Model is a formalization but lacks direct neural-level validation; it's a geometric abstraction that may oversimplify how concepts are neurally encoded and how context filters operate biologically.",
            "comparison_to_other_theories": "Frames implicospheres in a spatial, manipulable representation and is presented as compatible with prototype-style feature representations; contrasts with purely symbolic accounts by emphasizing continuous geometric transformations.",
            "notable_limitations_or_open_questions": "Open questions include mapping the planes and cultural filter onto brain mechanisms, empirical tests linking geometric operations to neural activity, and whether the three-plane decomposition captures all relevant cognitive subtleties.",
            "uuid": "e3461.3"
        },
        {
            "name_short": "Emergent binding / distributed vectors",
            "name_full": "Emergent binding in distributed neural-vector representations",
            "brief_description": "Functional computational model where concepts are encoded as high-dimensional neural activity vectors and creative combination arises via convolution/binding of these vectors producing novel emergent activity patterns correlated with the 'Aha!' experience.",
            "citation_title": "The AHA! Experience: Creativity through Emergent Binding in Neural Networks",
            "mention_or_use": "mention",
            "theory_name": "distributed neural representations with emergent binding",
            "theory_description": "Concepts are represented as multidimensional vectors of neural activity; combinations are produced by operations (convolution/binding) on these vectors, yielding emergent patterns that can correspond to novel ideas and subjective discovery signals.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Thagard & Stewart (2010) simulated large populations of neurons, represented concepts as multi-dimensional activity vectors (to reduce stochasticity), and convolved multiple vectors to produce new activity patterns; simulations produced patterns associated with heightened emotion (the Aha! moment), supporting the plausibility of emergent creative binding.",
            "counter_evidence_or_challenges": "Simulations are abstract and not direct neural recordings; authors acknowledge not every combination is creative, and it's unclear which neural operations map to convolution and how these operations scale to real brain complexity.",
            "comparison_to_other_theories": "Contrasts distributed/neural-vector representations with prior symbolic/compositional models, arguing neural representations facilitate more fluid creative combination; aligns with implicosphere ideas but provides an algorithmic mechanism for binding.",
            "notable_limitations_or_open_questions": "Key open questions: empirical neural validation (recorded neural patterns showing convolution-like binding), identification of neural mechanisms implementing the vector operations, and criteria determining which combinations yield genuinely novel, valuable outcomes.",
            "uuid": "e3461.4"
        },
        {
            "name_short": "Mental models",
            "name_full": "Mental models theory (conceptual development)",
            "brief_description": "Functional cognitive model that individuals construct internally coherent, manipulable mental models of domains which are used for reasoning, simulation, and conceptual change; models are revised with new information to resolve inconsistencies.",
            "citation_title": "Mental Models in Conceptual Development",
            "mention_or_use": "mention",
            "theory_name": "mental models",
            "theory_description": "Concepts and domain knowledge are represented as internal, structured models that can be mentally simulated and manipulated; conceptual change occurs by revising these models in response to new data and contextual queries.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Vosniadou (2002) developmental studies where children drew and answered generative questions about Earth's shape showed that participants construct and manipulate internal models; adults also revise mental models creatively when faced with inconsistencies, integrating explicit knowledge into models.",
            "counter_evidence_or_challenges": "Mental models are often inferred from behavior (drawings, explanations) rather than directly observed in neural data; they can produce misconceptions when revisions are partial, and how they relate to prototypical or exemplar representations is not fully specified.",
            "comparison_to_other_theories": "Compatible with prototype-style accounts (both allow manipulable internal structures) but emphasizes simulation and structured representation over purely feature-averaging or exemplar-storage accounts; complements implicosphere ideas by showing mechanistic use of internal models.",
            "notable_limitations_or_open_questions": "How mental models map to neural representations (distributed vectors vs symbolic structures) remains unresolved; scalability to highly creative, expert-level discoveries and inter-individual variability in model structure are open questions.",
            "uuid": "e3461.5"
        },
        {
            "name_short": "Symbolic representation (contrast)",
            "name_full": "Symbolic / compositional representations",
            "brief_description": "Traditional functional model in cognitive science where concepts are represented by discrete, language-like symbols and rules for combining them; previous work shows symbolic combination can produce concept combinations but may be less fluid than neural distributed representations.",
            "citation_title": "The AHA! Experience: Creativity through Emergent Binding in Neural Networks",
            "mention_or_use": "mention",
            "theory_name": "symbolic representation",
            "theory_description": "Concepts are encoded as discrete symbols or explicit structured representations with syntactic combinatory rules; compositional reasoning proceeds by rule-based manipulation of these symbols.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Symbolic combination has been successful in some computational models of concept combination and high-level reasoning (historical AI and cognitive modeling literature referenced indirectly in the paper).",
            "counter_evidence_or_challenges": "Thagard & Stewart (2010) argue symbolic representations are less conducive to fluid, emergent creative combinations compared to distributed neural-vector methods; symbolic systems may struggle to capture graded similarity and subtle blending.",
            "comparison_to_other_theories": "Contrasted with distributed/neural-vector representations in Thagard & Stewart: symbolic approaches can perform explicit compositional operations but may lack the emergent, affect-linked properties (e.g., Aha! signals) produced by vector binding.",
            "notable_limitations_or_open_questions": "How to reconcile symbolic and distributed accounts (hybrid architectures), and which aspects of human concept use are best captured by each, remain unresolved; empirical neural correlates favoring one format are indirect.",
            "uuid": "e3461.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "METAMAGICAL THEMAS.",
            "rating": 2,
            "sanitized_title": "metamagical_themas"
        },
        {
            "paper_title": "Is There an Exemplar Theory of Concepts?",
            "rating": 2,
            "sanitized_title": "is_there_an_exemplar_theory_of_concepts"
        },
        {
            "paper_title": "The AHA! Experience: Creativity through Emergent Binding in Neural Networks",
            "rating": 2,
            "sanitized_title": "the_aha_experience_creativity_through_emergent_binding_in_neural_networks"
        },
        {
            "paper_title": "Knowledge Geometry",
            "rating": 2,
            "sanitized_title": "knowledge_geometry"
        },
        {
            "paper_title": "Mental Models in Conceptual Development",
            "rating": 2,
            "sanitized_title": "mental_models_in_conceptual_development"
        },
        {
            "paper_title": "Mixed-initiative co- creativity",
            "rating": 2,
            "sanitized_title": "mixedinitiative_co_creativity"
        },
        {
            "paper_title": "Plug-and-blend: a framework for plug-and-play controllable story generation with sketches",
            "rating": 2,
            "sanitized_title": "plugandblend_a_framework_for_plugandplay_controllable_story_generation_with_sketches"
        }
    ],
    "cost": 0.01008475,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Creativity as Variations on a Theme: Formalizations, Evidence, and Engineered Applications</p>
<p>Rohan Agarwal roaga@gatech.edu 
Georgia Institute of Technology</p>
<p>Creativity as Variations on a Theme: Formalizations, Evidence, and Engineered Applications</p>
<p>There are many philosophies and theories on what creativity is and how it works, but one popular idea is that of variations on a theme and intersection of concepts. This literature review explores philosophical proposals of how creativity emerges from variations on a theme, and how formalizations of these proposals in human subject studies and computational methods result in creativity. Specifically, the philosophical idea of intangible clouds of concepts is analyzed with empirical studies of concept representation and mental model formation, and mathematical formalizations of such ideas. Empirical findings on emergent neural activity from neural network combinations are also examined for evidence of novel, emergent ideas from the collision of existing ones. Finally, work on human-AI co-creativity is used as a lens for concept collision and the effectiveness of this model of creativity. This paper also proposes directions for further research in studying creativity as variations on a theme.</p>
<p>Introduction</p>
<p>Creativity is often said to be one of the hallmarks that make us human, and it is a trait that serves us every day, from art and music to innovative technology and problem-solving. However, it is not well understood how it works; how does the human brain be creative so effectively?</p>
<p>There are many philosophical ideas on how creativity should be modeled cognitively, but this paper examines the popular proposal that creativity results from variations on a theme. Rather than effortful creation, this model imagines existing concepts subconsciously colliding and overlapping into new, creative ones that give us the creativity we see. There is plenty of anecdotal and philosophical reasoning that supports this idea, as Hofstadter (1982) originally presented. It also serves as a valuable and unique way to think about creativity, originality, and innovation.</p>
<p>However, more formalization and empirical evidence are needed to accept it as a model of creative cognition. To do so, this paper first examines the components of this model and how it imagines mental concepts being represented and how they interact. Then, empirical studies, from both computational and psychological approaches, that examine this form of mental concept representation are reviewed. While these studies formalize concept representation, insight into concept collision is still needed. A study using simulated neural network activity is reviewed to provide evidence for this idea. The field of human-AI co-creativity is also explored as an example and potentially useful application of concept collision, and more generally, this model of creativity. It is crucial to understand how this philosophical perspective on creativity can function and benefit us in a more concrete way. Engineered co-creative applications shed light on the empirical effectiveness of this model and its translation to real-world creativity, not just its correctness with respect to human cognition. Hofstadter (1982) set out to answer the fundamental question of how humans can imagine ideas that do not already exist (i.e., to be creative and original), which are notably often sensible and valuable (like an invention, scientific theory, or a piece of a music). He claimed that creativity stems from variations on existing themes and concepts in the creator's mind. He then justified his claim through a series of thought experiments and anecdotes, which while convincing, underscore the need for scientific evidence to support this model of creativity. First, acknowledging that he lacked a scientific model for what a concept is, he imagined a concept as a box with control knobs used to vary different attributes of the concept. By imagining the consequences of that metaphor for musical compositions and n-dimensional Rubik's Cubes, he concluded that a concept has an infinite number of knobs which reveal themselves depending on the concepts in the mind of the person. He noted how one person can vary a theme to create an idea, but others can still take that idea and vary it infinitely further (Hofstadter, 1982).</p>
<p>Review</p>
<p>Philosophical Proposal</p>
<p>Hofstadter then proposed subconscious slipping and blending between concepts as the source of these variations, changing the mental context and revealing different sets of knobs to the mind. He modeled concepts as vague clouds representing the possible set of variations and slipping as the intersection of multiple clouds. It is also notable that he advocated for using computers to help humans explore these possibility spaces, which he termed "implicospheres" (Hofstadter, 1982). In summary, the model of creativity proposed here is that of subconscious possibility spaces around concepts, built through manipulatable, context-dependent parameters, that intersect to yield new variations and concepts. Hofstadter, however, provides no scientific basis for this representation of concepts or their blending, so formal studies are now presented. Vosniadou (2002) investigated mental models in concept development and reasoning in children, arguing they are a core part of human cognition. She first analyzed their construction by having children draw and answer generative questions about their model of the Earth. Through further generative questioning (e.g., where would you end up if you walked forever?), the children were manipulating their models with imaginary scenarios to answer the questions. It was found that explicit knowledge can integrate with the conceptual model to create novel explanations and further conceptual knowledge. In fact, this is done over time as new information creates new theories in the mind and lets mental models be tweaked and revised.</p>
<p>Scientific Basis for Variations on a Theme as Creativity</p>
<p>Vosniadou also presented other interviews with adults that highlight how when faced with inconsistencies in their mental model, people creatively revise their model to solve the problem (often leading to misconceptions). The existing mental model in mind determines how new information is interpreted and conceptualized (Vosniadou, 2002). These findings support the idea of iteratively tweaking and growing concepts, and the power of concepts in generating novel creative ideas, especially when trying to integrate new information.</p>
<p>However, this does not answer how mental models are represented in the brain. Two main theories of concepts are the prototype theory, where categories are defined based on sets of characteristic features, and the exemplar theory, where categories are defined by encountered instances of the category (Murphy, 2016). Murphy (2016) conducted a literature review on both theories and psychological findings surrounding concepts. While there is strong evidence for salient exemplars influencing categorization, he found lackluster evidence on recalling specific exemplars to decide categorization. Murphy (2016) highlights several phenomena that have prototype explanations but no exemplar explanation, such as hierarchical structure of concepts, knowledge effects, and induction. In fact, since exemplar models in the literature seemed to only apply to category learning, and not concepts (i.e., mental models that can be used for learning, communication, and reasoning, as Vosniadou (2002) demonstrated), he argued that there is no exemplar theory of concepts at all (Murphy, 2016). If the prototype theory, or representing concepts through their features, is more accurate to human cognition, then that aligns well with the proposal of variations on a theme. It implies that concepts really are built around a central set of attributes that, if adjusted, can yield new variations of a concept and even new concepts entirely.</p>
<p>Such a model can also be mathematically formalized. Based on the idea of the implicosphere (Hofstadter, 1982), researchers designed a spatial knowledge representation based on projecting the implicosphere onto three planes: the real, the conceptual, and the symbolic (de Mello and de Carvalho, 2015). A cultural filter, or person-dependent context as Hofstadter (1982) described it, was used to transfer real-world phenomena to the conceptual plane, creating different variations of concepts for different people. The authors also demonstrated how this three-plane model can be used to explain reification (imagining new ideas from abstracted concepts), intuition, formalization, interpretation, and deduction of concepts (de Mello and de Carvalho, 2015). This work formalizes the idea of variations on a theme and demonstrates its usefulness for modeling many creative and cognitive tasks, which include key abilities found to apply to mental models (Vosniadou, 2002) and the prototype theory of concepts (Murphy, 2016).</p>
<p>This formalization shows that this model of creativity can align effectively with empirical findings on the subject.</p>
<p>More than just concept representation, though, how concepts collide to cause creative output is important to this theory of creativity. While concept combination has been successfully shown with symbolic representations in the past, Thagard and Stewart (2010) demonstrated its more generalizable potential with neural activity-in particular, by using convolution to combine vectors represented neural activity patterns. Their neural representations, more than symbolic/verbal ones, facilitated the fluid creative thinking Hofstadter described (Thagard and Stewart, 2010). The authors first devised a multi-dimensional vector representation of neural activity by multiplying the number of neurons to handle their stochasticity. Then they successfully convolved multiple representations of simulated neural activity into new ones, including patterns that correspond to the heightened emotions upon a creative discovery (e.g., an "aha!" or "eureka!" moment). These simulations provided evidence for the intersection of multimodal concepts in the brain leading to original ideas and a sense of creative discovery. The authors also stated that not every combination will be considered "creative," as Hofstadter (1982) also pointed out for the collision of implicospheres. However, the ones accompanied by the emotional experience of discovery likely are what we consider creative (Thagard and Stewart, 2010). This study directly supports the proposal that the collision of concepts in the brain is the source of creativity, not only in the outputted ideas, but also in the sense in which humans emotionally experience it.</p>
<p>Co-Creativity as a Lens</p>
<p>While all these studies provide great insight into the plausibility of this model of creativity, it is also valuable to consider concrete examples of how it enables creativity. Yannakakis et. al. (2014) introduced the paradigm of mixed-initiative co-creativity (MI-CC):</p>
<p>when a human and a computer both proactively collaborate on a creative work, like a story or a video game level. Reframing parts of the possibility space and introducing random stimulus are found to foster the creative process and creative output. The user of a co-creative system often has a diagram or user interface that serves as an extension of their mind, and facilitates creative, lateral thinking (Yannakakis, 2014). Effectively, the AI agent's concept space and the user's concept space collide and interact on this diagram; later works even outline multiple dimensions for such interactions, as if in 3D space, and modularize the different parts of this extended mind (Lin et. al, 2022). Yannakakis et. al. (2014) argued that this interaction (usually suggestions and iterative co-creation) facilitates greater exploration of the possibility space, leading to more novel and valuable creative output. Using a human subject study with a co-creative level design tool called Sentient Sketchbook, analysis of usage of the tool led to the conclusion that MI-CC is useful to human users and strongly guides the creative paths they take (Yannakakis, 2014). While this study is not about creative within the human mind, it demonstrates that when the human mind is effectively extended onto an external diagram, introducing new context, suggesting new ideas and concepts, and exploring the possibility space or variations around a concept lead to superior creative process and output. It is an engineered example that shows that the variations on a theme model is in fact an effective and valuable source of creativity.</p>
<p>In addition, MI-CC takes great advantage of "control knobs" similar to Hofstadter's (1982) metaphor for varying the features on a concept. For example, Lin and Riedl (2021) introduced a control knob system for guiding the story generation of a large language model. By providing a "sketch," a human user can guide the topics of a generated story, sentence by sentence. Not only does this framework allow for control knobs, but also blending of topics and concepts in the generation. Blending fluency and control fidelity were found to be effective through computational analysis, and a human subject study confirmed preference for the generations from this system. The authors envisioned their system being used for co-creative applications, as it was in Lin et. al. (2022). The system is remarkably similar to Hofstadter's (1982) metaphor of control knobs on a black box and blending of concepts to generate creative output. The study proves the possibility and effectiveness of a system based on these proposals.</p>
<p>Discussion</p>
<p>Summary</p>
<p>Variations on a theme as the source of creativity is a common model of how human creativity works, but without empirical evidence, it remained an anecdotal and philosophical one.</p>
<p>This paper presented studies that do provide substantial support for this theory, as originally proposed by Hofstadter (1982). Research into how we form and use mental models (Vosniadou, 2002) showed how they can grow, be manipulated, and used to produce novel, creative ideas in response to new context. Further literature review lent support to the prototype theory of concepts (Murphy, 2016), meaning we form concepts around characteristic features which can vary, similar to Hofstadter's idea of implicospheres (Hofstadter, 1982). While Hofstadter's (1982) theory may seem vague and unscientific, implicospheres and changing context can be used as a basis for geometric knowledge representations that explain core creative processes (de Mello and de Carvalho, 2015).</p>
<p>With evidence for variable features forming concepts and leading to creativity, there is also evidence for the intersection of concepts and its benefits for creativity. Thagard and Stewart (2010) demonstrated that multiple neural activity patterns, representing concepts, can be fluidly interweaved into novel activity and lead to the emotional "aha!" moment we often get upon a creative discovery. The field of mixed-initiative co-creativity also lends great support to the creative usefulness of this idea. Yannakakis et. al. (2014) demonstrated that when humans and AI proactively collaborate on creative tasks, effectively extending the mind of the human and introducing new context, the possible variations are better explored, and creativity is fostered.</p>
<p>This paradigm also makes extensive use of control knobs and blending concepts like what Hofstadter (1982) proposed, as shown by Lin and Riedl's (2021) controllable story generation model. Overall, there is evidence in diverse areas of scientific literature for variations on a theme being the source of human creativity, and an effective method for achieving creativity in engineered applications, including creative AI.</p>
<p>Limitations and Future Research</p>
<p>While there is substantial support, the question of the nature of human creativity is not settled. All the literature reviewed has only been able to answer that question through indirect observation, because it is near impossible to parse the inner workings of the brain otherwise.</p>
<p>There is still no clear-cut answer to how creativity works, and other theories could also be supported with the same studies. Additionally, all the studies that involve creative output-whether learning how the Earth works, new (but illegible) neural patterns, or video game levels-are very small examples of creativity compared to the most grand and valuable examples of scientific discovery, artistry, or innovation. In case creative cognition changes depending on the quality or scale of creative output, future work should aim to produce more valuable creative works or capture insights from those who do (perhaps through a longitudinal study). Some people are also more creative personality-wise, more successfully creative, or have different creative processes and styles. Further investigation is also needed in identifying how cognition varies between people-can one theory apply to everyone and everything we consider creative?</p>
<p>Knowledge Geometry. Flvio De Mello, Roberto Lins De Luis, Carvalho, 10.1142/s0219649215500288Journal of Information &amp; Knowledge Management. 14041550028de Mello, Flvio Luis, and Roberto Lins de Carvalho. "Knowledge Geometry." Journal of Information &amp; Knowledge Management 14, no. 04 (2015): 1550028. https://doi.org/10.1142/s0219649215500288.</p>
<p>. Douglas R &quot; Hofstadter, Metamagical Themas, Scientific American. 2474Hofstadter, Douglas R. "METAMAGICAL THEMAS." Scientific American 247, no. 4 (1982): 20-31. http://www.jstor.org/stable/24966697.</p>
<p>Plug-and-blend: a framework for plug-and-play controllable story generation with sketches. Zhiyu Lin, Mark O Riedl, Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment. the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment17Lin, Zhiyu, and Mark O. Riedl. "Plug-and-blend: a framework for plug-and-play controllable story generation with sketches." In Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, vol. 17, no. 1, pp. 58-65. 2021.</p>
<p>Creative Wand: A System to Study Effects of Communications in Co-creative Settings. Zhiyu Lin, Rohan Agarwal, Mark Riedl, Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment. the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment18Lin, Zhiyu, Rohan Agarwal, and Mark Riedl. "Creative Wand: A System to Study Effects of Communications in Co-creative Settings." In Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, vol. 18, no. 1, pp. 45-52. 2022.</p>
<p>Is There an Exemplar Theory of Concepts?. Gregory L Murphy, 10.3758/s13423-015-0834-3Psychonomic Bulletin &amp; Review. 234Murphy, Gregory L. "Is There an Exemplar Theory of Concepts?" Psychonomic Bulletin &amp; Review 23, no. 4 (2016): 1035-42. https://doi.org/10.3758/s13423-015-0834-3.</p>
<p>The AHA! Experience: Creativity through Emergent Binding in Neural Networks. Paul Thagard, Terrence C Stewart, 10.1111/j.1551-6709.2010.01142.xCognitive Science. 351Thagard, Paul, and Terrence C. Stewart. "The AHA! Experience: Creativity through Emergent Binding in Neural Networks." Cognitive Science 35, no. 1 (2010): 1-33. https://doi.org/10.1111/j.1551-6709.2010.01142.x.</p>
<p>Mental Models in Conceptual Development. Stella Vosniadou, 10.1007/978-1-4615-0605-8_20Model-Based ReasoningVosniadou, Stella. "Mental Models in Conceptual Development." Model-Based Reasoning, 2002, 353-68. https://doi.org/10.1007/978-1-4615-0605-8_20.</p>
<p>Mixed-initiative cocreativity. Georgios N Yannakakis, Antonios Liapis, Constantine Alexopoulos, Yannakakis, Georgios N., Antonios Liapis, and Constantine Alexopoulos. "Mixed-initiative co- creativity." (2014).</p>            </div>
        </div>

    </div>
</body>
</html>