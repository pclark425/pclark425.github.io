<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1940 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1940</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1940</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-43.html">extraction-schema-43</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experiments or studies that measure bloat, diversity, and executability (or related metrics like validity, correctness, or fitness) in genetic programming or evolutionary computation systems, particularly focusing on how these metrics interact and trade off against each other.</div>
                <p><strong>Paper ID:</strong> paper-281420999</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2509.16215v1.pdf" target="_blank">Discovering Software Parallelization Points Using Deep Neural Networks</a></p>
                <p><strong>Paper Abstract:</strong> This study proposes a deep learning-based approach for discovering loops in programming code according to their potential for parallelization. Two genetic algorithm-based code generators were developed to produce two distinct types of code: (i) independent loops, which are parallelizable, and (ii) ambiguous loops, whose dependencies are unclear, making them impossible to define if the loop is parallelizable or not. The generated code snippets were tokenized and preprocessed to ensure a robust dataset. Two deep learning models - a Deep Neural Network (DNN) and a Convolutional Neural Network (CNN) - were implemented to perform the classification. Based on 30 independent runs, a robust statistical analysis was employed to verify the expected performance of both models, DNN and CNN. The CNN showed a slightly higher mean performance, but the two models had a similar variability. Experiments with varying dataset sizes highlighted the importance of data diversity for model performance. These results demonstrate the feasibility of using deep learning to automate the identification of parallelizable structures in code, offering a promising tool for software optimization and performance improvement.</p>
                <p><strong>Cost:</strong> 0.009</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1940.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1940.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experiments or studies that measure bloat, diversity, and executability (or related metrics like validity, correctness, or fitness) in genetic programming or evolutionary computation systems, particularly focusing on how these metrics interact and trade off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DEAP-codegen-GA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DEAP-based genetic algorithm code generator for synthetic Python programs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GA implemented with the DEAP library that evolves complete Python programs encoded as strings to produce two labeled classes (parallelizable/independent loops vs. non-parallelizable/ambiguous loops); used to create a 4,000-sample dataset for downstream deep learning classification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DEAP-based genetic algorithm code generator</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Individuals are linear/string representations where each genome encodes a complete Python program as a string; domain is synthetic code generation / program synthesis targeted at producing loop examples labeled by parallelizability (binary classification). Crossover exchanges code line segments; mutation does small textual edits (variable changes, insertions).</td>
                        </tr>
                        <tr>
                            <td><strong>bloat_metric</strong></td>
                            <td>Indirect size constraints via fitness component s7: number of lines in program; s7 = +1 if lines between 10 and 150, otherwise -1. Also s6 penalizes number of for loops (>6 ⇒ -5). No explicit 'bloat' metric (e.g., average program length over generations) was reported.</td>
                        </tr>
                        <tr>
                            <td><strong>bloat_measurements</strong></td>
                            <td>No measured bloat time-series reported. The GA enforced line-count constraints (10–150 lines) via fitness penalties but the paper gives no numeric trajectory of program size (e.g., average lines per generation).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td>Not explicitly defined or quantified. The paper uses qualitative statements about 'diversity' and uses multiple independent generator runs and a Hall of Fame to retain varied solutions, but does not report a genotypic or phenotypic diversity metric (e.g., uniqueness, edit distance, or behavioral diversity).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_measurements</strong></td>
                            <td>No numerical diversity measurements reported (no percentages or trajectories). The authors state the process 'guarantees the generation of diverse and realistic code samples' but provide no quantified diversity values.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Compilation success component s_comp in fitness: +1 if program compiles successfully, otherwise -5. Compilation success is used as a strong penalty/reward in the fitness function.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_measurements</strong></td>
                            <td>Authors state all selected Hall of Fame individuals (500 best) were validated in VSCode and 'did not present any compilation issues'. The dataset size is 4,000 samples (2,000 per class); the paper implies generation prioritized compilable programs via s_comp but does not give an explicit overall compilation success rate across all generated individuals or per-generation compilation statistics.</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_rate</strong></td>
                            <td>0.9</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_rate</strong></td>
                            <td>0.1</td>
                        </tr>
                        <tr>
                            <td><strong>selection_method</strong></td>
                            <td>Roulette selection (fitness-proportionate selection)</td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td>10,000</td>
                        </tr>
                        <tr>
                            <td><strong>special_operators</strong></td>
                            <td>No novel semantic operators reported. Special design choices that affect trade-offs: (1) fitness-component-based parsimony/constraints (s7 on line counts, s6 loop-count penalty) acting as parsimony pressure; (2) strong compilation penalty (s_comp = -5) to favor executability; (3) Hall of Fame retention of best 500 individuals. Crossover is line-segment exchange; mutation are small textual edits.</td>
                        </tr>
                        <tr>
                            <td><strong>observed_tradeoffs</strong></td>
                            <td>The paper does not present an explicit empirical analysis of trade-offs between bloat, diversity, and executability. It uses fitness penalties to constrain program size and a strong negative score for non-compilation which implies a design trade-off (restrict size ranges to encourage realistic/compilable programs), but no quantified tradeoff (e.g., increasing parsimony decreases diversity or affects executability) is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_dynamics</strong></td>
                            <td>Reported: average, maximum, and minimum fitness improved early and then remained steady over 50 generations across 30 independent runs (Figure 1). No time-series reporting was provided for program size (bloat), diversity metrics, or compilation rate across generations—only fitness curves were shown.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_triangle_constraint</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_to_triangle</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_explanation</strong></td>
                            <td>Design-level explanation only: parsimony-like constraints (fitness penalties on line counts and excessive loops) and a heavy penalty for compilation failure were used to steer evolution toward size-constrained, compilable programs; Hall of Fame retention preserves best individuals. The paper does not experimentally test mechanisms such as introns protecting code or semantic operators preserving executability.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>code generation / program synthesis (Python loops for parallelization labeling)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>Linear/string-based representation (program-as-string); population of program strings evolved with line-segment crossover and small textual mutations</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>DEAP: Distributed Evolutionary Algorithms in Python <em>(Rating: 2)</em></li>
                <li>Pesc -parallel experience for sequential code <em>(Rating: 1)</em></li>
                <li>Generating gpu compiler heuristics using reinforcement learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1940",
    "paper_id": "paper-281420999",
    "extraction_schema_id": "extraction-schema-43",
    "extracted_data": [
        {
            "name_short": "DEAP-codegen-GA",
            "name_full": "DEAP-based genetic algorithm code generator for synthetic Python programs",
            "brief_description": "A GA implemented with the DEAP library that evolves complete Python programs encoded as strings to produce two labeled classes (parallelizable/independent loops vs. non-parallelizable/ambiguous loops); used to create a 4,000-sample dataset for downstream deep learning classification.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "DEAP-based genetic algorithm code generator",
            "system_description": "Individuals are linear/string representations where each genome encodes a complete Python program as a string; domain is synthetic code generation / program synthesis targeted at producing loop examples labeled by parallelizability (binary classification). Crossover exchanges code line segments; mutation does small textual edits (variable changes, insertions).",
            "bloat_metric": "Indirect size constraints via fitness component s7: number of lines in program; s7 = +1 if lines between 10 and 150, otherwise -1. Also s6 penalizes number of for loops (&gt;6 ⇒ -5). No explicit 'bloat' metric (e.g., average program length over generations) was reported.",
            "bloat_measurements": "No measured bloat time-series reported. The GA enforced line-count constraints (10–150 lines) via fitness penalties but the paper gives no numeric trajectory of program size (e.g., average lines per generation).",
            "diversity_metric": "Not explicitly defined or quantified. The paper uses qualitative statements about 'diversity' and uses multiple independent generator runs and a Hall of Fame to retain varied solutions, but does not report a genotypic or phenotypic diversity metric (e.g., uniqueness, edit distance, or behavioral diversity).",
            "diversity_measurements": "No numerical diversity measurements reported (no percentages or trajectories). The authors state the process 'guarantees the generation of diverse and realistic code samples' but provide no quantified diversity values.",
            "executability_metric": "Compilation success component s_comp in fitness: +1 if program compiles successfully, otherwise -5. Compilation success is used as a strong penalty/reward in the fitness function.",
            "executability_measurements": "Authors state all selected Hall of Fame individuals (500 best) were validated in VSCode and 'did not present any compilation issues'. The dataset size is 4,000 samples (2,000 per class); the paper implies generation prioritized compilable programs via s_comp but does not give an explicit overall compilation success rate across all generated individuals or per-generation compilation statistics.",
            "crossover_rate": "0.9",
            "mutation_rate": "0.1",
            "selection_method": "Roulette selection (fitness-proportionate selection)",
            "population_size": "10,000",
            "special_operators": "No novel semantic operators reported. Special design choices that affect trade-offs: (1) fitness-component-based parsimony/constraints (s7 on line counts, s6 loop-count penalty) acting as parsimony pressure; (2) strong compilation penalty (s_comp = -5) to favor executability; (3) Hall of Fame retention of best 500 individuals. Crossover is line-segment exchange; mutation are small textual edits.",
            "observed_tradeoffs": "The paper does not present an explicit empirical analysis of trade-offs between bloat, diversity, and executability. It uses fitness penalties to constrain program size and a strong negative score for non-compilation which implies a design trade-off (restrict size ranges to encourage realistic/compilable programs), but no quantified tradeoff (e.g., increasing parsimony decreases diversity or affects executability) is reported.",
            "temporal_dynamics": "Reported: average, maximum, and minimum fitness improved early and then remained steady over 50 generations across 30 independent runs (Figure 1). No time-series reporting was provided for program size (bloat), diversity metrics, or compilation rate across generations—only fitness curves were shown.",
            "supports_triangle_constraint": null,
            "counterexample_to_triangle": null,
            "mechanism_explanation": "Design-level explanation only: parsimony-like constraints (fitness penalties on line counts and excessive loops) and a heavy penalty for compilation failure were used to steer evolution toward size-constrained, compilable programs; Hall of Fame retention preserves best individuals. The paper does not experimentally test mechanisms such as introns protecting code or semantic operators preserving executability.",
            "domain_type": "code generation / program synthesis (Python loops for parallelization labeling)",
            "representation_type": "Linear/string-based representation (program-as-string); population of program strings evolved with line-segment crossover and small textual mutations",
            "uuid": "e1940.0"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "DEAP: Distributed Evolutionary Algorithms in Python",
            "rating": 2
        },
        {
            "paper_title": "Pesc -parallel experience for sequential code",
            "rating": 1
        },
        {
            "paper_title": "Generating gpu compiler heuristics using reinforcement learning",
            "rating": 1
        }
    ],
    "cost": 0.00866975,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Discovering Software Parallelization Points Using Deep Neural Networks
1 Oct 2025</p>
<p>Izavan Dos 
Federal Rural University of Pernambuco Recife
Brazil</p>
<p>S Correia 
Federal Rural University of Pernambuco Recife
Brazil</p>
<p>Henrique C T Santos henrique.santos@recife.ifpe.edu.br 
Federal Institute of Pernambuco Recife
Brazil</p>
<p>Tiago A E Ferreira 
Federal Rural University of Pernambuco Recife
Brazil</p>
<p>Discovering Software Parallelization Points Using Deep Neural Networks
1 Oct 2025F2AC1E67C64ED0A4809ED65654AE8D37arXiv:2509.16215v2[cs.LG]Software EngineeringMachine LearningProgram AnalysisLoop ClassificationParallelization DetectionDeep Neural NetworksConvolutional Neural NetworksGenetic AlgorithmCode Tokenization
This study proposes a deep learning-based approach for discovering loops in programming code according to their potential for parallelization.Two genetic algorithm-based code generators were developed to produce two distinct types of code: (i) independent loops, which are parallelizable, and (ii) ambiguous loops, whose dependencies are unclear, making them impossible to define if the loop is parallelizable or not.The generated code snippets were tokenized and preprocessed to ensure a robust dataset.Two deep learning models -a Deep Neural Network (DNN) and a Convolutional Neural Network (CNN) -were implemented to perform the classification.Based on 30 independent runs, a robust statistical analysis was employed to verify the expected performance of both models, DNN and CNN.The CNN showed a slightly higher mean performance, but the two models had a similar variability.Experiments with varying dataset sizes highlighted the importance of data diversity for model performance.These results demonstrate the feasibility of using deep learning to automate the identification of parallelizable structures in code, offering a promising tool for software optimization and performance improvement.</p>
<p>Introduction</p>
<p>In today's rapidly evolving technological landscape, optimizing software performance has become more crucial than ever.One of the most effective strategies for achieving this optimization is parallel program-ming.By harnessing the power of parallel computing, developers can significantly enhance the speed and efficiency of their applications [15].</p>
<p>Parallel programming allows tasks to be divided into smaller, independent units that can be executed simultaneously across multiple processing cores or even distributed computing systems.This approach not only reduces execution time but also maximizes resource utilization, resulting in faster and more responsive software.</p>
<p>As a result, the growing demand for faster computing has made parallel programming essential in modern software development.However, identifying code segments that can run in parallel remains a challenge, especially when dealing with legacy systems or code written by others [7].This issue resembles the challenge of debugging, where subtle structural details can greatly impact performance [6].Current methods, whether manual [19] or tool-assisted [7], struggle with: (1) identifying implicit loop dependencies, and (2) scaling to modern codebases.</p>
<p>Machine learning has introduced new methods for analyzing code, demonstrating strong capabilities in pattern recognition and classification [1].Notable examples include the detection of code quality issues [16] and enhancements in software design [5], which closely relate to identifying parallelizable code.This study aims to develop and evaluate an automated system that accurately identifies loops capable of being executed in parallel across various types of code.</p>
<p>One of the most common and effective opportunities for parallelization in software lies in loop structures.When the iterations of a loop are independent-meaning each iteration does not rely on the result of another-they can be executed in parallel rather than sequentially.This makes loops ideal candidates for parallel programming.Accordingly, the core idea of this work is to apply deep neural networks to detect when a loop can be parallelized.</p>
<p>To apply the deep learning algorithms, a dataset of codes was created.We employ a genetic algorithm to generate various code examples, including both parallelizable and non-parallelizable codes, framing the problem as a binary classification task.This approach enables the construction of a training dataset that addresses the need for diversity, as highlighted in prior research [13].Next, we evaluate two types of neural networks: Deep Neural Networks (DNNs), which are effective in learning complex code patterns [8], and Convolutional Neural Networks (CNNs), originally developed for image analysis [12] but adapted here for code analysis, following their application in other non-visual domains [18].</p>
<p>Traditional methods for detecting parallelizable code can be broadly categorized into two approaches.The first involves static code analysis, which uses techniques such as control and data flow analysis to identify dependencies that prevent parallel execution [19].While effective for simple and well-structured programs, these methods often struggle with complex or obfuscated code and may miss implicit dependencies.</p>
<p>The second category includes reinforcement learning (RL)-based techniques, where agents learn to annotate or transform code by interacting with an environment and receiving feedback in the form of rewards [4,3].These approaches are promising and have shown performance gains-for example, Cummins et al. [4] report improvements of up to 14% in compiler heuristics.However, they require large datasets, expert-crafted features, prolonged training times, and integration with real compiler pipelines, making them resource-intensive and less accessible for rapid prototyping.Colbert et al.Colbert et al.[3], for instance, rely on long benchmark executions and complex tuning procedures for GPU optimization using off-policy RL.</p>
<p>In contrast, our approach leverages deep learning models to directly classify loops based on learned structural patterns, offering potential advantages in speed, scalability, and automation.Our models are trained on approximately 4,000 synthetically generated code samples using a genetic algorithm, allowing for broad coverage of parallelizable and non-parallelizable loop structures.Training is completed in a matter of hours on a single GPU, significantly reducing resource requirements compared to RL-based approaches.We also apply Principal Component Analysis (PCA) to reduce input dimensionality [14,9], helping to improve generalization and model performance, as supported by recent studies [10].Our results indicate high classification accuracy and suggest that deep learning may provide meaningful improvements over traditional techniques, particularly for the automated identification of parallelism opportunities.</p>
<p>The remainder of this paper is organized as follows: Section 2 presents the proposed methodology, Section 3 analyzes the experimental results, and Section 4 concludes the paper and outlines future work directions.</p>
<p>METHODOLOGY</p>
<p>Programming Code Generation</p>
<p>To support model training, we implemented a code generator based on a genetic algorithm using the DEAP Python library 1 .Python was used as the programming language for both the generator and the generated examples; however, the approach can also be applied to other languages.</p>
<p>Two separate code generators were implemented: one for producing parallelizable examples (positive class) and another for generating non-parallelizable examples (negative class).Both generators share the same underlying logic and structure, differing only in how loops are constructed.In the positive class, loop variables are not reused within the loop body, ensuring independence; in the negative class, variables are deliberately reused or coupled with dependent assignments, simulating ambiguous or non-parallelizable scenarios.</p>
<p>Each sample includes common programming constructs such as function definitions, variables, operations, conditionals, libraries, and loops.The primary distinction between the two classes lies in the loop structure, as described above.</p>
<p>A genetic algorithm was used to evolve syntactically valid code samples.Each individual in the population encodes a complete Python program as a string.The initial population is randomly generated and then evolves through genetic operations.Crossover is performed by exchanging code line segments between individuals, whereas mutation applies small edits, such as variable modifications or the insertion of print statements.</p>
<p>The fitness function rewards structural features such as the number of functions, the presence of loops and conditionals, variable usage, and successful compilation.Invalid or overly simplistic programs are penalized.Formally, the fitness score f for a given individual program P is defined as:
f (P ) = 7 i=1 s i + s comp (1)
Where each s i is a score assigned to a specific structural feature of P , and s comp is a compilation score that strongly penalizes programs that fail to compile.Specifically, each score is assigned as follows:</p>
<p>• s 1 : number of import statements is between 1 and 12 ⇒ +1, otherwise −1;</p>
<p>• s 2 : number of def functions is between 2 and 8 ⇒ +1, otherwise −1;</p>
<p>• s 3 : number of if conditionals is between 2 and 8 ⇒ +1, otherwise −1;</p>
<p>• s 4 : number of print calls is between 2 and 8 ⇒ +1, otherwise −1;</p>
<p>• s 5 : number of variables is between 2 and 100 ⇒ +1, otherwise −1;</p>
<p>• s 6 : number of for loops is between 1 and 6 ⇒ +1, otherwise −5;</p>
<p>• s 7 : number of lines is between 10 and 150 ⇒ +1, otherwise −1;</p>
<p>• s comp : if the program compiles successfully ⇒ +1, otherwise −5.</p>
<p>The evolution process uses a population of 10,000 individuals over 50 generations, with roulette selection, 0.9 crossover probability, and 0.1 mutation probability.</p>
<p>To demonstrate the optimization progress and the quality of the generated solutions, Figure 1 shows the average, maximum, and minimum fitness values across 30 independent runs of the genetic algorithm.The curves indicate consistent improvement in population fitness early on, even with just 50 generations.Over time, fitness remains steady.For this study, 50 generations were sufficient to generate diverse and well-structured code samples aligned with the defined fitness criteria.In addition to tracking optimization progress, we used the Hall of Fame mechanism provided by the DEAP framework, which stores the best individuals found during the evolutionary process, to retain the 500 best individuals from a total population of 10,000 candidates.All selected individuals were validated in the VSCode2 environment and did not present any compilation issues, which reinforces the robustness of the evolutionary approach and the quality of the generated solutions.</p>
<p>This process guarantees the generation of diverse and realistic code samples for both classes while strictly adhering to the structural constraints imposed by the fitness function.A general overview of the entire genetic programming pipeline, including key stages such as initialization, selection, crossover, and mutation, is illustrated in Figure 2.</p>
<p>Dataset Creation</p>
<p>We generated a dataset of 4000 samples using the code generator:</p>
<p>• 2000 labeled as parallelizable (independent loops).</p>
<p>• 2000 labeled as non-parallelizable (dependent or ambiguous loops).</p>
<p>To build this dataset, the generator for independent codes was executed four times, producing the 2000 samples of the first class.Similarly, the generator for non-parallelizable codes was executed four times to produce the 2000 samples of the second class, resulting in a total of eight generator executions.</p>
<p>After generation, all code samples were tokenized using Python's tokenize library 3 .Each tokensuch as keywords, identifiers, or operators -was mapped to a unique numerical identifier and stored in a JSON dictionary to ensure consistent mapping.Identifiers were reused for repeated tokens.For example, the token "import": 1 indicates that the keyword import was assigned to the identifier 1.</p>
<p>This process yielded a set of integer sequences, each labeled as either class 1 (parallelizable) or class 0 (non-parallelizable).</p>
<p>Data Processing and Preparation</p>
<p>The tokenized sequences were used as input to the neural networks.To reduce dimensionality, we applied Principal Component Analysis (PCA).Models were trained using:</p>
<p>• The full original data (retaining 100% variance).</p>
<p>• Reduced representations preserving 95%, 90%, 85%, and 80% of variance.</p>
<p>We normalized the input data and split it into training (70%), validation (15%), and testing (15%) sets.</p>
<p>DNN Model Architecture</p>
<p>We implemented the deep neural network (DNN) using PyTorch4 .Preliminary experiments were conducted to explore different architectural configurations, and based on the results, the selected architecture was identified as the most promising for the task at hand.The architecture consisted of the following:</p>
<p>• First layer: 128 units, followed by Batch Normalization, ReLU, and Dropout (0.5).</p>
<p>• Second layer: 64 units, Batch Normalization, ReLU, and Dropout (0.5).</p>
<p>• Third layer: 32 units, Batch Normalization, ReLU, and Dropout (0.5).</p>
<p>• Output layer: 1 unit with sigmoid activation (binary classification).</p>
<p>We applied Batch Normalization after each linear layer, followed by ReLU activation and Dropout.The model was trained for 1000 epochs using Binary Cross-Entropy Loss (i.e., BCELoss5 ) and the Adam optimizer [11] with a learning rate of 0.001 and batch size of 4.</p>
<p>We logged training metrics (accuracy and loss) every epoch.After training, we evaluated the model's performance on the test set using accuracy, binary cross-entropy loss, a confusion matrix, and a classification report (precision, recall, F1-score).</p>
<p>CNN Model Architecture</p>
<p>We also implemented a convolutional neural network (CNN) using PyTorch, following the same approach as for the DNN and adopting the configuration that proved most promising in our preliminary tests.The architecture consisted of the following:</p>
<p>• First convolutional layer: 2 filters, kernel size 3, stride 1, padding 1; followed by Batch Normalization, ReLU, and Dropout (0.6).</p>
<p>• Second convolutional layer: 4 filters, kernel size 3, stride 1, padding 1; followed by Batch Normalization, ReLU, and Dropout (0.6).</p>
<p>• Fully connected layer: 4 units with ReLU activation.</p>
<p>• Output layer: 1 unit with sigmoid activation.</p>
<p>The output feature maps from the convolutional layers were flattened and fed into the fully connected layers.The same training setup used for the DNN-1000 epochs, Adam optimizer, BCELoss, learning rate of 0.001, and batch size of 4-was used for the CNN.</p>
<p>We evaluated performance using accuracy, loss, confusion matrix, and a classification report.</p>
<p>Training and Evaluation</p>
<p>Each model was trained and evaluated over 30 independent runs to account for variability due to random initialization and data shuffling.We trained the models on the training set and validated them after each epoch.Evaluation was conducted on the testing set by comparing predicted and true labels.Model performance was assessed using:</p>
<p>• Accuracy and binary cross-entropy loss.</p>
<p>• Confusion matrix.</p>
<p>• Precision, recall, and F1-score based on a classification report.</p>
<p>Additionally, we generated training history plots to illustrate the progression of loss and accuracy across epochs.</p>
<p>Results</p>
<p>This section presents the results obtained from experiments conducted with both the DNN and CNN models, based on 30 executions for each model to ensure statistical reliability and mitigate the effects of random initialization and data shuffling.The evaluation metrics include accuracy, precision, recall, F1-score, and Binary Cross-Entropy Loss.</p>
<p>The presentation of results follows a progressive analytical structure: first, we provide an overview of the 30 executions using boxplots to illustrate the performance distribution of each model.Then, we analyze the average behavior of the DNN and CNN models across these executions, highlighting key differences.Next, we incorporate a Principal Component Analysis (PCA) to visualize how performance varies across different training set proportions, followed by an examination of the models' average behavior at each of these proportions.Finally, we identify and analyze the best and worst executions for each model, offering insights into their variability and robustness.</p>
<p>Performance Distribution Across 30 Executions</p>
<p>To provide a comprehensive overview of model stability and variability using the full dataset, each experiment was repeated 30 times using the entire training set, with 100% of the original variance retained (with all PCA dimensions).Figure 3 presents boxplots of test accuracy (top) and test loss (bottom) for both the DNN and CNN models, where the points are the individual executions.These plots illustrate the distribution of performance across all executions, highlighting aspects such as spread, central tendency, and the presence of outliers.The visual evidence reinforces the importance of multiple runs to account for variability due to random initialization and data shuffling.To complement the visual analysis, a Kolmogorov-Smirnov (KS) test [2,17] was conducted to statistically compare the test accuracy distributions of the DNN and CNN models across 30 executions, using a 95% confidence level.The test yielded a KS statistic of 0.3333 and a p-value of 0.0708, indicating no significant difference between the accuracy distributions of the two models.</p>
<p>In contrast, applying the KS test to the test loss distributions under the same confidence level (95%) resulted in a KS statistic of 0.7000 and a p-value below 0.0001, evidencing a statistical difference.Although the CNN showed lower error values than the DNN, both are expected to achieve statistically equivalent performance in classification (test accuracy).Nevertheless, given this statistical equivalence in accuracy, the continuation of this work presents further analyses, including the best-and worst-case scenarios for each model.</p>
<p>Average Performance Using the Full Dataset</p>
<p>To complement the performance distribution shown previously, we now analyze the average behavior of both models across the 30 independent runs using the full training dataset, with 100% of the original variance retained.This broader evaluation provides insights into each model's stability, generalization capability, and sensitivity to initialization.The 95% confidence intervals were calculated using Student's t-test.</p>
<p>The DNN model achieved an average test accuracy of 91.37%, with a standard deviation of 7.41, a median of 94.41%, and a confidence interval of [88.59, 94.13].These results indicate that while the DNN is capable of high accuracy, its performance varies depending on initialization and training dynamics.</p>
<p>Under the same conditions, the CNN model achieved a slightly higher average test accuracy of 92.70%, with a standard deviation of 7.53, a median of 95.00%, and a confidence interval of [89.89, 95.51].This suggests that the CNN exhibits marginally better generalization, though its variability, reflected by the standard deviation, remains comparable to that of the DNN.</p>
<p>It is worth noting that the best and worst accuracies observed across the 30 runs vary considerably for both models.Specifically, the DNN achieved the highest accuracy of 95.67% and the lowest accuracy of 59.33%, while the CNN's best and worst accuracies were 97.67% and 55.83%, respectively.These extremes highlight the variability inherent in training deep learning models due to factors such as initialization and stochastic optimization.</p>
<p>A summary of these statistics is presented in Table 1, which includes the average test accuracy, standard deviation, and median values for both models.Additionally, Table 2 highlights the best and worst performances observed during the 30 executions, along with the corresponding 95% confidence intervals, illustrating the range of possible outcomes under different initializations.</p>
<p>Data Proportion Impact on Model Performance</p>
<p>The experimental results in this section were obtained by applying Principal Component Analysis (PCA) while retaining 95%, 90%, 85%, and 80% of the original variance.This dimensionality reduction preserves a controlled proportion of the dataset's information, enabling the evaluation of model performance under different levels of data compression.</p>
<p>For each proportion, boxplots of test accuracy and loss across 30 executions are presented for both DNN and CNN models.This repeated evaluation accounts for the randomness inherent to neural network training and provides a robust estimate of generalization and stability.Figures 4 and 5 summarize these results, combining all four proportions of retained variance to allow direct comparison of the models.The boxplots reveal trends in variability and performance, showing how dimensionality reduction impacts robustness and consistency across executions.</p>
<p>Statistical Summary of Model Performance</p>
<p>A detailed statistical evaluation was conducted to assess the average behavior and consistency of both DNN and CNN models under different levels of data compression, specifically with 95%, 90%, 85%, and 80% of retained PCA variance.Tables 3 to 6 present key performance metrics, including mean test accuracy, standard deviation, median, best and worst outcomes across 30 executions, and 95% confidence intervals calculated using Student's t-test, providing a comprehensive overview of each model's performance variability and allowing a direct comparison of stability under varying amounts of retained information.</p>
<p>Tables 3 and 4 summarize the mean, standard deviation, and median of the test accuracy for each model across all training proportions.The DNN achieved its highest average accuracy (94.04%) with the 85% configuration, which also presented the lowest standard deviation (1.66%) and a median of 94.16%, indicating stable and consistent performance across runs and limited fluctuation between executions.Similarly, the CNN reached its peak average accuracy of 93.09% with the 90% configuration, accompanied by a median of 94.25%, although the variability across runs was slightly higher compared to the DNN, as reflected by its standard deviation.These results highlight the relative stability of both models, the slight differences in sensitivity to PCA variance retention, and provide a clear picture of how the proportion of retained features affects predictive consistency and overall performance.Tables 5 and 6 provide additional insight into model robustness by reporting the best and worst performances observed, along with the respective 95% confidence intervals.The DNN displayed remarkable consistency at 85% retained variance, with accuracy values ranging from 89.00% to 96.83% and a narrow confidence interval of [93.41%, 94.65%].Meanwhile, the CNN achieved its best individual performance (97.00%) at the same 85% level, though it exhibited greater dispersion, with the lowest performance dropping to 71.00%.Despite fluctuations in the extreme values, both models maintained relatively narrow confidence intervals across all data proportions, reinforcing their ability to generalize well under varying degrees of information retention.These results suggest that moderate dimensionality reduction not only preserves classification performance but may also enhance model stability in some cases.</p>
<p>Best-Case Evaluation of DNN and CNN Models</p>
<p>To better illustrate the classification capabilities of both deep learning models, this subsection presents a detailed analysis of the best-performing run out of the 30 independent executions for each architecture.This includes training performance plots, confusion matrices, and classification reports, offering a comprehensive view of how each model behaves when operating at its full potential.</p>
<p>For the DNN model, the best result was obtained using PCA with 85% of the original variance retained, achieving a test accuracy of 96.83%.This shows that moderate dimensionality reduction preserved the most relevant features while potentially reducing noise.In contrast, the best CNN model did not employ dimensionality reduction, retaining 100% of the features, and achieved a slightly higher test accuracy of 97.67%, suggesting that this architecture benefits from the full feature set.Table 7 shows the corresponding confusion matrix, revealing balanced performance across both classes.The model correctly classified most samples, with only a small number of misclassifications, 11 for class 0 and 8 for class 1, indicating strong overall predictive capability.The classification report for this execution is shown in Table 8.The model achieved high precision, recall, and F1-scores for both classes, demonstrating balanced performance and strong predictive capability.Both macro and weighted averages are 0.97, reflecting consistent accuracy across the dataset.The support values indicate that the evaluation included 323 samples of Undefined Loop (0) and 277 samples of Independent Loop (1), confirming that the model performed reliably across classes of differing sizes.Overall, these results highlight the DNN's robustness in correctly classifying the majority of samples and maintaining high performance metrics throughout.The confusion matrix in Table 9 shows excellent classification performance, with zero false positives for class 0 and a small number of false negatives in class 1.The classification report for this execution, presented in Table 10, confirms a slightly higher overall accuracy compared to the DNN.Both macro and weighted averages reach 0.98, demonstrating consistent and balanced performance across classes.The high recall for class 0 and strong precision for class 1 emphasize the model's ability to correctly identify each category while minimizing misclassifications.</p>
<p>Worst-Case Evaluation of DNN and CNN Models</p>
<p>While the previous subsection highlighted the best-performing runs, this section focuses on the opposite end of the performance spectrum.Here, we examine the worst-performing runs for both the DNN and CNN models.As in the previous analysis, the evaluation includes training plots, confusion matrices, and classification reports, allowing for a detailed assessment of the models.By analyzing the worst-case performance, we can gain a deeper understanding of the limitations of each model and the scenarios in which they fail to generalize effectively.Table 11 presents the confusion matrix of the worst-performing DNN model, revealing a strong class imbalance in prediction.The model failed to correctly classify most instances of class 0 (Undefined Loop), with 244 misclassifications, while class 1 (Independent Loop) was classified correctly in all cases.This imbalance is further highlighted in the classification report shown in Table 12, where the model achieved perfect recall for class 1 but very low recall for class 0, resulting in a low F1-score for that class and an overall accuracy of 59.33%.The worst-performing CNN model also used the full feature set (100% variance retained).Its training curves are shown in Figure 9, which includes accuracy and loss plots for both training and validation.The final training accuracy was 88.14%, while validation accuracy dropped to 51.17%, again suggesting overfitting.As shown in Table 13, the confusion matrix reveals a highly imbalanced prediction pattern.The model correctly identified nearly all instances of class 0 (Undefined Loop), but severely misclassified most of class 1 (Independent Loop), with only 13 correct predictions.The classification report in Table 14 confirms the poor generalization of this model, particularly for class 1 (Independent Loop).While it reached a high precision of 0.93 for this class, the recall dropped drastically to 0.05, and the F1-score was only 0.09, indicating that the model failed to correctly identify most instances of this class.In contrast, class 0 (Undefined Loop) achieved perfect recall (1.00) but low precision (0.55), showing that many predictions were misclassified as this class.Overall, these imbalances resulted in a low overall accuracy of 55.83%, with macro and weighted averages also reflecting poor performance (0.40 and 0.42 F1-score, respectively).This highlights the model's inability to handle class-specific distinctions effectively under worst-case conditions.</p>
<p>Conclusion</p>
<p>This study has demonstrated the effectiveness of deep learning approaches for classifying programming code based on its parallelization potential.Using a carefully curated dataset of independent and undefined loops, we implemented and evaluated both DNN and CNN architectures.Both models achieved strong average performance across 30 runs and showed robust generalization across training proportions (80-100%), with comparable variability, as indicated by their similar standard deviations.To further support these findings, a Kolmogorov-Smirnov (KS) test was applied to the accuracy and loss distributions of both models.The results revealed no statistically significant difference in test accuracy at the 95% confidence level, while the test loss distributions were statistically different, with the CNN achieving lower error values.These results indicate that, although both models are statistically equivalent in terms of classification accuracy, the CNN demonstrated slightly superior performance in its best-case scenario.The findings carry important implications for automated code analysis tools, particularly in the domain of parallel computing.The CNN's consistent performance across multiple executions suggests that convolutional operations are especially effective at capturing the structural regularities that distinguish parallelizable loops.This work lays the groundwork for assessing parallelization potential using deep learning techniques.While existing literature on parallelization methods-including those cited in this study-provides useful context, our approach diverges by focusing specifically on classifying loops based on learned structural patterns rather than handcrafted heuristic rules and other parallelization identification methods.This methodological distinction limited the possibility of direct comparisons with prior techniques within our experimental setup.</p>
<p>Looking ahead, several promising directions emerge for extending this research.Expanding the dataset to include more diverse real-world code samples would further enhance model generalization.Testing alternative architectures, such as transformer-based models or hybrid CNN-RNN approaches, could provide additional insights into optimal network designs for this task.Practical validation through application to opensource projects would assess the real-world utility of the approach.Most significantly, future work should focus on formalizing mathematical relationships that determine loop independence, potentially leading to the definition of a new code smell category specifically for parallelization analysis.These advancements would build upon the robust framework established in this study, which demonstrates both the feasibility and potential of deep learning for automated parallelization assessment.</p>
<p>Figure 1 :
1
Figure 1: Fitness evolution across 30 runs of the genetic algorithm.The plot shows the average, maximum, and minimum fitness per generation.</p>
<p>Figure 2 :
2
Figure 2: Evolutionary process for generating labeled code samples.</p>
<p>Figure 3 :
3
Figure 3: Boxplots showing the test accuracy (top) and test loss (bottom) of DNN and CNN models using 100% of retained PCA variance across 30 executions.</p>
<p>Figure 4 :
4
Figure 4: Boxplots showing the test accuracy (top) and test loss (bottom) of the DNN model under different PCA information retention levels (95%, 90%, 85%, and 80%) across 30 independent executions.</p>
<p>Figure 5 :
5
Figure 5: Boxplots showing the test accuracy (top) and test loss (bottom) of the CNN model under different PCA information retention levels (95%, 90%, 85%, and 80%) across 30 independent executions.</p>
<p>Figure 6 presents the training behavior of the best DNN model.It contains two subplots: one showing training and validation accuracy, and the other showing training and validation loss across epochs.The model reached a final training accuracy of 88.61% and a validation accuracy of 95.00%, indicating effective generalization.The smooth convergence of both curves suggests stable training without overfitting.</p>
<p>Figure 6 :
6
Figure 6: Training and validation accuracy and loss of the best-performing DNN model using 85% PCA variance.</p>
<p>Figure 7
7
Figure 7 shows the training and validation performance of the best CNN model.Similar to the DNN, it includes two subplots: one displaying accuracy curves and the other showing loss curves.The CNN reached a training accuracy of 88.11% and a validation accuracy of 93.17%, indicating effective learning of the training data while generalizing well to unseen samples.The convergence of both curves and the relatively small gap between training and validation metrics suggest stable training, consistent improvement over epochs, and the absence of overfitting.</p>
<p>Figure 7 :
7
Figure 7: Training and validation accuracy and loss of the best-performing CNN model using 100% of the features.</p>
<ol>
<li>6 . 1 Figure 8
618
Figure 8 shows in detail the training behavior of the worst-performing DNN model, which was configured using 100% of the original features as input.The figure is divided into two subplots: the first illustrates the evolution of training and validation accuracy over the epochs, and the second presents the curves of training and validation loss.At the end of training, the model reached a relatively high training accuracy of 88.50%, but its validation accuracy dropped considerably to 62.67%.This sharp decline clearly reflects strong overfitting, since the model demonstrated good performance on the training set but failed to reproduce similar results on the validation set.The large gap between training and validation curves shows that the network tended to memorize the training data instead of learning patterns capable of generalizing to new, unseen samples.This discrepancy highlights the sensitivity of the DNN model to the specific characteristics of the training data and reinforces the importance of simultaneously analyzing both training and validation metrics when assessing the overall reliability and robustness of the model.</li>
</ol>
<p>Figure 8 :
8
Figure 8: Training and validation accuracy and loss of the worst-performing DNN model using 100% of the features.</p>
<p>Figure 9 :
9
Figure 9: Training and validation accuracy and loss of the worst-performing CNN model using 100% of the features.</p>
<p>Table 1 :
1
Average, standard deviation, and median test accuracy over 30 runs using 100% of the data.
Model Average (%) Std (%) Median (%)DNN91.377.4194.41CNN92.707.5395.00</p>
<p>Table 2 :
2
Best, worst, and 95% confidence interval of test accuracy for DNN and CNN.
Model Best (%) Worst (%)CI (95%)DNN95.6759.33[88.59, 94.13]CNN97.6755.83[89.89, 95.51]</p>
<p>Table 3 :
3
DNN model: mean, standard deviation, and median of test accuracy over 30 runs for different training proportions.
Proportion (%) Mean (%) Std (%) Median (%)9593.123.6593.919093.623.2594.758594.041.6694.168093.693.4594.41</p>
<p>Table 4 :
4
CNN model: mean, standard deviation, and median of test accuracy over 30 runs for different training proportions.
Proportion (%) Mean (%) Std (%) Median (%)9592.192.5092.509093.093.1094.258592.374.6993.418092.163.6393.08</p>
<p>Table 5 :
5
DNN model: best, worst, and 95% confidence interval of test accuracy over 30 runs.
Proportion (%) Best (%) Worst (%)CI (95%)9595.8376.17[91.75, 94.48]9096.5081.33[92.40, 94.83]8596.8389.00[93.41, 94.65]8096.6776.33[92.39, 94.98]</p>
<p>Table 6 :
6
CNN model: best, worst, and 95% confidence interval of test accuracy over 30 runs.
Proportion (%) Best (%) Worst (%)CI (95%)9596.5087.33[91.26, 93.12]9096.8386.33[91.93, 94.25]8597.0071.00[90.61, 94.11]8096.6782.17[90.79, 93.51]</p>
<p>Table 7 :
7
Confusion matrix of the best-performing DNN model.
Predicted 0 Predicted 1Actual 031211Actual 18269</p>
<p>Table 8 :
8
Classification report of the best-performing DNN model.
ClassPrecision Recall F1-score SupportUndefined Loop (0)0.970.970.97323Independent Loop (1)0.960.970.97277Accuracy0.97 (96.83%)Macro avg0.970.970.97600Weighted avg0.970.970.976003.5.2 CNN Best-Case Performance (Full Features)</p>
<p>Table 9 :
9
Confusion matrix of the best-performing CNN model.
Predicted 0 Predicted 1Actual 03230Actual 114263</p>
<p>Table 10 :
10
Classification report of the best-performing CNN model.
ClassPrecision Recall F1-score SupportUndefined Loop (0)0.961.000.98323Independent Loop (1)1.000.950.97277Accuracy0.98 (97.67%)Macro avg0.980.970.98600Weighted avg0.980.980.98600</p>
<p>Table 11 :
11
Confusion matrix of the worst-performing DNN model.
Predicted 0 Predicted 1Actual 079244Actual 10277</p>
<p>Table 12 :
12
Classification report of the worst-performing DNN model.
ClassPrecision Recall F1-score SupportUndefined Loop (0)1.000.240.39323Independent Loop (1)0.531.000.69277Accuracy0.59 (59.33%)Macro avg0.770.620.54600Weighted avg0.780.590.536003.6.2 CNN Worst-Case Performance (Full Features)</p>
<p>Table 13 :
13
Confusion matrix of the worst-performing CNN model.
Predicted 0 Predicted 1Actual 03221Actual 126413</p>
<p>Table 14 :
14
Classification report of the worst-performing CNN model.These results highlight the variability that can arise across different executions of the same model archi-tecture.While both DNN and CNN achieved excellent performance in their best runs, their worst cases revealed significant drops in accuracy and class imbalance issues.This underscores the importance of evaluating model robustness through multiple runs, as individual executions may lead to widely different outcomes depending on initialization and training dynamics.
ClassPrecision Recall F1-score SupportUndefined Loop (0)0.551.000.71323Independent Loop (1)0.930.050.09277Accuracy0.56 (55.83%)Macro avg0.740.520.40600Weighted avg0.720.560.42600
DEAP: Distributed Evolutionary Algorithms in Python. Available at: https://deap.readthedocs.io
Visual Studio Code editor, developed by Microsoft. Available at: https://code.visualstudio.com/
https://docs.python.org/3/library/tokenize.html
https://pytorch.org/docs/stable/index.html
https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html</p>
<p>A survey of machine learning for big code and naturalness. Miltiadis Allamanis, Earl T Barr, Premkumar Devanbu, Charles Sutton, 10.1145/3212695ACM Computing Surveys (CSUR). 5142018</p>
<p>Sulla determinazione empirica di una legge di distribuzione. Giornale dell'Istituto Italiano degli Attuari. An Kolmogorov, 19334</p>
<p>Generating gpu compiler heuristics using reinforcement learning. Ian Colbert, Jake Daly, Norm Rubin, arXiv:2111.120552021arXiv preprint</p>
<p>End-to-end deep learning of optimization heuristics. Chris Cummins, Pavlos Petoumenos, Zheng Wang, Hugh Leather, 10.1109/PACT.2017.2426th International Conference on Parallel Architectures and Compilation Techniques (PACT). Portland, OR, USA2017</p>
<p>Detecting code smells using deep learning. Ananta Kumar Das, Shikhar Yadav, Subhasish Dhal, 10.1109/TENCON.2019.8929384TENCON 2019 -IEEE Region 10 Conference (TENCON). Kochi, IndiaIEEE2019</p>
<p>Detecting code smells using machine learning techniques: Are we there yet?. Dario Di Nucci, Fabio Palomba, Damian A Tamburri, Alexander Serebrenik, Andrea De, Lucia , 10.1109/SANER.2018.83302552018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER). Campobasso, ItalyIEEE2018</p>
<p>Bridging the parallelization gap: Automating parallelism discovery and planning. Saturnino Garcia, Donghwan Jeon, Chris Louie, Sravanthi Kota Venkata, Michael Bedford, Taylor , USENIX Workshop on Hot Topics in Parallelism (HOTPAR). Berkeley, CA, USAUSENIX Association2010</p>
<p>Deep Learning. Ian Goodfellow, Yoshua Bengio, Aaron Courville, 2016MIT PressCambridge, MA, USA</p>
<p>V Gray, Principal Component Analysis: Methods, Applications, and Technology. Mathematics Research Developments Series. New York, NY, USANova Science Publishers2017. ISBN 9781536108897</p>
<p>Deep convolutional neural network model for bad code smells detection based on oversampling method. Nasraldeen Alnor, Adam Khleel, Károly Nehéz, 10.11591/ijeecs.v26.i3.pp1725-1735Indonesian Journal of Electrical Engineering and Computer Science. 2632022</p>
<p>Adam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.69802014arXiv preprint</p>
<p>Gradient-based learning applied to document recognition. Yann Lecun, Léon Bottou, Yoshua Bengio, Patrick Haffner, 10.1109/5.726791Proceedings of the IEEE. 86111998</p>
<p>Deep learning based code smell detection. Hui Liu, Jiahao Jin, Zhifeng Xu, Yanzhen Zou, Yifan Bu, Lu Zhang, 10.1109/TSE.2019.2901463IEEE Transactions on Software Engineering. 4792019</p>
<p>on lines and planes of closest fit to systems of points in space. Karl Pearson, Liii, 10.1080/14786440109462720The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science. 2111901</p>
<p>Pesc -parallel experience for sequential code. C T Henrique, Luciano S Santos, Jonathan H A De Souza, De Carvalho, A E Tiago, Ferreira, 10.1002/cpe.70102Concurrency and Computation: Practice and Experience. 372025</p>
<p>Code smell detection by deep direct-learning and transfer-learning. Tushar Sharma, Vasiliki Efstathiou, Panos Louridas, Diomidis Spinellis, 10.1016/j.jss.2021.110936Journal of Systems and Software. 176110936June 2021</p>
<p>Table for estimating the goodness of fit of empirical distributions. Nickolay Smirnov, 10.1214/aoms/1177730256The Annals of Mathematical Statistics. 1921948</p>
<p>City-wide traffic flow forecasting using a deep convolutional neural network. Shangyu Sun, Huayi Wu, Longgang Xiang, 10.3390/s20020421Sensors. 2024212020</p>
<p>High Performance Compilers for Parallel Computing. Michael Joseph, Wolfe , 1995Addison-Wesley, Reading, MA, USAISBN 9780201547972</p>            </div>
        </div>

    </div>
</body>
</html>