<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4221 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4221</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4221</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-97.html">extraction-schema-97</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <p><strong>Paper ID:</strong> paper-279402741</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2506.12385v1.pdf" target="_blank">Recent Advances and Future Directions in Literature-Based Discovery</a></p>
                <p><strong>Paper Abstract:</strong> The explosive growth of scientific publications has created an urgent need for automated methods that facilitate knowledge synthesis and hypothesis generation. Literature-based discovery (LBD) addresses this challenge by uncovering previously unknown associations between disparate domains. This article surveys recent methodological advances in LBD, focusing on developments from 2000 to the present. We review progress in three key areas: knowledge graph construction, deep learning approaches, and the integration of pre-trained and large language models (LLMs). While LBD has made notable progress, several fundamental challenges remain unresolved, particularly concerning scalability, reliance on structured data, and the need for extensive manual curation. By examining ongoing advances and outlining promising future directions, this survey underscores the transformative role of LLMs in enhancing LBD and aims to support researchers and practitioners in harnessing these technologies to accelerate scientific innovation.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4221.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4221.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KGC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge Graph Completion</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of algorithms that predict missing nodes or edges in a knowledge graph (link prediction / node prediction) to discover implicit relationships between concepts in a corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Knowledge Graph Completion (KGC) pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The paper frames LBD as a KGC task: construct a KG from extracted semantic triples or co-occurrence links, then apply KGC techniques to predict missing edges or nodes (e.g., scoring candidate triples (h,r,t) or inferring missing components). Construction methods described include co-occurrence graphs and explicit relation-extraction predications; KGC is applied to discover candidate A–C links via predicted A–B and B–C links or by direct link-prediction over the graph.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Primarily biomedical (but applicable cross-domain)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Implicit relational/predicate discovery (semantic relations and associations between concepts); discovery of missing graph edges (qualitative relationships rather than explicit quantitative equations).</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Example conceptual discovery recapitulated in KG form: "Fish oil" → "Blood viscosity" → "Raynaud's disease" (co-occurrence or predication chains); relational triple example: "Fish oil" → treats → "Raynaud's disease".</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Build KG from semantic predications (subject-relation-object triples) or co-occurrence counts extracted from text (e.g., using relation extractors like SemRep or by co-occurrence modeling); then apply KGC/link-prediction algorithms to infer missing edges.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Not specified in detail in the survey beyond standard KGC practice; referenced applications validate candidate links via downstream use-cases (e.g., drug-repurposing case studies) or dataset benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey mentions application of KGC algorithms but does not supply numeric metrics within this paper; specific metrics are reported in cited primary works (not enumerated here).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>KG construction quality strongly affects KGC results; reliance on structured vocabularies and term normalization, brittleness to noisy predications and co-occurrence edges; scalability to very large corpora is a challenge.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared conceptually to classical ABC/co-occurrence LBD approaches; KGC is presented as a modern replacement/extension but specific numerical comparisons are not provided in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4221.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4221.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Crichton et al. NN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural networks for open and closed literature-based discovery (Crichton et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural-network LBD approach using node embeddings (LINE) and MLP/CNN architectures to score A–B and B–C links and aggregate them for open and closed discovery tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neural networks for open and closed literature-based discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Embedding-based neural LBD (MLP/CNN with LINE embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Build node embeddings using the LINE algorithm, construct inputs by combining embeddings along discovery paths (A, B, C). Closed discovery: score A–B and B–C links with a neural model and aggregate; alternate approach combines A, B, C embeddings into a single vector for direct scoring. Open discovery: variants score and aggregate multiple paths or stack multiple A–B–C path embeddings into pseudo-images processed by a CNN.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical LBD datasets (evaluated on PubTator and BioGRID datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Implicit association/predicate prediction between concepts (A–B–C path scoring); pattern discovery of linking concepts (qualitative/associative relations).</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Uses ABC-style path examples such as Fish oil → Blood viscosity → Raynaud's disease as an illustrative discovery; the method discovers linking B concepts between A and C.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Text → concept/entity extraction → node embedding (LINE) → neural scoring of path embeddings (MLP/CNN). Does not parse explicit numeric equations.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Evaluated on PubTator and BioGRID benchmark datasets; performance reported as state-of-the-art in the cited work (survey does not reproduce numeric values).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey states "state-of-the-art performance on the PubTator and BioGRID datasets" but does not provide precision/recall/F1 numbers within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Requires manual construction of all possible hypothesis triples prior to evaluation (time-consuming and reliant on domain expertise) in the original formulation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to prior LBD approaches on PubTator and BioGRID; reported improvements (numeric comparisons in original paper).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4221.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4221.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cuffy et al. (2023)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exploring a deep learning neural architecture for closed literature-based discovery (Cuffy et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A closed-discovery DL framework that automates ranking of candidate bridging concepts (B) for a given A and C using a single forward pass through a neural model, removing the need to enumerate all A–B–C triples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploring a deep learning neural architecture for closed literature-based discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Automated ranking neural LBD (single-pass ranking)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>DL model (closed discovery) that, given A and C, produces ranked linking B terms through one forward propagation, avoiding explicit enumeration of all A–B–C triples; reduces dependency on domain-specific preprocessing and manual candidate generation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical LBD (applied to typical biomedical corpora/datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Discovery of implicit bridging concepts and associative relationships (qualitative link identification).</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Identification/ranking of plausible B concepts linking A and C (paper does not report discovery of explicit numeric laws).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Entity/concept extraction from text → embed concepts → neural model directly predicts/ranks candidate B concepts given A and C.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Evaluated in closed-discovery settings in the cited work; specific validation protocols and metrics are reported in the primary paper (not reproduced here).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Survey notes this approach reduces manual candidate enumeration but does not detail limitations beyond those general to DL LBD (interpretability, dataset dependence).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to earlier enumerative/aggregation DL approaches; presented as an efficiency improvement (comparative numeric results in original paper).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4221.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4221.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cuffy et al. (2025)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Predicting implicit concept embeddings for singular relationship discovery replication of closed literature-based discovery (Cuffy et al., 2025)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that reframes LBD as prediction of the embedding of a linking concept B given A and C; predicted embeddings are compared to candidate concept embeddings to identify plausible intermediates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Predicting implicit concept embeddings for singular relationship discovery replication of closed literature-based discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Implicit-concept-embedding prediction model</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MLP model trained to predict the embedding vector of the intermediary concept B from embeddings of A and C; discovery is performed by nearest-neighbor matching between predicted embedding and candidate concept embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical LBD / general LBD replication studies</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Implicit relational discovery (identifies associative/intermediary concepts rather than numeric laws).</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Predicts embeddings corresponding to bridging concepts (no explicit numeric equations reported in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Embed concepts from text (embedding method not fully detailed in survey) → train MLP to map (A_embedding, C_embedding) → predicted B_embedding → match to candidate concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Demonstrated effectiveness in replication contexts in the cited work; detailed evaluation in original paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Dependent on the quality of base embeddings and candidate concept set; survey does not provide additional failure rates.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Presented as an alternative to direct triple scoring; compared to prior DL LBD approaches in the primary work.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4221.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4221.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SciMON</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SciMON (Scientific inspiration machines optimized for novelty)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework grounding literature-based discovery in natural language contexts by generating full-sentence hypotheses and iteratively refining them to optimize novelty and conceptual depth.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SciMON: Scientific inspiration machines optimized for novelty</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SciMON (LM-grounded hypothesis generator)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses generative language-model based methods to produce candidate research hypotheses as full sentences grounded in literature contexts, then iteratively refines these outputs to increase novelty; contrasts with purely concept-linking ABC methods by operating in natural language space.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General scientific research (evaluated in scientific-hypothesis generation contexts)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Generation of novel hypothesis statements and conceptual relationships in natural language (qualitative, contextual relationships rather than explicit quantitative laws).</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Outputs full-sentence hypotheses (survey notes SciMON produces ideas judged more original and conceptually deeper than those from GPT-4; no explicit quantitative equations cited).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>LM-based generation grounded in literature passages (natural language grounding), iterative refinement loop to control novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Human evaluation/comparative evaluation vs GPT-4 reported in the SciMON paper (survey cites claim of greater originality/depth than GPT-4).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey reports qualitative claim (more original and conceptually deeper than GPT-4) but does not provide numeric metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Generative LM outputs may require additional filtering and validation; controlling factuality and grounding remains a challenge.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared directly to GPT-4 in the cited work; SciMON reported to produce more original/deeper ideas than GPT-4 per the authors.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4221.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4221.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BioGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BioGPT (Generative pre-trained transformer for biomedical text generation and mining)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-specific large generative transformer trained on biomedical corpora (e.g., PubMed) for tasks such as literature retrieval, summarization, and question-answering in biomedicine.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>BioGPT: Generative pre-trained transformer for biomedical text generation and mining</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BioGPT (domain-specific LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A generative pre-trained transformer model trained on biomedical text corpora (PubMed, etc.), enabling domain-adapted retrieval, summarization and QA to support literature-based discovery workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BioGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Facilitates extraction/synthesis of literature-derived relationships and insights (qualitative associations, summaries, and hypothesis generation) rather than explicit numeric laws in the surveyed work.</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Used for literature retrieval and synthesis tasks; no explicit quantitative law equations are reported in this survey entry.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>LM-based retrieval, summarization and QA from domain text (trained on PubMed-level corpora).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Not detailed in survey; original BioGPT paper evaluates generation/mining tasks within biomedicine.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Requires domain-specific training corpora; factuality and hallucination risk in generative outputs remain concerns.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Presented as a domain-adapted LM; comparative performance vs general LLMs discussed in primary literature (not enumerated in this survey).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4221.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e4221.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SciGLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SciGLM (Training scientific language models with self-reflective instruction annotation and tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A scientific-domain language model trained/tuned with self-reflective instruction annotation approaches to improve performance on scientific tasks such as retrieval and hypothesis support.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SciGLM: Training scientific language models with self-reflective instruction annotation and tuning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SciGLM (scientific LLM with self-reflective tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A training/tuning methodology for scientific LMs emphasizing self-reflective instruction annotations to improve reasoning and domain-specific performance; cited as an example of a state-of-the-art scientific LLM used for literature tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SciGLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General scientific literature (e.g., PubMed, arXiv)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Enables generation and synthesis of scientific relationships and hypotheses in natural language; not described as extracting explicit mathematical/quantitative laws in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>LM-based synthesis and reasoning over scientific corpora using instruction-tuning/self-reflective annotations.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Not specified in this survey; original paper would contain evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Survey notes LLMs remain challenging in scalability and validation; model-specific limitations not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Positioned as a domain-specific LLM improvement; direct baselines are in original work.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4221.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e4221.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Authors' COVID-19 pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERT-based semantic triple extraction + KG construction + KGC for COVID-19 drug repurposing</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The authors' LBD approach for COVID-19 drug repurposing: use a BERT variant as a preprocessing tool to extract semantic triples, build a KG, and apply KGC algorithms to predict repurposing candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Drug repurposing for COVID-19 via knowledge graph completion</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BERT-based semantic triple extraction + KG + KGC pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Preprocess literature with a BERT variant ('BERT5' as stated) to generate a subset of semantic subject-relation-object triples, use those triples to construct a knowledge graph, and apply KGC algorithms to predict candidate drug repurposing edges in the KG.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT5 (as stated in the paper)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical (COVID-19 drug repurposing)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Discovery of candidate treatment relations (drug → treats → disease) and other biomedical semantic relations; qualitative relational predictions rather than explicit numeric laws.</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Predicting drug–disease treatment candidate edges (no explicit mathematical equations reported in survey summary).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Use BERT-based model to extract semantic predications from text (subject-relation-object triples), construct KG from these triples, then run KGC/link-prediction algorithms on the KG.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Applied KGC to predict repurposing candidates; original study likely validated candidates against known repurposing signals or subsequent evaluation (detailed validation protocols in the cited primary paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Relies on quality of semantic triple extraction (term normalization, UMLS coverage); many LBD approaches limited by abstract-only text, term ambiguity, and need for manual curation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared methodologically to other KG and KGC approaches in the drug-repurposing literature; specific numeric comparisons are in the cited paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4221.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e4221.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMs (general)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Models (PLMs/LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Pre-trained and large language models (e.g., BERT variants, GPT-family, domain-specific LLMs) that provide contextual understanding, generation, and zero-shot reasoning to support literature-based discovery tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Large language models: A survey of their development, capabilities, and applications</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Large language models (general LLM usage in LBD)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The survey describes PLMs and LLMs as core components of modern LBD pipelines: PLMs used for NER and relation extraction (preprocessing), and LLMs used for retrieval, summarization, question-answering, hypothesis generation, and grounding hypotheses in natural language (examples include BioGPT, SciGLM, GPT-4 as a baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Cross-domain (biomedicine emphasized, but potential to extend to social sciences and others)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Facilitate extraction/synthesis of relationships and patterns in literature (semantic relations and hypothesis statements). The survey does not claim LLMs extracted explicit quantitative mathematical laws in the cited examples.</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Generation of hypothesis sentences, retrieval/summarization of literature, and identification of relational candidates (no explicit equations provided in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>LM-based extraction: use PLMs for entity and relation extraction (semantic triples), or LLMs for natural-language grounded hypothesis generation and iterative refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Reported empirical results showing improved reasoning and hypothesis generation capabilities in cited works; primary studies provide task-specific evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Scalability, factuality/hallucination, validation of generated hypotheses, dependence on high-quality corpora and ontologies, and limited interpretability of deep models; grounding LLM outputs to verifiable evidence remains a challenge.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Survey cites comparisons (e.g., SciMON vs GPT-4) and notes LLMs outperform earlier PLMs in generalization and reasoning in many tasks; numeric baselines are in the referenced works.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Neural networks for open and closed literature-based discovery <em>(Rating: 2)</em></li>
                <li>Exploring a deep learning neural architecture for closed literature-based discovery <em>(Rating: 2)</em></li>
                <li>Predicting implicit concept embeddings for singular relationship discovery replication of closed literature-based discovery <em>(Rating: 2)</em></li>
                <li>SciMON: Scientific inspiration machines optimized for novelty <em>(Rating: 2)</em></li>
                <li>BioGPT: Generative pre-trained transformer for biomedical text generation and mining <em>(Rating: 2)</em></li>
                <li>SciGLM: Training scientific language models with self-reflective instruction annotation and tuning <em>(Rating: 2)</em></li>
                <li>Drug repurposing for COVID-19 via knowledge graph completion <em>(Rating: 2)</em></li>
                <li>A computational inflection for scientific discovery <em>(Rating: 2)</em></li>
                <li>Large language models: A survey of their development, capabilities, and applications <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4221",
    "paper_id": "paper-279402741",
    "extraction_schema_id": "extraction-schema-97",
    "extracted_data": [
        {
            "name_short": "KGC",
            "name_full": "Knowledge Graph Completion",
            "brief_description": "A set of algorithms that predict missing nodes or edges in a knowledge graph (link prediction / node prediction) to discover implicit relationships between concepts in a corpus.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Knowledge Graph Completion (KGC) pipeline",
            "system_description": "The paper frames LBD as a KGC task: construct a KG from extracted semantic triples or co-occurrence links, then apply KGC techniques to predict missing edges or nodes (e.g., scoring candidate triples (h,r,t) or inferring missing components). Construction methods described include co-occurrence graphs and explicit relation-extraction predications; KGC is applied to discover candidate A–C links via predicted A–B and B–C links or by direct link-prediction over the graph.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Primarily biomedical (but applicable cross-domain)",
            "number_of_papers": null,
            "law_type": "Implicit relational/predicate discovery (semantic relations and associations between concepts); discovery of missing graph edges (qualitative relationships rather than explicit quantitative equations).",
            "law_examples": "Example conceptual discovery recapitulated in KG form: \"Fish oil\" → \"Blood viscosity\" → \"Raynaud's disease\" (co-occurrence or predication chains); relational triple example: \"Fish oil\" → treats → \"Raynaud's disease\".",
            "extraction_method": "Build KG from semantic predications (subject-relation-object triples) or co-occurrence counts extracted from text (e.g., using relation extractors like SemRep or by co-occurrence modeling); then apply KGC/link-prediction algorithms to infer missing edges.",
            "validation_approach": "Not specified in detail in the survey beyond standard KGC practice; referenced applications validate candidate links via downstream use-cases (e.g., drug-repurposing case studies) or dataset benchmarks.",
            "performance_metrics": "Survey mentions application of KGC algorithms but does not supply numeric metrics within this paper; specific metrics are reported in cited primary works (not enumerated here).",
            "success_rate": null,
            "challenges_limitations": "KG construction quality strongly affects KGC results; reliance on structured vocabularies and term normalization, brittleness to noisy predications and co-occurrence edges; scalability to very large corpora is a challenge.",
            "comparison_baseline": "Compared conceptually to classical ABC/co-occurrence LBD approaches; KGC is presented as a modern replacement/extension but specific numerical comparisons are not provided in this survey.",
            "uuid": "e4221.0",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Crichton et al. NN",
            "name_full": "Neural networks for open and closed literature-based discovery (Crichton et al.)",
            "brief_description": "A neural-network LBD approach using node embeddings (LINE) and MLP/CNN architectures to score A–B and B–C links and aggregate them for open and closed discovery tasks.",
            "citation_title": "Neural networks for open and closed literature-based discovery",
            "mention_or_use": "mention",
            "system_name": "Embedding-based neural LBD (MLP/CNN with LINE embeddings)",
            "system_description": "Build node embeddings using the LINE algorithm, construct inputs by combining embeddings along discovery paths (A, B, C). Closed discovery: score A–B and B–C links with a neural model and aggregate; alternate approach combines A, B, C embeddings into a single vector for direct scoring. Open discovery: variants score and aggregate multiple paths or stack multiple A–B–C path embeddings into pseudo-images processed by a CNN.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Biomedical LBD datasets (evaluated on PubTator and BioGRID datasets)",
            "number_of_papers": null,
            "law_type": "Implicit association/predicate prediction between concepts (A–B–C path scoring); pattern discovery of linking concepts (qualitative/associative relations).",
            "law_examples": "Uses ABC-style path examples such as Fish oil → Blood viscosity → Raynaud's disease as an illustrative discovery; the method discovers linking B concepts between A and C.",
            "extraction_method": "Text → concept/entity extraction → node embedding (LINE) → neural scoring of path embeddings (MLP/CNN). Does not parse explicit numeric equations.",
            "validation_approach": "Evaluated on PubTator and BioGRID benchmark datasets; performance reported as state-of-the-art in the cited work (survey does not reproduce numeric values).",
            "performance_metrics": "Survey states \"state-of-the-art performance on the PubTator and BioGRID datasets\" but does not provide precision/recall/F1 numbers within this paper.",
            "success_rate": null,
            "challenges_limitations": "Requires manual construction of all possible hypothesis triples prior to evaluation (time-consuming and reliant on domain expertise) in the original formulation.",
            "comparison_baseline": "Compared to prior LBD approaches on PubTator and BioGRID; reported improvements (numeric comparisons in original paper).",
            "uuid": "e4221.1",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Cuffy et al. (2023)",
            "name_full": "Exploring a deep learning neural architecture for closed literature-based discovery (Cuffy et al., 2023)",
            "brief_description": "A closed-discovery DL framework that automates ranking of candidate bridging concepts (B) for a given A and C using a single forward pass through a neural model, removing the need to enumerate all A–B–C triples.",
            "citation_title": "Exploring a deep learning neural architecture for closed literature-based discovery",
            "mention_or_use": "mention",
            "system_name": "Automated ranking neural LBD (single-pass ranking)",
            "system_description": "DL model (closed discovery) that, given A and C, produces ranked linking B terms through one forward propagation, avoiding explicit enumeration of all A–B–C triples; reduces dependency on domain-specific preprocessing and manual candidate generation.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Biomedical LBD (applied to typical biomedical corpora/datasets)",
            "number_of_papers": null,
            "law_type": "Discovery of implicit bridging concepts and associative relationships (qualitative link identification).",
            "law_examples": "Identification/ranking of plausible B concepts linking A and C (paper does not report discovery of explicit numeric laws).",
            "extraction_method": "Entity/concept extraction from text → embed concepts → neural model directly predicts/ranks candidate B concepts given A and C.",
            "validation_approach": "Evaluated in closed-discovery settings in the cited work; specific validation protocols and metrics are reported in the primary paper (not reproduced here).",
            "performance_metrics": null,
            "success_rate": null,
            "challenges_limitations": "Survey notes this approach reduces manual candidate enumeration but does not detail limitations beyond those general to DL LBD (interpretability, dataset dependence).",
            "comparison_baseline": "Compared to earlier enumerative/aggregation DL approaches; presented as an efficiency improvement (comparative numeric results in original paper).",
            "uuid": "e4221.2",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Cuffy et al. (2025)",
            "name_full": "Predicting implicit concept embeddings for singular relationship discovery replication of closed literature-based discovery (Cuffy et al., 2025)",
            "brief_description": "A method that reframes LBD as prediction of the embedding of a linking concept B given A and C; predicted embeddings are compared to candidate concept embeddings to identify plausible intermediates.",
            "citation_title": "Predicting implicit concept embeddings for singular relationship discovery replication of closed literature-based discovery",
            "mention_or_use": "mention",
            "system_name": "Implicit-concept-embedding prediction model",
            "system_description": "MLP model trained to predict the embedding vector of the intermediary concept B from embeddings of A and C; discovery is performed by nearest-neighbor matching between predicted embedding and candidate concept embeddings.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Biomedical LBD / general LBD replication studies",
            "number_of_papers": null,
            "law_type": "Implicit relational discovery (identifies associative/intermediary concepts rather than numeric laws).",
            "law_examples": "Predicts embeddings corresponding to bridging concepts (no explicit numeric equations reported in survey).",
            "extraction_method": "Embed concepts from text (embedding method not fully detailed in survey) → train MLP to map (A_embedding, C_embedding) → predicted B_embedding → match to candidate concepts.",
            "validation_approach": "Demonstrated effectiveness in replication contexts in the cited work; detailed evaluation in original paper.",
            "performance_metrics": null,
            "success_rate": null,
            "challenges_limitations": "Dependent on the quality of base embeddings and candidate concept set; survey does not provide additional failure rates.",
            "comparison_baseline": "Presented as an alternative to direct triple scoring; compared to prior DL LBD approaches in the primary work.",
            "uuid": "e4221.3",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "SciMON",
            "name_full": "SciMON (Scientific inspiration machines optimized for novelty)",
            "brief_description": "A framework grounding literature-based discovery in natural language contexts by generating full-sentence hypotheses and iteratively refining them to optimize novelty and conceptual depth.",
            "citation_title": "SciMON: Scientific inspiration machines optimized for novelty",
            "mention_or_use": "mention",
            "system_name": "SciMON (LM-grounded hypothesis generator)",
            "system_description": "Uses generative language-model based methods to produce candidate research hypotheses as full sentences grounded in literature contexts, then iteratively refines these outputs to increase novelty; contrasts with purely concept-linking ABC methods by operating in natural language space.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "General scientific research (evaluated in scientific-hypothesis generation contexts)",
            "number_of_papers": null,
            "law_type": "Generation of novel hypothesis statements and conceptual relationships in natural language (qualitative, contextual relationships rather than explicit quantitative laws).",
            "law_examples": "Outputs full-sentence hypotheses (survey notes SciMON produces ideas judged more original and conceptually deeper than those from GPT-4; no explicit quantitative equations cited).",
            "extraction_method": "LM-based generation grounded in literature passages (natural language grounding), iterative refinement loop to control novelty.",
            "validation_approach": "Human evaluation/comparative evaluation vs GPT-4 reported in the SciMON paper (survey cites claim of greater originality/depth than GPT-4).",
            "performance_metrics": "Survey reports qualitative claim (more original and conceptually deeper than GPT-4) but does not provide numeric metrics.",
            "success_rate": null,
            "challenges_limitations": "Generative LM outputs may require additional filtering and validation; controlling factuality and grounding remains a challenge.",
            "comparison_baseline": "Compared directly to GPT-4 in the cited work; SciMON reported to produce more original/deeper ideas than GPT-4 per the authors.",
            "uuid": "e4221.4",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "BioGPT",
            "name_full": "BioGPT (Generative pre-trained transformer for biomedical text generation and mining)",
            "brief_description": "A domain-specific large generative transformer trained on biomedical corpora (e.g., PubMed) for tasks such as literature retrieval, summarization, and question-answering in biomedicine.",
            "citation_title": "BioGPT: Generative pre-trained transformer for biomedical text generation and mining",
            "mention_or_use": "mention",
            "system_name": "BioGPT (domain-specific LLM)",
            "system_description": "A generative pre-trained transformer model trained on biomedical text corpora (PubMed, etc.), enabling domain-adapted retrieval, summarization and QA to support literature-based discovery workflows.",
            "model_name": "BioGPT",
            "model_size": null,
            "scientific_domain": "Biomedical",
            "number_of_papers": null,
            "law_type": "Facilitates extraction/synthesis of literature-derived relationships and insights (qualitative associations, summaries, and hypothesis generation) rather than explicit numeric laws in the surveyed work.",
            "law_examples": "Used for literature retrieval and synthesis tasks; no explicit quantitative law equations are reported in this survey entry.",
            "extraction_method": "LM-based retrieval, summarization and QA from domain text (trained on PubMed-level corpora).",
            "validation_approach": "Not detailed in survey; original BioGPT paper evaluates generation/mining tasks within biomedicine.",
            "performance_metrics": null,
            "success_rate": null,
            "challenges_limitations": "Requires domain-specific training corpora; factuality and hallucination risk in generative outputs remain concerns.",
            "comparison_baseline": "Presented as a domain-adapted LM; comparative performance vs general LLMs discussed in primary literature (not enumerated in this survey).",
            "uuid": "e4221.5",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "SciGLM",
            "name_full": "SciGLM (Training scientific language models with self-reflective instruction annotation and tuning)",
            "brief_description": "A scientific-domain language model trained/tuned with self-reflective instruction annotation approaches to improve performance on scientific tasks such as retrieval and hypothesis support.",
            "citation_title": "SciGLM: Training scientific language models with self-reflective instruction annotation and tuning",
            "mention_or_use": "mention",
            "system_name": "SciGLM (scientific LLM with self-reflective tuning)",
            "system_description": "A training/tuning methodology for scientific LMs emphasizing self-reflective instruction annotations to improve reasoning and domain-specific performance; cited as an example of a state-of-the-art scientific LLM used for literature tasks.",
            "model_name": "SciGLM",
            "model_size": null,
            "scientific_domain": "General scientific literature (e.g., PubMed, arXiv)",
            "number_of_papers": null,
            "law_type": "Enables generation and synthesis of scientific relationships and hypotheses in natural language; not described as extracting explicit mathematical/quantitative laws in the survey.",
            "law_examples": null,
            "extraction_method": "LM-based synthesis and reasoning over scientific corpora using instruction-tuning/self-reflective annotations.",
            "validation_approach": "Not specified in this survey; original paper would contain evaluations.",
            "performance_metrics": null,
            "success_rate": null,
            "challenges_limitations": "Survey notes LLMs remain challenging in scalability and validation; model-specific limitations not detailed here.",
            "comparison_baseline": "Positioned as a domain-specific LLM improvement; direct baselines are in original work.",
            "uuid": "e4221.6",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Authors' COVID-19 pipeline",
            "name_full": "BERT-based semantic triple extraction + KG construction + KGC for COVID-19 drug repurposing",
            "brief_description": "The authors' LBD approach for COVID-19 drug repurposing: use a BERT variant as a preprocessing tool to extract semantic triples, build a KG, and apply KGC algorithms to predict repurposing candidates.",
            "citation_title": "Drug repurposing for COVID-19 via knowledge graph completion",
            "mention_or_use": "use",
            "system_name": "BERT-based semantic triple extraction + KG + KGC pipeline",
            "system_description": "Preprocess literature with a BERT variant ('BERT5' as stated) to generate a subset of semantic subject-relation-object triples, use those triples to construct a knowledge graph, and apply KGC algorithms to predict candidate drug repurposing edges in the KG.",
            "model_name": "BERT5 (as stated in the paper)",
            "model_size": null,
            "scientific_domain": "Biomedical (COVID-19 drug repurposing)",
            "number_of_papers": null,
            "law_type": "Discovery of candidate treatment relations (drug → treats → disease) and other biomedical semantic relations; qualitative relational predictions rather than explicit numeric laws.",
            "law_examples": "Predicting drug–disease treatment candidate edges (no explicit mathematical equations reported in survey summary).",
            "extraction_method": "Use BERT-based model to extract semantic predications from text (subject-relation-object triples), construct KG from these triples, then run KGC/link-prediction algorithms on the KG.",
            "validation_approach": "Applied KGC to predict repurposing candidates; original study likely validated candidates against known repurposing signals or subsequent evaluation (detailed validation protocols in the cited primary paper).",
            "performance_metrics": null,
            "success_rate": null,
            "challenges_limitations": "Relies on quality of semantic triple extraction (term normalization, UMLS coverage); many LBD approaches limited by abstract-only text, term ambiguity, and need for manual curation.",
            "comparison_baseline": "Compared methodologically to other KG and KGC approaches in the drug-repurposing literature; specific numeric comparisons are in the cited paper.",
            "uuid": "e4221.7",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "LLMs (general)",
            "name_full": "Large Language Models (PLMs/LLMs)",
            "brief_description": "Pre-trained and large language models (e.g., BERT variants, GPT-family, domain-specific LLMs) that provide contextual understanding, generation, and zero-shot reasoning to support literature-based discovery tasks.",
            "citation_title": "Large language models: A survey of their development, capabilities, and applications",
            "mention_or_use": "mention",
            "system_name": "Large language models (general LLM usage in LBD)",
            "system_description": "The survey describes PLMs and LLMs as core components of modern LBD pipelines: PLMs used for NER and relation extraction (preprocessing), and LLMs used for retrieval, summarization, question-answering, hypothesis generation, and grounding hypotheses in natural language (examples include BioGPT, SciGLM, GPT-4 as a baseline).",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Cross-domain (biomedicine emphasized, but potential to extend to social sciences and others)",
            "number_of_papers": null,
            "law_type": "Facilitate extraction/synthesis of relationships and patterns in literature (semantic relations and hypothesis statements). The survey does not claim LLMs extracted explicit quantitative mathematical laws in the cited examples.",
            "law_examples": "Generation of hypothesis sentences, retrieval/summarization of literature, and identification of relational candidates (no explicit equations provided in survey).",
            "extraction_method": "LM-based extraction: use PLMs for entity and relation extraction (semantic triples), or LLMs for natural-language grounded hypothesis generation and iterative refinement.",
            "validation_approach": "Reported empirical results showing improved reasoning and hypothesis generation capabilities in cited works; primary studies provide task-specific evaluations.",
            "performance_metrics": null,
            "success_rate": null,
            "challenges_limitations": "Scalability, factuality/hallucination, validation of generated hypotheses, dependence on high-quality corpora and ontologies, and limited interpretability of deep models; grounding LLM outputs to verifiable evidence remains a challenge.",
            "comparison_baseline": "Survey cites comparisons (e.g., SciMON vs GPT-4) and notes LLMs outperform earlier PLMs in generalization and reasoning in many tasks; numeric baselines are in the referenced works.",
            "uuid": "e4221.8",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Neural networks for open and closed literature-based discovery",
            "rating": 2,
            "sanitized_title": "neural_networks_for_open_and_closed_literaturebased_discovery"
        },
        {
            "paper_title": "Exploring a deep learning neural architecture for closed literature-based discovery",
            "rating": 2,
            "sanitized_title": "exploring_a_deep_learning_neural_architecture_for_closed_literaturebased_discovery"
        },
        {
            "paper_title": "Predicting implicit concept embeddings for singular relationship discovery replication of closed literature-based discovery",
            "rating": 2,
            "sanitized_title": "predicting_implicit_concept_embeddings_for_singular_relationship_discovery_replication_of_closed_literaturebased_discovery"
        },
        {
            "paper_title": "SciMON: Scientific inspiration machines optimized for novelty",
            "rating": 2,
            "sanitized_title": "scimon_scientific_inspiration_machines_optimized_for_novelty"
        },
        {
            "paper_title": "BioGPT: Generative pre-trained transformer for biomedical text generation and mining",
            "rating": 2,
            "sanitized_title": "biogpt_generative_pretrained_transformer_for_biomedical_text_generation_and_mining"
        },
        {
            "paper_title": "SciGLM: Training scientific language models with self-reflective instruction annotation and tuning",
            "rating": 2,
            "sanitized_title": "sciglm_training_scientific_language_models_with_selfreflective_instruction_annotation_and_tuning"
        },
        {
            "paper_title": "Drug repurposing for COVID-19 via knowledge graph completion",
            "rating": 2,
            "sanitized_title": "drug_repurposing_for_covid19_via_knowledge_graph_completion"
        },
        {
            "paper_title": "A computational inflection for scientific discovery",
            "rating": 2,
            "sanitized_title": "a_computational_inflection_for_scientific_discovery"
        },
        {
            "paper_title": "Large language models: A survey of their development, capabilities, and applications",
            "rating": 1,
            "sanitized_title": "large_language_models_a_survey_of_their_development_capabilities_and_applications"
        }
    ],
    "cost": 0.0160855,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Recent Advances and Future Directions in Literature-Based Discovery
14 Jun 2025</p>
<p>Andrej Kastrin andrej.kastrin@mf.uni-lj.si 
University of Ljubljana
LjubljanaSlovenia</p>
<p>Bojan Cestnik bojan.cestnik@temida.si 
Jožef Stefan Institute
LjubljanaSlovenia</p>
<p>Temida d
LjubljanaSlovenia</p>
<p>Nada Lavrač nada.lavrac@ijs.si 
Jožef Stefan Institute
LjubljanaSlovenia</p>
<p>Recent Advances and Future Directions in Literature-Based Discovery
14 Jun 2025DBA73BB417A8FE366670E0CC21569698arXiv:2506.12385v1[cs.CL]Artificial intelligenceNatural language processingComputational scientific discoveryLiterature-based discovery
The explosive growth of scientific publications has created an urgent need for automated methods that facilitate knowledge synthesis and hypothesis generation.Literature-based discovery (LBD) addresses this challenge by uncovering previously unknown associations between disparate domains.This article surveys recent methodological advances in LBD, focusing on developments from 2000 to the present.We review progress in three key areas: knowledge graph construction, deep learning approaches, and the integration of pre-trained and large language models (LLMs).While LBD has made notable progress, several fundamental challenges remain unresolved, particularly concerning scalability, reliance on structured data, and the need for extensive manual curation.By examining ongoing advances and outlining promising future directions, this survey underscores the transformative role of LLMs in enhancing LBD and aims to support researchers and practitioners in harnessing these technologies to accelerate scientific innovation.</p>
<p>Introduction</p>
<p>The explosive growth of research publications across various scientific disciplines has led to an overwhelming volume of knowledge, ranging from research articles and monographs to preprints and conference proceedings [4].This proliferation has made it increasingly difficult for researchers to effectively locate, interpret, and synthesize relevant knowledge.As a result, staying current within one's field becomes more challenging, and the risk of missing important findings or inadvertently duplicating existing work rises significantly.Furthermore, the increasing complexity and interdisciplinarity of research further complicate the task of integrating knowledge from multiple sources, and much of the information remains siloed, underutilized, or disconnected.These challenges have led to a rising interest in developing automated methods, particularly those based on natural language processing (NLP), to support hypothesis generation and the discovery of novel scientific insights.</p>
<p>A promising approach to address this problem is literature-based discovery (LBD).LBD, originally introduced by Swanson [29] in the mid-1980s, is an approach designed to generate novel research hypotheses by revealing previously overlooked associations between two complementary and non-interactive sets of scientific literatures.It emerged as a response to the growing difficulty of staying abreast of developments across disparate fields and remains a valuable methodology in the face of ever-expanding scholarly output.</p>
<p>The primary motivation of this article is to provide an overview of current methodological challenges in LBD, survey recent scientific advances, and identify future research directions that align LBD with emerging trends in AI and more broadly computational scientific discovery.We limit the scope to the period between 2000 and early 2025, focusing exclusively on state-of-the-art approaches, as earlier methods have already been comprehensively covered in previous surveys [28,12,32].</p>
<p>The article is organized as follows.Section 2 presents the necessary preliminaries and a concise overview of LBD research.Recent advances in LBD methodologies are examined in Section 3, followed by a discussion of future research directions in Section 4. The article concludes with a synthesis of key findings in Section 5.</p>
<p>Preliminaries and Background</p>
<p>LBD is a subfield of artificial intelligence (AI) at the intersection of information retrieval, NLP and computational scientific discovery, which is dedicated to automating the scientific discovery process.The early Swanson's approach to LBD can be formalized using a generic ABC model (Figure 1) that considers two independent literature sets, A and C [30].In this model, a represents a source concept, c is a target concept, and b serves as a bridge or intermediate concept that connects the two.The key idea is that if a is associated with b in one body of literature and b is associated with c in another-yet a and c have not been directly linked in any publication-there may be a novel, undiscovered relationship between a and c worth exploring.</p>
<p>A seminal example of this model is Swanson's [29] groundbreaking discovery linking dietary fish oil (a) to Raynaud's disease (c).He found that Raynaud's disease was associated with reduced blood viscosity in one set of articles, while another set linked high blood viscosity to fish oil.Although no studies at the time had made a direct connection between Raynaud's disease and fish oil, Swanson's hypothesis suggested a new therapeutic use for fish oil, which was later confirmed by clinical research [8].</p>
<p>In general, LBD encompasses two tasks: hypothesis validation and hypothesis generation, which correspond to closed and open discovery modes, respectively.In closed discovery, the process starts with two known elements-a starting concept (a) and a target concept (c)-and seeks to validate or elaborate the Despite its pivotal importance, the ABC model exhibits critical limitations that severely constrain the broader applicability of LBD.First, scalability remains a pressing challenge.Traditional LBD systems were developed for relatively small, curated datasets and are poorly suited to handle the exponential growth of biomedical publications [32].Effectively managing large-scale, heterogeneous corpora demands advanced computational capabilities and methodological innovations that classical LBD frameworks were not originally designed to support.</p>
<p>Second, the heavy reliance on structured data sources represents a major constraint.LBD approaches have historically depended on controlled vocabularies and ontologies, such as Unified Medical Language System (UMLS) [3], which facilitate computational access but simultaneously narrow the scope of discovery to well-represented areas [12].Consequently, current LBD systems often exhibit limited flexibility when extracting knowledge directly from unstructured or semi-structured texts, which account for a substantial portion of the scientific literature.</p>
<p>Third, the reliance on extensive manual curation and expert intervention remains a substantial barrier to progress in LBD.Traditional LBD workflows necessitate expert involvement at multiple stages, including hypothesis validation, result refinement, and relevance assessment [28].This dependence not only slows the overall discovery process but also poses significant challenges to achieving the scalability and reproducibility required for the broader application of LBD tools.</p>
<p>The landscape of LBD is evolving rapidly, but a comprehensive approach to tackling these challenges is essential for realizing its full potential in biomedical research and beyond.</p>
<p>Recent Advances</p>
<p>The field of LBD has seen notable progress in recent years, driven largely by advancements in machine learning, text mining, and statistical analysis.Research efforts have increasingly harnessed these technologies to develop more effective and sophisticated LBD systems.This section reviews three major directions contributing to the recent evolution of LBD: knowledge graphs (KGs), deep learning (DL), and language models (LMs).</p>
<p>Knowledge Graphs</p>
<p>KGs have emerged as a pivotal technology in NLP, offering a structured and scalable approach to organizing scientific knowledge.By representing information as networks of entities and their relationships, KGs enable graph-based reasoning and facilitate the identification of implicit associations across disparate literature sources.</p>
<p>Formally, KGs are defined as G = (V, E), where V represents the set of vertices (nodes) and E represents edges (links).Relationships in the graph are often modeled as triples (h, r, t), where h (head) and t (tail) are nodes and r is the relation connecting them.</p>
<p>Their construction typically follows two principal methodologies: (i) co-occurrence modeling, where links between entities are established if they co-appear within the same article; and (ii) explicit relation extraction, where semantic relationships are directly identified using specialized NLP tools such as SemRep [26].Co-occurrence models are widely adopted due to their simplicity and scalability, while relation extraction methods provide greater precision and richer semantic information. 4In particular, co-occurrence-based approaches have gained popularity in LBD systems owing to their ease of implementation [28,12].Recent approaches also enable the direct construction of KGs based on predications (subject-relation-object triples) extracted from sources such as PubMed abstracts.Resources such as the UMLS and Open Biomedical Ontologies (OBO) offer rich terminological frameworks that enhance the integration and crossreferencing of knowledge.</p>
<p>We approach LBD by formulating it as a knowledge graph completion (KGC) task.KGC techniques aim to predict missing information in graphs, either by discovering new edges (link prediction) or by identifying missing nodes (node prediction).Depending on the method used to construct the KG, the elements h, r, and t (as previously defined) may differ: in co-occurrence-based graphs, all three components often represent concepts or terms, whereas in relational databases, h and t denote entities and r represents a predicate, such as treats.</p>
<p>Examples include structures like "Fish oil" → "Blood viscosity" → "Raynaud's disease" for co-occurrence graphs, or "Fish oil" → treats → "Raynaud's disease" for relational graphs.</p>
<p>Two main approaches to KGC are usually employed: (i) evaluating the plausibility of candidate triples (h, r, t) by assigning a predictive score, and (ii) inferring missing elements by submitting incomplete triples, such as (h, r), (h, t), or (r, t), and predicting the missing component (i.e., predicting t given (h, r), r given (h, t), or h given (r, t)).</p>
<p>Deep Learning</p>
<p>In contrast to traditional machine learning methods that rely on features explicitly constructed using domain knowledge, DL uses specialized and deep architectures to extract meaningful features from unstructured input, can automatically learn from simple inputs, and extracts task-specific representations of structures.</p>
<p>Crichton et al. [5] provided compelling evidence that neural network models are highly effective for advancing LBD.The authors built upon a multilayer perceptron (MLP) framework designed for both closed and open discovery tasks, achieving state-of-the-art performance on the PubTator and BioGRID datasets.Their approach begins by generating input representations through node embeddings using the Large-scale Information Network Embedding (LINE) algorithm [31], followed by various strategies for combining the embeddings of nodes along a discovery path-structured according to Swanson's ABC model-to construct the input for the neural model.</p>
<p>In closed discovery, the first approach uses a neural model to assign scores to individual A−B and B−C links, which are then aggregated to evaluate the full A−B−C path.The second approach combines the embeddings of A, B, and C into a single input vector, allowing the model to predict a score for the entire path directly, thus removing the need for an explicit aggregation step.In open discovery, the first method similarly scores A−B and B−C links and aggregates them, but additionally uses an accumulator function to integrate multiple paths leading to the same C.The second method employs a convolutional neural network (CNN) that processes stacked embeddings of multiple A−B−C paths, producing a unified score for each A−C pair without relying on separate aggregation or accumulation functions.(Unlike conventional CNN applications where images are used, the input here is a pseudo-image created by stacking vectorized A−B−C paths.)</p>
<p>While Crichton et al. [5] relied on embedding representations for all concepts as model inputs, their method required users to manually construct all possible hypothesis triples prior to evaluation, a process that is both time-consuming and reliant on substantial domain expertise.Addressing this limitation, Cuffy et al. [6] introduced a closed discovery framework that automates the ranking of potential linking B terms for a given A and C pair using a single forward propagation step through the DL model.This approach eliminates the need to generate all A−B−C triples a priori, thereby reducing the dependency on domain-specific knowledge and significantly streamlining the LBD workflow.</p>
<p>Cuffy et al. [7] introduced a further advancement by reformulating the LBD task as the prediction of implicit concept embeddings rather than direct relationship scoring.Instead of classifying triples, their model predicts the embedding of the linking concept (B) given the starting (A) and target (C) concepts.By comparing predicted embeddings against all candidate concepts, the MLP model identifies plausible intermediates, demonstrating its effectiveness in systematic knowledge discovery replication.</p>
<p>Beyond general-purpose LBD tasks, DL has been effectively applied in domainspecific applications, such as drug repurposing.Zhu et al. [39] introduced a BioBERT-based model enhanced with entity-aware attention mechanisms for drug-drug interaction extraction, while Gupta et al. [10] utilized an NSGA-III-based CNN architecture to optimize biomedical search engines.Rather et al. [25] further showcased DL's capacity to uncover latent biomedical relationships through word2vec-based embeddings.Taken together, these studies demonstrate the transformative potential of DL for LBD, facilitating more nuanced knowledge representation and discovery.</p>
<p>Language Models</p>
<p>LMs are nowadays regarded as fundamental components of NLP, tasked with estimating the probability distributions of linguistic units-such as words, phrases, or sentences-based on their contextual surroundings.The evolution of LMs can be delineated into several distinct stages: beginning with statistical language models (SLMs), progressing through neural language models (NLMs), advancing to pre-trained language models (PLMs), and culminating in the emergence of large language models (LLMs).SLMs utilize basic probabilistic frameworks to model word sequences (e.g., n-grams), whereas NLMs employ neural networks to capture complex syntactic and semantic patterns (e.g., RNNs, LSTMs, transformers).PLMs leverage large-scale textual corpora and self-supervised learning to encode general linguistic structures and knowledge (e.g., Bidirectional Encoder Representations from Transformers (BERT), Generative Pretrained Transformer (GPT)).</p>
<p>Here, we focus specifically on how recent developments in PLMs and LLMs have been integrated into LBD pipelines.While both PLMs and LLMs are trained on large corpora using self-supervised methods, LLMs represent a significant advancement in terms of model size, training data scale, and architectural complexity.Building upon the foundation established by PLMs, LLMs offer improved generalization, greater expressivity, enhanced contextual understanding, adaptability, and zero-shot reasoning capabilities-making them particularly well-suited for advanced LBD tasks.A comprehensive overview of the historical development of LMs is provided in recent surveys by Wang et al. [34] and Annepaka et al. [1].</p>
<p>PLMs have elevated the quality and scope of LBD by integrating deep contextual understanding into NLP pipelines.Used both as powerful preprocessing tools and as core components in downstream tasks such as named entity recognition and relation extraction, PLMs have enabled more accurate and scalable discovery workflows.For example, in our LBD approach to drug repurposing for Covid-19 [38], we employed BERT5 as a preprocessing tool to generate an accurate subset of semantic triples, which were then used to construct a KG.KGC algorithms were subsequently applied to this graph to predict potential drug repurposing candidates.</p>
<p>Compared to PLMs, LLMs exhibit remarkable adaptability, with recent empirical results indicating strong potential for their use as a general-purpose tool to support scientific reasoning [13].A growing body of evidence reveals a broad range of promising capabilities of LLM relevant to the scientific process, including the coherent integration of diverse knowledge concepts, the critical evaluation of existing studies, the generation of scientific hypotheses, and the identification of research gaps within scientific literature [21].State-of-the-art LLMs, such as BioGPT [20] and SciGLM [37] are trained on domain-specific corpora like PubMed and arXiv and are particularly effective at literature retrieval, document summarization, and question answering.They facilitate more efficient access to scientific information by identifying relevant publications, extracting key insights, and synthesizing knowledge across documents.</p>
<p>Specifically, building on the improved reasoning capabilities of LMs, the LBD community has begun developing methods that incorporate richer contextual information to address the limitations of traditional approaches, which are primarily based on the ABC model.Classical LBD techniques often fail to capture the nuanced contextual cues considered by human scientists during the ideation process and are largely restricted to predicting pairwise relationships between isolated concepts [13].To overcome these constraints, Wang et al. [33] introduced a novel framework, SciMON, which grounds LBD in natural language contexts, thereby narrowing the generative space in a more controlled and meaningful way.SciMON optimizes novel research hypotheses by iteratively refining idea suggestions derived from published literature until sufficient novelty is achieved.Unlike traditional models that merely predict conceptual links, SciMON generates complete sentences as outputs, offering a more nuanced and contextually rich representation of scientific knowledge.The authors report that it produces ideas that are both more original and exhibit greater conceptual depth than those generated by GPT-4.</p>
<p>A long-standing limitation of LBD has been its restriction to the biomedical domain, primarily due to the widespread availability of the PubMed database and auxiliary knowledge resources (e.g., UMLS vocabularies [3], SemMedDB repository [16], PubTator annotations [35]), which are freely available and optimized for computational access and analysis.However, LLM-powered LBD may have a much broader scope of applicability.In particular, Yang et al. [36] showed that the majority of published hypotheses in the social sciences can be structured in a manner compatible with the LBD framework.</p>
<p>In summary, recent advances in KGs, DL techniques, and LM development have significantly expanded the capabilities of LBD.Table 1 highlights the principal characteristics of the described approaches.Nevertheless, several key challenges remain, which are discussed in the following section.</p>
<p>Future Directions</p>
<p>Although LBD has made significant advances over the past five years, numerous open challenges remain to be addressed.The following discussion outlines several key areas of ongoing work, reflecting the current focus of our research efforts; however, the list is not intended to be exhaustive.</p>
<p>Advancing Interpretability</p>
<p>Interpretability remains one of the principal challenges associated with the application of DL techniques in science [24].Ensuring interpretability in LBD is not simply an auxiliary feature; it is foundational.While DL approaches offer considerable potential for enhancing hypothesis generation from large corpora, their inherent "black-box" nature continues to present significant obstacles for scientific domains where transparent reasoning processes are essential.In particular, many LBD methods, especially those rooted in Swanson's ABC model, focus primarily on hypothesis generation but often lack mechanisms for explaining the reasoning behind the generated hypotheses.While DL systems excel in extracting patterns from literature, they frequently fall short of providing understandable explanations, which symbolic systems have historically offered [2].</p>
<p>Traditional strategies, such as employing attention mechanisms or inspecting model coefficients, offer partial solutions by highlighting feature importance or visualizing internal representations [22].However, these approaches often lack a structured reasoning component and thus fall short of delivering full scientific explanatory power.A promising direction is the integration of neuro-symbolic AI into LBD methodologies.The neuro-symbolic approach aims to combine the pattern recognition capabilities of neural networks with the explicit reasoning structures of symbolic AI [27,2].This integration enables models not only to learn from data but also to reason in ways that are inherently interpretable and grounded in logical principles.Neuro-symbolic approaches have already been successfully applied to various NLP tasks [11].</p>
<p>Augmenting Data Resources</p>
<p>One of the principal limitations of current LBD applications lies in their restricted use of data resources.Most existing approaches rely primarily on Pub-Med, often limiting their textual input to article abstracts rather than utilizing the full texts.While abstracts offer a concise summary of findings, they frequently omit critical contextual relationships that could be valuable for complex hypothesis generation, particularly for LMs.Expanding beyond the biomedical domain to include full-text articles and additional knowledge bases presents a significant opportunity for advancing LBD.In particular, new bibliographic databases such as Semantic Scholar [19] have emerged as valuable resources.These platforms aggregate extensive metadata, citation networks, and, in some cases, full-text content across a wide range of scientific disciplines, offering richer semantic contexts for discovery processes.</p>
<p>In addition, auxiliary knowledge resources, such as the UMLS for the biomedical domain, are of significant importance, particularly during the preprocessing stages of LBD (e.g., guiding the extraction of knowledge concepts and the computation of predicates).Although widely integrated into LBD applications for its standardized vocabularies and extensive concept mappings, the use of UMLS is not without limitations.Issues such as term ambiguity and incomplete concept coverage can substantially impact the performance of downstream tasks.For instance, a significant portion of errors in tools like SemRep stem from difficulties in correctly identifying and normalizing biomedical entities using UMLS, accounting for up to 27% of errors in some evaluations [15].FurthermoreIn addition, auxiliary knowledge resources, such as the UMLS for the biomedical domain, are of significant importance, particularly during the preprocessing stages of LBD (e.g., guiding the extraction of knowledge concepts and the computation of predicates).Although widely integrated into LBD applications for its standardized vocabularies and extensive concept mappings, the use of UMLS is not without limitations.Issues such as term ambiguity and incomplete concept coverage can substantially impact the performance of downstream tasks.For instance, a significant portion of errors in tools like SemRep stem from difficulties in correctly identifying and normalizing biomedical entities using UMLS, accounting for up to 27% of errors in some evaluations [15].Finally, to the best of our knowledge at the time of writing, no comparably well-developed knowledge resource exists outside the life sciences domain.In our experience, the limited adoption of LBD beyond biomedicine is largely due to the greater terminological diversity and, in particular, the absence of standardized ontologies in the humanities and social sciences., to the best of our knowledge at the time of writing, no comparably well-developed knowledge resource exists outside the life sciences domain.In our experience, the limited adoption of LBD beyond biomedicine is largely due to the greater terminological diversity and, in particular, the absence of standardized ontologies in the humanities and social sciences.</p>
<p>Refining Benchmarking Practices</p>
<p>Knuth's [17] concept of literate programming, which emphasizes that computer programs should be readable and understandable by humans, closely aligns with open science initiatives that stress the importance of standardized practices and tools to ensure research outputs are independently verifiable and can support further scientific progress.</p>
<p>Following the principles of open science, we initiated a project aimed at promoting reproducibility within the field of LBD.Existing LBD approaches and results often remain difficult to replicate due to the lack of access to original datasets and unresolved programming dependencies.These limitations pose significant barriers to both the theoretical understanding and practical reuse of previously published methods.To address this gap, we have made publicly available benchmark datasets, replicable LBD case studies, and a collection of interactive Jupyter Notebooks that transparently document each step of the LBD pipeline, including data acquisition, text preprocessing, hypothesis discovery, and evaluation.Furthermore, we provide the LBD community with access to standardized benchmark datasets and prototypical LBD techniques presented through dockerized Jupyter environments, thereby greatly simplifying replication and extension.All associated materials are openly accessible at https: //github.com/akastrin/ida2025lbd.</p>
<p>Conclusion</p>
<p>This survey has reviewed the evolution of LBD over the past five years.We discussed the growing role of KGs, advances in DL methodologies, and the transformative impact of PLMs and LLMs on hypothesis generation and scientific reasoning.</p>
<p>Rapid advances in AI, particularly in the development of LLMs, are reshaping the scientific landscape at an unprecedented pace.These developments open up significant opportunities for treating scientific corpora as dynamic knowledge bases from which novel insights, hypotheses, and ideas can be systematically uncovered.Despite this progress, several fundamental challenges remain unresolved in LBD, notably issues related to scalability, dependence on structured data, the need for extensive manual curation, and the limited interpretability of current DL approaches.</p>
<p>Recent trends in neuro-symbolic AI suggest promising avenues for enhancing both the accuracy and explainability of LBD systems.By combining the strengths of DL with the reasoning capabilities of symbolic methods, these hybrid approaches aim to deliver more transparent and trustworthy discoveries, thereby enabling broader domain applicability of LBD beyond the biomedical sciences.</p>
<p>Fig. 1 .
1
Fig. 1.Swanson's ABC model of discovery.When a is related to b, and b is related to c, it suggests the possibility of an undiscovered indirect relationship between a and c.</p>
<p>Table 1 .
1
Summary of key strengths and limitations of recent approaches in LBD.
Approach StrengthsLimitationsKGsCaptures complex, heterogeneousRequires high-quality semanticassociations; enables context-annotation; extensive filtering of-driven subgraph creation.ten needed.DLOutperforms traditional base-Interpretability remains a chal-lines, especially when input rep-lenge; generalizability may beresentations are well-optimized.constrained by data representa-tion.LMsOffers potential for explainableStill emerging; scalability and val-AI; capable of processing hetero-idation challenges.geneous, cross-domain data.
Co-occurrence refers to the statistical tendency of two terms or concepts to appear together in text (e.g., fever and infection), without implying a specific semantic or causal relationship. In contrast, a semantic relation denotes a defined and meaningful connection between terms, such as a taxonomic link (e.g., influenza as a type of viral infection), regardless of how frequently they co-occur.
Due to its success in general NLP tasks, BERT has been adapted to various specialized domains, including biomedicine, resulting in models such as BioBERT[18], ClinicalBERT[14], PubMedBERT[9], and COVID-Twitter-BERT[23].
Acknowledgments.The authors acknowledge the financial support from the Slovenian Research and Innovation Agency through the Knowledge Technologies (Grant No. P2-0103), and Methodology for Data Analysis in Medical Sciences (Grant No. P3-0154) core research projects, as well as Embeddings-Based Techniques for Media Monitoring Applications (Grant No. L2-50070) research project.Disclosure of Interests.The authors have no competing interests to declare that are relevant to the content of this article.
Large language models: A survey of their development, capabilities, and applications. Y Annepaka, P Pakray, 10.1007/s10115-024-02310-4Knowledge and Information Systems. 6732025</p>
<p>Neuro-symbolic artificial intelligence: A survey. B P Bhuyan, A Ramdane-Cherif, R Tomar, T P Singh, 10.1007/s00521-024-09960-zNeural Computing and Applications. 36212024</p>
<p>The Unified Medical Language System (UMLS): Integrating biomedical terminology. O Bodenreider, 10.1093/nar/gkh061Nucleic Acids Research. 32Database2004</p>
<p>Growth rates of modern science: A latent piecewise growth curve approach to model publication numbers from established and new literature databases. L Bornmann, R Haunschild, R Mutz, 10.1057/s41599-021-00903-wHumanities and Social Sciences Communications. 812242021</p>
<p>Neural networks for open and closed literature-based discovery. G Crichton, S Baker, Y Guo, A Korhonen, 10.1371/journal.pone.0232891PLoS One. 155e02328912020</p>
<p>Exploring a deep learning neural architecture for closed literature-based discovery. C Cuffy, B T Mcinnes, 10.1016/j.jbi.2023.104362Journal of Biomedical Informatics. 1431043622023</p>
<p>Predicting implicit concept embeddings for singular relationship discovery replication of closed literature-based discovery. C Cuffy, B T Mcinnes, 10.3389/frma.2025.1509502Frontiers in Research Metrics and Analytics. 1015095022025</p>
<p>Fish-oil dietary supplementation in patients with Raynaud's phenomenon: A double-blind, controlled, prospective study. R A Digiacomo, J M Kremer, D M Shah, 10.1016/0002-9343(89)90261-1The American Journal of Medicine. 8621989</p>
<p>Domainspecific language model pretraining for biomedical natural language processing. Y Gu, R Tinn, H Cheng, M Lucas, N Usuyama, X Liu, 10.1145/3458754ACM Transactions on Computing for Healthcare. 312021</p>
<p>NSGA-III-based deep-learning model for biomedical search engines. M Gupta, N Kumar, B K Singh, N Gupta, 10.1155/2021/9935862Mathematical Problems in Engineering. 2021199358622021</p>
<p>Is neuro-symbolic AI meeting its promises in natural language processing? A structured review. Nayak Hamilton, A Božić, B Longo, L , 10.3233/SW-223228Semantic Web. 1542024</p>
<p>Literature based discovery: Models, methods, and trends. S Henry, B T Mcinnes, 10.1016/j.jbi.2017.08.011Journal of Biomedical Informatics. 742017</p>
<p>A computational inflection for scientific discovery. T Hope, D Downey, D S Weld, O Etzioni, E Horvitz, 10.1145/3576896Communications of the ACM. 6682023</p>
<p>K Huang, J Altosaar, R Ranganath, 10.48550/arXiv.1904.05342arXivClinicalBERT: Modeling clinical notes and predicting hospital readmission. 2020</p>
<p>Broad-coverage biomedical relation extraction with SemRep. H Kilicoglu, G Rosemblat, M Fiszman, D Shin, 10.1186/s12859-020-3517-7BMC Bioinformatics. 2111882020</p>
<p>SemMedDB: A PubMed-scale repository of biomedical semantic predications. H Kilicoglu, D Shin, M Fiszman, G Rosemblat, T C Rindflesch, 10.1093/bioinformatics/bts591Bioinformatics. 28232012</p>
<p>Literate programming. D E Knuth, The Computer Journal. 2721984</p>
<p>BioBERT: A pre-trained biomedical language representation model for biomedical text mining. J Lee, W Yoon, S Kim, D Kim, S Kim, C H So, 10.1093/bioinformatics/btz682Bioinformatics. 3642020</p>
<p>S2ORC: The Semantic Scholar Open Research Corpus. K Lo, L L Wang, M Neumann, R Kinney, D Weld, 10.18653/v1/2020.acl-main.447Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. D Jurafsky, J Chai, N Schluter, J Tetreault, the 58th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics2020</p>
<p>BioGPT: Generative pre-trained transformer for biomedical text generation and mining. R Luo, L Sun, Y Xia, T Qin, S Zhang, H Poon, 10.1093/bib/bbac409Briefings in Bioinformatics. 2364092022</p>
<p>Z Luo, Z Yang, Z Xu, W Yang, X Du, 10.48550/arXiv.2501.04306LLM4SR: A survey on large language models for scientific research. 2025</p>
<p>Explainable artificial intelligence: A survey of needs, techniques, applications, and future direction. M Mersha, K Lam, J Wood, A K Alshami, J Kalita, 10.1016/j.neucom.2024.128111Neurocomputing. 5991281112024</p>
<p>COVID-Twitter-BERT: A natural language processing model to analyse COVID-19 content on Twitter. M Müller, M Salathé, P E Kummervold, 10.3389/frai.2023.1023281Frontiers in Artificial Intelligence. 610232812023</p>
<p>Definitions, methods, and applications in interpretable machine learning. W J Murdoch, C Singh, K Kumbier, R Abbasi-Asl, B Yu, 10.1073/pnas.1900654116Proceedings of the National Academy of Sciences. the National Academy of Sciences2019116</p>
<p>Using deep learning towards biomedical knowledge discovery. N N Rather, C O Patel, S A Khan, 10.5815/ijmsc.2017.02.01International Journal of Mathematical Sciences and Computing. 322017</p>
<p>The interaction of domain knowledge and linguistic structure in natural language processing: Interpreting hypernymic propositions in biomedical text. T C Rindflesch, M Fiszman, 10.1016/j.jbi.2003.11.003Journal of Biomedical Informatics. 3662003</p>
<p>Neuro-symbolic artificial intelligence: Current trends. M K Sarker, L Zhou, A Eberhart, P Hitzler, 10.3233/AIC-210084AI Communications. 3432021</p>
<p>Learning the heterogeneous bibliographic information network for literature-based discovery. Y Sebastian, E G Siew, S O Orimaye, 10.1016/j.knosys.2016.10.015Knowledge-Based Systems. 1152017</p>
<p>Fish oil, Raynaud's syndrome, and undiscovered public knowledge. D R Swanson, 10.1353/pbm.1986.0087Perspectives in Biology and Medicine. 3011986</p>
<p>Undiscovered public knowledge. D R Swanson, 10.1086/601720The Library Quarterly. 5621986</p>
<p>LINE: Large-scale information network embedding. J Tang, M Qu, M Wang, M Zhang, J Yan, Q Mei, 10.1145/2736277.2741093Proceedings of the 24th International Conference on World Wide Web. A Gangemi, S Leonardi, A Panconesi, the 24th International Conference on World Wide Web2015International World Wide Web Conference Committee</p>
<p>A systematic review on literaturebased discovery: General overview, methodology, &amp; statistical analysis. M Thilakaratne, K Falkner, T Atapattu, 10.1145/3365756ACM Computing Surveys. 5261292019</p>
<p>SciMON: Scientific inspiration machines optimized for novelty. Q Wang, D Downey, H Ji, T Hope, 10.18653/v1/2024.acl-long.18Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. L W Ku, A Martins, V Srikumar, the 62nd Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics2024</p>
<p>History, development, and principles of large language models: An introductory survey. Z Wang, Z Chu, T V Doan, S Ni, M Yang, W Zhang, 10.1007/s43681-024-00583-7AI and Ethics. 52025</p>
<p>PubTator 3.0: An AI-powered literature resource for unlocking biomedical knowledge. C H Wei, A Allot, P T Lai, R Leaman, S Tian, L Luo, 10.1093/nar/gkae235Nucleic Acids Research. 52W12024</p>
<p>Large language models for automated open-domain scientific hypotheses discovery. Z Yang, X Du, J Li, J Zheng, S Poria, E Cambria, 10.18653/v1/2024.findings-acl.804Findings of the Association for Computational Linguistics: ACL 2024. L W Ku, A Martins, V Srikumar, Association for Computational Linguistics2024</p>
<p>SciGLM: Training scientific language models with self-reflective instruction annotation and tuning. D Zhang, Z Hu, S Zhoubian, Z Du, K Yang, Z Wang, 10.48550/arXiv.1904.05342arXiv2024</p>
<p>Drug repurposing for COVID-19 via knowledge graph completion. R Zhang, D Hristovski, D Schutte, A Kastrin, M Fiszman, H Kilicoglu, 10.1016/j.jbi.2021.103696Journal of Biomedical Informatics. 1151036962021</p>
<p>Extracting drug-drug interactions from texts with BioBERT and multiple entity-aware attentions. Y Zhu, L Li, H Lu, A Zhou, X Qin, 10.1016/j.jbi.2020.103451Journal of Biomedical Informatics. 1061034512020</p>            </div>
        </div>

    </div>
</body>
</html>