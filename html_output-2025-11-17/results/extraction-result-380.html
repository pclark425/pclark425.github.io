<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-380 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-380</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-380</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-16.html">extraction-schema-16</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <p><strong>Paper ID:</strong> paper-14154185</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1109.6341v1.pdf" target="_blank">Domain Adaptation for Statistical Classifiers</a></p>
                <p><strong>Paper Abstract:</strong> The most basic assumption used in statistical learning theory is that training data and test data are drawn from the same underlying distribution. Unfortunately, in many applications, the"in-domain"test data is drawn from a distribution that is related, but not identical, to the"out-of-domain"distribution of the training data. We consider the common case in which labeled out-of-domain data is plentiful, but labeled in-domain data is scarce. We introduce a statistical formulation of this problem in terms of a simple mixture model and present an instantiation of this framework to maximum entropy classifiers and their linear chain counterparts. We present efficient inference algorithms for this special case based on the technique of conditional expectation maximization. Our experimental results show that our approach leads to improved performance on three real world tasks on four different data sets from the natural language processing domain.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e380.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e380.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prior-based adaptation (Chelba & Acero)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prior-estimation domain adaptation using out-of-domain maximum entropy weights as Gaussian prior mean</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An adaptation technique which trains a maximum entropy model on out-of-domain data and uses the learned weights as the mean of a Gaussian prior when training an in-domain maximum entropy classifier, thereby transferring parameter information from the out-of-domain domain to the in-domain estimator.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Adaptation of maximum entropy classifier: Little data can help a lot.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Prior-based parameter transfer for discriminative classifiers</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Train a maximum entropy model on abundant out-of-domain labeled data to obtain parameter weights. Use those learned weights as the mean of an isotropic Gaussian prior over parameters when training a maximum entropy model on scarce in-domain labeled data; perform MAP estimation for the in-domain parameters under this prior. This biases the in-domain solution toward the out-of-domain solution while allowing adaptation to in-domain evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / model-regularization technique</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>Natural language processing — out-of-domain corpora (e.g., newswire)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>Natural language processing — in-domain corpora (e.g., conversational speech, transcribed speech, biomedical text)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>The core idea is to convert learned discriminative weights from the source domain into a prior distribution (Gaussian) for use in MAP estimation on a related but different target domain; hyperparameters (prior variance) are tuned on development data. Implementation requires replacing the zero-mean prior normally used with a mean equal to out-of-domain weights.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful — used as a competitive baseline in experiments; improved over naive baselines but was outperformed by the Mega Model. Paper reports the Prior model performed roughly comparably to other baselines but was consistently weaker than the Mega Model across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Theoretically odd to estimate and then fix a prior from data; model is asymmetric (treats in-domain and out-of-domain differently); difficult to generalize to multiple out-of-domain datasets; may overconstrain in-domain estimation when distributions differ substantially.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Availability of abundant labeled out-of-domain data; straightforward implementation within maximum entropy training frameworks; compatibility with Gaussian MAP regularization.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Requires a trained out-of-domain classifier and sufficient in-domain labeled data to tune hyperparameters (development set or cross-validation) and to perform MAP estimation; computational ability to train maximum entropy models with Gaussian priors.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Limited: method is directly applicable to discriminative classifiers where Gaussian priors are used; but theoretical and practical limitations reduce applicability when source and target distributions differ strongly or when multiple source domains exist.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps and modelling/regularization principle</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation for Statistical Classifiers', 'publication_date_yy_mm': '2011-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e380.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e380.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Feats baseline (use predictions as features)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Using out-of-domain classifier predictions as additional features for in-domain learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transfer technique that builds a classifier on out-of-domain data and uses that classifier's predictions (on in-domain inputs) as additional features for training an in-domain classifier, enabling transfer of predictive structure without altering the in-domain model architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Prediction-as-feature transfer</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Train one or more classifiers on source (out-of-domain) data. Run the trained source classifier(s) on target (in-domain) inputs and take their output predictions (class probabilities or discrete labels) as new features appended to the in-domain feature vector. Train a target-domain classifier using the augmented feature vectors, thereby leveraging source-domain predictive signals.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / feature-augmentation technique</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>Natural language processing — out-of-domain corpora (newswire/broadcast news)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>Natural language processing — in-domain corpora (conversational speech, transcribed speech)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application with simple adaptation (feature augmentation)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>No fundamental change to the source classifier; its outputs are simply encoded and concatenated to in-domain features. Implementation choices include whether to pass hard labels or soft probabilities and whether to stack multiple source models.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful — evaluated as a baseline and shown to perform roughly comparably to the Prior model on the tasks in this paper, but inferior to the Mega Model overall.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Requires careful handling of correlated/noisy predictions; risk of propagating domain mismatch errors into the in-domain learner; needs design choices for encoding predictions as features and might need held-out data for calibration.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Method-agnostic (works with arbitrary classifiers), easy to implement, does not require joint modeling of latent variables between domains.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Needs a trained source-domain classifier and the ability to run it on target inputs; requires additional features to be handled by the target classifier and (optionally) a development set to tune how predictions are encoded.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>High within supervised learning: applicable across classification tasks and model families where source predictions can be computed; less appropriate when source predictions are systematically biased for the target domain.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps / instrumental technique</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation for Statistical Classifiers', 'publication_date_yy_mm': '2011-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e380.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e380.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conditional Expectation Maximization (CEM)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Maximum conditional likelihood via bound maximization and the CEM algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An EM-style optimization algorithm tailored to discriminative (conditional) models with hidden variables that maximizes a lower bound on the change in conditional likelihood between iterations, enabling efficient inference in conditional models with latent structure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Maximum conditional likelihood via bound maximization and the CEM algorithm.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Conditional Expectation Maximization (CEM)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>An iterative bound-maximization algorithm for conditional models with latent variables. At each iteration: (E-step) compute posterior expectations of latent variables under current parameters; (M-step) maximize a derived lower bound (using Jensen's inequality for the joint term and a variational upper bound for negated marginal terms) with respect to parameters, optionally including priors (MAP). The algorithm guarantees monotonic increase in conditional likelihood change and is suitable for discriminative models like the Mega Model.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / optimization algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>Statistical machine learning / discriminative model optimization (algorithmic research literature)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>Applied domain adaptation for discriminative NLP models (maximum entropy and linear-chain models)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Applied the CEM algorithm specifically to the Mega Model's hierarchical conditional mixture; derived closed-form E-step for binary latent indicators z and derived M-step updates for MAP parameters (π, λ, ψ) including weighted maximum-entropy optimizations and analytic updates for certain parameters. Incorporated Gaussian and Beta priors into the CEM bound.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful — CEM enabled efficient inference for the Mega Model; empirical behavior: convergence typically in 2–5 iterations, with 5 iterations sufficient in experiments; overall facilitated the improved predictive performance of the Mega Model.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>CEM optimization still requires repeated expensive weighted maximum-entropy (BFGS) optimizations (dominant cost); potential for local optima (authors note possibility of stochastic temperature-based methods but did not need them).</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>CEM is designed for conditional models and provides monotonic improvement guarantees; the Mega Model's latent structure admits tractable E-step and analytic/MAP M-step components; reusing prior optimization state (warm starts) reduces overall runtime.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Need to implement both expectation computations for latent z and weighted maximum-entropy optimization (e.g., L-BFGS); priors and partition functions must be computable; development data to tune hyperparameters; computational resources to perform multiple weighted optimizations.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>High for discriminative models with latent variables: authors note CEM is the appropriate choice for such conditional models and that the same approach can be applied to other conditional frameworks, subject to tractability of E/M steps.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>theoretical principles (variational bounds) plus explicit algorithmic procedure</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation for Statistical Classifiers', 'publication_date_yy_mm': '2011-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e380.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e380.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mega Model (mixture-domain adaptation)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Maximum Entropy Genre Adaptation Model (Mega Model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A novel hierarchical mixture model for domain adaptation that models in-domain and out-of-domain data as mixtures over three underlying distributions (truly in-domain, truly out-of-domain, and general-domain) and integrates this with maximum entropy classifiers and linear-chain sequence models using latent indicator variables and CEM for inference.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Three-component mixture domain adaptation for discriminative classifiers</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Assume three latent generating distributions q(i), q(o), q(g). Model in-domain distribution p(i) as mixture of q(i) and q(g) and out-of-domain p(o) as mixture of q(o) and q(g). Introduce binary latent indicator z for each example indicating whether it is 'truly domain-specific' or 'general'. For inputs x, model their generative distribution with naive-Bayes Bernoulli parameters ψ; for labels y use conditional maximum entropy Gibbs distributions with parameter vectors λ(i), λ(o), λ(g) depending on z. Place Beta priors on ψ and Gaussian priors on λ. Perform inference/learning via Conditional EM with derived E- and M-steps (weighted maxent optimizations and analytic updates). For sequence data, apply per-token z indicators in a MEMM extension.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / probabilistic modelling + optimization</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>Natural language processing — out-of-domain annotated corpora (e.g., newswire / Wall Street Journal)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>Natural language processing — diverse in-domain tasks (conversational Fisher data, ASR-transcribed broadcast news, recapitalization corpora CNN/NPR and ABC)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context (mixture modelling and conditional inference integrated into discriminative classifiers)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Integrated a three-component mixture into a conditional maximum-entropy framework, introduced latent z indicators, coupled generative naive-Bayes modeling of input features with discriminative Gibbs classifiers, and applied CEM to perform MAP estimation of hierarchical parameters. For sequence labeling, adapted to MEMM with per-token z variables and discussed extension to CRFs (not used for efficiency reasons). Also applied feature selection (information gain) to the naive Bayes features in recapitalization task to prevent overfitting.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful — consistently outperformed all baseline systems (OnlyI, OnlyO, Mix, MixW, Feats, Prior) across four datasets. Reported improvements: Mention Type accuracy from 81.2% (OnlyI) to 92.1% (Mega) (+13.4% relative); Mention Tagging F from 83.5% to 88.2% (+5.6% relative); ABC recap from 95.5% to 98.1% (+2.9% relative); CNN/NPR recap from 94.6% to 96.8% (+2.3% relative). Statistical significance reported (e.g., p ≤ 0.03 for Mention Type vs Prior).</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Inference is more complex than standard maxent; dominant computational cost is repeated weighted maximum-entropy optimizations across CEM iterations (authors report up to ~15 such optimizations but mitigated by warm starts). Naive-Bayes generative component can overfit on high-dimensional/noisy features (necessitating feature selection for some tasks). CRF extension would be computationally expensive if z is per-token.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Shared general-domain structure between source and target (q(g)) allows transfer; abundant labeled out-of-domain data supplies information about q(g); binary-feature representation and weighted maxent optimization are straightforward to implement; bound-based CEM gives convergence guarantees; warm start of optimizers reduces runtime.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Labeled out-of-domain data (large), some labeled in-domain data (can be small), capacity to run weighted maximum-entropy training (L-BFGS), ability to compute posterior expectations for latent variables, and (for recap task) feature-selection infrastructure to control naive-Bayes overfitting. Hyperparameter tuning via dev set (20%).</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Authors argue the core idea (decomposing p(i) and p(o) into q(i), q(o), q(g)) is general and can be applied to other modeling frameworks including generative models (where standard EM suffices), language modelling, and machine translation; extension to other discriminative sequence models (CRFs) is possible but may require computational trade-offs.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>theoretical modelling principles plus explicit algorithmic procedures and implementation details</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation for Statistical Classifiers', 'publication_date_yy_mm': '2011-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e380.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e380.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Linear-chain adaptation (MEMM / CRF discussion)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Extension of the Mega Model to linear-chain sequence models (Maximum Entropy Markov Models and Conditional Random Fields)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Application/adaptation of the three-component mixture adaptation framework to sequence-labeling models: implemented for MEMMs (per-token z indicators) and discussed for CRFs with caution about computational costs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Adaptation of mixture-domain approach to linear-chain models (MEMM/CRF)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Extend per-instance latent indicator z to per-token indicators within a linear-chain discriminative sequence model. For MEMMs, treat each token's label conditioning as a Gibbs distribution parameterized by λ(z) and run CEM with token-wise expectations; for CRFs, consider assigning z per-sentence or per-token but note per-token z in CRFs increases computational cost due to global normalization.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / model-extension</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>Sequence labeling in NLP trained on out-of-domain corpora (newswire)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>Sequence labeling for in-domain sequence types (ASR-transcribed text, recapitalization tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>For MEMM: use per-word z indicators and perform weighted MEMM optimization inside the CEM M-step. For CRF: authors discuss options (one z per sentence vs one per word) and note direct per-word z in CRFs is computationally expensive; thus CRF extension is left for future work or requires approximate computation.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful for MEMM (used empirically for mention tagging and recap tasks); CRF extension not implemented due to computational concerns, only discussed as feasible with tradeoffs.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>In CRFs, per-token latent variables increase complexity because of global normalization across sequences, making inference and CEM more expensive; computational cost is the main barrier.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>MEMM's per-state (local) normalization aligns naturally with per-token z indicators enabling efficient application; shared feature representations between classification and sequence tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Need infrastructure for MEMM training (weighted per-token optimization), ability to compute token-level z expectations, and computational resources adequate for repeated weighted sequence-model optimizations.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Moderate — MEMM extension is straightforward and effective; CRF extension is conceptually possible but may be computationally expensive, requiring approximations or efficient inference schemes to be practical.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>algorithmic adaptation and instrumental/technical skills</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation for Statistical Classifiers', 'publication_date_yy_mm': '2011-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e380.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e380.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Information-gain feature selection applied to Naive Bayes component</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Feature selection using information gain to prevent naive Bayes overfitting in the Mega Model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Applying a standard text feature-selection criterion (information gain) to the feature set used by the generative naive Bayes portion of the Mega Model to reduce overfitting and improve recapitalization task performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An extensive empirical study of feature selection metrics for text classification.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Information-gain feature selection for generative input model</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Compute information gain of each candidate binary feature with respect to a domain indicator (in-domain vs out-of-domain) and select the top-K features (authors chose K=10k) to be used in the naive Bayes Bernoulli model (ψ parameters) that models input feature generation; leave the full feature set for the discriminative maximum-entropy classifier.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>data preprocessing / feature-selection technique</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>Feature-selection literature / text classification research</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>Preventing overfitting in generative component of domain-adaptation model for NLP recapitalization task</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application without modification</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Applied selection specifically to features used in the naive Bayes generative model (ψ), not to the discriminative classifier; chose top-10k features by information gain with respect to domain label rather than class label.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful — authors report that naive Bayes overfitting caused problems on recapitalization tasks and that applying information-gain selection alleviated these errors and improved performance.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Choice of selection threshold (10k) was somewhat arbitrary (not tuned to test data); selecting features for domain discrimination rather than class label requires additional computation.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Established information-gain metrics for text features; clear practical need (observed overfitting) and easy implementation within pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Feature extraction pipeline, ability to compute information gain across in/out domain labels, and capacity to re-train naive Bayes and discriminative components with the reduced feature set.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>High for models that combine generative and discriminative components where the generative part is prone to overfitting; selection criteria and thresholds will need adaptation per task.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps and practical know-how</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain Adaptation for Statistical Classifiers', 'publication_date_yy_mm': '2011-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Maximum conditional likelihood via bound maximization and the CEM algorithm. <em>(Rating: 2)</em></li>
                <li>Adaptation of maximum entropy classifier: Little data can help a lot. <em>(Rating: 2)</em></li>
                <li>Hierarchical mixtures of experts and the EM algorithm. <em>(Rating: 1)</em></li>
                <li>Conditional random fields: Probabilistic models for segmenting and labeling sequence data. <em>(Rating: 1)</em></li>
                <li>An extensive empirical study of feature selection metrics for text classification. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-380",
    "paper_id": "paper-14154185",
    "extraction_schema_id": "extraction-schema-16",
    "extracted_data": [
        {
            "name_short": "Prior-based adaptation (Chelba & Acero)",
            "name_full": "Prior-estimation domain adaptation using out-of-domain maximum entropy weights as Gaussian prior mean",
            "brief_description": "An adaptation technique which trains a maximum entropy model on out-of-domain data and uses the learned weights as the mean of a Gaussian prior when training an in-domain maximum entropy classifier, thereby transferring parameter information from the out-of-domain domain to the in-domain estimator.",
            "citation_title": "Adaptation of maximum entropy classifier: Little data can help a lot.",
            "mention_or_use": "use",
            "procedure_name": "Prior-based parameter transfer for discriminative classifiers",
            "procedure_description": "Train a maximum entropy model on abundant out-of-domain labeled data to obtain parameter weights. Use those learned weights as the mean of an isotropic Gaussian prior over parameters when training a maximum entropy model on scarce in-domain labeled data; perform MAP estimation for the in-domain parameters under this prior. This biases the in-domain solution toward the out-of-domain solution while allowing adaptation to in-domain evidence.",
            "procedure_type": "computational method / model-regularization technique",
            "source_domain": "Natural language processing — out-of-domain corpora (e.g., newswire)",
            "target_domain": "Natural language processing — in-domain corpora (e.g., conversational speech, transcribed speech, biomedical text)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "The core idea is to convert learned discriminative weights from the source domain into a prior distribution (Gaussian) for use in MAP estimation on a related but different target domain; hyperparameters (prior variance) are tuned on development data. Implementation requires replacing the zero-mean prior normally used with a mean equal to out-of-domain weights.",
            "transfer_success": "partially successful — used as a competitive baseline in experiments; improved over naive baselines but was outperformed by the Mega Model. Paper reports the Prior model performed roughly comparably to other baselines but was consistently weaker than the Mega Model across tasks.",
            "barriers_encountered": "Theoretically odd to estimate and then fix a prior from data; model is asymmetric (treats in-domain and out-of-domain differently); difficult to generalize to multiple out-of-domain datasets; may overconstrain in-domain estimation when distributions differ substantially.",
            "facilitating_factors": "Availability of abundant labeled out-of-domain data; straightforward implementation within maximum entropy training frameworks; compatibility with Gaussian MAP regularization.",
            "contextual_requirements": "Requires a trained out-of-domain classifier and sufficient in-domain labeled data to tune hyperparameters (development set or cross-validation) and to perform MAP estimation; computational ability to train maximum entropy models with Gaussian priors.",
            "generalizability": "Limited: method is directly applicable to discriminative classifiers where Gaussian priors are used; but theoretical and practical limitations reduce applicability when source and target distributions differ strongly or when multiple source domains exist.",
            "knowledge_type": "explicit procedural steps and modelling/regularization principle",
            "uuid": "e380.0",
            "source_info": {
                "paper_title": "Domain Adaptation for Statistical Classifiers",
                "publication_date_yy_mm": "2011-09"
            }
        },
        {
            "name_short": "Feats baseline (use predictions as features)",
            "name_full": "Using out-of-domain classifier predictions as additional features for in-domain learning",
            "brief_description": "A transfer technique that builds a classifier on out-of-domain data and uses that classifier's predictions (on in-domain inputs) as additional features for training an in-domain classifier, enabling transfer of predictive structure without altering the in-domain model architecture.",
            "citation_title": "",
            "mention_or_use": "use",
            "procedure_name": "Prediction-as-feature transfer",
            "procedure_description": "Train one or more classifiers on source (out-of-domain) data. Run the trained source classifier(s) on target (in-domain) inputs and take their output predictions (class probabilities or discrete labels) as new features appended to the in-domain feature vector. Train a target-domain classifier using the augmented feature vectors, thereby leveraging source-domain predictive signals.",
            "procedure_type": "computational method / feature-augmentation technique",
            "source_domain": "Natural language processing — out-of-domain corpora (newswire/broadcast news)",
            "target_domain": "Natural language processing — in-domain corpora (conversational speech, transcribed speech)",
            "transfer_type": "direct application with simple adaptation (feature augmentation)",
            "modifications_made": "No fundamental change to the source classifier; its outputs are simply encoded and concatenated to in-domain features. Implementation choices include whether to pass hard labels or soft probabilities and whether to stack multiple source models.",
            "transfer_success": "partially successful — evaluated as a baseline and shown to perform roughly comparably to the Prior model on the tasks in this paper, but inferior to the Mega Model overall.",
            "barriers_encountered": "Requires careful handling of correlated/noisy predictions; risk of propagating domain mismatch errors into the in-domain learner; needs design choices for encoding predictions as features and might need held-out data for calibration.",
            "facilitating_factors": "Method-agnostic (works with arbitrary classifiers), easy to implement, does not require joint modeling of latent variables between domains.",
            "contextual_requirements": "Needs a trained source-domain classifier and the ability to run it on target inputs; requires additional features to be handled by the target classifier and (optionally) a development set to tune how predictions are encoded.",
            "generalizability": "High within supervised learning: applicable across classification tasks and model families where source predictions can be computed; less appropriate when source predictions are systematically biased for the target domain.",
            "knowledge_type": "explicit procedural steps / instrumental technique",
            "uuid": "e380.1",
            "source_info": {
                "paper_title": "Domain Adaptation for Statistical Classifiers",
                "publication_date_yy_mm": "2011-09"
            }
        },
        {
            "name_short": "Conditional Expectation Maximization (CEM)",
            "name_full": "Maximum conditional likelihood via bound maximization and the CEM algorithm",
            "brief_description": "An EM-style optimization algorithm tailored to discriminative (conditional) models with hidden variables that maximizes a lower bound on the change in conditional likelihood between iterations, enabling efficient inference in conditional models with latent structure.",
            "citation_title": "Maximum conditional likelihood via bound maximization and the CEM algorithm.",
            "mention_or_use": "use",
            "procedure_name": "Conditional Expectation Maximization (CEM)",
            "procedure_description": "An iterative bound-maximization algorithm for conditional models with latent variables. At each iteration: (E-step) compute posterior expectations of latent variables under current parameters; (M-step) maximize a derived lower bound (using Jensen's inequality for the joint term and a variational upper bound for negated marginal terms) with respect to parameters, optionally including priors (MAP). The algorithm guarantees monotonic increase in conditional likelihood change and is suitable for discriminative models like the Mega Model.",
            "procedure_type": "computational method / optimization algorithm",
            "source_domain": "Statistical machine learning / discriminative model optimization (algorithmic research literature)",
            "target_domain": "Applied domain adaptation for discriminative NLP models (maximum entropy and linear-chain models)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Applied the CEM algorithm specifically to the Mega Model's hierarchical conditional mixture; derived closed-form E-step for binary latent indicators z and derived M-step updates for MAP parameters (π, λ, ψ) including weighted maximum-entropy optimizations and analytic updates for certain parameters. Incorporated Gaussian and Beta priors into the CEM bound.",
            "transfer_success": "successful — CEM enabled efficient inference for the Mega Model; empirical behavior: convergence typically in 2–5 iterations, with 5 iterations sufficient in experiments; overall facilitated the improved predictive performance of the Mega Model.",
            "barriers_encountered": "CEM optimization still requires repeated expensive weighted maximum-entropy (BFGS) optimizations (dominant cost); potential for local optima (authors note possibility of stochastic temperature-based methods but did not need them).",
            "facilitating_factors": "CEM is designed for conditional models and provides monotonic improvement guarantees; the Mega Model's latent structure admits tractable E-step and analytic/MAP M-step components; reusing prior optimization state (warm starts) reduces overall runtime.",
            "contextual_requirements": "Need to implement both expectation computations for latent z and weighted maximum-entropy optimization (e.g., L-BFGS); priors and partition functions must be computable; development data to tune hyperparameters; computational resources to perform multiple weighted optimizations.",
            "generalizability": "High for discriminative models with latent variables: authors note CEM is the appropriate choice for such conditional models and that the same approach can be applied to other conditional frameworks, subject to tractability of E/M steps.",
            "knowledge_type": "theoretical principles (variational bounds) plus explicit algorithmic procedure",
            "uuid": "e380.2",
            "source_info": {
                "paper_title": "Domain Adaptation for Statistical Classifiers",
                "publication_date_yy_mm": "2011-09"
            }
        },
        {
            "name_short": "Mega Model (mixture-domain adaptation)",
            "name_full": "Maximum Entropy Genre Adaptation Model (Mega Model)",
            "brief_description": "A novel hierarchical mixture model for domain adaptation that models in-domain and out-of-domain data as mixtures over three underlying distributions (truly in-domain, truly out-of-domain, and general-domain) and integrates this with maximum entropy classifiers and linear-chain sequence models using latent indicator variables and CEM for inference.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "Three-component mixture domain adaptation for discriminative classifiers",
            "procedure_description": "Assume three latent generating distributions q(i), q(o), q(g). Model in-domain distribution p(i) as mixture of q(i) and q(g) and out-of-domain p(o) as mixture of q(o) and q(g). Introduce binary latent indicator z for each example indicating whether it is 'truly domain-specific' or 'general'. For inputs x, model their generative distribution with naive-Bayes Bernoulli parameters ψ; for labels y use conditional maximum entropy Gibbs distributions with parameter vectors λ(i), λ(o), λ(g) depending on z. Place Beta priors on ψ and Gaussian priors on λ. Perform inference/learning via Conditional EM with derived E- and M-steps (weighted maxent optimizations and analytic updates). For sequence data, apply per-token z indicators in a MEMM extension.",
            "procedure_type": "computational method / probabilistic modelling + optimization",
            "source_domain": "Natural language processing — out-of-domain annotated corpora (e.g., newswire / Wall Street Journal)",
            "target_domain": "Natural language processing — diverse in-domain tasks (conversational Fisher data, ASR-transcribed broadcast news, recapitalization corpora CNN/NPR and ABC)",
            "transfer_type": "adapted/modified for new context (mixture modelling and conditional inference integrated into discriminative classifiers)",
            "modifications_made": "Integrated a three-component mixture into a conditional maximum-entropy framework, introduced latent z indicators, coupled generative naive-Bayes modeling of input features with discriminative Gibbs classifiers, and applied CEM to perform MAP estimation of hierarchical parameters. For sequence labeling, adapted to MEMM with per-token z variables and discussed extension to CRFs (not used for efficiency reasons). Also applied feature selection (information gain) to the naive Bayes features in recapitalization task to prevent overfitting.",
            "transfer_success": "successful — consistently outperformed all baseline systems (OnlyI, OnlyO, Mix, MixW, Feats, Prior) across four datasets. Reported improvements: Mention Type accuracy from 81.2% (OnlyI) to 92.1% (Mega) (+13.4% relative); Mention Tagging F from 83.5% to 88.2% (+5.6% relative); ABC recap from 95.5% to 98.1% (+2.9% relative); CNN/NPR recap from 94.6% to 96.8% (+2.3% relative). Statistical significance reported (e.g., p ≤ 0.03 for Mention Type vs Prior).",
            "barriers_encountered": "Inference is more complex than standard maxent; dominant computational cost is repeated weighted maximum-entropy optimizations across CEM iterations (authors report up to ~15 such optimizations but mitigated by warm starts). Naive-Bayes generative component can overfit on high-dimensional/noisy features (necessitating feature selection for some tasks). CRF extension would be computationally expensive if z is per-token.",
            "facilitating_factors": "Shared general-domain structure between source and target (q(g)) allows transfer; abundant labeled out-of-domain data supplies information about q(g); binary-feature representation and weighted maxent optimization are straightforward to implement; bound-based CEM gives convergence guarantees; warm start of optimizers reduces runtime.",
            "contextual_requirements": "Labeled out-of-domain data (large), some labeled in-domain data (can be small), capacity to run weighted maximum-entropy training (L-BFGS), ability to compute posterior expectations for latent variables, and (for recap task) feature-selection infrastructure to control naive-Bayes overfitting. Hyperparameter tuning via dev set (20%).",
            "generalizability": "Authors argue the core idea (decomposing p(i) and p(o) into q(i), q(o), q(g)) is general and can be applied to other modeling frameworks including generative models (where standard EM suffices), language modelling, and machine translation; extension to other discriminative sequence models (CRFs) is possible but may require computational trade-offs.",
            "knowledge_type": "theoretical modelling principles plus explicit algorithmic procedures and implementation details",
            "uuid": "e380.3",
            "source_info": {
                "paper_title": "Domain Adaptation for Statistical Classifiers",
                "publication_date_yy_mm": "2011-09"
            }
        },
        {
            "name_short": "Linear-chain adaptation (MEMM / CRF discussion)",
            "name_full": "Extension of the Mega Model to linear-chain sequence models (Maximum Entropy Markov Models and Conditional Random Fields)",
            "brief_description": "Application/adaptation of the three-component mixture adaptation framework to sequence-labeling models: implemented for MEMMs (per-token z indicators) and discussed for CRFs with caution about computational costs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "Adaptation of mixture-domain approach to linear-chain models (MEMM/CRF)",
            "procedure_description": "Extend per-instance latent indicator z to per-token indicators within a linear-chain discriminative sequence model. For MEMMs, treat each token's label conditioning as a Gibbs distribution parameterized by λ(z) and run CEM with token-wise expectations; for CRFs, consider assigning z per-sentence or per-token but note per-token z in CRFs increases computational cost due to global normalization.",
            "procedure_type": "computational method / model-extension",
            "source_domain": "Sequence labeling in NLP trained on out-of-domain corpora (newswire)",
            "target_domain": "Sequence labeling for in-domain sequence types (ASR-transcribed text, recapitalization tasks)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "For MEMM: use per-word z indicators and perform weighted MEMM optimization inside the CEM M-step. For CRF: authors discuss options (one z per sentence vs one per word) and note direct per-word z in CRFs is computationally expensive; thus CRF extension is left for future work or requires approximate computation.",
            "transfer_success": "successful for MEMM (used empirically for mention tagging and recap tasks); CRF extension not implemented due to computational concerns, only discussed as feasible with tradeoffs.",
            "barriers_encountered": "In CRFs, per-token latent variables increase complexity because of global normalization across sequences, making inference and CEM more expensive; computational cost is the main barrier.",
            "facilitating_factors": "MEMM's per-state (local) normalization aligns naturally with per-token z indicators enabling efficient application; shared feature representations between classification and sequence tasks.",
            "contextual_requirements": "Need infrastructure for MEMM training (weighted per-token optimization), ability to compute token-level z expectations, and computational resources adequate for repeated weighted sequence-model optimizations.",
            "generalizability": "Moderate — MEMM extension is straightforward and effective; CRF extension is conceptually possible but may be computationally expensive, requiring approximations or efficient inference schemes to be practical.",
            "knowledge_type": "algorithmic adaptation and instrumental/technical skills",
            "uuid": "e380.4",
            "source_info": {
                "paper_title": "Domain Adaptation for Statistical Classifiers",
                "publication_date_yy_mm": "2011-09"
            }
        },
        {
            "name_short": "Information-gain feature selection applied to Naive Bayes component",
            "name_full": "Feature selection using information gain to prevent naive Bayes overfitting in the Mega Model",
            "brief_description": "Applying a standard text feature-selection criterion (information gain) to the feature set used by the generative naive Bayes portion of the Mega Model to reduce overfitting and improve recapitalization task performance.",
            "citation_title": "An extensive empirical study of feature selection metrics for text classification.",
            "mention_or_use": "use",
            "procedure_name": "Information-gain feature selection for generative input model",
            "procedure_description": "Compute information gain of each candidate binary feature with respect to a domain indicator (in-domain vs out-of-domain) and select the top-K features (authors chose K=10k) to be used in the naive Bayes Bernoulli model (ψ parameters) that models input feature generation; leave the full feature set for the discriminative maximum-entropy classifier.",
            "procedure_type": "data preprocessing / feature-selection technique",
            "source_domain": "Feature-selection literature / text classification research",
            "target_domain": "Preventing overfitting in generative component of domain-adaptation model for NLP recapitalization task",
            "transfer_type": "direct application without modification",
            "modifications_made": "Applied selection specifically to features used in the naive Bayes generative model (ψ), not to the discriminative classifier; chose top-10k features by information gain with respect to domain label rather than class label.",
            "transfer_success": "successful — authors report that naive Bayes overfitting caused problems on recapitalization tasks and that applying information-gain selection alleviated these errors and improved performance.",
            "barriers_encountered": "Choice of selection threshold (10k) was somewhat arbitrary (not tuned to test data); selecting features for domain discrimination rather than class label requires additional computation.",
            "facilitating_factors": "Established information-gain metrics for text features; clear practical need (observed overfitting) and easy implementation within pipeline.",
            "contextual_requirements": "Feature extraction pipeline, ability to compute information gain across in/out domain labels, and capacity to re-train naive Bayes and discriminative components with the reduced feature set.",
            "generalizability": "High for models that combine generative and discriminative components where the generative part is prone to overfitting; selection criteria and thresholds will need adaptation per task.",
            "knowledge_type": "explicit procedural steps and practical know-how",
            "uuid": "e380.5",
            "source_info": {
                "paper_title": "Domain Adaptation for Statistical Classifiers",
                "publication_date_yy_mm": "2011-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Maximum conditional likelihood via bound maximization and the CEM algorithm.",
            "rating": 2,
            "sanitized_title": "maximum_conditional_likelihood_via_bound_maximization_and_the_cem_algorithm"
        },
        {
            "paper_title": "Adaptation of maximum entropy classifier: Little data can help a lot.",
            "rating": 2,
            "sanitized_title": "adaptation_of_maximum_entropy_classifier_little_data_can_help_a_lot"
        },
        {
            "paper_title": "Hierarchical mixtures of experts and the EM algorithm.",
            "rating": 1,
            "sanitized_title": "hierarchical_mixtures_of_experts_and_the_em_algorithm"
        },
        {
            "paper_title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data.",
            "rating": 1,
            "sanitized_title": "conditional_random_fields_probabilistic_models_for_segmenting_and_labeling_sequence_data"
        },
        {
            "paper_title": "An extensive empirical study of feature selection metrics for text classification.",
            "rating": 1,
            "sanitized_title": "an_extensive_empirical_study_of_feature_selection_metrics_for_text_classification"
        }
    ],
    "cost": 0.017023749999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Domain Adaptation for Statistical Classifiers
Sep 2011. 2006</p>
<p>Hal Daumé Iii 
Information Sciences Institute
University of Southern California
4676 Admiralty Way, Suite 1001 Marina del Rey90292CAUSA</p>
<p>Daniel Marcu marcu@isi.edu 
Information Sciences Institute
University of Southern California
4676 Admiralty Way, Suite 1001 Marina del Rey90292CAUSA</p>
<p>Domain Adaptation for Statistical Classifiers</p>
<p>Journal of Artificial Intelligence Research
26Sep 2011. 2006Submitted 8/05; published 5/06
The most basic assumption used in statistical learning theory is that training data and test data are drawn from the same underlying distribution. Unfortunately, in many applications, the "in-domain" test data is drawn from a distribution that is related, but not identical, to the "out-of-domain" distribution of the training data. We consider the common case in which labeled out-of-domain data is plentiful, but labeled in-domain data is scarce. We introduce a statistical formulation of this problem in terms of a simple mixture model and present an instantiation of this framework to maximum entropy classifiers and their linear chain counterparts. We present efficient inference algorithms for this special case based on the technique of conditional expectation maximization. Our experimental results show that our approach leads to improved performance on three real world tasks on four different data sets from the natural language processing domain.</p>
<p>Introduction</p>
<p>The generalization properties of most current statistical learning techniques are predicated on the assumption that the training data and test data come from the same underlying probability distribution. Unfortunately, in many applications, this assumption is inaccurate. It is often the case that plentiful labeled data exists in one domain (or coming from one distribution), but one desires a statistical model that performs well on another related, but not identical domain. Hand labeling data in the new domain is a costly enterprise, and one often wishes to be able to leverage the original, "out-of-domain" data when building a model for the new, "in-domain" data. We do not seek to eliminate the annotation of in-domain data, but instead seek to minimize the amount of new annotation effort required to achieve good performance. This problem is known both as domain adaptation and transfer.</p>
<p>In this paper, we present a novel framework for understanding the domain adaptation problem. The key idea in our framework is to treat the in-domain data as drawn from a mixture of two distributions: a "truly in-domain" distribution and a "general domain" distribution. Similarly, the out-of-domain data is treated as if drawn from a mixture of a "truly out-of-domain" distribution and a "general domain" distribution. We apply this framework in the context of conditional classification models and conditional linear-chain sequence labeling models, for which inference may be efficiently solved using the technique of conditional expectation maximization. We apply our model to four data sets with varying degrees of divergence between the "in-domain" and "out-of-domain" data and obtain predictive accuracies higher than any of a large number of baseline systems and a second model proposed in the literature for this problem.</p>
<p>The domain adaptation problem arises very frequently in the natural language processing domain, in which millions of dollars have been spent annotating text resources for morphological, syntactic and semantic information. However, most of these resources are based on text from the news domain (in most cases, the Wall Street Journal). The sort of language that appears in text from the Wall Street Journal is highly specialized and is, in most circumstances, a poor match to other domains. For instance, there has been a recent surge of interest in performing summarization (Elhadad, Kan, Klavans, &amp; McKeown, 2005) or information extraction (Hobbs, 2002) of biomedical texts, summarization of electronic mail (Rambow, Shrestha, Chen, &amp; Lauridsen, 2004), information extraction from transcriptions of meetings, conversations or voice-mail (Huang, Zweig, &amp; Padmanabhan, 2001), among others. Conversely, in the machine translation domain, most of the parallel resources that machine translation system depend on for parameter estimation are drawn from transcripts of political meetings, yet the translation systems are often targeted at news data (Munteanu &amp; Marcu, 2005).</p>
<p>Statistical Domain Adaptation</p>
<p>In the multiclass classification problem, one typically assumes the existence of a training set D = {(x n , y n ) ∈ X × Y : 1 ≤ n ≤ N }, where X is the input space and Y is a finite set. It is assumed that each (x n , y n ) is drawn from a fixed, but unknown base distribution p and that the training set is independent and identically distributed, given p. The learning problem is to find a function f : X → Y that obtains high predictive accuracy (this is typically done either by explicitly minimizing the regularized empirical error, or by maximizing the probabilities of the model parameters).</p>
<p>Domain Adaptation</p>
<p>In the context of domain adaptation, the situation becomes more complicated. We assume that we are given two sets of training data, D (o) and D (i) , the "out-of-domain" and "indomain" data sets, respectively. We no longer assume that there is a single fixed, but known distribution from which these are drawn, but rather assume that D (o) is drawn from a distribution p (o) and D (i) is drawn from a distribution p (i) . The learning problem is to find a function f that obtains high predictive accuracy on data drawn from p (i) . (Indeed, our model will turn out to be symmetric with respect to D (i) and D (o) , but in the contexts we consider obtaining a good predictive model of D (i) makes more intuitive sense.) We will assume that |D (o) | = N (o) and |D (i) | = N (i) , where typically we have N (i) ≪ N (o) . As before, we will assume that the N (o) out-of-domain data points are drawn iid from p (o) and that the N (i) in-domain data points are drawn iid from p (i) .</p>
<p>Obtaining a good adaptation model requires the careful modeling of the relationship between p (i) and p (o) . If these two distributions are independent (in the obvious intuitive sense), then the out-of-domain data D (o) is useless for building a model of p (i) and we may as well ignore it. On the other hand, if p (i) and p (o) are identical, then there is no adaptation necessary and we can simply use a standard learning algorithm. In practical problems, though, p (i) and p (o) are neither identical nor independent.</p>
<p>Prior Work</p>
<p>There has been relatively little prior work on this problem, and nearly all of it has focused on specific problem domains, such as n-gram language models or generative syntactic parsing models. The standard approach used is to treat the out-of-domain data as "prior knowledge" and then to estimate maximum a posterior values for the model parameters under this prior distribution. This approach has been applied successfully to language modeling  and parsing . Also in the parsing domain, Hwa (1999) and Gildea (2001) have shown that simple techniques based on using carefully chosen subsets of the data and parameter pruning can improve the performance of an adapted parser. These models assume a data distribution p (D | θ) with parameters θ and a prior distribution over these parameters p (θ | η) with hyper-parameters η. They estimate the η hyperparameters from the out-of-domain data and then find the maximum a posteriori parameters for the in-domain data, with the prior fixed.</p>
<p>In the context of conditional and discriminative models, the only domain adaptation work of which we are aware is the model of Chelba and Acero (2004). This model again uses the out-of-domain data to estimate a prior distribution, but does so in the context of a maximum entropy model. Specifically, a maximum entropy model is trained on the out-of-domain data, yielding optimal weights for that problem. These weights are then used as the mean weights for the Gaussian prior on the learned weights for the in-domain data.</p>
<p>Though effective experimentally, the practice of estimating a prior distribution from out-of-domain data and fixing it for the estimation of in-domain data leaves much to be desired. Theoretically, it is strange to estimate and fix a prior distribution from data; this is made more apparent by considering the form of these models. Denoting the in-domain data and parameters by D (i) and θ, respectively, and the out-of-domain data and parameters by D (o) and η, we obtain the following form for these "prior" estimation models:
θ = arg max θ p θ | arg max η p (η) p D (o) | η p D (i) | θ(1)
One would have a very difficult time rationalizing this optimization problem by anything other than experimental performance. Moreover, these models are unusual in that they do not treat the in-domain data and the out-of-domain data identically. Intuitively, there is no difference in the two sets of data; they simply come from different, related distributions. Yet, the prior-based models are highly asymmetric with respect to the two data sets. This also makes generalization to more than one "out of domain" data set difficult. Finally, as we will see, the model we propose in this paper, which alleviates all of these problems, outperforms them experimentally.</p>
<p>A second generic approach to the domain adaptation problem is to build an out of domain model and use its predictions as features for the in domain data. This has been successfully used in the context of named entity tagging (?). This approach is attractive because it makes no assumptions about the underlying classifier; in fact, multiple classifiers can be used.</p>
<p>Our Framework</p>
<p>In this paper, we propose the following relationship between the in-domain and the out-ofdomain distributions. We assume that instead of two underlying distributions, there are actually three underlying distributions, which we will denote q (o) , q (g) and q (i) . We then consider p (o) to be a mixture of q (o) and q (g) , and consider p (i) to be a mixture of q (i) and q (g) . One can intuitively view the q (o) distribution as a distribution of data that is truly out-of-domain, q (i) as a distribution of data that is truly in-domain and q (g) as a distribution of data that is general to both domains. Thus, knowing q (g) and q (i) is sufficient to build a model of the in-domain data. The out-of-domain data can help us by providing more information about q (g) than is available by just considering the in-domain data.</p>
<p>For example, in part-of-speech tagging, the assignment of the tag "determiner" (DT) to the word "the" is likely to be a general decision, independent of domain. However, in the Wall Street Journal, "monitor" is almost always a verb (VB), but in technical documentation it will most likely be a noun. The q (g) distribution should account for the case of "the/DT", the q (o) should account for "monitor/VB" and q (i) should account for "monitor/NN."</p>
<p>Domain Adaptation in Maximum Entropy Models</p>
<p>The domain adaptation framework outlined in Section 2.3 is completely general in that it can be applied to any statistical learning model. In this section we apply it to loglinear conditional maximum entropy models and their linear chain counterparts, since these models have proved quite effective in many learning tasks. We will first review the maximum entropy framework, then will extend it to the domain adaptation problem; finally we will discuss domain adaptation in linear chain maximum entropy models.</p>
<p>Maximum Entropy Models</p>
<p>The maximum entropy framework seeks a conditional distribution p (y | x) that is closest (in the sense of KL divergence) to the uniform distribution but also matches a set of training data D with respect to feature function expectations (Della Pietra, Della Pietra, &amp; Lafferty, 1997). By introducing one Lagrange multiplier λ i for each feature function f i , this optimization problem results in a probability distribution of the form:
p (y | x ; λ) = 1 Z λ,x exp λ ⊤ f (x, y)(2)
Here, u ⊤ v denotes the scalar product of two vectors u and v, given by:
u ⊤ v = i u i v i .
The normalization constant in Eq (2), Z λ,x , is obtained by summing the exponential over all possible classes y ′ ∈ Y. This probability distribution is also known as an exponential distribution or a Gibbs distribution. The learning (or optimization) problem is to find the vector λ that maximizes the likelihood in Eq (2). In practice, to prevent over-fitting, one typically optimizes a penalized (log) likelihood, where an isotropic Gaussian prior with mean 0 and covariance matrix σ 2 I is placed over the parameters λ ). The graphical model for the standard maximum entropy model is depicted on the left of Figure 1. In this figure, circular nodes correspond to random variables and square nodes correspond to fixed variables. Shaded nodes are observed in the training data and empty nodes are hidden or unobserved. Arrows denote conditional dependencies. In general, the feature functions f (x, y) may be arbitrary real-valued functions; however, in this paper we will restrict our attention to binary features. In practice, this is not a harsh restriction: many problems in the natural language domain naturally employ only binary features (for real valued features, binning techniques can be applied). Additionally, for notational convenience, we will assume that the features f i (x, y) can be written in product form as g i (y)h i (x) for arbitrary binary functions g over outputs and binary features h over inputs. The latter assumption means that we can consider x to be a binary vector where x i = h i (x); in the following this will simplify notation significantly (the extension to the full case is straightforward, but messy, and is therefore not considered in the remainder of this paper). By considering x as a vector, we may move the class dependence to the parameters and consider λ to be a matrix where λ y,i is the weight for h i for class y. We will write λ y to refer to the column vector of λ corresponding to class y. As x is also considered a column vector, we write λ y ⊤ x as shorthand for the dot product between x and the weights for class y. Under this modified notation, we may rewrite Eq (2) as:
p (y | x ; λ) = 1 Z λ,x exp λ y ⊤ x(3)
Combining this with a Gaussian prior on the weights, we obtain the following form for the log posterior of a data set:
l = log p (λ | D, σ s ) = − 1 2σ 2 λ ⊤ λ + N n=1   λ yn ⊤ x n − log y ′ ∈Y exp λ y ′ ⊤ x n   + const (4)
The parameters λ can be estimated using any convex optimization technique; in practice, limited memory BFGS (Nash &amp; Nocedal, 1991;Averick &amp; Moré, 1994) seems to be a good choice (Malouf, 2002;Minka, 2003) and we will use this algorithm for the experiments described in this paper. In order to perform these calculations, one must be able to compute the gradient of Eq (4) with respect to λ, which is available in closed form.</p>
<p>The Maximum Entropy Genre Adaptation Model</p>
<p>Extending the maximum entropy model to account for both in-domain and out-of-domain data in the framework described earlier requires the addition of several extra model parameters. In particular, for each in-domain data point (x       According to this model, the z n s are binary random variables that we assume are drawn from a Bernoulli distribution with parameter π (i) (for in-domain) and π (o) (for outof-domain). Furthermore, we assume that there are three λ vectors, λ (i) , λ (o) and λ (g) corresponding to q (i) , q (o) and q (g) , respectively. For instance, if z n = 1, then we assume thatx n should be classified using λ (i) . Finally, we model the binary vectors x
(i) n s (respec- tively x (o)
n s) as being drawn independently from Bernoulli distributions parameterized by ψ (i) and ψ (g) (respectively, ψ (o) and ψ (g) ). Again, when z n = 1, we assume that x n is drawn according to ψ (i) . This corresponds to a naïve Bayes assumption over the generative probabilities of the x n vectors. Finally, we place a common Beta prior over the naïve Bayes parameters, ψ. Allowing ν to range over {i, o, g}, the full hierarchical model is:
ψ (ν) f | a, b ∼ Bet(a, b) λ (ν) | σ 2 ∼ Nor(0, σ 2 I) z (i) n | π (i) ∼ Ber(π (i) ) z (o) n | π (o) ∼ Ber(π (o) ) x (i) nf | z (i) n , ψ (i) f , ψ (g) f ∼ Ber(ψ z (i) n f ) x (o) nf | z (o) n , ψ (o) f , ψ (g) f ∼ Ber(ψ z (o) n f ) y (i) n | x (i) n , z (i) n , λ (i) , λ (g) ∼ Gibbs(x (i) n , λ z (i) n ) y (o) n | x (o) n , z (o) n , λ (o) , λ (g) ∼ Gibbs(x (o) n , λ z (o) n )(5)
We term this model the "Maximum Entropy Genre Adaptation Model" (the Mega Model). The corresponding graphical model is shown on the right in Figure 1. The generative story for an in-domain data point x (i) is as follows:</p>
<ol>
<li>Select whether x (i) will be truly in-domain or general-domain and indicate this by z (i) ∈ {i, g}. Choose z (i) = i with probability π (i) and z (i) = g with probability 1 − π (i) .</li>
</ol>
<p>For each component
f of x (i) , choose x (i) f to be 1 with probability ψ z (i) f and 0 with probability 1 − ψ z (i) f .
3. Choose a class y according to Eq (3) using the parameter vector λ z (i) .</p>
<p>The story for out-of-domain data points is identical, but uses the truly out-of-domain and general-domain parameters, rather than the truly in-domain parameters and generaldomain parameters.</p>
<p>Linear Chain Models</p>
<p>The straightforward extension of the maximum entropy classification model to the maximum entropy Markov model (MEMM) (McCallum, Freitag, &amp; Pereira, 2000) is obtained by assuming that the targets y n are sequences of labels. The canonical example for this model is part of speech tagging: each word in a sequence is assigned a part of speech tag. By introducing a first order Markov assumption on the tag sequence, one obtains a linear chain model that can be viewed as the discriminative counterpart to the standard (generative) hidden Markov model. The parameters of these models can be estimated again using limited memory BFGS. The extension of the Mega Model to the linear chain framework is similarly straightforward, under the assumption that each label (part of speech tag) has its own indicator variable z (versus a global indicator variable z for the entire tag sequence).</p>
<p>The techniques described herein may also be applied to the conditional random field framework of Lafferty, McCallum, and Pereira (2001), which fixes a bias problem of the MEMM by performing global normalization rather than per-state normalization. There is, however, a subtle difficulty in a direct application to CRFs. Specifically, one would need to decide if a single z variable would be assigned to an entire sentence, or to each word individually. In the MEMM case, it is most natural to have one z per word. However, to do so in a CRF would be computationally more expensive. In the remainder, we continue to use the MEMM model for efficiency purposes.</p>
<p>Conditional Expectation Maximization</p>
<p>Inference in the Mega Model is slightly more complex than in standard maximum entropy models. However, inference can be solved efficiently using conditional expectation maximization (CEM), a variant of the standard expectation maximization (EM) algorithm (Dempster, Laird, &amp; Rubin, 1977), due to Jebara and Pentland (1998). At a high level, EM is useful for computing in generative models with hidden variables, while CEM is useful for computing in discriminative models with hidden variables; the Mega Model belongs to the latter family, so CEM is the appropriate choice.</p>
<p>The standard EM family of algorithms maximizes a joint likelihood over data. In particular, if (x n , y n ) N n=1 are data and z is a (discrete) hidden variable, the M-step of EM proceeds by maximizing the bound given in Eq (6) log
p (x, y | Θ) = log z p (z, x, y | Θ) = log E z∼p(· | x;Θ) p (x, y | z; Θ)(6)
In Eq (6), E z denotes an expectation. One may now apply Jensen's inequality to this equation, which states that f (E{x}) ≤ E{f (x)} whenever f is convex. Taking f = log, we are able to decompose the log of an expectation into the expectation of a log. This typically separates terms and makes taking derivatives and solving the resolution optimization problem tractable. Unfortunately, EM cannot be directly applied to conditional models (such as the Mega Model) of the form in Eq (7) because such models result in an M-step that requires the maximization of an equation of the form given in Eq (8).
log p (y | x; Θ) = log z p (z, y | x; Θ) = log E z∼p(· | x,Θ) p (y | x, z; Θ) (7) l = log z p (z, x, y | Θ) − log z p (z, x | Θ)(8)
Jensen's inequality can be applied to the first term in Eq (8), which can be maximized readily as in standard EM. However, applying Jensen's inequality to the second term would lead to an upper bound on the likelihood, since that term appears negated.</p>
<p>The conditional EM solution (Jebara &amp; Pentland, 1998) is to bound the change in log-likelihood between iterations, rather than the log-likelihood itself. The change in loglikelihood can be written as in Eq (9), where Θ t denotes the parameters at iteration t.
∆l c = log p y | x; Θ t − log p y | x; Θ t−1(9)
By rewriting the conditional distribution p (y | x) as p (x, y) divided by p (x), we can express ∆l c as the log of the joint distribution difference minus the log of the marginal distribution. Here, we can apply Jensen's inequality to the first term (the joint difference), but not to the second (because it appears negated). Fortunately, Jensen's is not the only bound we can employ. The standard variational upper bound of the logarithm function is: log x ≤ x − 1; this leads to a lower bound of the negation, which is exactly what is desired. This bound is attractive for other reasons: (1) it is tangent to the logarithm; (2) it is tight;</p>
<p>(3) it makes contact at the current operating point (according to the maximization at the previous time step); (4) it is a simply linear function; and (5) in the terminology of the calculus of variations, it is the variational dual to the logarithm; see (Smith, 1998).</p>
<p>Applying Jensen's inequality to the first term in Eq (9) and the variational dual to the second term, we obtain that the change of log-likelihood in moving from model parameters Θ t−1 at time t − 1 to Θ t at time t (which we shall denote Q t ) is bounded by ∆l ≥ Q t , where Q t is defined by Eq (10), where h = E{z | x; Θ} when z = 1 and 1 − E{z | x; Θ} when z = 0, with expectations taken with respect to the parameters from the previous iteration.
Q t = z∈Z h z log p z, x, y | Θ t p (z, x, y | Θ t−1 ) − z p z, x | Θ t z p (z, x | Θ t−1 ) + 1(10)
By applying the two bounds (Jensen's inequality and the variational bound), we have removed all "sums of logs," which are hard to deal with analytically. The full derivation is given in Appendix A. The remaining expression is a lower bound on the change in likelihood, and maximization of it will result in maximization of the likelihood.</p>
<p>As in the MAP variant of standard EM, there is no change to the E-step when priors are placed on the parameters. The assumption in standard EM is that we wish to maximize
p (Θ | x, y) ∝ p (Θ) p (y | Θ, x)
where the prior probability of Θ is ignored, leaving just the likelihood term of the parameters given the data. In MAP estimation, we do not make this assumption and instead use a true prior p (Θ). In doing so, we need only to add a factor of log p (Θ) to the definition of Q t in Eq (10). It is important to note that although we do make use of a full joint distribution p (x, y, z), the objective function of our model is conditional. The joint distribution is only used in the process of creating the bound: the overall optimization is to maximize the conditional likelihood of the labels given the input. In particular, the bound using the full joint likelihood holds for any parameters of the marginal.
j t−1 n,zn = log p x n , y n , z n | Θ t−1 ψ n,zn = F f =1 ψ zn f x nf 1 − ψ zn f 1−x nf m t−1 n = zn p x n , z n | Θ t−1 −1 ψ n,zn,−f ′ = f =f ′ ψ zn f x nf 1 − ψ zn f 1−x nf</p>
<p>Parameter Estimation for the Mega Model</p>
<p>As made explicit in Eq (10), the relevant distributions for performing CEM are the full joint distributions over the input variables x, the output variables y, and the hidden variables z. Additionally, we require the marginal distribution over the x variables and the z variables. Finally, we need to compute expectations over the z variables. We will derive the expectation step in this section and present the final solution for the maximization step for each class of variables. The derivation of the equations for the maximization is given in Appendix B.</p>
<p>The Q bound on complete conditional likelihood for the Mega Modelis given below:
Q t = N (i) n=1   z (i) n h (i) n log p z (i) n , x (i) n , y (i) n p ′ z (i) n , x (i) n , y (i) n − z (i) n p z (i) n , x (i) n z (i) n p ′ z (i) n , x (i) n + 1   + N (o) n=1   z (o) n h (o) n log p z (o) n , x (o) n , y (o) n p ′ z (o) n , x (o) n , y (o) n − z (o) n p z (o) n , x (o) n z (o) n p ′ z (o) n , x (o) n + 1  (11)
In this equation, p ′ () is the probability distribution at the previous iteration. The first term in Eq (11) is the bound for the in-domain data, while the second term is the bound for the out-of-domain data. In all the optimizations described in this section, there are nearly identical terms for the in-domain parameters and the out-of-domain parameters. For brevity, we will only explicitly write the equations for the in-domain parameters; the corresponding out-of-domain equations can be easily derived from these. Moreover, to reduce notational overload, we will elide the superscripts denoting in-domain and out-of-domain when obvious from context. For notational brevity, we will use the notation depicted in Table 1.</p>
<p>Expectation Step</p>
<p>The E-step is concerned with calculating h n given current model parameters. Since z n ∈ {0, 1}, we easily find h n = p (z n = 1|Θ), which can be calculated as follows:
p (z n = z | x n , y n , ψ, λ, π) = p (z n = z | π) p (x n | ψ, z n = z) p (y n | λ, z n = z) z p (z n = z | π) p (x n | ψ, z n = z) p (y n | λ, z n = z) ∝ π z (1 − π) 1−z ψ n,z 1 Z x n ,λ z exp λ z yn ⊤ x n(12)
Here, Z is the partition function from before. This can be easily calculated for z ∈ {0, 1} and the expectation can be found by dividing the value for z = 1 by the sum over both.</p>
<p>M-Step for π</p>
<p>As shown in Appendix B.1, we can directly compute the value of π by solving a simple quadratic equation. We can compute π as −a + √ a 2 − b, where:
a = 1 − N n=1 2h n − m t−1 n (ψ n,0 − ψ n,1 ) 2 N n=1 m t−1 n (ψ n,0 − ψ n,1 ) b = − N n=1 h n N n=1 m t−1 n (ψ n,0 − ψ n,1 )</p>
<p>M-Step for λ</p>
<p>Viewing Q t as a function of λ, it is easy to see that optimization for this variable is convex. An analytical solution is not available, but the gradient of Q t with respect to λ (i) can be seen to be identical to the gradient of the standard maximum entropy posterior, Eq (4), but where each data point is weighted according to its posterior probability, (1 − h n ). We may thus use identical optimization techniques for computing optimal λ variables as for standard maximum entropy models; the only difference is that the data points are now weighted. A similar story holds for λ (o) . In the case of λ (g) , we obtain the standard maximum entropy gradient, computed over all N (i) + N (o) data points, where each x n . This is shown in Appendix B.2.</p>
<p>M-Step for ψ</p>
<p>Like the case for λ, we cannot obtain an analytical solution for finding the ψ that maximizes Q t . However, we can compute simple derivatives for Q t with respect to a single component ψ f which can be maximized analytically. As shown in Appendix B.3, we can compute ψ<br />
(i) f as −a + √ a 2 − b, where: a = − N n=1 1 − h n + j n,0 (1 − π)ψ n,0,−f 2 N n=1 j n,0 (1 − π)ψ n,0,−f b = 1 + N n=1 (1 − h n ) x nf N n=1 j n,0 (1 − π)ψ n,0,−f Algorithm MegaCEM Initialize ψ (ν) f = 0.5, λ(ν</p>
<p>{-Maximization</p>
<p>Step -} Analytically update π (i) and π (o) according to the equations shown in Section 5.2 Optimize λ (i) , λ (o) and λ (g) using BFGS while Iterations remain and/or ψ haven't converged do</p>
<p>Update ψs according to derivation in Section 5.4 end while end while return λ, ψ, π The case for ψ (o) is identical. For ψ (g) , the only difference is that we must replace each sum to over the data points with two sums, one for each of the in-domain and out-of-domain points; and, as before, the 1 − h n s must be replaced with h n ; this is made explicit in the Appendix. Thus, to optimize the ψ variables, we simply iterate through and optimize each component analytically, as given above, until convergence.</p>
<p>Training Algorithm</p>
<p>The full training algorithm is depicted in Figure 2. Convergence properties of the CEM algorithm ensure that this will converge to a (local) maximum in the posterior space. If local optima become a problem in practice, one can alternatively use a stochastic optimization algorithm, in which a temperature is applied enabling the optimization to jump out of local optima early on. However, we do not explore this idea further in this work. In the context of our application, this extension was not required.</p>
<p>CEM Convergence</p>
<p>One immediate question about the conditional EM model we have described is how many EM iterations are required for the model to converge. In our experiments, 5 iterations of CEM is more than sufficient, and often only 2 or 3 are necessary. To make this more clear, in Figure 3, we have plotted the negative complete log likelihood of the model on the first data set, described below in Section 6.2. There are three separate maximizations in the full training algorithm (see Figure 2); the first involves updating the π variables, the second involves optimizing the λ variables and the third involves optimizing the ψ variables. We compute the likelihood after each of these steps.</p>
<p>Running a total 5 CEM iterations is still relatively efficient in our model. The dominating expense is in the weighted maximum entropy optimization, which, at 5 CEM iterations, must be computed 15 times (each iteration requires the optimization of each of the three sets of λ variables). At worst this will take 15 times the amount of time to train a model on the complete data set (the union of the in-domain and out-of-domain data), but in practice we can resume each optimization at the ending point of the previous iteration, which causes the subsequent optimizations to take much less time.</p>
<p>Prediction</p>
<p>Once training has supplied us with model parameters, the subsequent task is to apply these parameters to unseen data to obtain class predictions. We assume all this test data is "indomain" (i.e., is drawn either from Q (i) or Q (g) in the notation of the introduction), and obtain a decision rule of the form given in Eq (13) for a new test point x.
y = arg max y∈Y p (y | x; Θ) = arg max y∈Y z p (z | x; Θ) p (y | x, z; Θ) = arg max y∈Y z p (z | Θ) p (x | z; Θ) p (y | x, z; Θ) = arg max y∈Y π   F f =1 ψ (g) f x f 1 − ψ (g) f 1−x f   exp λ (g) y ⊤ x Z x,λ (g) + (1 − π)   F f =1 ψ (i) f x f 1 − ψ (i) f 1−x f   exp λ (i) y ⊤ x Z x,λ (i)(13)
Thus, the decision rule is to simply select the class which has highest probability according to the maximum entropy classifiers, weighted linearly by the marginal probabilities of the new data point being drawn from Q (i) versus Q (g) . In this sense, our model can be seen as linearly interpolating an in-domain model and a general-domain model, but where the interpolation parameter is input specific.</p>
<p>Experimental Results</p>
<p>In this section, we describe the result of applying the Mega Model to several datasets with varying degrees of divergence between the in-domain and out-of-domain data. However, before describing the data and results, we will discuss the systems against which we compare.</p>
<p>Baseline Systems</p>
<p>Though there has been little literature on this problem and thus few real systems against which to compare, there are several obvious baselines, which we describe in this section.</p>
<p>OnlyI: This model is obtained simply by training a standard maximum entropy model on the in-domain data. This completely ignores the out-of-domain data and serves as a baseline case for when such data is unavailable.</p>
<p>OnlyO: This model is obtained by training a standard maximum entropy model on the out-of-domain data, completely ignoring the in-domain data. This serves as a baseline for expected performance without annotating any new data. It also gives a sense of how close the out-of-domain distribution is to the in-domain distribution.</p>
<p>LinI: This model is obtained by linearly interpolating the OnlyI and OnlyO systems. The interpolation parameter is estimated on held-out (development) in-domain data. This means that, in practice, extra in-domain data would need to be annotated in order to create a development set; alternatively, cross-validation could be used.</p>
<p>Mix: This model is obtained by training a maximum entropy model on the union of the out-of-domain and in-domain data sets.</p>
<p>MixW: This model is also obtained by training a maximum entropy model on the union of the out-of-domain and in-domain data sets, but where the out-of-domain data is downweighted so that is effectively equinumerous with the in-domain data.</p>
<p>Feats: This model uses the out-of-domain data to build one classifier and then uses this classifier's predictions as features for the in-domain data, as described by ? (?).</p>
<p>Prior: This is the adaptation model described in Section 2.2, where the out-of-domain data is used to estimate a prior for the in-domain classifier. In the case of the maximum entropy models we consider here, the weights learned from the out-of-domain data are used as the mean of the Gaussian prior distribution placed over the weights in the training of the in-domain data, as is described by Chelba and Acero (2004).</p>
<p>In all cases, we tune model hyperparameters using performance on development data. This development data is taken to be a random 20% of the training data in all cases. Once appropriate hyperparameters are found, the 20% is folded back in to the training set.</p>
<p>Data Sets</p>
<p>We evaluate our models on three different problems. The first two problems come from the Automatic Content Extraction (ACE) data task. This data was selected because the ACE program specifically looks at data in different domains. The third problem is the same as that tackled by Chelba and Acero (2004), which required them to annotate data themselves.</p>
<p>Mention Type Classification</p>
<p>The first problem, Mention Type, is a subcomponent of the entity mention detection task (an extension of the named entity tagging task, wherein pronouns and nominals are marked, in addition to simple names). We assume that the extents of the mentions are marked and we simply need to identify their type, one of: Person, Geo-political Entity, Organization, Location, Weapon or Vehicle. As the out-of-domain data, we use the newswire and broadcast news portions of the ACE 2005 training data; as the in-domain data, we use the Fisher conversations data. An example out-of-domain sentence is:</p>
<p>Once again, a prime battleground will be the constitutional allocation of powerbetween the federal government nom gpe and the states nom gpe , and between Congress nam org and federal regulatory agencies bar org .</p>
<p>An example in-domain sentence is: Accuracy is computed as 0/1 loss. We use the standard feature functions employed in named entity models, include lexical items, stems, prefixes and suffixes, capitalization patterns, part-of-speech tags, and membership information on gazetteers of locations, businesses and people. The accuracies reported are the result of running ten fold cross-validation.</p>
<p>Mention Tagging</p>
<p>The second problem, Mention Tagging is the precursor to the Mention Type task, in which we attempt to tag entity mentions in raw text. We use the standard Begin/In/Out encoding and use a maximum entropy Markov model to perform the tagging (McCallum et al., 2000). As the out-of-domain data, we use again the newswire and broadcast news data; as the in-domain data, we use broadcast news data that has been transcribed by automatic speech recognition. The in-domain data lacks capitalization, punctuation, etc., and also contains transcription errors (speech recognition word error rate is approximately 15%). For the tagging task, we have 112k out-of-domain examples (in the context of tagging, an example is a single word), but now 5k in-domain examples and 11k test examples. Accuracy is F-measure across the segmentation. We use the same features as in the mention type identification task. The scores reported are after ten fold cross-validation.</p>
<p>Recapitalization</p>
<p>The final problem, Recap, is the task of recapitalizing text. Following Chelba and Acero (2004), we again use a maximum entropy Markov model, where the possible tags are: Lowercase, Capitalized, All Upper Case, Punctuation or Mixed case. The out-of-domain data in this task comes from the Wall Street Journal, and two separate in-domain data sets come from broadcast news text from CNN/NPR and ABC Primetime, respectively. We use 3.5m out-of-domain examples (one example is one word  Chelba and Acero (2004). In order to maintain comparability to the results described by Chelba and Acero (2004), we do not perform cross-validation for these experiments: we use the same train/test split as described in their paper.</p>
<p>Feature Selection</p>
<p>While the maximum entropy models used for the classification are adept at dealing with many irrelevant and/or redundant features, the naïve Bayes generative model, which we use to model the distribution of the input variables, can overfit on such features. This turned out not to be a problem for the Mention Type and Mention Tagging problems, but for the Recap problems, it caused some errors. To alleviate this problem, for the Recap problem only, we applied a feature selection algorithm just to the features used for the naïve Bayes model (the entire feature set was used for the maximum entropy model). Specifically, we took the 10k top features according to the information gain criteria to predict "indomain" versus "out-of-domain" (as opposed to feature selection for class label); Forman (2003) provides an overview of different selection techniques. 1</p>
<p>Results</p>
<p>Our results are shown in Table 2, where we can see that training only on in-domain data always outperforms training only on out-of-domain data. The linearly interpolated model does not improve on the base models significantly. Placing all the data in one bag helps, and there is no clear advantage to re-weighting the out domain data. The Prior model and the Feats model perform roughly comparably, with the Prior model edging out by a small margin. 2 Our model outperforms both the Prior model and the Feats model.</p>
<ol>
<li>The value of 10k was selected arbitrarily after an initial run of the model on development data; it was not tuned to optimize either development or test performance. 2. Our numbers for the result of the Prior model on the data from Chelba and Acero (2004) differ slightly from those reported in their paper. There are two potential reasons for this. First, most of their numbers  Table 2: Experimental results; The first set of rows show the sizes of the in-domain and out-of-domain training data sets. The second set of rows (Accuracy) show the performance of the various models on each of the four tasks. The last two rows (% Reduction) show the percentage reduction in error rate by using the Mega Model over the baseline model (Mix) and the best alternative method (Prior).</li>
</ol>
<p>We applied McNemar's test (Gibbons &amp; Chakraborti, 2003, section 14.5) to gage statistical significance of these results, comparing the results of the Prior model with our own Mega Model (for the mention tagging experiment, we compute McNemar's test on simple Hamming accuracy rather than F-score; this is suboptimal, but we do not know how to compute statistical significance for the F-score). For the mention type task, the difference is statistical significant at the p ≤ 0.03 level; for the mention tagging task, p ≤ 0.001; for the recapitalization tasks, the difference on the ABC data is significant only at the p ≤ 0.06 level, while for the CNN/NPR data it is significant at the p ≤ 0.004 level.</p>
<p>In the mention type task, we have improved a baseline model trained only on in-domain data from an accuracy of 81.2% up to 92.1%, a relative improvement of 13.4%. For mention tagging, we improve from 83.5% F-measure up to 88.2%, a relative improvement of 5.6%. In the ABC recapitalization task (for which much in-domain data is available), we increase performance from 95.5% to 98.1%, a relative improvement of 2.9%. In the CNN/NPR recapitalization task (with very little in-domain data), we increase performance from 94.6% to 96.8%, a relative improvement of 2.3%.</p>
<p>are reported based on using all 20m examples; we consider only the 3.5m example case. Second, there are likely subtle differences in the training algorithms used. Nevertheless, on the whole, our relative improvements agree with those in their paper. </p>
<p>Learning Curves</p>
<p>Of particular interest is the amount of annotated in-domain data needed to see a marked improvement from the OnlyO baseline to a well adapted system. We show in Figure 4 the learning curves on the Mention Type and Mention Tagging problems. Along the x-axis, we plot the amount of in-domain data used; along the y-axis, we plot the accuracy. We plot three lines: a flat line for the OnlyO model that does not use any in-domain data, and curves for the Prior and MegaM models. As we can see, our model maintains an accuracy above both the other models, while the Prior curve actually falls below the baseline in the type identification task. 3</p>
<p>Model Introspection</p>
<p>We have seen in the previous sections that the Mega Model routinely outperforms competing models. Despite this clear performance improvement, a question remains open regarding the internal workings of the models. The π (i) variable captures the degree to which the indomain data set is truly in-domain. The z variables in the model aim to capture, for each test data point, whether it is "general domain" or "in-domain." In this section, we discuss the particular values of the parameters the model learns for these variables.</p>
<p>We present two analyses. In the first (Section 7.1), we inspect the model's inner workings on the Mention Type task from Section 6.2.1. In this analysis, we look specifically at the expected values of the hidden variables found by the model. In the second analysis (Section 7.2), we look at the ability of the model to judge degree of relatedness, as defined by the π variables.  Table 3: Examples from the test data for the Mention Type task. The "True" column is the correct entity type and the "Hyp" column is our model's prediction. The final column is the probability this example is truly in-domain under our model.</p>
<p>Model Expectations</p>
<p>To focus our discussion, we will consider only the Mention Type task, Section 6.2.1. In Table 3, we have shown seven test-data examples from the Mention Type task. The Precontext is the text that appears before the entity and the post-context is the text that appears after. We report the true class and the class our model hypothesizes. Finally, we report the probability of this example being truly in-domain, according to our model. As we can see, the three examples that the model thinks are general domain are "new jersey," "hospital" and "government." It believes that "me," "anything" and "kid" are all in-domain. In general, the probabilities tend to be skewed toward 0 and 1, which is not uncommon for naïve Bayes models. We have shown two errors in this data. In the first, our model thinks that "hospital" is a location when truly it is an organization. This is a difficult distinction to make: in the training data, hospitals were often used as locations.</p>
<p>The second example error is "anything" in "is he capable of getting anything over here." The long-distance context of this example is a discussion about biological warfare and Saddam Hussein, and "anything" is supposed to refer to a type of biological warhead. Our model mistakingly thinks this is a person. This error is likely due to the fact that our model identifies that the word "anything" is likely to be truly in-domain (the word is not so common in newswire). It has also learned that most truly in-domain entities are people. Thus, lacking evidence otherwise, the model incorrectly guesses that "anything" is a person.</p>
<p>It is interesting to observe that the model believes that the entity "me" in "gives me chills" is closer to general domain than the "me" in "the fisher thing calling me ha ha they screwed up." This likely occurs because the context "ha ha" has not occurred anywhere in the out-of-domain training data, and twice in the in-domain training data. It is unlikely this example would have been misclassified otherwise ("me" is fairly clearly a person), but this example shows that our model is able to take context into account in deciding the domain.</p>
<p>All of the decisions made by the model, shown in Table 3 seem qualitatively reasonable. The numbers are perhaps excessively skewed, but the ranking is believable. The in-domain data is primarily from conversations about random (not necessarily news worthy) topics, and is hence highly colloquial. Contrastively, the out-of-domain data is from formal news. The model is able to learn that entities like "new jersey" and "government" have more to do with news that words like "me" and "kid."</p>
<p>Mention Mention Recap Recap</p>
<p>Type Tagging CNN ABC π (i) 0.14 0.41 0.36 0.51 π (o) 0.11 0.45 0.40 0.69 Table 4: Values for the π variables discovered by the Mega Model algorithm.</p>
<p>Degree of Relatedness</p>
<p>In this section, we analyze the values of π found by the model. Low values of π (i) and π (o) mean that the in-domain data was significantly different than the out-of-domain data; high values mean that they were similar. This is because a high value for π means that the general domain model will be used in most cases. For all tasks but Mention Type, the values of π were middling around 0.4. For Mention Type, π (i) was 0.14 and π (o) was 0.11, indicating that there was a significant difference between the in-domain and out-of-domain data. The exact values for all tasks are shown in Table 4. These values for π make intuitive sense. The distinction between conversation data and news data (for the Mention Type task) is significantly stronger than the difference between manually and automatically transcribed newswire (for the Mention Tagging task). The values for π reflect this qualitative distinction. The rather strong difference between the π values for the recapitalization tasks was not expected a priori. However, a post hoc analysis shows this result is reasonable. We compute the KL divergence between a unigram language model for the out-of-domain data set and each of the in-domain data sets. The KL divergence for the CNN data was 0.07, while the divergence for the ABC data 0.11. This confirms that the ABC data is perhaps more different from the baseline out-of-domain than the CNN data, as reflected by the π values.</p>
<p>We are also interested in cases where there is little difference between in-domain and out-of-domain data. To simulate this case, we have performed the following experiment. We consider again the Mention Type task, but use only the training portion of the out-ofdomain data. We randomly split the data in half, assigning each half to "in-domain" and "out-of-domain." In theory, the model should learn that it may rely only on the general domain model. We performed this experiment under ten fold cross-validation and found that the average value of π selected by the model was 0.94. While this is strictly less than one, it does show that the model is able to identify that these are very similar domains.</p>
<p>Conclusion and Discussion</p>
<p>In this paper, we have presented the Mega Model for domain adaptation in the discriminative (conditional) learning framework. We have described efficient optimization algorithms based on the conditional EM technique. We have experimentally shown, in four data sets, that our model outperforms a large number of baseline systems, including the current state of the art model, and does so requiring significantly less in-domain data.</p>
<p>Although we focused specifically on discriminative modeling in a maximum entropy framework, we believe the novel, basic idea on which this work is founded-to break the in-domain distribution p (i) and out-of-domain distribution p (o) into three distributions, q (i) , q (o) and q (g) -is general. In particular, one could perform a similar analysis in the case of generative models and obtain similar algorithms (though in the case of a generative model, standard EM could be used). Such a model could be applied to domain adaptation in language modeling or machine translation.</p>
<p>With the exception of the work described in Section 2.2, previous work in-domain adaptation is quite rare, especially in the discriminative learning framework. There is a substantial literature in the language modeling/speech community, but most of the adaptation with which they are concerned is based on adapting to new speakers (Iyer, Ostendorf, &amp; Gish, 1997;Kalai, Chen, Blum, &amp; Rosenfeld, 1999). From a learning perspective, the Mega Model is most similar to a mixture of experts model. Our model can be seen as a constrained experts model, with three experts, where the constraints specify that in-domain data can only come from one of two experts, and out-of-domain data can only come from one of two experts (with a single expert overlapping between the two). Most attempts to build discriminative mixture of experts models make heuristic approximations in order to perform the necessary optimization (Jordan &amp; Jacobs, 1994), rather than apply conditional EM, which gives us strict guarantees that we monotonically increase the data (incomplete) log likelihood of each iteration in training.</p>
<p>The domain adaptation problem is also closely related to multitask learning (also known as learning to learn and inductive transfer). In multitask learning, one attempts to learn a function that solves many machine learning problems simultaneously. This related problem is discussed by Thrun (1996), Caruana (1997) and Baxter (2000), among others. The similarity between multitask learning and domain adaptation is that they both deal with data drawn from related, but distinct distributions. The primary difference is that domain adaptation cares only about predicting one label type, while multitask learning cares about predicting many.</p>
<p>As the various sub-communities of the natural language processing family begin and continue to branch out into domains other than newswire, the importance of developing models for new domains without annotating much new data will become more and more important. The Mega Model is a first step toward being able to migrate simple classification-style models (classifiers and maximum entropy Markov models) across domains. Continued research in the area of adaptation is likely to benefit from other work done in active learning and in learning with large amounts unannotated data. p x, y, z | ψ (ν) , λ (ν) , π =    N n=1 Ber(z n | π) </p>
<p>The marginal distribution is obtained by removing the last two terms (the exp and the sum of exps) from the final equation. Plugging Eq (19) into Eq (10) and using the notation from Eq (12), we obtain the following expression for Q t :
Q t = ν   log Nor(λ (ν) ; 0, σ 2 I) + F f =1 log Bet(ψ (ν) f ; a, b)   + N n=1
zn h n z n log π + (1 − z n ) log(1 − π) + log ψ n,zn
+ F f =1
x nf log λ zn yn − log c exp λ zn c ⊤ x n − j t n,zn −m t−1 n π zn (1 − π) 1−zn ψ n,zn + 1 (20)</p>
<p>as well as an analogous term for the out-of-domain data. j and m are defined in Table 1.</p>
<p>B.1 M-Step for π</p>
<p>For computing π, we simply differentiate Q t (see Eq (20)) with respect to π, obtaining:
∂Q t ∂π = N n=1
h n π + 1 − h n 1 − π + m t−1 n (ψ n,0 − ψ n,1 )</p>
<p>solving this for 0 leads directly to a quadratic expression of the form: 0 = π 2 N n=1 m t−1 n (ψ n,0 − ψ n,1 )
+ π 1 −1 + N n=1
2h n − m t−1 n (ψ n,0 − ψ n,1 )
+ π 0 − N n=1 h n(22)
Solving this directly for π gives the desired update equation.</p>
<p>B.2 M-Step for λ</p>
<p>For optimizing λ (i) , we rewrite Q t , Eq (20), neglecting all irrelevant terms, as:
Q t [λ] = N n=1 (1 − h n )    F f =1 x nf λ yn,f − log c exp λ c ⊤ x n    + log Nor(λ; 0, σ 2 I)(23)
In Eq (23), the bracketed expression is exactly the log-likelihood term obtained for standard logistic regression models. Thus, the optimization of Q with respect to λ (i) and λ (o) can be performed using a weighted version of standard logistic regression optimization, with weights defined by (1−h n ). In the case of λ (g) , we obtain a weighted logistic regression model, but over all N (i) + N (o) data points, and with weights defined by h n .</p>
<p>B.3 M-Step for ψ</p>
<p>In the case of ψ (i) and ψ (o) , we rewrite Eq (20) and remove all irrelevant terms, as:
Q t [ψ (i) ] = F f =1 log Bet(ψ f ; a, b) + N n=1
(1 − h n ) log ψ n,0 − m t−1 n (1 − π)ψ n,0</p>
<p>Due to the presence of the product term in ψ, we cannot compute an analytical solution to this maximization problem. However, we can take derivatives component-wise (in F ) and obtain analytical solutions (when combined with the prior). This admits an iterative solution for maximizing Q t ψ by maximizing each component separately until convergence. Computing derivatives of Q t with respect to ψ f requires differentiating ψ n,0 with respect to ψ f ; this has a convenient form (recalling the notation from Table 1:
∂ ∂ψ f ψ n,0 = [ψ n,0,−f ] ∂ ∂ψ f {x nf ψ f + (1 − x nf )(1 − ψ f )} = ψ n,0,−f(25)
Using this result, we can maximize Q t with respect to ψ f by solving:
∂ ∂ψ f Q t ψ f = N n=1 (1 − h n ) x nf (1 − ψ f ) − (1 − x nf )ψ f ψ f (1 − ψ f )(26)
−j n,0 (1 − π)ψ n,0,−f + 1 1 − h n + j n,0 (1 − π)ψ n,0,−f
ψ f (1 − ψ f ) = 1 ψ f (1 − ψ f ) 1 + N n=1 (1 − h n ) (x nf − ψ f ) −N+ (ψ f ) 0 1 + N n=1 (1 − h n ) x nf(27)
This final equation can be solved analytically. A similar expression arises for ψ</p>
<p>(o)</p>
<p>f . In the case of ψ (g) f , we obtain a quadratic form with sums over the entire data set and with h n replacing the occurrences of (1 − h n ):
0 = ψ (g) f 2   N (i) n=1 j (i) n,1 π (i) ψ (i) n,1,−f + N (o) n=1 j (o) n,1 π (o) ψ (o) n,1,−f   + ψ (g) f 1 − N (i) n=1 h (i) n + j (i) n,1 π (i) ψ (i) n,1,−f − N (o) n=1 h (o) n + j (o) n,1 π (o) ψ (o) n,1,−f + ψ (g) f 0   1 + N (i) n=1 h (i) n x (i) nf + N (o) n=1 h (o) n x (o) nf  (28)
Again, this can be solved analytically. The values j, m, ψ ·,· and ψ ·,·,−· are defined in Table 1.</p>
<p>, we assume the existence of a binary indicator variable z</p>
<p>is drawn from q (i) (the truly in-domain distribution), while a value z (i) n = 0 indicates that it is drawn from q (g) (the general-domain distribution). Similarly, for each out-of-domain data point (x</p>
<p>this data point is drawn from q (o) (the truly out-of-domain distribution) and a value of 0 means that it is drawn from q (g) (the general-domain distribution). Of course, these indicator variables are not observed in the data, so we must infer their values automatically.</p>
<p>Figure 1 :
1(Left) the standard logistic regression model; (Right) the Mega Model.</p>
<p>all ν ∈ {g, i, o} and all f . while parameters haven't converged or iterations remain do{-Expectation Step -} for n = 1..N (i) doCompute the in-domain marginal probabilities, m(i) n Compute the in-domain expectations, h (i) n , by Eq (12) end for for n = 1..N (o) do Compute the out-of-domain marginal probabilities, m (o) n Compute the out-of-domain expectations, h</p>
<p>Figure 2 :
2The full training algorithm for the Mega Model.</p>
<p>Figure 3 :
3Convergence of training algorithm.</p>
<p>Figure 4 :
4Learning curves for Prior and MegaM models.</p>
<p>x nf | ψ zn f )Gibbs(y n | x n , λ zn )</p>
<p>n=1 j n,0 (1 − π)ψ n,0,−f Equating this to zero yields a quadratic expression of the</p>
<p>Table 1 :
1Notation used for Mega Model equations.</p>
<p>). For the CNN/NPR data, we use 146k in-domain training examples and 73k test examples; for the ABC Primetime data, we use 33k in-domain training examples and 8k test examples. We use identical features to</p>
<p>Pre-context . . . Entity . . . Post-contextTrue 
Hyp p (z = I) 
my home is in trenton . . . new jersey . . . and that's where 
GPE GPE 
0.02 
veteran's administration . . . hospital . . . 
ORG LOC 
0.11 
you know by the american . . . government. . . because what is 
ORG ORG 
0.17 
gives . . . 
me 
. . . chills because if 
PER PER 
0.71 
is he capable of getting . . . anything . . . over here 
WEA PER 
0.92 
the fisher thing calling . . . 
me 
. . . ha ha they screwed up PER PER 
0.93 
when i was a . . . 
kid 
. . . that that was a 
PER PER 
0.98 </p>
<p>c 2006 AI Access Foundation. All rights reserved.
. This is because the Fisher data is personal conversations. It hence has a much higher degree of first and second person pronouns than news. (The baseline that always guesses "person" achieves a 77.8% accuracy.) By not being able to intelligently use the out-of-domain data only when the in-domain model is unsure, performance drops, as observed in the Prior model.
AcknowledgmentsWe thank Ciprian Chelba and Alex Acero for making their data available. We thank Ryan McDonald for pointing out the Feats baseline, which we had not previously considered. We also thank Kevin Knight and Dragos Munteanu for discussions related to this project. This paper was greatly improved by suggestions from reviewers, including reviewers of a previous, shorter version. This work was partially supported by DARPA-ITO grant N66001-00-1-9814, NSF grant IIS-0097846, NSF grant IIS-0326276, and a USC Dean Fellowship to Hal Daumé III.Appendix A. Conditional Expectation MaximizationIn this appendix, we derive Eq (10) from Eq (7) by making use of Jensen's inequality and the variational bound. The interested reader is referred to the work ofJebara and Pentland (1998)for further details. Our discussion will consider a bound in the change of the log likelihood between iteration t − 1 and iteration t, ∆l c , as given in Eq(14):Here, we have effectively rewritten the log-change in the ratio of the conditionals as the difference between the log-change in the ratio of the joints and the log-change in the ratio of the marginals. We may rewrite Eq (15) by introducing the hidden variables z as:We can now apply Jensen's inequality to the first term in Eq (16) to obtain:In Eq (17), the expression denoted h x,y,z,Θ t−1 is the joint expectation of z under the previous iteration's parameter settings. Unfortunately, we cannot also apply Jensen's inequality to the remaining term in Eq (17) because it appears negated. By applying the variational dual (log x ≤ x − 1) to this term, we obtain the following, final bound:Applying the bound from Eq (18) to the distributions chosen in our model yields Eq (10).Appendix B. Derivation of Estimation EquationsGiven the model structure and parameterization of the Mega Modelgiven in Section 3.2, Eq (5), we obtain the following expression for the joint probability of the data:
Evaluation of large-scale optimization problems on vector and parallel architectures. B M Averick, J J Moré, SIAM Journal of Optimization. 4Averick, B. M., &amp; Moré, J. J. (1994). Evaluation of large-scale optimization problems on vector and parallel architectures. SIAM Journal of Optimization, 4.</p>
<p>A model of inductive bias learning. J Baxter, Journal of Artificial Intelligence Research. 12Baxter, J. (2000). A model of inductive bias learning. Journal of Artificial Intelligence Research, 12 , 149-198.</p>
<p>Unsupervised langauge model adaptation. M Bacchiani, B Roark, Proceedings of the International Conference on Acoustics, Speech and Signal Processing. the International Conference on Acoustics, Speech and Signal ProcessingICASSPBacchiani, M., &amp; Roark, B. (2003). Unsupervised langauge model adaptation. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing (ICASSP).</p>
<p>Multitask learning: A knowledge-based source of inductive bias. Machine Learning. R Caruana, 28Caruana, R. (1997). Multitask learning: A knowledge-based source of inductive bias. Ma- chine Learning, 28 , 41-75.</p>
<p>Adaptation of maximum entropy classifier: Little data can help a lot. C Chelba, A Acero, Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP). the Conference on Empirical Methods in Natural Language Processing (EMNLP)Barcelona, SpainChelba, C., &amp; Acero, A. (2004). Adaptation of maximum entropy classifier: Little data can help a lot. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), Barcelona, Spain.</p>
<p>A Gaussian prior for smoothing maximum entropy models. S Chen, R Rosenfeld, CMUCS 99-108Carnegie Mellon University, Computer Science DepartmentTech. rep.Chen, S., &amp; Rosenfeld, R. (1999). A Gaussian prior for smoothing maximum entropy models. Tech. rep. CMUCS 99-108, Carnegie Mellon University, Computer Science Department.</p>
<p>Inducing features of random fields. S Della Pietra, V J Della Pietra, J D Lafferty, IEEE Transactions on Pattern Analysis and Machine Intelligence. 194Della Pietra, S., Della Pietra, V. J., &amp; Lafferty, J. D. (1997). Inducing features of random fields. IEEE Transactions on Pattern Analysis and Machine Intelligence, 19 (4), 380- 393.</p>
<p>Maximum likelihood from incomplete data via the EM algorithm. A Dempster, N Laird, D Rubin, Journal of the Royal Statistical Society. 39Dempster, A., Laird, N., &amp; Rubin, D. (1977). Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, B39.</p>
<p>Customization in a unified framework for summarizing medical literature. N Elhadad, M.-Y Kan, J Klavans, K Mckeown, Journal of Artificial Intelligence in Medicine. 332Elhadad, N., Kan, M.-Y., Klavans, J., &amp; McKeown, K. (2005). Customization in a unified framework for summarizing medical literature. Journal of Artificial Intelligence in Medicine, 33 (2), 179-198.</p>
<p>An extensive empirical study of feature selection metrics for text classification. G Forman, Journal of Machine Learning Research. 3Forman, G. (2003). An extensive empirical study of feature selection metrics for text clas- sification. Journal of Machine Learning Research, 3, 1289-1305.</p>
<p>Nonparametric Statistical Inference. J D Gibbons, S Chakraborti, Marcel Dekker, IncGibbons, J. D., &amp; Chakraborti, S. (2003). Nonparametric Statistical Inference. Marcel Dekker, Inc.</p>
<p>Corpus variation and parser performance. D Gildea, Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP). the Conference on Empirical Methods in Natural Language Processing (EMNLP)Gildea, D. (2001). Corpus variation and parser performance. In Proceedings of the Confer- ence on Empirical Methods in Natural Language Processing (EMNLP).</p>
<p>Information extraction from biomedical text. J R Hobbs, Journal of Biomedical Informatics. 354Hobbs, J. R. (2002). Information extraction from biomedical text. Journal of Biomedical Informatics, 35 (4), 260-264.</p>
<p>Information extraction from voicemail. J Huang, G Zweig, M Padmanabhan, Proceedings of the Conference of the Association for Computational Linguistics (ACL). the Conference of the Association for Computational Linguistics (ACL)Huang, J., Zweig, G., &amp; Padmanabhan, M. (2001). Information extraction from voicemail. In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</p>
<p>Supervised grammar induction using training data with limited constituent information. R Hwa, Proceedings of the Conference of the Association for Computational Linguistics (ACL). the Conference of the Association for Computational Linguistics (ACL)Hwa, R. (1999). Supervised grammar induction using training data with limited constituent information. In Proceedings of the Conference of the Association for Computational Linguistics (ACL), pp. 73-79.</p>
<p>Using out-of-domain data to improve in-domain language models. R Iyer, M Ostendorf, H Gish, IEEE Signal Processing. 84Iyer, R., Ostendorf, M., &amp; Gish, H. (1997). Using out-of-domain data to improve in-domain language models. IEEE Signal Processing, 4 (8).</p>
<p>Maximum conditional likelihood via bound maximization and the CEM algorithm. T Jebara, A Pentland, Advances in Neural Information Processing Systems (NIPS). Jebara, T., &amp; Pentland, A. (1998). Maximum conditional likelihood via bound maximization and the CEM algorithm. In Advances in Neural Information Processing Systems (NIPS).</p>
<p>Hierarchical mixtures of experts and the EM algorithm. M Jordan, R Jacobs, Neural Computation. 6Jordan, M., &amp; Jacobs, R. (1994). Hierarchical mixtures of experts and the EM algorithm. Neural Computation, 6, 181-214.</p>
<p>On-line algorithms for combining language models. A Kalai, S Chen, A Blum, R Rosenfeld, ICASSP. Kalai, A., Chen, S., Blum, A., &amp; Rosenfeld, R. (1999). On-line algorithms for combining language models. In ICASSP.</p>
<p>Conditional random fields: Probabilistic models for segmenting and labeling sequence data. J Lafferty, A Mccallum, F Pereira, Proceedings of the International Conference on Machine Learning (ICML). the International Conference on Machine Learning (ICML)Lafferty, J., McCallum, A., &amp; Pereira, F. (2001). Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the International Conference on Machine Learning (ICML).</p>
<p>A comparison of algorithms for maximum entropy parameter estimation. R Malouf, Proceedings of CoNLL. CoNLLMalouf, R. (2002). A comparison of algorithms for maximum entropy parameter estimation. In Proceedings of CoNLL.</p>
<p>Maximum entropy Markov models for information extraction and segmentation. A Mccallum, D Freitag, F Pereira, Proceedings of the International Conference on Machine Learning (ICML). the International Conference on Machine Learning (ICML)McCallum, A., Freitag, D., &amp; Pereira, F. (2000). Maximum entropy Markov models for information extraction and segmentation. In Proceedings of the International Confer- ence on Machine Learning (ICML).</p>
<p>A comparison of numerical optimizers for logistic regression. T P Minka, Minka, T. P. (2003). A comparison of numerical optimizers for logistic regression. http: //www.stat.cmu.edu/~minka/papers/logreg/.</p>
<p>Improving machine translation performance by exploiting non-parallel corpora. D Munteanu, D Marcu, Computational Linguistics. To appearMunteanu, D., &amp; Marcu, D. (2005). Improving machine translation performance by exploit- ing non-parallel corpora. Computational Linguistics, To appear.</p>
<p>A numerical study of the limited memory BFGS method and the truncated Newton method for large scale optimization. S Nash, J Nocedal, SIAM Journal of Optimization. 1Nash, S., &amp; Nocedal, J. (1991). A numerical study of the limited memory BFGS method and the truncated Newton method for large scale optimization. SIAM Journal of Optimization, 1, 358-372.</p>
<p>Summarizing email threads. O Rambow, L Shrestha, J Chen, C Lauridsen, Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL) Short. the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL) ShortPaper SectionRambow, O., Shrestha, L., Chen, J., &amp; Lauridsen, C. (2004). Summarizing email threads. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL) Short Paper Section.</p>
<p>Supervised and unsupervised PCFG adaptation to novel domains. B Roark, M Bacchiani, Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics and Human Language Technology (NAACL/HLT). the Conference of the North American Chapter of the Association for Computational Linguistics and Human Language Technology (NAACL/HLT)Roark, B., &amp; Bacchiani, M. (2003). Supervised and unsupervised PCFG adaptation to novel domains. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics and Human Language Technology (NAACL/HLT).</p>
<p>Variational Methods in Optimization. D R Smith, Dover Publications, IncMineola; New YorkSmith, D. R. (1998). Variational Methods in Optimization. Dover Publications, Inc., Mine- ola, New York.</p>
<p>Is learning the n-th thing any easier than learning the first. S Thrun, Advances in Neural Information Processing Systems (NIPS). Thrun, S. (1996). Is learning the n-th thing any easier than learning the first. In Advances in Neural Information Processing Systems (NIPS).</p>            </div>
        </div>

    </div>
</body>
</html>