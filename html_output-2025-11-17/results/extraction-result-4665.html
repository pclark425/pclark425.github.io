<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4665 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4665</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4665</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-103.html">extraction-schema-103</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <p><strong>Paper ID:</strong> paper-267224915</p>
                <p><strong>Paper Title:</strong> <a href="https://ojs.aaai.org/index.php/AAAI-SS/article/download/27688/27461/31739" target="_blank">Memory Matters: The Need to Improve Long-Term Memory in LLM Agents</a></p>
                <p><strong>Paper Abstract:</strong> In this paper, we provide a review of the current efforts to develop LLM agents, which are autonomous agents that leverage large language models. We examine the memory management approaches used in these agents. One crucial aspect of these agents is their long-term memory, which is often implemented using vector databases. We describe how vector databases are utilized to store and retrieve information in LLM agents. Moreover we highlight open problems, such as the separation of different types of memories and the management of memory over the agentâ€™s lifetime. Lastly, we propose several topics for future research to address these challenges and further enhance the capabilities of LLM agents, including the use of metadata in procedural and semantic memory and the integration of external knowledge sources with vector databases.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4665.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4665.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Auto-GPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Auto-GPT: An Autonomous GPT-4 Experiment</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A goal-driven autonomous agent framework that uses GPT-4 as a controller to decompose user goals into subtasks, execute them via tools/commands, and store outcomes as memories to inform future subtasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Auto-GPT: An Autonomous GPT-4 Experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Auto-GPT</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An autonomous, self-directed agent that takes a natural-language goal, decomposes it into subtasks with GPT-4, executes subtasks via terminal commands and APIs, and persists information from executed subtasks as memories for later use.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>short-term (context window) and long-term (vector database / external memory)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Short-term memory implemented by prepending previous subtask prompts and results to subsequent LLM calls; long-term memory typically stored externally using vector databases to retain outcomes from earlier subtask executions for retrieval in future subtasks.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Open-ended goal completion (task decomposition and execution; e.g., writing/debugging code, multi-step automation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>User supplies a high-level goal; agent recursively decomposes into executable subtasks and uses tools/APIs to complete them, storing subtask outcomes to guide future steps.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>No quantitative comparison reported; authors describe use of short-term context and external vector DBs for longer-term storage and note that memory enables carrying information across subtasks but has limitations due to context-window size and vector DB shortcomings.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Confabulation/hallucinations, difficulty maintaining task focus and contextual understanding across long workflows, context-window limits for short-term memory, and vector DB limitations for long-term memory (segregation, scaling, retrieval accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Memory is necessary to pass information across subtasks, but current methods (context prepending + vector DBs) are limited; need better long-term memory management (segregation of memory types, metadata, forgetting strategies) to improve reliability.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4665.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4665.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BabyAGI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BabyAGI</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A lightweight autonomous task-management agent that uses an LLM with a vector database to generate, prioritize, and execute tasks based on an objective and past results.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>BabyAGI</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An LLM-driven task manager which continuously creates and prioritizes tasks toward a goal, leveraging a vector-store (e.g., Chroma or Weaviate) to store past task results and context for reuse.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>long-term (vector database / retrieval-augmented memory)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Stores task results and related information as embeddings in a vector database (e.g., Chroma or Weaviate) which are retrieved to inform creation and prioritization of new tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Task generation, prioritization and execution (AI task manager)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Given an objective and prior task outputs, the agent generates new tasks, prioritizes them, executes tasks via tools, and uses past results stored in a vector DB to guide future task creation.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>No quantitative comparisons provided; paper notes use of vector DBs to enable adaptation across tasks by retrieving prior task results.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Vector DB limitations (indexing/retrieval/metadata handling), potential inconsistencies between episodic and semantic stores, and scaling/lifespan management of memories.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Using a vector DB to store past task outputs allows the agent to adapt task generation/prioritization, but requires better memory organization, metadata, and forgetting strategies to remain effective.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4665.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4665.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SmartGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SmartGPT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system aiming to enable LLMs to complete complex tasks autonomously by decomposing tasks, gathering information from external sources, and executing subtasks without user input.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>SmartGPT</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An autonomous agent that breaks complex tasks into smaller problems, collects information from external (internet) sources, and uses that information to drive task completion.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external retrieval / web-sourced context (memory not explicitly described as vector DB)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Collects information from external sources (the internet) to inform task solving; the paper does not specify a persistent long-term vector-based memory implementation for SmartGPT.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Complex task completion without user input</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Break complex user goals into subproblems, fetch external information, and iteratively solve and integrate results to complete tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>No comparisons provided; memory use described qualitatively as external information gathering rather than a structured LTM implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Not detailed in the paper beyond general agent issues (hallucinations, context management); memory architecture not specified.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>External information retrieval can augment agent capabilities, but clearer long-term memory architectures and metadata management are needed for sustained performance.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4665.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4665.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-Engineer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT Engineer</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source project that generates an entire codebase from a user prompt, enabling developers to build and extend autonomous agents or code-generation pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>GPT Engineer</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>GPT-Engineer</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A project that prompts an LLM to produce full codebases from specifications; presented as a platform for building and customizing autonomous agents or code-generation toolboxes.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>not specified</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Paper references the project in context of agent tooling; the paper does not describe GPT-Engineer using explicit long-term memory stores or vector DBs.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Codebase generation / developer support</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Generate a complete codebase based on a user-defined prompt; used as a tool for creating custom autonomous agents.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>No memory-related comparisons reported.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Not discussed with respect to memory in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Serves as an example of LLM-driven tooling; memory implications not detailed in the paper.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4665.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4665.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChemCrow</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChemCrow: Augmenting large-language models with chemistry tools</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-specific LLM agent that combines LLMs with expert-designed tools to assist with organic synthesis, drug discovery, and materials design tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ChemCrow: Augmenting large-language models with chemistry tools.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ChemCrow</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A specialized autonomous agent that pairs LLMs with chemistry-specific tools (expert modules) to perform tasks in synthesis and discovery workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>not specified (augmented with expert tools)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>The paper describes ChemCrow as LLMs augmented with domain tools; it does not detail a long-term memory implementation (e.g., vector DB) in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Domain-specific scientific tasks (organic synthesis, drug/materials discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Use LLM reasoning plus domain tools to plan and propose experimental or design steps in chemistry-related workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>No memory-specific evaluations reported in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Domain-specific risks remain (e.g., accuracy of tool outputs, safety); memory architecture not discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Augmenting LLMs with expert tools is promising for specialized domains; integrating this with structured long-term memory remains an open area.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4665.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4665.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative Agents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A sandbox of virtual characters controlled by LLM-based agents that integrate memory, planning, and reflection mechanisms to simulate believable, long-term human-like behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Generative Agents (Park et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agents that simulate human characters in a sandbox world, combining LLM-driven planning with memory and reflection systems to produce temporally coherent and socially plausible behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic and declarative memory (agent-specific memory modules)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Integrates memory, planning, and reflection mechanisms where agents record experiences and retrieve relevant memories to influence behavior and dialogue; described qualitatively in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Interactive behavior simulation / multi-agent social simulation</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Create virtual characters that interact over time; agents must recall past events, plan actions, and reflect to produce believable sequences of behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>No quantitative ablation provided here; memory and reflection are presented as key components enabling believable, temporally consistent agent behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Scalability of memory, retrieval relevance, potential inconsistencies between episodic memories and semantic beliefs, and lack of formal grounding are noted as ongoing challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Combining episodic memory with planning and reflection improves temporal coherence and believability, but robust memory organization and longevity management remain open problems.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4665.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e4665.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Teenage-AGI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Teenage-AGI</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An implementation where each LLM 'thought' and perceived memory is stored in a Pinecone vector database and retrieved to augment the LLM context for subsequent reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Teenage-AGI</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Teenage-AGI</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An LLM-based agent framework that records each generated thought/perception as an embedding in a vector DB and retrieves top-k related memories to prepend to prompts, improving contextual relevance.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>long-term (vector database / Pinecone); declarative & episodic</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Stores each thought and perceived memory as embeddings in Pinecone; on new thoughts/perceptions the DB is queried for top-k matches and those items are added to the prompt context (working memory).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>General reasoning/creative generation via thought augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Enhance LLM outputs by retrieving and attending to prior related experiences (thoughts/perceptions) stored as vector embeddings to inform current reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>No numerical comparison provided; described qualitatively that retrieval of related past experiences often improves output accuracy and meaningfulness (akin to few-shot prompting benefits).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Potential retrieval errors, mixing of memory types if not segregated, scaling of stored thoughts, and still susceptible to LLM hallucinations without higher-level logical control.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Embedding and retrieving prior 'thoughts' can make outputs more accurate and relevant, but requires careful memory organization (type separation, metadata) and integration with higher-level reasoning to avoid inconsistencies.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4665.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e4665.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Voyager</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Voyager: An openended embodied agent with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An embodied lifelong learning agent operating in Minecraft that stores descriptions of learned skills in a vector database and uses a GPT model to plan and retrieve skills relevant to the current environment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Voyager: An openended embodied agent with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Voyager</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An LLM-powered embodied agent in Minecraft which learns and refines skills (small programs interacting with the environment), stores skill descriptions in a vector DB, and uses LLM planning with retrieved skills to act and learn iteratively.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>procedural memory in a vector database (embedding descriptions of learned skills)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Embeds descriptions of learned skills and environment/plans; retrieves closest skill embeddings from the vector DB, refines skills through prompting, and uses them in chain-of-thought planning for task execution.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Embodied lifelong learning / skill acquisition in Minecraft</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Agent explores a Minecraft environment, synthesizes and refines small programs (skills), stores skill descriptions as embeddings, and retrieves and composes skills to accomplish open-ended tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>No numeric ablation in this review; described qualitatively that storing procedural skill descriptions in a vector DB enables fast retrieval of relevant skills and iterative refinement that supports lifelong learning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Challenges include hallucinations, lack of higher-level logical System 2, potential mixing of memory types in same store, and lifelong memory scaling/organization issues.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Storing procedural skills as embeddings enables rapid retrieval and reuse in novel contexts, but effective lifelong skill management requires indexing, metadata, and separation from other memory types.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4665.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e4665.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MRKL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic modular architecture where an LLM acts as a central controller, routing queries to specialized expert modules (neural or symbolic) to leverage diverse reasoning capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MRKL</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A modular architecture where an LLM coordinates and delegates to expert modules (neural/symbolic) for reasoning, effectively combining retrieval and specialized computational modules under LLM control.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external knowledge modules and potentially external memory attachments (not specified as vector DB in this review)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Described as combining LLMs with expert modules; the review suggests this architecture could attach LLM modules to cognitive-architecture long-term memory but does not specify an implemented vector-based memory.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>General modular reasoning and tool use</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Use LLM as controller to route subproblems to expert modules appropriate for the subtask, integrating results to solve complex problems.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>No empirical memory comparisons in this review; MRKL is presented as a framework that could benefit from principled long-term memory attachments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Unclear how to align LLM representations with cognitive-architecture assumptions on mental representations and grounding; memory-grounding to embodiment remains an open question.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Modular architectures can combine LLM strengths with specialist modules, but integrating long-term memory that respects memory type distinctions and grounding is a research challenge.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4665.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e4665.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>dev-GPT2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>dev-gpt (dev-GPT2 reference in review)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced simpler system that uses heuristic counting of failures to avoid infinite retry loops in subtask attempts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td> </td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>dev-GPT / dev-GPT2 (referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A simple agent-level heuristic that counts failures per subtask strategy and switches to a new strategy after a threshold number of failures to avoid loops.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>short-term failure counters (simple heuristic); not full LTM</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Counts the number of failures per subtask strategy (a simple form of logged history) and triggers strategy changes after threshold (e.g., try a new strategy after 10 failures).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Subtask execution loop control / failure management</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Manage retries on failing subtasks by tracking repeated failures per strategy and altering behavior to avoid infinite loops.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>No formal comparisons; provided as a simple mitigation for infinite subtask loops by using a form of logged failure memory instead of sophisticated LTM.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Heuristic thresholds are brittle; does not generalize to richer memory needs or semantic/procedural memory separation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Even simple recorded-memory heuristics (failure counts) can mitigate specific failure modes (infinite subtask loops), suggesting practical short-term measures while richer LTM systems are developed.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Voyager: An openended embodied agent with large language models <em>(Rating: 2)</em></li>
                <li>Generative agents: Interactive simulacra of human behavior <em>(Rating: 2)</em></li>
                <li>ChemCrow: Augmenting large-language models with chemistry tools <em>(Rating: 2)</em></li>
                <li>MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning <em>(Rating: 2)</em></li>
                <li>Auto-GPT: An Autonomous GPT-4 Experiment. <em>(Rating: 1)</em></li>
                <li>Teenage-AGI <em>(Rating: 1)</em></li>
                <li>GPT Engineer <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4665",
    "paper_id": "paper-267224915",
    "extraction_schema_id": "extraction-schema-103",
    "extracted_data": [
        {
            "name_short": "Auto-GPT",
            "name_full": "Auto-GPT: An Autonomous GPT-4 Experiment",
            "brief_description": "A goal-driven autonomous agent framework that uses GPT-4 as a controller to decompose user goals into subtasks, execute them via tools/commands, and store outcomes as memories to inform future subtasks.",
            "citation_title": "Auto-GPT: An Autonomous GPT-4 Experiment.",
            "mention_or_use": "mention",
            "agent_name": "Auto-GPT",
            "agent_description": "An autonomous, self-directed agent that takes a natural-language goal, decomposes it into subtasks with GPT-4, executes subtasks via terminal commands and APIs, and persists information from executed subtasks as memories for later use.",
            "memory_type": "short-term (context window) and long-term (vector database / external memory)",
            "memory_description": "Short-term memory implemented by prepending previous subtask prompts and results to subsequent LLM calls; long-term memory typically stored externally using vector databases to retain outcomes from earlier subtask executions for retrieval in future subtasks.",
            "task_name": "Open-ended goal completion (task decomposition and execution; e.g., writing/debugging code, multi-step automation)",
            "task_description": "User supplies a high-level goal; agent recursively decomposes into executable subtasks and uses tools/APIs to complete them, storing subtask outcomes to guide future steps.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "No quantitative comparison reported; authors describe use of short-term context and external vector DBs for longer-term storage and note that memory enables carrying information across subtasks but has limitations due to context-window size and vector DB shortcomings.",
            "limitations_or_challenges": "Confabulation/hallucinations, difficulty maintaining task focus and contextual understanding across long workflows, context-window limits for short-term memory, and vector DB limitations for long-term memory (segregation, scaling, retrieval accuracy).",
            "key_insights": "Memory is necessary to pass information across subtasks, but current methods (context prepending + vector DBs) are limited; need better long-term memory management (segregation of memory types, metadata, forgetting strategies) to improve reliability.",
            "uuid": "e4665.0"
        },
        {
            "name_short": "BabyAGI",
            "name_full": "BabyAGI",
            "brief_description": "A lightweight autonomous task-management agent that uses an LLM with a vector database to generate, prioritize, and execute tasks based on an objective and past results.",
            "citation_title": "",
            "mention_or_use": "mention",
            "agent_name": "BabyAGI",
            "agent_description": "An LLM-driven task manager which continuously creates and prioritizes tasks toward a goal, leveraging a vector-store (e.g., Chroma or Weaviate) to store past task results and context for reuse.",
            "memory_type": "long-term (vector database / retrieval-augmented memory)",
            "memory_description": "Stores task results and related information as embeddings in a vector database (e.g., Chroma or Weaviate) which are retrieved to inform creation and prioritization of new tasks.",
            "task_name": "Task generation, prioritization and execution (AI task manager)",
            "task_description": "Given an objective and prior task outputs, the agent generates new tasks, prioritizes them, executes tasks via tools, and uses past results stored in a vector DB to guide future task creation.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "No quantitative comparisons provided; paper notes use of vector DBs to enable adaptation across tasks by retrieving prior task results.",
            "limitations_or_challenges": "Vector DB limitations (indexing/retrieval/metadata handling), potential inconsistencies between episodic and semantic stores, and scaling/lifespan management of memories.",
            "key_insights": "Using a vector DB to store past task outputs allows the agent to adapt task generation/prioritization, but requires better memory organization, metadata, and forgetting strategies to remain effective.",
            "uuid": "e4665.1"
        },
        {
            "name_short": "SmartGPT",
            "name_full": "SmartGPT",
            "brief_description": "A system aiming to enable LLMs to complete complex tasks autonomously by decomposing tasks, gathering information from external sources, and executing subtasks without user input.",
            "citation_title": "",
            "mention_or_use": "mention",
            "agent_name": "SmartGPT",
            "agent_description": "An autonomous agent that breaks complex tasks into smaller problems, collects information from external (internet) sources, and uses that information to drive task completion.",
            "memory_type": "external retrieval / web-sourced context (memory not explicitly described as vector DB)",
            "memory_description": "Collects information from external sources (the internet) to inform task solving; the paper does not specify a persistent long-term vector-based memory implementation for SmartGPT.",
            "task_name": "Complex task completion without user input",
            "task_description": "Break complex user goals into subproblems, fetch external information, and iteratively solve and integrate results to complete tasks.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "No comparisons provided; memory use described qualitatively as external information gathering rather than a structured LTM implementation.",
            "limitations_or_challenges": "Not detailed in the paper beyond general agent issues (hallucinations, context management); memory architecture not specified.",
            "key_insights": "External information retrieval can augment agent capabilities, but clearer long-term memory architectures and metadata management are needed for sustained performance.",
            "uuid": "e4665.2"
        },
        {
            "name_short": "GPT-Engineer",
            "name_full": "GPT Engineer",
            "brief_description": "An open-source project that generates an entire codebase from a user prompt, enabling developers to build and extend autonomous agents or code-generation pipelines.",
            "citation_title": "GPT Engineer",
            "mention_or_use": "mention",
            "agent_name": "GPT-Engineer",
            "agent_description": "A project that prompts an LLM to produce full codebases from specifications; presented as a platform for building and customizing autonomous agents or code-generation toolboxes.",
            "memory_type": "not specified",
            "memory_description": "Paper references the project in context of agent tooling; the paper does not describe GPT-Engineer using explicit long-term memory stores or vector DBs.",
            "task_name": "Codebase generation / developer support",
            "task_description": "Generate a complete codebase based on a user-defined prompt; used as a tool for creating custom autonomous agents.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "No memory-related comparisons reported.",
            "limitations_or_challenges": "Not discussed with respect to memory in this review.",
            "key_insights": "Serves as an example of LLM-driven tooling; memory implications not detailed in the paper.",
            "uuid": "e4665.3"
        },
        {
            "name_short": "ChemCrow",
            "name_full": "ChemCrow: Augmenting large-language models with chemistry tools",
            "brief_description": "A domain-specific LLM agent that combines LLMs with expert-designed tools to assist with organic synthesis, drug discovery, and materials design tasks.",
            "citation_title": "ChemCrow: Augmenting large-language models with chemistry tools.",
            "mention_or_use": "mention",
            "agent_name": "ChemCrow",
            "agent_description": "A specialized autonomous agent that pairs LLMs with chemistry-specific tools (expert modules) to perform tasks in synthesis and discovery workflows.",
            "memory_type": "not specified (augmented with expert tools)",
            "memory_description": "The paper describes ChemCrow as LLMs augmented with domain tools; it does not detail a long-term memory implementation (e.g., vector DB) in this review.",
            "task_name": "Domain-specific scientific tasks (organic synthesis, drug/materials discovery)",
            "task_description": "Use LLM reasoning plus domain tools to plan and propose experimental or design steps in chemistry-related workflows.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "No memory-specific evaluations reported in this review.",
            "limitations_or_challenges": "Domain-specific risks remain (e.g., accuracy of tool outputs, safety); memory architecture not discussed.",
            "key_insights": "Augmenting LLMs with expert tools is promising for specialized domains; integrating this with structured long-term memory remains an open area.",
            "uuid": "e4665.4"
        },
        {
            "name_short": "Generative Agents",
            "name_full": "Generative Agents: Interactive simulacra of human behavior",
            "brief_description": "A sandbox of virtual characters controlled by LLM-based agents that integrate memory, planning, and reflection mechanisms to simulate believable, long-term human-like behavior.",
            "citation_title": "Generative agents: Interactive simulacra of human behavior.",
            "mention_or_use": "mention",
            "agent_name": "Generative Agents (Park et al.)",
            "agent_description": "Agents that simulate human characters in a sandbox world, combining LLM-driven planning with memory and reflection systems to produce temporally coherent and socially plausible behavior.",
            "memory_type": "episodic and declarative memory (agent-specific memory modules)",
            "memory_description": "Integrates memory, planning, and reflection mechanisms where agents record experiences and retrieve relevant memories to influence behavior and dialogue; described qualitatively in the review.",
            "task_name": "Interactive behavior simulation / multi-agent social simulation",
            "task_description": "Create virtual characters that interact over time; agents must recall past events, plan actions, and reflect to produce believable sequences of behavior.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "No quantitative ablation provided here; memory and reflection are presented as key components enabling believable, temporally consistent agent behavior.",
            "limitations_or_challenges": "Scalability of memory, retrieval relevance, potential inconsistencies between episodic memories and semantic beliefs, and lack of formal grounding are noted as ongoing challenges.",
            "key_insights": "Combining episodic memory with planning and reflection improves temporal coherence and believability, but robust memory organization and longevity management remain open problems.",
            "uuid": "e4665.5"
        },
        {
            "name_short": "Teenage-AGI",
            "name_full": "Teenage-AGI",
            "brief_description": "An implementation where each LLM 'thought' and perceived memory is stored in a Pinecone vector database and retrieved to augment the LLM context for subsequent reasoning.",
            "citation_title": "Teenage-AGI",
            "mention_or_use": "mention",
            "agent_name": "Teenage-AGI",
            "agent_description": "An LLM-based agent framework that records each generated thought/perception as an embedding in a vector DB and retrieves top-k related memories to prepend to prompts, improving contextual relevance.",
            "memory_type": "long-term (vector database / Pinecone); declarative & episodic",
            "memory_description": "Stores each thought and perceived memory as embeddings in Pinecone; on new thoughts/perceptions the DB is queried for top-k matches and those items are added to the prompt context (working memory).",
            "task_name": "General reasoning/creative generation via thought augmentation",
            "task_description": "Enhance LLM outputs by retrieving and attending to prior related experiences (thoughts/perceptions) stored as vector embeddings to inform current reasoning.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "No numerical comparison provided; described qualitatively that retrieval of related past experiences often improves output accuracy and meaningfulness (akin to few-shot prompting benefits).",
            "limitations_or_challenges": "Potential retrieval errors, mixing of memory types if not segregated, scaling of stored thoughts, and still susceptible to LLM hallucinations without higher-level logical control.",
            "key_insights": "Embedding and retrieving prior 'thoughts' can make outputs more accurate and relevant, but requires careful memory organization (type separation, metadata) and integration with higher-level reasoning to avoid inconsistencies.",
            "uuid": "e4665.6"
        },
        {
            "name_short": "Voyager",
            "name_full": "Voyager: An openended embodied agent with large language models",
            "brief_description": "An embodied lifelong learning agent operating in Minecraft that stores descriptions of learned skills in a vector database and uses a GPT model to plan and retrieve skills relevant to the current environment.",
            "citation_title": "Voyager: An openended embodied agent with large language models.",
            "mention_or_use": "mention",
            "agent_name": "Voyager",
            "agent_description": "An LLM-powered embodied agent in Minecraft which learns and refines skills (small programs interacting with the environment), stores skill descriptions in a vector DB, and uses LLM planning with retrieved skills to act and learn iteratively.",
            "memory_type": "procedural memory in a vector database (embedding descriptions of learned skills)",
            "memory_description": "Embeds descriptions of learned skills and environment/plans; retrieves closest skill embeddings from the vector DB, refines skills through prompting, and uses them in chain-of-thought planning for task execution.",
            "task_name": "Embodied lifelong learning / skill acquisition in Minecraft",
            "task_description": "Agent explores a Minecraft environment, synthesizes and refines small programs (skills), stores skill descriptions as embeddings, and retrieves and composes skills to accomplish open-ended tasks.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "No numeric ablation in this review; described qualitatively that storing procedural skill descriptions in a vector DB enables fast retrieval of relevant skills and iterative refinement that supports lifelong learning.",
            "limitations_or_challenges": "Challenges include hallucinations, lack of higher-level logical System 2, potential mixing of memory types in same store, and lifelong memory scaling/organization issues.",
            "key_insights": "Storing procedural skills as embeddings enables rapid retrieval and reuse in novel contexts, but effective lifelong skill management requires indexing, metadata, and separation from other memory types.",
            "uuid": "e4665.7"
        },
        {
            "name_short": "MRKL",
            "name_full": "MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning",
            "brief_description": "A neuro-symbolic modular architecture where an LLM acts as a central controller, routing queries to specialized expert modules (neural or symbolic) to leverage diverse reasoning capabilities.",
            "citation_title": "MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.",
            "mention_or_use": "mention",
            "agent_name": "MRKL",
            "agent_description": "A modular architecture where an LLM coordinates and delegates to expert modules (neural/symbolic) for reasoning, effectively combining retrieval and specialized computational modules under LLM control.",
            "memory_type": "external knowledge modules and potentially external memory attachments (not specified as vector DB in this review)",
            "memory_description": "Described as combining LLMs with expert modules; the review suggests this architecture could attach LLM modules to cognitive-architecture long-term memory but does not specify an implemented vector-based memory.",
            "task_name": "General modular reasoning and tool use",
            "task_description": "Use LLM as controller to route subproblems to expert modules appropriate for the subtask, integrating results to solve complex problems.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "No empirical memory comparisons in this review; MRKL is presented as a framework that could benefit from principled long-term memory attachments.",
            "limitations_or_challenges": "Unclear how to align LLM representations with cognitive-architecture assumptions on mental representations and grounding; memory-grounding to embodiment remains an open question.",
            "key_insights": "Modular architectures can combine LLM strengths with specialist modules, but integrating long-term memory that respects memory type distinctions and grounding is a research challenge.",
            "uuid": "e4665.8"
        },
        {
            "name_short": "dev-GPT2",
            "name_full": "dev-gpt (dev-GPT2 reference in review)",
            "brief_description": "A referenced simpler system that uses heuristic counting of failures to avoid infinite retry loops in subtask attempts.",
            "citation_title": " ",
            "mention_or_use": "mention",
            "agent_name": "dev-GPT / dev-GPT2 (referenced)",
            "agent_description": "A simple agent-level heuristic that counts failures per subtask strategy and switches to a new strategy after a threshold number of failures to avoid loops.",
            "memory_type": "short-term failure counters (simple heuristic); not full LTM",
            "memory_description": "Counts the number of failures per subtask strategy (a simple form of logged history) and triggers strategy changes after threshold (e.g., try a new strategy after 10 failures).",
            "task_name": "Subtask execution loop control / failure management",
            "task_description": "Manage retries on failing subtasks by tracking repeated failures per strategy and altering behavior to avoid infinite loops.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "No formal comparisons; provided as a simple mitigation for infinite subtask loops by using a form of logged failure memory instead of sophisticated LTM.",
            "limitations_or_challenges": "Heuristic thresholds are brittle; does not generalize to richer memory needs or semantic/procedural memory separation.",
            "key_insights": "Even simple recorded-memory heuristics (failure counts) can mitigate specific failure modes (infinite subtask loops), suggesting practical short-term measures while richer LTM systems are developed.",
            "uuid": "e4665.9"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Voyager: An openended embodied agent with large language models",
            "rating": 2,
            "sanitized_title": "voyager_an_openended_embodied_agent_with_large_language_models"
        },
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior",
            "rating": 2,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        },
        {
            "paper_title": "ChemCrow: Augmenting large-language models with chemistry tools",
            "rating": 2,
            "sanitized_title": "chemcrow_augmenting_largelanguage_models_with_chemistry_tools"
        },
        {
            "paper_title": "MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning",
            "rating": 2,
            "sanitized_title": "mrkl_systems_a_modular_neurosymbolic_architecture_that_combines_large_language_models_external_knowledge_sources_and_discrete_reasoning"
        },
        {
            "paper_title": "Auto-GPT: An Autonomous GPT-4 Experiment.",
            "rating": 1,
            "sanitized_title": "autogpt_an_autonomous_gpt4_experiment"
        },
        {
            "paper_title": "Teenage-AGI",
            "rating": 1,
            "sanitized_title": "teenageagi"
        },
        {
            "paper_title": "GPT Engineer",
            "rating": 1,
            "sanitized_title": "gpt_engineer"
        }
    ],
    "cost": 0.01461125,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Memory Matters: The Need to Improve Long-Term Memory in LLM Agents</p>
<p>Kostas Hatalis kostas@gocharlie.ai 
GoCharlie.ai
18106AllentownPA</p>
<p>Despina Christou despina@gocharlie.ai 
GoCharlie.ai
18106AllentownPA</p>
<p>Joshua Myers jamyers@ara.com 
Applied Research Associates, Inc
27616RaleighNC</p>
<p>Steven Jones steven.jones@cic.iqmri.org 
Center for Integrated Cognition
48105Ann ArborMI</p>
<p>Keith Lambert 
Cocoa AI
60642ChicagoIL</p>
<p>Adam Amos-Binks aamosbinks@ara.com 
Applied Research Associates, Inc
27616RaleighNC</p>
<p>Zohreh Dannenhauer dannenhauerz@metsci.com 
Metron, Inc
20190RestonVA</p>
<p>Dustin Dannenhauer 
GoCharlie.ai
18106AllentownPA</p>
<p>Memory Matters: The Need to Improve Long-Term Memory in LLM Agents
F2C4E5F7A46C8E3B0CAFF3040B00CC3E
In this paper, we provide a review of the current efforts to develop LLM agents, which are autonomous agents that leverage large language models.We examine the memory management approaches used in these agents.One crucial aspect of these agents is their long-term memory, which is often implemented using vector databases.We describe how vector databases are utilized to store and retrieve information in LLM agents.Moreover we highlight open problems, such as the separation of different types of memories and the management of memory over the agent's lifetime.Lastly, we propose several topics for future research to address these challenges and further enhance the capabilities of LLM agents, including the use of metadata in procedural and semantic memory and the integration of external knowledge sources with vector databases.</p>
<p>Introduction</p>
<p>Over the last year, there has been considerable interest in autonomous agents capable of leveraging large language models (LLMs).LLMs are evolving at a rapid pace, each with their own trade-off between size, training cost, and latent representation thanks to the availability of large corpuses of text and the development of the attention mechanism.Their large knowledge bases and general reasoning are bootstrapping the deployment of specialized chat agents, coding assistants (e.g., copilot (GitHub 2023)), and technical questionanswering (e.g., AskYourPDF (AskYourPDF 2023)).We refer to any agent system that relies on an LLM, in capacities beyond human-machine interfaces (such as task decomposition, planning, or task execution), as an LLM agent.</p>
<p>Pairing LLMs with autonomy requires memory systems.These memory systems ensure that interactions are coherent, contextual, and efficient and that the system can learn and adapt over time.Efforts like Auto-GPT (Significant-Gravitas 2023) ask a human user to describe a goal in natural language and proceed to decompose the task into subtasks that are then executed via terminal commands and API calls.Information from earlier executions of subtasks is stored as memories to accomplish future subtasks.Short-term memory was implemented by prepending previous subtask prompts and results to subsequent subtask calls.Since LLMs have fixed-size context windows, complex tasks quickly generate more information than can fit within these limits.Long-term memory solutions currently implemented via vector databases have significant limitations.We review the current efforts to develop LLM agents, describe their use of vector databases for long-term memory, identify open problems in using vector databases as longterm memory, and propose topics for future work.</p>
<p>Recent LLM Agents</p>
<p>LLM agents are a recent but rapidly evolving trend.These agents independently perform tasks, create new ones, prioritize them, and adapt to changing requirements to achieve a specific objective.LLMs, such as GPT-4, serve as the core controller for these agents.Most LLM agents utilize a framework containing at least the following components, all implemented as LLM API calls with different prompts: planning, task execution, memory management, and tool use.</p>
<p>Planning decomposes complex high-level tasks into smaller, simpler sub-tasks recursively until sub-tasks are executable.Once the original high-level task is fully decomposed into executable sub-tasks, task execution proceeds sequentially.Each task attempt is checked for success and is re-tried until it succeeds, enabling limited adaptation capabilities.Memory management addresses short-term and long-term information storage outside of LLM's context window, allowing agents to retain context-specific knowledge and recall past experiences.API calls to external tools enable LLM agents to access real-time information, execute code, and leverage proprietary databases.</p>
<p>A formal example of such a framework is MRKL (Modular Reasoning, Knowledge, and Language) (Karpas et al. 2022), a neuro-symbolic architecture for autonomous agents that combines the power of LLMs with expert modules.The LLM acts as a central controller, routing inquiries to the most suitable expert module based on its understanding of the task and the capabilities of the modules.These modules can be neural or symbolic, providing the agent with diverse tools for handling different tasks.MRKL enables agents to leverage both neural and symbolic reasoning, allowing them to tackle complex problems effectively.</p>
<p>Several examples of autonomous agents with LLMs have garnered noteworthy attention.One of the most well-known examples is Auto-GPT (Significant-Gravitas 2023).Auto-GPT leverages GPT-4 as its controller and operates with minimal user input.It employs a self-assigned goal-oriented approach to break down objectives into sub-tasks and uses various tools to achieve them.Noteworthy capabilities include writing, debugging, testing, and editing code.However, challenges persist, such as confabulatory tendencies and difficulty in task focus and contextual understanding.</p>
<p>Other examples are BabyAGI (Nakajima 2023) and SmartGPT (Corman 2023), which demonstrate AI-powered task management systems.BabyAGI utilizes LLMs like OpenAI and vector databases like Chroma or Weaviate to generate, prioritize, and execute tasks.By leveraging LLMs' natural language processing capabilities, BabyAGI creates new tasks based on an objective and the results of previous tasks, enabling it to adapt and evolve based on changing requirements.SmartGPT, on the other hand, focuses on enabling LLMs to complete complex tasks without user input.It achieves this by breaking tasks into minor problems, collecting information from external sources, and leveraging the internet.</p>
<p>GPT-Engineer (Osika 2023) is an open-platform project that aims to make it easy for developers to build and extend their own autonomous agents.By generating an entire codebase based on a user-defined prompt, GPT-Engineer enables developers to customize the behavior of their agents according to their specific needs.This project highlights the potential of LLMs in code generation and the creation of personalized code-generation toolboxes.</p>
<p>The agents mentioned above are considered generalist agents to be used to solve open ended problems.ChemCrow (Bran et al. 2023) is an example of a domain-specific LLM agent.It utilizes LLMs augmented with expert-designed tools to accomplish organic synthesis, drug discovery, and materials design tasks.By combining LLMs with specialized tools, ChemCrow demonstrates the potential of autonomous agents in specific domains and showcases how LLMs can be integrated with existing expert knowledge.</p>
<p>Generative Agents (Park et al. 2023) takes a unique approach by creating a sandbox environment where multiple virtual characters, controlled by LLM-powered agents, interact with each other.Inspired by The Sims, this experiment combines LLMs with memory, planning, and reflection mechanisms to simulate believable human behavior.Generative Agents highlights the potential of autonomous agents in interactive applications and the integration of LLMs in creating realistic virtual environments.</p>
<p>Long-Term Memory via Vector Databases</p>
<p>The common model of cognition (Laird, Lebiere, and Rosenbloom 2017) is both a theoretical description of the memory systems that underlie human cognition (Hake, Sibert, and Stocco 2022) and a description of real computational systems (cognitive architectures) used to implement intelligent agents.The common model distinguishes between long-term memory and working memory and is depicted in including the state of current reasoning and abstractions of the ongoing physical situation of the agent's embodiment.Long-term memory (LTM) systems alter an agent's behavior by changing the contents of working memory, which can lead to changes to the abstract representations that control embodiment.Long-term memory is subdivided into procedural, semantic, and episodic memory.These memory systems must operate incrementally and in real time, maintaining reactivity to environmental changes.</p>
<p>One approach to leveraging LLMs is to attach a queryable LLM module to a cognitive architecture.In this approach, the cognitive architecture's long-term memory systems can store knowledge learned from interpreting LLM responses (Kirk et al. 2022).However, this differs from LLM agents described above that put the LLM more in control.Another potential approach is to more directly attach LLMs to specific cognitive architecture long-term memory modules, but it is unclear how, given cognitive architecture assumptions on the forms of mental representations and grounding to an embodiment where LLMs alone do not provide a theory of mental representations or grounding.</p>
<p>We propose that LLM agents can potentially align with the functionality described in the common model of cognition, then review implementations of long-term memory for these agents.An LLM context window can abstractly function similarly to working memory.LLM agents can use a description of the current situation and retrieve contents of a long-term memory store to populate a prompt template.Then, a prompt template program and LLM collectively function similarly to procedural memory by creating prompts and responses to alter the contents of a context window over time.Storage of these contents over time (especially to timescales beyond what a context window can support) to an external database can provide episodic memory storage.Additionally, derived facts (either mined from episodic memory or reasoned) can be stored separately as semantic memory.We now describe how vector databases in implemented LLM agents support long-term memory capabilities, followed by risks and limitations.</p>
<p>Vector Databases</p>
<p>Vector embeddings have become a popular representation for memories because transformer neural network LLMs use vector embeddings natively.Input data as raw text is run through an encoder network that embeds the data in a fixeddimensional space.These embeddings represent data such that distance-based measures can be used to retrieve similar data.</p>
<p>A vector database is designed to support data storage and retrieval in an embedding representation rather than more structured, scalar data in traditional relational databases.Queries for vector databases rely on similarity matching to return the top-k matches, using algorithms such as cosine similarity, euclidean distance, or dot product.Metadata can be added as an additional filtering step 1 that offers conditional logic filters on top of similarity measure-based retrieval (e.g., the year metadata field must be greater than equal to '2020').One instance of a vector database being used to augment an LLM is Teenage-AGI (Pixel 2023).In this implementation, each "thought" and memory that the LLM outputs or perceives is stored in a respective Pinecone vector DB.Whenever a new thought or perception is processed, both databases are queried for the top-k matches, and these are added to the context for the LLM prompt (aka the LLM agent's working memory).This allows the LLM to attend to previous experiences related to the current thought or memory, which often improves the accuracy and meaningfulness of the output as seen in research on few-shot prompting.</p>
<p>Another instance of an LLM agent utilizing a vector database is Voyager, an "LLM-powered embodied lifelong learning agent" (Wang et al. 2023), which acts in Minecraft.Descriptions of skills (computer programs that interact with the Minecraft engine) that an agent has learned are retained in a vector database and a GPT model is used to generate plans.Plans and a description of the environment are embedded and the closest skills in the db are retrieved.The skills are refined through iterative prompting until they are correct, and plans are generated by chain-of-thought prompting (Zhang et al. 2022) with the agent's current state as context.</p>
<p>The two previous approaches to enhancing LLM agent performance with vectors databases add different types of memory to the agent.In the case of Teenage-AGI, the database contains declarative and episodic memories (embeddings of previous experiences and thoughts) while in the case of Voyager, the database contains procedural memories (embeddings of descriptions of skills).</p>
<p>In both cases, the database quickly retrieves relevant material to the current state and task even though what the information is used for is different (informing context vs deciding what skills to use).These approaches are similar to Kahneman's System 1 (Kahneman 2011) -the fast, associative, and intuitive part of human consciousness.However, without a proper analog to the logical and slower System 2, underlying issues with LLM agents such as hallucinations and irrational planning will continue to plague both the data 1 https://docs.pinecone.io/docs/metadata-filteringstored in long-term memory and the executive functioning and planning of the agent.</p>
<p>Fundamental Problems</p>
<p>Separation between types of memories: Poor retrieval may occur if all types of long-term memory (procedural, episodic, and semantic) are stored in the same vector database.For example, an agent could have the knowledge that the Earth is a globe stored in its semantic memory but have recently concluded a debate on the flatness of the Earth.The episodic memories of an argument that the Earth is flat are directly inconsistent with the agent's semantic memory.Therefore memories must be segregated based on type.</p>
<p>Infinite subtask loop: Current LLM agents can become stuck trying to revisit the same sub-task over and over.This usually happens when a subtask fails and the LLM suggests one or more alternative solutions that also fail.With each failure, the LLM keeps suggesting from a fixed set of solutions without trying something new.Episodic memory offers a way to detect if failures are reoccuring, since each failure is stored in the long-term memory.Simpler solutions, such as dev-GPT2 count the number of failures per subtask strategy and try a new strategy after 10 failures.</p>
<p>Lifelong Memory Management: LLM agents will accumulate many memories as they solve tasks over their lifetime.Vector databases offer performance features such as indexing, scaling, and metadata-filtered queries, but don't address issues such as how the agent's information flow is segmented or how memories are organized under metadata categories.Continuously stored memories will result in a more complete agent history at the cost of space and time for retrieval.Solutions to forgetting such as (MartÃ­nez-Plumed et al. 2015) may be required to maintain performance over many tasks.</p>
<p>Conclusions and Future Work</p>
<p>We review recent efforts to develop LLM agents: agents that use LLMs in capacities beyond human-machine interfaces such as problem solving.Agents rely on information over various time horizons to accomplish complex, multi-step tasks.We discuss how short-term memory and long-term memory are currently being used in LLM agents by referencing the common model of cognition (Laird, Lebiere, and Rosenbloom 2017), and elaborate on the risks with using vector-databases for long-term memory.</p>
<p>In future work, exploring the development of learning mechanisms for metadata in both procedural and semantic memory would be valuable.This would involve investigating how the agent can autonomously learn and update metadata attributes based on experiences and interactions with the environment.For procedural memory, the agent could learn metadata attributes such as the success rates, reliability scores, or preferences of different actions, allowing it to prioritize and adapt its decision-making process.Similarly, for semantic memory, the agent could learn metadata attributes that capture the occurrence frequencies, probabilistic information, or temporal context of concepts and relationships, enabling more efficient retrieval and utilization of memories.Generalizing these, future work could explore the capacity of LLM agents to use metamemory judgments to deliberately alter memory indexing.</p>
<p>It would also be beneficial to investigate the integration of metadata attributes with external knowledge sources, such as ontologies or knowledge graphs.An agent could leverage these sources' rich semantic relationships and structured information by linking the LTM with knowledge bases.This integration could enable more comprehensive and accurate metadata attributes, as well as facilitate the reasoning and inference capabilities of the LLM.For instance, an agent could use the metadata attributes to perform semantic searches or traverse the knowledge graph to retrieve related concepts and relationships.This would enhance an agent's ability to contextualize and interpret memories within a broader knowledge framework, leading to more robust decision-making and problem-solving capabilities.Recent approaches such as OntoGPT and graphGPT look to achieve semantic parsing and node generation through the use of LLMs to create the Knowledge base/ontology from which an episodic or declarative LTM grounding can take place.</p>
<p>Figure 1 .Figure 1 :
11
Figure1: The common model of cognition, altered to guish between episodic and semantic memory.(Jones and Laird 2023)</p>
<p>https://github.com/jina-ai/dev-gpt</p>
<p>. Askyourpdf, 2023</p>
<p>. Accessed, </p>
<p>A M Bran, S Cox, A D White, P Schwaller, arXiv:2304.05376ChemCrow: Augmenting large-language models with chemistry tools. 2023arXiv preprint</p>
<p>Corman, SmartGPT. 2023</p>
<p>Github, GitHub Copilot. 2023</p>
<p>Inferring a Cognitive Architecture from Multitask Neuroimaging Data: A Data-Driven Test of the Common Model of Cognition Using Granger Causality. H S Hake, C Sibert, A Stocco, Topics in Cognitive Science. 1442022</p>
<p>A cognitive architecture theory of anticipatory thinking. S J Jones, J E Laird, 2023AI Magazine</p>
<p>Thinking, Fast and Slow. D Kahneman, 2011</p>
<p>MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning. E Karpas, O Abend, Y Belinkov, B Lenz, O Lieber, N Ratner, Y Shoham, H Bata, Y Levine, K Leyton-Brown, arXiv:2205.004452022arXiv preprint</p>
<p>A standard model of the mind: Toward a common computational framework across artificial intelligence, cognitive science, neuroscience, and robotics. J R Kirk, R E Wray, P Lindes, J E Laird, J E Laird, C Lebiere, P S Rosenbloom, F MartÃ­nez-Plumed, C Ferri, J HernÃ¡ndez-Orallo, M J Ramirez-Quintana, arXiv:2208.09554Adaptive Behavior. Ai Magazine2022. 2017. 201538arXiv preprintKnowledge acquisition with forgetting: an incremental and developmental setting</p>
<p>. Y Nakajima, 2023</p>
<p>A Osika, GPT Engineer. 2023</p>
<p>J S Park, J C O'brien, C J Cai, M R Morris, P Liang, M S Bernstein, arXiv:2304.03442Generative agents: Interactive simulacra of human behavior. 2023arXiv preprint</p>
<p>S Pixel, Teenage-AGI. 2023</p>
<p>Significant-Gravitas, Auto-GPT: An Autonomous GPT-4 Experiment. 2023</p>
<p>Voyager: An openended embodied agent with large language models. G Wang, Y Xie, Y Jiang, A Mandlekar, C Xiao, Y Zhu, L Fan, A Anandkumar, arXiv:2305.162912023arXiv preprint</p>
<p>Automatic Chain of Thought Prompting in Large Language Models. Z Zhang, A Zhang, M Li, A Smola, The Eleventh International Conference on Learning Representations. 2022</p>            </div>
        </div>

    </div>
</body>
</html>