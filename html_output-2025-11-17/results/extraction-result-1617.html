<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1617 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1617</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1617</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-31.html">extraction-schema-31</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <p><strong>Paper ID:</strong> paper-259108745</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2306.04839v1.pdf" target="_blank">Solving Novel Program Synthesis Problems with Genetic Programming using Parametric Polymorphism</a></p>
                <p><strong>Paper Abstract:</strong> Contemporary genetic programming (GP) systems for general program synthesis have been primarily concerned with evolving programs that can manipulate values from a standard set of primitive data types and simple indexed data structures. In contrast, human programmers do not limit themselves to a small finite set of data types and use polymorphism to express an unbounded number of types including nested data structures, product types, and generic functions. Code-building Genetic Programming (CBGP) is a recently introduced method that compiles type-safe programs from linear genomes using stack-based compilation and a formal type system. Although prior work with CBGP has shown initial demonstrations of polymorphism inside evolved programs, we have provided a deeper exploration of these capabilities through the evolution of programs which make use of generic data types such as key-value maps, tuples, and sets, as well as higher order functions and functions with polymorphic type signatures. In our experiments, CBGP is able to solve problems with all of these properties, where every other GP system that we know of has restrictions that make it unable to even consider problems with these properties. This demonstration provides a significant step towards fully aligning the expressiveness of GP to real world programming.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1617.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1617.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CBGP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Code-building Genetic Programming</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A genetic programming system that evolves linear genomes which are compiled via a stack-based Hindley-Milner type-aware compiler into type-safe ASTs and then into native functions; supports parametric polymorphism, nested data structures, higher-order functions, and builds programs as native host-language functions for fast execution and evaluation on input/output examples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Code-building Genetic Programming (CBGP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CBGP represents programs as variable-length linear genomes composed of genes (literals, variables, function applications, abstractions, let-bindings). A stack-based compilation algorithm (using HM type unification) incrementally composes AST fragments from genes into type-safe ASTs; at the end of compilation an AST matching the problem output type is selected and compiled/evaluated as a native function in the host language (Clojure/Java bytecode). Evolution uses a generational GA with lexicase parent selection; variation is applied to genomes (the implementation used in the experiments applies uniform mutation-by-addition-and-deletion (UMAD) to create children). The function set is strongly polymorphic (HM-style), enabling a single polymorphic function to operate across many instantiated concrete types and allowing arbitrary nesting of type constructors.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs (linear genomes compiled to native functions/code)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Uniform Mutation by Addition and Deletion (UMAD) on linear genomes: variable-length genomes are mutated by uniformly choosing positions to delete genes and uniformly inserting genes sampled from the genetic source (constants, variables, functions, etc.). In the experiments reported in the paper, children were created by UMAD mutation (additions and deletions) rather than by explicit crossover.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>No explicit novelty-search metric. The paper uses counts of constructed data/function types as a proxy for exploration/novelty: (a) total number of unique types produced during evolution (counted every time a type appears in a program across all programs/generations and then aggregated per run), and (b) number of types that appear at least 1000 times in a run.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td>Reported qualitatively and with aggregated counts: the number of unique types produced per run (median across runs) is 'a few orders of magnitude higher' than other GP systems (which handle at most ~5–10 monomorphized types). For the frequently-occurring types (≥1000 appearances per run) the paper reports 'number over 100 for all but one problem'. The paper also reports the median frequency of how often a type occurred in a run was 2 for every problem.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Executability/correctness measured by I/O generalization: a candidate is compiled to a native function and then evaluated on 200 training cases; if it passes all training cases evolution halts and the candidate is tested on 2000 unseen test cases. A run is considered successful if a program passes both training and testsets. Programs are also required to be type-safe via HM-based compilation (static guarantee during compilation).</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Experimental success is reported per problem as 'number of runs out of 100' that find a program that passes training and generalizes on test cases. Example summary: CBGP 'was able to solve every problem except for one in at least 1 run out of 100.' Exact per-problem counts are in the paper's Table 4 (not fully enumerated in the text excerpt).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td>Genotypic/constructive diversity measured indirectly via 'number of distinct types constructed' (unique type signatures created during evolution) and frequency counts (types occurring ≥1000 times). Also qualitative mention of many rare types produced briefly.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td>Median unique-type counts per run (presented in Table 4) are orders of magnitude higher than previous GP systems; frequently-occurring types (≥1000 appearances) exceed 100 for most problems. No numerical diversity index (e.g., Shannon) is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>Not explicitly formalized. The paper notes that runs which find solutions quickly have less time to produce esoteric/rare constructed types (thus fewer unique types), suggesting an inverse relation between search duration (and thus opportunity to explore weird types) and early executable solutions, but no quantitative tradeoff curve is presented.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>General program synthesis (programming-by-example) with polymorphic typed benchmarks (17 custom problems requiring nested structures, HOFs, polymorphism, sets/maps/tuples/vectors).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>No controlled empirical baselines in experiments; discussion/qualitative comparison with PushGP, Grammatical Evolution / Grammar-Guided GP, Strongly-Typed GP variants (including PolyGP). CBGP is claimed able to handle exponentially more data types than those systems.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CBGP can evolve type-safe programs that use parametric polymorphism, nested data structures, and higher-order functions; compiling genomes to native functions yields efficient execution; using HM unification during compilation avoids combinatoric explosion of monomorphized functions/instructions (only one polymorphic function per logical operation). Mutational variation via UMAD produced solutions; CBGP generates a very large variety of constructed types during runs (many types produced thousands of times), indicating exploration of a large type space. Generalization of evolved programs on unseen data is stated to be higher for CBGP than other GP systems (qualitative claim).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Solving Novel Program Synthesis Problems with Genetic Programming using Parametric Polymorphism', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1617.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1617.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>UMAD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Uniform Mutation by Addition and Deletion</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mutation operator for variable-length linear genomes that uniformly deletes genes and inserts randomly sampled genes (from the genetic source), used to produce children in linear-genome GP systems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Program Synthesis Using Uniform Mutation by Addition and Deletion</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Uniform Mutation by Addition and Deletion (UMAD)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>UMAD operates on linear genomes representing programs: with some probabilities genes are uniformly deleted and new genes are uniformly inserted at positions, sampling inserted genes from the genetic source distribution (available literals, variables, functions, etc.). Designed for variable-length linear genomes (e.g., Push-like genomes) to enable growth and shrinkage of programs without requiring tree-structure operators.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs (linear genomes encoding AST fragments/functions)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Uniform deletion of genes and uniform insertion of genes drawn from the genetic source; can change genome length arbitrarily and is applied per-child during generation. The paper used UMAD to create children in CBGP experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Variation operator used within program synthesis GP (CBGP experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Historically used in linear Push genomes; compared in literature to subtree mutation/crossover on trees, but not directly compared in this paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>UMAD is the variation operator used to produce children in the paper's CBGP experiments; it is applicable to variable-length linear genomes and enabled discovery of solutions without using explicit crossover in the reported runs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Solving Novel Program Synthesis Problems with Genetic Programming using Parametric Polymorphism', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1617.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1617.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PolyGP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PolyGP (polymorphic GP in Haskell)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A strongly-typed genetic programming system implemented in Haskell that uses HM-style unification to maintain type safety while evolving typed expression trees; reported to use subtree crossover and subtree mutation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PolyGP: A polymorphic genetic programming system in Haskell</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PolyGP</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PolyGP evolves typed expression trees and employs the Hindley-Milner unification algorithm to ensure type-safe construction of programs during genetic operations. The system supports polymorphism to some degree but (as described) lacks function abstraction (anonymous functions) and let-bindings and typically focuses on specific type constructors (e.g., lists).</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs (typed expression trees)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Subtree crossover on typed expression trees (paper references PolyGP as using subtree crossover to recombine typed subtrees while maintaining type safety via unification).</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Subtree mutation on typed expression trees (replace a typed subtree with another typed subtree built by type-aware generation/unification).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Strongly-typed GP for program synthesis (prior work referenced in related work).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Mentioned as a comparable STGP approach; contrasted with CBGP regarding lack of function abstraction and let-bindings and limited data-structure support.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>PolyGP demonstrates how HM unification can be used to guide typed tree construction and operators (subtree crossover/mutation), but lacks some expressive constructs (anonymous functions, let-bindings) and typically operates on more limited type constructors compared to CBGP.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Solving Novel Program Synthesis Problems with Genetic Programming using Parametric Polymorphism', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1617.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1617.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PushGP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Push-based Genetic Programming (PushGP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GP approach that evolves programs in the Push language (stack-based language with one stack per data type), where instructions operate on typed stacks; commonly used with linear genomes representing sequences of Push instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The Push3 execution stack and the evolution of control</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PushGP</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PushGP evolves sequences of Push instructions (linear genomes). Program execution uses a separate runtime stack for each data type; instructions pop inputs from and push outputs onto designated stacks. The number of stacks (and associated instructions) scales with the number of monomorphized types, so supporting polymorphism by monomorphization leads to a combinatoric explosion of instructions and stacks.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs (Push instruction sequences / linear genomes)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>General program synthesis / genetic programming (related work).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Discussed qualitatively as unable to scale to arbitrary polymorphism without curated, limited type/instruction sets; often requires external specification of a small curated set of types and instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Paper argues PushGP cannot practically support full parametric polymorphism or arbitrary nesting of type constructors because each monomorphized type requires separate stacks and instruction variants; thus PushGP implementations typically limit the number of types and instructions to remain tractable.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Solving Novel Program Synthesis Problems with Genetic Programming using Parametric Polymorphism', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1617.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1617.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GE/G3P</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Grammatical Evolution / Grammar-Guided Genetic Programming</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Grammar-based GP systems that map genotype codons to program ASTs using context-free grammars; to ensure type safety they typically monomorphize types via grammar rules, leading to combinatoric growth of grammar rules when handling polymorphism.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Grammatical evolution: Evolving programs for an arbitrary language</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Grammatical Evolution (GE) / Grammar-Guided Genetic Programming (G3P)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GE/G3P use context-free grammars to translate integer codons or genotype sequences into concrete ASTs by selecting production rules. Type-safety is enforced by having separate grammar productions for each concrete type (monomorphization). CFG-based grammars cannot encode HM-style polymorphic type checking because CFGs are context-free and cannot enforce call-site-dependent type constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs (codon sequences translated via grammars into ASTs)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Grammar-based program synthesis / GP (related work).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Discussed as monomorphizing type constructors by enumerating concrete grammar rules; limited by CFG inability to provide polymorphic type safety and by combinatoric explosion when attempting to cover many nested types.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper argues GE/G3P approaches cannot practically support parametric polymorphism across arbitrary nested type constructors because grammars must monomorphize types (producing many grammar rules) and cannot enforce type constraints that depend on call-site contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Solving Novel Program Synthesis Problems with Genetic Programming using Parametric Polymorphism', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1617.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1617.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Lexicase</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Lexicase Selection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A parent selection algorithm for evolutionary computation that selects individuals by filtering on randomly-ordered test-cases one-by-one, enabling selection of specialists that perform well on subsets of cases and supporting solving of 'uncompromising' problems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Solving Uncompromising Problems with Lexicase Selection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Lexicase selection</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Selection proceeds by shuffling the set of training cases and filtering the population to those individuals that are best (lowest error) on the first case, then among those the best on the next, and so on, until one parent remains (ties resolved uniformly). This preserves individuals that excel on particular subsets of cases, which can improve evolvability on heterogeneous problem sets.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>used as a selection mechanism for evolving programs (genomes)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Parent selection in program-synthesis GP (used in CBGP experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Lexicase selection is used in CBGP; paper references prior work showing lexicase's effectiveness on uncompromising problems.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Lexicase selection was used to choose parents in CBGP runs; it is part of the evolutionary configuration that enabled solving the polymorphic benchmarks reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Solving Novel Program Synthesis Problems with Genetic Programming using Parametric Polymorphism', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Functional Code Building Genetic Programming <em>(Rating: 2)</em></li>
                <li>Code Building Genetic Programming <em>(Rating: 2)</em></li>
                <li>Program Synthesis Using Uniform Mutation by Addition and Deletion <em>(Rating: 2)</em></li>
                <li>PolyGP: A polymorphic genetic programming system in Haskell <em>(Rating: 2)</em></li>
                <li>The Push3 execution stack and the evolution of control <em>(Rating: 2)</em></li>
                <li>Grammatical evolution: Evolving programs for an arbitrary language <em>(Rating: 2)</em></li>
                <li>Solving Uncompromising Problems with Lexicase Selection <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1617",
    "paper_id": "paper-259108745",
    "extraction_schema_id": "extraction-schema-31",
    "extracted_data": [
        {
            "name_short": "CBGP",
            "name_full": "Code-building Genetic Programming",
            "brief_description": "A genetic programming system that evolves linear genomes which are compiled via a stack-based Hindley-Milner type-aware compiler into type-safe ASTs and then into native functions; supports parametric polymorphism, nested data structures, higher-order functions, and builds programs as native host-language functions for fast execution and evaluation on input/output examples.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Code-building Genetic Programming (CBGP)",
            "system_description": "CBGP represents programs as variable-length linear genomes composed of genes (literals, variables, function applications, abstractions, let-bindings). A stack-based compilation algorithm (using HM type unification) incrementally composes AST fragments from genes into type-safe ASTs; at the end of compilation an AST matching the problem output type is selected and compiled/evaluated as a native function in the host language (Clojure/Java bytecode). Evolution uses a generational GA with lexicase parent selection; variation is applied to genomes (the implementation used in the experiments applies uniform mutation-by-addition-and-deletion (UMAD) to create children). The function set is strongly polymorphic (HM-style), enabling a single polymorphic function to operate across many instantiated concrete types and allowing arbitrary nesting of type constructors.",
            "input_type": "programs (linear genomes compiled to native functions/code)",
            "crossover_operation": null,
            "mutation_operation": "Uniform Mutation by Addition and Deletion (UMAD) on linear genomes: variable-length genomes are mutated by uniformly choosing positions to delete genes and uniformly inserting genes sampled from the genetic source (constants, variables, functions, etc.). In the experiments reported in the paper, children were created by UMAD mutation (additions and deletions) rather than by explicit crossover.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": "No explicit novelty-search metric. The paper uses counts of constructed data/function types as a proxy for exploration/novelty: (a) total number of unique types produced during evolution (counted every time a type appears in a program across all programs/generations and then aggregated per run), and (b) number of types that appear at least 1000 times in a run.",
            "novelty_results": "Reported qualitatively and with aggregated counts: the number of unique types produced per run (median across runs) is 'a few orders of magnitude higher' than other GP systems (which handle at most ~5–10 monomorphized types). For the frequently-occurring types (≥1000 appearances per run) the paper reports 'number over 100 for all but one problem'. The paper also reports the median frequency of how often a type occurred in a run was 2 for every problem.",
            "executability_metric": "Executability/correctness measured by I/O generalization: a candidate is compiled to a native function and then evaluated on 200 training cases; if it passes all training cases evolution halts and the candidate is tested on 2000 unseen test cases. A run is considered successful if a program passes both training and testsets. Programs are also required to be type-safe via HM-based compilation (static guarantee during compilation).",
            "executability_results": "Experimental success is reported per problem as 'number of runs out of 100' that find a program that passes training and generalizes on test cases. Example summary: CBGP 'was able to solve every problem except for one in at least 1 run out of 100.' Exact per-problem counts are in the paper's Table 4 (not fully enumerated in the text excerpt).",
            "diversity_metric": "Genotypic/constructive diversity measured indirectly via 'number of distinct types constructed' (unique type signatures created during evolution) and frequency counts (types occurring ≥1000 times). Also qualitative mention of many rare types produced briefly.",
            "diversity_results": "Median unique-type counts per run (presented in Table 4) are orders of magnitude higher than previous GP systems; frequently-occurring types (≥1000 appearances) exceed 100 for most problems. No numerical diversity index (e.g., Shannon) is reported.",
            "novelty_executability_tradeoff": "Not explicitly formalized. The paper notes that runs which find solutions quickly have less time to produce esoteric/rare constructed types (thus fewer unique types), suggesting an inverse relation between search duration (and thus opportunity to explore weird types) and early executable solutions, but no quantitative tradeoff curve is presented.",
            "frontier_characterization": null,
            "benchmark_or_domain": "General program synthesis (programming-by-example) with polymorphic typed benchmarks (17 custom problems requiring nested structures, HOFs, polymorphism, sets/maps/tuples/vectors).",
            "comparison_baseline": "No controlled empirical baselines in experiments; discussion/qualitative comparison with PushGP, Grammatical Evolution / Grammar-Guided GP, Strongly-Typed GP variants (including PolyGP). CBGP is claimed able to handle exponentially more data types than those systems.",
            "key_findings": "CBGP can evolve type-safe programs that use parametric polymorphism, nested data structures, and higher-order functions; compiling genomes to native functions yields efficient execution; using HM unification during compilation avoids combinatoric explosion of monomorphized functions/instructions (only one polymorphic function per logical operation). Mutational variation via UMAD produced solutions; CBGP generates a very large variety of constructed types during runs (many types produced thousands of times), indicating exploration of a large type space. Generalization of evolved programs on unseen data is stated to be higher for CBGP than other GP systems (qualitative claim).",
            "uuid": "e1617.0",
            "source_info": {
                "paper_title": "Solving Novel Program Synthesis Problems with Genetic Programming using Parametric Polymorphism",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "UMAD",
            "name_full": "Uniform Mutation by Addition and Deletion",
            "brief_description": "A mutation operator for variable-length linear genomes that uniformly deletes genes and inserts randomly sampled genes (from the genetic source), used to produce children in linear-genome GP systems.",
            "citation_title": "Program Synthesis Using Uniform Mutation by Addition and Deletion",
            "mention_or_use": "use",
            "system_name": "Uniform Mutation by Addition and Deletion (UMAD)",
            "system_description": "UMAD operates on linear genomes representing programs: with some probabilities genes are uniformly deleted and new genes are uniformly inserted at positions, sampling inserted genes from the genetic source distribution (available literals, variables, functions, etc.). Designed for variable-length linear genomes (e.g., Push-like genomes) to enable growth and shrinkage of programs without requiring tree-structure operators.",
            "input_type": "programs (linear genomes encoding AST fragments/functions)",
            "crossover_operation": null,
            "mutation_operation": "Uniform deletion of genes and uniform insertion of genes drawn from the genetic source; can change genome length arbitrarily and is applied per-child during generation. The paper used UMAD to create children in CBGP experiments.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Variation operator used within program synthesis GP (CBGP experiments).",
            "comparison_baseline": "Historically used in linear Push genomes; compared in literature to subtree mutation/crossover on trees, but not directly compared in this paper's experiments.",
            "key_findings": "UMAD is the variation operator used to produce children in the paper's CBGP experiments; it is applicable to variable-length linear genomes and enabled discovery of solutions without using explicit crossover in the reported runs.",
            "uuid": "e1617.1",
            "source_info": {
                "paper_title": "Solving Novel Program Synthesis Problems with Genetic Programming using Parametric Polymorphism",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "PolyGP",
            "name_full": "PolyGP (polymorphic GP in Haskell)",
            "brief_description": "A strongly-typed genetic programming system implemented in Haskell that uses HM-style unification to maintain type safety while evolving typed expression trees; reported to use subtree crossover and subtree mutation.",
            "citation_title": "PolyGP: A polymorphic genetic programming system in Haskell",
            "mention_or_use": "mention",
            "system_name": "PolyGP",
            "system_description": "PolyGP evolves typed expression trees and employs the Hindley-Milner unification algorithm to ensure type-safe construction of programs during genetic operations. The system supports polymorphism to some degree but (as described) lacks function abstraction (anonymous functions) and let-bindings and typically focuses on specific type constructors (e.g., lists).",
            "input_type": "programs (typed expression trees)",
            "crossover_operation": "Subtree crossover on typed expression trees (paper references PolyGP as using subtree crossover to recombine typed subtrees while maintaining type safety via unification).",
            "mutation_operation": "Subtree mutation on typed expression trees (replace a typed subtree with another typed subtree built by type-aware generation/unification).",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Strongly-typed GP for program synthesis (prior work referenced in related work).",
            "comparison_baseline": "Mentioned as a comparable STGP approach; contrasted with CBGP regarding lack of function abstraction and let-bindings and limited data-structure support.",
            "key_findings": "PolyGP demonstrates how HM unification can be used to guide typed tree construction and operators (subtree crossover/mutation), but lacks some expressive constructs (anonymous functions, let-bindings) and typically operates on more limited type constructors compared to CBGP.",
            "uuid": "e1617.2",
            "source_info": {
                "paper_title": "Solving Novel Program Synthesis Problems with Genetic Programming using Parametric Polymorphism",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "PushGP",
            "name_full": "Push-based Genetic Programming (PushGP)",
            "brief_description": "A GP approach that evolves programs in the Push language (stack-based language with one stack per data type), where instructions operate on typed stacks; commonly used with linear genomes representing sequences of Push instructions.",
            "citation_title": "The Push3 execution stack and the evolution of control",
            "mention_or_use": "mention",
            "system_name": "PushGP",
            "system_description": "PushGP evolves sequences of Push instructions (linear genomes). Program execution uses a separate runtime stack for each data type; instructions pop inputs from and push outputs onto designated stacks. The number of stacks (and associated instructions) scales with the number of monomorphized types, so supporting polymorphism by monomorphization leads to a combinatoric explosion of instructions and stacks.",
            "input_type": "programs (Push instruction sequences / linear genomes)",
            "crossover_operation": null,
            "mutation_operation": null,
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "General program synthesis / genetic programming (related work).",
            "comparison_baseline": "Discussed qualitatively as unable to scale to arbitrary polymorphism without curated, limited type/instruction sets; often requires external specification of a small curated set of types and instructions.",
            "key_findings": "Paper argues PushGP cannot practically support full parametric polymorphism or arbitrary nesting of type constructors because each monomorphized type requires separate stacks and instruction variants; thus PushGP implementations typically limit the number of types and instructions to remain tractable.",
            "uuid": "e1617.3",
            "source_info": {
                "paper_title": "Solving Novel Program Synthesis Problems with Genetic Programming using Parametric Polymorphism",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "GE/G3P",
            "name_full": "Grammatical Evolution / Grammar-Guided Genetic Programming",
            "brief_description": "Grammar-based GP systems that map genotype codons to program ASTs using context-free grammars; to ensure type safety they typically monomorphize types via grammar rules, leading to combinatoric growth of grammar rules when handling polymorphism.",
            "citation_title": "Grammatical evolution: Evolving programs for an arbitrary language",
            "mention_or_use": "mention",
            "system_name": "Grammatical Evolution (GE) / Grammar-Guided Genetic Programming (G3P)",
            "system_description": "GE/G3P use context-free grammars to translate integer codons or genotype sequences into concrete ASTs by selecting production rules. Type-safety is enforced by having separate grammar productions for each concrete type (monomorphization). CFG-based grammars cannot encode HM-style polymorphic type checking because CFGs are context-free and cannot enforce call-site-dependent type constraints.",
            "input_type": "programs (codon sequences translated via grammars into ASTs)",
            "crossover_operation": null,
            "mutation_operation": null,
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Grammar-based program synthesis / GP (related work).",
            "comparison_baseline": "Discussed as monomorphizing type constructors by enumerating concrete grammar rules; limited by CFG inability to provide polymorphic type safety and by combinatoric explosion when attempting to cover many nested types.",
            "key_findings": "The paper argues GE/G3P approaches cannot practically support parametric polymorphism across arbitrary nested type constructors because grammars must monomorphize types (producing many grammar rules) and cannot enforce type constraints that depend on call-site contexts.",
            "uuid": "e1617.4",
            "source_info": {
                "paper_title": "Solving Novel Program Synthesis Problems with Genetic Programming using Parametric Polymorphism",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Lexicase",
            "name_full": "Lexicase Selection",
            "brief_description": "A parent selection algorithm for evolutionary computation that selects individuals by filtering on randomly-ordered test-cases one-by-one, enabling selection of specialists that perform well on subsets of cases and supporting solving of 'uncompromising' problems.",
            "citation_title": "Solving Uncompromising Problems with Lexicase Selection",
            "mention_or_use": "use",
            "system_name": "Lexicase selection",
            "system_description": "Selection proceeds by shuffling the set of training cases and filtering the population to those individuals that are best (lowest error) on the first case, then among those the best on the next, and so on, until one parent remains (ties resolved uniformly). This preserves individuals that excel on particular subsets of cases, which can improve evolvability on heterogeneous problem sets.",
            "input_type": "used as a selection mechanism for evolving programs (genomes)",
            "crossover_operation": null,
            "mutation_operation": null,
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Parent selection in program-synthesis GP (used in CBGP experiments).",
            "comparison_baseline": "Lexicase selection is used in CBGP; paper references prior work showing lexicase's effectiveness on uncompromising problems.",
            "key_findings": "Lexicase selection was used to choose parents in CBGP runs; it is part of the evolutionary configuration that enabled solving the polymorphic benchmarks reported.",
            "uuid": "e1617.5",
            "source_info": {
                "paper_title": "Solving Novel Program Synthesis Problems with Genetic Programming using Parametric Polymorphism",
                "publication_date_yy_mm": "2023-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Functional Code Building Genetic Programming",
            "rating": 2,
            "sanitized_title": "functional_code_building_genetic_programming"
        },
        {
            "paper_title": "Code Building Genetic Programming",
            "rating": 2,
            "sanitized_title": "code_building_genetic_programming"
        },
        {
            "paper_title": "Program Synthesis Using Uniform Mutation by Addition and Deletion",
            "rating": 2,
            "sanitized_title": "program_synthesis_using_uniform_mutation_by_addition_and_deletion"
        },
        {
            "paper_title": "PolyGP: A polymorphic genetic programming system in Haskell",
            "rating": 2,
            "sanitized_title": "polygp_a_polymorphic_genetic_programming_system_in_haskell"
        },
        {
            "paper_title": "The Push3 execution stack and the evolution of control",
            "rating": 2,
            "sanitized_title": "the_push3_execution_stack_and_the_evolution_of_control"
        },
        {
            "paper_title": "Grammatical evolution: Evolving programs for an arbitrary language",
            "rating": 2,
            "sanitized_title": "grammatical_evolution_evolving_programs_for_an_arbitrary_language"
        },
        {
            "paper_title": "Solving Uncompromising Problems with Lexicase Selection",
            "rating": 2,
            "sanitized_title": "solving_uncompromising_problems_with_lexicase_selection"
        }
    ],
    "cost": 0.0149815,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Solving Novel Program Syn-thesis Problems with Genetic Programming using Parametric Polymorphism
2023. July 15-19, 2023. July 15-19, 2023</p>
<p>Edward Pantridge 
Thomas Helmuth 
Solving Novel Program Syn-thesis Problems with Genetic Programming using Parametric Polymorphism</p>
<p>Genetic and Evolutionary Computation Conference (GECCO '23)
Lisbon, Portugal GECCO '23; Lisbon, Portugal2023. July 15-19, 2023. July 15-19, 202310.1145/3583131.3590502. ACM, New York, NY, USA, 9 pages. https:// ACM ISBN 979-8-4007-0119-1/23/07. . . $15.00
Contemporary genetic programming (GP) systems for general program synthesis have been primarily concerned with evolving programs that can manipulate values from a standard set of primitive data types and simple indexed data structures. In contrast, human programmers do not limit themselves to a small finite set of data types and use polymorphism to express an unbounded number of types including nested data structures, product types, and generic functions. Code-building Genetic Programming (CBGP) is a recently introduced method that compiles type-safe programs from linear genomes using stack-based compilation and a formal type system. Although prior work with CBGP has shown initial demonstrations of polymorphism inside evolved programs, we have provided a deeper exploration of these capabilities through the evolution of programs which make use of generic data types such as key-value maps, tuples, and sets, as well as higher order functions and functions with polymorphic type signatures. In our experiments, CBGP is able to solve problems with all of these properties, where every other GP system that we know of has restrictions that make it unable to even consider problems with these properties. This demonstration provides a significant step towards fully aligning the expressiveness of GP to real world programming.CCS CONCEPTS• Software and its engineering → Genetic programming. KEYWORDS automatic programming, genetic programming, inductive program synthesis, polymorphism ACM Reference Format:</p>
<p>INTRODUCTION</p>
<p>Genetic programming has recently turned more of its focus on the task of general program synthesis [22]. Fitting within the programming by example framework [12], the goal of the task is to automatically produce a program specified by a set of training examples showing correct input/output behavior for the desired program. Programming by example systems are not given a natural language description of the program like with large language model synthesis systems [3,7,27], nor a sketch [5,28] or underlying grammar for the program [1,2] like in syntax-guided synthesis. This work only considers programming by example techniques that take specifications in the form of training cases.</p>
<p>Genetic programming systems which manipulate multiple data types and perform basic iteration and control flow have existed for decades [29]. These systems vary in exactly which types and operations are supported, but generally include the primitive data types , , , , and ℎ . GP systems also commonly support indexed data structures, such as lists or vectors, that contain these primitive types. Furthermore, GP systems for program synthesis must be able to produce some form of conditional control flow and iteration or recursion.</p>
<p>In contrast, human programmers use a vast set of computational paradigms and language features to create programs that solve "real world" problems. This includes writing programs that introduce new abstractions, create new data types through composition, and define new functions. Difficult problems are solved by the nontrivial composition of simple components, therefore a finite set of simple non-composable types and a fixed function set is insufficient in most problem domains.</p>
<p>With this in mind, it seems obvious that the expressive power of most contemporary GP systems is woefully weak compared to the aspirations of our field. This paper takes a step in the right direction by expanding the use of polymorphism in a GP to allow for arbitrary nesting of structures, generic transformation of data, and functions with polymorphic type signatures. In order to properly demonstrate the expanded landscape of problems GP can be applied to, we also present a suite of synthetic benchmarks which require the use of new data types and behaviors. To our knowledge, no existing GP system can even be applied to all of these problems, let alone solve them.</p>
<p>In the next section we describe Code-building GP (CBGP), the GP method that we enhanced for this work, which can solve most of our new benchmark problems. In the subsequent section we provide a precise definition of "polymorphism" for the purposes of this paper. We then summarise prior work if GP methods that handle polymorphism. The remaining sections describe our benchmark problems, experimental methods, and results respectively. Finally we conclude with a discussion of some insights from our experimental results and directions for future work.</p>
<p>CODE-BUILDING GENETIC PROGRAMMING</p>
<p>CBGP evolves general programs using linear genomes and a stackbased compilation process that compiles genomes into type-safe abstract syntax trees (ASTs). Although originally introduced in [24], the introduction of a formal type system in [23] allowed for a more rigorous definition of CBGP's capabilities, such as the use of polymorphic functions and control flow via higher order functions. Genomes in the CBGP system are variable length sequences of "genes" which are nodes found in program ASTs. These include literals, variables, function applications, function abstractions, and let local variable bindings. To compile the genome, each gene is processed in order. Genes which correspond to leaf nodes of an AST (such as literals and variables) are annotated with their type and pushed to a stack of ASTs. Genes which correspond to internal nodes of an AST (such as function applications, abstraction, and let bindings) will search the AST stack for ASTs with compatible types to create a new composite AST. For example, the function application gene will first cause compilation to search the stack for an AST with a function type and then, depending on the arity of the function and its argument types, compilation will search the stack for additional ASTs to use as inputs to the function. If found, all used ASTs will be removed from the stack and a new composite AST which calls the function on the arguments will be pushed. This stack-based approach allows for genes with unsatisfied constraints to NOOP gracefully. After the entire genome has been compiled, an AST for the problem's output type is selected from the ASTs on the stack and returned as the genomes corresponding program. The compilation process also includes a mechanism for dynamically resolving local variable references depending on which variables are in scope at different locations of the program.</p>
<p>Evolution is driven by a standard generational genetic algorithm starting from a population of randomly generated genome sequences, where genes are sampled from a weighted genetic source (the set of literals, variables, and other genes that can appear in CBGP genomes) [16]. Each generation, genomes are compiled into ASTs which are loaded into the host language's runtime as native functions. These functions are evaluated on a dataset of training cases from which a vector of error values is produced to inform parent selection. Variation of parent genomes (via mutation and/or crossover) is performed to create the next generation.</p>
<p>CBGP has demonstrated trade-offs compared to other contemporary GP methods. The generalization of evolved programs on unseen data is higher for CBGP than other GP systems, however it fails to solve problems which require non-trivial control flow [23]. Additionally, the creation and execution of native functions dramatically reduces the execution costs compared to GP systems that incur the overhead of a custom program execution model. This paper presents results using a functional CBGP system identical to that of [23] 1 . We configure the system with an enhanced set of functions which operate on a larger, more generic, set of data 1 The implementation CBGP system can be found here: https://github.com/erp12/cbgp-lite/releases/tag/ GECCO-2023. types, and apply the system to novel benchmark problems that we believe would be unapproachable using other contemporary GP systems.</p>
<p>PARAMETRIC POLYMORPHISM</p>
<p>When multiple data types share a common interface, we call that interface polymorphic; when an interface only supports a single type, it is monomorphic. Polymorphism has been a core feature of most popular programming languages since the popularization of Algol68 and ML in 1970s [11,20]. There are many forms of polymorphism, including ad-hoc polymorphism, parametric polymorphism, subtyping, and row polymorphism [6]. The remainder of this paper will use "polymorphism" to refer specifically to parametric polymorphism unless otherwise specified.</p>
<p>Parametric polymorphism refers to the use of generic data types which can produce or consume values of any type. The definition of a polymorphic type includes one or more "type variables" which get bound to a concrete type at the call site where the polymorphic type is used.</p>
<p>The most common example of parametric polymorphism is a collection (aka data structure). The job of a collection is to hold some number of items and provide an interface for accessing them. This typically does not require knowledge of the items' data type(s) which allows us to implement the collection's behavior generically such that each instance of the collection can use an arbitrary item type. In this paper, we only consider "typed" collections where all items must belong to the same type, but we acknowledge that some type systems support forms of polymorphism that allow for heterogeneous collections.</p>
<p>The Hindley-Milner (HM) type system is one of the earliest examples of a type system which supports parametric polymorphism and provides type checking and type inference capabilities [19]. An implementation of the HM type system, such as Algorithm W, can analyze the abstract syntax tree (AST) of a purely functional program and determine the most general type of the values produced by every expression [21]. If no such type can be found, the program is proved to be not type safe. This analysis does not require executing the program.</p>
<p>Type Constructors</p>
<p>One place where polymorphism arises in Hindley-Milner based systems is via type constructors. This is a common way of implementing interfaces for generic data structures and composite types. A type constructor defines a way of building types from other types. For example, the type constructor must be given the data type of a list's elements to produce a concrete list type such as
[ ] or [ ].
The resulting types are considered concrete and can be given to other type constructors. For example, a matrix type could be modeled as
[ [ ]]
. Type constructors can be defined to require multiple types. Examples include key-value structures like [<em>, </em>] or product types such as a 2-element [<em>, </em>]. Perhaps the most important type constructor in the HM system (and all lambda calculus based systems) is the function type constructor. A function type is defined by one or more argument types and a return type, denoted as ( 1 , ..., ) → for a function of arity .</p>
<p>The CBGP system used for the experiments presented in this paper is supported by a HM type system which includes the following type constructors.</p>
<p>•
[<em>] • [</em>] • [<em>, </em>] • [<em>, </em>] • Unary Function: (<em>) → _ • Binary Function: (</em>, <em>) → _ • Trinary Functions: (</em>, <em>, </em>) → _
Each of these type constructors has a corresponding a set of polymorphic functions which define the interface of the type. 2 We also include functions for converting between different collection types where appropriate. For example, a map-to-vector function would accept a value of type</p>
<p>[ , ] and return a value of type [</p>
<p>[ , ]] and vice versa for the vector-to-map function.</p>
<p>It is common for human programmers to define new type constructors as part of their application, but programs of this kind are outside of the scope of this work.</p>
<p>Type Schemes</p>
<p>Some types produced by type constructors are naturally expressed as abstract types which contain a type variable. These variables indicate locations within the type's structure where any type can be substituted. Typically these variables appear in function types to indicate the function can manipulate values of any type. In the HM type system these abstract types are referred to as "type schemes. "</p>
<p>The canonical type scheme is the type of the identity function. It accepts a single argument of an arbitrary type and returns the same value (of the same type). We denote the identity function's type as:</p>
<p>identity : ∀ . → which can be read as: "For all possible types , a function which takes an instance of and returns an instance of . "</p>
<p>To demonstrate a more complex type scheme, consider the type of the get function which accesses the value in a under a specific key.</p>
<p>get : ∀ , .(</p>
<p>[ , ], ) → Notice that this scheme has 2 type variables that each occur in 2 locations within the type. When the get function is passed some arguments, all instances of each type variable must be bound to the same type for the composite AST to be type-safe.</p>
<p>Functional Programming Constructs</p>
<p>Although they are not forms of polymorphism, HM based systems often make heavy use of functional programming constructs such as higher order functions, function composition, and partial function applications.</p>
<dl>
<dt>Higher order functions (HOF) are functions which take other functions as arguments or return function objects. Commonly used HOF include the collection processing functions map, filter, reduce, and fold. In addition to being higher order, these functions are polymorphic:</dt>
<dd>∀ , .(( → ), [ ]) → [ ] : ∀ .(( → ), [ ]) → [ ] : ∀ .((( , ) → ), [ ]) → : ∀ , .((( , ) → ), ,[ ])
→ Some GP systems, including CBGP, have demonstrated the capability of calling HOF inside evolved programs [10,23]. This paper extends this capability by providing versions of each HOF for all the collection type constructors mentioned in 3.1 ( , , and ). In addition we present the novel capability of being able to evolve programs which themselves are higher order functions.</dd>
<dt>Function composition is the process of creating a new function by chaining multiple other functions. We denote function composition using the • operator. In the following example, h is defined as the composition of f and g. We also show the type of h assuming given types for f and g.</dt>
<dt>ℎ = • = . ( ( )) : → : → [ ] ℎ : → [ ]</dt>
<dt>The composition operator is considered a polymorphic function with the following type:</dt>
<dt>∀ , , .( → , → ) → ( → )</dt>
<dt>Partial function application is the process of creating a new function by binding some, but not all, of a function's arguments to fixed values. The result is a new function that only requires inputs for the unbound arguments and will return the result of the original function when called. Below we give the type of the partial application function, P, capable of binding 1 argument of a binary function, as well as an example usage on the binary function, f, and the literal value 10 to create a new function, g.</dt>
<dd>∀ , , .(( , ) → , ) → ( → ) : ( , ) → = ( , 10) : →
The results presented in this paper incorporate function composition and partial application operators to the function set used by evolution. This provides novel expressive power for creating new functions, including polymorphic functions, within the logic of evolved programs.</dd>
</dl>
<p>APPROACHES TO POLYMORPHISM IN GP</p>
<p>Many modern genetic programming systems are designed to solve general program synthesis problems in which the desired synthesized programs are expected to resemble those which humans write. This implies the use of many data types and language constructs, including various forms of polymorphism.</p>
<p>Most contemporary genetic programming systems do not explicitly support polymorphic types but instead utilize strategies for eliminating polymorphsim while still supporting a wide enough range of data types to be compatible with common benchmark problems.</p>
<p>Monomorphization</p>
<p>Monomorphization is the process of generating a finite set of monomorphic types derived from a single polymorphic type. For example the type constructor builds types in the form [ ] for some given element type , thus we can monomorphize using different element types, such as
[ ], [ ], and [ ].
For the remainder of this section, we will assume our system supports 5 ground types. These types are inherently monomorphic.
= { , , , ℎ , }
The number of additional types produced by monomorphizing a type constructor with input types and using | | ground types is | | . For example, monomorphizing produces 5 types and monomorphizing a unary function → produces 25 types. After monomorphizing all type constructors in section 3.1 with the ground types of there would be an additional 835 types (not including the 5 ground types). This does not cover any nesting of data structures, function types which operate on data structures, or higher order functions. For full coverage of these types, each type constructor would need to be monomorphized using the additional 835 types, resulting in excess of 400 billion types in total.</p>
<p>The following sections will detail how various contemporary GP systems utilize monomorphized types and in particular discuss how the combinatoric explosion limits the viability of the system as the number of complex types grows.</p>
<p>PushGP.</p>
<p>PushGP evolves programs in the Push language which represents programs as nested sequences of literals and instructions [29]. Program execution utilizes one stack per data type, and instructions take arguments from specific stacks and return values to specific stacks. The number of stacks grows according to the number of monomorphized types. Each stack requires a set of related instructions for manipulating its elements. Thus the combinatoric explosion of types results in an even more severe explosion in instructions, which would result in program search spaces that are too large to search efficiently.</p>
<p>To mitigate this issue, PushGP systems often require external specification of a smaller set of types and instructions which are curated for the specific problem domain. PushGP can solve problems with around 5 types and over 100 instructions [13,17]. However, we hypothesize its performance will suffer if required to handle even the 25 types required just to monomorphize with the 5 types in , let alone if it were asked to handle arbitrary single-layer nesting of the type constructors in Section 3.1. Producing polymorphic Push programs where the input values could be any type is impossible, as is allowing arbitrary nesting of type constructors.</p>
<p>Grammatical Evolution (GE) and Grammar Guided Genetic</p>
<p>Programming (G3P). GE uses context-free grammars in Backus-Naur form to translate sequences of codons (typically integers) into an abstract syntax trees (AST) by resolving each codon to a particular derivation rule of the grammar [26]. G3P similarly uses grammar rules to generate and evolve program trees [8,9]. In order to ensure type safety in the ASTs the grammar uses a separate derivation rule for expressions of each data type.</p>
<p>Up to this point, grammar-based approaches have monomorphized each type constructor to pair it with any necessary ground types, such as creating separate grammar rules for [ ], [ ], etc., depending on the problem [8,9]. By doing so, the type safety of the system is entirely determined by the grammar rules, instead of using a system designed for polymorphism such as the HM type system. Monomorphizing results in a combinatoric explosion of grammar rules and types, as discussed above, when used to monomorphize all possible types, especially nested data structures.</p>
<p>One might consider creating dedicated derivation rules for each polymorphic type; however, this presents some challenges. Suppose there were grammar rules for a polymorphic , such that it could hold elements of different types. Presumably, there would be rules to retrieve an element from an index of the vector. However, the grammar could not know what data type this element is, so it could not have rules that allow it to use such an element with other operators that require specific types, even as simple as allowing two elements to be added together. Context-free grammars (CFG) are unable to ensure type safety of polymorphic expressions because they require type information that is dependant on the context of the call site. This is why the principal use of CFG in practice is to verify program syntax, rather than with semantic verification such as type checking. Thus we see no possible approach to supporting polymorphic data types in grammar-based GP approaches.</p>
<p>Polymorphism in CBGP</p>
<p>Code-building GP is described in detail in [23] and summarized in section 2. The stack-based compilation process composes ASTs by leveraging the type unification algorithm from the HM type system. This means that CBGP has full support for all type constructors, including arbitrary amounts of nested structures. In addition, the function set does not experience a combinatoric explosion because there is only 1 (polymorphic) function per logical transformation over polymorphic types. For example, CBGP includes 1 function for reversing a vector rather than 1 reverse function per concrete vector type.</p>
<p>Strongly Typed Genetic Programming (STGP)</p>
<p>Multiple STGP systems that support at least a limited form of polymorphism have been proposed. Perhaps the most comparable to this work is PolyGP which evolves typed expression trees using subtree mutation and crossover [30]. PolyGP also used the unification algorithm of the HM type system to guide the construction of type-safe programs, however it does not support expressions for function abstraction (aka anonymous functions) or let bindings for creating reusable local variables. In contrast with CBGP, PolyGP uses recursion instead of HOF for traversal of lists. PolyGP, and other STGP systems, typically only included the type constructor. It has also been observed that many tree-based GP systems suffer from program bloat that can hinder search performance [25].</p>
<p>BENCHMARK PROBLEMS</p>
<p>Existing general program synthesis benchmark suites were designed to be used with systems that monomorphize a small number of type constructors, primarily vectors of the ground types in [13,14,17]. Inductive program synthesis systems outside of GP have almost exclusively been tested on benchmark problems that require a small set of data types from a domain-specific language that contains a limited set of functions [4].</p>
<p>Since we want to exhibit CBGP's ability to handle a large set of polymorphic types and other related capabilities, we decided to design our own suite of benchmark problems. These problems are designed to be non-trivial, in that they require more than a single function call, but are otherwise not intended to push the envelope of difficulty in general program synthesis. Instead, we designed a set of benchmarks that exhibit the following properties that no prior general program synthesis GP system has tackled concurrently:</p>
<p>• Problems that use type constructors for data types not previously used in GP, specifically , , and data structures.</p>
<p>• Problems that require nested data structures, such as
[ [ ]] and [ [ ]]
. • Problems whose solutions are higher-order functions that take a function as one of their arguments. • Problems whose solutions are themselves polymorphic functions that are required to run on arguments of different data types. For example, the min-key problem takes as its argument a map where the keys can be any single type, the values are integers, and the program must return the key with the minimum value. Thus the type of this problem is -: ∀ .</p>
<p>[ , ] → Table 1 lists the 17 problems we use in our experiments, along with the data structures they require and other properties. We have included at least 4 problems that exhibit each data structure and each property. Below we give English-language descriptions of each problem:</p>
<ol>
<li>
<p>area-of-rectangle -Given two tuples of floats representing the upper-right and lower-left Cartesian coordinates of a rectangle, find the area of the rectangle.</p>
</li>
<li>
<p>centimeters-to-meters: -Given a length in centimeters, return a tuple of (meters, centimeters) that corresponds to the same length.</p>
</li>
<li>
<p>count-true -Given a vector of any type and a predicate function of type ( ) → , return the count of the number of elements in the vector that make the predicate true.</p>
</li>
<li>
<p>filter-bounds -Given a set of elements that are all of the same comparable type , and two instances of type representing a lower and upper bound, filter the set to only include the elements that fall between two bounds (inclusively). This is the only problem not new in this work; it was previously studied in [24], which used vectors as the data structures instead of sets.  7. max-applied-fn -Given an integer 0 &lt; &lt; 50 and a function of type ( ) → , return the integer in the range [0, ) that results in the largest value when the function is applied to it.</p>
</li>
</ol>
<p>Problem Structures Nest HOF Poly</p>
<ol>
<li>min-key -Given a ∀ .</li>
</ol>
<p>[ , ] where the keys are of some type , return the key with the minimum value.</p>
<ol>
<li>set-cartesian-product -Given two sets of integers, return their Cartesian product, which will be a set of tuples
[ [ , ]].</li>
<li>
<p>set-symmetric-difference -Given two sets of integers, return their symmetric difference, which will be a set of integers.</p>
</li>
<li>
<p>sets-with-element -Given a set of sets of integers and a target integer, filter the set to only contain sets that contain the target.</p>
</li>
<li>
<p>simple-encryption -Given a string and a function of type ( ℎ ) → ℎ , apply the function to each character to encrypt the string.  14. sum-2-vals-polymorphic -Given a ∀ .</p>
</li>
</ol>
<p>[ , ] and two instances of that are keys of the map, look up the values associated with those keys in the map and return their sum. , where the strings represent names and the integers represent hours worked, and given a specific name, return the sum of the hours associated with that name.</p>
<p>sum-2D -Given 2-dimensional vector of integers</p>
<p>We define problem-specific lists of constants and ephemeral random constants that are used as genes in the CBGP genomes. Additionally, each problem automatically generates training and test data tailored to the problem. The error function, which determines how close a program's output is to the expected output, is based on the type of the output as follows:
• or -absolute difference. • -Levenshtein string edit distance. • [ ] -Jaccard distance of sets. •
[ , ] -absolute difference on each of the tuple components.</p>
<p>• of any type -This only occurs when the problem's output is polymorphic. Here, we simply give an error of 0 if the program's output is correct, and of 1 otherwise.</p>
<p>EXPERIMENTAL METHODS</p>
<p>We only conduct experiments using CBGP; we do not provide any comparison experiments with other systems, since, as discussed in Section 4, we know of no other modern GP system that can handle the polymorphic and data structure requirements for our benchmark problems. The CBGP hyperparameters for our experiments  Table 3: For polymorphic and each ground type in CBGP, we list the number of functions included when specifying to include functions of that type. We also give a few examples of each type of function.</p>
<p>are given in Table 2. Each parent is selected using lexicase selection [18]. Linear parent genomes are mutated to create children using uniform mutation with additions and deletions (UMAD), a technique first used on linear Push genomes but applicable to any variable length linear genome [15]. In our implementations of CBGP, the abstract syntax trees produced by genome compilation are evaluated into functions native to the host language Clojure. Being a Lisp dialect, Clojure was chosen because it is trivial to generate program code from data structures. Also Clojure runs on the Java Virtual Machine, which allows evolved programs to be pre-compiled to Java bytecode for superior efficiency compared to other GP program execution models. From anecdotal experience, running a single generation in CBGP takes about 10 seconds on a relatively modern laptop workstation, where generations of similar runs in other Clojure-based GP systems take many minutes.</p>
<p>We generate 200 random training cases for each run that are used to evaluate each program. If a program is found that passes all of the training cases, evolution is halted, and the program is tested on the 2000 unseen test cases. If it also passes those cases, the run is considered successful; if it fails one or more test cases, or if no program is found that passes all of the training cases within 300 generations, the run is considered failed.</p>
<p>In order to determine which functions are included in the genetic source for each problem, we adopt the approach taken by PushGP and G3P for general program synthesis. We construct the set of ground types that are relevant to each problem, and include any functions that make use of at least one of those data types. 3 Additionally, we always use all polymorphic functions and type constructors, so that data structures and anonymous functions can be built no matter what ground types are used. This ensures that CBGP programs could create any possible data structures built out of the ground types.</p>
<p>Note that 101 out of the total 166 functions in our CBGP implementation are polymorphic (in that at least one of their parameters can be any type or is a type constructor that contains any type), meaning only a small proportion of the functions are added  gives the median number of data types that were produced at least 1000 times per CBGP run.</p>
<p>by specifying one or more types. Table 3 gives the number of functions added by listing each type; note that the total sums to more than 166, because some functions are added by more than one type. Table 4 presents the primary results of our experiments with CBGP. For each problem, we report the number of runs out of 100 that find a program that passes all training cases and generalizes to the unseen test set. Additionally, we are interested in exploring the number of data types that are produced by some program during evolution. These include ground types, the types of the functions in our function set, and the types of all ASTs constructed during evolution. For each run, we count the number of unique types produced, and present the median across all runs of a problem. We ignore differences in the names of type variables when comparing the uniqueness of a type. Because many constructed types occur extremely rarely, 4 we are also curious as to the number of types that occur frequently throughout evolution. In order to tabulate frequently-appearing types, Table 4 also gives the number of types that appear at least 1000 times per run.</p>
<p>RESULTS</p>
<p>Note that type counts are incremented every time a type appears in a program, for every program in every generation. Thus runs that find solutions quickly will have less time to produce esoteric constructed types than runs that last a full 300 generations. We hypothesize that this explains the relatively small number of types (&gt; a-30621229 input2)) (vec input1))))) (defn max-applied-fn [input1 input2] (last (sort-by input2 (range input1))))
(defn first-index-of-true [input1 input2] (index-of (map input2 input1) true)) (defn time-sheet [input1 input2] (reduce + (map second (get (group-by first input1) input2)))) (defn sum-2D [input1]
(reduce + (mapcat reverse input1))) for the count-true problem, as well as other problems with high success rates. Figure 1 presents solution programs to some of the problems, chosen to exemplify some of the programming themes discussed in this work. The solution to filter-bounds creates two new functions, both in different ways. The first filter in the function uses partial to apply the first argument to &gt;, making a function that checks if its argument is less than input3. The second filter uses an anonymous function that checks whether its argument is greater than input2. This combination of filters produces the desired functionality.</p>
<p>Example Solution Programs</p>
<p>The problem max-applied-fn takes a function as its second parameter. To solve this problem, the evolved function correctly produces the range from 0 to input1, and then uses sort-by on input2 to arrange those integers based on their output when the function input2 is applied to them. This puts the correct output at the end of the resulting vector, so last returns it.</p>
<p>The solution to first-index-of-true converts the input vector into a vector of Booleans using map, and then is able to simply find the index of the first appearance of true.</p>
<p>The parameters to the time-sheet problem are of the types
[ [ , ]
] and , and the return type is . Note that problem's type signature does not indicate that a would be useful for solving this problem. Even so, the evolved solution uses the group-by function to create a map where the keys are strings from the tuples and the values are vectors of the tuples themselves. It can then retrieve the tuples corresponding to the correct name using get on this map, instead of a more conventional approach that would use filter to reduce the input1 vector to only include the tuples where the first element was the correct name. The rest of the function simply grabs the second element of each remaining tuple and then sums them.</p>
<p>Finally, the solution program to sum-2D must sum all of the integers in a
[ [ ]]
. A simple way to do so is to concatenate all of the internal vectors together and then use reduce to sum their contents, which this program does. However, the way in which it concatenates the internal vectors is interesting. The mapcat function applies a function (in this case reverse) to each element of vector (in this case the the elements are the rows of input1), and then concatenates the resulting vectors. In fact, here mapcat could be passed the identity function, but we did not include one in our function set, because we did not imagine a use case. Fortunately order does not matter when summing numbers and evolution was able to find reverse as a suitable alternative.</p>
<p>DISCUSSION</p>
<p>CBGP was able to solve every problem except for one in at least 1 run out of 100. These results show that CBGP is capable of handling problems with diverse sets of requirements regarding type constructors, nested data structures, higher-order functions, and polymorphism. Programs made use of the three data structures not used in previous program synthesis GP systems, , , and . The number of data types created during the CBGP runs is a few orders of magnitude higher than the number of data types handled by other program synthesis GP systems, which handle at most 5 to 10 monomorphized types. Even the number of data types that occur "frequently", of at least 1000 times per run, number over 100 for all but one problem. We expect that many of these represent common ground types and function types, as well as type constructors that are useful for the problem. Most of the more unusual types appear only a few times throughout evolution. Such types are likely composed of deeply nested function or data structure types, have little or no evolutionary advantage, and disappear from the population quickly.</p>
<p>CONCLUSIONS</p>
<p>In this paper we expand the kinds of problems that CBGP can tackle in terms of type constructors and polymorphic functions. We show that CBGP can solve problems exhibiting a variety of properties that no prior GP system has tackled all at once: parametric polymorphism, nested data structures, higher-order functions, and a large, general-purpose function set. Compared to other modern general program synthesis GP systems and other non-GP inductive program synthesis systems, CBGP can handle exponentially more data types and/or functions within one GP run while still maintaining its ability to find solutions.</p>
<p>Our results further show that CBGP does produce a large number of data types during its runs, including many that are produced thousands of times per run. These results show that CBGP is not simply ignoring the huge space of possible types, but builds parts of programs with many types throughout evolution. We do not have data on which types were used most often by solution programs or in their evolutionary lineages, so such a study will remain for future work.</p>
<p>Anecdotally, we have noted at least a few solution programs that make use of partial function application; we have not noted any use of function composition, though we have only examined a small number of the solutions. Future work should examine more closely how these and other methods of utilizing polymorphism contribute to evolving solution programs.</p>
<p>CBGP still relies on its stack-based compilation algorithm to produce programs from linear genomes. Many avenues are available for alternative compilation technique while staying within the Hindley-Milner type system. We think it would be worthwhile to explore how different compilation procedures could result in different sizes, shapes, and behaviors of programs.</p>
<p>CBGP currently has no way of indicating that a function could be applied to some data types; instead, it must be applied to one type specifically, or all of them (through parametric polymorphism). In contrast, ad-hoc polymorphism refers to the ability to define functions which can only be applied to a discrete set of types, but can arbitraily vary the behavior of the function for each type. For example, this work included separate int-add and float-add functions that operate on integers and floats respectively, where it could potentially be more evolvable to have a single add function that works on both data types (or even a combination of the two). Some functional programming languages, like Haskell, implement adhoc polymorphism using type classes that define shared properties that specific types can have, such as the ability to be compared or the ability to be treated like numbers. Other languages implement ad-hoc polymorphism in the form of function overloading.</p>
<p>The other common form of polymorphism, "subtype polymorphism", is also a natural fit for CBGP. By defining a hierarchy of types, we would gain the ability to define functions that apply generically to other generic types, such as a single size function which can accept instances of any collection type ( , , and ). Adding these additional forms of polymorphism to the type system supporting CBGP would dramatically generalize the function set and reduce its cardinality without sacrificing any expressiveness. In turn, the may allow evolution to make movements in the search space that would otherwise be impossible.</p>
<p>ACKNOWLEDGMENTS</p>
<p>We would like to thank Lee Spector, Ryan Boldi, and Nicholas Freitag McPhee for discussions that helped shape this work.</p>
<p>5 .
5first-index-of-true -Given a vector of type and a predicate function of type ( ) → , return the first index in the vector where the predicate is true.6. get-vals-of-key -Given a vector of maps[ [ , ]] and a key that exists in each map, return a vector of the values of that key from all of the maps.</p>
<p>[ [ ]], return the sum of all elements. 16. sum-vector-vals -Given a [ , ] and vector of strings that are keys of the map, look up the values associated with those keys in the map and return their sum. 17. time-sheet -Given a vector of tuples [ [ , ]]</p>
<p>Figure 1 :
1A sample of solution Clojure programs evolved by CBGP. Anonymous function argument symbols were generated using a unique natural number prefixed with an a-. Whitespace was adjusted for readability.</p>
<p>Table 2 :
2The evolutionary hyperparameters used for all CBGP runs in our experiments. of the map, look up the values associated with those keys in the map and return their sum.13. sum-2-vals -Given a 
[ 
, ] and two strings that 
are keys </p>
<p>Table 4 :
4Experimental results. Succ measures the number of 
runs out of 100 that successfully find a program that passes 
all given training and test cases. Types gives the median 
number of data types produced per CBGP run. Types ≥ 1000 </p>
<p>Technically, the keys of and must be comparable with equality, and thus this constraint is an example of ad-hoc polymorphism, not parametric polymorphism. In practice, we omit these constraints since our host language Clojure allows for equality on any two values.
Note PushGP has typically taken the opposite approach of only including functions where all related types are included in the set specified by the genetic user[16] 
In fact, the median frequency of how often a type occurred in a run was 2 for every problem.</p>
<p>Syntax-guided synthesis. Rajeev Alur, Rastislav Bodik, Garvit Juniwal, Milo M K Martin, Mukund Raghothaman, A Sanjit, Rishabh Seshia, Singh, 10.1109/FMCAD.2013.6679385Emina Torlak, and Abhishek Udupa. Armando Solar-LezamaRajeev Alur, Rastislav Bodik, Garvit Juniwal, Milo M. K. Martin, Mukund Raghothaman, Sanjit A. Seshia, Rishabh Singh, Armando Solar- Lezama, Emina Torlak, and Abhishek Udupa. 2013. Syntax-guided synthesis. In 2013 Formal Methods in Computer-Aided Design. 1-8. https://doi.org/10.1109/FMCAD.2013.6679385</p>
<p>Search-Based Program Synthesis. Rajeev Alur, Rishabh Singh, Dana Fisman, Armando Solar-Lezama, 10.1145/3208071Commun. ACM. 61Rajeev Alur, Rishabh Singh, Dana Fisman, and Armando Solar-Lezama. 2018. Search-Based Program Synthesis. Commun. ACM 61, 12 (nov 2018), 84-93. https://doi.org/10.1145/3208071</p>
<p>Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, Charles Sutton, arXiv:2108.07732Program Synthesis with Large Language Models. arXivJacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. 2021. Program Synthesis with Large Language Models. arXiv (Aug. 2021). http://arxiv.org/abs/2108.07732 arXiv: 2108.07732.</p>
<p>DeepCoder: Learning to Write Programs. Matej Balog, Alexander L Gaunt, Marc Brockschmidt, Sebastian Nowozin, Daniel Tarlow, arXiv:1611.01989Matej Balog, Alexander L. Gaunt, Marc Brockschmidt, Sebastian Nowozin, and Daniel Tarlow. 2016. DeepCoder: Learning to Write Programs. CoRR abs/1611.01989 (2016). arXiv:1611.01989 http://arxiv.org/abs/1611.01989</p>
<p>Evolutionary Program Sketching. Iwo Bladek, Krzysztof Krawiec, 10.1007/978-3-319-55696-3_1EuroGP 2017: Proceedings of the 20th European Conference on Genetic Programming. Mauro Castelli, James McDermott, and Lukas SekaninaAmsterdamSpringer Verlag10196Iwo Bladek and Krzysztof Krawiec. 2017. Evolutionary Program Sketch- ing. In EuroGP 2017: Proceedings of the 20th European Conference on Genetic Programming (LNCS, Vol. 10196), Mauro Castelli, James McDer- mott, and Lukas Sekanina (Eds.). Springer Verlag, Amsterdam, 3-18. https://doi.org/doi:10.1007/978-3-319-55696-3_1</p>
<p>On Understanding Types, Data Abstraction, and Polymorphism. Luca Cardelli, Peter Wegner, 10.1145/6041.6042ACM Comput. Surv. 174Luca Cardelli and Peter Wegner. 1985. On Understanding Types, Data Ab- straction, and Polymorphism. ACM Comput. Surv. 17, 4 (dec 1985), 471-523. https://doi.org/10.1145/6041.6042</p>
<p>. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared Kaplan, Harri Edwards, Yura Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Such, Josh Achiam. Peter Welinderand Wojciech Zaremba. 2021. Evaluating Large Language Models Trained on Code. arXivMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared Kaplan, Harri Edwards, Yura Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Fe- lipe Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, Will Guss, Alex Nichol, Igor Babuschkin, Suchir Balaji, Shan- tanu Jain, Andrew Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Pe- ter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021. Evaluating Large Language Models Trained on Code. arXiv (2021). http://arxiv.org/abs/2107.03374</p>
<p>A Grammar Design Pattern for Arbitrary Program Synthesis Problems in Genetic Programming. Stefan Forstenlechner, David Fagan, Miguel Nicolau, Michael O&apos; Neill, 10.1007/978-3-319-55696-3_17EuroGP 2017: Proceedings of the 20th European Conference on Genetic Programming. AmsterdamSpringer Verlag10196Stefan Forstenlechner, David Fagan, Miguel Nicolau, and Michael O'Neill. 2017. A Grammar Design Pattern for Arbitrary Program Synthesis Problems in Ge- netic Programming. In EuroGP 2017: Proceedings of the 20th European Conference on Genetic Programming (LNCS, Vol. 10196). Springer Verlag, Amsterdam, 262- 277. https://doi.org/10.1007/978-3-319-55696-3_17</p>
<p>Extending Program Synthesis Grammars for Grammar-Guided Genetic Programming. In Parallel Problem Solving from Nature -PPSN XV. Stefan Forstenlechner, David Fagan, Miguel Nicolau, Michael O&apos; Neill, Springer International PublishingChamStefan Forstenlechner, David Fagan, Miguel Nicolau, and Michael O'Neill. 2018. Extending Program Synthesis Grammars for Grammar-Guided Genetic Pro- gramming. In Parallel Problem Solving from Nature -PPSN XV. Springer Interna- tional Publishing, Cham, 197-208.</p>
<p>Why Functional Program Synthesis Matters (in the Realm of Genetic Programming). Fraser Garrow, Michael A Lones, Robert Stewart, 10.1145/3520304.3534045Proceedings of the Genetic and Evolutionary Computation Conference Companion. the Genetic and Evolutionary Computation Conference CompanionBoston, Massachusetts; New York, NY, USAAssociation for Computing MachineryGECCO '22)Fraser Garrow, Michael A. Lones, and Robert Stewart. 2022. Why Functional Program Synthesis Matters (in the Realm of Genetic Programming). In Proceed- ings of the Genetic and Evolutionary Computation Conference Companion (Boston, Massachusetts) (GECCO '22). Association for Computing Machinery, New York, NY, USA, 1844-1853. https://doi.org/10.1145/3520304.3534045</p>
<p>From LCF to HOL: A Short History. Mike Gordon, MIT PressCambridge, MA, USAMike Gordon. 2000. From LCF to HOL: A Short History. MIT Press, Cambridge, MA, USA, 169-185.</p>
<p>Automating String Processing in Spreadsheets using Input-Output Examples. Sumit Gulwani, PoPL'11. Austin, Texas, USA; austin, texas, usaSumit Gulwani. 2011. Automating String Processing in Spread- sheets using Input-Output Examples. In PoPL'11, January 26-28, 2011, Austin, Texas, USA (popl'11, january 26-28, 2011, austin, texas, usa ed.).</p>
<p>PSB2: The Second Program Synthesis Benchmark Suite. Thomas Helmuth, Peter Kelly, 10.1145/3449639.34592852021 Genetic and Evolutionary Computation Conference (GECCO '21). Lille, FranceACMThomas Helmuth and Peter Kelly. 2021. PSB2: The Second Program Synthe- sis Benchmark Suite. In 2021 Genetic and Evolutionary Computation Conference (GECCO '21). ACM, Lille, France. https://doi.org/10.1145/3449639.3459285</p>
<p>Applying Genetic Programming to PSB2: The Next Generation Program Synthesis Benchmark Suite. Genetic Programming and Evolvable Machines. Thomas Helmuth, Peter Kelly, 10.1007/s10710-022-09434-yThomas Helmuth and Peter Kelly. 2022. Applying Genetic Program- ming to PSB2: The Next Generation Program Synthesis Benchmark Suite. Genetic Programming and Evolvable Machines (June 2022), 375-404. https://doi.org/10.1007/s10710-022-09434-y</p>
<p>Program Synthesis Using Uniform Mutation by Addition and Deletion. Thomas Helmuth, Nicholas Freitag Mcphee, Lee Spector, GECCO '18Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceKyoto, JapanThomas Helmuth, Nicholas Freitag McPhee, and Lee Spector. 2018. Program Syn- thesis Using Uniform Mutation by Addition and Deletion. In Proceedings of the Genetic and Evolutionary Computation Conference (Kyoto, Japan) (GECCO '18).</p>
<p>. 10.1145/3205455.3205603ACMNew York, NY, USAACM, New York, NY, USA, 1127-1134. https://doi.org/10.1145/3205455.3205603</p>
<p>Genetic Source Sensitivity and Transfer Learning in Genetic Programming. Thomas Helmuth, Edward Pantridge, Grace Woolson, Lee Spector, 10.1162/isal_a_00326Artificial Life Conference Proceedings. MIT PressThomas Helmuth, Edward Pantridge, Grace Woolson, and Lee Spector. 2020. Genetic Source Sensitivity and Transfer Learning in Genetic Pro- gramming. In Artificial Life Conference Proceedings. MIT Press, 303-311. https://doi.org/10.1162/isal_a_00326</p>
<p>GECCO '15). Association for Computing Machinery. Thomas Helmuth, Lee Spector, 10.1145/2739480.2754769Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation. the 2015 Annual Conference on Genetic and Evolutionary ComputationMadrid, Spain; New York, NY, USAGeneral Program Synthesis Benchmark SuiteThomas Helmuth and Lee Spector. 2015. General Program Synthesis Benchmark Suite. In Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation (Madrid, Spain) (GECCO '15). Association for Computing Machin- ery, New York, NY, USA, 1039-1046. https://doi.org/10.1145/2739480.2754769</p>
<p>Solving Uncompromising Problems with Lexicase Selection. Thomas Helmuth, Lee Spector, James Matheson, 10.1109/TEVC.2014.2362729IEEE Transactions on Evolutionary Computation. 19Thomas Helmuth, Lee Spector, and James Matheson. 2015. Solv- ing Uncompromising Problems with Lexicase Selection. IEEE Trans- actions on Evolutionary Computation 19, 5 (Oct. 2015), 630-643. https://doi.org/doi:10.1109/TEVC.2014.2362729</p>
<p>The principal type-scheme of an object in combinatory logic. Roger Hindley, Transactions of the american mathematical society. 146Roger Hindley. 1969. The principal type-scheme of an object in combinatory logic. Transactions of the american mathematical society 146 (1969), 29-60.</p>
<p>Report on the Algorithmic Language ALGOL 68. B J Mailloux, J E Peck, C H Koster, 10.1007/BF02163002Numer. Math. 142B. J. Mailloux, J. E. Peck, and C. H. Koster. 1969. Report on the Al- gorithmic Language ALGOL 68. Numer. Math. 14, 2 (dec 1969), 79-218. https://doi.org/10.1007/BF02163002</p>
<p>A theory of type polymorphism in programming. Robin Milner, 10.1016/0022-0000(78)90014-4J. Comput. System Sci. 17Robin Milner. 1978. A theory of type polymorphism in programming. J. Comput. System Sci. 17, 3 (1978), 348-375. https://doi.org/10.1016/0022-0000(78)90014-4</p>
<p>Automatic programming: The open issue?. O&apos; Michael, Lee Neill, Spector, Genetic Programming and Evolvable Machines. Michael O'Neill and Lee Spector. 2019. Automatic programming: The open issue? Genetic Programming and Evolvable Machines (2019).</p>
<p>. 10.1007/s10710-019-09364-2https://doi.org/10.1007/s10710-019-09364-2</p>
<p>Functional Code Building Genetic Programming. Edward Pantridge, Thomas Helmuth, Lee Spector, 10.1145/3512290.3528866Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceBoston, Massachusetts; New York, NY, USAAssociation for Computing MachineryGECCO '22)Edward Pantridge, Thomas Helmuth, and Lee Spector. 2022. Functional Code Building Genetic Programming. In Proceedings of the Genetic and Evolutionary Computation Conference (Boston, Massachusetts) (GECCO '22). Association for Computing Machinery, New York, NY, USA, 1000-1008. https://doi.org/10.1145/3512290.3528866</p>
<p>Code Building Genetic Programming. Edward Pantridge, Lee Spector, 10.1145/3377930.3390239Proceedings of the 2020 Genetic and Evolutionary Computation Conference. the 2020 Genetic and Evolutionary Computation ConferenceCancún, Mexico; New York, NY, USAAssociation for Computing MachineryGECCO '20)Edward Pantridge and Lee Spector. 2020. Code Building Genetic Programming. In Proceedings of the 2020 Genetic and Evolutionary Computation Conference (Can- cún, Mexico) (GECCO '20). Association for Computing Machinery, New York, NY, USA, 994-1002. https://doi.org/10.1145/3377930.3390239</p>
<p>A field guide to genetic programming. Riccardo Poli, William B Langdon, Nicholas Freitag Mcphee, J. R. KozaRiccardo Poli, William B. Langdon, and Nicholas Freitag McPhee. 2008. A field guide to genetic programming. Published via http://lulu.com and freely avail- able at http://www.gp-field-guide.org.uk. (With contributions by J. R. Koza).</p>
<p>Grammatical evolution: Evolving programs for an arbitrary language. Conor Ryan, Michael O Collins, Neill, Genetic Programming. Berlin Heidelberg; Berlin, HeidelbergSpringerConor Ryan, JJ Collins, and Michael O. Neill. 1998. Grammatical evolution: Evolving programs for an arbitrary language. In Genetic Programming. Springer Berlin Heidelberg, Berlin, Heidelberg, 83-96.</p>
<p>Choose Your Programming Copilot: A Comparison of the Program Synthesis Performance of Github Copilot and Genetic Programming. Dominik Sobania, Martin Briesch, Franz Rothlauf, 10.1145/3512290.3528700Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceBoston, Massachusetts; New York, NY, USAAssociation for Computing MachineryGECCO '22)Dominik Sobania, Martin Briesch, and Franz Rothlauf. 2022. Choose Your Programming Copilot: A Comparison of the Program Synthesis Performance of Github Copilot and Genetic Programming. In Proceedings of the Genetic and Evolutionary Computation Conference (Boston, Massachusetts) (GECCO '22). Association for Computing Machinery, New York, NY, USA, 1019-1027. https://doi.org/10.1145/3512290.3528700</p>
<p>Program sketching. Armando Solar-Lezama, International Journal on Software Tools for Technology Transfer. 15Armando Solar-Lezama. 2013. Program sketching. International Journal on Soft- ware Tools for Technology Transfer 15, 5 (2013), 475-495.</p>
<p>The Push3 execution stack and the evolution of control. Lee Spector, Jon Klein, Maarten Keijzer, 10.1145/1068009.1068292Lee Spector, Jon Klein, and Maarten Keijzer. 2005. The Push3 execution stack and the evolution of control. 1689-1696. https://doi.org/10.1145/1068009.1068292</p>
<p>PolyGP: A polymorphic genetic programming system in Haskell. Tina Yu, Chris Clack, Stanford University BookstoreTina Yu and Chris Clack. 1997. PolyGP: A polymorphic genetic programming system in Haskell. Stanford University Bookstore.</p>            </div>
        </div>

    </div>
</body>
</html>