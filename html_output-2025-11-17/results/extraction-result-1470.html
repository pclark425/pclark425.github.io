<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1470 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1470</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1470</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-30.html">extraction-schema-30</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of curriculum learning approaches for teaching agents commonsense or science procedures in interactive text environments, including details about the curriculum strategy, task composition, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-219052489</p>
                <p><strong>Paper Title:</strong> <a href="https://www.aclweb.org/anthology/2020.acl-main.684.pdf" target="_blank">Learning Web-based Procedures by Reasoning over Explanations and Demonstrations in Context</a></p>
                <p><strong>Paper Abstract:</strong> We explore learning web-based tasks from a human teacher through natural language explanations and a single demonstration. Our approach investigates a new direction for semantic parsing that models explaining a demonstration in a context, rather than mapping explanations to demonstrations. By leveraging the idea of inverse semantics from program synthesis to reason backwards from observed demonstrations, we ensure that all considered interpretations are consistent with executable actions in any context, thus simplifying the problem of search over logical forms. We present a dataset of explanations paired with demonstrations for web-based tasks. Our methods show better task completion rates than a supervised semantic parsing baseline (40% relative improvement on average), and are competitive with simple exploration-and-demonstration based methods, while requiring no exploration of the environment. In learning to align explanations with demonstrations, basic properties of natural language syntax emerge as learned behavior. This is an interesting example of pragmatic language acquisition without any linguistic annotation.</p>
                <p><strong>Cost:</strong> 0.009</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1470.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1470.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of curriculum learning approaches for teaching agents commonsense or science procedures in interactive text environments, including details about the curriculum strategy, task composition, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>curriculum learning (future-work mention)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Curriculum learning for web-based procedure learning (suggested)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A brief suggestion in the paper's conclusion that future work could apply curriculum learning by first training on simpler web tasks and then using those learned components compositionally in explanations for more complex tasks; no curriculum experiments are performed in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning Web-based Procedures by Reasoning over Explanations and Demonstrations in Context</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LED</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>LED (Learning from Explained Demonstrations) is a grounded, latent-variable model that reasons over assignments of grounded logical-form variables (DOM elements, features, relations, actions, strings) consistent with a single demonstrated action in a web-page context and aligns those latent logical forms to natural-language stepwise explanations via a variational EM procedure; a sequence model variant (LED+Syntax) models token alignments with HMM-style transitions.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>MiniWoB (Mini World-of-Bits)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>A suite of simulated web-based interactive tasks (HTML DOM interfaces) where the agent can perform elementary actions such as clicking DOM elements and typing short strings; task instances vary in page content and arguments and include buttons, form fields, lists, and small interactive games.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>web-based procedures (automation of web tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_examples</strong></td>
                            <td>Clicking buttons, typing into fields, forwarding emails, selecting radio buttons, simple scripted tasks such as Tic-Tac-Toe, selecting links/search results; (the dataset contains 40 click/type tasks from MiniWoB)</td>
                        </tr>
                        <tr>
                            <td><strong>compositional_structure</strong></td>
                            <td>Tasks are described in a DSL over DOM elements and can combine element selectors, element features and a single binary relation between elements; the model treats logical forms as compositional assignments of element, feature, relation, action and typed-string variables, but the DSL (and model) disallows nested/multiple relations (limited compositional depth).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_curriculum</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_description</strong></td>
                            <td>No curriculum is implemented. The paper only suggests as future work a curriculum that would (a) train first on simpler tasks and (b) compose learned simpler-task components when interpreting explanations for more complex tasks; no operational details, ordering, or experiments are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_ordering_principle</strong></td>
                            <td>proposed: simple-to-complex / compositional prerequisites (suggested), but not implemented</td>
                        </tr>
                        <tr>
                            <td><strong>task_complexity_range</strong></td>
                            <td>Not specified for a curriculum; the paper's task set spans simple click/type tasks up to more complex scripted tasks (e.g., tic-tac-toe) and varies in number of actions per task (explanations average 3.3 steps), but no explicit curriculum complexity bins are defined or used.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_curriculum</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_curriculum</strong></td>
                            <td>No curriculum used. Reported empirical results (no curriculum) show LED approaches outperform a supervised semantic-parsing baseline (reported as ~40% relative improvement on average over that baseline) and be roughly competitive with a behavior-cloning + reinforcement-learning (BC+RL) approach while requiring only a single explained demonstration and no environment exploration; LED(+Syntax) gives a small but statistically-significant improvement over LED (binomial test p < 0.1). Task completion rates were measured over 100 test instances per task (exact per-task numbers reported in paper figures/tables, not restated here).</td>
                        </tr>
                        <tr>
                            <td><strong>has_curriculum_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>alternative_curriculum_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_generalization</strong></td>
                            <td>The paper reports that LED (and SemParse) can potentially generalize to new task instances and even to new tasks from explanations and context alone (since LED roots logical forms in context and marginalizes interpretations), but no systematic transfer or compositional generalization experiments for unseen-composition tasks or curriculum-structured transfer are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper does not evaluate curriculum methods; key relevant findings are: (1) natural-language explanations paired with a single demonstration substantially reduce required supervision compared to exploration-based learning and improve sample efficiency, (2) LED, which grounds logical forms in observed demonstrations (inverse semantics), yields large gains over a supervised semantic-parsing baseline (~40% relative improvement on average) and is competitive with BC+RL despite no exploration, and (3) LED's modeling choices and DSL limit compositional depth (single relation variable), so a curriculum that progressively introduces compositional complexity could be promising but was not tested.</td>
                        </tr>
                        <tr>
                            <td><strong>name_short_display</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>World of bits: An open-domain platform for Web-based agents <em>(Rating: 2)</em></li>
                <li>Reinforcement learning on web interfaces using workflow-guided exploration <em>(Rating: 2)</em></li>
                <li>DOM-Q-NET: grounded RL on structured language <em>(Rating: 2)</em></li>
                <li>From language to programs: Bridging reinforcement learning and maximum marginal likelihood <em>(Rating: 1)</em></li>
                <li>Learning language games through interaction <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1470",
    "paper_id": "paper-219052489",
    "extraction_schema_id": "extraction-schema-30",
    "extracted_data": [
        {
            "name_short": "curriculum learning (future-work mention)",
            "name_full": "Curriculum learning for web-based procedure learning (suggested)",
            "brief_description": "A brief suggestion in the paper's conclusion that future work could apply curriculum learning by first training on simpler web tasks and then using those learned components compositionally in explanations for more complex tasks; no curriculum experiments are performed in this work.",
            "citation_title": "Learning Web-based Procedures by Reasoning over Explanations and Demonstrations in Context",
            "mention_or_use": "mention",
            "agent_name": "LED",
            "agent_description": "LED (Learning from Explained Demonstrations) is a grounded, latent-variable model that reasons over assignments of grounded logical-form variables (DOM elements, features, relations, actions, strings) consistent with a single demonstrated action in a web-page context and aligns those latent logical forms to natural-language stepwise explanations via a variational EM procedure; a sequence model variant (LED+Syntax) models token alignments with HMM-style transitions.",
            "agent_size": null,
            "environment_name": "MiniWoB (Mini World-of-Bits)",
            "environment_description": "A suite of simulated web-based interactive tasks (HTML DOM interfaces) where the agent can perform elementary actions such as clicking DOM elements and typing short strings; task instances vary in page content and arguments and include buttons, form fields, lists, and small interactive games.",
            "procedure_type": "web-based procedures (automation of web tasks)",
            "procedure_examples": "Clicking buttons, typing into fields, forwarding emails, selecting radio buttons, simple scripted tasks such as Tic-Tac-Toe, selecting links/search results; (the dataset contains 40 click/type tasks from MiniWoB)",
            "compositional_structure": "Tasks are described in a DSL over DOM elements and can combine element selectors, element features and a single binary relation between elements; the model treats logical forms as compositional assignments of element, feature, relation, action and typed-string variables, but the DSL (and model) disallows nested/multiple relations (limited compositional depth).",
            "uses_curriculum": false,
            "curriculum_name": null,
            "curriculum_description": "No curriculum is implemented. The paper only suggests as future work a curriculum that would (a) train first on simpler tasks and (b) compose learned simpler-task components when interpreting explanations for more complex tasks; no operational details, ordering, or experiments are provided.",
            "curriculum_ordering_principle": "proposed: simple-to-complex / compositional prerequisites (suggested), but not implemented",
            "task_complexity_range": "Not specified for a curriculum; the paper's task set spans simple click/type tasks up to more complex scripted tasks (e.g., tic-tac-toe) and varies in number of actions per task (explanations average 3.3 steps), but no explicit curriculum complexity bins are defined or used.",
            "performance_with_curriculum": null,
            "performance_without_curriculum": "No curriculum used. Reported empirical results (no curriculum) show LED approaches outperform a supervised semantic-parsing baseline (reported as ~40% relative improvement on average over that baseline) and be roughly competitive with a behavior-cloning + reinforcement-learning (BC+RL) approach while requiring only a single explained demonstration and no environment exploration; LED(+Syntax) gives a small but statistically-significant improvement over LED (binomial test p &lt; 0.1). Task completion rates were measured over 100 test instances per task (exact per-task numbers reported in paper figures/tables, not restated here).",
            "has_curriculum_comparison": false,
            "alternative_curriculum_performance": null,
            "transfer_generalization": "The paper reports that LED (and SemParse) can potentially generalize to new task instances and even to new tasks from explanations and context alone (since LED roots logical forms in context and marginalizes interpretations), but no systematic transfer or compositional generalization experiments for unseen-composition tasks or curriculum-structured transfer are reported.",
            "key_findings": "The paper does not evaluate curriculum methods; key relevant findings are: (1) natural-language explanations paired with a single demonstration substantially reduce required supervision compared to exploration-based learning and improve sample efficiency, (2) LED, which grounds logical forms in observed demonstrations (inverse semantics), yields large gains over a supervised semantic-parsing baseline (~40% relative improvement on average) and is competitive with BC+RL despite no exploration, and (3) LED's modeling choices and DSL limit compositional depth (single relation variable), so a curriculum that progressively introduces compositional complexity could be promising but was not tested.",
            "name_short_display": null,
            "uuid": "e1470.0"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "World of bits: An open-domain platform for Web-based agents",
            "rating": 2,
            "sanitized_title": "world_of_bits_an_opendomain_platform_for_webbased_agents"
        },
        {
            "paper_title": "Reinforcement learning on web interfaces using workflow-guided exploration",
            "rating": 2,
            "sanitized_title": "reinforcement_learning_on_web_interfaces_using_workflowguided_exploration"
        },
        {
            "paper_title": "DOM-Q-NET: grounded RL on structured language",
            "rating": 2,
            "sanitized_title": "domqnet_grounded_rl_on_structured_language"
        },
        {
            "paper_title": "From language to programs: Bridging reinforcement learning and maximum marginal likelihood",
            "rating": 1,
            "sanitized_title": "from_language_to_programs_bridging_reinforcement_learning_and_maximum_marginal_likelihood"
        },
        {
            "paper_title": "Learning language games through interaction",
            "rating": 1,
            "sanitized_title": "learning_language_games_through_interaction"
        }
    ],
    "cost": 0.0092665,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Learning Web-based Procedures by Reasoning over Explanations and Demonstrations in Context
Association for Computational LinguisticsCopyright Association for Computational LinguisticsJuly 5 -10, 2020. 2020</p>
<p>Shashank Srivastava ssrivastava@cs.unc.edu 
University of North Carolina
Chapel Hill</p>
<p>Oleksandr Polozov polozov@microsoft.com 
Microsoft Research
Redmond</p>
<p>Nebojsa Jojic jojic@microsoft.com 
Microsoft Research
Redmond</p>
<p>Christopher Meek meek@microsoft.com 
Microsoft Research
Redmond</p>
<p>Learning Web-based Procedures by Reasoning over Explanations and Demonstrations in Context</p>
<p>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics
the 58th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational LinguisticsJuly 5 -10, 2020. 20207652
We explore learning web-based tasks from a human teacher through natural language explanations and a single demonstration. Our approach investigates a new direction for semantic parsing that models explaining a demonstration in a context, rather than mapping explanations to demonstrations. By leveraging the idea of inverse semantics from program synthesis to reason backwards from observed demonstrations, we ensure that all considered interpretations are consistent with executable actions in any context, thus simplifying the problem of search over logical forms. We present a dataset of explanations paired with demonstrations for web-based tasks. Our methods show better task completion rates than a supervised semantic parsing baseline (40% relative improvement on average), and are competitive with simple exploration-anddemonstration based methods, while requiring no exploration of the environment. In learning to align explanations with demonstrations, basic properties of natural language syntax emerge as learned behavior. This is an interesting example of pragmatic language acquisition without any linguistic annotation.</p>
<p>Introduction</p>
<p>People routinely perform repetitive web-based tasks, involving sequences of clicking and typing actions. These include activities such as forwarding emails, booking flight tickets, ordering pizza, etc. These activities largely consist of small sequences of actions in an environment with restricted semantics, and are potentially amenable to automation. In this work, we explore whether an AI agent can be taught such tasks through natural language explanations and a single demonstration by a user (as one might teach such a task to a human assistant). * *Work done while the first author was at Microsoft Research.</p>
<p>Type 'news.com' in the URL bar in the browser, and press enter Type 'NLP' in the search at the top-right, and press enter Email me the link to the three most recent articles nlp Date Date Send me NLP news everyday at 8am</p>
<p>Step 1:</p>
<p>Step 2:</p>
<p>Step 3:</p>
<p>Can you show me how?</p>
<p>Let me teach you … Figure 1: AI assistants that can be taught web-based procedures by their users can have diverse practical applications. Here, we explore learning very simple tasks from the Mini World-of-Bits framework using natural language explanations and a single demonstration of the task From the perspective of language understanding, this involves challenges such as converting instructional language to actions, resolving ambiguities through pragmatics, and learning script-like behavior. The web domain is rich in textual, structural and spatial features, allowing for exploration of multiple types of grounding behavior including spatial and visual language understanding, as well as reasoning over semi-structured data. Also, despite its richness, the tasks involved usually do not require much background knowledge.</p>
<p>From a practical perspective, teachable AI assistants can change the way people interact with computers. Today's conversational assistants such as Alexa or Cortana act on a small number of preprogrammed language commands (e.g., "What is the weather going to be like?"). However, they cannot be taught new functionalities important to a user (as in Figure 1). Enabling users to teach computers personalized procedures through explained demonstrations can make conversational AI systems fundamentally more useful.</p>
<p>In Section 2, we situate our work in the broader body of work on grounded semantic parsing and learning from language. Section 3 summarizes our framework and dataset. In Section 4, we describe our approach in detail. Here, we investigate a new paradigm for interpreting language in grounded contexts. Instead of mapping statements to logical forms that then execute in a context as in traditional semantic parsing, the method considers the set of possible typing and clicking actions in a context, identifies features of corresponding web elements and their relationships with other elements on the webpage, and aligns these to natural language explanations through a generative model. Section 5 describes the empirical evaluation. Our contributions are:</p>
<p>• An approach towards learning web-based tasks from a single explained demonstration. • A dataset of explanations and demonstrations for tasks from the MiniWoB framework. • Empirical results showing that explained demonstrations can be an effective mode of supervision for learning such tasks. Language can significantly reduce the number of samples needed compared to learning from demonstrations alone.</p>
<p>Related Work</p>
<p>Semantic Parsing: Supervised models for converting statements to logical forms have long been studied in a wide range of settings (Zelle and Mooney , 1996;Zettlemoyer and Collins, 2005;Wong and Mooney, 2007;Kwiatkowksi et al., 2010;Yin and Neubig, 2017). More recent approaches focused on using weaker forms of supervision such as denotations or observations of world state (Berant et al., 2013;Clarke et al., 2010;Krishnamurthy and Mitchell, 2012) and semi-supervised methods aimed at efficient prototyping (Pasupat and Liang, 2015;Wang et al., 2015). These methods require more readily available supervision, such as question/answer pairs for model training, rather than annotations of logical forms. (Artzi and Zettlemoyer, 2013) learn to follow instructions in the context of robot navigation by conditioning parsing on environmental context. Artzi and Zettlemoyer (2011) use conversational feedback as a signal to induce logical forms for individual utterances from transcripts of conversations in a dialog-based setup. Some other recent approaches (Long et al., 2016;Guu et al., 2017) explore learning language from sequences of utterances and interactions in simple environments, which is conceptually similar to our work. Muhlgay et al. (2019) and Guu et al. (2017) explore better strategies to search the space of logical forms. While all of these methods are related to multiple facets of work, our method diverges from them in that the space of candidate logical forms is driven by the constraints of possible actions in an environment rather than the natural language utterance. This guarantees that all of the considered logical forms during search are consistent with executable actions in any novel context. Finally, some recent methods (Andreas et al., 2016) marginalize over latent interpretations of language in context of downstream tasks. We use a similar Bayesian approach, where actions are chosen by marginalizing logical forms (rather than choosing a single interpretation of an explanation).</p>
<p>Interactive Learning from Language: Several frameworks have leveraged natural language supervision to learn new tasks, starting with early work on the SHRLDU system (Winograd, 1972) and Interactive Task Learning (Laird et al., 2017).</p>
<p>In particular, several reinforcement learning approaches have been explored in text-based environments for learning strategies, following instruction manuals, game playing, etc. (Branavan et al., 2009;Goldwasser and Roth, 2014;Misra et al., 2018;Narasimhan et al., 2015). These approaches leverage the ability to explore and interact with the environment to learning policies that lead to favourable outcomes. This is different from our goal here, where the agent needs to learn from a single explained demonstration of a task, and no interactivity with the environment is assumed. Some recent approaches have shown language explanations to be effective for learning realistic tasks including relation extraction, concept learning and question answering (Hancock et al., 2018;Srivastava et al., 2017Srivastava et al., , 2018Andreas et al., 2018).</p>
<p>In terms of the goal and problem formulation, our approach extends multiples lines of previous work. Quirk et al. (2015)'s work is similar to ours in motivation in learning user-specified recipes, but has no aspects of grounding or demonstrations. (Wang et al., 2016) explore interactive parser training through language games in context of block-world environments.  explore mapping natural language to specific elements on complex and realistic web-pages, although not in context of learning from demonstrations. Our framework directly extends previous work on learning web-based tasks from the Mini Word-of-Bits framework using multiple demonstrations and exploration of the environment (Shi et al., 2017;. In particular, our DSL extends the constraint language defined in  to explore learning from explained demonstrations instead.</p>
<p>Framework and dataset</p>
<p>We build on the Mini World-of-bits (MiniWoB) framework (Shi et al., 2017), a collection of webbased tasks initially proposed as a testbed for reinforcement learning agents. The tasks vary in difficulty in terms of the number of actions required, variability between instances of the task, and types of reasoning involved (including clicking specified buttons, forwarding emails and playing tic-tac-toe). See the top half of Figure 2 for an example of a task. Each task consists of a task description (yellow box), and an interactive web interface.</p>
<p>While previous methods have focused on learning sequential decision making to complete these tasks through a mixture of exploration (the framework provides simulators, where correctly completing a task yields a reward) and behavior cloning (by observing multiple demonstrations from human users); our focus is on learning to complete these tasks in a one-shot sense (without any exploration). This is because the one-shot case is a much more realistic scenario for learning web-based procedures from a teacher. In practical situations (where there are no simulators), it would not be feasible for an AI agent to learn to book flights by booking multiple incorrect tickets, or manage a user's email by sending multiple incorrect emails. On the other hand, a paradigm where the agent attempts to generalize from a single demonstration and explanations can be feasible for many more of such scenarios.  </p>
<p>Dataset</p>
<p>We created a dataset of natural language explanations paired with demonstrations by human users for tasks from the MiniWoB framework. For this, crowdsourced workers on Amazon Mechanical Turk were asked to demonstrate how to complete these tasks and provide stepwise explanations to an AI assistant on how to complete the task. Since users would be unfamiliar with most of the tasks, for each task they were allowed to experiment with the interface as many times as they liked, and only the final demonstration was logged.</p>
<p>In all, we collect 520 demonstrations (each consisting of a sequence of click/type actions in the context of a MiniWoB task) paired with stepwise explanation sequences. Figure 3 shows samples of collected explanations. On average, each explanation sequence contains 3.3 explanations. The dataset contains 1719 explanations in total (individual steps), averaging 8.4 words per explanation. The size of the vocabulary of the explanations is 995. In general, workers found the teaching process to be engaging, with an average rating of 8.3 on a 1-10 scale on how they enjoyed the HIT in a post-completion survey. The dataset is available at https://aka.ms/Web-D-E.</p>
<p>Data characteristics: From a manual analysis of 100 randomly selected explanation sequences and task demonstrations, we find that in almost all cases (97%), the sequence of actions described in the explanations corresponds to the sequence of actions in the demonstration. More than 85% of explanations mention a clicking or typing action, while around 10% identify an entity/string on the webpage that is used in an action in the next step (e.g., the first explanation for the second task in Figure 3). Around 3% of the explanations correspond to conditionals and hypotheticals, which go beyond the scope of our approach. Roughly 15% of the explanations mention multiple entities on the webpage -usually specifying one element in relation to the other (e.g., "the radio button to the right of the text-box"). the city after "from:" AfterWord(string) FindMatchingContext(string, context) enter "Seattle" as the source city ... There are three types of operations: (1) click and type actions on specified web elements (with a specified string, in case of a type action), (2) operations that filter elements on a page that satisfy a criterion, and (3) operations that filter strings based on a criterion. We include a special operator FindMatchingContext to accommodate cases in which the users provide explanations for an instance of a task with specific arguments mentioned in the task description (e.g., see the last row in Table 1). In this case, the operator can pick out the corresponding argument for the new instance by looking at the surrounding context in the new task description. The evaluation of logical forms in the DSL in the context of a webpage consists of set operations over all DOM elements on the webpage (and text-spans of up to two tokens for string operators). For example, the logical form HasTag(type=button) will evaluate to the set of elements on a page that have a HTML tag type with value button.</p>
<p>Learning from explanations and demonstrations</p>
<p>Our approach for learning web-based tasks, which we call LED -for Learning from Explained Demon-
click(elem3) click(tag=square &amp; rightOf(triangle))
Click the square to the right of the triangle</p>
<p>(1)</p>
<p>(2) strations, models the process of explaining a demonstration of a task in a grounded context. We assume that the reasoning behind each action in a demonstration can be described by a logical form, l, in the DSL. 1 LED's essential idea is that preferred logical forms are both (1) consistent with the user demonstration, d, in the observed context, c, and (2) relevant to the user's language explanations, x. Figure 4 illustrates this for a toy-example, where the context consists of a web-page with three elements, the demonstration consists of a single action, and a corresponding explanation is provided. Based on the observed demonstration (that elem3 was clicked), it is hard to infer the reason behind clicking it. Multiple logical forms in the DSL can be consistent with clicking elem3 in this context. e.g., it is at the top of the page, its color is blue, etc. However, these interpretations would not justify the provided explanation as those logical forms are not relevant to the explanation. Modeling relevance between logical forms and explanations can help identify the reasoning behind user demonstrations.</p>
<p>This framing diverges from traditional semantic parsing, where statements x are mapped to logi-cal forms l (e.g., database queries), which are then are executed against a context c (e.g., a knowledge base) to get a denotation (corresponds here with a demonstration) d. i.e., d = l(x) c . In this modeltheoretic view of semantics, parsed logical forms are not informed by the environmental context until execution. In comparison, LED roots logical forms in the observed context, and thus pragmatic consistency is ensured by design. 2 We maximize the log-likelihood of observing the explanations given the demonstration in a grounded context:
L(θ) = log p(x|d, c) = log l p(x|l) relevance p(l|d, c) consistency (1)
Here, the first term corresponds to scoring relevance between logical forms and explanations (modeled using a semantic parsing model). The second term enforces consistency between candidate logical forms and the demonstration in the context, and can be deterministically evaluated. As we see in Section 4.2, consistency is enforced by temperature-based annealing during training.</p>
<p>Grounded Logical forms as latent variables</p>
<p>Eqn 1 marginalizes over latent logical forms. To make this tractable, we represent a logical form in a grounded context as an assignment of a tuple of discrete variables, l := (e 0 , f 0 , r, e 1 , f 1 , a, t, f t ).</p>
<p>These variables indicate things such as which DOM element is acted upon (e 0 ), if its relation (r) with another element on the page (e 1 ) is relevant, and so on. These are defined below.</p>
<p>• e 0 ∈ domElements(c) denotes the DOMelement on which an action is performed. (e.g., e 0 = elem3 in Fig 4) This is observed from the demonstration, thus p(e 0 ) = I e 0 =e observed . 3
• f 0 = (f 01 . . . f 0n F ) is a set of selector variables, where f 0i denotes if feature i of element e 0 is relevant for choosing it. Its domain is {φ ∪ F i },
where F i is the range of values feature i can take. f 0i = φ denotes that the feature was not relevant for choosing e 0 (e.g., f 0 color = φ in Fig 4). If f 0i = φ, it can only take the observed value of the feature for e 0 in the context (e.g., f 0 tag = square in Fig 4). In Table 1, these correspond to operators that return web-elements and have names with prefix Has.</p>
<p>• r denotes if relation r between e 0 and another element on the webpage is relevant for choosing it. Its domain is {φ ∪ R}, where R is the set of (binary) relations between elements in the DSL.</p>
<p>In Table 1, these are operators that have names with prefix Reln. r = φ denotes that the no relation was relevant for choosing e 0 . If r = φ, it can only take the value of a relation that exists between e 0 and another element. If r = reln, e 1 can only take values of elements such that reln(e 0 , e 1 ) is true in the context.
• f 1 = (f 11 . . . f 1n F ) is a set of selector variables,
where f 1i denotes if feature i of element e 1 is relevant. e.g., for 'click the checkbox next to the button that says submit', the HasText feature of the button is relevant). f 1i = φ denotes that feature i was not relevant. If f 1i = φ, it can only take the observed value of the feature for e 1 . • a denotes the action performed on e 0 (click or type). This is observed from the demonstration. • t denotes the string to type, if a = type. This is observed from the demonstration (and is a substring of the task description text).
• f t = (f t1 . . . f tn T ) is a set of selector variables,
where f tj denotes if the text feature j of t is relevant for choosing it (In Table 1, operators with a string return type correspond to text features). Inverse Semantics: Assignments of values to these variables represents a search in the DSL space, since given any context, there is a mapping a from logical forms to an assignment of these variables. A key idea here is that, borrowing from program synthesis, we can leverage the inverse semantics of operators in the DSL (Polozov and Gulwani, 2015) to guarantee consistency of logical forms with the grounded context. i.e., at any step, the space of candidate logical forms we consider is consistent with the observed demonstration. This is possible because in our case, computing the inverse semantics for all operators in the DSL is feasible. 4</p>
<p>As just described, our approach will use the context of the webpage leverage DSL inverse semantics to maintain an implicit set of candidate logical forms that are consistent with the observed demonstration. We will use variational inference to infer the logical forms that are most relevant to the seen explanations, and choose the action to take based on the inferred distribution over logical forms.</p>
<p>Model Description</p>
<p>In Eqn 1, the second term corresponds to a prior probability overs logical forms given a demonstration and context (webpage). Our representation of logical forms as latent variable assignments (from Section 4.1) enables us to decompose this probability into local factor distributions. We choose these local priors to correspond to distributions that are uniform over assignments that are consistent, and has zero support otherwise, similar to previous work on pragmatic reasoning (Frank and Goodman, 2012; Monroe et al., 2017). In other words, these distributions are proportional to indicator function over valid assignments of variables in each factor. As seen below, these define a prior over l that is also proportional to a simple indicator function over values of l that are consistent with the observed demonstration and context. p(l | d, c) = p(e0, f0, r, e1, f1, a, t, ft | d, c) = p(e0|d) p(f0|e0, c) p(e1, r|e0, c) × p(f1|e1, c) p(a, t|d) p(ft|t, c) ∝ I V alid(e 0 ,d) I V alid(f 0 ,e 0 ,c) I V alid(e 1 ,r,e 0 ,c) × I V alid(f 1 ,e 1 ,c) I V alid(a,t,d) I V alid(f t ,t,c) = I V alid (l,d,c) (2) Substituting this in Eqn 1 and using Jensen's inequality, any distribution q over logical forms provides a lower-bound on the log-likelihood:
L(θ) ≥ l q(l) log p(x|l) I V alid(l) q(l) = l q(l) log p(x|l) + log I V alid(l) + Hq(3)
where H q is the entropy for distribution q. In Sec 4.1, we represent l as a tuple of variables. Next, we make a mean field approximation by assuming the distribution q(l) decomposes as:</p>
<p>-DOM elements or strings on the webpage -to search over. Compare this with an operation in arithmetic, e.g., add(int, int), which might require a search over infinite co-domains.
q(l) = q(e0, a, t) i q f 0i qe 1 qr i q f 1i j q f tj (4)
Focusing on the unobserved variables (given a demonstration), we have q(l) = q f 0 q e 1 q r q f 1 q ft . 5</p>
<p>Parsing model: We assume that the probability of an explanation decomposes into the probability of individual words as log p θ (x|l) = w∈x log p(w|f 0 , r, f 1 , f t , a). Further, we assume that individual words are generated from features, relations and actions in the logical form as:
log p(w|f0, r, f1, ft, a) = log 1 C {f 0 ,r,f 1 , f t ,a} k p(w|k) z kw p(z kw ) ≥ {f 0 ,r,f 1 , f t ,a} k b kw log p(w|k, z kw ) + log p(z kw ) + H b kw (5)
Here, k is an index over values of f 0 , r, f 1 , f t and a. z kw denotes an alignment between a particular value of a feature, relation or action (k) and word w in the explanation, in which case the word is generated from the distribution p(w|k). The presence of a summation inside of a logarithm makes maximizing this objective hard. We again use Jensen's inequality to get a bound by introducing variational distributions b kw over alignments z kw . b kw can be thought of as representing the proportions of an explanation word contributed by specific feature values, relations or actions k in the logical form. Each p(w|k) is parameterized as a multinomial distribution, θ kw , over the vocabulary.</p>
<p>Training and Inference: Our model training follows a variational EM approach, where in the Estep, we perform inference for the latent logical form variables and alignment proportions, keeping the model parameters as fixed. In the M-step, we update the parameters, θ kw , taking the variational distributions and alignments as fixed. Combining Eqn 2, Eqn 3 and Eqn 5, we get:
L(θ) ≥ l q f 0 qe 1 qrq f 1 q f t w k b kw [log θ z kw kw + log p(z kw )] + H b kw + log I V alid(l,d,c) + H f 0 + He 1 + Hr + H f 1 + H f t(6)
Maximizing this objective w.r.t. the variational distributions yields the following E-step updates: 6 
q f 0i (v f 0i ) ∝ exp w bv f 0i w log(θv f 0i w ) + log I V alid(v f 0i , e 0 ,c) qe 1 (ve 1 ) ∝ exp f 1i w b f 1i w v f 1i q f 1i (v f 1i ) log θv f 1iw + log I V alid (v f 1i ,q f 1i (v f 1i ) ∝ exp ve 1 qe 1 (ve 1 ) w bv f 1i w log θv f 1i w + log I V alid(v f 1i ,e 1 ,c) q f tj (v f tj ) ∝ exp w bv f tj w log(θv f tj w ) + log I V alid(v f tj ,t,c)(7)
Similarly, the updates for the alignment proportions (taking p(z kw ) in Eqn 6 to be uniform) are:
b kw ∝ exp k q k (k) log θ kw(8)
LED(+syntax): The above approach allows for arbitrary alignments between words and features, relations or actions in the grounded logical form (k), essentially representing x as a bag-of-words. 7 We also explore a variant that models x as a sequence of tokens by introducing a prior over joint alignments z kx = z k 1 w 1 . . . z k T w T in a sentence x := w 1 . . . w T (in Eqn 5). This is done by simply modeling p(z kx ) with pairwise transition probabilities as p(z kx ) := n p(z kt |z k t−1 ) = n T kt,k t−1 . In this case, updates for alignment proportions (Eqn. 8) correspond with emission probabilities in a HMM (which we omit here for brevity).</p>
<p>Since the updates in Eqn 7 and Eqn 8 are cyclic, in each E-step, we make 20 iterations of updates to the variational distributions and alignment proportions in a round-robin schedule. We note that consistency is enforced during training by the log-ofindicator-variable terms in Eqn 7. This is because any inconsistent assignments get a score of log(0), which tends to negative infinity. However, to ensure smooth training (and alleviate modeling issues from our mean field approximation), we leverage an annealing based strategy, where we incremen- 6 The optimal value for the concave problem j xj log y j x j s.t. j xj = 1 is achieved when x * j ∝ yj. 7 E.g., this won't differentiate between "click the URL below the button" and "click the button below the URL". tally increase the penalty for log(0) terms during training as −N/2 for the N 'th EM iteration (for large N , this also is a prohibitive penalty). In our experiments, this was seen to improve training.</p>
<p>In the M-step, we maximize the objective w.r.t. θ k :
θ k (w) ∝ exp n w∈xn b n kw q k(9)
The one exception is a special copy mechanism for string-valued features. For these, θ kw is not learned, but simply corresponds to an indicator function denoting if w matches the value of the feature. e.g., θ HasText('submit'),'submit' = 1.</p>
<p>Experiments</p>
<p>We next discuss LED's empirical performance.</p>
<p>Procedure Learning performance</p>
<p>First, we evaluate the method for completion rates on tasks from the MiniWoB framework. Following Liu et al. (2018), we filtered 40 tasks from the MiniWoB framework (Shi et al., 2017) that require only clicking and typing actions. During training of the LED model, we sample an explained demonstration for each of the 40 tasks, and models are trained on the aggregate of these (the model sees one explanation-demonstration pair for a task). For testing, models are evaluated on a new instance of a task, where the model greedily computes the demonstration d (specifying a click or typing action on a web element in the current DOM) that would maximize p(x|d, c) (see Eqn 1) and executes the corresponding actions. The method then moves to the next explanations. This requires an enumeration of all possibly clicking and typing actions that can be performed in a context c at every step. 8 Since the number of actions in a demonstration can be different from the number of steps in the explanation, we heuristically align the sequence of actions in demonstrations to the sequence of sentences in the explanations in our dataset based on a small manually defined list of trigger words.</p>
<p>A direct comparison of LED with other approaches is not possible, since they differ considerably in the type of supervision and resources used. Nonetheless, here we compare LED's performance with the following two methods to get a coarse sense of its effectiveness: The model is based on a sequence-to-sequence neural semantic parser from Jia and Liang (2016). During testing, the method parses the sequence of explanations to logical forms, and sequentially (attempts to) executes the predicted logical forms. In contrast, LED requires no logical form annotations. However, it leverages the inverse semantics of the DSL operators, which may not be feasible for every DSL. 2. BC+RL: This is the original approach from Shi et al. (2017), who proposed the MiniWoB framework and consists of behavior cloning and exploration. This learns a task by supervised learning on about 200 demonstrations, followed by exploration via reinforcement learning to fine-tune the learned policies. In comparison, LED requires no exploration of the environment but leverages additional supervision in the form of natural language explanations. Multiple methods have since explored other RL-based approaches, resulting in much improved performance Luo, 2019;Jia et al., 2019). In particular, Liu et al. (2018) leverage a constraint language similar to our DSL to train a RL policy to get large gains in performance. However, all these methods require multiple demonstrations and exploration of the environment. Figure 5 shows task completion performance for different methods on a subset of tasks from the MiniWoB framework. We compute task comple-  tion rates over 100 randomly selected test instances of each task. The differences between instances involves different arguments for a task and differences in the state of the environment. Firstly, we note that the LED approaches consistently outperforms SemParse across all tasks. This is a strong result, since LED does not have access to logical form annotations for explanations as SemParse does. This strongly indicates that knowledge of the pragmatic context is important for language interpretation in this domain, since our approach which roots logical forms in observed demonstrations performs better or as well for all but one task. We note that there is a large variance among tasks in terms of amenability to learning from explanations or exploration. For tasks like tic-tactoe, explanation-based methods perform poorly as expected, since learning the game involves reasoning that is hard to explain through step-wise explanation of a demonstration, but can be more naturally learned from exploration. On the other hand, explanation-based methods perform well on tasks that are easily expressed through language. On the whole, the LED approaches and are roughly competitive with BC+RL, while requiring no exploration and only a single demonstration. Note that unlike exploration-based methods, LED and SemParse can potentially generalize to new tasks during testing (where no demonstration is seen during training) from explanations and context only.</p>
<p>We also note that LED(+Syntax) generally outperforms vanilla LED, although the effect size is not large. However, this trend is statistically significant (binomial test, p &lt; 0.1).</p>
<p>Language Interpretation performance</p>
<p>Next, we quantitatively evaluate the parsing performance of our method at the level of individual explanations (rather than task completion rate). For this, we evaluate the trained models on explanations from a set of 80 demonstrations from the dataset (unseen during training), where we calculate the match between the predicted action from an explanation in the context, and the actual action in the logged demonstration (accuracy of pre- dicted action in a context). Table 2 summarizes this performance, which shows a similar trend as Section 5.1. Both LED methods perform substantially better than SemParse, and all three methods perform much better than randomly choosing the next executable action in the context (Random). We note again that LED's involves no logical form annotations, and is driven purely by grounding explanations in observed demonstrations.</p>
<p>Visualizing learned language</p>
<p>Figure 6 depicts the learned lexicon by visualizing a representative subset of learned θ kw values for LED (+Syntax) (from Sec 4.2) as a heatmap. We note that the model correctly induces mappings between words and DSL operators. The rows and columns are manually ordered to emphasize the block diagonal structure. Table 3 shows the learned transition probabilities, T k 1 ,k 2 , for LED (+Syntax). To reduce model size, we share parameters for values of k corresponding to types f 0 , r, f 1 , f t and a. A common template about the general structure of user explanations is reflected from the parameter values. Most explanations start with the description of the action a, followed by mentioning features that identify the relevant element f 0 . In fact, f 0 distributions generate the majority of words in most explanations. Relation mentions, when present, usually follow this, in turn followed by features corresponding to f 0 , reflective of a VSO word order in most explanations. Diagonal values are substantially higher, indicating that words describing specific objects and actions tend to cluster together, as would be expected from the semantics of natural language.</p>
<p>Common Errors</p>
<p>From a qualitative error analysis, we note that most errors in task learning come from three sources. Firstly, although the method learns reasonable mappings between words and semantic operators, the method often misaligns attributes of different ele-  Table 3: Learned transition probabilities between latent variable categories for LED (+Syntax). These reflect a prominence of VSO sentence structures in user explanations. ments, even with the LED(+Syntax) model. This is likely because the training data is not adequate to learn these constraints, and methods that enforce these through informed priors maybe more effective. Another common error is due to challenges with anaphora resolution and discourse referents. Finally, a large number of explanations are not explicit in describing the sequence of actions required to perform a task, and some needed actions remain unmentioned. While this would be expected in realistic computer-human interactions, fixing these errors is beyond the scope of the current method.</p>
<p>Conclusion</p>
<p>Our work here is a step in the direction of teachable AI agents that can learn new behavior from conversational interactions with ordinary users. In terms of technique, our bottom-up approach to generating logical forms ensures consistency between interpretations and the ambient context during search. Conversely, this would be complicated in domains with rich composition and nesting in logical forms, which go beyond simple features and relations. e.g., "click the third email from Jeanette", and where modeling inverse semantics is infeasible.</p>
<p>Here, we posed the learning of web-based tasks as similar to instruction-following problem, with no aspect of interactivity or exploration of the environment. In future work, the possibility of learning from a mix of explanations, exploration and a limited budget of interaction with the environment can be explored. Also, language grounding models that incorporate richer alignments between explanations and demonstrations can lead to more effective learning. Since LED only requires tokenization as pre-processing, it can possibly extend to low resource scenarios. In terms of problem framing, interactive use-cases that enable the agent to ask questions when it is confused may also be realistic. Future work can also explore curriculum learning in this domain, by first learning simpler tasks, which can be compositionally invoked in explanations for complex tasks.</p>
<p>Figure 2 :
2Crowd-worker interface used for collecting natural language explanations and demonstrations</p>
<p>Figure 3 :
3Examples of collected explanations</p>
<p>Figure 4 :
4Modeling principle for Learning from ExplainedDemonstrations (LED). We prefer logical forms (l) that are both consistent with the user demonstration (d) in the context (c), and relevant to the user's explanations (x).</p>
<p>(e.g., in Fig 4, r can't take the value LeftOf, since elem3 is the rightmost element in the context). Our choice of having a single variable for r disallows logical forms with multiple or nested relations. This was guided by an analysis of our dataset, where none of the collected explanations show such behavior. • e 1 denotes that relation r between elements e 0 and e 1 is relevant for choosing e 0 . Its domain is {φ∪domElements(c)}. e 1 = φ if and only if r = φ, i.e. if no relation is relevant for choosing e 0 .</p>
<p>r w log θv r w + log I V alid(e 1 ,vr ,e 0 ,c) qr(vr) ∝ exp ve 1 qe 1 (ve 1 ) w bv r w log θv r w + log I V alid(e 1 ,vr ,e 0 ,c)</p>
<p>Figure 5 :
5Task-completion rates for MiniWoB tasks with varying difficulty. Rates are calculated over 100 new instances of each task 1. SemParse: This is a supervised semantic parsing baseline, trained on a manually annotated dataset of around 300 explanations labeled with their DSL logical forms (covering roughly one annotated explanation sequence for every task).</p>
<p>Figure 6 :
6Heatmap showing learned values of θ kw for 20 frequent words w in and representative values of k. Darker shades correspond to higher probability values.</p>
<p>Task: Forward an email Click on the segment that mentions Maureen Click on the button name "Forward" at the bottom of the page Type in the word 'Amata' in front of the row tagged 'to' Click on the arrow button at the top of the pageTask: Select a radio buttonFocus on the word sequence after SelectClick on the radio button to the left of the word sequence Press submit</p>
<p>Table 1 :
1Major operators in DSL for learning of web-based procedures3.2 DSL for semantic parsingWe define a domain specific language (DSL) for describing web-based procedures in terms of DOM elements by expanding on the constraint language in. The DSL operators correspond to actions on DOM elements, element features and relations between them. The DSL defines the vocabulary of logical forms for parsing of user explanations, and grounds sensors and effectors in the web environment.Table 1summarizes the DSL.</p>
<p>Table 2 :
2Semantic parsing performance (predicted action </p>
<p>match) for interpreting individual explanations in a context </p>
<p>We do not infer individual logical forms corresponding to an explanation, since we marginalize over all logical forms that resolve to the same action in a context.
For example, inFigure 4, click(tag=triangle &amp; rightOf(square)) won't be considered for the provided utterance, as it is inconsistent with the context. 3 I condition denotes an indicator function for condition.
Since there is only a relatively small number of candidates
Using q f 0 as shorthand notation for the product of variational distributions i q f 0i , and so on.
This is possible since the set of actionable elements on a webpage, and the set of candidate strings that can be typed (up to two length tokens from task description) are not large.</p>
<p>Learning with latent language. Jacob Andreas, Dan Klein, Sergey Levine, 10.18653/v1/N18-1197Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesLong Papers1Association for Computational LinguisticsJacob Andreas, Dan Klein, and Sergey Levine. 2018. Learning with latent language. In Proceedings of the 2018 Conference of the North American Chap- ter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Pa- pers), pages 2166-2179. Association for Computa- tional Linguistics.</p>
<p>Neural module networks. Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein, 10.1109/CVPR.2016.122016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016. Las Vegas, NV, USAIEEE Computer SocietyJacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. 2016. Neural module networks. In 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016, pages 39-48. IEEE Computer Society.</p>
<p>Bootstrapping semantic parsers from conversations. Yoav Artzi, Luke Zettlemoyer, Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing. the 2011 Conference on Empirical Methods in Natural Language ProcessingEdinburgh, Scotland, UKAssociation for Computational LinguisticsYoav Artzi and Luke Zettlemoyer. 2011. Bootstrapping semantic parsers from conversations. In Proceed- ings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 421-432, Edinburgh, Scotland, UK. Association for Compu- tational Linguistics.</p>
<p>Weakly supervised learning of semantic parsers for mapping instructions to actions. Yoav Artzi, Luke Zettlemoyer, 10.1162/tacl_a_00209Transactions of the Association for Computational Linguistics. 1Yoav Artzi and Luke Zettlemoyer. 2013. Weakly su- pervised learning of semantic parsers for mapping instructions to actions. Transactions of the Associa- tion for Computational Linguistics, 1:49-62.</p>
<p>Semantic parsing on Freebase from question-answer pairs. Jonathan Berant, Andrew Chou, Roy Frostig, Percy Liang, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. the 2013 Conference on Empirical Methods in Natural Language ProcessingSeattle, Washington, USAAssociation for Computational LinguisticsJonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on Freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Lan- guage Processing, pages 1533-1544, Seattle, Wash- ington, USA. Association for Computational Lin- guistics.</p>
<p>Reinforcement learning for mapping instructions to actions. S R K Branavan, Harr Chen, Luke Zettlemoyer, Regina Barzilay, Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLPSuntec, SingaporeAssociation for Computational LinguisticsS.R.K. Branavan, Harr Chen, Luke Zettlemoyer, and Regina Barzilay. 2009. Reinforcement learning for mapping instructions to actions. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 82-90, Suntec, Singapore. Association for Computational Linguistics.</p>
<p>Driving semantic parsing from the world's response. James Clarke, Dan Goldwasser, Ming-Wei Chang, Dan Roth , Proceedings of the Fourteenth Conference on Computational Natural Language Learning. the Fourteenth Conference on Computational Natural Language LearningUppsala, SwedenAssociation for Computational LinguisticsJames Clarke, Dan Goldwasser, Ming-Wei Chang, and Dan Roth. 2010. Driving semantic parsing from the world's response. In Proceedings of the Four- teenth Conference on Computational Natural Lan- guage Learning, pages 18-27, Uppsala, Sweden. As- sociation for Computational Linguistics.</p>
<p>Predicting pragmatic reasoning in language games. C Michael, Noah D Frank, Goodman, 10.1126/science.1218633Science. 3366084Michael C. Frank and Noah D. Goodman. 2012. Pre- dicting pragmatic reasoning in language games. Sci- ence, 336(6084):998-998.</p>
<p>Learning from natural instructions. Dan Goldwasser, Dan Roth, 10.1007/s10994-013-5407-yMach. Learn. 942Dan Goldwasser and Dan Roth. 2014. Learning from natural instructions. Mach. Learn., 94(2):205-232.</p>
<p>From language to programs: Bridging reinforcement learning and maximum marginal likelihood. Kelvin Guu, Panupong Pasupat, Evan Liu, Percy Liang, 10.18653/v1/P17-1097Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver1Kelvin Guu, Panupong Pasupat, Evan Liu, and Percy Liang. 2017. From language to programs: Bridg- ing reinforcement learning and maximum marginal likelihood. In Proceedings of the 55th Annual Meet- ing of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1051-1062, Van- couver, Canada. Association for Computational Lin- guistics.</p>
<p>Training classifiers with natural language explanations. Braden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy Liang, Christopher Ré, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics1Braden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy Liang, and Christopher Ré. 2018. Training classifiers with natural language explanations. In Proceedings of the 56th Annual Meeting of the Association for Computational Lin- guistics (Volume 1: Long Papers), pages 1884-1895. Association for Computational Linguistics.</p>
<p>Data recombination for neural semantic parsing. Robin Jia, Percy Liang, 10.18653/v1/P16-1002Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyLong Papers1Association for Computational LinguisticsRobin Jia and Percy Liang. 2016. Data recombination for neural semantic parsing. In Proceedings of the 54th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 12-22, Berlin, Germany. Association for Computa- tional Linguistics.</p>
<p>DOM-Q-NET: grounded RL on structured language. Sheng Jia, Jamie Kiros, Jimmy Ba, ICLR 20197th International Conference on Learning Representations. New Orleans, LA, USAOpenReview.netSheng Jia, Jamie Kiros, and Jimmy Ba. 2019. DOM- Q-NET: grounded RL on structured language. In 7th International Conference on Learning Represen- tations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net.</p>
<p>Weakly supervised training of semantic parsers. Jayant Krishnamurthy, Tom Mitchell, Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language LearningJeju Island, KoreaAssociation for Computational LinguisticsJayant Krishnamurthy and Tom Mitchell. 2012. Weakly supervised training of semantic parsers. In Proceedings of the 2012 Joint Conference on Empir- ical Methods in Natural Language Processing and Computational Natural Language Learning, pages 754-765, Jeju Island, Korea. Association for Com- putational Linguistics.</p>
<p>Inducing probabilistic CCG grammars from logical form with higherorder unification. Tom Kwiatkowksi, Luke Zettlemoyer, Sharon Goldwater, Mark Steedman, Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing. the 2010 Conference on Empirical Methods in Natural Language ProcessingCambridge, MAAssociation for Computational LinguisticsTom Kwiatkowksi, Luke Zettlemoyer, Sharon Goldwa- ter, and Mark Steedman. 2010. Inducing probabilis- tic CCG grammars from logical form with higher- order unification. In Proceedings of the 2010 Con- ference on Empirical Methods in Natural Language Processing, pages 1223-1233, Cambridge, MA. As- sociation for Computational Linguistics.</p>
<p>Interactive task learning. John E Laird, Kevin A Gluck, John R Anderson, Kenneth D Forbus, Odest Chadwicke, Christian Jenkins, Dario D Lebiere, Matthias Salvucci, Andrea Scheutz, J Gregory Thomaz, Robert E Trafton, Shiwali Wray, James R Mohan, Kirk, 10.1109/MIS.2017.3121552IEEE Intell. Syst. 324John E. Laird, Kevin A. Gluck, John R. Anderson, Ken- neth D. Forbus, Odest Chadwicke Jenkins, Christian Lebiere, Dario D. Salvucci, Matthias Scheutz, An- drea Thomaz, J. Gregory Trafton, Robert E. Wray, Shiwali Mohan, and James R. Kirk. 2017. Interac- tive task learning. IEEE Intell. Syst., 32(4):6-21.</p>
<p>Reinforcement learning on web interfaces using workflow-guided exploration. Kelvin Evan Zheran Liu, Panupong Guu, Tianlin Pasupat, Percy Shi, Liang, 6th International Conference on Learning Representations. Vancouver, BC, CanadaConference Track ProceedingsEvan Zheran Liu, Kelvin Guu, Panupong Pasupat, Tian- lin Shi, and Percy Liang. 2018. Reinforcement learn- ing on web interfaces using workflow-guided explo- ration. In 6th International Conference on Learn- ing Representations, ICLR 2018, Vancouver, BC, Canada, April 30 -May 3, 2018, Conference Track Proceedings.</p>
<p>Simpler context-dependent logical forms via model projections. Reginald Long, Panupong Pasupat, Percy Liang, 10.18653/v1/P16-1138Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyLong Papers1Association for Computational LinguisticsReginald Long, Panupong Pasupat, and Percy Liang. 2016. Simpler context-dependent logical forms via model projections. In Proceedings of the 54th An- nual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1456- 1465, Berlin, Germany. Association for Computa- tional Linguistics.</p>
<p>Goal-induced inverse reinforcement learning. Katie Luo, EECS-2019-81University of California, BerkeleyTechnical ReportKatie Luo. 2019. Goal-induced inverse reinforcement learning. Technical Report EECS-2019-81, Univer- sity of California, Berkeley.</p>
<p>Policy shaping and generalized update equations for semantic parsing from denotations. Dipendra Misra, Ming-Wei Chang, Xiaodong He, Wen-Tau Yih, 10.18653/v1/D18-1266Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational LinguisticsDipendra Misra, Ming-Wei Chang, Xiaodong He, and Wen-tau Yih. 2018. Policy shaping and generalized update equations for semantic parsing from denota- tions. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2442-2452, Brussels, Belgium. Association for Computational Linguistics.</p>
<p>Colors in context: A pragmatic neural model for grounded language understanding. Will Monroe, X D Robert, Noah D Hawkins, Christopher Goodman, Potts, 10.1162/tacl_a_00064Transactions of the Association for Computational Linguistics. 5Will Monroe, Robert X.D. Hawkins, Noah D. Good- man, and Christopher Potts. 2017. Colors in context: A pragmatic neural model for grounded language understanding. Transactions of the Association for Computational Linguistics, 5:325-338.</p>
<p>Value-based search in execution space for mapping instructions to programs. Dor Muhlgay, Jonathan Herzig, Jonathan Berant, 10.18653/v1/N19-1193Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaLong and Short Papers1Association for Computational LinguisticsDor Muhlgay, Jonathan Herzig, and Jonathan Berant. 2019. Value-based search in execution space for mapping instructions to programs. In Proceedings of the 2019 Conference of the North American Chap- ter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 1942-1954, Minneapolis, Minnesota. Association for Computational Linguis- tics.</p>
<p>Language understanding for text-based games using deep reinforcement learning. Karthik Narasimhan, Tejas Kulkarni, Regina Barzilay, 10.18653/v1/D15-1001Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalAssociation for Computational LinguisticsKarthik Narasimhan, Tejas Kulkarni, and Regina Barzi- lay. 2015. Language understanding for text-based games using deep reinforcement learning. In Pro- ceedings of the 2015 Conference on Empirical Meth- ods in Natural Language Processing, pages 1-11, Lisbon, Portugal. Association for Computational Linguistics.</p>
<p>Mapping natural language commands to Web elements. Panupong Pasupat, Tian-Shun Jiang, Evan Liu, Kelvin Guu, Percy Liang, 10.18653/v1/D18-1540Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational LinguisticsPanupong Pasupat, Tian-Shun Jiang, Evan Liu, Kelvin Guu, and Percy Liang. 2018. Mapping natural lan- guage commands to Web elements. In Proceed- ings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4970-4976, Brussels, Belgium. Association for Computational Linguistics.</p>
<p>Compositional semantic parsing on semi-structured tables. Panupong Pasupat, Percy Liang, 10.3115/v1/P15-1142Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing. the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language ProcessingBeijing, ChinaLong Papers1Association for Computational LinguisticsPanupong Pasupat and Percy Liang. 2015. Compo- sitional semantic parsing on semi-structured tables. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Lan- guage Processing (Volume 1: Long Papers), pages 1470-1480, Beijing, China. Association for Compu- tational Linguistics.</p>
<p>Flash-Meta: A framework for inductive program synthesis. Oleksandr Polozov, Sumit Gulwani, 10.1145/2814270.2814310Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOP-SLA 2015. the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOP-SLA 2015New York, NY, USAACMOleksandr Polozov and Sumit Gulwani. 2015. Flash- Meta: A framework for inductive program synthesis. In Proceedings of the 2015 ACM SIGPLAN Inter- national Conference on Object-Oriented Program- ming, Systems, Languages, and Applications, OOP- SLA 2015, pages 107-126, New York, NY, USA. ACM.</p>
<p>Language to code: Learning semantic parsers for If-This-Then-That recipes. Chris Quirk, Raymond Mooney, Michel Galley, 10.3115/v1/P15-1085Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing. the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language ProcessingBeijing, ChinaAssociation for Computational Linguistics1Chris Quirk, Raymond Mooney, and Michel Galley. 2015. Language to code: Learning semantic parsers for If-This-Then-That recipes. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 878-888, Beijing, China. Association for Computational Linguistics.</p>
<p>World of bits: An open-domain platform for Web-based agents. Tianlin Shi, Andrej Karpathy, Linxi Fan, Jonathan Hernandez, Percy Liang, Proceedings of the 34th International Conference on Machine Learning. the 34th International Conference on Machine LearningSydney, NSWTianlin Shi, Andrej Karpathy, Linxi Fan, Jonathan Her- nandez, and Percy Liang. 2017. World of bits: An open-domain platform for Web-based agents. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Aus- tralia, 6-11 August 2017, pages 3135-3144.</p>
<p>Joint concept learning and semantic parsing from natural language explanations. Shashank Srivastava, Igor Labutov, Tom Mitchell, 10.18653/v1/D17-1161Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkAssociation for Computational LinguisticsShashank Srivastava, Igor Labutov, and Tom Mitchell. 2017. Joint concept learning and semantic parsing from natural language explanations. In Proceed- ings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1527-1536, Copenhagen, Denmark. Association for Computa- tional Linguistics.</p>
<p>Zero-shot learning of classifiers from natural language quantification. Shashank Srivastava, Igor Labutov, Tom Mitchell, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational Linguistics1Long Papers). Association for Computational LinguisticsShashank Srivastava, Igor Labutov, and Tom Mitchell. 2018. Zero-shot learning of classifiers from natu- ral language quantification. In Proceedings of the 56th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 306-316. Association for Computational Linguis- tics.</p>
<p>Learning language games through interaction. I Sida, Percy Wang, Christopher D Liang, Manning, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016. the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016Berlin, GermanyLong PapersSida I. Wang, Percy Liang, and Christopher D. Man- ning. 2016. Learning language games through in- teraction. In Proceedings of the 54th Annual Meet- ing of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Vol- ume 1: Long Papers.</p>
<p>Building a semantic parser overnight. Yushi Wang, Jonathan Berant, Percy Liang, 10.3115/v1/P15-1129Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing. the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language ProcessingBeijing, China1Long Papers). Association for Computational LinguisticsYushi Wang, Jonathan Berant, and Percy Liang. 2015. Building a semantic parser overnight. In Proceed- ings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th Interna- tional Joint Conference on Natural Language Pro- cessing (Volume 1: Long Papers), pages 1332-1342, Beijing, China. Association for Computational Lin- guistics.</p>
<p>Understanding natural language. Terry Winograd, Cognitive psychology. 31Terry Winograd. 1972. Understanding natural lan- guage. Cognitive psychology, 3(1):1-191.</p>
<p>Learning synchronous grammars for semantic parsing with lambda calculus. Yuk Wah Wong, Raymond Mooney, Proceedings of the 45th. the 45thYuk Wah Wong and Raymond Mooney. 2007. Learn- ing synchronous grammars for semantic parsing with lambda calculus. In Proceedings of the 45th</p>
<p>Annual Meeting of the Association of Computational Linguistics. Prague, Czech RepublicAssociation for Computational LinguisticsAnnual Meeting of the Association of Computational Linguistics, pages 960-967, Prague, Czech Repub- lic. Association for Computational Linguistics.</p>
<p>A syntactic neural model for general-purpose code generation. Pengcheng Yin, Graham Neubig, 10.18653/v1/P17-1041Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational Linguistics1Pengcheng Yin and Graham Neubig. 2017. A syntactic neural model for general-purpose code generation. In Proceedings of the 55th Annual Meeting of the As- sociation for Computational Linguistics (Volume 1: Long Papers), pages 440-450, Vancouver, Canada. Association for Computational Linguistics.</p>
<p>Learning to parse database queries using inductive logic programming. M John, Raymond J Zelle, Mooney, Proceedings of the Thirteenth National Conference on Artificial Intelligence. the Thirteenth National Conference on Artificial IntelligenceAAAI Press2AAAI'96John M. Zelle and Raymond J. Mooney. 1996. Learn- ing to parse database queries using inductive logic programming. In Proceedings of the Thirteenth Na- tional Conference on Artificial Intelligence -Volume 2, AAAI'96, pages 1050-1055. AAAI Press.</p>
<p>Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. Luke S Zettlemoyer, Michael Collins, UAI. AUAI PressLuke S. Zettlemoyer and Michael Collins. 2005. Learn- ing to map sentences to logical form: Structured classification with probabilistic categorial grammars. In UAI, pages 658-666. AUAI Press.</p>            </div>
        </div>

    </div>
</body>
</html>