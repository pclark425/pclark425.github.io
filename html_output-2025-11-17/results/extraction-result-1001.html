<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1001 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1001</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1001</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-23.html">extraction-schema-23</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <p><strong>Paper ID:</strong> paper-003ef1cd670d01af05afa0d3c72d72228f494432</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/003ef1cd670d01af05afa0d3c72d72228f494432" target="_blank">LLM+P: Empowering Large Language Models with Optimal Planning Proficiency</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> LLM+P is the first framework that incorporates the strengths of classical planners into large language models, and is able to provide optimal solutions for most problems, while LLMs fail to provide even feasible plans for most Problems.</p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have demonstrated remarkable zero-shot generalization abilities: state-of-the-art chatbots can provide plausible answers to many common questions that arise in daily life. However, so far, LLMs cannot reliably solve long-horizon planning problems. By contrast, classical planners, once a problem is given in a formatted way, can use efficient search algorithms to quickly identify correct, or even optimal, plans. In an effort to get the best of both worlds, this paper introduces LLM+P, the first framework that incorporates the strengths of classical planners into LLMs. LLM+P takes in a natural language description of a planning problem, then returns a correct (or optimal) plan for solving that problem in natural language. LLM+P does so by first converting the language description into a file written in the planning domain definition language (PDDL), then leveraging classical planners to quickly find a solution, and then translating the found solution back into natural language. Along with LLM+P, we define a diverse set of different benchmark problems taken from common planning scenarios. Via a comprehensive set of experiments on these benchmark problems, we find that LLM+P is able to provide optimal solutions for most problems, while LLMs fail to provide even feasible plans for most problems.\footnote{The code and results are publicly available at https://github.com/Cranial-XIX/llm-pddl.git.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1001.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1001.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM+P</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM+P (Large Language Model + Planner)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pipeline that uses an LLM to translate natural-language planning problems into PDDL problem files, calls a classical PDDL planner (Fast-Downward) to compute optimal/suboptimal plans, and uses the LLM to translate the resulting PDDL plan back to natural language or robot actions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM+P</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>LLM+P uses an LLM (GPT-4 in the experiments) to convert a natural-language description of a planning instance into a PDDL problem file (leveraging in-context learning with an example (problem, PDDL) pair), feeds this problem file together with a provided domain PDDL file to a classical planner (FAST-DOWNWARD, using aliases SEQ-OPT-FDSS-1 for guaranteed optimal search and LAMA for heuristic search), and then translates the returned PDDL plan back into natural language (or connects to robot action executors). It assumes a human-provided domain PDDL and a simple demonstration PDDL example as context.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>PDDL (classical symbolic representation)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>World is represented in PDDL: a domain file specifies predicates and lifted action schemas (preconditions and effects) encoding the transition function; a problem file lists objects, a grounded initial state (conjunction of predicates) and goal conditions. The representation used in this work is deterministic (classical PDDL); state transitions are encoded as deterministic operator effects. The framework grounds the lifted domain with objects from the generated problem file before planning.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td>Translate natural-language problem to PDDL problem file (problem construction) and translate PDDL plans back to natural language; perform in-context learning for formatting.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Classical symbolic planning via FAST-DOWNWARD (aliases used: SEQ-OPT-FDSS-1 for optimal search; LAMA for heuristic/suboptimal search).</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td>Seven robot planning domains (BlockSWORLD, BARMAN, Floortile, GRIPPERS, Storage, TERMES, TyReWorld) drawn from IPC-style generated PDDL benchmarks</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>A collection of robot planning benchmark domains (blocks manipulation, bartending, floor-tile painting, multi-gripper transport, crate storage with hoists, structure building, tire-repair tasks). Each problem has a natural-language description and a ground-truth PDDL problem file; domains vary in horizon length and relational/spatial complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Success rate (%) of producing correct (optimal) plans within a 200s planner time limit; for robot demo, plan cost (total-cost) comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Per-domain LLM+P optimal success rates reported in Table I: BARMAN 20% (LAMA suboptimal success 100%), BlockSWORLD 90%, Floortile 0%, GRIPPERS 95% (100% with suboptimal alias), Storage 85%, TERMES 20%, TyReWorld 10% (90% with suboptimal alias). Robot tidy-up demo: optimal plan cost 22 vs LLM-AS-P suboptimal cost 31.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against direct LLM planning (LLM-AS-P variants) and Tree of Thoughts (ToT) adaptation: e.g., in BlockSWORLD LLM (15% optimal, 30% correct including suboptimal) vs LLM+P 90% optimal; in GRIPPERS LLM variants 25-35% vs LLM+P 95%. See Table I for per-domain baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Paper includes ablation regarding context: LLM+P fails frequently without an example (problem,PDDL) context — context is crucial. No ablation comparing with/without explicit uncertainty modeling of LLM outputs or probabilistic world models.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using an LLM as a translator into PDDL plus a classical planner yields substantially higher correctness and (often) optimal plans than relying on LLMs alone for planning. The approach does not model LLM uncertainty or probabilistic effects in the world model — failures are primarily due to mis-specified/generated PDDL (missing initial facts) rather than planner inability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1001.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1001.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PDDL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Planning Domain Definition Language</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A standardized symbolic language for encoding classical planning domains (action schemas, predicates) and problem instances (objects, initial state, goals).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Pddl-the planning domain definition language</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PDDL (domain + problem files)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PDDL expresses the world model as a domain file (lifted predicates and action schemas with preconditions and effects) and a problem file (objects, grounded initial predicates, and goal conditions). Planners take domain+problem PDDL to perform symbolic search over states represented as sets of ground predicates.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>PDDL (symbolic, lifted and grounded representations)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>States are factored and represented as sets of ground predicate literals; actions are operator schemas with preconditions and deterministic effects; the transition function is given by applying effects when preconditions hold. In the paper's use, PDDL is classical/deterministic (no PPDDL/probabilistic extensions are used).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Intended to be used with classical symbolic planners (heuristic-search planners such as FAST-DOWNWARD).</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>PDDL serves as the targeted symbolic world-model language that the LLM is asked to produce; correctness of generated PDDL is critical for planner success.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1001.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1001.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FAST-DOWNWARD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FAST-DOWNWARD planning system</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely used classical PDDL planner implementing heuristic search; used here to compute optimal or heuristic plans from generated PDDL.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The fast downward planning system</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>FAST-DOWNWARD (SEQ-OPT-FDSS-1, LAMA aliases)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A classical planning system that performs heuristic-search over grounded PDDL state spaces. In experiments the authors run FAST-DOWNWARD with an optimal alias (SEQ-OPT-FDSS-1) and a common heuristic alias (LAMA) with a 200s search cutoff to generate plans from LLM-generated PDDL problem files.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>PDDL (symbolic)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>Operates on grounded PDDL states represented by predicate sets; actions are deterministic operators whose preconditions/effects define transitions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Heuristic search planning (Fast-Downward engines: SEQ-OPT-FDSS-1 for optimal search; LAMA for heuristic/suboptimal search).</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td>Robot planning benchmark domains (as used by LLM+P)</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>See LLM+P entry: IPC-style generated robot planning domains used to evaluate planner when given correct PDDL.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Success rate (%) of finding a plan (optimal or suboptimal) within 200s</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>When provided correct problem PDDL (from LLM+P with correct generation), FAST-DOWNWARD finds optimal/suboptimal plans corresponding to the success rates reported for LLM+P (see LLM+P per-domain values).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Classical planners like FAST-DOWNWARD reliably produce optimal plans when supplied correct symbolic PDDL problem descriptions; the bottleneck is generating correct PDDL from noisy natural language via LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1001.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1001.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ToT (LLM-AS-P Tree of Thoughts)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tree of Thoughts (adapted for LLM-as-Planner, LLM-AS-P)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An adaptation of the Tree of Thoughts deliberative reasoning paradigm where the LLM is used to propose available actions at tree nodes and to evaluate/rank partial action sequences for planning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Tree of thoughts: Deliberate problem solving with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM-AS-P (Tree of Thoughts adaptation)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Authors adapted the breadth-first ToT algorithm for planning: at each tree node the LLM (GPT-4) is asked to list available actions and then to evaluate/rank partial plan paths on their likelihood of reaching the goal. This results in many LLM calls; the method uses LLM-produced likelihoods to guide search but does not employ an explicit symbolic PDDL world model for planning.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>implicit (LM-based), no explicit symbolic PDDL world model used in the ToT adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>The method relies on the LLM's internal knowledge and text-based simulation of partial plans; it does not maintain a formal lifted/grounded PDDL belief or PPDDL model. Partial plans are represented as text sequences evaluated by LLM likelihoods.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td>Action generation and partial-plan evaluation (scoring likelihood of reaching goal)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td>LLM-provided likelihood / ranking (informal)</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td>Likelihood-based ranking of partial plans from the LLM (used heuristically, not as formal probabilistic belief states)</td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Breadth-first Tree of Thoughts search adaptation (deliberative LLM-guided search)</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td>Same seven robot planning benchmark domains used in the paper</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>IPC-style robot planning benchmarks with relational/spatial structure; long horizons that make ToT expensive in calls/time.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Success rate (%) within 200s</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Poor performance overall (see Table I): ToT column shows near-zero success in most domains (e.g., BARMAN 0, BlockSWORLD 0 (5), Floortile 0, GRIPPERS 10 (20), Storage 0, TERMES 0, TyReWorld 0) and frequent timeouts due to many LLM calls.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to LLM direct planning and LLM+P: LLM+P substantially outperforms ToT; ToT sometimes ranks partial plans well but fails to determine goal attainment and often times out.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Authors observed ToT requires many LLM calls and times out in most long-horizon problems; LLM ranking of partial plans can be reasonable but insufficient to detect goal satisfaction.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>ToT-style deliberation relying solely on LLM judgments is not effective for these long-horizon symbolic planning benchmarks; integrating a symbolic planner (LLM+P) is more reliable and efficient.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1001.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1001.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SayCan</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Do as I can, not as I say: Grounding language in robotic affordances (SayCan)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior system that combines LLM scoring of natural language instructions with learned affordance models to select feasible robot actions from language commands.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Do as i can, not as i say: Grounding language in robotic affordances</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SayCan</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced as a related method that uses LLMs together with affordance functions to map natural language service requests to robot actions while accounting for action feasibility; the LLM provides language-derived priors/scores and the affordance/utility component grounds actions in robot capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>Affordance-based (not explicitly PDDL in the cited presentation); a hybrid of language priors and learned affordance scores</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>Not described in detail in this paper; SayCan uses affordance functions that estimate the feasibility/utility of actions given the current (perceived) state and uses LLM-derived language priors to rank actions. The representation is not presented here as a PPDDL/belief-state formalism.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td>Provide language priors/scores for actions and translate service requests</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td>Action feasibility / model uncertainty (affordance uncertainty); LLM confidence used as part of scoring</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td>Affordance function scores and ranking combining LLM-derived priors with learned feasibility estimates (described in the referenced work)</td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Affordance-guided action selection (not classical PDDL planning as described here)</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td>Service-robot instruction scenarios (referenced study)</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>Natural language service requests grounded to robot affordances in embodied robotic settings (not the IPC-style PDDL benchmarks used in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as related work that integrates LLM outputs with models of action feasibility (affordances) to account for uncertainty about action success; used as motivation for combining LLMs with external modules.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1001.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1001.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TAMP in Belief Space</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Integrated task and motion planning in belief space</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hierarchical planning framework that integrates discrete task planning and continuous motion planning while reasoning in belief space to handle state uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Integrated task and motion planning in belief space</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Task-and-Motion Planning in Belief Space</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced as prior work combining classical planning over discrete tasks with continuous motion planning while representing uncertainty about continuous states as belief distributions; used to plan under probabilistic uncertainty in robot execution.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>Belief space (probabilistic belief-state representation)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>Represents uncertainty over continuous states as probability distributions (beliefs); actions have probabilistic/uncertain outcomes and motion planning is done conditioned on belief updates. This is a probabilistic symbolic/continuous hybrid, not classical deterministic PDDL.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td>State (belief) uncertainty and aleatoric uncertainty in outcomes</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td>Belief-state representations (probability distributions over continuous state) and planning in belief space</td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Hierarchical task and motion planning in belief space (combines discrete task planners and continuous motion planners with belief propagation)</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as prior art that explicitly represents uncertainty via belief states for planning, illustrating a contrast to the deterministic PDDL-based planning employed in LLM+P.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1001.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1001.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Uncertainty Alignment for LLM Planners</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Robots that ask for help: Uncertainty alignment for large language model planners</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced work that studies aligning or handling uncertainty from LLM planners in robotic contexts (referenced in related work).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Robots that ask for help: Uncertainty alignment for large language model planners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Uncertainty alignment for LLM planners</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Mentioned in related work as an approach addressing uncertainty alignment for LLM-based planners; the paper investigates how to handle LLM uncertainty in robotic planning contexts (only cited; details not provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td>Planner / language-based planner component (as per the cited paper)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td>LLM output uncertainty / alignment-related uncertainty</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as related research that specifically considers uncertainty from LLM planners and methods to align or handle that uncertainty in robotic planning systems.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Integrated task and motion planning in belief space <em>(Rating: 2)</em></li>
                <li>Do as i can, not as i say: Grounding language in robotic affordances <em>(Rating: 2)</em></li>
                <li>Pddl-the planning domain definition language <em>(Rating: 2)</em></li>
                <li>PDDL planning with pretrained large language models <em>(Rating: 2)</em></li>
                <li>Leveraging pre-trained large language models to construct and utilize world models for model-based task planning <em>(Rating: 2)</em></li>
                <li>Autotamp: Autoregressive task and motion planning with llms as translators and checkers <em>(Rating: 2)</em></li>
                <li>Tree of thoughts: Deliberate problem solving with large language models <em>(Rating: 1)</em></li>
                <li>Robots that ask for help: Uncertainty alignment for large language model planners <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1001",
    "paper_id": "paper-003ef1cd670d01af05afa0d3c72d72228f494432",
    "extraction_schema_id": "extraction-schema-23",
    "extracted_data": [
        {
            "name_short": "LLM+P",
            "name_full": "LLM+P (Large Language Model + Planner)",
            "brief_description": "A pipeline that uses an LLM to translate natural-language planning problems into PDDL problem files, calls a classical PDDL planner (Fast-Downward) to compute optimal/suboptimal plans, and uses the LLM to translate the resulting PDDL plan back to natural language or robot actions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "LLM+P",
            "system_description": "LLM+P uses an LLM (GPT-4 in the experiments) to convert a natural-language description of a planning instance into a PDDL problem file (leveraging in-context learning with an example (problem, PDDL) pair), feeds this problem file together with a provided domain PDDL file to a classical planner (FAST-DOWNWARD, using aliases SEQ-OPT-FDSS-1 for guaranteed optimal search and LAMA for heuristic search), and then translates the returned PDDL plan back into natural language (or connects to robot action executors). It assumes a human-provided domain PDDL and a simple demonstration PDDL example as context.",
            "world_model_type": "PDDL (classical symbolic representation)",
            "world_model_description": "World is represented in PDDL: a domain file specifies predicates and lifted action schemas (preconditions and effects) encoding the transition function; a problem file lists objects, a grounded initial state (conjunction of predicates) and goal conditions. The representation used in this work is deterministic (classical PDDL); state transitions are encoded as deterministic operator effects. The framework grounds the lifted domain with objects from the generated problem file before planning.",
            "uses_llm": true,
            "llm_role": "Translate natural-language problem to PDDL problem file (problem construction) and translate PDDL plans back to natural language; perform in-context learning for formatting.",
            "llm_model_name": "GPT-4",
            "uncertainty_modeling": false,
            "uncertainty_type": "",
            "uncertainty_method": "",
            "planning_algorithm": "Classical symbolic planning via FAST-DOWNWARD (aliases used: SEQ-OPT-FDSS-1 for optimal search; LAMA for heuristic/suboptimal search).",
            "planning_integrates_uncertainty": false,
            "text_environment_name": "Seven robot planning domains (BlockSWORLD, BARMAN, Floortile, GRIPPERS, Storage, TERMES, TyReWorld) drawn from IPC-style generated PDDL benchmarks",
            "text_environment_description": "A collection of robot planning benchmark domains (blocks manipulation, bartending, floor-tile painting, multi-gripper transport, crate storage with hoists, structure building, tire-repair tasks). Each problem has a natural-language description and a ground-truth PDDL problem file; domains vary in horizon length and relational/spatial complexity.",
            "performance_metric": "Success rate (%) of producing correct (optimal) plans within a 200s planner time limit; for robot demo, plan cost (total-cost) comparison.",
            "performance_value": "Per-domain LLM+P optimal success rates reported in Table I: BARMAN 20% (LAMA suboptimal success 100%), BlockSWORLD 90%, Floortile 0%, GRIPPERS 95% (100% with suboptimal alias), Storage 85%, TERMES 20%, TyReWorld 10% (90% with suboptimal alias). Robot tidy-up demo: optimal plan cost 22 vs LLM-AS-P suboptimal cost 31.",
            "baseline_comparison": "Compared against direct LLM planning (LLM-AS-P variants) and Tree of Thoughts (ToT) adaptation: e.g., in BlockSWORLD LLM (15% optimal, 30% correct including suboptimal) vs LLM+P 90% optimal; in GRIPPERS LLM variants 25-35% vs LLM+P 95%. See Table I for per-domain baselines.",
            "has_ablation_uncertainty": false,
            "ablation_results": "Paper includes ablation regarding context: LLM+P fails frequently without an example (problem,PDDL) context — context is crucial. No ablation comparing with/without explicit uncertainty modeling of LLM outputs or probabilistic world models.",
            "key_findings": "Using an LLM as a translator into PDDL plus a classical planner yields substantially higher correctness and (often) optimal plans than relying on LLMs alone for planning. The approach does not model LLM uncertainty or probabilistic effects in the world model — failures are primarily due to mis-specified/generated PDDL (missing initial facts) rather than planner inability.",
            "uuid": "e1001.0",
            "source_info": {
                "paper_title": "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "PDDL",
            "name_full": "Planning Domain Definition Language",
            "brief_description": "A standardized symbolic language for encoding classical planning domains (action schemas, predicates) and problem instances (objects, initial state, goals).",
            "citation_title": "Pddl-the planning domain definition language",
            "mention_or_use": "use",
            "system_name": "PDDL (domain + problem files)",
            "system_description": "PDDL expresses the world model as a domain file (lifted predicates and action schemas with preconditions and effects) and a problem file (objects, grounded initial predicates, and goal conditions). Planners take domain+problem PDDL to perform symbolic search over states represented as sets of ground predicates.",
            "world_model_type": "PDDL (symbolic, lifted and grounded representations)",
            "world_model_description": "States are factored and represented as sets of ground predicate literals; actions are operator schemas with preconditions and deterministic effects; the transition function is given by applying effects when preconditions hold. In the paper's use, PDDL is classical/deterministic (no PPDDL/probabilistic extensions are used).",
            "uses_llm": null,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": false,
            "uncertainty_type": "",
            "uncertainty_method": "",
            "planning_algorithm": "Intended to be used with classical symbolic planners (heuristic-search planners such as FAST-DOWNWARD).",
            "planning_integrates_uncertainty": false,
            "text_environment_name": null,
            "text_environment_description": null,
            "performance_metric": null,
            "performance_value": null,
            "baseline_comparison": null,
            "has_ablation_uncertainty": null,
            "ablation_results": null,
            "key_findings": "PDDL serves as the targeted symbolic world-model language that the LLM is asked to produce; correctness of generated PDDL is critical for planner success.",
            "uuid": "e1001.1",
            "source_info": {
                "paper_title": "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "FAST-DOWNWARD",
            "name_full": "FAST-DOWNWARD planning system",
            "brief_description": "A widely used classical PDDL planner implementing heuristic search; used here to compute optimal or heuristic plans from generated PDDL.",
            "citation_title": "The fast downward planning system",
            "mention_or_use": "use",
            "system_name": "FAST-DOWNWARD (SEQ-OPT-FDSS-1, LAMA aliases)",
            "system_description": "A classical planning system that performs heuristic-search over grounded PDDL state spaces. In experiments the authors run FAST-DOWNWARD with an optimal alias (SEQ-OPT-FDSS-1) and a common heuristic alias (LAMA) with a 200s search cutoff to generate plans from LLM-generated PDDL problem files.",
            "world_model_type": "PDDL (symbolic)",
            "world_model_description": "Operates on grounded PDDL states represented by predicate sets; actions are deterministic operators whose preconditions/effects define transitions.",
            "uses_llm": false,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": false,
            "uncertainty_type": "",
            "uncertainty_method": "",
            "planning_algorithm": "Heuristic search planning (Fast-Downward engines: SEQ-OPT-FDSS-1 for optimal search; LAMA for heuristic/suboptimal search).",
            "planning_integrates_uncertainty": false,
            "text_environment_name": "Robot planning benchmark domains (as used by LLM+P)",
            "text_environment_description": "See LLM+P entry: IPC-style generated robot planning domains used to evaluate planner when given correct PDDL.",
            "performance_metric": "Success rate (%) of finding a plan (optimal or suboptimal) within 200s",
            "performance_value": "When provided correct problem PDDL (from LLM+P with correct generation), FAST-DOWNWARD finds optimal/suboptimal plans corresponding to the success rates reported for LLM+P (see LLM+P per-domain values).",
            "baseline_comparison": null,
            "has_ablation_uncertainty": null,
            "ablation_results": null,
            "key_findings": "Classical planners like FAST-DOWNWARD reliably produce optimal plans when supplied correct symbolic PDDL problem descriptions; the bottleneck is generating correct PDDL from noisy natural language via LLMs.",
            "uuid": "e1001.2",
            "source_info": {
                "paper_title": "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "ToT (LLM-AS-P Tree of Thoughts)",
            "name_full": "Tree of Thoughts (adapted for LLM-as-Planner, LLM-AS-P)",
            "brief_description": "An adaptation of the Tree of Thoughts deliberative reasoning paradigm where the LLM is used to propose available actions at tree nodes and to evaluate/rank partial action sequences for planning.",
            "citation_title": "Tree of thoughts: Deliberate problem solving with large language models",
            "mention_or_use": "use",
            "system_name": "LLM-AS-P (Tree of Thoughts adaptation)",
            "system_description": "Authors adapted the breadth-first ToT algorithm for planning: at each tree node the LLM (GPT-4) is asked to list available actions and then to evaluate/rank partial plan paths on their likelihood of reaching the goal. This results in many LLM calls; the method uses LLM-produced likelihoods to guide search but does not employ an explicit symbolic PDDL world model for planning.",
            "world_model_type": "implicit (LM-based), no explicit symbolic PDDL world model used in the ToT adaptation",
            "world_model_description": "The method relies on the LLM's internal knowledge and text-based simulation of partial plans; it does not maintain a formal lifted/grounded PDDL belief or PPDDL model. Partial plans are represented as text sequences evaluated by LLM likelihoods.",
            "uses_llm": true,
            "llm_role": "Action generation and partial-plan evaluation (scoring likelihood of reaching goal)",
            "llm_model_name": "GPT-4",
            "uncertainty_modeling": false,
            "uncertainty_type": "LLM-provided likelihood / ranking (informal)",
            "uncertainty_method": "Likelihood-based ranking of partial plans from the LLM (used heuristically, not as formal probabilistic belief states)",
            "planning_algorithm": "Breadth-first Tree of Thoughts search adaptation (deliberative LLM-guided search)",
            "planning_integrates_uncertainty": false,
            "text_environment_name": "Same seven robot planning benchmark domains used in the paper",
            "text_environment_description": "IPC-style robot planning benchmarks with relational/spatial structure; long horizons that make ToT expensive in calls/time.",
            "performance_metric": "Success rate (%) within 200s",
            "performance_value": "Poor performance overall (see Table I): ToT column shows near-zero success in most domains (e.g., BARMAN 0, BlockSWORLD 0 (5), Floortile 0, GRIPPERS 10 (20), Storage 0, TERMES 0, TyReWorld 0) and frequent timeouts due to many LLM calls.",
            "baseline_comparison": "Compared to LLM direct planning and LLM+P: LLM+P substantially outperforms ToT; ToT sometimes ranks partial plans well but fails to determine goal attainment and often times out.",
            "has_ablation_uncertainty": false,
            "ablation_results": "Authors observed ToT requires many LLM calls and times out in most long-horizon problems; LLM ranking of partial plans can be reasonable but insufficient to detect goal satisfaction.",
            "key_findings": "ToT-style deliberation relying solely on LLM judgments is not effective for these long-horizon symbolic planning benchmarks; integrating a symbolic planner (LLM+P) is more reliable and efficient.",
            "uuid": "e1001.3",
            "source_info": {
                "paper_title": "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "SayCan",
            "name_full": "Do as I can, not as I say: Grounding language in robotic affordances (SayCan)",
            "brief_description": "A prior system that combines LLM scoring of natural language instructions with learned affordance models to select feasible robot actions from language commands.",
            "citation_title": "Do as i can, not as i say: Grounding language in robotic affordances",
            "mention_or_use": "mention",
            "system_name": "SayCan",
            "system_description": "Referenced as a related method that uses LLMs together with affordance functions to map natural language service requests to robot actions while accounting for action feasibility; the LLM provides language-derived priors/scores and the affordance/utility component grounds actions in robot capabilities.",
            "world_model_type": "Affordance-based (not explicitly PDDL in the cited presentation); a hybrid of language priors and learned affordance scores",
            "world_model_description": "Not described in detail in this paper; SayCan uses affordance functions that estimate the feasibility/utility of actions given the current (perceived) state and uses LLM-derived language priors to rank actions. The representation is not presented here as a PPDDL/belief-state formalism.",
            "uses_llm": true,
            "llm_role": "Provide language priors/scores for actions and translate service requests",
            "llm_model_name": null,
            "uncertainty_modeling": true,
            "uncertainty_type": "Action feasibility / model uncertainty (affordance uncertainty); LLM confidence used as part of scoring",
            "uncertainty_method": "Affordance function scores and ranking combining LLM-derived priors with learned feasibility estimates (described in the referenced work)",
            "planning_algorithm": "Affordance-guided action selection (not classical PDDL planning as described here)",
            "planning_integrates_uncertainty": true,
            "text_environment_name": "Service-robot instruction scenarios (referenced study)",
            "text_environment_description": "Natural language service requests grounded to robot affordances in embodied robotic settings (not the IPC-style PDDL benchmarks used in this paper).",
            "performance_metric": null,
            "performance_value": null,
            "baseline_comparison": null,
            "has_ablation_uncertainty": null,
            "ablation_results": null,
            "key_findings": "Mentioned as related work that integrates LLM outputs with models of action feasibility (affordances) to account for uncertainty about action success; used as motivation for combining LLMs with external modules.",
            "uuid": "e1001.4",
            "source_info": {
                "paper_title": "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "TAMP in Belief Space",
            "name_full": "Integrated task and motion planning in belief space",
            "brief_description": "A hierarchical planning framework that integrates discrete task planning and continuous motion planning while reasoning in belief space to handle state uncertainty.",
            "citation_title": "Integrated task and motion planning in belief space",
            "mention_or_use": "mention",
            "system_name": "Task-and-Motion Planning in Belief Space",
            "system_description": "Referenced as prior work combining classical planning over discrete tasks with continuous motion planning while representing uncertainty about continuous states as belief distributions; used to plan under probabilistic uncertainty in robot execution.",
            "world_model_type": "Belief space (probabilistic belief-state representation)",
            "world_model_description": "Represents uncertainty over continuous states as probability distributions (beliefs); actions have probabilistic/uncertain outcomes and motion planning is done conditioned on belief updates. This is a probabilistic symbolic/continuous hybrid, not classical deterministic PDDL.",
            "uses_llm": null,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": true,
            "uncertainty_type": "State (belief) uncertainty and aleatoric uncertainty in outcomes",
            "uncertainty_method": "Belief-state representations (probability distributions over continuous state) and planning in belief space",
            "planning_algorithm": "Hierarchical task and motion planning in belief space (combines discrete task planners and continuous motion planners with belief propagation)",
            "planning_integrates_uncertainty": true,
            "text_environment_name": null,
            "text_environment_description": null,
            "performance_metric": null,
            "performance_value": null,
            "baseline_comparison": null,
            "has_ablation_uncertainty": null,
            "ablation_results": null,
            "key_findings": "Cited as prior art that explicitly represents uncertainty via belief states for planning, illustrating a contrast to the deterministic PDDL-based planning employed in LLM+P.",
            "uuid": "e1001.5",
            "source_info": {
                "paper_title": "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "Uncertainty Alignment for LLM Planners",
            "name_full": "Robots that ask for help: Uncertainty alignment for large language model planners",
            "brief_description": "A referenced work that studies aligning or handling uncertainty from LLM planners in robotic contexts (referenced in related work).",
            "citation_title": "Robots that ask for help: Uncertainty alignment for large language model planners",
            "mention_or_use": "mention",
            "system_name": "Uncertainty alignment for LLM planners",
            "system_description": "Mentioned in related work as an approach addressing uncertainty alignment for LLM-based planners; the paper investigates how to handle LLM uncertainty in robotic planning contexts (only cited; details not provided in this paper).",
            "world_model_type": null,
            "world_model_description": null,
            "uses_llm": true,
            "llm_role": "Planner / language-based planner component (as per the cited paper)",
            "llm_model_name": null,
            "uncertainty_modeling": true,
            "uncertainty_type": "LLM output uncertainty / alignment-related uncertainty",
            "uncertainty_method": null,
            "planning_algorithm": null,
            "planning_integrates_uncertainty": true,
            "text_environment_name": null,
            "text_environment_description": null,
            "performance_metric": null,
            "performance_value": null,
            "baseline_comparison": null,
            "has_ablation_uncertainty": null,
            "ablation_results": null,
            "key_findings": "Cited as related research that specifically considers uncertainty from LLM planners and methods to align or handle that uncertainty in robotic planning systems.",
            "uuid": "e1001.6",
            "source_info": {
                "paper_title": "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency",
                "publication_date_yy_mm": "2023-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Integrated task and motion planning in belief space",
            "rating": 2
        },
        {
            "paper_title": "Do as i can, not as i say: Grounding language in robotic affordances",
            "rating": 2
        },
        {
            "paper_title": "Pddl-the planning domain definition language",
            "rating": 2
        },
        {
            "paper_title": "PDDL planning with pretrained large language models",
            "rating": 2
        },
        {
            "paper_title": "Leveraging pre-trained large language models to construct and utilize world models for model-based task planning",
            "rating": 2
        },
        {
            "paper_title": "Autotamp: Autoregressive task and motion planning with llms as translators and checkers",
            "rating": 2
        },
        {
            "paper_title": "Tree of thoughts: Deliberate problem solving with large language models",
            "rating": 1
        },
        {
            "paper_title": "Robots that ask for help: Uncertainty alignment for large language model planners",
            "rating": 1
        }
    ],
    "cost": 0.022366999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>LLM+P: Empowering Large Language Models with Optimal Planning Proficiency</h1>
<p>Bo Liu ${ }^{<em> \dagger}$, Yuqian Jiang ${ }^{</em> \dagger}$, Xiaohan Zhang ${ }^{\ddagger}$, Qiang Liu ${ }^{\dagger}$, Shiqi Zhang ${ }^{\ddagger}$, Joydeep Biswas ${ }^{\dagger}$, Peter Stone ${ }^{\dagger \S}$</p>
<h4>Abstract</h4>
<p>Large language models (LLMs) have demonstrated remarkable zero-shot generalization abilities: state-of-the-art chatbots can provide plausible answers to many common questions that arise in daily life. However, so far, LLMs cannot reliably solve long-horizon robot planning problems. By contrast, classical planners, once a problem is given in a formatted way, can use efficient search algorithms to quickly identify correct, or even optimal, plans. In an effort to get the best of both worlds, this paper introduces LLM+P, the first framework that incorporates the strengths of classical planners into LLMs. LLM+P takes in a natural language description of a planning problem, then returns a correct (or optimal) plan for solving that problem in natural language. LLM+P does so by first converting the language description into a file written in the planning domain definition language (PDDL), then leveraging classical planners to quickly find a solution, and then translating the found solution back into natural language. Along with LLM+P, we define a diverse set of different benchmark problems taken from robot planning scenarios. Via a comprehensive set of experiments on these benchmark problems, we find that LLM+P is able to provide optimal solutions for most problems, while LLMs fail to provide even feasible plans for most problems. We also show LLM+P enables a home robot to solve a complex manipulation task that is specified by the user in natural language. ${ }^{\dagger}$</p>
<h2>I. INTRODUCTION</h2>
<p>Ever since the birth of the field, AI researchers have sought to create programs that can converse in natural language with the same grace and flexibility as people. While even relatively simple models, such as Eliza from 1966 [1], can generate responses to some prompts that seem reasonable, it has always been relatively easy to generate prompts that expose their weaknesses compared to people - their lack of true "understanding."</p>
<p>While large language models (LLMs) such as GPT-4 [2] and ChatGPT [3] have far surpassed expectations of just a few years ago, they are no different in this respect. Indeed the internet is now awash with examples of people reveling in getting ChatGPT to generate output that even a 5-year-old human child would know to be ill-advised.</p>
<p>Given how LLMs are designed and trained, this phenomenon should come as no surprise. They are not specifically built to demonstrate understanding. They are trained</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>to generate sequences of words that might be plausible to a human given a prior context. In the terms of Mahowald et al. [4] LLMs have become amazingly proficient at linguistic competence - knowing how to say things; but they are not nearly as good at functional competence - knowing what to say. Specifically, they can be (relatively) easily fooled by, for example, asking for the result of a straightforward arithmetic problem that does not appear in their training corpus or by asking for the solution to a novel planning problem that requires knowledge about how the world works.</p>
<h2>A Failure Example of GPT-4 in Planning</h2>
<p>Problem (P1): You have 5 blocks. One cannot place more than one block on another block. b5 is on top of b3. b4 is on top of b2. b2 is on top of b1. b3 is on top of b4. b1 is on the table. b5 is clear. Your arm is empty.
Your goal is to move the blocks. b1 should be on top of b2. b3 should be on top of b5. b4 should be on top of b1.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>GPT-4:</p>
<ol>
<li>Move b5 from b3 to the table.</li>
<li>Move b3 from b4 to b5.</li>
<li>Move b4 from b2 to the table.</li>
<li>Move b2 from b1 to b5.</li>
<li>Move b1 from the table to b2.</li>
<li>Move b4 from the table to b1.</li>
</ol>
<p>Does that mean that we should increase efforts to include all arithmetic and planning problems in their training corpus? Clearly, that is a fool's errand. On the other hand, why should it be necessary? We already have calculators and generalpurpose symbolic planners that are guaranteed to produce correct answers. Thus a natural alternative approach, and one that we are admittedly not the first to explore, is to connect LLMs to such tools.</p>
<p>With this motivation in mind, the objective of the research reported in this paper is, for the first time, to enable LLMs to solve planning problems correctly. We aim to do so without altering the LLMs themselves, even with finetuning [5], [6]. Rather, we introduce a methodology, called LLM+P by which, when posed a natural language description of a planning problem, the LLM:</p>
<p>1) outputs a problem description suitable as input to a</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 1: LLM+P makes use of a large language model (LLM) to produce the PDDL description of the given problem, then leverages a classical planner for finding an <em>optimal</em> plan, then translates the raw plan back to natural language using the LLM again.</p>
<p>general-purpose planner;</p>
<p>2) solves the problem using the general-purpose planner; and</p>
<p>3) converts the output of the planner back to natural language (or connects to action executors of a robot).</p>
<p>Our extensive empirical evaluations indicate that LLM+P is able to generate correct solutions to many more planning problems than are LLMs on their own. While demonstrated in this paper on planning problems, this general methodology can be applied to any class of problems for which we have a sound and complete solver, such as arithmetic problems (by leveraging calculators).</p>
<p><strong>Limitation:</strong> In this paper, we do not ask the LLM to <em>recognize</em> that it has been posed a prompt that is suitable for processing using the proposed LLM+P pipeline. A valuable future research direction will be to consider recognizing when a prompt should be processed by LLM+P.</p>
<h2>II. BACKGROUND</h2>
<p>This section introduces the notation we use for representing a planning problem to be solved by LLMs, and recaps the standard representation of classical planners.</p>
<h3>A. The Classical Planning Problem</h3>
<p>Formally, the input of a planning problem <em>P</em> is defined by a tuple $\langle\mathscr{S}, s^{init},\mathscr{S}^{G},\mathscr{A}, f\rangle$:</p>
<ul>
<li>$\mathscr{S}$ is a finite and discrete set of states used to describe the world's state (i.e., state space). We assume a factored state space such that each state $s \in \mathscr{S}$ is defined by the values of a fixed set of variables.</li>
<li>$s^{init} \in \mathscr{S}$ is an initial world state.</li>
<li>$\mathscr{S}^{G} \subset \mathscr{S}$ is a set of goal states. $\mathscr{S}^{G}$ are usually specified as a list of <em>goal conditions</em>, all of which must hold in a goal state.</li>
<li>$\mathscr{A}$ is a set of symbolic actions.</li>
<li>$f$ is the underlying state transition function. $f$ takes the current state and an action as input and outputs the corresponding next state.</li>
</ul>
<p>A solution to a planning problem <em>P</em> is a symbolic plan $\pi$ in the form of $\langle a_1, a_2, \ldots, a_N \rangle$, such that the preconditions of $a_1$ hold in $s^{init}$, the preconditions of $a_2$ hold in the state that results from applying $a_1$, and so on, with the goal conditions all holding in the state that results after applying $a_N$.</p>
<h3>B. Planning Domain Definition Language (PDDL)</h3>
<p>The planning domain definition language (PDDL) serves as a standardized encoding of classical planning problems [7], [8]. The PDDL representation of a planning problem <em>P</em> is separated into two files: a domain file and a problem file. The domain PDDL file provides a lifted representation of the underlying rules of the world. It includes a set of predicates that define the state space $\mathscr{S}$ and the actions (i.e., $\mathscr{A}$) with their preconditions and effects (i.e., the transition function $f$). The problem PDDL file provides a list of objects to ground the domain, the problem's initial state $s^{init}$ and goal conditions $\mathscr{S}^{G}$. There exists a rich set of symbolic planners that implement efficient search algorithms to solve planning problems formalized in PDDL. In this work, we aim to take a natural language prompt which describes the initial state $s^{init}$ and goal conditions $\mathscr{S}^{G}$, formulate it in PDDL,</p>
<p>and leverage symbolic planners to output correct plans. We assume the domain rules are available (See the assumptions in Section III).</p>
<h2>III. Method</h2>
<p>This section first uses a running example to investigate ways for formulating planning prompts in PDDL and then introduces the LLM+P method.</p>
<h2>A. Large Language Model as a PDDL Writer</h2>
<p>LLMs are bad at planning (or long-horizon reasoning) [9] but they are good at describing and translating textual inputs, including re-writing planning prompts in the PDDL format. The intuition is that we can view PDDL as a different language than English, so re-writing planning prompts in PDDL is essentially a "machine translation" task that LLMs are known to excel at. Here we provide an example of a PDDL problem file written by GPT-4 without any promptengineering. As we see, the generated file appears to have the correct PDDL syntax but uses a made-up predicate (empty) and misses the initial condition that b1 is on the table.</p>
<h2>An Example PDDL Problem File Written by GPT-4</h2>
<p>Prompt: Description of Problem (P1) + Provide me with the problem PDDL file that describes the planning problem directly without further explanations.</p>
<h2>GPT-4 (the generated problem PDDL):</h2>
<p>(:objects b1 b2 b3 b4 b5 - block)
(:init (on b5 b3) (on b4 b2) (on b2
b1) (on b3 b4) (clear b5) (empty))
(:goal (and (on b1 b2) (on b3 b5)
(on b4 b1)))</p>
<h2>B. In-Context Learning</h2>
<p>LLMs are known to be capable of in-context learning without finetuning their parameters. By in-context learning, we mean LLMs' ability to perform unseen downstream tasks by simply conditioning on a few input-label pairs (demonstrations) [10]. Here is a pair of problem descriptions in natural language and in PDDL provided to GPT-4 as context. When the context is included with the prompt from the example above, the resulting PDDL problem file is directly solvable by the planner.</p>
<h2>An Example PDDL Problem File Written by GPT-4 with Context</h2>
<h2>Context (shaded):</h2>
<p>An example planning problem is: You have 5 blocks. b2 is on top of b5. b5 is on top of b1. b1 is on top of b4. b3 is on top of b2. b4 is on the table. b3 is clear. Your arm is empty. Your goal is to move the blocks. b4 should be on top of b3. The problem PDDL is:
(:objects b1 b2 b3 b4 b5)
(:init (arm-empty) (on b1 b4) (on
b2 b5) (on b3 b2)
(on-table b4) (on b5 b1)
(clear b3))
(:goal (and (on b4 b3))))
Prompt: Description of Problem (P1) + Context + Provide me with the problem PDDL file that describes the planning problem directly without further explanations.</p>
<h2>GPT-4 (the generated problem PDDL):</h2>
<p>(:objects b1 b2 b3 b4 b5 )
(:init (arm-empty) (on-table b1)
(on b2 b1) (on b3 b4)
(on b4 b2) (on b5 b3) (clear
b5)))
(:goal (and (on b1 b2) (on b3 b5)
(on b4 b1)))</p>
<h2>Planner:</h2>
<p>(unstack b5 b3) (putdown b5)
(unstack b3 b4) (stack b3 b5)
(unstack b4 b2) (putdown b4)
(unstack b2 b1) (putdown b2)
(pickup b1) (stack b1 b2) (pickup
b4) (stack b4 b1)</p>
<h2>C. Large Language Model + Classical Planner (LLM+P)</h2>
<p>Having introduced the LLM's ability to encode problems in PDDL and in-context learning, we are ready to introduce the proposed LLM+P solution (the bottom of Fig. 1). In particular, we assume that for each problem domain, a human expert can provide a domain description (i.e. action preconditions and effects) that will be fixed for all problem instances that happen in that domain. While the problem of automatically generating the description is another valuable research question, in this proposed work, we assume that the description is available as a PDDL domain file. The LLM+P method is directly applicable as a natural language interface for giving tasks to robot systems. For instance, assume we want a robot to act as a bartender to make cocktails. It is reasonable to tell it what actions it can take, but leave itself to infer how to make new cocktails most efficiently given a set of ingredients to combine. Moreover, we assume the agent is provided with a minimal example that demonstrates what an example problem PDDL looks like for a simple</p>
<p>problem inside that domain. Next, the agent is provided with a new (potentially quite complicated) problem $(P)$. The LLM then uses the in-context learning to infer the problem PDDL file corresponding to $P$. Once the problem PDDL file is generated, we feed it into any classical planner, together with the provided domain PDDL file, to generate a PDDL plan [11]. In the end, the LLM translates the PDDL plan back into the natural language to finish up the LLM+P pipeline. To summarize, the assumptions we need for LLM+P are:</p>
<ol>
<li>A robot knows when to trigger LLM+P based on its conversation with a human user.</li>
<li>A domain PDDL is provided to define the actions that the robot is capable of. This specification is taskagnostic - the entities relevant to the task are specified in the LLM-generated problem PDDL.</li>
<li>A simple problem description in natural language and its corresponding problem PDDL file are also provided.</li>
</ol>
<h2>IV. Related Work</h2>
<p>This section first provides a brief overview of classical planning algorithms. Then it summarizes recent advances in using large language models for planning tasks. It concludes with a discussion of recent research on augmenting LLMs with external modules.</p>
<h2>A. Classical Planning</h2>
<p>Automated planning (or classical planning) techniques can be used for computing a sequence of actions that achieves a given goal [12], [13], [14]. Automated planning algorithms have been widely used in robot systems. Shakey is the first robot that was equipped with a planning component, which was constructed using STRIPS [15]. Some previous generalpurpose planning architectures were also demonstrated to be useful for robot planning, such as PRODIGY [16] and HTN [17]. Recent classical planning systems designed for robotics frequently use planning domain description language (PDDL) or answer set programming (ASP) as the underlying action language for the planners [18], [19], [20], [21]. For example, researchers have used classical planning algorithms for sequencing actions for a mobile robot working on delivery tasks [22], reasoning about safe and efficient urban driving behaviors for autonomous vehicles [23], and planning actions for a team of mobile robots [24]. Task and motion planning (TAMP) is a hierarchical planning framework that combines classical planning in discrete spaces and robot motion planning in continuous space [25], [26].</p>
<p>Most of the above-mentioned planning methods require domain-specific programming languages as the underlying representation of the problems and their solutions. LLM+P, on the other hand, takes advantage of LLMs and serves as a natural language interface for robots to solve complex planning tasks. The main feature that motivates us to use such classical planning systems is that most of these planners are sound and complete, meaning that they are guaranteed to be logically correct and will output a plan if one exists. Many are also able to find optimal (shortest) plans, at least if given sufficient time.</p>
<h2>B. Planning with Large Language Models</h2>
<p>Various large language models (LLMs) have been developed in recent years, such as Bert [27], CodeX [28], Opt [29], GPT-3 [10], ChatGPT [30], GPT-4 [2], Llama [31], Llama2 [32], and PaLM [33]. As LLMs are pretrained with a tremendous amount of offline text data, they can emerge with surprising zero-shot generalization ability, which can be leveraged for robot planning tasks [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45]. Several recent methods had successes in extracting task knowledge from LLMs to decompose commands or instructions for robots in natural language. For instance, the work of Huang et al. showed that LLMs can be used for task planning in household domains by iteratively augmenting prompts [38]. SayCan is another approach that enabled robot planning with affordance functions to account for action feasibility, where the service requests are specified in natural language [34]. Vemprala et al. recently studied how ChatGPT can be applied to generalized robotics domains [3].</p>
<p>However, a major drawback of existing LLMs is their lack of long-horizon reasoning ability for complex tasks (See [9], [46] and Section 8.2 from [2]). Specifically, the output they produce when presented with such a task is often incorrect in the sense that following the output plan will not actually solve the task. Therefore, in this work, we focus on resolving this issue by leveraging the properties of classical planners. Similarly, some recent work also investigates approaches for combining classical planning with LLMs [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57]. They either use prompting or fine-tuning to make LLMs capable of solving PDDL planning problems. Improvements to longhorizon planning capabilities have also been made by iteratively querying LLMs, as demonstrated in Minecraft [58]. In contrast, we do not solely rely on LLM as the problem solver, but are more into taking the advantage of both the planner (i.e., generating accurate and optimal plans) and the LLM itself (i.e., 1-shot generalization for translating naturallanguage problem descriptions into PDDL).</p>
<h2>C. Augmenting LLMs with External Modules</h2>
<p>Recently developed methods have shown that the performance of downstream tasks of LLMs can be improved by combining them with external modules. For instance, WebGPT [59] is a fine-tuned version of GPT-3 by combining web knowledge to answer open-ended questions. Lazaridou et al. studied how search engines like Google can be utilized as external tools for LLMs [60]. MemPrompt [61] presented a human-in-the-loop system where a growing memory of errors and user feedback is served as past experience adding to the prompts for more accurately answering new questions. REPLUG [62] is another retrieval-augmented language modeling paradigm that treats the language model as a black box and augments it with a tuneable retrieval model. Specifically, people have investigated using calculators for computation [63], [64]. In very recent work related to ours, Schick et al. trained a model called ToolFormer that can decide when and how to call certain tool APIs by in-line</p>
<p>augmentation on prompts for LLMs [65]. In this work, we propose that classical planners can be another particularly useful external module. In comparison, LLM+P, does not rely on any fine-tuning or re-training of LLMs. By simply incorporating knowledge from classical planners, LLM+P incorporates long-horizon reasoning and planning capabilities into existing LLMs.</p>
<p>The authors are informed that a concurrent work [66] presents preliminary results of integrating LLMs with PDDL using the SayCan dataset [34]. However, the SayCan dataset has a limited scope, as it contains only three predefined actions. Consequently, all model variants evaluated in the original paper achieved a success rate of approximately $90 \%$. Due to the homogeneity of the SayCan dataset, Lyu et al. did not necessitate a rigorous definition of the domain PDDL, which can lead to infeasible plans. As a result, we consider our LLM+P method as a more comprehensive investigation into enhancing LLMs with optimal planning proficiency.</p>
<h2>V. EXPERIMENTS</h2>
<p>We conduct experiments to answer these questions:</p>
<p>1) How well does LLM-AS-P work? To what extent can state-of-the-art LLMs and LLM-based reasoning methods be directly used for planning? (Not at all)
2) How well does LLM+P work compare to LLM-AS-P? (Much better)
3) What role does the context play in the success of LLM+P? (It's crucial)
4) Can LLM+P help make service robots more efficient on realistic tasks? (Yes)</p>
<h2>A. Benchmark Problems</h2>
<p>We present seven robot planning domains borrowed from past International Planning Competitions and 20 automatically generated tasks for each domain [67]. Below is a list of the planning domains, along with a brief summary of each.</p>
<p>1) BlockSWORLD: Given a set of piles of blocks on a table, a robot is tasked with rearranging them into a specified target configuration.
2) BARMAN: A robot bartender is tasked with creating cocktails for a customer's order, utilizing the available ingredients and containers.
3) Floortile: A set of robots are tasked to use paint color patterns on floor tiles. Robots can move around and change colors but cannot step on painted tiles.
4) GRIPPERS: A set of robots with two grippers is given a task to move objects among different rooms.
5) Storage: Given a set of hoists, the goal is to lift and drop crates using the hoists into a depot. Crates are initially stored in different areas and hoists can be moved among storage areas.
6) TERMES: A robot is tasked to build complex structures by carrying and placing blocks, and also climbing on them so that it can build towers.
7) TyReWorld: The robot is given a task to replace flat tires by, for example, inflating tires, tightening nuts,
and moving tools back to the boot when done, all in the proper order.
For each problem $P, P$ comes with a natural language description and a ground-truth problem PDDL file. Each domain also includes an example problem description, a corresponding PDDL file, and a plan description, used as context in various approaches. We assume each problem domain has its own domain PDDL file given by the user or a domain expert prior to addressing any planning problems in that domain. This dataset is made publicly available in our codebase for reproducibility.</p>
<h2>B. Experiment Setup</h2>
<p>We leverage the GPT-4 model provided by OpenAI ${ }^{2}$ for all experiments. We set the temperature to 0 , and use the top probability response. As a result, the response returned from the LLM is deterministic. Once a text PDDL response is generated, we feed it into the FAST-DOWNWARD planner ${ }^{3}$ and try both aliases SEQ-OPT-FDSS-1 (guaranteed optimal) and LAMA (not guaranteed optimal) with a maximum search time of 200 seconds. We report the success rate of the optimal alias, and for the domains that time out, we show the success rate of the sub-optimal alias in parentheses. For the baseline methods, we manually count the number of optimal plans, and report the number of correct plans in parentheses (if there are any sub-optimal plans).</p>
<p>We also evaluate a recent LLM-based approach for deliberate reasoning called Tree of Thoughts [68], referred to as LLM-AS-P (ToT). We adapt the breadth-first-search algorithm from the original ToT implementation ${ }^{4}$ for planning. The LLM is prompted to expand the search tree from allowed actions and evaluate the paths on their likelihood of reaching the goal. The same time limit of 200 seconds is applied.</p>
<h2>C. Results and Analysis</h2>
<p>The results of applying LLM-AS-P and LLM+P across 7 domains are provided in Table I.</p>
<table>
<thead>
<tr>
<th>Domain</th>
<th>Success Rate \%</th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>LLM $^{-}$</td>
<td>LLM</td>
<td>LLM $^{T o T}$</td>
<td>LLM+P $^{-}$</td>
<td>LLM+P</td>
</tr>
<tr>
<td>BARMAN</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>20 (100)</td>
</tr>
<tr>
<td>BlockSWORLD</td>
<td>20</td>
<td>15 (30)</td>
<td>0 (5)</td>
<td>0</td>
<td>90</td>
</tr>
<tr>
<td>Floortile</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>GRIPPERS</td>
<td>25 (60)</td>
<td>35 (50)</td>
<td>10 (20)</td>
<td>0</td>
<td>95 (100)</td>
</tr>
<tr>
<td>Storage</td>
<td>0</td>
<td>0 (25)</td>
<td>0</td>
<td>0</td>
<td>85</td>
</tr>
<tr>
<td>TERMES</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>20</td>
</tr>
<tr>
<td>TyReWorld</td>
<td>5</td>
<td>15</td>
<td>0</td>
<td>0</td>
<td>10 (90)</td>
</tr>
</tbody>
</table>
<p>TABLE I: Success rate \% of applying LLM-AS-P without context (LLM ${ }^{-}$), LLM-AS-P (LLM), Tree of Thoughts (LLM ${ }^{T o T}$ ), LLM+P without context (LLM ${ }^{-}$), and LLM+P.</p>
<p>Findings (LLM-AS-P):</p>
<p>1) We observe that though LLM-AS-P provides a plan in natural language for every problem, most of these</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup> <sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>: ${ }^{2}$ We use the most recent model as of September 2023. https:// platform.openai.com/docs/models/gpt-4 ${ }^{3}$ https://github.com/aibasel/downward/tree/ release-22.12.0 ${ }^{4}$ https://github.com/princeton-nlp/ tree-of-thought-1lm/</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 2: Demonstration of the optimal tidy-up plan. The robot starts at the coffee table and 1) picks up the bottle, 2) navigates to a room with the side table and the recycle bin, 3) puts down the bottle, 4) grasps the soup can, 5) puts the soup can in the recycle bin, 6) re-grasps the bottle, 7) navigates to the kitchen, 8) places the bottle in the pantry.</p>
<p>plans are not feasible. The main reason is that LLM-AS-P lacks the ability to reason about preconditions.</p>
<p>2) In most cases, LLM-AS-P fails in the same way with or without the example plan as context. In particular, in the BlockSwordD domain, LLM-AS-P cannot keep track of properties like ON and Clear. In the BARMAN domain, LLM-AS-P's plans fail to clean shot glasses before using them again.</p>
<p>3) The hardest domains are the ones with complex spatial relationship. The LLM-AS-P methods (with or without context) completely fail at this type of problems. In the FLOORTILE domain, LLM-AS-P generates "move right to tile.0-4 and paint tile.1-2 black" but the robot can only paint neighboring tiles. In TERMES and STORAGE, LLM-AS-P ignores the requirement that the robot cannot unload the block/crate at the same position it occupies.</p>
<p>4) LLM-AS-P (ToT) calls the LLM at each tree node to provide a list of available actions, and then calls the LLM to evaluate each new path on the tree as a partial plan. We find that the LLM is able to give reasonable rankings on the partial plans, but it often fails to recognize whether the plan reaches the goal. LLM-AS-P (ToT) times out in most cases due to the large number of LLM calls, so it is not suitable for solving long-horizon problems.</p>
<h3>Findings (LLM+P):</h3>
<p>1) The proposed LLM+P produces an optimal plan for the majority of problems. Most failed cases are due to mis-specified problem files, such as missing one of the initial conditions (e.g. leaving the tiles disconnected in FLOORTILE), causing the planning problem to be unsolvable.</p>
<p>2) Without the context (i.e., an example problem and its corresponding problem PDDL), we observe that LLMs fail to produce correct problem PDDL files. Therefore, the context is important for LLM+P to work.</p>
<h3><em>D. Robot Demonstration</em></h3>
<p>We verify that LLM+P can efficiently solve realistic service robot problems by deploying it on a real robot tasked with tidying up a home. The user asks the robot to move a mustard bottle from the coffee table to the pantry, and throws away the empty soup can from the side table. Since the side table and the recycle bin are on the way from the coffee table to the pantry, the optimal plan is to take the mustard bottle to the side table, and re-grasps it after throwing away the soup can, with a total cost of 22. Fig. 2 shows the optimal plan found by LLM+P. Parts of the prompt and the generated PDDL are shown below. LLM-AS-P outputs a sub-optimal plan which takes the bottle to the pantry first and travels back for the soup can, with a total cost of 31.</p>
<h3><strong>Tidy-Up Problem PDDL Generated by LLM+P</strong></h3>
<p><strong>Problem (P):</strong> You are a home robot with one gripper. The distance between coffee table and side table is 10. The distance between coffee table and pantry is 20... You are at the coffee table. There is a mustard bottle... Your goal is to move objects to their destinations...</p>
<h3><strong>Problem PDDL generated by LLM+P:</strong></h3>
<div class="codehilite"><pre><span></span><code>(:objects coffee-table side-table
recycle-bin pantry - location
mustard-bottle soup-can - object)
(:init (= (total-cost) 0) (= (distance coffee-table side-table)
10) (= (distance coffee-table
pantry) 20) ... (robot-at
coffee-table) (at mustard-bottle
coffee-table) (at soup-can
side-table) (hand-empty) )
(:goal (and (at mustard-bottle
pantry) (at soup-can recycle-bin)))
(:metric minimize (total-cost)) )
</code></pre></div>

<h3>VI. CONCLUSION AND FUTURE WORK</h3>
<p>In this work, we propose to leverage classical planners to empower large language models with optimal planning capabilities. The key design choice of the proposed LLM+P framework is to focus LLMs on translating the planning problem from natural language to structured PDDL format. Moreover, we show that it is important to also make LLMs aware of a simple (problem, PDDL) pair as a demonstration (or the context) for in-context learning. Some interesting directions to further extend the LLM+P framework include: 1) enabling the LLM to auto-detect when and how to apply LLM+P; and 2) reducing LLM+P's dependency on information by humans, potentially involving finetuning.</p>
<h2>REFERENCES</h2>
<p>[1] J. Weizenbaum, "Eliza-a computer program for the study of natural language communication between man and machine," Communications of the ACM, vol. 9, no. 1, pp. 36-45, 1966.
[2] OpenAI, "Opt-4 technical report," 2023.
[3] S. Vemprala, R. Bonatti, A. Bucker, and A. Kapoor, "Chatgpt for robotics: Design principles and model abilities," Microsoft, Tech. Rep. MSR-TR-2023-8, February 2023. [Online]. Available: https://www.microsoft.com/en-us/research/publication/ chatgpt-for-robotics-design-principles-and-model-abilities/
[4] K. Mahowald, A. A. Ivanova, I. A. Blank, N. Kanwisher, J. B. Tenenbaum, and E. Fedorenko, "Dissociating language and thought in large language models: a cognitive perspective," arXiv preprint arXiv:2301.06627, 2023.
[5] C. Lee, K. Cho, and W. Kang, "Mixout: Effective regularization to finetune large-scale pretrained language models," arXiv preprint arXiv:1909.11299, 2019.
[6] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V. Le, "Finetuned language models are zero-shot learners," arXiv preprint arXiv:2109.01652, 2021.
[7] D. McDermott, M. Ghallab, A. Howe, C. Knoblock, A. Ram, M. Veloso, D. Weld, and D. Wilkins, "Pddl-the planning domain definition language," 1998.
[8] P. Haslum, N. Lipovetzky, D. Magazzeni, and C. Muise, "An introduction to the planning domain definition language," Synthesis Lectures on Artificial Intelligence and Machine Learning, vol. 13, no. 2, pp. $1-187,2019$.
[9] K. Valmeekam, A. Olmo, S. Sreedharan, and S. Kambhampati, "Large language models still can't plan (a benchmark for llms on planning and reasoning about change)," arXiv preprint arXiv:2206.10498, 2022.
[10] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., "Language models are few-shot learners," Advances in neural information processing systems, vol. 33, pp. 1877-1901, 2020.
[11] M. Helmert, "The fast downward planning system," Journal of Artificial Intelligence Research, vol. 26, pp. 191-246, 2006.
[12] T. Bylander, "The computational complexity of propositional STRIPS planning," Artificial Intelligence, vol. 69, no. 1-2, pp. 165-204, 1994.
[13] J. McCarthy, "Situations, actions, and causal laws," Stanford University Technical Report, Tech. Rep., 1963.
[14] R. E. Fikes and N. J. Nilsson, "Strips: A new approach to the application of theorem proving to problem solving," Artificial intelligence, vol. 2, no. 3-4, pp. 189-208, 1971.
[15] N. J. Nilsson et al., "Shakey the robot," 1984.
[16] J. Carbonell, O. Etzioni, Y. Gil, R. Joseph, C. Knoblock, S. Minton, and M. Veloso, "Prodigy: An integrated architecture for planning and learning," ACM SIGART Bulletin, vol. 2, no. 4, pp. 51-55, 1991.
[17] D. S. Nau, T.-C. Au, O. Ilghami, U. Kuter, J. W. Murdock, D. Wu, and F. Taman, "Shop2: An htn planning system," Journal of artificial intelligence research, 2003.
[18] Y.-q. Jiang, S.-q. Zhang, P. Khandelwal, and P. Stone, "Task planning in robotics: an empirical comparison of pddl-and asp-based systems," Frontiers of Information Technology \&amp; Electronic Engineering, vol. 20, pp. 363-373, 2019.
[19] G. Brewka, T. Eiter, and M. Truszczyński, "Answer set programming at a glance," Communications of the ACM, vol. 54, no. 12, pp. 92-103, 2011.
[20] V. Lifschitz, "Answer set programming and plan generation," Artificial Intelligence, vol. 138, no. 1-2, pp. 39-54, 2002.
[21] M. Fox and D. Long, "Pddl2. 1: An extension to pddl for expressing temporal planning domains," Journal of artificial intelligence research, vol. 20, pp. 61-124, 2003.
[22] S. Zhang, F. Yang, P. Khandelwal, and P. Stone, "Mobile robot planning using action language bc with an abstraction hierarchy," in International Conference on Logic Programming and Nonmonotonic Reasoning. Springer, 2015, pp. 502-516.
[23] Y. Ding, X. Zhang, X. Zhan, and S. Zhang, "Task-motion planning for safe and efficient urban driving," in 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2020.
[24] Y. Jiang, H. Yedidsion, S. Zhang, G. Sharon, and P. Stone, "Multi-robot planning with conflicts and synergies," Autonomous Robots, vol. 43, no. 8, pp. 2011-2032, 2019.
[25] F. Lagriffoul, N. T. Dantam, C. Garrett, A. Akbari, S. Srivastava, and L. E. Kavraki, "Platform-independent benchmarks for task and motion planning," IEEE Robotics and Automation Letters, vol. 3, no. 4, pp. 3765-3772, 2018.
[26] L. P. Kaelbling and T. Lozano-Pérez, "Integrated task and motion planning in belief space," The International Journal of Robotics Research, vol. 32, no. 9-10, pp. 1194-1227, 2013.
[27] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, "Bert: Pre-training of deep bidirectional transformers for language understanding," arXiv preprint arXiv:1810.04805, 2018.
[28] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, et al., "Evaluating large language models trained on code," arXiv preprint arXiv:2107.03374, 2021.
[29] S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V. Lin, et al., "Opt: Open pre-trained transformer language models," arXiv preprint arXiv:2205.01068, 2022.
[30] OpenAI, "Chatgpt," Accessed: 2023-02-08, 2023, cit. on pp. 1, 16. [Online]. Available: https://openai.com/blog/chatgpt/
[31] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, et al., "Llama: Open and efficient foundation language models," arXiv preprint arXiv:2302.13971, 2023.
[32] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al., "Llama 2: Open foundation and fine-tuned chat models," arXiv preprint arXiv:2307.09288, 2023.
[33] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, et al., "Palm: Scaling language modeling with pathways," arXiv preprint arXiv:2204.02311, 2022.
[34] M. Ahn, A. Brohan, N. Brown, Y. Chebotar, O. Cortes, B. David, C. Finn, K. Gopalakrishnan, K. Hausman, A. Herzog, et al., "Do as i can, not as i say: Grounding language in robotic affordances," arXiv preprint arXiv:2204.01691, 2022.
[35] Y. Ding, X. Zhang, C. Paxton, and S. Zhang, "Task and motion planning with large language models for object rearrangement," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023.
[36] D. Driess, F. Xia, M. S. Sajjadi, C. Lynch, A. Chowdhery, B. Ichter, A. Wahid, J. Tompson, Q. Vuong, T. Yu, et al., "Palm-e: An embodied multimodal language model," arXiv preprint arXiv:2303.03378, 2023.
[37] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Florence, A. Zeng, J. Tompson, I. Mordatch, Y. Chebotar, et al., "Inner monologue: Embodied reasoning through planning with language models," arXiv preprint arXiv:2207.05608, 2022.
[38] W. Huang, P. Abbeel, D. Pathak, and I. Mordatch, "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents," in International Conference on Machine Learning. PMLR, 2022, pp. 9118-9147.
[39] Y. Kant, A. Ramachandran, S. Yenamandra, I. Gilitschenski, D. Batra, A. Szot, and H. Agrawal, "Housekeep: Tidying virtual households using commonsense reasoning," in Computer Vision-ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23-27, 2022, Proceedings, Part XXXIX. Springer, 2022, pp. 355-373.
[40] I. Singh, V. Blukis, A. Mousavian, A. Goyal, D. Xu, J. Tremblay, D. Fox, J. Thomason, and A. Garg, "Progprompt: Generating situated robot task plans using large language models," arXiv preprint arXiv:2209.11302, 2022.
[41] K. Lin, C. Agia, T. Migimatsu, M. Pavone, and J. Bohg, "Text2motion: From natural language instructions to feasible plans," arXiv preprint arXiv:2303.12353, 2023.
[42] Y. Yang, J.-R. Gaglione, C. Neary, and U. Topcu, "Automaton-based representations of task knowledge from generative language models," arXiv preprint arXiv:2212.01944, 2023.
[43] Y. Ding, X. Zhang, S. Amiri, N. Cao, H. Yang, A. Kaminski, C. Esselink, and S. Zhang, "Integrating action knowledge and llms for task planning and situation handling in open worlds," arXiv preprint arXiv:2305.17590, 2023.
[44] A. Z. Ren, A. Dixit, A. Bodrova, S. Singh, S. Tu, N. Brown, P. Xu, L. Takayama, F. Xia, J. Varley, et al., "Robots that ask for help: Uncertainty alignment for large language model planners," arXiv preprint arXiv:2307.01928, 2023.
[45] Y. Chen, J. Arkin, Y. Zhang, N. Roy, and C. Fan, "Autotamp:</p>
<p>Autoregressive task and motion planning with llms as translators and checkers," arXiv preprint arXiv:2306.06531, 2023.
[46] K. Valmeekam, S. Sreedharan, M. Marquez, A. Olmo, and S. Kambhampati, "On the planning abilities of large language models (a critical investigation with a proposed benchmark)," arXiv preprint arXiv:2302.06706, 2023.
[47] T. Silver, V. Hariprasad, R. S. Shuttleworth, N. Kumar, T. LozanoPérez, and L. P. Kaelbling, "PDDL planning with pretrained large language models," in NeurIPS 2022 Foundation Models for Decision Making Workshop, 2022. [Online]. Available: https: //openreview.net/forum?id=1QMMUB4zfl
[48] V. Pallagani, B. Muppasani, K. Murugesan, F. Rossi, L. Horesh, B. Srivastava, F. Fabiano, and A. Loreggia, "Plansformer: Generating symbolic plans using transformers," arXiv preprint arXiv:2212.08681, 2022.
[49] D. Arora and S. Kambhampati, "Learning and leveraging verifiers to improve planning capabilities of pre-trained language models," arXiv preprint arXiv:2305.17077, 2023.
[50] L. Guan, K. Valmeekam, S. Sreedharan, and S. Kambhampati, "Leveraging pre-trained large language models to construct and utilize world models for model-based task planning," arXiv preprint arXiv:2305.14909, 2023.
[51] T. Silver, S. Dan, K. Srinivas, J. B. Tenenbaum, L. P. Kaelbling, and M. Katz, "Generalized planning in pddl domains with pretrained large language models," arXiv preprint arXiv:2305.11014, 2023.
[52] V. Pallagani, B. Muppasani, K. Murugesan, F. Rossi, B. Srivastava, L. Horesh, F. Fabiano, and A. Loreggia, "Understanding the capabilities of large language models for automated planning," arXiv preprint arXiv:2305.16151, 2023.
[53] K. Valmeekam, M. Marquez, S. Sreedharan, and S. Kambhampati, "On the planning abilities of large language models-a critical investigation," arXiv preprint arXiv:2305.15771, 2023.
[54] Y. Xie, C. Yu, T. Zhu, J. Bai, Z. Gong, and H. Soh, "Translating natural language to planning goals with large-language models," arXiv preprint arXiv:2302.05128, 2023.
[55] R. Hazra, P. Z. D. Martires, and L. De Raedt, "Saycanpay: Heuristic planning with large language models using learnable domain knowledge," arXiv preprint arXiv:2308.12682, 2023.
[56] K. Rana, J. Haviland, S. Garg, J. Abou-Chakra, I. Reid, and N. Suenderhauf, "Sayplan: Grounding large language models using 3d scene graphs for scalable task planning," arXiv preprint arXiv:2307.06135, 2023.
[57] Z. Zhou, J. Song, K. Yao, Z. Shu, and L. Ma, "Isr-llm: Iterative self-refined large language model for long-horizon sequential task planning," arXiv preprint arXiv:2308.13724, 2023.
[58] Z. Wang, S. Cai, A. Liu, X. Ma, and Y. Liang, "Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents," arXiv preprint arXiv:2302.01560, 2023.
[59] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim, C. Hesse, S. Jain, V. Kosaraju, W. Saunders, et al., "Webgpt: Browserassisted question-answering with human feedback," arXiv preprint arXiv:2112.09332, 2021.
[60] A. Lazaridou, E. Gribovskaya, W. Stokowiec, and N. Grigorev, "Internet-augmented language models through few-shot prompting for open-domain question answering," arXiv preprint arXiv:2203.05115, 2022.
[61] A. Madaan, N. Tandon, P. Clark, and Y. Yang, "Memory-assisted prompt editing to improve gpt-3 after deployment," 2023.
[62] W. Shi, S. Min, M. Yasunaga, M. Seo, R. James, M. Lewis, L. Zettlemoyer, and W.-t. Yih, "Replug: Retrieval-augmented black-box language models," arXiv preprint arXiv:2301.12652, 2023.
[63] W. Chen, X. Ma, X. Wang, and W. W. Cohen, "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks," arXiv preprint arXiv:2211.12588, 2022.
[64] L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y. Yang, J. Callan, and G. Neubig, "Pal: Program-aided language models," arXiv preprint arXiv:2211.10435, 2022.
[65] T. Schick, J. Dwivedi-Yu, R. Dessì, R. Raileanu, M. Lomeli, L. Zettlemoyer, N. Cancedda, and T. Scialom, "Toolformer: Language models can teach themselves to use tools," arXiv preprint arXiv:2302.04761, 2023.
[66] Q. Lyu, S. Havaldar, A. Stein, L. Zhang, D. Rao, E. Wong, M. Apidianaki, and C. Callison-Burch, "Faithful chain-of-thought reasoning," arXiv preprint arXiv:2301.13379, 2023.
[67] J. Seipp, Á. Torralba, and J. Hoffmann, "PDDL generators," https: //doi.org/10.5281/zenodo.6382173, 2022.
[68] S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths, Y. Cao, and K. Narasimhan, "Tree of thoughts: Deliberate problem solving with large language models," arXiv preprint arXiv:2305.10601, 2023.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>*Equal contribution.
${ }^{\dagger}$ Department of Computer Science, The University of Texas at Austin {bliu, lqiang, joydeep, pstone}@cs.utexas.edu, jiangyuqian@utexas.edu
${ }^{\ddagger}$ Department of Computer Science, State University of New York at Binghamton {xzhan244, zhangs}@binghamton.edu
${ }^{\S}$ Sony AI
${ }^{\dagger}$ The code and results are publicly available at https://github. com/Cranial-XIX/llm-pddl.git.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>