<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1628 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1628</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1628</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-31.html">extraction-schema-31</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <p><strong>Paper ID:</strong> paper-237091068</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2108.07000v1.pdf" target="_blank">Evolutionary Algorithms in Approximate Computing: A Survey</a></p>
                <p><strong>Paper Abstract:</strong> In recent years, many design automation methods have been developed to routinely create approximate implementations of circuits and programs that show excellent trade-offs between the quality of output and required resources. This paper deals with evolutionary approximation as one of the popular approximation methods. The paper provides the first survey of evolutionary algorithm (EA)-based approaches applied in the context of approximate computing. The survey reveals that EAs are primarily applied as multi-objective optimizers. We propose to divide these approaches into two main classes: (i) parameter optimization in which the EA optimizes a vector of system parameters, and (ii) synthesis and optimization in which EA is responsible for determining the architecture and parameters of the resulting system. The evolutionary approximation has been applied at all levels of design abstraction and in many different applications. The neural architecture search enabling the automated hardware-aware design of approximate deep neural networks was identified as a newly emerging topic in this area.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1628.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1628.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Genetic Programming</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Tree-based evolutionary method that evolves executable programs by applying genetic operators (crossover, mutation, selection) to syntax-tree representations; fitness is measured by executing candidate programs on training data and computing error metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A field guide to genetic programming.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Genetic Programming (GP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GP represents candidate programs as syntax trees built from a set of terminals (inputs/constants) and functions (operators). Evolution proceeds by selecting parent programs, applying subtree crossover (swapping subtrees between parents) and various mutation operators (e.g., subtree replacement, node replacement, subprogram reuse), and evaluating offspring by executing them on a training dataset to compute a fitness defined by an aggregate error metric. GP is used for program synthesis, feature extraction, and approximate implementations at software/feature-extraction levels in the surveyed literature.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Subtree crossover: two parent syntax trees are selected and subtrees (i.e., program fragments) are swapped to produce offspring that combine code segments from both parents. The paper describes GP's standard crossover at the level of syntax-tree subprograms and also mentions more complex operators (e.g., subprogram definition and reuse).</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Typical GP mutation replaces a randomly selected subtree with a newly generated subtree (or mutates nodes/constants). The paper also notes a variety of GP mutation operators and possible subprogram re-use operators applied to program trees.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Fitness via program execution: f(α,D_tr) = sum_i E(y_i, α(x_i)), where candidate program α is executed on a training dataset D_tr and E is an error metric (e.g., MAE, application-specific measures). Execution on test data is used to validate generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td>Not specified for GP per se in the survey; multi-objective EAs employing GP use Pareto non-dominance and population-based diversity preservation methods (e.g., NSGA-II crowding distance).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Program synthesis, feature extraction (EEG seizure, ECG arrhythmia), image filters, median filters, hash functions, embedded inference feature extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Hand-designed algorithms, conventional feature extraction pipelines, standard hash functions; sometimes greedy or probabilistic approximation methods (e.g., probabilistic approach to TMR).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>GP is effective at synthesizing approximate programs and feature-extraction code that trade energy/resource use for slight accuracy loss; fitness is execution-based (train/test error). The survey emphasizes that GP leverages crossover+mutation to explore program space but does not report standardized novelty metrics; multi-objective frameworks (e.g., NSGA-II) are often used to maintain solution diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolutionary Algorithms in Approximate Computing: A Survey', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1628.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1628.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CGP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cartesian Genetic Programming</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph-based GP variant encoding directed acyclic graphs as fixed-size genotype arrays that evolve circuits or programs predominantly via point mutation and (1+λ) search, widely used for evolving approximate circuits.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cartesian genetic programming: its status and future.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Cartesian Genetic Programming (CGP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CGP uses a fixed grid of nodes (n_c × n_r) implementing functions; the genotype is an integer vector that encodes node function codes and connections, producing a DAG for the candidate. The typical search uses a (1+λ) evolutionary strategy with point mutation as the primary genetic operator; crossover is generally not used in the basic CGP configuration. CGP is heavily used for evolving approximate hardware (gate-level, RTL) arithmetic circuits and building libraries of approximations (e.g., EvoApprox8b/EvoApproxLib).</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>hardware descriptions / circuit representations (can be mapped to Verilog/C/Matlab)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Point mutation on genotype integers: randomly modify integers encoding node function or connection; mutation may change function codes or wiring. Search strategy typically (1+λ) where λ offspring are generated by mutating a single parent.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Circuit correctness/error measured by simulation (sampling of input vectors) or exact formal methods (ROBDD or SAT-based analysis) to compute error metrics such as MAE, WCE, average Hamming distance; area/delay/power estimated via switching activity/delay models or synthesis tools.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td>Measured implicitly via multi-objective Pareto non-dominance; the resulting EvoApproxLib reports many Pareto-non-dominated designs (see diversity_results).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td>EvoApproxLib (CGP-produced library) contains 16,833 non-dominated implementations (reported in the survey), and EvoApprox8b contains hundreds of approximate implementations (8-bit adders/multipliers).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>CGP often trades-off error (novelty/deviation from exact behavior) and hardware metrics (area/power/delay); the survey reports multiple Pareto-front trade-offs but no explicit novelty-vs-executability quantitative frontier beyond standard error vs resource curves.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td>Numerous MAE vs power/area Pareto fronts are reported (e.g., MAE-power plots for evolved 8-bit multipliers); however the survey summarizes these qualitatively and provides example plots (no single numeric frontier description).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Gate-level/RTL circuit synthesis (adders, multipliers, median filters, DCT, image filters), FPGA-targeted LUT circuit synthesis, libraries of approximate arithmetic circuits.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Conventional approximate circuit architectures (truncated multipliers, broken-array multipliers), hand-designed adders/multipliers, greedy/probabilistic approximation methods.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CGP (mutation-driven, often without crossover) is highly effective for evolving approximate circuits, producing large libraries of diverse trade-offs (thousands of Pareto-optimal points). CGP can be combined with formal analysis (ROBDD/SAT) to ensure or verify executability/ error bounds; inclusion of larger building blocks (e.g., full adders) can yield >10× speedups in evolution for some tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolutionary Algorithms in Approximate Computing: A Survey', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1628.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1628.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LGP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Linear Genetic Programming</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An evolutionary approach that encodes programs as linear sequences of instructions (machine-level style), applying mutation at the integer/gene level and crossover at instruction boundaries to evolve executable programs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A field guide to genetic programming.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Linear Genetic Programming (LGP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>LGP encodes candidate solutions as linear sequences of instructions (OP, Ra, Rb, Rc); mutation alters integers (opcodes, registers) and crossover exchanges instruction sequences between parents (usually at instruction granularity). It is applied to evolve instruction-level programs (e.g., specialized hash functions) that are directly executable or synthesizable.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs / instruction sequences</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Instruction-level crossover: cut-and-splice at instruction boundaries to swap sequences of instructions between parent programs, producing offspring programs that combine instruction subsequences.</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Randomly alter an integer in the program encoding (change opcode or register indices) to any permitted value; typical point mutation at instruction/gene level.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Quality measured by execution on real data (e.g., hash function performance on network data) and by implementation cost/latency on target hardware (FPGA).</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Program synthesis for network flow hashing; embedded program generation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Standard hash functions and hand-designed implementations; conventional program designs.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LGP allows evolving instruction-level programs that are competitive with standard designs for specific hardware targets; crossover at the instruction level and point mutation enable exploration of executable program space, but the survey does not report explicit novelty metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolutionary Algorithms in Approximate Computing: A Survey', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1628.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1628.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PetaBricks GA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GA for PetaBricks auto-tuning (mutator-based)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GA-based empirical auto-tuning system for the PetaBricks language that evolves algorithm configurations and decision trees using automatically generated mutator functions applied to code/configurations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language and compiler support for auto-tuning variable-accuracy algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PetaBricks GA (mutator-driven auto-tuner)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The system extends PetaBricks language/compiler with accuracy-aware features and uses a GA to maintain a population of candidate algorithm configurations; mutators (automatically generated per program via static analysis) modify configuration variables and decision trees that select algorithm variants. Candidate configurations are evaluated empirically with a dynamically specified number of tests to balance evaluation cost and statistical relevance.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>program configuration and decision trees (source-level configuration, not arbitrary literature)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Mutator functions specific to each program (automatically generated) modify configuration variables and decision trees, expanding population via mutation-like operators; the paper describes these as mutators rather than standard crossover, with emphasis on empirical test-based evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Empirical test-based evaluation: candidate algorithm configurations are executed on benchmark inputs and performance/quality metrics collected; number of tests adaptively chosen to ensure statistically relevant fitness values while reducing runtime.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Auto-tuning variable-accuracy algorithms in PetaBricks; evaluated on five/twelve representative programs (paper lists six benchmarks in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Hand-tuned algorithm configurations; non-tuned default implementations.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mutator-driven GA in PetaBricks enables automatic generation and empirical evaluation of multiple accuracy/performance trade-offs with reduced evaluation cost via adaptive testing; crossover is not emphasized, mutators (controlled mutation) are the main operator.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolutionary Algorithms in Approximate Computing: A Survey', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1628.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1628.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ABACUS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ABACUS (automated behavioral synthesis with AST mutators)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated approximation framework that parses Verilog to an AST and applies source-level mutation operators (mutators) to generate approximate Verilog variants which are simulated and synthesized to evaluate error and hardware metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ABACUS: A technique for automated behavioral synthesis of approximate computing circuits.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ABACUS (AST-mutator-based approximate synthesizer)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>ABACUS parses behavioral/RTL Verilog into an AST, applies a suite of mutation operators (bit-width simplification, variable-to-constant substitution, approximate arithmetic transformations, expression and loop transformations) to produce approximate source variants, then emits Verilog, simulates for error metrics, and synthesizes for area/power estimation. Originally used with a greedy search, later versions use NSGA-II for multi-objective optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>code (Verilog source / behavioral descriptions)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>AST-level mutators: localized transformations on the abstract syntax tree such as bit-width reductions, replacing variables with constants, replacing exact arithmetic with approximate operator models, expression rewrites, and loop transformations.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Simulation-based error metrics (MAE/WCE/ER or application-specific PSNR) and synthesis-derived hardware metrics (area, power) after generated Verilog is synthesized; candidates are thus executable Verilog validated by simulation/synthesis.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>ABACUS explicitly trades off error (application quality metrics) against hardware metrics using multi-objective optimization (NSGA-II in later work), but no explicit 'novelty' metric is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td>Produces Pareto fronts of error vs area/power for mutated programs (qualitative characterization in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Behavioral/RTL Verilog designs for image/video processing and other circuits; evaluated on example designs (e.g., DCT, filters).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Exact implementations synthesized with standard tools; manual approximation strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Source-level mutation via AST mutators generates executable approximate Verilog variants whose error and hardware cost can be evaluated end-to-end; using NSGA-II yields Pareto fronts of viable trade-offs. Crossover is not a described operator; search is mutation-driven.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolutionary Algorithms in Approximate Computing: A Survey', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1628.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1628.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NSGA-II</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Non-dominated Sorting Genetic Algorithm II</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A popular multi-objective evolutionary algorithm that uses non-dominated sorting and a crowding-distance metric to maintain diversity on the Pareto front while evolving solutions via selection, crossover, and mutation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A fast and elitist multiobjective genetic algorithm: NSGA-II.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>NSGA-II (multi-objective EA with diversity preservation)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>NSGA-II ranks population members by Pareto-dominance fronts and uses a crowding-distance metric within fronts to preserve diversity; selection and genetic operators (crossover and mutation) produce offspring and the best individuals across parents and offspring are selected for the next generation. NSGA-II is widely used as the multi-objective optimization backbone for many approximate computing problems (parameter optimization, source-code mutator search, neural architecture search).</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>parameters, configurations, architectures, code-parameter vectors (various depending on application)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>General GA crossover (application-dependent): when applied to genotype vectors (e.g., integers representing parameters or architecture choices) common crossover schemes (one-point, uniform, etc.) are used by the cited works; the survey does not standardize to one mechanism but notes offspring are created from parents by crossover and mutation in GA setups.</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Problem-specific mutation: for integer/bit-vector genotypes, random gene perturbation; for code/configuration mutators, mutation operators are application-specific (AST mutators, parameter flips). NSGA-II itself is agnostic to the specific mutation operator used by component implementations.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Fitness components are application-specific (error metrics like MAE/WCE/ER, hardware estimates, latency, energy). NSGA-II treats these as multi-objective signals; executability is enforced via simulation/formal checks when required.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td>Crowding distance within Pareto fronts (NSGA-II) used to preserve population diversity along the front.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>NSGA-II facilitates exploring trade-offs between error (novelty from exact design) and executability/resource metrics by explicitly constructing Pareto fronts; the survey highlights NSGA-II's role in producing sets of trade-off solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td>NSGA-II produces Pareto fronts across objectives (error vs area/power/latency/accuracy) in many surveyed works; the paper emphasizes the method's capability to provide a set of diverse trade-off solutions rather than a single optimum.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Parameter optimization, source-code approximation, hardware/software co-design, neural architecture search.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Single-objective or weight-aggregated optimization, constrained/prioritization methods; other multi-objective EAs are referenced but NSGA-II is a common benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>NSGA-II is the de-facto multi-objective optimizer in surveyed approximate-computing works because it constructs Pareto fronts and preserves diversity via crowding-distance; it is typically combined with domain-specific crossover/mutation operators and fitness estimation strategies to reduce evaluation cost.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolutionary Algorithms in Approximate Computing: A Survey', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1628.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1628.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EvoApproxLib</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>EvoApproxLib (library of CGP-evolved approximate circuits)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A publicly available library of evolved approximate arithmetic circuits (adders, multipliers, dividers, MACs) produced primarily by CGP, characterized by multiple error metrics and hardware parameters, and provided in Verilog/C/Matlab formats.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evoapprox8b: Library of approximate adders and multipliers for circuit design and benchmarking of approximation methods.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>EvoApproxLib (CGP-evolved approximate circuit library)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>EvoApproxLib aggregates hundreds-to-thousands of CGP-evolved approximate implementations across bitwidths (8-bit up to 128-bit for adders, various multipliers, MACs), each fully characterized by error metrics (MAE, WCE, Hamming distance) and estimated electrical parameters (power, delay) obtained via synthesis modeling. The library serves as a resource for selecting approximate building blocks and for NAS/co-design tools to pick components per layer/unit.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>hardware circuit implementations (Verilog/C/Matlab representations)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Evolved via CGP's point mutations over integer genotype encoding node functions/connections; libraries seeded by several baseline exact architectures and then diversified by mutation-driven search.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Each component is validated by simulation and synthesized with design tools (e.g., Synopsys Design Compiler 45 nm, Vdd=1V); error metrics like MAE and WCE are computed (simulation or formal methods) and power/delay estimated via switching activity and cell delay models.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>The survey reports that EvoApproxLib contains 16,833 non-dominated implementations (across available circuits) and that synthesized results were produced (example: MAE vs. power plots comparing libraries and baselines).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td>Counting of Pareto non-dominated implementations and variety across error/resource trade-offs; library diversity implicit in large number of non-dominated points.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td>16,833 non-dominated implementations reported in EvoApproxLib; EvoApprox8b contains hundreds of 8-bit adder/multiplier variants.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>Library demonstrates explicit trade-offs (Pareto sets) between error metrics (MAE, WCE) and hardware metrics (power, area); surveys present MAE vs power plots showing diverse frontier.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td>MAE vs power/area Pareto plots are presented for 8-bit multipliers showing clusters of EvoApproxLib points dominating many hand-designed approximations; no single analytic frontier provided but extensive empirical Pareto set available.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Arithmetic circuits for hardware accelerators and CNN multipliers; used in NAS and co-design (e.g., ALWANN).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Broken-array multipliers, truncated multipliers, lpAClib multipliers, and other published approximate designs.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CGP can produce large, diverse libraries of approximate circuits providing many Pareto-optimal trade-offs; EvoApproxLib's large non-dominated set (16,833) is evidence of high design diversity and practical executability (synthesizable Verilog with reported power/delay estimates).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolutionary Algorithms in Approximate Computing: A Survey', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1628.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e1628.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Verifiability-driven CGP+SAT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Verifiability-driven CGP combined with SAT solving</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid approach where CGP proposes candidate approximate circuits and a SAT solver is used to formally verify whether a candidate meets a specified error bound within a time budget; circuits proven to satisfy constraints are scored by area and promoted.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Approximating complex arithmetic circuits with formal error guarantees: 32-bit multipliers accomplished.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Verifiability-driven CGP + SAT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CGP generates candidate circuits and a SAT-based verifiability check is used to compute exact worst-case error within solver time limits; if SAT proves the candidate meets the error spec, its fitness is set to area (minimized); otherwise candidate is discarded. The strategy aims to evolve candidates that are both approximate and formally verifiable under given bounds.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>circuit representations (gate-level netlists / candidate circuits)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>CGP point mutation on genotype integers (function codes, connections) to create candidate circuits that are then subject to SAT-based verification.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Formal verification via SAT solvers: the miter CNF is fed to a SAT solver to decide satisfiability/unsatisfiability to determine if the candidate circuit meets the declared error bound (e.g., WCE constraints); runtime limits applied to the solver decide if candidate is usable.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Reported success in approximating and formally guaranteeing error bounds for complex arithmetic circuits including 32-bit multipliers, MACs and dividers (paper [40] summary), but survey does not provide global quantitative success rates; strategy relies on solver time limits.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>Tradeoff implemented operationally: only candidates that can be formally verified within time limits are accepted; this biases search toward designs that are both approximate and tractable for formal verification, potentially reducing novelty but increasing guaranteed executability.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Formal approximation of large arithmetic circuits (up to 32-bit multipliers, 32-bit MACs, 24-bit dividers).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Pure simulation-based CGP approaches (which may not provide formal guarantees); other approximation strategies lacking formal verifiability.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Combining CGP with SAT-based verifiability allows producing approximate arithmetic circuits with formal error guarantees; the approach constrains evolution to verifiable solutions and uses area as a fitness when verification succeeds, trading some search breadth for formal executability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolutionary Algorithms in Approximate Computing: A Survey', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1628.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e1628.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mutation-operator analyses (Souza et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Analysis of mutation operators in multi-objective CGP</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Studies comparing different mutation operators in multi-objective CGP for combinational logic design to assess their impact on search efficiency, solution diversity, and quality of Pareto fronts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>On the analysis of mutation operators in multiobjective cartesian genetic programming for designing combinational logic circuits.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Mutation-operator comparative analyses for CGP</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Works like Souza et al. and De Souza et al. (surveyed) empirically compare mutation operator variants in multi-objective CGP setups (e.g., differing mutation rates, mutation scopes, building-block-aware mutations) to determine impact on convergence speed, Pareto front coverage, and design diversity for combinational circuit benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>circuit genotypes / program representations (CGP encoding)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Variants include standard point mutation, focused multi-gene mutations, building-block-aware mutations, and operators that modify function codes or wiring with different probabilities; studies evaluate their relative efficacy.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Same circuit error and hardware metrics as CGP studies (simulation-based MAE/WCE, area/power estimates); evaluation of mutation operators is based on resulting Pareto front quality and search speed.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Specific results vary by study; the survey notes that using more complex building blocks (e.g., full adders) sped up approximation >10× in one study [45], and comparative analyses are reported but the survey does not enumerate per-operator numeric results.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td>Measured via Pareto front coverage and possibly counts of non-dominated solutions per run (implicit diversity indicators).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Combinational logic circuits (benchmarks up to 15 circuits, arithmetic circuits, multipliers).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Standard single-point mutation CGP, CGP with larger building blocks, different mutation rates; comparisons assess speed and Pareto quality.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mutation operator choice significantly affects search speed and Pareto front quality; incorporating domain-specific building blocks can dramatically speed up search (>10× in one reported case), but detailed numeric comparisons depend on benchmark and operator variant.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolutionary Algorithms in Approximate Computing: A Survey', 'publication_date_yy_mm': '2021-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Cartesian genetic programming: its status and future. <em>(Rating: 2)</em></li>
                <li>A field guide to genetic programming. <em>(Rating: 2)</em></li>
                <li>ABACUS: A technique for automated behavioral synthesis of approximate computing circuits. <em>(Rating: 2)</em></li>
                <li>Evoapprox8b: Library of approximate adders and multipliers for circuit design and benchmarking of approximation methods. <em>(Rating: 2)</em></li>
                <li>A fast and elitist multiobjective genetic algorithm: NSGA-II. <em>(Rating: 2)</em></li>
                <li>Approximating complex arithmetic circuits with formal error guarantees: 32-bit multipliers accomplished. <em>(Rating: 2)</em></li>
                <li>On the analysis of mutation operators in multiobjective cartesian genetic programming for designing combinational logic circuits. <em>(Rating: 2)</em></li>
                <li>Language and compiler support for auto-tuning variable-accuracy algorithms. <em>(Rating: 1)</em></li>
                <li>Automated design of error-resilient and hardware-efficient deep neural networks. <em>(Rating: 1)</em></li>
                <li>Evolutionary design of complex approximate combinational circuits. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1628",
    "paper_id": "paper-237091068",
    "extraction_schema_id": "extraction-schema-31",
    "extracted_data": [
        {
            "name_short": "GP",
            "name_full": "Genetic Programming",
            "brief_description": "Tree-based evolutionary method that evolves executable programs by applying genetic operators (crossover, mutation, selection) to syntax-tree representations; fitness is measured by executing candidate programs on training data and computing error metrics.",
            "citation_title": "A field guide to genetic programming.",
            "mention_or_use": "mention",
            "system_name": "Genetic Programming (GP)",
            "system_description": "GP represents candidate programs as syntax trees built from a set of terminals (inputs/constants) and functions (operators). Evolution proceeds by selecting parent programs, applying subtree crossover (swapping subtrees between parents) and various mutation operators (e.g., subtree replacement, node replacement, subprogram reuse), and evaluating offspring by executing them on a training dataset to compute a fitness defined by an aggregate error metric. GP is used for program synthesis, feature extraction, and approximate implementations at software/feature-extraction levels in the surveyed literature.",
            "input_type": "programs",
            "crossover_operation": "Subtree crossover: two parent syntax trees are selected and subtrees (i.e., program fragments) are swapped to produce offspring that combine code segments from both parents. The paper describes GP's standard crossover at the level of syntax-tree subprograms and also mentions more complex operators (e.g., subprogram definition and reuse).",
            "mutation_operation": "Typical GP mutation replaces a randomly selected subtree with a newly generated subtree (or mutates nodes/constants). The paper also notes a variety of GP mutation operators and possible subprogram re-use operators applied to program trees.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Fitness via program execution: f(α,D_tr) = sum_i E(y_i, α(x_i)), where candidate program α is executed on a training dataset D_tr and E is an error metric (e.g., MAE, application-specific measures). Execution on test data is used to validate generalization.",
            "executability_results": null,
            "diversity_metric": "Not specified for GP per se in the survey; multi-objective EAs employing GP use Pareto non-dominance and population-based diversity preservation methods (e.g., NSGA-II crowding distance).",
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Program synthesis, feature extraction (EEG seizure, ECG arrhythmia), image filters, median filters, hash functions, embedded inference feature extraction.",
            "comparison_baseline": "Hand-designed algorithms, conventional feature extraction pipelines, standard hash functions; sometimes greedy or probabilistic approximation methods (e.g., probabilistic approach to TMR).",
            "key_findings": "GP is effective at synthesizing approximate programs and feature-extraction code that trade energy/resource use for slight accuracy loss; fitness is execution-based (train/test error). The survey emphasizes that GP leverages crossover+mutation to explore program space but does not report standardized novelty metrics; multi-objective frameworks (e.g., NSGA-II) are often used to maintain solution diversity.",
            "uuid": "e1628.0",
            "source_info": {
                "paper_title": "Evolutionary Algorithms in Approximate Computing: A Survey",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "CGP",
            "name_full": "Cartesian Genetic Programming",
            "brief_description": "A graph-based GP variant encoding directed acyclic graphs as fixed-size genotype arrays that evolve circuits or programs predominantly via point mutation and (1+λ) search, widely used for evolving approximate circuits.",
            "citation_title": "Cartesian genetic programming: its status and future.",
            "mention_or_use": "mention",
            "system_name": "Cartesian Genetic Programming (CGP)",
            "system_description": "CGP uses a fixed grid of nodes (n_c × n_r) implementing functions; the genotype is an integer vector that encodes node function codes and connections, producing a DAG for the candidate. The typical search uses a (1+λ) evolutionary strategy with point mutation as the primary genetic operator; crossover is generally not used in the basic CGP configuration. CGP is heavily used for evolving approximate hardware (gate-level, RTL) arithmetic circuits and building libraries of approximations (e.g., EvoApprox8b/EvoApproxLib).",
            "input_type": "hardware descriptions / circuit representations (can be mapped to Verilog/C/Matlab)",
            "crossover_operation": null,
            "mutation_operation": "Point mutation on genotype integers: randomly modify integers encoding node function or connection; mutation may change function codes or wiring. Search strategy typically (1+λ) where λ offspring are generated by mutating a single parent.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Circuit correctness/error measured by simulation (sampling of input vectors) or exact formal methods (ROBDD or SAT-based analysis) to compute error metrics such as MAE, WCE, average Hamming distance; area/delay/power estimated via switching activity/delay models or synthesis tools.",
            "executability_results": null,
            "diversity_metric": "Measured implicitly via multi-objective Pareto non-dominance; the resulting EvoApproxLib reports many Pareto-non-dominated designs (see diversity_results).",
            "diversity_results": "EvoApproxLib (CGP-produced library) contains 16,833 non-dominated implementations (reported in the survey), and EvoApprox8b contains hundreds of approximate implementations (8-bit adders/multipliers).",
            "novelty_executability_tradeoff": "CGP often trades-off error (novelty/deviation from exact behavior) and hardware metrics (area/power/delay); the survey reports multiple Pareto-front trade-offs but no explicit novelty-vs-executability quantitative frontier beyond standard error vs resource curves.",
            "frontier_characterization": "Numerous MAE vs power/area Pareto fronts are reported (e.g., MAE-power plots for evolved 8-bit multipliers); however the survey summarizes these qualitatively and provides example plots (no single numeric frontier description).",
            "benchmark_or_domain": "Gate-level/RTL circuit synthesis (adders, multipliers, median filters, DCT, image filters), FPGA-targeted LUT circuit synthesis, libraries of approximate arithmetic circuits.",
            "comparison_baseline": "Conventional approximate circuit architectures (truncated multipliers, broken-array multipliers), hand-designed adders/multipliers, greedy/probabilistic approximation methods.",
            "key_findings": "CGP (mutation-driven, often without crossover) is highly effective for evolving approximate circuits, producing large libraries of diverse trade-offs (thousands of Pareto-optimal points). CGP can be combined with formal analysis (ROBDD/SAT) to ensure or verify executability/ error bounds; inclusion of larger building blocks (e.g., full adders) can yield &gt;10× speedups in evolution for some tasks.",
            "uuid": "e1628.1",
            "source_info": {
                "paper_title": "Evolutionary Algorithms in Approximate Computing: A Survey",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "LGP",
            "name_full": "Linear Genetic Programming",
            "brief_description": "An evolutionary approach that encodes programs as linear sequences of instructions (machine-level style), applying mutation at the integer/gene level and crossover at instruction boundaries to evolve executable programs.",
            "citation_title": "A field guide to genetic programming.",
            "mention_or_use": "mention",
            "system_name": "Linear Genetic Programming (LGP)",
            "system_description": "LGP encodes candidate solutions as linear sequences of instructions (OP, Ra, Rb, Rc); mutation alters integers (opcodes, registers) and crossover exchanges instruction sequences between parents (usually at instruction granularity). It is applied to evolve instruction-level programs (e.g., specialized hash functions) that are directly executable or synthesizable.",
            "input_type": "programs / instruction sequences",
            "crossover_operation": "Instruction-level crossover: cut-and-splice at instruction boundaries to swap sequences of instructions between parent programs, producing offspring programs that combine instruction subsequences.",
            "mutation_operation": "Randomly alter an integer in the program encoding (change opcode or register indices) to any permitted value; typical point mutation at instruction/gene level.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Quality measured by execution on real data (e.g., hash function performance on network data) and by implementation cost/latency on target hardware (FPGA).",
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Program synthesis for network flow hashing; embedded program generation.",
            "comparison_baseline": "Standard hash functions and hand-designed implementations; conventional program designs.",
            "key_findings": "LGP allows evolving instruction-level programs that are competitive with standard designs for specific hardware targets; crossover at the instruction level and point mutation enable exploration of executable program space, but the survey does not report explicit novelty metrics.",
            "uuid": "e1628.2",
            "source_info": {
                "paper_title": "Evolutionary Algorithms in Approximate Computing: A Survey",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "PetaBricks GA",
            "name_full": "GA for PetaBricks auto-tuning (mutator-based)",
            "brief_description": "A GA-based empirical auto-tuning system for the PetaBricks language that evolves algorithm configurations and decision trees using automatically generated mutator functions applied to code/configurations.",
            "citation_title": "Language and compiler support for auto-tuning variable-accuracy algorithms.",
            "mention_or_use": "mention",
            "system_name": "PetaBricks GA (mutator-driven auto-tuner)",
            "system_description": "The system extends PetaBricks language/compiler with accuracy-aware features and uses a GA to maintain a population of candidate algorithm configurations; mutators (automatically generated per program via static analysis) modify configuration variables and decision trees that select algorithm variants. Candidate configurations are evaluated empirically with a dynamically specified number of tests to balance evaluation cost and statistical relevance.",
            "input_type": "program configuration and decision trees (source-level configuration, not arbitrary literature)",
            "crossover_operation": null,
            "mutation_operation": "Mutator functions specific to each program (automatically generated) modify configuration variables and decision trees, expanding population via mutation-like operators; the paper describes these as mutators rather than standard crossover, with emphasis on empirical test-based evaluation.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Empirical test-based evaluation: candidate algorithm configurations are executed on benchmark inputs and performance/quality metrics collected; number of tests adaptively chosen to ensure statistically relevant fitness values while reducing runtime.",
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Auto-tuning variable-accuracy algorithms in PetaBricks; evaluated on five/twelve representative programs (paper lists six benchmarks in survey).",
            "comparison_baseline": "Hand-tuned algorithm configurations; non-tuned default implementations.",
            "key_findings": "Mutator-driven GA in PetaBricks enables automatic generation and empirical evaluation of multiple accuracy/performance trade-offs with reduced evaluation cost via adaptive testing; crossover is not emphasized, mutators (controlled mutation) are the main operator.",
            "uuid": "e1628.3",
            "source_info": {
                "paper_title": "Evolutionary Algorithms in Approximate Computing: A Survey",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "ABACUS",
            "name_full": "ABACUS (automated behavioral synthesis with AST mutators)",
            "brief_description": "An automated approximation framework that parses Verilog to an AST and applies source-level mutation operators (mutators) to generate approximate Verilog variants which are simulated and synthesized to evaluate error and hardware metrics.",
            "citation_title": "ABACUS: A technique for automated behavioral synthesis of approximate computing circuits.",
            "mention_or_use": "mention",
            "system_name": "ABACUS (AST-mutator-based approximate synthesizer)",
            "system_description": "ABACUS parses behavioral/RTL Verilog into an AST, applies a suite of mutation operators (bit-width simplification, variable-to-constant substitution, approximate arithmetic transformations, expression and loop transformations) to produce approximate source variants, then emits Verilog, simulates for error metrics, and synthesizes for area/power estimation. Originally used with a greedy search, later versions use NSGA-II for multi-objective optimization.",
            "input_type": "code (Verilog source / behavioral descriptions)",
            "crossover_operation": null,
            "mutation_operation": "AST-level mutators: localized transformations on the abstract syntax tree such as bit-width reductions, replacing variables with constants, replacing exact arithmetic with approximate operator models, expression rewrites, and loop transformations.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Simulation-based error metrics (MAE/WCE/ER or application-specific PSNR) and synthesis-derived hardware metrics (area, power) after generated Verilog is synthesized; candidates are thus executable Verilog validated by simulation/synthesis.",
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "ABACUS explicitly trades off error (application quality metrics) against hardware metrics using multi-objective optimization (NSGA-II in later work), but no explicit 'novelty' metric is reported.",
            "frontier_characterization": "Produces Pareto fronts of error vs area/power for mutated programs (qualitative characterization in survey).",
            "benchmark_or_domain": "Behavioral/RTL Verilog designs for image/video processing and other circuits; evaluated on example designs (e.g., DCT, filters).",
            "comparison_baseline": "Exact implementations synthesized with standard tools; manual approximation strategies.",
            "key_findings": "Source-level mutation via AST mutators generates executable approximate Verilog variants whose error and hardware cost can be evaluated end-to-end; using NSGA-II yields Pareto fronts of viable trade-offs. Crossover is not a described operator; search is mutation-driven.",
            "uuid": "e1628.4",
            "source_info": {
                "paper_title": "Evolutionary Algorithms in Approximate Computing: A Survey",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "NSGA-II",
            "name_full": "Non-dominated Sorting Genetic Algorithm II",
            "brief_description": "A popular multi-objective evolutionary algorithm that uses non-dominated sorting and a crowding-distance metric to maintain diversity on the Pareto front while evolving solutions via selection, crossover, and mutation.",
            "citation_title": "A fast and elitist multiobjective genetic algorithm: NSGA-II.",
            "mention_or_use": "mention",
            "system_name": "NSGA-II (multi-objective EA with diversity preservation)",
            "system_description": "NSGA-II ranks population members by Pareto-dominance fronts and uses a crowding-distance metric within fronts to preserve diversity; selection and genetic operators (crossover and mutation) produce offspring and the best individuals across parents and offspring are selected for the next generation. NSGA-II is widely used as the multi-objective optimization backbone for many approximate computing problems (parameter optimization, source-code mutator search, neural architecture search).",
            "input_type": "parameters, configurations, architectures, code-parameter vectors (various depending on application)",
            "crossover_operation": "General GA crossover (application-dependent): when applied to genotype vectors (e.g., integers representing parameters or architecture choices) common crossover schemes (one-point, uniform, etc.) are used by the cited works; the survey does not standardize to one mechanism but notes offspring are created from parents by crossover and mutation in GA setups.",
            "mutation_operation": "Problem-specific mutation: for integer/bit-vector genotypes, random gene perturbation; for code/configuration mutators, mutation operators are application-specific (AST mutators, parameter flips). NSGA-II itself is agnostic to the specific mutation operator used by component implementations.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Fitness components are application-specific (error metrics like MAE/WCE/ER, hardware estimates, latency, energy). NSGA-II treats these as multi-objective signals; executability is enforced via simulation/formal checks when required.",
            "executability_results": null,
            "diversity_metric": "Crowding distance within Pareto fronts (NSGA-II) used to preserve population diversity along the front.",
            "diversity_results": null,
            "novelty_executability_tradeoff": "NSGA-II facilitates exploring trade-offs between error (novelty from exact design) and executability/resource metrics by explicitly constructing Pareto fronts; the survey highlights NSGA-II's role in producing sets of trade-off solutions.",
            "frontier_characterization": "NSGA-II produces Pareto fronts across objectives (error vs area/power/latency/accuracy) in many surveyed works; the paper emphasizes the method's capability to provide a set of diverse trade-off solutions rather than a single optimum.",
            "benchmark_or_domain": "Parameter optimization, source-code approximation, hardware/software co-design, neural architecture search.",
            "comparison_baseline": "Single-objective or weight-aggregated optimization, constrained/prioritization methods; other multi-objective EAs are referenced but NSGA-II is a common benchmark.",
            "key_findings": "NSGA-II is the de-facto multi-objective optimizer in surveyed approximate-computing works because it constructs Pareto fronts and preserves diversity via crowding-distance; it is typically combined with domain-specific crossover/mutation operators and fitness estimation strategies to reduce evaluation cost.",
            "uuid": "e1628.5",
            "source_info": {
                "paper_title": "Evolutionary Algorithms in Approximate Computing: A Survey",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "EvoApproxLib",
            "name_full": "EvoApproxLib (library of CGP-evolved approximate circuits)",
            "brief_description": "A publicly available library of evolved approximate arithmetic circuits (adders, multipliers, dividers, MACs) produced primarily by CGP, characterized by multiple error metrics and hardware parameters, and provided in Verilog/C/Matlab formats.",
            "citation_title": "Evoapprox8b: Library of approximate adders and multipliers for circuit design and benchmarking of approximation methods.",
            "mention_or_use": "mention",
            "system_name": "EvoApproxLib (CGP-evolved approximate circuit library)",
            "system_description": "EvoApproxLib aggregates hundreds-to-thousands of CGP-evolved approximate implementations across bitwidths (8-bit up to 128-bit for adders, various multipliers, MACs), each fully characterized by error metrics (MAE, WCE, Hamming distance) and estimated electrical parameters (power, delay) obtained via synthesis modeling. The library serves as a resource for selecting approximate building blocks and for NAS/co-design tools to pick components per layer/unit.",
            "input_type": "hardware circuit implementations (Verilog/C/Matlab representations)",
            "crossover_operation": null,
            "mutation_operation": "Evolved via CGP's point mutations over integer genotype encoding node functions/connections; libraries seeded by several baseline exact architectures and then diversified by mutation-driven search.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Each component is validated by simulation and synthesized with design tools (e.g., Synopsys Design Compiler 45 nm, Vdd=1V); error metrics like MAE and WCE are computed (simulation or formal methods) and power/delay estimated via switching activity and cell delay models.",
            "executability_results": "The survey reports that EvoApproxLib contains 16,833 non-dominated implementations (across available circuits) and that synthesized results were produced (example: MAE vs. power plots comparing libraries and baselines).",
            "diversity_metric": "Counting of Pareto non-dominated implementations and variety across error/resource trade-offs; library diversity implicit in large number of non-dominated points.",
            "diversity_results": "16,833 non-dominated implementations reported in EvoApproxLib; EvoApprox8b contains hundreds of 8-bit adder/multiplier variants.",
            "novelty_executability_tradeoff": "Library demonstrates explicit trade-offs (Pareto sets) between error metrics (MAE, WCE) and hardware metrics (power, area); surveys present MAE vs power plots showing diverse frontier.",
            "frontier_characterization": "MAE vs power/area Pareto plots are presented for 8-bit multipliers showing clusters of EvoApproxLib points dominating many hand-designed approximations; no single analytic frontier provided but extensive empirical Pareto set available.",
            "benchmark_or_domain": "Arithmetic circuits for hardware accelerators and CNN multipliers; used in NAS and co-design (e.g., ALWANN).",
            "comparison_baseline": "Broken-array multipliers, truncated multipliers, lpAClib multipliers, and other published approximate designs.",
            "key_findings": "CGP can produce large, diverse libraries of approximate circuits providing many Pareto-optimal trade-offs; EvoApproxLib's large non-dominated set (16,833) is evidence of high design diversity and practical executability (synthesizable Verilog with reported power/delay estimates).",
            "uuid": "e1628.6",
            "source_info": {
                "paper_title": "Evolutionary Algorithms in Approximate Computing: A Survey",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "Verifiability-driven CGP+SAT",
            "name_full": "Verifiability-driven CGP combined with SAT solving",
            "brief_description": "A hybrid approach where CGP proposes candidate approximate circuits and a SAT solver is used to formally verify whether a candidate meets a specified error bound within a time budget; circuits proven to satisfy constraints are scored by area and promoted.",
            "citation_title": "Approximating complex arithmetic circuits with formal error guarantees: 32-bit multipliers accomplished.",
            "mention_or_use": "mention",
            "system_name": "Verifiability-driven CGP + SAT",
            "system_description": "CGP generates candidate circuits and a SAT-based verifiability check is used to compute exact worst-case error within solver time limits; if SAT proves the candidate meets the error spec, its fitness is set to area (minimized); otherwise candidate is discarded. The strategy aims to evolve candidates that are both approximate and formally verifiable under given bounds.",
            "input_type": "circuit representations (gate-level netlists / candidate circuits)",
            "crossover_operation": null,
            "mutation_operation": "CGP point mutation on genotype integers (function codes, connections) to create candidate circuits that are then subject to SAT-based verification.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Formal verification via SAT solvers: the miter CNF is fed to a SAT solver to decide satisfiability/unsatisfiability to determine if the candidate circuit meets the declared error bound (e.g., WCE constraints); runtime limits applied to the solver decide if candidate is usable.",
            "executability_results": "Reported success in approximating and formally guaranteeing error bounds for complex arithmetic circuits including 32-bit multipliers, MACs and dividers (paper [40] summary), but survey does not provide global quantitative success rates; strategy relies on solver time limits.",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "Tradeoff implemented operationally: only candidates that can be formally verified within time limits are accepted; this biases search toward designs that are both approximate and tractable for formal verification, potentially reducing novelty but increasing guaranteed executability.",
            "frontier_characterization": null,
            "benchmark_or_domain": "Formal approximation of large arithmetic circuits (up to 32-bit multipliers, 32-bit MACs, 24-bit dividers).",
            "comparison_baseline": "Pure simulation-based CGP approaches (which may not provide formal guarantees); other approximation strategies lacking formal verifiability.",
            "key_findings": "Combining CGP with SAT-based verifiability allows producing approximate arithmetic circuits with formal error guarantees; the approach constrains evolution to verifiable solutions and uses area as a fitness when verification succeeds, trading some search breadth for formal executability.",
            "uuid": "e1628.7",
            "source_info": {
                "paper_title": "Evolutionary Algorithms in Approximate Computing: A Survey",
                "publication_date_yy_mm": "2021-08"
            }
        },
        {
            "name_short": "Mutation-operator analyses (Souza et al.)",
            "name_full": "Analysis of mutation operators in multi-objective CGP",
            "brief_description": "Studies comparing different mutation operators in multi-objective CGP for combinational logic design to assess their impact on search efficiency, solution diversity, and quality of Pareto fronts.",
            "citation_title": "On the analysis of mutation operators in multiobjective cartesian genetic programming for designing combinational logic circuits.",
            "mention_or_use": "mention",
            "system_name": "Mutation-operator comparative analyses for CGP",
            "system_description": "Works like Souza et al. and De Souza et al. (surveyed) empirically compare mutation operator variants in multi-objective CGP setups (e.g., differing mutation rates, mutation scopes, building-block-aware mutations) to determine impact on convergence speed, Pareto front coverage, and design diversity for combinational circuit benchmarks.",
            "input_type": "circuit genotypes / program representations (CGP encoding)",
            "crossover_operation": null,
            "mutation_operation": "Variants include standard point mutation, focused multi-gene mutations, building-block-aware mutations, and operators that modify function codes or wiring with different probabilities; studies evaluate their relative efficacy.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Same circuit error and hardware metrics as CGP studies (simulation-based MAE/WCE, area/power estimates); evaluation of mutation operators is based on resulting Pareto front quality and search speed.",
            "executability_results": "Specific results vary by study; the survey notes that using more complex building blocks (e.g., full adders) sped up approximation &gt;10× in one study [45], and comparative analyses are reported but the survey does not enumerate per-operator numeric results.",
            "diversity_metric": "Measured via Pareto front coverage and possibly counts of non-dominated solutions per run (implicit diversity indicators).",
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Combinational logic circuits (benchmarks up to 15 circuits, arithmetic circuits, multipliers).",
            "comparison_baseline": "Standard single-point mutation CGP, CGP with larger building blocks, different mutation rates; comparisons assess speed and Pareto quality.",
            "key_findings": "Mutation operator choice significantly affects search speed and Pareto front quality; incorporating domain-specific building blocks can dramatically speed up search (&gt;10× in one reported case), but detailed numeric comparisons depend on benchmark and operator variant.",
            "uuid": "e1628.8",
            "source_info": {
                "paper_title": "Evolutionary Algorithms in Approximate Computing: A Survey",
                "publication_date_yy_mm": "2021-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Cartesian genetic programming: its status and future.",
            "rating": 2,
            "sanitized_title": "cartesian_genetic_programming_its_status_and_future"
        },
        {
            "paper_title": "A field guide to genetic programming.",
            "rating": 2,
            "sanitized_title": "a_field_guide_to_genetic_programming"
        },
        {
            "paper_title": "ABACUS: A technique for automated behavioral synthesis of approximate computing circuits.",
            "rating": 2,
            "sanitized_title": "abacus_a_technique_for_automated_behavioral_synthesis_of_approximate_computing_circuits"
        },
        {
            "paper_title": "Evoapprox8b: Library of approximate adders and multipliers for circuit design and benchmarking of approximation methods.",
            "rating": 2,
            "sanitized_title": "evoapprox8b_library_of_approximate_adders_and_multipliers_for_circuit_design_and_benchmarking_of_approximation_methods"
        },
        {
            "paper_title": "A fast and elitist multiobjective genetic algorithm: NSGA-II.",
            "rating": 2,
            "sanitized_title": "a_fast_and_elitist_multiobjective_genetic_algorithm_nsgaii"
        },
        {
            "paper_title": "Approximating complex arithmetic circuits with formal error guarantees: 32-bit multipliers accomplished.",
            "rating": 2,
            "sanitized_title": "approximating_complex_arithmetic_circuits_with_formal_error_guarantees_32bit_multipliers_accomplished"
        },
        {
            "paper_title": "On the analysis of mutation operators in multiobjective cartesian genetic programming for designing combinational logic circuits.",
            "rating": 2,
            "sanitized_title": "on_the_analysis_of_mutation_operators_in_multiobjective_cartesian_genetic_programming_for_designing_combinational_logic_circuits"
        },
        {
            "paper_title": "Language and compiler support for auto-tuning variable-accuracy algorithms.",
            "rating": 1,
            "sanitized_title": "language_and_compiler_support_for_autotuning_variableaccuracy_algorithms"
        },
        {
            "paper_title": "Automated design of error-resilient and hardware-efficient deep neural networks.",
            "rating": 1,
            "sanitized_title": "automated_design_of_errorresilient_and_hardwareefficient_deep_neural_networks"
        },
        {
            "paper_title": "Evolutionary design of complex approximate combinational circuits.",
            "rating": 1,
            "sanitized_title": "evolutionary_design_of_complex_approximate_combinational_circuits"
        }
    ],
    "cost": 0.02248325,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Evolutionary Algorithms in Approximate Computing: A Survey</p>
<p>Lukas Sekanina sekanina@fit.vutbr.cz 
Faculty of Information Technology
Brno University of Technology
Bozetechova 2612 66BrnoCzech Republic</p>
<p>Evolutionary Algorithms in Approximate Computing: A Survey
Submitted to Journal of Integrated Circuits and Systems 1Index Terms-evolutionary algorithmapproximate com- putingdigital circuitneural networkoptimization
In recent years, many design automation methods have been developed to routinely create approximate implementations of circuits and programs that show excellent trade-offs between the quality of output and required resources. This paper deals with evolutionary approximation as one of the popular approximation methods. The paper provides the first survey of evolutionary algorithm (EA)-based approaches applied in the context of approximate computing. The survey reveals that EAs are primarily applied as multiobjective optimizers. We propose to divide these approaches into two main classes: (i) parameter optimization in which the EA optimizes a vector of system parameters, and (ii) synthesis and optimization in which EA is responsible for determining the architecture and parameters of the resulting system. The evolutionary approximation has been applied at all levels of design abstraction and in many different applications. The neural architecture search enabling the automated hardwareaware design of approximate deep neural networks was identified as a newly emerging topic in this area.Index Terms-evolutionary algorithm; approximate computing; digital circuit; neural network; optimization. the iterations can be stopped earlier or approximated using a heuristics[6]. Approximate computing has been applied at different levels of the computing stack. Surveys [2, 3] provide detailed introduction to relevant approximation techniques. At the lowest level, voltage over-scaling enables to reduce power</p>
<p>I. INTRODUCTION</p>
<p>As Dennard's scaling is no longer valid for the newest technologies, it is still more and more difficult to increase the performance of computer systems under a given power budget [1]. Moreover, challenging technological issues (such as higher process variability) typical for the smallest technology nodes lead to reliability problems that must be properly handled during manufacturing, testing, verification, and design. One of the most prominent approaches developed to address these issues is approximate computing [2,3]. It exploits the fact that many applications are intrinsically errorresilient. This resilience can be utilized to simplify their implementation and thus reduce power consumption, area, or delay for an acceptable loss in the quality of output. Current pervasive applications such as machine learning, image, video and speech processing, data mining, and robotics, fortunately, belong to this class of error-resilient applications.</p>
<p>Many design automation methods have been developed to create approximate implementations for this important class of applications [2,3,4]. State-of-the-art results were quite often obtained by evolutionary algorithms (EAs) [5]. The reason for the good applicability of EAs for purposes of approximate computing is that EAs are excellent in stochastic multi-objective design and optimization and in handling various constraints. The approximation problem can be formulated as a multi-objective optimization problem in which the accuracy, performance, and resources are conflicting design objectives. EA can be seeded by existing solution(s) whose functionality is degraded in a controlled way in the course of evolution. The result of the evolution process is a set of solutions that exhibit useful trade-offs among the key observed objectives.</p>
<p>In the context of approximate computing, EAs have been applied at different levels of design abstraction, for optimization as well as synthesis purposes, and in numerous applications. The goal of this paper is to provide the first systematic survey of the utilization of EAs in approximate computing. We identified over 60 papers in this area that we divided into two main classes concerning the use of EA: (i) parameter optimization in which the EA optimizes a vector of system parameters, and (ii) synthesis and optimization in which the EA is responsible for determining the architecture and parameters of the resulting system. As evolutionary algorithms are frequently used for purposes of design, optimization, and approximation of deep neural networks (DNNs), we handle this topic separately from the previous two in the third part of this survey, which deals with the evolutionary approximation in neural networks. After reading this paper, the reader should understand why, when, and how EAs are currently used in the context of approximate computing.</p>
<p>The rest of the paper is organized as follows. Sections II. and III. provide an introduction to approximate computing and evolutionary algorithms, respectively. In Section IV., we introduce our approach to the classification of the evolutionary approaches in approximate computing. Section V. is then devoted to the applications in which an EA optimizes a vector of parameters of a system undergoing the approximation. Section VI. deals with the evolutionary design of approximate implementations by genetic programming. The evolutionary approximation of neural networks is discussed in Section VII. Conclusions are given in Section VIII.</p>
<p>II. APPROXIMATE COMPUTING</p>
<p>According to Mittal [2] "Approximate computing exploits the gap between the level of accuracy required by the applications/users and that provided by the computing system, for achieving diverse optimizations". The error resilience originates in applications with (i) analog inputs (such as image processing, sensor data processing, and voice recognition that operate on noisy real-world data), (ii) analog output (which is intended for human perception and can inherently tolerate errors imperceptible to users), (iii) no unique answer, and (iv) iterative processing of large amounts of data where consumption while some timing errors are introduced into the circuit. One of the most popular and general-purpose approximation techniques is functional approximation which replaces the exact circuit or program by a simplified implementation. The functional approximation is often used in approximate implementations of arithmetic circuits as well as accelerators. In the basic case, it takes a form of a suitable bit width reduction or pruning of less critical parts of the circuit. However, sophisticated strategies based on logic resynthesis have also been proposed [4]. Approximations can be injected to the memory subsystem by approximating the cache functionality, memory operations, or elementary memory cells. At the highest level of abstraction, approximations can be introduced at the level of the instruction set architecture, schedulers, compilers, or to the source code through techniques such as loop perforation, task skipping, relaxed synchronization, and memorization.</p>
<p>Approximate implementations are usually created manually by a domain expert. However, a recent trend is to develop fully automated approximation methods capable of (i) identifying suitable components that should undergo the approximation process with the highest priority, (ii) generating candidate approximate implementations, and (iii) evaluating them concerning various criteria. These methods are constructed using iterative heuristics [4].</p>
<p>The quality of approximate implementations is typically expressed using one or several error metrics, where the most commonly used ones are the error rate (ER), the mean absolute error (MAE), and the worst-case error (WCE):
ER = ∀x∈B:Oapprox(x) =Oorig(x) 1 n (1) MAE = ∀x∈B |O approx (x) − O orig (x)| n (2) WCE = max ∀x∈B |O approx (x) − O orig (x)|(3)
where the output of the approximate implementation and original (exact) implementation is O approx and O orig , B contains all possible input vectors, and n = |B|. Apart from these general-purpose metrics, the error can also be evaluated at the application level using application-specific metrics such as the Peak Signal to Noise Ratio (PSNR) for image processing. The error is obtained either by simulation (typically only a subset of B is considered to reduce a considerable computation overhead), error probability modeling [7] or exact formal analysis [8]. For example, in the case of 16-bit approximate multipliers generated in the course of approximation, the relative error between the exact WCE and the WCE estimated using 10 8 randomly generate vectors (out of all possible 2 32 vectors) can go far beyond 10%. This inaccuracy of simulation has motivated the development of exact formal error analysis methods that are surveyed, e.g., in [8].</p>
<p>III. EVOLUTIONARY ALGORITHMS</p>
<p>Evolutionary algorithms are metaheuristic search algorithms that employ a population of candidate solutions and bio-inspired operators such as mutation, crossover, and selection to search effectively in the space of candidate solutions [9]. Contrasted to the gradient-based optimization methods, nothing is supposed about the objective function except its evaluability.</p>
<p>A generic single-objective EA utilizing fitness function f , which assigns a fitness score to every candidate solution, works as follows. After initializing and evaluating the first population, the algorithm repeats the following steps until a termination condition is not satisfied: (i) selection of parents for a new population; (ii) creating offspring from the parents by means of crossover, mutation, and other relevant operators; (iii) creating the new population by considering parents as well as offspring; (iv) evaluation of the new population. The candidate solution with the highest fitness score is the result of EA (if the objective is to maximize the fitness).</p>
<p>Various branches of EAs primarily differ in problem encoding, genetic operators, and fitness function construction. These topics are briefly discussed in the following paragraphs. At the same time, we have to omit some advanced topics (such as co-evolutionary algorithms, parallel EAs, and various hybrid methods) and related algorithms (ant colony optimization (ACO), particle swarm optimization (PSO), etc.) because of limited space.</p>
<p>A. Types of EAs</p>
<p>The genetic algorithm (GA) tries to optimize a vector of parameters. This vector is called genotype, its length is usually constant, and the values it contains are either of the same data types (e.g., Boolean values, integers, or floats) or mixed data type. GA uses fitness proportional or tournament selection (for details, see [9]) to determine the parents of the new population. Mutation randomly modifies each item of the parental vector (the so-called gene) with a very low probability. Crossover swaps some parts of two parents and creates two offspring. The new population is composed of either offspring individuals (a generational GA) or both the offspring and parents (a steady-state GA).</p>
<p>Genetic programming (GP) has been invented for automated program synthesis [10]. Candidate programs are represented by syntax trees. GP defines a set of terminals (the inputs to the program and constants) and a set of functions that are used as building blocks of candidate programs. The search algorithm is almost identical to the generic EA. In addition to crossover and mutation, more complex genetic operators are often employed, e.g., subprogram definition and reuse [10]. In order to obtain the fitness score, a candidate program α is executed on a training data set D tr containing n pairs (x i , y i ), where y i is the expected output value for the input x i . The objective of GP is to minimize the overall error, which is typically expressed in the fitness function as
f (α, D tr ) = n i=1 E(y i , α(x i )),(4)
where E is a suitable error metric. The result of GP (i.e., the best performing program at the end of evolution) is evaluated on test data to validate its performance. GP is often presented as a solver for symbolic regression problems. Cartesian Genetic Programming (CGP) was established for the evolutionary circuit design [11]. A candidate solution is represented using a grid of n c × n r nodes, each of them implementing one of n a -input functions from the function set. A candidate circuit has n i primary inputs and n o primary outputs. The genotype consists of (n a + 1)n c n r + n o integers that define (i) function codes of the nodes, (ii) the connections among the nodes and with primary inputs, and (iii) the connection of the primary outputs. The feedback connections are not allowed in the basic version of CGP. The genotype thus specifies a directed acyclic graph (some nodes of the grid can remain unused). CGP applies a point mutation as its basic genetic operator and a simple (1 + λ) search strategy, in which λ offspring are generated from a single parent. The main advantage of CGP is that subcircuits can easily be reused, and a designer can constrain the maximum size of the circuit by a suitable setting of the number of columns. Furthermore, CGP can evolve solutions at various levels of abstraction, including the transistor, gate, registertransfer (RT) as well as program level, by choosing suitable types of nodes [11].</p>
<p>Linear Genetic Programming (LGP) focuses on the automated design of instruction-level programs for processors with general-purpose registers [10]. Some registers hold the program inputs, and the program output is expected in predefined register(s). A candidate solution is a machine-level program consisting of instructions, each of them in the form (OP, R a , R b , R c ), where OP is the operation code and R a , R b , and R c are registers used by this instruction. Candidate programs are encoded as strings of integers. The mutation is quite standard as it alters a randomly selected integer to any permitted value. The crossover is usually applied at the level of instructions, not individual genes.</p>
<p>B. Multi-Objective Optimization</p>
<p>The approximation problem can be seen as a multiobjective optimization problem, i.e. an optimization problem that involves multiple objective functions g 1 (a), g 2 (a), . . . , g k (a), where g i : A → R, k is the number of objectives, and a ∈ A is a candidate solution from the set of solutions A. In the multi-objective optimization, there does not typically exist one solution that minimizes all objective functions simultaneously because the design objectives are conflicting. Hence, rather than one (optimal) solution, the optimization results in a set of solutions, i.e. the solutions that cannot be improved in any of the objectives without degrading at least one of the other objectives. Formally, a solution a is said to (Pareto) dominate another solution b, a, b ∈ A, if: g i (a) ≤ g i (b) for all i ∈ {1, 2, . . . , k} and g j (a) &lt; g j (b) for at least one index j ∈ {1, 2, . . . , k} , and all g i have to be minimized. A solution a * ∈ A is called a non-dominated solution if there does not exist another solution that dominates it. The set of non-dominated solutions is called the Pareto front. We say that non-dominated solutions are Pareto optimal solutions if all possible candidate solutions are considered during the optimization, and there are no provably better non-dominated solutions in the search space. In practice, we are almost always faced with a situation in which the EA produces suboptimal solutions, i.e., the resulting Pareto front contains the best non-dominated solutions obtained during the evolution, but not truly Pareto-optimal solutions. A recent survey of evolutionary multi-objective optimization methods is in [12].</p>
<p>A common approach adopted in the design of approximate implementations is either (i) transforming the multiobjective problem to a single-objective one (using suitable constraints, prioritization or aggregation methods) and solving it with a common single-objective method or (ii) employing a truly multi-objective approach.</p>
<p>When using constraints, only one of the objective functions is optimized while the remaining ones are transformed to constraints g i (a) ≤ c i , where c i are suitable constants. A penalty function is then introduced to punish any solution violating the constraints. However, this method does not guarantee that all hard constraints are satisfied because solutions with a high penalty can be promoted to the next generation if there are no better solutions. The prioritization means that the most important objective is optimized first, and when a suitable solution is obtained, the second most important objective is optimized but ensuring that the first one is not worsened. This is repeated for all the objective functions according to their priority. Finally, the aggregation methods introduce a suitable aggregation function (such as the weighted sum, weighted exponential sum, or weighted product) for the objective functions and optimize the composition. This approach suffers from several problems. First, it is not easy to determine suitable weights. Second, the linear weighted sum only works for problems with convex Pareto fronts, i.e., solutions on non-convex segments are unreachable. Third, similar to the constrained optimization, the method has to be executed several times with different weight settings to approximate the Pareto optimal front.</p>
<p>Truly multi-objective optimization methods iteratively build the Pareto front in the course of optimization by comparing candidate solutions using the non-dominance relation, promoting good solutions, and trying to cover the expected Pareto front. In comparison with other multi-objective optimization methods, EAs gained a significant attention in this task. One of the most popular methods is NSGA-II [13]. It is based on sorting individuals in a population according to the dominance relation into multiple fronts. The first front contains all non-dominated solutions. Each subsequent front is constructed by removing all the preceding fronts from the population and finding a new Pareto front in the remaining individuals. The solutions within the individual fronts are then sorted according to the crowding distance metric. This metric helps to preserve the diversity of the population along the fronts. Best individuals from these fronts then serve as parents for the new population. NSGA-II thus always produces a set of solutions (i.e., a Pareto front) when terminated.</p>
<p>IV. PROPOSED CLASSIFICATION</p>
<p>In this section, we present four observations that we utilized to introduce the proposed classification of EAs in the context of approximate computing.</p>
<p>Employing the EA is natural concerning its goal in the approximation task. Minor modifications introduced in the course of evolution into existing solutions (note that EA is typically seeded with an exact solution) and the principle of the survival of the fittest naturally lead to discovering such solutions which show very good trade-offs between the error DOI and other objectives. Our first observation is that all problems solved by EAs in the context of approximate computing are multi-objective optimization problems. Hence, it makes no sense to distinguish between single-and multi-objective approaches.</p>
<p>The second observation is related to the problem encoding. The inspected papers can be divided into two main classes. The Parameter Optimization class deals with problems in which the user specifies a set of parameters that have to be optimized. These parameters are then stored in the genotype, and a GA is typically employed to optimize their values. A typical optimization problem within this class is a component selection problem in which the GA's task is to select the most suitable approximate component (from a library of components) for each of n predefined positions in the circuit or program implementation. On the other hand, the Synthesis and Optimization class covers such problems in which approximate programs or circuits are synthesized and optimized. This task is performed by a suitable type of GP. This is a more challenging problem than the parameter optimization because the genotype encodes not only types of components but also their connection, and the search space is thus much larger.</p>
<p>One of the fitness functions typically evaluates the error of candidate solutions. Other fitness functions are devoted to performance (delay, latency) and resources (area, power). The third observation reflects the fact that the fitness score can be either precisely evaluated (which is usually computationally demanding) or estimated (which is less expensive). See Section II. for a quick overview of the approaches adopted for the error calculation. Regarding the other objectives: in the course of evolution, it is not tractable to precisely evaluate all circuit parameters (in particular, power consumption) using professional design tools. Hence, basic circuit characteristics are estimated in the fitness function, and only resulting circuits are fully evaluated using the standard process at the end of evolution.</p>
<p>Our fourth observation is that the evolutionary approximation has been applied at all levels of the circuit design abstraction, i.e., at the level of abstract models (such as binary decision diagrams (BDDs)), gates, look-up tables (LUT), register transfer (RTL), and behavioral description, as well as at the level of software and compilers. Both the Parameter Optimization and the Synthesis and Optimization methods have been utilized on all levels of design abstraction. Table I shows that we classified the papers into two main classes: Parameter Optimization and Synthesis and Parameter Optimization. Within these classes we further use the following sub-classes: the EA used -GA, GP, CGP, LGP, PSO; Level of abstraction -gate, LUT, RTL, SW, and BDD; Error calculation method -simulation, statistical method, BDD analysis, SAT solving, combinatorial analysis; Platform -processor (CPU), microcontroller (MCU), field programmable gate array (FPGA), and application-specific integrated circuit (ASIC). Table I also briefly characterizes the Application domain and Benchmark problems for each paper.</p>
<p>Because of limited space, we do not provide any systematic comparison between EAs and other approximation methods. Only in some cases, we highlight some interesting improvements obtained by EAs with respect to other methods. More details are available in referenced papers.</p>
<p>V. PARAMETER OPTIMIZATION</p>
<p>The parameter optimization problem consists of optimizing n parameters that the user must carefully choose from all the relevant parameters associated with a given system under approximation. These parameters typically determine the bit width of components, the version of approximate implementation of a component, or other configuration options. The genotype then contains n values that are optimized by EA with the aim of finding the best trade-offs between the error and other objectives.</p>
<p>A. Hardware Level</p>
<p>The following papers demonstrate that the parameter optimization can be introduced at different levels of abstraction.</p>
<p>Several approximate transistor-level implementations of a one-bit full adder are considered in [16]. A parallel genetic algorithm is then employed to select the most suitable ones to serve as building blocks of multi-bit adders.</p>
<p>Following the same idea, from a set of different approximate adder blocks, a GA is used in [20] to select the most relevant ones to build a heterogeneous multiplier. At the same time, the MAE is minimized for the overall design.</p>
<p>In [19], NSGA-II performs this selection from a library of 11 approximate implementations to minimize the powerarea product and error in an image compression application. Compared to the baseline architecture that uses regular multipliers in the 65 nm CMOS technology, 43% area, and 54% power savings were obtained with a minimal PSNR degradation.</p>
<p>In [24], GA tries to select the most suitable versions of approximate components (adders and multipliers) for approximate implementations of Sobel, Prewitt, and Laplacian filter. The goal is to minimize energy consumption while meeting the quality constraints.</p>
<p>Barbareschi et al. [25] employs NSGA-II to find the best trade-offs between the classification accuracy and hardware cost for a set of classifiers (based on decision trees) that are implemented in FPGA. The genotype specifies the number of bits needed for each comparison conducted in the first layer of the classifier.</p>
<p>A multi-objective evolutionary algorithm is employed to solve the so-called binding problem of high-level synthesis (HLS). The task is to find an optimal assignment of approximate components to nodes of the data flow graph describing a complex digital circuit [18]. The genotype contains n integers specifying a particular component version assuming that the data flow graph has n nodes for which the biding must be determined. The error is estimated using a statistical error analysis based on error propagation models in arithmetic circuits. The method is evaluated using the reduce (sum) and discrete cosine transform (DCT) circuits. As the library of approximate circuits (a predecessor of EvoApprox8b [39]) was too large (hundreds of approximate components), two methods enabling to reduce its volume (and so the search space) while still providing suitable trade-offs for the HLS are proposed and compared. And finally, in this category, we present two more sophisticated approaches. In [22], the parameter optimization is combined with constrained pruning. The objective is to approximate a digital signal processing block of a hearing aid consisting of m FIR filter banks. The method utilizes a library of pruned circuit topologies and approximate multipliers indexed according to the level or degree of pruning. The approximation problem is formulated as assigning a particular inexact level to each filter bank (i.e., all components of the bank will have the same degree of approximation). The genome contains m integers that define the level of approximation for each bank. The goal of NSGA-II is to minimize power consumption and maximize the quality of signal processing. The resulting inexact FIR filter bank is 1.92× or 2.56× more efficient in terms of power consumed while producing 10% or 20% less intelligible speech, respectively, compared with a hearing-aid utilizing exact filters.</p>
<p>A display rendering pipeline (including circuits for tone mapping, color space conversion, electro-optical transfer function compensation, etc.) is constructed to process input images in monitors. This pipeline can be characterized using several parameters whose values can be optimized to maximize the image color quality while minimizing the area and power consumed on an FPGA. These parameters are encoded into a genotype containing thus the number of fraction bits, types of approximate adders, etc. and optimized by NSGA-II [23].</p>
<p>B. Software Level</p>
<p>In the context of software-level approximation, the parameter optimization can take various forms.</p>
<p>Ansel et al. [14] propose a new kind of language extension and an accuracy-aware compiler to create a code supporting various degrees of accuracy for the PetaBricks programming language and compiler. The compiler performs empirical auto-tuning based on a GA to build an optimized configuration for each accuracy level required by a user. GA maintains a population of candidate algorithm configurations which is expanded using a set of mutators. The mutator functions are different for each program and are generated fully automatically with information from static analysis. Mutators can modify configuration variables or decision trees that decide which algorithm to use for each choice site, accuracy, and input size. To evaluate candidate programs, the number of tests is dynamically specified with the aim of shortening the evaluation time and, at the same time, obtaining a statistically relevant fitness score. The method was evaluated using six benchmarks that are representative of commonly used algorithms that leverage variable accuracy.</p>
<p>ExpAX [15] introduces annotations to the source code that enable to express error expectations. For example, the expectation magnitude(v) &gt; c using E with rate &lt; d allows to bound both the error rate and the error magnitude of variable v: it states that the rate at which the error incurred on variable v exceeds normalized magnitude c is bounded by d concerning the error metrics E. A static safety analysis is performed that uses the high-level expectations to infer a safe-to-approximate set of program operations automatically. This step requires a finding of possible safe-to-approximate variables.</p>
<p>Unsafe-to-approximate variables are variables violating memory safety or functional correctness. A GA is used to determine a subset of safe-to-approximate operations that minimizes the error and energy requirements. The genotype is a bit vector indicating for each variable whether it is or is not suitable for approximation. Significant energy savings (up to 35%) with the considerable reduction in programmer effort (3× to 113× fewer annotations w.r.t EnerJ [53]) were reported while providing formal safety and statistical quality-of-result guarantees.</p>
<p>GRATER [17] performs a sensitivity analysis to find safeto-approximate variables in OpenCL kernel. The genome specifies the precision (i.e., data type) of these variables. The objective is to find an approximate kernel that minimizes the resource utilization on FPGA while meeting the target quality.</p>
<p>Barone et al. [26] propose E-IDEA, an automatic application-driven approximation tool targeting different implementations (hardware and software). E-IDEA uses Clang-Chimera tool to analyze the Abstract Syntax Tree (AST) of the C/C++ source code of the application. Through the so-called mutators, approximations can be introduced at the level of the source code. The set of mutators includes loop-perforation mutators, precision-scaling mutators for the floating-point arithmetic, a precision scaling mutator for the integer arithmetic, and a mutator supporting approximate arithmetic operator models of circuits being part of the EvoApproxLib library [39]. An evolutionary approximation method based on NSGA-II tries to find the best approximation version of a given C/C++ code, according to user-defined optimization objectives. A candidate solution is represented as a vector of integers; each of them corresponds to one parameter that can be mutated. The positions in the source code at which a mutation can be applied are specified by a set of matching rules. The method is evaluated using five applications (K-Means, Taylor, JPEG, Sobel, and CNN), for which it shows good trade-offs between the error and hardware cost.</p>
<p>VI. SYNTHESIS OF APPROXIMATE IMPLEMENTATIONS</p>
<p>This section deals with evolutionary algorithms that optimize not only some circuit or program parameters, but also simplify, optimize, or even redesign circuit topology. This task is predominantly solved by genetic programming, and by CGP in particular. We will start our survey with gatelevel designs and then continue up to higher levels of abstraction. CGP usually begins with an exact circuit implementation and tries to find the best trade-offs between the error and other properties of the approximate implementations. In the multi-objective setup, CGP is either combined with NSGA-II (or another truly multi-objective EA) or some of the objectives are considered as constraints (e.g., the error and delay) while CGP minimizes the remaining one (e.g., the power consumption). The CGP-based approximation is often utilized for arithmetic circuits, but the method is identical if a general logic synthesis (and optimization) problem is considered. Contrasted to the conventional paradigm, which employs different methods for the synthesis of arithmetic circuits and general logic, this unified methodology is seen as a strong advantage of CGP.</p>
<p>A. Gate Level Approximations</p>
<p>The first work on evolutionary gate-level approximation is from 2013 [28]. CGP is used to minimize the error while resources (the number of gates) available to CGP are constrained. Interesting trade-offs are evolved for four singleoutput circuits and 2-bit, 3-bit, and 4-bit adders. It is also demonstrated for arithmetic circuits that the error metric based on MAE provides better results than Hamming distance. This work is extended for 2-bit, 3-bit, and 4-bit multipliers and median filters in [29]. Evolved small approximate multipliers are deployed as building blocks of larger 8-bit and 16-bit approximate multipliers that show better tradeoffs than the approximate multipliers presented in seminal paper [54].</p>
<p>CGP evolved a library of approximate arithmetic circuits that exhibit many different trade-offs between the error (expressed by several error metrics) and circuit properties. The first version of the library, EvoApprox8b, contains hundreds of approximate implementations of 8-bit adders and multipliers [39]. To seed the initial population, the authors utilize 13 different adders and 6 different multipliers ranging from the basic implementations such as Ripple-Carry Adder or Ripple-Carry Array Multiplier to advanced architectures such as Higher Valency Tree Adder and Wallace Tree Multiplier. Power consumption is estimated using the switching activity analysis. The delay of a candidate circuit is calculated as the sum of the delays on the cells along the longest path. The delay of a cell is modeled as a function of its input transition time and capacitive load on the cell's output. The library was later extended to EvoApproxLib and EvoApproxLib-LITE [55].</p>
<p>In Fig. 1, evolved approximate 8-bit multipliers are compared with other approximate multipliers. Because of limited space, we can show only the MAE vs. power trade-offs. The black points represent the EvoApproxLib-LITE version of the library. The original circuits of EvoApprox8b are red points, conventional broken array multipliers are green points, and truncated multipliers are blue points. Purple color denotes other multipliers analyzed in [56] (approximate multipliers (AM), error-tolerant multipliers (ETM), and underdesigned multipliers (UDM)) and lpAClib multipliers [57]. The grey points in Fig. 1 show all 16,833 non-dominated implementations currently available in the EvoApproxLib. All approximate multipliers were synthesized with Synopsys Design Compiler, 45 nm process, and V dd =1V.</p>
<p>The EvoApproxLib was later extended with evolved approximate implementations of up to 128-bit adders, up to 32bit multipliers, dividers, Multiply&amp;Accumulate (MAC) circuits, and 8 × k-bit multipliers, k ∈ {4, 5, 6, 7} [55,40,51]. Each approximate circuit is fully characterized in terms of   Fig. 1: The MAE-power plot for 8-bit approximate multipliers taken from the EvoApproxLib-LITE (black points), EvoApproxLib (grey points), and EvoApprox8b (red points) are compared with broken array multipliers (green points), truncated multipliers (blue points) and other selected approximate multipliers from lpAClib [57] and [56]. Adopted from [55].</p>
<p>several error metrics, electrical parameters for various technology libraries and can be downloaded in Verilog, C, and Matlab formats. The CGP-based approximation can provide qualityconfigurable circuits whose accuracy (and thus power consumption) can be dynamically switched according to the application requirements [46]. In another research, approximate multipliers are evolved in such a way that they show low error for the most frequent input vectors. In contrast, a higher error is acceptable for the remaining input vectors [48]. This feature is essential in applications such as CNN accelerators, where the distribution of weights is known, and multipliers can be evolved with respect to the particular set of weights. De Souza et al. compare two mutation operators in a multi-objective approximation on 15 benchmark circuits with up to 14 inputs [50]. Mrazek at al. [45] investigate if the standard CGP utilizing two-input gates can be improved by supporting more complex building blocks such as full adders. They report over 10× speedup in the approximation of 12-bit multipliers if CGP can use full adders as building blocks.</p>
<p>Another innovative application of approximate computing is in reducing the area overhead associated with unavoidable hardware redundancy needed to ensure the reliability of digital circuits. Sanchez-Clemente et al. [33] compare two approaches to reduce the area of the Triple Modular Redundancy scheme (TMR). The evolutionary approach based on CGP provides radically different solutions that are hard to reach by other methods. The goal of CGP is to evolve suitable under-and over-approximations (measured using the Hamming distance) of the original circuit while the area is minimized. The (second) probabilistic approach approximates a circuit in a greedy manner, and the method is based on a probabilistic estimation of the error. Experimental results obtained for several combinational circuits demonstrated that the evolutionary approach can produce better solutions, but the probabilistic approach is close. In the followup work, Albandes et al. [21] propose another approach. GA has to find replacements for some gates according to a predefined library that specifies what transformations are valid for each logic gate. For example, a two-input NAND(x,y) is underapproximated either by NOT(x) or NOT(y) or the zero constant. The candidate replacements are stored in the geno-type. NSGA-II tries to find the best trade-offs between the size of the circuit (to be minimized) and the Fault Coverage (to be maximized).</p>
<p>B. Approximate Circuits for FPGAs</p>
<p>Research on approximate logic circuits [34], as well as approximate arithmetic circuits and image filters [32], revealed that approximations discovered by CGP at the gate level are almost perfectly preserved by common synthesis tools for FPGAs if these circuits are not small. On the other hand, common synthesis tools provide (for some circuits) results far from optimum. For example, a 40% reduction (68 LUTs) was achieved by CGP for 'clmb' benchmark circuit (Bus Interface) without introducing any error. Additional 43% reduction can be obtained by introducing only a 0.1% error [34]. Recently, Vasicek [52] presented a novel iterative method for the synthesis of approximate circuits optimized for LUT-based technologies. The method operates internally at the level of 2-input LUTs and produces LUT-level netlists that may consist of up to k-input LUTs, where k can be chosen by the user depending on the intended target technology. One of the critical properties of the proposed method is the ability to keep the propagation delay under control. For various approximate adders (up to 64-bit) and multipliers (8-bit and 16-bit) the method produced better trade-offs than the state of the art when the WCE, the number of LUTs, and propagation delay are considered.</p>
<p>C. Formal Error Analysis in the Fitness Function</p>
<p>As the circuit simulation across all possible input vectors is intractable for complex circuits and with the aim of providing the exact error of an approximate implementation, two main approaches, based on Reduced Ordered Binary Decision Diagrams (ROBDD) and satisfiability (SAT) solvers, have been developed for relaxed equivalence checking [8]. In both cases, an auxiliary circuit, the so-called miter, is constructed and then analyzed. The miter connects corresponding outputs of the candidate circuit (to be checked), the golden circuit, and an error-specific circuit to determine the approximation error.</p>
<p>If the auxiliary circuit is expressed using an ROBDD the requested error metrics are obtained by analyzing the ROBDD. As ROBDDs are inefficient in representing classes of circuits for which the number of nodes in ROBDD is growing exponentially with the number of input variables (e.g., multipliers and dividers), their use in equivalence checking of approximate circuits is typically possible for adders and other less structurally complex functions [8]. On the other hand, all commonly used error metrics can be evaluated by means of ROBDDs. For example, the average Hamming distance is employed for approximation of complex combinational circuits at the gate-level in [31] and for FP-GAs in [34]. The MAE is (exactly) calculated using ROB-DDs for approximate adders. These adders are employed in approximate DCT circuits, which are evaluated in a hardware implementation of the HEVC video standard [38].</p>
<p>Suppose now that the error analysis is based on SAT solving. In that case, the miter is represented as a logic formula in Conjunctive Normal Form (CNF) for which SAT solver decides whether it is satisfiable or unsatisfiable. The interpretation of this outcome depends on the construction of the miter. Common SAT solvers are, in principle, applicable to the worst-case analysis only. However, this approach is more scalable than ROBDDs and, hence, it is applied to determine WCE of complex approximate multipliers [40], dividers, and MACs [51]. Here, CGP is combined with SAT solving uniquely in the so-called verifiability driven search strategy [40]. CGP generates such candidate approximate circuits that can be evaluated by a SAT solver (i.e., the SAT solver decides whether the circuit satisfies a given error bound) within a given time limit. If it can be proved by the SAT solver that the candidate circuit satisfies the specification, its fitness score corresponds to its area, and the goal is to minimize the area. Otherwise, the circuit is not utilized anymore.</p>
<p>The principles of approximate computing can be applied directly at the level of ROBDD circuit representation [35], i.e., before any circuit implementation is carried out. ROB-DDs are minimized under several objectives by performing both variable reordering and approximation while a predefined error constraint is not violated. A multi-objective GA uses an -preferred relation to compare subvectors of objective functions with equal priorities. The genotype contains two parts: permutation of input variables of the given Boolean function and a vector consisting of pairs designating the approximation operators and the ROBDD level indices where each operator should be applied. On 20 Boolean functions from the ISCAS89 benchmark set, the method reduces the ROBDD size by 68.02% on average in comparison with the initial ROBDDs. This improvement is achieved at a low cost of total inaccuracy (the average is 2.12%), which is insignificant compared to the amount of size reduction.</p>
<p>D. Higher Levels of Abstraction</p>
<p>Instead of one-bit connections and elementary gates, CGP can work at the level of multi-bit connections and elementary functions such as adders, multipliers, and comparators.</p>
<p>Approximate multiple-constant multiplierless multipliers are evolved by a multi-objective CGP [27]. The specification includes a set of building blocks (in particular, adders, subtractors, and shifts) and a set of k constants {C 1 , . . . , C k } for which the circuit has to output k products, i.e., C 1 x, . . . , C k x. The goal is to minimize the average error across all the products, the number of additions/subtractions, and delay.</p>
<p>By using simple functions such as addition, minimum and maximum, CGP provides approximate implementations of arctan and square root functions [44]. These evolved functions then replace their standard implementations in the gradient orientation and magnitude computation modules that are critical components of the gradient histogram computation of the histogram of oriented gradients (HOG) feature extraction method. This method, followed by the standard support vector machine (SVM)-based classifier, was used to detect pedestrians in images.</p>
<p>Kemcha et al. [47] introduce a multi-objective Particle Swarm Optimization to evolve approximate implementations of an exact sequential circuit (in particular, a sequential divider) modeled at the RT level. Candidate circuits are represented using a vector of integers that can be interpreted as a netlist defining components and their connections. Contrasted to the standard CGP, feedback connections are supported in the circuit. The objective is to find the best tradeoffs between accuracy, delay, and area.</p>
<p>Another application is searching for approximate implementations of the median function. In hardware, the median circuit typically consists of a sequence of compare-and-swap operators over the primary inputs and intermediate results.</p>
<p>By reducing the number of compare-and-swap operations, one can improve the energy-efficiency of median function computing, which is helpful in many applications, including image filtering and sensor data processing. The approximate implementations of 9-input and 25-input median obtained by CGP are evaluated on several microcontrollers, where the actual power consumption is measured [30]. This work is extended in [37], where the authors propose a new combinatorial analysis-based approach and the so-called distance error enabling to precisely determine the error for a candidate approximate median network without running the full simulation.</p>
<p>E. Source Code Level</p>
<p>The automated approximation method called ABACUS is developed for circuits described at the behavioral or RT level in Verilog [58,59]. First, the source code is parsed to create its AST. Various mutation operators are then applied to the AST to derive approximate versions, which are then written back to Verilog and simulated for error evaluation and synthesized for the area and power evaluation. The mutation operators include the bit width simplifications, variable to constant substitutions, approximate arithmetic transformations (e.g., an exact addition is replaced by an approximate addition), expression transformations (e.g., z = a * b+c * d is replaced by z = a * (b+d)), and loop transformations. While the original version of ABACUS uses an iterative stochastic greedy algorithm [58], the latest version is based on NSGA-II [59].</p>
<p>F. Approximation From Scratch</p>
<p>Rather than creating an approximate implementation of an existing solution, evolutionary algorithms sometimes enable to evolve an entirely new approximation from scratch. This approach is useful when we do not have any suitable initial solution, or the problem is relatively simple, and EA is thus directly capable of providing very competitive results.</p>
<p>Towards this end, various approximate implementations of image filters (median filter, adaptive median filter, weighted median filter) are approximated by CGP, which is initialized with an exact implementation, and compared against image filters evolved from scratch [41]. Their quality is measured on a set of 30 images containing salt and pepper noise and impulse noise of different intensities. Evolved filters consistently outperform approximate filters, i.e., they occupy the Pareto front containing the PSNR-power trade-offs.</p>
<p>For network flow hashing, specialized hash functions are evolved using LGP [42]. Their quality is measured on real network data, and their implementation cost and delay are reported for an FPGA implementation. Compared to sev-eral standard hash functions, evolved hash functions provide quite competitive results.</p>
<p>In [43], GP creates programs for error-aware extraction of features from raw data.</p>
<p>These features are then used by an SVM-based classifier in applications such as electroencephalogram-based seizure detection and electrocardiogram-based arrhythmia detection. The system is implemented on a heterogeneous processor. By controlling the size of these GP trees, one can partly control the energy requirements of the chip. The paper demonstrates a significant reduction in feature extraction energy (more than 10×) at the expense of a slight degradation in system performance. The hardware-related details of the chip are summarized in paper [60]. A multi-objective problem formulation together with an accelerator design was proposed in [49].</p>
<p>VII. EVOLUTIONARY APPROXIMATION IN CNNS</p>
<p>The unprecedented success of machine learning methods based on deep neural networks comes with the very high computation cost needed to train these networks [61]. However, even a fully trained convolutional neural network (CNN) which is used, e.g., to classify images, requires considerable resources. For example, the inference phase of a trained CNN (such as ResNet-50) requires performing 3.9 · 10 9 multiply-and-accumulate operations to classify one single input image. A lot of effort has been invested in developing compact and so energy-efficient CNN architectures [62]. In addition to manual design methods, the socalled neural architecture search significantly helped to automate the neural network design process [63,64]. One of the popular approaches is the evolutionary design of CNNs. The design objective is to provide high-quality trade-offs between the network accuracy, size, and energy. Moreover, various approximations can be introduced and explored during the evolutionary design process.</p>
<p>CNNs usually contain from four to tens layers of different types. When used as an image classifier, the input layer provides pixels of the input image to other layers. Convolutional layers are capable of extracting useful features from the input data. Each convolutional layer generates, by applying one or several convolutional kernels (filters), a successively higher level of abstraction of the input data, called a feature map which preserves essential yet unique information. Pooling layers combine, e.g., by means of averaging, a set of input values into a small number of output values to reduce the network complexity. Fully connected layers are composed of artificial neurons; each of them sums weighted input signals (coming from a previous layer) and produces a single output. Convolutional layers and fully connected layers are typically followed by non-linear activation functions such as sigmoid or rectified linear units (ReLU). Modern CNNs also utilize other types of layers (such as residual connections, inception, and bottleneck blocks). The structure of the network is defined by its hyperparameters (e.g., the number and type of layers, the number of channels, the number and size of filters, etc.). This structure also determines the number of tunable parameters (weights). Once the CNN architecture and hyperparameters are defined, CNN can be trained (i.e., the weights are iteratively updated) to minimize a loss function. While the training algorithm involves forward as well as backward computations along with the network, the resulting trained network, when used in an application, performs only the forward computations (the inference). Hence, in most cases, only the inference engine is implemented and accelerated for a target application. These implementations are developed for GPUs, microcontrollers, and as specialized accelerators in ASICs and FPGAs. The architecture of CNN is thus optimized concerning resources available on the target platform and to meet the target latency.</p>
<p>Approximate implementations are introduced to CNNs at the level of data type selection, quantization, microarchitecture (e.g., pruning), arithmetic circuits, and memory subsystem. The most significant gains are obtained when adopting a cross-layer approximation approach, which involves software, architecture, and hardware at the same time, breaking thus conventional methods focused on optimizing each layer of abstraction independently [65]. A recent survey of methods for evolutionary design of neural network architectures was presented in [66]. We will focus on methods that are related to evolutionary approximations. Table II shows that the evolutionary approximation can be utilized for very different purposes during the CNN design. We briefly introduce the main techniques in the following paragraphs.</p>
<p>A. Evolutionary Approximation of Components of NNs</p>
<p>The most obvious approach is to approximate non-linear mathematical functions that have to be implemented in hardware with reduced resources. In general, this is a wellexplored area of research [67]. Recent works utilizing EAs have addressed specific hardware constraints [68,69]. A lot of effort is also invested to obtaining suitable approximate implementations of multipliers because the multiplication and the MACs are dominating arithmetic operations in CNNs [62]. For CNNs with quantized weights, the 8-bit and 8xk-bit approximate multipliers are evolved by CGP with the goal to minimize WCE and power consumption of resulting multipliers [70,55]. Experiments reveal that the inexact multiplication by zero leads to the accumulation of errors in CNNs and poor classification accuracy. Hence, an additional constraint was formulated for CGP: if at least one of the operands is zero, the product must be precisely zero. The CNNs utilizing evolved approximate multipliers satisfying this constraint show good error-energy trade-offs for ResNet networks on CIFAR-10 dataset [55]. These evolved multipliers are also used by ALWANN tool that provides highlyoptimized implementations of CNNs for custom low-power accelerators in which the number of computing units is lower than the number of layers [71]. ALWANN is capable of selecting a suitable approximate multiplier for each computing unit from a library of approximate multipliers in such a way that (i) one approximate multiplier serves several layers, and (ii) the overall error and energy consumption are minimized. The optimizations, including the multiplier selection problem, are solved by means of the NSGA-II algorithm.</p>
<p>B. Hardware-Aware Neural Architecture Search</p>
<p>The evolutionary design of neural networks, or neuroevolution, has recently led to the fully automated design of complex CNNs that are quite competitive in terms of accuracy and size, even for the most challenging datasets such as Im-ageNet [72]. In order to represent a candidate CNN in the genotype, a well-known CNN (such as MobileNetV2 in [73]) is usually taken as a template. The genotype then contains a set of parameters, each of them specifying possible values of the critical network's hyperparameters (the layer type, the number of filters, the kernel sizes, etc.). In some cases, the genotype also specifies internal connections of computational elements in selected layers; in other words, it encodes a computational graph of the neural network. Concerning the target hardware accelerator and latency, the EA can thus optimize not only the hyperparameters but also computational subgraphs and various quantization and approximation schemes. According to the genotype, a candidate CNN is built. It is trained on the training data set and evaluated in terms of its accuracy, size, power and other parameters. The new generation of CNNs is created using common operators used in EAs and considering the multi-objective nature of the problem. For example, the mutation operators typically enable inserting and deleting layers, channels, or modifying the number and size of filters in [74].</p>
<p>In [74], the fixed-point quantization is applied as a postprocessing step after NAS is finished. However, for example, in APQ, a suitable quantization scheme is directly evolved during NAS [73]. APQ thus performs a joint search for architecture, pruning, and quantization policy starting with the MobileNetV2 network. To reduce the high computation overhead associated with NAS, the accuracy is predicted using a quantization-aware predictor implemented as a 3-layer feed-forward neural network. The input to the predictor is the encoding of the network architecture, the pruning strategy, and the quantization policy. The predictor is first trained without quantization, followed by transferring its weights to train the quantization-aware predictor, largely reducing the quantization data collection time. The latency and energy of each layer are precomputed and stored in the look-up tables. Similar techniques, including weight sharing, training data reduction, accuracy and latency estimation are widely adopted to reduce the design time because the CNN design is very computationally expensive [64]. To reduce the energy needed for multiplication in convolutional layers and maximize the overall accuracy, Pinos et al. [75] co-evolved CNN architecture together with a suitable approximate multiplier taken from the EvoApproxLib. A significant improvement in the search efficiency can be obtained by suitable reduction and optimization of the search space before the NAS is conducted. For example, MCUNet, which optimizes CNNs for microcontrollers, adopts a twostage neural architecture search approach that first optimizes the search space to fit the resource constraints and then specializes the network architecture in the optimized search space [76]. A similar approach, but targeting smaller microcontrollers, is presented in µNAS [77]. HSCoNAS [78] adopts progressive space shrinking to refine the search space towards target hardware and thus reduces the search overheads. By means of NSGA-II, NASCaps [79] jointly optimizes the network accuracy and the hardware efficiency (energy, memory, and latency) of an ASIC-based hardware accelerator developed for the so-called capsule networks. </p>
<p>VIII. CONCLUSIONS</p>
<p>We provided the first survey of EA-based approaches used in approximate computing. From over 60 papers dealing with this topic, we learned that EAs are applied as multiobjective optimizers, with the aim not only to optimize some parameters of approximate HW/SW systems but also to determine their architecture. EAs were used for all relevant design abstractions and in tens of different applications. However, as EAs suffer from long execution times, their utilization has (almost always) to be accompanied by a suitable fitness estimation strategy. This observation is especially valid for a newly established research topic -the hardware-aware neural architecture search helping in the automated design of approximate accelerators of deep neural networks.</p>
<p>Table I .
I: Selected papers in which the EA is used for purposes of approximate computing. Specific abbreviations: Sim -simulation; Statistical -statistical error analysis; Sim+Comb -Simulation and combinatorial analysis.Year Ref. EA 
Level 
EA's target 
Error Calc. Application domain 
Benchmark problems 
Platform 
Parameter Optimization 
2011 [14] GA 
SW 
config. parameters 
Sim 
SW auto-tuning 
5 programs 
CPU 
2014 [15] GA 
SW 
program variables 
Sim 
SW approximation 
9 programs 
CPU 
2015 [16] GA 
gate 
adder selection 
Sim 
arithm. circuit 
adder 
ASIC 
2016 [17] GA 
SW 
porgram variables 
Sim 
OpenCL kernels 
6 programs 
FPGA 
2016 [18] GA 
RTL 
component selection 
Statistical 
high level synthesis 
DCT, reduce sum 
ASIC 
2017 [19] GA 
RTL 
multiplier selection 
Sim 
image compression 
4 images 
ASIC 
2018 [20] GA 
gate 
adder selection 
Sim 
multiplier design 
edge detection, k-means clustering 
ASIC 
2018 [21] GA 
gate 
gate selection 
Sim 
TMR 
5 benchmark circuits 
ASIC 
2019 [22] GA 
RTL 
component selection 
Sim 
FIR filter bank 
hearing aid 
ASIC 
2020 [23] GA 
RTL 
config. parameters 
Sim 
display rendering pipeline 
image color improvement 
FPGA 
2021 [24] GA 
RTL 
component selection 
Sim 
component selection 
Sobel, Prewitt, and Laplacian filter 
ASIC 
2021 [25] GA 
RTL 
bit widths 
Sim 
bit width assignment 
spam detector 
FPGA 
2021 [26] GA 
SW 
parameters, components Sim 
SW, cross-layer 
K-Means, Taylor, JPEG, Sobel, CNN 
FPGA 
Synthesis and Optimization 
2013 [27] CGP RTL 
circuit synthesis 
Sim 
multiple constant multiplier 
5 multipliers 
none 
2013 [28] CGP gate 
circuit synthesis 
Sim 
logic synthesis 
cm152, sym9, t481, 9-majority, 3b and 4b adders 
ASIC 
2015 [29] CGP gate/RTL circuit synthesis 
Sim 
logic synthesis 
2b, 3b, 4b multiplier, 9-median, 25-median 
ASIC 
2015 [30] CGP SW 
program synthesis 
Sim 
SW code 
9-median, 25-median 
MCU 
2016 [31] CGP gate 
circuit synthesis 
BDD 
logic synthesis 
16 circuits 
ASIC 
2016 [32] CGP gate 
circuit synthesis 
Sim 
logic synthesis 
8b adder, 8b multiplier, median, Sobel, Gaussian filters FPGA 
2016 [33] CGP gate 
circuit synthesis 
Sim 
TMR 
9 circuits 
ASIC 
2016 [34] CGP gate/LUT circuit synthesis 
BDD 
logic synthesis 
24 circuits 
FPGA 
2017 [35] GA 
BDD 
variable permutation 
BDD 
logic synthesis 
20 circuits 
none 
2017 [36] CGP RTL 
circuit synthesis 
Sim 
DCT 
3 images 
ASIC 
2017 [37] CGP SW 
program synthesis 
Sim+Comb median 
sensor data filter, image filters 
MCU 
2017 [38] CGP gate 
circuit synthesis 
BDD 
adder 
DCT in HEVC 
ASIC 
2017 [39] CGP gate 
circuit synthesis 
Sim 
arithm. circuits 
8b adder, 8b multiplier 
ASIC 
2017 [40] CGP gate 
circuit synthesis 
SAT 
arithm. circuits 
up to 32b multipliers, up to 128b adders 
ASIC 
2017 [41] CGP RTL 
circuit synthesis 
Sim 
image filter 
30 images 
ASIC 
2018 [42] LGP SW 
program synthesis 
Sim 
hash function 
network flow hashing 
FPGA 
2018 [43] GP 
SW 
program synthesis 
Sim 
features extraction programs EEG-seizure, ECG-cardiac-arrhythmia detection 
ASIC 
2018 [44] CGP RTL 
program synthesis 
Sim 
sqrt, arctan 
feature extraction 
CPU 
2018 [45] CGP cell 
circuit synthesis 
Sim 
arithm. circuits 
12b multiplier 
ASIC 
2018 [46] CGP gate 
circuit synthesis 
Sim 
quality configurable circuit 
Gaussian noise filter 
ASIC 
2019 [47] PSO RTL 
circuit synthesis 
Sim 
sequential circuit design 
divider 
ASIC 
2019 [48] CGP gate 
circuit synthesis 
Sim 
arithm. circuit 
Gaussian noise filter, CNN 
ASIC 
2020 [49] GP 
SW 
program synthesis 
Sim 
features extraction programs EEG-seizure, ECG-cardiac-arrhythmia detection 
ASIC 
2020 [50] CGP gate 
circuit synthesis 
Sim 
logic synthesis 
15 circuits 
ASIC 
2020 [51] CGP gate 
circuit synthesis 
SAT 
arithm. circuits 
32b multiplier, 32b MAC, 24b divider 
ASIC 
2021 [52] CGP LUT 
circuit synthesis 
Sim 
arithm. circuits 
up to 64b adders and 8b, 16b multipliers 
FPGA </p>
<p>Table II .
II: Evolutionary algorithms in approximate computing methods applied to hardware-aware deep neural network design. The 'classifier' means a CNN-based image classifier. The 'hyperp.' means that EA is used to optimize CNN's hyperparameters, together with hardware parameters (+HW), quantization (+Q), and network architecture (+Arch.)Year Cite EA 
Level 
EA's target 
Platform 
2016 [70] CGP gate 
8b multiplier 
ASIC 
2017 [69] LGP instruction 
function approx. 
CPU 
2019 [68] GA 
vector 
function approx. 
FPGA 
2019 [71] GA 
vector 
multiplier selection ASIC 
2019 [74] GA 
hyperp. 
classifier 
ASIC 
2019 [80] GA 
hyperp.+HW 
classifier 
FPGA 
2019 [81] GA 
hyperp. 
classifier 
multiple 
2020 [79] GA 
hyperp. 
classifier 
ASIC 
2020 [79] GA 
hyperp. 
classifier 
ASIC 
2020 [73] GA 
hyperp.+Q 
classifier 
ASIC 
2020 [76] GA 
hyperp. 
classifier 
MCU 
2020 [82] GA 
hyperp. 
classifier 
multiple 
2020 [55] CGP gate 
8xk-bit multiplier 
ASIC 
2021 [78] GA 
hyperp. 
classifier 
multiple 
2021 [77] GA 
hyperp. 
classifier 
MCU 
2021 [75] CGP hyperp.+Arch classifier 
ASIC </p>
<p>ACKNOWLEDGEMENTSThis work was supported by the Czech science foundation project 21-13001S.
. M Duranton, K D Bosschere, B Coppens, C Gamrat, T Hoberg, H Munk, C Roderick, T Vardanega, O Zendra, M. Duranton, K. D. Bosschere, B. Coppens, C. Gamrat, T. Hoberg, H. Munk, C. Roderick, T. Vardanega, and O. Zendra, HiPEAC Vision 2021, 2021. [Online]. Available: https://www.hipeac.net/vision</p>
<p>A survey of techniques for approximate computing. S , ACM Comput. Surv. 484S. Mittal, "A survey of techniques for approximate computing," ACM Comput. Surv., vol. 48, no. 4, p. 1-33, 2016.</p>
<p>Exploiting errors for efficiency: A survey from circuits to applications. P Stanley-Marbell, A Alaghi, M Carbin, E Darulova, L Dolecek, A Gerstlauer, G Gillani, D Jevdjic, T Moreau, M Cacciotti, A Daglis, N E Jerger, B Falsafi, S Misailovic, A Sampson, D Zufferey, ACM Comput. Surv. 533P. Stanley-Marbell, A. Alaghi, M. Carbin, E. Darulova, L. Dole- cek, A. Gerstlauer, G. Gillani, D. Jevdjic, T. Moreau, M. Cacciotti, A. Daglis, N. E. Jerger, B. Falsafi, S. Misailovic, A. Sampson, and D. Zufferey, "Exploiting errors for efficiency: A survey from circuits to applications," ACM Comput. Surv., vol. 53, no. 3, 2020.</p>
<p>Approximate logic synthesis: A survey. I Scarabottolo, G Ansaloni, G A Constantinides, L Pozzi, S Reda, Proceedings of the IEEE. 10812I. Scarabottolo, G. Ansaloni, G. A. Constantinides, L. Pozzi, and S. Reda, "Approximate logic synthesis: A survey," Proceedings of the IEEE, vol. 108, no. 12, pp. 2195-2213, 2020.</p>
<p>Automated search-based functional approximation for digital circuits. L Sekanina, Z Vasicek, V Mrazek, Approximate Circuits, Methodologies and CAD, S. Reda and M. ShafiqueSpringerL. Sekanina, Z. Vasicek, and V. Mrazek, "Automated search-based functional approximation for digital circuits," in Approximate Cir- cuits, Methodologies and CAD, S. Reda and M. Shafique, Eds. Springer, 2019, pp. 175-203.</p>
<p>Neural acceleration for general-purpose approximate programs. H Esmaeilzadeh, A Sampson, L Ceze, D Burger, Commun. ACM. 581H. Esmaeilzadeh, A. Sampson, L. Ceze, and D. Burger, "Neural accel- eration for general-purpose approximate programs," Commun. ACM, vol. 58, no. 1, p. 105-115, 2014.</p>
<p>Probabilistic error modeling for approximate adders. S Mazahir, O Hasan, R Hafiz, M Shafique, J Henkel, IEEE Transactions on Computers. 663S. Mazahir, O. Hasan, R. Hafiz, M. Shafique, and J. Henkel, "Prob- abilistic error modeling for approximate adders," IEEE Transactions on Computers, vol. 66, no. 3, pp. 515-530, 2017.</p>
<p>Formal methods for exact analysis of approximate circuits. Z Vasicek, IEEE Access. 71Z. Vasicek, "Formal methods for exact analysis of approximate cir- cuits," IEEE Access, vol. 7, no. 1, pp. 177 309-177 331, 2019.</p>
<p>Introduction to Evolutionary Computing, Second Edition, ser. A E Eiben, J E Smith, Natural Computing Series. SpringerA. E. Eiben and J. E. Smith, Introduction to Evolutionary Computing, Second Edition, ser. Natural Computing Series. Springer, 2015.</p>
<p>. R Poli, W B Langdon, N F Mcphee, A field guide to genetic programming. lulu.comR. Poli, W. B. Langdon, and N. F. McPhee, A field guide to genetic programming. lulu.com, 2008.</p>
<p>Cartesian genetic programming: its status and future. J F Miller, Genet. Program. Evolvable Mach. 211-2J. F. Miller, "Cartesian genetic programming: its status and future," Genet. Program. Evolvable Mach., vol. 21, no. 1-2, pp. 129-168, 2020.</p>
<p>Evolutionary multiobjective optimization: open research areas and some challenges lying ahead. C A Coello, S Gonzalez Brambila, J Gamboa, M G Castillo Tapia, R. Hernandez Gomez, Complex &amp; Intelligent Systems. 2020C. A. Coello Coello, S. Gonzalez Brambila, J. Figueroa Gamboa, M. G. Castillo Tapia, and R. Hernandez Gomez, "Evolutionary multi- objective optimization: open research areas and some challenges lying ahead," Complex &amp; Intelligent Systems, vol. 2020, pp. 1-16, 2020.</p>
<p>A fast and elitist multiobjective genetic algorithm: NSGA-II. K Deb, A Pratap, S Agarwal, T Meyarivan, IEEE Transactions on Evolutionary Computation. 62K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan, "A fast and elitist multiobjective genetic algorithm: NSGA-II," IEEE Transactions on Evolutionary Computation, vol. 6, no. 2, pp. 182-197, 2002.</p>
<p>Language and compiler support for auto-tuning variable-accuracy algorithms. J Ansel, Y L Wong, C Chan, M Olszewski, A Edelman, S Amarasinghe, International Symposium on Code Generation and Optimization. J. Ansel, Y. L. Wong, C. Chan, M. Olszewski, A. Edelman, and S. Amarasinghe, "Language and compiler support for auto-tuning variable-accuracy algorithms," in International Symposium on Code Generation and Optimization (CGO 2011), 2011, pp. 85-96.</p>
<p>ExpAX: A framework for automating approximate programming. J Park, X Zhang, K Ni, H Esmaeilzadeh, M Naik, J. Park, X. Zhang, K. Ni, H. Esmaeilzadeh, and M. Naik, "ExpAX: A framework for automating approximate programming," 2014. [Online]. Available: https://smartech.gatech.edu/handle/1853/52032</p>
<p>Designing energy-efficient approximate adders using parallel genetic algorithms. A A Naseer, R A Ashraf, D Dechev, R F Demara, IEEEA. A. Naseer, R. A. Ashraf, D. Dechev, and R. F. DeMara, "Design- ing energy-efficient approximate adders using parallel genetic algo- rithms," in SoutheastCon 2015. IEEE, 2015, pp. 1-7.</p>
<p>Grater: An approximation workflow for exploiting data-level parallelism in fpga acceleration. A Lotfi, A Rahimi, A Yazdanbakhsh, H Esmaeilzadeh, R K Gupta, 2016 Design, Automation and Test in Europe, Conference and Exhibition. A. Lotfi, A. Rahimi, A. Yazdanbakhsh, H. Esmaeilzadeh, and R. K. Gupta, "Grater: An approximation workflow for exploiting data-level parallelism in fpga acceleration," in 2016 Design, Automation and Test in Europe, Conference and Exhibition (DATE), 2016, pp. 1279-1284.</p>
<p>Evolving component library for approximate high level synthesis. F Vaverka, R Hrbacek, L Sekanina, 2016 IEEE Symposium Series on Computational Intelligence (SSCI). F. Vaverka, R. Hrbacek, and L. Sekanina, "Evolving component li- brary for approximate high level synthesis," in 2016 IEEE Symposium Series on Computational Intelligence (SSCI), 2016, pp. 1-8.</p>
<p>Approximate compressed sensing for hardware-efficient image compression. S P Kadiyala, V K Pudi, S.-K Lam, 30th IEEE International System. S. P. Kadiyala, V. K. Pudi, and S.-K. Lam, "Approximate compressed sensing for hardware-efficient image compression," in 30th IEEE In- ternational System-on-Chip Conference, 2017, pp. 340-345.</p>
<p>A novel heterogeneous approximate multiplier for low power and high performance. I Alouani, H Ahangari, O Ozturk, S Niar, IEEE Embedded Systems Letters. 102I. Alouani, H. Ahangari, O. Ozturk, and S. Niar, "A novel heteroge- neous approximate multiplier for low power and high performance," IEEE Embedded Systems Letters, vol. 10, no. 2, pp. 45-48, 2018.</p>
<p>Improving approximate-TMR using multi-objective optimization genetic algorithm. I Albandes, A Serrano-Cases, A Sanchez-Clemente, M Martins, A Martinez-Alvarez, S Cuenca-Asensi, F L Kastensmidt, 2018 IEEE 19th Latin-American Test Symposium. I. Albandes, A. Serrano-Cases, A. Sanchez-Clemente, M. Martins, A. Martinez-Alvarez, S. Cuenca-Asensi, and F. L. Kastensmidt, "Im- proving approximate-TMR using multi-objective optimization ge- netic algorithm," in 2018 IEEE 19th Latin-American Test Symposium (LATS), 2018, pp. 1-6.</p>
<p>An optimum inexact design for an energy efficient hearing aid. S P Kadiyala, A Sen, S Mahajan, Q Wang, A Lingamaneni, J S German, X Hong, K V Palem, A Basu, J. Low Power Electron. 152S. P. Kadiyala, A. Sen, S. Mahajan, Q. Wang, A. Lingamaneni, J. S. German, X. Hong, K. V. Palem, and A. Basu, "An optimum inexact design for an energy efficient hearing aid," J. Low Power Electron., vol. 15, no. 2, pp. 129-143, 2019.</p>
<p>Parameter optimization of approximate image processing algorithms in FPGAs. N A Vu Doan, M Manuel, S Conrady, A Kreddig, W Stechele, 2020 Eighth International Symposium on Computing and Networking Workshops. CANDARWN. A. Vu Doan, M. Manuel, S. Conrady, A. Kreddig, and W. Stechele, "Parameter optimization of approximate image processing algorithms in FPGAs," in 2020 Eighth International Symposium on Computing and Networking Workshops (CANDARW), 2020, pp. 74-80.</p>
<p>Workload-aware approximate computing configuration. D Ma, R Thapa, X Wang, C Hao, X Jiao, Design Automation and Test in Europe. EDAA, 2021. D. Ma, R. Thapa, X. Wang, C. Hao, and X. Jiao, "Workload-aware ap- proximate computing configuration," in Design Automation and Test in Europe. EDAA, 2021, pp. 920-923.</p>
<p>Advancing synthesis of decision tree-based multiple classifier systems: an approximate computing case study. M Barbareschi, S Barone, N Mazzocca, 10.1007/s10115-021-01565-5Knowl. Inf. Syst. 636M. Barbareschi, S. Barone, and N. Mazzocca, "Advancing synthesis of decision tree-based multiple classifier systems: an approximate computing case study," Knowl. Inf. Syst., vol. 63, no. 6, pp. 1577-1596, 2021. [Online]. Available: https://doi.org/10.1007/ s10115-021-01565-5</p>
<p>Multi-objective application-driven approximate design method. S Barone, M Traiola, M Barbareschi, A Bosio, IEEE Access. 9S. Barone, M. Traiola, M. Barbareschi, and A. Bosio, "Multi-objective application-driven approximate design method," IEEE Access, vol. 9, pp. 86 975-86 993, 2021.</p>
<p>Multiobjective evolution of approximate multiple constant multipliers. J Petrlik, L Sekanina, 2013 IEEE 16th International Symposium on Design and Diagnostics of Electronic Circuits Systems (DDECS). J. Petrlik and L. Sekanina, "Multiobjective evolution of approximate multiple constant multipliers," in 2013 IEEE 16th International Sym- posium on Design and Diagnostics of Electronic Circuits Systems (DDECS), 2013, pp. 116-119.</p>
<p>Approximate circuit design by means of evolvable hardware. L Sekanina, Z Vasicek, 2013 IEEE International Conference on Evolvable Systems (ICES). L. Sekanina and Z. Vasicek, "Approximate circuit design by means of evolvable hardware," in 2013 IEEE International Conference on Evolvable Systems (ICES), 2013, pp. 21-28.</p>
<p>Evolutionary approach to approximate digital circuits design. Z Vasicek, L Sekanina, IEEE Transactions on Evolutionary Computation. 193Z. Vasicek and L. Sekanina, "Evolutionary approach to approximate digital circuits design," IEEE Transactions on Evolutionary Computa- tion, vol. 19, no. 3, pp. 432-444, 2015.</p>
<p>Evolutionary approximation of software for embedded systems: Median function. V Mrazek, Z Vasicek, L Sekanina, Proceedings of the Companion Publication of the 2015 Annual Conference on Genetic and Evolutionary Computation, ser. GECCO Companion '15. the Companion Publication of the 2015 Annual Conference on Genetic and Evolutionary Computation, ser. GECCO Companion '15New York, NY, USAACMV. Mrazek, Z. Vasicek, and L. Sekanina, "Evolutionary approximation of software for embedded systems: Median function," in Proceedings of the Companion Publication of the 2015 Annual Conference on Ge- netic and Evolutionary Computation, ser. GECCO Companion '15. New York, NY, USA: ACM, 2015, pp. 795-801.</p>
<p>Evolutionary design of complex approximate combinational circuits. Z Vasicek, L Sekanina, Genetic Programming and Evolvable Machines. 172Z. Vasicek and L. Sekanina, "Evolutionary design of complex approx- imate combinational circuits," Genetic Programming and Evolvable Machines, vol. 17, no. 2, pp. 1-24, 2016.</p>
<p>Evolutionary functional approximation of circuits implemented into FPGAs. Z Vasicek, V Mrazek, L Sekanina, 2016 IEEE Symposium Series on Computational Intelligence (SSCI). Z. Vasicek, V. Mrazek, and L. Sekanina, "Evolutionary functional ap- proximation of circuits implemented into FPGAs," in 2016 IEEE Sym- posium Series on Computational Intelligence (SSCI), 2016, pp. 1-8.</p>
<p>Error mitigation using approximate logic circuits: A comparison of probabilistic and evolutionary approaches. A J Sanchez-Clemente, L Entrena, R Hrbacek, L Sekanina, IEEE Transactions on Reliability. 654A. J. Sanchez-Clemente, L. Entrena, R. Hrbacek, and L. Sekanina, "Error mitigation using approximate logic circuits: A comparison of probabilistic and evolutionary approaches," IEEE Transactions on Re- liability, vol. 65, no. 4, pp. 1871-1883, 2016.</p>
<p>Search-based synthesis of approximate circuits implemented into FPGAs. Z Vasicek, L Sekanina, 26th Int. Conference on Field Programmable Logic and Applications. Z. Vasicek and L. Sekanina, "Search-based synthesis of approximate circuits implemented into FPGAs," in 26th Int. Conference on Field Programmable Logic and Applications, 2016, pp. 1-4.</p>
<p>An adaptive prioritized -preferred evolutionary algorithm for approximate BDD optimization. S Shirinzadeh, M Soeken, D Große, R Drechsler, Proc. of the Genetic and Evolutionary Computation Conference, ser. GECCO'17. of the Genetic and Evolutionary Computation Conference, ser. GECCO'17ACMS. Shirinzadeh, M. Soeken, D. Große, and R. Drechsler, "An adaptive prioritized -preferred evolutionary algorithm for approximate BDD optimization," in Proc. of the Genetic and Evolutionary Computation Conference, ser. GECCO'17. ACM, 2017, pp. 1232-1239.</p>
<p>Evolutionary architecture design for approximate DCT. A Azaraien, B Djalaei, M E Salehi, 19th International Symposium on Computer Architecture and Digital Systems. A. Azaraien, B. Djalaei, and M. E. Salehi, "Evolutionary architecture design for approximate DCT," in 19th International Symposium on Computer Architecture and Digital Systems, 2017, pp. 1-2.</p>
<p>Trading between quality and nonfunctional properties of median filter in embedded systems. Z Vasicek, V Mrazek, Genetic Prog. and Evolvable Machines. 181Z. Vasicek and V. Mrazek, "Trading between quality and non- functional properties of median filter in embedded systems," Genetic Prog. and Evolvable Machines, vol. 18, no. 1, pp. 45-82, 2017.</p>
<p>Towards low power approximate DCT architecture for HEVC standard. Z Vasicek, V Mrazek, L Sekanina, Design, Automation &amp; Test in Europe Conference &amp; Exhibition. Z. Vasicek, V. Mrazek, and L. Sekanina, "Towards low power approx- imate DCT architecture for HEVC standard," in Design, Automation &amp; Test in Europe Conference &amp; Exhibition, DATE 2017, 2017, pp. 1576-1581.</p>
<p>Evoapprox8b: Library of approximate adders and multipliers for circuit design and benchmarking of approximation methods. V Mrazek, R Hrbacek, Z Vasicek, L Sekanina, Design, Automation Test in Europe Conference Exhibition. V. Mrazek, R. Hrbacek, Z. Vasicek, and L. Sekanina, "Evoapprox8b: Library of approximate adders and multipliers for circuit design and benchmarking of approximation methods," in Design, Automation Test in Europe Conference Exhibition, 2017, 2017, pp. 258-261.</p>
<p>Approximating complex arithmetic circuits with formal error guarantees: 32-bit multipliers accomplished. M Ceska, J Matyas, V Mrazek, L Sekanina, Z Vasicek, T Vojnar, IEEE/ACM International Conference on Computer-Aided Design. M. Ceska, J. Matyas, V. Mrazek, L. Sekanina, Z. Vasicek, and T. Vo- jnar, "Approximating complex arithmetic circuits with formal error guarantees: 32-bit multipliers accomplished," in IEEE/ACM Interna- tional Conference on Computer-Aided Design, 2017, pp. 416-423.</p>
<p>Approximate circuits in lowpower image and video processing: The approximate median filter. L Sekanina, Z Vasicek, V Mrazek, 26RadioengineeringL. Sekanina, Z. Vasicek, and V. Mrazek, "Approximate circuits in low- power image and video processing: The approximate median filter," Radioengineering, vol. 26, no. 3, pp. 623-632, 2017.</p>
<p>Fast reconfigurable hash functions for network flow hashing in FPGAs. D Grochol, L Sekanina, Proceedings of the 2018 NASA/ESA Conference on Adaptive Hardware and Systems. the 2018 NASA/ESA Conference on Adaptive Hardware and SystemsIEEED. Grochol and L. Sekanina, "Fast reconfigurable hash functions for network flow hashing in FPGAs," in Proceedings of the 2018 NASA/ESA Conference on Adaptive Hardware and Systems. IEEE, 2018, pp. 257-263.</p>
<p>Genetic programming for energy-efficient and energy-scalable approximate feature computation in embedded inference systems. J Lu, H Jia, N Verma, N K Jha, IEEE Transactions on Computers. 672J. Lu, H. Jia, N. Verma, and N. K. Jha, "Genetic programming for energy-efficient and energy-scalable approximate feature computation in embedded inference systems," IEEE Transactions on Computers, vol. 67, no. 2, pp. 222-236, 2018.</p>
<p>Cooperative coevolutionary approximation in HOG-based human detection embedded system. M Wiglasz, L Sekanina, IEEE Symp. Series on Computational Intelligence. M. Wiglasz and L. Sekanina, "Cooperative coevolutionary approxi- mation in HOG-based human detection embedded system," in IEEE Symp. Series on Computational Intelligence, 2018, pp. 1313-1320.</p>
<p>Role of circuit representation in evolutionary design of energy-efficient approximate circuits. V Mrazek, Z Vasicek, R Hrbacek, IET Computers &amp; Digital Techniques. 20184V. Mrazek, Z. Vasicek, and R. Hrbacek, "Role of circuit representation in evolutionary design of energy-efficient approximate circuits," IET Computers &amp; Digital Techniques, vol. 2018, no. 4, pp. 139-149, 2018.</p>
<p>Design of qualityconfigurable approximate multipliers suitable for dynamic environment. V Mrazek, Z Vasicek, L Sekanina, 2018 NASA/ESA Conference on Adaptive Hardware and Systems (AHS). V. Mrazek, Z. Vasicek, and L. Sekanina, "Design of quality- configurable approximate multipliers suitable for dynamic environ- ment," in 2018 NASA/ESA Conference on Adaptive Hardware and Systems (AHS), 2018, pp. 264-271.</p>
<p>Evolutionary design of approximate sequential circuits at RTL using particle swarm optimization. R Kemcha, N Nedjah, A R Maouche, M Bougherara, Computational Science and Its Applications -ICCSA 2019. ChamSpringerR. Kemcha, N. Nedjah, A. R. Maouche, and M. Bougherara, "Evolu- tionary design of approximate sequential circuits at RTL using particle swarm optimization," in Computational Science and Its Applications -ICCSA 2019. Cham: Springer, 2019, pp. 671-684.</p>
<p>Automated circuit approximation method driven by data distribution. Z Vasicek, V Mrazek, L Sekanina, Design, Automation and Test in Europe Conference. EDAA. Z. Vasicek, V. Mrazek, and L. Sekanina, "Automated circuit approx- imation method driven by data distribution," in Design, Automation and Test in Europe Conference. EDAA, 2019, pp. 96-101.</p>
<p>Reducing energy of approximate feature extraction in heterogeneous architectures for sensor inference via energy-aware genetic programming. Y Tang, H Jia, N Verma, IEEE Transactions on Circuits and Systems I: Regular Papers. 675Y. Tang, H. Jia, and N. Verma, "Reducing energy of approximate fea- ture extraction in heterogeneous architectures for sensor inference via energy-aware genetic programming," IEEE Transactions on Circuits and Systems I: Regular Papers, vol. 67, no. 5, pp. 1576-1587, 2020.</p>
<p>On the analysis of mutation operators in multiobjective cartesian genetic programming for designing combinational logic circuits. L Souza, H Bernardino, Anais do XVII Encontro Nacional de Inteligencia Artificial e Computacional. Porto Alegre, RS, BrasilSBCL. Souza and H. Bernardino, "On the analysis of mutation operators in multiobjective cartesian genetic programming for designing com- binational logic circuits," in Anais do XVII Encontro Nacional de In- teligencia Artificial e Computacional. Porto Alegre, RS, Brasil: SBC, 2020, pp. 390-401.</p>
<p>Adaptive verifiability-driven strategy for evolutionary approximation of arithmetic circuits. M Ceska, J Matyas, V Mrazek, L Sekanina, Z Vasicek, T Vojnar, Applied Soft Computing. 95106466M. Ceska, J. Matyas, V. Mrazek, L. Sekanina, Z. Vasicek, and T. Vo- jnar, "Adaptive verifiability-driven strategy for evolutionary approxi- mation of arithmetic circuits," Applied Soft Computing, vol. 95, no. 106466, pp. 1-17, 2020.</p>
<p>Synthesis of approximate circuits for LUT-based FP-GAs. Z Vasicek, 2021 24th International Symposium on Design and Diagnostics of Electronic Circuits Systems (DDECS). Z. Vasicek, "Synthesis of approximate circuits for LUT-based FP- GAs," in 2021 24th International Symposium on Design and Diag- nostics of Electronic Circuits Systems (DDECS), 2021, pp. 17-22.</p>
<p>EnerJ: approximate data types for safe and general low-power computation. A Sampson, W Dietl, E Fortuna, D Gnanapragasam, L Ceze, D Grossman, Proc. of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation. M. W. Hall and D. A. Paduaof the 32nd ACM SIGPLAN Conference on Programming Language Design and ImplementationACMA. Sampson, W. Dietl, E. Fortuna, D. Gnanapragasam, L. Ceze, and D. Grossman, "EnerJ: approximate data types for safe and general low-power computation," in Proc. of the 32nd ACM SIGPLAN Confer- ence on Programming Language Design and Implementation, M. W. Hall and D. A. Padua, Eds. ACM, 2011, pp. 164-174.</p>
<p>Trading accuracy for power with an underdesigned multiplier architecture. P Kulkarni, P Gupta, M Ercegovac, 2011 24th Internatioal Conference on VLSI Design. P. Kulkarni, P. Gupta, and M. Ercegovac, "Trading accuracy for power with an underdesigned multiplier architecture," in 2011 24th Interna- tioal Conference on VLSI Design, Jan 2011, pp. 346-351.</p>
<p>Libraries of approximate circuits: Automated design and application in CNN accelerators. V Mrazek, L Sekanina, Z Vasicek, IEEE Journal on Emerging and Selected Topics in Circuits and Systems. 104V. Mrazek, L. Sekanina, and Z. Vasicek, "Libraries of approximate cir- cuits: Automated design and application in CNN accelerators," IEEE Journal on Emerging and Selected Topics in Circuits and Systems, vol. 10, no. 4, pp. 406-418, 2020.</p>
<p>Approximate arithmetic circuits: Design and evaluation. H Jiang, L Liu, F Lombardi, J Han, Approximate Circuits. CAD, S. Reda and M. ShafiqueSpringerH. Jiang, L. Liu, F. Lombardi, and J. Han, "Approximate arithmetic circuits: Design and evaluation," in Approximate Circuits, Method- ologies and CAD, S. Reda and M. Shafique, Eds. Springer, 2019, pp. 67-98.</p>
<p>Invited: Cross-layer approximate computing: From logic to architectures. M Shafique, R Hafiz, S Rehman, DAC'16. M. Shafique, R. Hafiz, S. Rehman et al., "Invited: Cross-layer approx- imate computing: From logic to architectures," in DAC'16, 2016.</p>
<p>ABACUS: A technique for automated behavioral synthesis of approximate computing circuits. K Nepal, Y Li, R I Bahar, S Reda, Proc. of DATE'14. EDA Consortium. of DATE'14. EDA ConsortiumK. Nepal, Y. Li, R. I. Bahar, and S. Reda, "ABACUS: A technique for automated behavioral synthesis of approximate computing circuits," in Proc. of DATE'14. EDA Consortium, 2014, pp. 1-6.</p>
<p>Automated high-level generation of low-power approximate computing circuits. K Nepal, S Hashemi, H Tann, R I Bahar, S Reda, IEEE Transactions on Emerging Topics in Computing. 71K. Nepal, S. Hashemi, H. Tann, R. I. Bahar, and S. Reda, "Automated high-level generation of low-power approximate computing circuits," IEEE Transactions on Emerging Topics in Computing, vol. 7, no. 1, pp. 18-30, 2019.</p>
<p>Exploiting approximate feature extraction via genetic programming for hardware acceleration in a heterogeneous microprocessor. H Jia, N Verma, IEEE Journal of Solid-State Circuits. 534H. Jia and N. Verma, "Exploiting approximate feature extraction via genetic programming for hardware acceleration in a heterogeneous microprocessor," IEEE Journal of Solid-State Circuits, vol. 53, no. 4, pp. 1016-1027, 2018.</p>
<p>A survey on deep learning and its applications. S Dong, P Wang, K Abbas, Computer Science Review. 40100379S. Dong, P. Wang, and K. Abbas, "A survey on deep learning and its applications," Computer Science Review, vol. 40, p. 100379, 2021.</p>
<p>Efficient processing of deep neural networks: A tutorial and survey. V Sze, Y Chen, T Yang, J S Emer, Proceedings of the IEEE. 10512V. Sze, Y. Chen, T. Yang, and J. S. Emer, "Efficient processing of deep neural networks: A tutorial and survey," Proceedings of the IEEE, vol. 105, no. 12, pp. 2295-2329, 2017.</p>
<p>Neural architecture search: A survey. T Elsken, J H Metzen, F Hutter, J. Mach. Learn. Res. 2021T. Elsken, J. H. Metzen, and F. Hutter, "Neural architecture search: A survey," J. Mach. Learn. Res., vol. 20, pp. 55:1-55:21, 2019.</p>
<p>A comprehensive survey of neural architecture search: Challenges and solutions. P Ren, Y Xiao, X Chang, P Huang, Z Li, X Chen, X Wang, ACM Comput. Surv. 544P. Ren, Y. Xiao, X. Chang, P.-y. Huang, Z. Li, X. Chen, and X. Wang, "A comprehensive survey of neural architecture search: Challenges and solutions," ACM Comput. Surv., vol. 54, no. 4, 2021.</p>
<p>Efficient AI system design with cross-layer approximate computing. S Venkataramani, Proceedings of the IEEE. 10812S. Venkataramani et al., "Efficient AI system design with cross-layer approximate computing," Proceedings of the IEEE, vol. 108, no. 12, pp. 2232-2250, 2020.</p>
<p>Designing neural networks through neuroevolution. K O Stanley, J Clune, J Lehman1, R Miikkulainen, Nature Machine Intelligence. 1K. O. Stanley, J. Clune, J. Lehman1, and R. Miikkulainen, "Design- ing neural networks through neuroevolution," Nature Machine Intelli- gence, vol. 1, pp. 24-35, 2019.</p>
<p>Elementary functions and approximate computing. J.-M Muller, Proceedings of the IEEE. 10812J.-M. Muller, "Elementary functions and approximate computing," Proceedings of the IEEE, vol. 108, no. 12, pp. 2136-2149, 2020.</p>
<p>An evolutionary computation approach for approximate computing of PNN hardware circuits. C.-Y Chen, C.-W Chang, Z.-C Chen, 2019 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS). C.-Y. Chen, C.-W. Chang, and Z.-C. Chen, "An evolutionary computa- tion approach for approximate computing of PNN hardware circuits," in 2019 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS), 2019, pp. 1-2.</p>
<p>On evolutionary approximation of sigmoid function for HW/SW embedded systems. M Minarik, L Sekanina, EuroGP'17, ser. Springer10196M. Minarik and L. Sekanina, "On evolutionary approximation of sig- moid function for HW/SW embedded systems," in EuroGP'17, ser. LNCS, vol. 10196. Springer, 2017, pp. 343-358.</p>
<p>Design of power-efficient approximate multipliers for approximate artificial neural networks. V Mrazek, S S Sarwar, L Sekanina, Z Vasicek, K Roy, 2016 IEEE/ACM International Conference on Computer-Aided Design. V. Mrazek, S. S. Sarwar, L. Sekanina, Z. Vasicek, and K. Roy, "De- sign of power-efficient approximate multipliers for approximate arti- ficial neural networks," in 2016 IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2016, pp. 1-7.</p>
<p>ALWANN: Automatic layer-wise approximation of deep neural network accelerators without retraining. V Mrazek, Z Vasicek, L Sekanina, M A Hanif, M Shafique, IEEE/ACM International Conference on Computer-Aided Design. V. Mrazek, Z. Vasicek, L. Sekanina, M. A. Hanif, and M. Shafique, "ALWANN: Automatic layer-wise approximation of deep neural net- work accelerators without retraining," in 2019 IEEE/ACM Interna- tional Conference on Computer-Aided Design, 2019, pp. 1-8.</p>
<p>NS-GANetV2: evolutionary multi-objective surrogate-assisted neural architecture search. Z Lu, K Deb, E Goodman, W Banzhaf, V N Boddeti, Computer Vision -ECCV 2020. Springer International PublishingZ. Lu, K. Deb, E. Goodman, W. Banzhaf, and V. N. Boddeti, "NS- GANetV2: evolutionary multi-objective surrogate-assisted neural ar- chitecture search," in Computer Vision -ECCV 2020. Springer In- ternational Publishing, 2020, pp. 35-51.</p>
<p>APQ: Joint search for network architecture, pruning and quantization policy. T Wang, K Wang, H Cai, J Lin, Z Liu, H Wang, Y Lin, S Han, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). T. Wang, K. Wang, H. Cai, J. Lin, Z. Liu, H. Wang, Y. Lin, and S. Han, "APQ: Joint search for network architecture, pruning and quantization policy," in 2020 IEEE/CVF Conference on Computer Vision and Pat- tern Recognition (CVPR), 2020, pp. 2075-2084.</p>
<p>Automated design of error-resilient and hardware-efficient deep neural networks. C Schorn, T Elsken, S Vogel, A Runge, A Guntoro, G Ascheid, Neural Comput. Appl. 3224C. Schorn, T. Elsken, S. Vogel, A. Runge, A. Guntoro, and G. Ascheid, "Automated design of error-resilient and hardware-efficient deep neu- ral networks," Neural Comput. Appl., vol. 32, no. 24, pp. 18 327- 18 345, 2020.</p>
<p>Evolutionary neural architecture search supporting approximate multipliers. M Pinos, V Mrazek, L Sekanina, EuroGP'21, ser. SpringerM. Pinos, V. Mrazek, and L. Sekanina, "Evolutionary neural architec- ture search supporting approximate multipliers," in EuroGP'21, ser. LNCS. Springer, 2021, pp. 82-97.</p>
<p>MCUNet: Tiny deep learning on IoT devices. J Lin, W.-M Chen, Y Lin, J Cohn, C Gan, S Han, 34th Conference on Neural Information Processing Systems. J. Lin, W.-M. Chen, Y. Lin, J. Cohn, C. Gan, and S. Han, "MCUNet: Tiny deep learning on IoT devices," in 34th Conference on Neural Information Processing Systems (NeurIPS 2020), 2020, pp. 1-12.</p>
<p>µNAS: Constrained neural architecture search for microcontrollers. E Liberis, L Dudziak, N D Lane, Proc. of the 1st Workshop on Machine Learning and Systems, ser. EuroMLSys '21. of the 1st Workshop on Machine Learning and Systems, ser. EuroMLSys '21New York, NY, USAACME. Liberis, L. Dudziak, and N. D. Lane, "µNAS: Constrained neural architecture search for microcontrollers," in Proc. of the 1st Workshop on Machine Learning and Systems, ser. EuroMLSys '21. New York, NY, USA: ACM, 2021, p. 70-79.</p>
<p>HSCoNAS: Hardware-software co-design of efficient dnns via neural architecture search. X Luo, D Liu, S Huai, W Liu, Design, Automation &amp; Test in Europe Conference &amp; Exhibition, DATE 2021. IEEEX. Luo, D. Liu, S. Huai, and W. Liu, "HSCoNAS: Hardware-software co-design of efficient dnns via neural architecture search," in Design, Automation &amp; Test in Europe Conference &amp; Exhibition, DATE 2021. IEEE, 2021, pp. 418-421.</p>
<p>NASCaps: A framework for neural architecture search to optimize the accuracy and hardware efficiency of convolutional capsule networks. A Marchisio, A Massa, V Mrazek, B Bussolino, M Martina, M Shafique, 2020 IEEE/ACM International Conference On Computer Aided Design (ICCAD). A. Marchisio, A. Massa, V. Mrazek, B. Bussolino, M. Martina, and M. Shafique, "NASCaps: A framework for neural architecture search to optimize the accuracy and hardware efficiency of convolutional capsule networks," in 2020 IEEE/ACM International Conference On Computer Aided Design (ICCAD), 2020, pp. 1-9.</p>
<p>Artificial neural network and accelerator co-design using evolutionary algorithms. P Colangelo, O Segal, A Speicher, M Margala, 2019 IEEE High Performance Extreme Computing Conference (HPEC). P. Colangelo, O. Segal, A. Speicher, and M. Margala, "Artificial neu- ral network and accelerator co-design using evolutionary algorithms," in 2019 IEEE High Performance Extreme Computing Conference (HPEC), 2019, pp. 1-8.</p>
<p>ChamNet: Towards efficient network design through platform-aware model adaptation. X Dai, P Zhang, B Wu, H Yin, F Sun, Y Wang, M Dukhan, Y Hu, Y Wu, Y Jia, P Vajda, M Uyttendaele, N K Jha, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 11X. Dai, P. Zhang, B. Wu, H. Yin, F. Sun, Y. Wang, M. Dukhan, Y. Hu, Y. Wu, Y. Jia, P. Vajda, M. Uyttendaele, and N. K. Jha, "ChamNet: To- wards efficient network design through platform-aware model adapta- tion," in 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 11 390-11 399.</p>
<p>Deep-Maker: A multi-objective optimization framework for deep neural networks in embedded systems. M Loni, S Sinaei, A Zoljodi, M Daneshtalab, M Sjödin, Microprocessors and Microsystems. 73102989M. Loni, S. Sinaei, A. Zoljodi, M. Daneshtalab, and M. Sjödin, "Deep- Maker: A multi-objective optimization framework for deep neural networks in embedded systems," Microprocessors and Microsystems, vol. 73, p. 102989, 2020.</p>            </div>
        </div>

    </div>
</body>
</html>