<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-404 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-404</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-404</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-214605613</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2003.08978v2.pdf" target="_blank">Generating new concepts with hybrid neuro-symbolic models</a></p>
                <p><strong>Paper Abstract:</strong> Human conceptual knowledge supports the ability to generate novel yet highly structured concepts, and the form of this conceptual knowledge is of great interest to cognitive scientists. One tradition has emphasized structured knowledge, viewing concepts as embedded in intuitive theories or organized in complex symbolic knowledge structures. A second tradition has emphasized statistical knowledge, viewing conceptual knowledge as an emerging from the rich correlational structure captured by training neural networks and other statistical models. In this paper, we explore a synthesis of these two traditions through a novel neuro-symbolic model for generating new concepts. Using simple visual concepts as a testbed, we bring together neural networks and symbolic probabilistic programs to learn a generative model of novel handwritten characters. Two alternative models are explored with more generic neural network architectures. We compare each of these three models for their likelihoods on held-out character classes and for the quality of their productions, finding that our hybrid model learns the most convincing representation and generalizes further from the training observations.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e404.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e404.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Full NS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Full Neuro-Symbolic model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid neuro-symbolic generative model that represents characters as probabilistic programs (sequence of symbolic parts/strokes) while using neural networks (CNNs, LSTM with attention) to model complex conditional distributions (stroke trajectories, start locations) and a symbolic renderer as an explicit causal step.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Full Neuro-Symbolic (Full NS) model</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A modular probabilistic-program generative system that synthesizes characters one stroke at a time. The outer procedure (a probabilistic program) samples a sequence of strokes and locations; after sampling each stroke trajectory the system renders the stroke with a symbolic renderer onto an image canvas which becomes the memory/context for the next step. Neural modules are invoked for (1) predicting the next stroke starting location (a CNN-MLP that outputs a GMM), (2) generating the stroke trajectory (a CNN feature-map encoder feeding an LSTM with visual attention that outputs an autoregressive GMM for spline offsets), and (3) predicting termination. The model is trained by maximizing the log-likelihood of observed stroke sequences (gradient-based optimization of neural parameters).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>A probabilistic program that explicitly represents compositional and causal structure (sequence of stroke parts and their programmatic assembly). A symbolic renderer (deterministic procedural module) renders sampled strokes to an image canvas between steps; the program-level control flow (sampling strokes, applying renderer, termination decision) is declarative/structured.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural networks trained with gradient descent: CNNs for image encoding (location and stroke encoders), an MLP for location output mapping to GMM parameters, an LSTM with attention for autoregressive stroke generation (mixture-density outputs following Graves 2013), and a termination predictor; mixture density (GMM) output layers are used for continuous outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular integration: a fixed probabilistic program controls sequencing and calls neural modules as conditionals; information is passed via a symbolic image canvas (renderer output) that neural modules encode with CNNs (i.e., renderer->CNN->LSTM). The neural modules output probabilistic (GMM) parameters used by the program to sample continuous stroke variables. Training optimizes neural parameters to maximize the program's log-likelihood of data; the program structure is not learned end-to-end (the program controls flow and invokes neural components).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Combines compositional, causal structure (explicit stroke-part sequencing and symbolic rendering) with neural-captured rich correlations across strokes and styles; yields creativity-like generative behavior: (a) samples that preserve structural compositionality while exhibiting richer intra-stroke correlations and stylistic coherence across multiple strokes, (b) stronger out-of-distribution generalization to novel alphabets compared to pure neural baselines, and (c) the ability to generate novel characters that are often visually distinct from nearest training exemplars while remaining coherent.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Generative modeling and likelihood evaluation on Omniglot handwritten characters (tasks: 'character splits', 'alphabet splits', and holdout evaluation set); qualitative sample-generation and nearest-neighbor novelty analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>Negative log-likelihood per test character (alphabet splits): 13.77, 14.18, 17.53 (three CV splits; lower is better). Reported to outperform neural alternatives on held-out evaluation set (holdout set losses not given explicitly in text).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Exhibits superior generalization when test characters deviate substantially from training (notably in the 'alphabet splits' and held-out evaluation set): lower negative log-likelihoods than purely neural alternatives and generates characters that generalize further from observed exemplars; on the easier 'character splits' task (novel classes from familiar alphabets) the advantage is reduced and baselines can match or beat it, suggesting the hybrid's inductive bias helps most for out-of-distribution / compositional generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>The declarative probabilistic program and stroke decomposition provide an interpretable causal account: sequences of explicit strokes and rendered canvases can be inspected, and symbolic renderer steps correspond to understandable motor-to-image transformations. Neural modules remain opaque, but their inputs/outputs correspond to semantically meaningful quantities (start location distributions, stroke offsets), aiding interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>The model constrains information flow by design: 'it does not allow arbitrary information to flow between parts and variables as in monolithic neural networks', which can limit flexibility; performance advantage diminishes on easier within-alphabet splits where exemplar/statistical approaches suffice; the renderer and program structure are fixed (not learned), which may limit adaptability; numeric results for some comparisons (e.g., exact holdout numbers for baselines) are not provided in the text excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Division-of-labor neuro-symbolic framework: use structured probabilistic programs / symbolic rendering to encode strong compositional and causal inductive biases, while using neural statistical modules to capture complex, nonparametric correlations (mixture-density outputs) that symbolic parametric priors cannot. The paper argues that this complementary strengths approach yields better out-of-distribution/generalization behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e404.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e404.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neuro-symbolic (general)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neuro-Symbolic models (hybrid structured-statistical models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of hybrid systems that combine explicit structured symbolic representations (programs, grammars, logical forms) with statistical/neural components that model complex, high-dimensional correlations and continuous variables.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neuro-symbolic hybrid models (class)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>General description of architectures that integrate symbolic structured representations (e.g., probabilistic programs, grammars, compositional rules) with neural network components to model raw sensory inputs, conditional distributions, or parameters of symbolic primitives. Architectures vary from probabilistic-programs invoking neural submodules to statistical selection over symbolic hypothesis spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Probabilistic programs, grammars, symbolic compositional structures, program induction frameworks, and symbolic renderers (explicit causal models of part assembly).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural networks (CNNs, RNNs/LSTMs), mixture-density networks, attention mechanisms, and other gradient-trained procedural modules.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Typically modular: the high-level symbolic layer produces/composes parts or hypotheses and conditions or is conditioned on outputs of neural encoders; neural networks provide likelihoods/parameterizations (e.g., GMM parameters) or perceptual encodings. Integration can take the form of statistical inference over symbolic expressions with neural likelihood models, or procedural programs that call neural modules. The paper's Full NS is an instance where the probabilistic program orchestrates neural modules and uses a symbolic renderer as an intermediate memory.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Combines compositional causal generalization from symbolic structure with the ability to model high-dimensional, nonparametric correlations via neural nets, producing better out-of-distribution generalization and richer sample statistics than symbolic-only or neural-only approaches in the studied domain.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Omniglot character generation and held-out likelihood evaluation; more generally targeted at concept learning, program induction, and generative modeling of structured artifacts.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>For the concrete instance (Full NS) the alphabet-splits negative log-likelihoods are 13.77, 14.18, 17.53 per character (three splits); generally reported to outperform neural-only alternatives on out-of-distribution splits.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Claimed to improve out-of-distribution and compositional generalization by providing a strong inductive bias via symbolic structure while retaining neural flexibility to model complex sensory correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Symbolic components afford explanations in terms of part sequences and program steps; analysis of rendered strokes and program variables supports human-understandable inspection. Neural components reduce transparency but are constrained to semantically meaningful roles.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Trade-off between structure and flexibility: stronger symbolic constraints can limit arbitrary correlations and reduce expressivity; training and design choices (fixed program structure, renderer) may hamper learning of novel program primitives; engineering complexity of modular systems.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Complementary-strengths principle: symbolic/declarative modules provide strong inductive biases (causal, compositional priors) while neural/imperative modules capture nonparametric statistical regularities; hybridization aims for division of labor to improve generalization and sample quality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e404.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e404.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BPL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Program Learning (BPL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probabilistic program induction framework that models concepts (e.g., handwritten characters) as generative programs with compositional and causal structure, using Bayesian inference to learn programs from few examples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Human-level concept learning through probabilistic program induction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bayesian Program Learning (BPL)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A parametric Bayesian model that represents characters as generative programs composed of reusable parts/strokes with priors over program structure; inference selects programs that explain observed drawing data. BPL can be used as a prior to generate novel characters (forward sampling) and to perform few-shot concept learning via posterior inference.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Fully symbolic/probabilistic program representation of character generation (program grammar over strokes and parts, explicit causal assembly rules).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>None in its original parametric form; uses parametric probability distributions (e.g., simple Gaussian/multinomial assumptions) but not neural networks to model complex correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Not hybrid in this paper: BPL is used as a reference symbolic prior; in the paper it is compared qualitatively to the neuro-symbolic model's samples and used to highlight the need for neural-enhanced correlation modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Strong compositional and causal inductive biases enabling effective few-shot learning and interpretable program explanations; generates structurally coherent novel characters according to program priors.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Omniglot character generation and few-shot classification; used here for unconditional sampling and qualitative comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Supports strong compositional / few-shot generalization due to structured priors, but its parametric assumptions (e.g., relative independence of strokes in the prior) limit its ability to capture rich stylistic correlations present in human drawings.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High interpretability: learned programs provide explicit causal/compositional explanations of generated examples and of inferred concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Simplifying and rigid parametric assumptions about distributions of parts (e.g., strokes assumed largely independent in the prior) reduce the model's ability to capture complex correlations and stylistic coherence across parts; samples sometimes lack rich correlation structure compared to human drawings or neural-enhanced models.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Bayesian program induction: probabilistic grammars/programs define hypothesis space and Bayesian inference selects program hypotheses that explain observed data; emphasizes compositional causal priors as primary.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Human-level concept learning through probabilistic program induction <em>(Rating: 2)</em></li>
                <li>Learning to infer graphics programs from hand-drawn images <em>(Rating: 2)</em></li>
                <li>Learning Structured Generative Concepts <em>(Rating: 2)</em></li>
                <li>How to grow a mind: Statistics, structure, and abstraction <em>(Rating: 2)</em></li>
                <li>A rational analysis of rule-based concept learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-404",
    "paper_id": "paper-214605613",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "Full NS",
            "name_full": "Full Neuro-Symbolic model",
            "brief_description": "A hybrid neuro-symbolic generative model that represents characters as probabilistic programs (sequence of symbolic parts/strokes) while using neural networks (CNNs, LSTM with attention) to model complex conditional distributions (stroke trajectories, start locations) and a symbolic renderer as an explicit causal step.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Full Neuro-Symbolic (Full NS) model",
            "system_description": "A modular probabilistic-program generative system that synthesizes characters one stroke at a time. The outer procedure (a probabilistic program) samples a sequence of strokes and locations; after sampling each stroke trajectory the system renders the stroke with a symbolic renderer onto an image canvas which becomes the memory/context for the next step. Neural modules are invoked for (1) predicting the next stroke starting location (a CNN-MLP that outputs a GMM), (2) generating the stroke trajectory (a CNN feature-map encoder feeding an LSTM with visual attention that outputs an autoregressive GMM for spline offsets), and (3) predicting termination. The model is trained by maximizing the log-likelihood of observed stroke sequences (gradient-based optimization of neural parameters).",
            "declarative_component": "A probabilistic program that explicitly represents compositional and causal structure (sequence of stroke parts and their programmatic assembly). A symbolic renderer (deterministic procedural module) renders sampled strokes to an image canvas between steps; the program-level control flow (sampling strokes, applying renderer, termination decision) is declarative/structured.",
            "imperative_component": "Neural networks trained with gradient descent: CNNs for image encoding (location and stroke encoders), an MLP for location output mapping to GMM parameters, an LSTM with attention for autoregressive stroke generation (mixture-density outputs following Graves 2013), and a termination predictor; mixture density (GMM) output layers are used for continuous outputs.",
            "integration_method": "Modular integration: a fixed probabilistic program controls sequencing and calls neural modules as conditionals; information is passed via a symbolic image canvas (renderer output) that neural modules encode with CNNs (i.e., renderer-&gt;CNN-&gt;LSTM). The neural modules output probabilistic (GMM) parameters used by the program to sample continuous stroke variables. Training optimizes neural parameters to maximize the program's log-likelihood of data; the program structure is not learned end-to-end (the program controls flow and invokes neural components).",
            "emergent_properties": "Combines compositional, causal structure (explicit stroke-part sequencing and symbolic rendering) with neural-captured rich correlations across strokes and styles; yields creativity-like generative behavior: (a) samples that preserve structural compositionality while exhibiting richer intra-stroke correlations and stylistic coherence across multiple strokes, (b) stronger out-of-distribution generalization to novel alphabets compared to pure neural baselines, and (c) the ability to generate novel characters that are often visually distinct from nearest training exemplars while remaining coherent.",
            "task_or_benchmark": "Generative modeling and likelihood evaluation on Omniglot handwritten characters (tasks: 'character splits', 'alphabet splits', and holdout evaluation set); qualitative sample-generation and nearest-neighbor novelty analyses.",
            "hybrid_performance": "Negative log-likelihood per test character (alphabet splits): 13.77, 14.18, 17.53 (three CV splits; lower is better). Reported to outperform neural alternatives on held-out evaluation set (holdout set losses not given explicitly in text).",
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": true,
            "generalization_properties": "Exhibits superior generalization when test characters deviate substantially from training (notably in the 'alphabet splits' and held-out evaluation set): lower negative log-likelihoods than purely neural alternatives and generates characters that generalize further from observed exemplars; on the easier 'character splits' task (novel classes from familiar alphabets) the advantage is reduced and baselines can match or beat it, suggesting the hybrid's inductive bias helps most for out-of-distribution / compositional generalization.",
            "interpretability_properties": "The declarative probabilistic program and stroke decomposition provide an interpretable causal account: sequences of explicit strokes and rendered canvases can be inspected, and symbolic renderer steps correspond to understandable motor-to-image transformations. Neural modules remain opaque, but their inputs/outputs correspond to semantically meaningful quantities (start location distributions, stroke offsets), aiding interpretation.",
            "limitations_or_failures": "The model constrains information flow by design: 'it does not allow arbitrary information to flow between parts and variables as in monolithic neural networks', which can limit flexibility; performance advantage diminishes on easier within-alphabet splits where exemplar/statistical approaches suffice; the renderer and program structure are fixed (not learned), which may limit adaptability; numeric results for some comparisons (e.g., exact holdout numbers for baselines) are not provided in the text excerpt.",
            "theoretical_framework": "Division-of-labor neuro-symbolic framework: use structured probabilistic programs / symbolic rendering to encode strong compositional and causal inductive biases, while using neural statistical modules to capture complex, nonparametric correlations (mixture-density outputs) that symbolic parametric priors cannot. The paper argues that this complementary strengths approach yields better out-of-distribution/generalization behavior.",
            "uuid": "e404.0",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Neuro-symbolic (general)",
            "name_full": "Neuro-Symbolic models (hybrid structured-statistical models)",
            "brief_description": "A class of hybrid systems that combine explicit structured symbolic representations (programs, grammars, logical forms) with statistical/neural components that model complex, high-dimensional correlations and continuous variables.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Neuro-symbolic hybrid models (class)",
            "system_description": "General description of architectures that integrate symbolic structured representations (e.g., probabilistic programs, grammars, compositional rules) with neural network components to model raw sensory inputs, conditional distributions, or parameters of symbolic primitives. Architectures vary from probabilistic-programs invoking neural submodules to statistical selection over symbolic hypothesis spaces.",
            "declarative_component": "Probabilistic programs, grammars, symbolic compositional structures, program induction frameworks, and symbolic renderers (explicit causal models of part assembly).",
            "imperative_component": "Neural networks (CNNs, RNNs/LSTMs), mixture-density networks, attention mechanisms, and other gradient-trained procedural modules.",
            "integration_method": "Typically modular: the high-level symbolic layer produces/composes parts or hypotheses and conditions or is conditioned on outputs of neural encoders; neural networks provide likelihoods/parameterizations (e.g., GMM parameters) or perceptual encodings. Integration can take the form of statistical inference over symbolic expressions with neural likelihood models, or procedural programs that call neural modules. The paper's Full NS is an instance where the probabilistic program orchestrates neural modules and uses a symbolic renderer as an intermediate memory.",
            "emergent_properties": "Combines compositional causal generalization from symbolic structure with the ability to model high-dimensional, nonparametric correlations via neural nets, producing better out-of-distribution generalization and richer sample statistics than symbolic-only or neural-only approaches in the studied domain.",
            "task_or_benchmark": "Omniglot character generation and held-out likelihood evaluation; more generally targeted at concept learning, program induction, and generative modeling of structured artifacts.",
            "hybrid_performance": "For the concrete instance (Full NS) the alphabet-splits negative log-likelihoods are 13.77, 14.18, 17.53 per character (three splits); generally reported to outperform neural-only alternatives on out-of-distribution splits.",
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": true,
            "generalization_properties": "Claimed to improve out-of-distribution and compositional generalization by providing a strong inductive bias via symbolic structure while retaining neural flexibility to model complex sensory correlations.",
            "interpretability_properties": "Symbolic components afford explanations in terms of part sequences and program steps; analysis of rendered strokes and program variables supports human-understandable inspection. Neural components reduce transparency but are constrained to semantically meaningful roles.",
            "limitations_or_failures": "Trade-off between structure and flexibility: stronger symbolic constraints can limit arbitrary correlations and reduce expressivity; training and design choices (fixed program structure, renderer) may hamper learning of novel program primitives; engineering complexity of modular systems.",
            "theoretical_framework": "Complementary-strengths principle: symbolic/declarative modules provide strong inductive biases (causal, compositional priors) while neural/imperative modules capture nonparametric statistical regularities; hybridization aims for division of labor to improve generalization and sample quality.",
            "uuid": "e404.1",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "BPL",
            "name_full": "Bayesian Program Learning (BPL)",
            "brief_description": "A probabilistic program induction framework that models concepts (e.g., handwritten characters) as generative programs with compositional and causal structure, using Bayesian inference to learn programs from few examples.",
            "citation_title": "Human-level concept learning through probabilistic program induction",
            "mention_or_use": "use",
            "system_name": "Bayesian Program Learning (BPL)",
            "system_description": "A parametric Bayesian model that represents characters as generative programs composed of reusable parts/strokes with priors over program structure; inference selects programs that explain observed drawing data. BPL can be used as a prior to generate novel characters (forward sampling) and to perform few-shot concept learning via posterior inference.",
            "declarative_component": "Fully symbolic/probabilistic program representation of character generation (program grammar over strokes and parts, explicit causal assembly rules).",
            "imperative_component": "None in its original parametric form; uses parametric probability distributions (e.g., simple Gaussian/multinomial assumptions) but not neural networks to model complex correlations.",
            "integration_method": "Not hybrid in this paper: BPL is used as a reference symbolic prior; in the paper it is compared qualitatively to the neuro-symbolic model's samples and used to highlight the need for neural-enhanced correlation modeling.",
            "emergent_properties": "Strong compositional and causal inductive biases enabling effective few-shot learning and interpretable program explanations; generates structurally coherent novel characters according to program priors.",
            "task_or_benchmark": "Omniglot character generation and few-shot classification; used here for unconditional sampling and qualitative comparison.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": true,
            "generalization_properties": "Supports strong compositional / few-shot generalization due to structured priors, but its parametric assumptions (e.g., relative independence of strokes in the prior) limit its ability to capture rich stylistic correlations present in human drawings.",
            "interpretability_properties": "High interpretability: learned programs provide explicit causal/compositional explanations of generated examples and of inferred concepts.",
            "limitations_or_failures": "Simplifying and rigid parametric assumptions about distributions of parts (e.g., strokes assumed largely independent in the prior) reduce the model's ability to capture complex correlations and stylistic coherence across parts; samples sometimes lack rich correlation structure compared to human drawings or neural-enhanced models.",
            "theoretical_framework": "Bayesian program induction: probabilistic grammars/programs define hypothesis space and Bayesian inference selects program hypotheses that explain observed data; emphasizes compositional causal priors as primary.",
            "uuid": "e404.2",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Human-level concept learning through probabilistic program induction",
            "rating": 2,
            "sanitized_title": "humanlevel_concept_learning_through_probabilistic_program_induction"
        },
        {
            "paper_title": "Learning to infer graphics programs from hand-drawn images",
            "rating": 2,
            "sanitized_title": "learning_to_infer_graphics_programs_from_handdrawn_images"
        },
        {
            "paper_title": "Learning Structured Generative Concepts",
            "rating": 2,
            "sanitized_title": "learning_structured_generative_concepts"
        },
        {
            "paper_title": "How to grow a mind: Statistics, structure, and abstraction",
            "rating": 2,
            "sanitized_title": "how_to_grow_a_mind_statistics_structure_and_abstraction"
        },
        {
            "paper_title": "A rational analysis of rule-based concept learning",
            "rating": 1,
            "sanitized_title": "a_rational_analysis_of_rulebased_concept_learning"
        }
    ],
    "cost": 0.01369575,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Generating new concepts with hybrid neuro-symbolic models</p>
<p>Reuben Feinman reuben.feinman@nyu.edu 
Center for Neural Science
Department of Psychology and Center for Data Science
New York University
Brenden M. Lake</p>
<p>New York University</p>
<p>Generating new concepts with hybrid neuro-symbolic models
Neural networkscompositionalitycausalitygenerative models
Human conceptual knowledge supports the ability to generate novel yet highly structured concepts, and the form of this conceptual knowledge is of great interest to cognitive scientists. One tradition has emphasized structured knowledge, viewing concepts as embedded in intuitive theories or organized in complex symbolic knowledge structures. A second tradition has emphasized statistical knowledge, viewing conceptual knowledge as an emerging from the rich correlational structure captured by training neural networks and other statistical models. In this paper, we explore a synthesis of these two traditions through a novel neuro-symbolic model for generating new concepts. Using simple visual concepts as a testbed, we bring together neural networks and symbolic probabilistic programs to learn a generative model of novel handwritten characters. Two alternative models are explored with more generic neural network architectures. We compare each of these three models for their likelihoods on held-out character classes and for the quality of their productions, finding that our hybrid model learns the most convincing representation and generalizes further from the training observations.</p>
<p>Introduction</p>
<p>People can synthesize new concepts in imaginative ways; architects design new houses, chefs invent new recipes, and entrepreneurs create new business models. The resulting productions exhibit novel variations but maintain important structural consistencies with known entities. In contrast, state-of-the-art generative models from machine learning struggle with creative imagination, producing samples that either closely mimic the training data or that exhibit anomalous characteristics . How do people create novel yet coherent new concepts? How can we understand these abilities in computational terms?</p>
<p>Human conceptual knowledge plays a central role in creative generalization. A chef knows not only a repertoire of recipes, but also understands that recipes are built from reusable ingredients (e.g. carrots, flour, butter), and that these ingredients satisfy specific roles (thickening, seasoning, greasing). Furthermore, a chef understands which ingredients can substitute for others (e.g. butter for oil when greasing) and which should never be combined (e.g. ketchup and milk). In addition, they understand that recipes are composed of reusable causal procedures (cutting, whisking, browning), and they know how to compose these procedures in terms of order and substitutability. This causal and compositional knowledge is essential to understanding a culinary concept, as opposed to merely executing it, and is essential to a chef's ability to create new culinary concepts such as "carrots tartar" or "pea guacamole."</p>
<p>There have been two traditions of work on computational models of conceptual knowledge. The first tradition emphasizes "structured knowledge" for capturing relations between concepts and correlations between conceptual features, viewing concepts as embedded in intuitive theories (Murphy &amp; Medin, 1985) or capturing structured knowledge through symbolic representations such as hierarchies, trees, grammars and programs (Kemp &amp; Tenenbaum, 2008, 2009Tenenbaum et al., 2011). This tradition has prioritized the compositional and causal nature of conceptual knowledge, as emphasized through accounts of concept learning as program induction (Goodman et al., 2008;Stuhlmuller et al., 2010;Lake et al., 2015;Goodman et al., 2015;Ellis et al., 2018;Lake &amp; Piantadosi, 2019). The Bayesian Program Learning (BPL) framework (Lake et al., 2015), for example, demonstrates how to learn programs from images to express the causal and compositional nature of concepts and background knowledge. Although these models offer a convincing account for how strong inductive biases support flexible generalization, they often make simplifying and rigid parametric assumptions about the distributions of concepts in pursuit of a structured representation. As a result, they so far have been unsuccessful in characterizing the most complex correlations and invariances associated with human concepts in raw, highdimensional stimulus spaces.</p>
<p>The second tradition in models of conceptual knowledge emphasizes "statistical knowledge," a more amorphous form of background knowledge that is often not amenable to symbolic description. In the statistics view, conceptual knowledge manifests as complex systems of patterns and correlations recorded from observations. The meaning of a word, for example, can be derived from its patterns of co-occurrance with other words (Deerwester et al., 1990). Similarly, latent representations of objects and other sensory stimuli can be derived from "suspicious coincidences" noted in the data (Barlow, 1989). The statistics view emphasizes emergence, where conceptual knowledge emerges from the interaction of simpler processes, as operationalized through training neural network architectures (McClelland, 2010). Although a powerful modeling tool, standard neural networks do not explicitly model the compositional and causal structure of concepts. As result, they have difficulty generalizing to examples that vary systematically from training (Marcus, 2003;Lake &amp; Baroni, 2018), and to novel tasks, especially those that demand more generative and creative abilities (Lake et al., 2017.</p>
<p>Our goal in this paper is to explore generative models of concepts at the interface of these structured and statistical traditions, offering new ways of synthesizing key ideas from each. Previous efforts to integrate these traditions have demonstrated ways of performing statistical inference over structured representations . This includes models of concept learning as Bayesian inference over fully-symbolic expressions in formal logical (Goodman et al., 2008;Piantadosi et al., 2016), or models of inductive reasoning supported by structured intuitive theories (Kemp &amp; Tenenbaum, 2009). In accounts of this nature, statistics is primary in selecting between structured symbolic hypotheses (Kemp &amp; Tenenbaum, 2008;Perfors et al., 2011;Lake et al., 2015;Lake &amp; Piantadosi, 2019), while only secondary in selecting the constrained parametric distributions encapsulated in those hypotheses (Gaussians, multinomials, etc.).</p>
<p>Here we aim to more thoroughly integrate the structured and statistical traditions through hybrid neuro-symbolic generative models. Our goal is to devise a causal generative model with explicit compositional structure, and with complex correlations represented implicitly through neural networks rather than simple parametric distributions. We use simple visual concepts -handwritten characters from the world's languages -as a case study for exploring neurosymbolic models of concept generation. The Omniglot dataset (Lake et al., 2015) of handwritten characters provides an excellent preliminary modeling environment: it contains a large number of natural, simple concepts that people learn and use, and it has been explored extensively in prior work from both cognitive science and AI. Following the mixture density network framework for handwriting generation (Graves, 2013), we explore three distinct generative neural architectures, varying the strength and form of inductive bias imposed on the model, including their position on the neurosymbolic spectrum and the fidelity in which compositionality and causality are presented. We evaluate the generalization capacity of these models by comparing their log-likelihoods on a holdout set of characters. Furthermore, we analyze the samples produced by each model, looking for characters that are qualitatively consistent but sufficiently dissimilar from the training set. We find that a hybrid neuro-symbolic architecture with the strongest form of compositional structure exhibits the best generalization performance, and that it generates characters that are highly consistent with human drawings. In contrast, our generic neural models exhibit weaker performance on the holdout set, and they produce characters that more closely mimic the training examples.</p>
<p>Related Work</p>
<p>In the machine learning community, there have been a number of works studying generative neural network models for handwritten characters, including DRAW (Gregor et al., 2015), AIR (Eslami et al., 2016) and SPIRAL (Ganin et al., 2018). Although these models learn a procedure to generate new characters, they do not use the human drawing data from Omniglot, and therefore the generative process may not reflect the true causal processes of human character production. Our goal is different in that we aim to model the causal process of human handwriting directly from drawing data. Ha &amp; Eck (2018) introduced a neural network architecture called Sketch-RNN to model human drawing data for simple objects like cats, firetrucks, and windmills. Although their goal loosely resembles our own, the Sketch-RNN model is trained on just a single class of objects at one time (e.g. "cat"), and it receives 70,000 examples from the class. In contrast, our motivation is to model human conceptual knowledge of handwriting concepts in general. This background knowledge plays a central role in creative generalization, enabling people to synthesize new concepts that deviate from the observed entities. We train our models on many character classes at once, providing only 20 training examples of each class and asking them to generate new character concepts. The Sketch-RNN model has not been applied in this way.</p>
<p>Most related to our work is the Bayesian Program Learning (BPL) approach of Lake et al. (2015) that was also applied to the simple visual concepts in Omniglot. BPL is a parametric Bayesian model that captures causal, compositional structure in human background knowledge of handwriting, and shows that these ingredients are important for few-shot learning of new character concepts. Beyond supporting fewshot learning, the BPL character prior can also generate new character concepts by unconditional sampling. Although a powerful demonstration of compositional representation, the BPL parametric model makes many simplifying assumptions about characters. For example, it assumes that strokes in a character are generated largely independently from each other in the prior (although they are strongly correlated in the posterior). As result, new characters generated by the model often lack the rich correlation structure of human drawings. We build on this work and develop a new neuro-symbolic model that represents the compositional structure of characters while using neural networks to capture richer correlations.</p>
<p>Omniglot Case Study</p>
<p>We use simple visual concepts as a case study for modeling conceptual structure and developing generative models of concepts. The Omniglot dataset contains human drawings of characters from 50 unique alphabets, providing a large set of cognitively natural concepts that are simple enough for evaluating models (Lake et al., 2015. In our experiments, we use drawings from the Omniglot background set to train our models, which contains 30 alphabets and a total of 19,280 unique drawings. We also use 10 alphabets from the Omniglot evaluation set as a holdout set for quantitative evaluations, reserving the remaining 10 alphabets for future work on few-shot classification.</p>
<p>In the drawing data, a stroke is represented as a variablelength sequence of pen locations {z 1 , ..., z T }, with z i  R 2 (Fig. 2, left). As a pre-processing step, we convert each stroke into a minimal spline representation using least-squares optimization ( Fig. 2, right), borrowing the B-spline tools from Lake et al. (2015). The number of spline control points depends on the stroke complexity and is determined by a resid-  GenerateCharacter consists of sequentially reading from and rendering to an image canvas, which is initialized to zero. At each time step, the current canvas I is fed to procedure GenerateStroke, which produces a stroke sample. The canvas is first processed by the location model, a CNN-MLP architecture that processes the image and returns a Gaussian mixture model (GMM) distribution for the starting location of the next stroke y. The location y is then sampled and passed along with I to the stroke model. The stroke model processes I with a CNN and feeds the embedding to an LSTM with attention. The LSTM samples a stroke trajectory x sequentially one offset at a time using GMM outputs. The sampled stroke is passed to a symbolic renderer, and the updated image canvas is then processed by a termination model that decides whether to continue the character sample.
GenerateStroke(I) location model p(y | I) stroke model p(x | y, I) CNN MLP CNN LSTM y I I I I, y attention p( 1 ) p( 2 |  1 ) p( T |  1:T1 )  y  p ( y | I ) I, y, x x  p ( x | y , I ) procedure GENERATECHARACTER I 0 . Initialize
ual threshold. Furthermore, we removed small strokes from the data using a threshold on the trajectory length. These processing steps help suppress noise and emphasize signal in the character drawings. Our generative models are trained to produce character drawings, where each drawing is represented as an ordered set of splines (strokes). The number of strokes, and the number of spline coordinates per stroke, are allowed to vary. </p>
<p>Neuro-Symbolic Model</p>
<p>Our primary interest is to test whether a hybrid neurosymbolic model can capture the compositional, causal structure in a large corpus of simple character concepts. The architecture and sampling procedure of our hybrid model, which we call the "Full Neuro-Symbolic" (Full NS) model, is given in Fig. 1. Compared to generic neural networks, the Full NS model lies closer to structure on the structure-statistics spectrum, possessing a much stronger inductive bias. As in BPL (Lake et al., 2015), the generative model is a probabilistic program that captures real compositional and causal structure by sampling characters as a sequence of parts and locations/relations. Unlike BPL, the model has a symbolic engine that renders each part to an image canvas before producing the next one, and parts are generated using a powerful recurrent neural network that encodes and attends to the current canvas. Although correlations between parts can be captured through a process of rendering and then encoding, the model does not allow arbitrary information to flow between parts and variables as in monolithic neural networks. The Full NS model represents a character as a sequence of strokes, with each stroke decomposed into a starting location y t  R 2 , conveying the first spline control point, and a stroke trajectory x t = { 1 , ...,  N }, conveying deltas between spline control points. It generates characters one stroke at a time, using a symbolic renderer as an intermediate processing step after forming each stroke. An image canvas I is used as a memory state to convey information about previous strokes. At each time step t, the next stroke's starting location and trajectory are sampled with procedure GenerateStroke. In this procedure, the current image canvas I is first read by the location model ( Fig. 1; bottom middle), a convolutional neural network (CNN) that processes the image and returns a probability distribution for starting location y t :
y t  p(y t | I).
A visualization of the density p(y t | I) is given in Fig. 3, "Location Prediction." The starting location y t is then passed along with the image canvas I to the stroke model ( Fig. 1;  bottom right), a Long Short-Term Memory (LSTM) architecture with a CNN-based image attention mechanism inspired by Xu et al. (2016). The stroke model samples the next stroke trajectory x t sequentially one offset at a time, selectively attending to different parts of the image canvas at each sample step and combining this information with the context of y t :</p>
<p>x t  p(x t | y t , I). After each stroke, the model receives the current image canvas ("Input Canvas") and makes a series of predictions. Termination Prediction. First, the model predicts a termination probability p (blue bar), i.e. a probability of terminating the drawing. Location Prediction. Next, the model predicts a probability density for the next stroke's starting location. The heatmap indicates the predicted density, and the hollow red dot indicates the ground-truth location. Stroke Prediction. Finally, the model predicts an auto-regressive probability density for the next stroke's trajectory (the "stroke"). Red dots indicate the previous control points, heatmaps indicate the predicted density for the next control point, and hollow red dot indicates the ground-truth next control point.</p>
<p>A visualization of the auto-regressive density p(x t | y t , I) is given in Fig. 3, "Stroke Prediction." Mixture Outputs. Both our location model and stroke model follow a technique from Graves (2013), who proposed to use neural networks with mixture outputs to model handwriting data. The parameters  = { 1:K ,  1:K ,  1:K ,  1:K } output by our network specify a Gaussian mixture model (GMM) with K components ( Fig. 1; colored ellipsoids), where  k  (0, 1) is the mixture weight of the k th component,  k  R 2 its means,  k  R 2 + its standard deviations, and  k  (1, 1) its correlation. In our location model, a single GMM describes the distribution p(y t | I). In our stroke model, the LSTM outputs one GMM at each timestep, describing p( t | 1:t1 , y t , I).</p>
<p>Training. Our Full NS model provides a density function which can be used to score the log-likelihood for any character drawing. We train the model to maximize the loglikelihood (minimize log-loss) of the training set drawings, using mini-batch gradient descent with a batch size of 200 and the Adam update rule.</p>
<p>Alternative Models</p>
<p>In addition to our Full NS model, we explored two alternative models with more generic neural network architectures. In each alternative, we lesioned key structural ingredients of the Full NS model, hoping to test the importance of these ingredients to model performance.</p>
<p>Hierarchical LSTM. As one alternative neural model, we explored a hierarchical recurrent architecture (Sordoni et al., 2015;Ling et al., 2016;Chung et al., 2017), which we denote "Hierarchical LSTM" (H-LSTM). Like our Full NS architecture, the H-LSTM model is trained on causal data demonstrating how people actually produce drawings of characters. In addition, it models the compositional structure of characters by separating them into explicit stroke parts, which defines the hierarchy in the hierarchical LSTM. Unlike our Full NS model, however, the H-LSTM has no renderer and thus lacks any explicit causal knowledge of how motor actions become raw images of inked characters. Instead, information about the previous strokes is written to memory via recurrent connections and gating mechanisms. These transformations can propagate arbitrary correlations, and they must be learned entirely from the data. Specifically, at each time step t, the previous stroke x t1 is read by a stroke encoder f enc , a bi-directional LSTM that processes the stroke and returns a fixed-length vector (red box in Fig. 4). This vector is then passed as an input to the character LSTM along with previous location y t1 and previous hidden state h t1 :
h t = f LSTM (y t1 , f enc (x t1 ), h t1 ).
The new hidden state h t is then fed to the location model p(y t | h t ), a multi-layer perceptron that outputs a GMM distribution for the next stroke's starting location y t (green box in Fig. 4). The location is sampled from this distribution and passed as an input along with h t to the stroke model p(x t | h t , y t ), an LSTM that samples a stroke trajectory one offset at a time with GMM outputs (yellow box in Fig. 4):
y t  p(y t | h t ) x t  p(x t | h t , y t ).
Baseline LSTM. A second alternative is even less structured and represents the most purely statistical architecture we examined. For this model, we explored a naive unrolled LSTM, denoted "Baseline." This model is a reproduction of the unconditional version of Sketch-RNN (Ha &amp; Eck, 2018, Sec 3.3). Similar to Full NS and H-LSTM, the Baseline LSTM is trained on causal data demonstrating the process of producing character; however, it does not explicitly take the compositional structure of characters into account in the architecture itself. Instead, it uses a single RNN to model a character as one long sequence of pen actions with stroke breaks.</p>
<p>Following Sketch-RNN, we expand the binary pen state variable v t  {0, 1} from Graves (2013) to a ternary variable v t  {0, 1, 2} to handle multi-stroke drawings. Value 0 indicates that we are continuing the current stroke, 1 that we are ending the current stroke and starting a new one, and 2 that we are ending the drawing. The initial hidden and cell states of the LSTM are set to zero, and at each time step t, the previous offset  t1 , previous pen state v t1 , and previous hidden state h t1 are fed as inputs to the LSTM, which outputs new hidden state h t :
h t = f LSTM ( t1 , v t1 , h t1 ).
An output layer receives h t and returns a categorical distribution for next pen state v t , as well as a GMM distribution for next offset  t :
 v = f v (h t ), v t  p(v t |  v )   = f  (h t ),  t  p( t |   ).</p>
<p>Experiments</p>
<p>We evaluated the creative generalizations of our 3 neural network models using both quantitative and qualitative analyses. Each of our models estimates a probability density function for characters from training examples. This density function can be used to compute likelihoods for held-out characters and to generate new character samples. A generative model for characters that exhibits creative generalization should produce high likelihood scores for novel character concepts from  Table 1: Test losses from our 3 models. Losses indicate the average negative log-likelihood per test character (lower is better). In our alphabet splits task, we divide the background set into train/test splits such that the model must generalize to new characters from novel alphabets. In our "character splits task, we divide the background set such that the model must generalize to new characters from familiar alphabets. In our "holdout task, we provide the entire background set for training and use the held-out evaluation setwhich contains new characters from novel alphabets-for testing.</p>
<p>held-out classes. In addition, the model should generate new characters that are sufficiently dissimilar from the training examples, but that are structurally consistent with ground truth. In our quantitative analysis, we tested our models for their likelihood performance on novel character classes using a rigorous set of experiments with different train/test splits. In our qualitative analysis, we inspected character samples produced by each model, comparing them to characters from both BPL and ground truth and looking at nearest neighbors from the training set.</p>
<p>Evaluation on Held-Out Concepts</p>
<p>Methods. In our quantitative analysis, we evaluated our models for two different forms of likelihood generalization, corresponding to different train/test splits. In the first generalization task, denoted "character splits," we asked whether our models could generalize to new character classes from familiar alphabets. We created 3 train/test splits from the Omniglot background set, sampling 80% of characters per alphabet for train and 20% for test. In our second task, denoted "alphabet splits," we asked whether our models could generalize to new character classes from novel alphabets. We again sampled 3 train/test splits of size 80-20, this time splitting by alphabet. In both the "character splits" and "alphabet splits" tasks, we explored multiple hyperparameter configurations for our models, varying parameters such as the number of hidden layers, number of units per layer, and dropout probability. 1 Average validation loss across splits was used to select the best configuration for each model in each task. We then took our best configurations in each task and reported their validation losses on all 3 splits. As a final quantitative analysis, we tested our models on one additional task that extends the "alphabet splits" task. Our motivation was to provide a more rigorous analysis using a completely withheld test set as per standard practice in machine learning evaluations. We re-trained our best configurations of each model on the entire background set, using the hyperparameters selected from our "alphabet splits" task. We then reported losses on the evaluation set, which contains character drawings from 10 novel alphabets. Results. Results from our CV-splits experiments are given in Table 1, "Alphabet Splits" and "Character Splits." In our alphabet splits experiment, the Full NS model consistently outperformed its alternatives, exhibiting the best generalization performance in each of the 3 splits with losses of 13.77, 14.18 and 17.53, respectively (per character average). Thus, our neuro-symbolic architecture appears best equipped to capture overarching principles in handwriting concepts that generalize far outside of the training examples. In our character splits task, the Baseline LSTM exhibited best performance in 2 out of 3 splits, and the Full NS model in 1 of 3. The character splits test present a much easier generalization task, where exemplar-based learning could offer a suitable alternative to learning general structural principals. Although our naive Baseline model performs well, its lack of consistency across splits suggests that this model may rely on more of an exemplar-based technique for learning, which we investigate further in our sample analyses. Interestingly, the selected hyperparameter configuration for our Full NS model remained constant across the "alphabet" and "character" split tasks, whereas the configuration changed for both the Baseline and H-LSTM models.</p>
<p>Results for each model on the held-out set of characters are shown in Table 1, "Holdout." Similarly to the "alphabets" task, our Full NS model outperforms both alternative models on the holdout set, providing further support that this architecture learns the best general model of these simple visual concepts.</p>
<p>Generating New Concepts</p>
<p>Methods. In our qualitative analysis, we analyzed the 3 neural network models on their ability to produce novel visual concepts. We took our trained models from the previous experiment and sampled 36 characters from each model, following the model's causal generative procedure. In addition, we sampled 36 characters from the BPL character prior, and we selected 36 "ground truth" characters from Omniglot at random. Samples were then compared visually side-by-side.</p>
<p>As an additional qualitative analysis, we compared character samples from each model for their similarity to the training examples. Although the complexity and structural coherency of generated characters are important criteria, these observations alone provide insufficient evidence for a human- like generative process; a model that memorizes the training examples might produce samples with structural coherence and rich variations, but such a model does not account for the flexible ways that humans generate new concepts. In our second analysis, we took the character samples from our models and found the 5 most-similar training characters for each, using cosine distance in the last hidden layer of a CNN classifier as a metric space for perceptual similarity. The CNN was trained to classify characters from the Omniglot background set, a 964-way classification task.</p>
<p>Results. Fig. 5 shows samples from each of our three models, as well as from the BPL forward model 2 and from the Omniglot data (ground truth). Compared to BPL, the neuralenhanced models capture more correlational structure and character complexity. For instance, the Full NS model propagates stylistic and structural consistency across three strokes to form a Braille-like character, as shown by the sample in column 1, row 2. Fig. 6 Figure 7: Topologically-Organized character samples and their nearest Omniglot neighbors. We drew 100 character samples from our Full NS model and organized them into a 10x10 grid such that neighboring characters have similar drawing styles (left). We then found the "nearest neighbor" of each sample from the Omniglot character dataset and organized the neighbors into a corresponding 10x10 grid (right).</p>
<p>acters that closely mimic the nearest training examples in the majority (7/9 by our eyes) of cases. In contrast, our Full NS model produces only a few (3/9) characters that directly mirror the nearest training examples, suggesting that it can generalize further from the training observations.</p>
<p>To get an idea of the different character styles produced by our Full NS model, we sampled 100 characters from the model and organized them into a 10x10 grid such that neighboring characters have high perceptual similarity (Fig. 7, left). Characters were sampled at a lower level of stochasticity, using the temperature parameter proposed by Ha &amp; Eck (2018) to modify the entropy of the mixture density outputs (we used T = 0.5). The model produces characters in multiple distinct styles, with some having more angular, linebased structure and others relying on complex curves. In Fig.  7, (right) we plotted the most-similar Omniglot character for each sample in a corresponding grid. In many cases, samples from the model have a distinct style and are visually dissimilar from their nearest Omniglot neighbor.</p>
<p>Conclusion</p>
<p>We presented a new neuro-symbolic generative model of simple visual concepts. Our model successfully captures compositional and causal structure in handwritten character concepts, forming a representation that generalizes to new concepts. We tested our model by comparing its likelihood scores on a holdout set of novel characters, finding that it consistently outperforms two generic neural network alternatives when the test characters deviate significantly from the training examples. Furthermore, our generative model produces new character concepts with richer variations than simple parametric models, yet that remain structurally coherent and visually consistent with human productions.</p>
<p>Neuro-symbolic models offer a promising set of tools to express the rich background knowledge that enables creative imagination. These models can explain the nonparametric correlation structure embodied in conceptual knowledge while maintaining important inductive biases to account for the structured ways that people generate new concepts. We believe that models of this kind will be useful to explain a variety of human imaginative behaviors, such as when a chef creates the new recipe "pea guacamole." In future work, we'd like to explore applications of neuro-symbolic models to other types of concepts with varying complexity.</p>
<p>Figure 1 :
1Full neuro-symbolic (Full NS) model. Our Full NS model produces character samples one stroke at a time. The procedure</p>
<p>Figure 2 :
2Spline representation. Raw strokes (left) are converted into minimal splines (right) using least-squares optimization. Crosses (left) indicate pen locations and red dots (right) indicate spline control points.</p>
<p>Figure 3 :
3Predictions of the Full NS model for a test character.</p>
<p>Figure 4 :
4Hierarchical LSTM model. The model samples characters one stroke at a time, using a character-level LSTM as a memory state. At each time, the model samples a starting location for the next stroke from a location predictor (MLP), and a stroke trajectory from the stroke predictor (LSTM). These samples are then fed to the model as inputs for the next time, with the location fed directly and the trajectory processed by a stroke encoder (bi-directional LSTM).</p>
<p>Figure 5 :
5Character sample comparison. Characters generated by our Full NS, H-LSTM and Baseline LSTM models are shown side-byside, along with samples from the BPL forward model 2 as well as ground truth characters from Omniglot.</p>
<p>Figure 6 :
6Novelty of character samples. Character drawings sampled from each model were compared to their 5 nearest neighbors from the training set. Each row corresponds to one character sample from the model. The red box indicates the model sample, and the 5 nearest neighbors are shown in the succeeding columns.</p>
<p>shows a handful of character samples produced by each neural model plotted alongside their five nearest neighbors from the Omniglot training set. Both the H-LSTM and the Baseline LSTM models produce char-samples from Full NS 
model (T=0.5) </p>
<p>corresponding 
Omniglot neighbors </p>
<p>stroke key: </p>
<p>For details about hyperparameters, see Appendix A.
BPL character samples have been centered for better visual appearance; the actual samples often protrude outside of the image window. A more complex non-parametric BPL model was used in the visual Turing tests inLake et al. (2015) that has explicit re-use of character parts. Those samples were also centered.
AcknowledgementsWe thank Maxwell Nye, Josh Tenenbaum, Tuan-Anh Le, and Jay McClelland for helpful discussions regarding this work.Appendix A. Model HyperparametersHere we review the hyperparameters (HPs) used for each of our models, indicating which HPs were fixed and which were tuned. All neural networks with GMM output layers use 20 mixture components.Full NS. The Full NS model has 3 submodules: a location model, a stroke model, and a termination model. Each submodule uses a distinct CNN, and each receives an image canvas of size (28,28). The location and termination modelswhich return outputs for a single time step-each use a feedforward CNN architecture inspired byVinyals et al. (2016). The CNNs consist of a stack of 4 blocks, with each block i including a 3x3 convolution with K i filters, batch normalization, nonlinear activation f , 2x2 max-pooling, and dropout with rate p. These blocks are followed by a single fully-connected layer with D units, activation f and dropout p. Hyperparameters {K i }, f , p and D were selected from tuning. The stroke model uses a modified CNN architecture without spatial pooling, designed to convey high-resolution spatial information for visual attention. The CNN returns a feature map of size(64,14,14), which is then passed to an LSTM. The LSTM predicts the spline trajectory of the next stroke one offset at a time, attending to different parts of the feature map at each step. The HPs of the CNN were fixed, but the HPs of the LSTM were tuned, including the number of LSTM layers and number of units per layer.Hierarchical LSTM. The Hierarchical LSTM model has a character-level LSTM backbone and 3 submodules: a stroke encoder (BiLSTM), a location model (MLP), and a stroke model (LSTM). The number of LSTM layers, number of units per layer and dropout rate in the character-level LSTM were selected from tuning, but HPs of all submodules were fixed. The stroke encoder is a bidirectional LSTM with a single layer of 256 units. It outputs a fixed-length vector representation of the previous stroke, which is fed to the character LSTM as input. The location model is a 2-layer MLP that receives the current hidden state of the character LSTM and outputs a GMM for the next stroke's starting location. The stroke model is an LSTM with a single layer of 256 units and outputs a GMM at each time step for the next spline offset.Baseline LSTM. The Baseline LSTM is a single module. It has L LSTM layers, each with K units and dropout rate p. The values of L, K and p were selected from tuning.B. Samples with stroke decompositionInFig. 8, we show a larger collection of characters from our Full NS model, using color coding to convey the stroke composition of each sample. We produced character samples at two different levels of stochasticity, using a temperature parameter to modify the entropy of the mixture density outputs(Ha &amp; Eck, 2018, Eq.8). Samples are shown for temperature settings T = 1.0 and T = 0.5.
Unsupervised learning. H B Barlow, Neural Computation. 13Barlow, H. B. (1989). Unsupervised learning. Neural Computation, 1(3), 295-311.</p>
<p>Hierarchical multiscale recurrent neural networks. J Chung, S Ahn, Y Bengio, In ICLRChung, J., Ahn, S., &amp; Bengio, Y. (2017). Hierarchical multiscale recurrent neural networks. In ICLR.</p>
<p>Indexing by latent semantic analysis. S Deerwester, S T Dumais, G W Furnas, T K Landauer, R Harshman, JASIS. 41Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., &amp; Harshman, R. (1990). Indexing by latent semantic analysis. JASIS, 41, 391-407.</p>
<p>Learning to infer graphics programs from hand-drawn images. K Ellis, D Ritchie, A Solar-Lezama, J B Tenenbaum, NIPS. Ellis, K., Ritchie, D., Solar-lezama, A., &amp; Tenenbaum, J. B. (2018). Learning to infer graphics programs from hand-drawn images. In NIPS.</p>
<p>Attend, infer, repeat: Fast scene understanding with generative models. S M A Eslami, N Heess, T Weber, Y Tassa, D Szepesvari, K Kavukcuoglu, G E Hinton, NIPS. Eslami, S. M. A., Heess, N., Weber, T., Tassa, Y., Szepesvari, D., Kavukcuoglu, K., &amp; Hinton, G. E. (2016). Attend, infer, repeat: Fast scene understanding with generative models. In NIPS.</p>
<p>Synthesizing programs for images using reinforced adversarial learning. Y Ganin, T Kulkarni, I Babuschkin, S M A Eslami, O Vinyals, ICML. Ganin, Y., Kulkarni, T., Babuschkin, I., Eslami, S. M. A., &amp; Vinyals, O. (2018). Syn- thesizing programs for images using reinforced adversarial learning. In ICML.</p>
<p>A rational analysis of rule-based concept learning. N D Goodman, J B Tenenbaum, J Feldman, T L Griffiths, Cognitive Science. 32Goodman, N. D., Tenenbaum, J. B., Feldman, J., &amp; Griffiths, T. L. (2008). A rational analysis of rule-based concept learning. Cognitive Science, 32, 108-154.</p>
<p>Concepts in a probabilistic language of thought. N D Goodman, J B Tenenbaum, T Gerstenberg, The conceptual mind: New directions in the study of concepts. E. Margolis and S. LaurenceCambridge, MAMIT PressGoodman, N. D., Tenenbaum, J. B., &amp; Gerstenberg, T. (2015). Concepts in a proba- bilistic language of thought. In E. Margolis and S. Laurence (Ed.), The conceptual mind: New directions in the study of concepts (pp. 623-653). Cambridge, MA: MIT Press.</p>
<p>Generating sequences with recurrent neural networks. A Graves, arXiv:1308.0850arXiv preprintGraves, A. (2013). Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850.</p>
<p>DRAW: A recurrent neural network for image generation. K Gregor, I Danihelka, A Graves, D J Rezende, D Wierstra, ICML. Gregor, K., Danihelka, I., Graves, A., Rezende, D. J., &amp; Wierstra, D. (2015). DRAW: A recurrent neural network for image generation. In ICML.</p>
<p>A neural representation of sketch drawings. D Ha, D Eck, ICLR. Ha, D., &amp; Eck, D. (2018). A neural representation of sketch drawings. In ICLR.</p>
<p>The discovery of structural form. C Kemp, J B Tenenbaum, PNASKemp, C., &amp; Tenenbaum, J. B. (2008). The discovery of structural form. PNAS, 105(31), 10687-92.</p>
<p>Structured statistical models of inductive reasoning. C Kemp, J B Tenenbaum, Psychological Review. 116Kemp, C., &amp; Tenenbaum, J. B. (2009). Structured statistical models of inductive rea- soning. Psychological Review, 116, 20-58.</p>
<p>Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. B M Lake, M Baroni, ICML. Lake, B. M., &amp; Baroni, M. (2018). Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. In ICML.</p>
<p>B M Lake, S T Piantadosi, People Infer Recursive Visual Concepts from Just a Few Examples. Lake, B. M., &amp; Piantadosi, S. T. (2019). People Infer Recursive Visual Concepts from Just a Few Examples. Computational Brain &amp; Behavior.</p>
<p>Human-level concept learning through probabilistic program induction. B M Lake, R Salakhutdinov, J B Tenenbaum, Science. 350Lake, B. M., Salakhutdinov, R., &amp; Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350, 1332-1338.</p>
<p>The Omniglot challenge: A 3-year progress report. B M Lake, R Salakhutdinov, J B Tenenbaum, Behavioral Sciences. 29Lake, B. M., Salakhutdinov, R., &amp; Tenenbaum, J. B. (2019). The Omniglot challenge: A 3-year progress report. Behavioral Sciences, 29, 97-104.</p>
<p>Building machines that learn and think like people. B M Lake, T D Ullman, J B Tenenbaum, S J Gershman, Behavioral and Brain Sciences. 40253Lake, B. M., Ullman, T. D., Tenenbaum, J. B., &amp; Gershman, S. J. (2017). Building machines that learn and think like people. Behavioral and Brain Sciences, 40, E253.</p>
<p>Character-based neural machine translation. W Ling, I Trancoso, C Dyer, A Black, ICLR. Ling, W., Trancoso, I., Dyer, C., &amp; Black, A. (2016). Character-based neural machine translation. In ICLR.</p>
<p>The Algebraic Mind: Integrating Connectionism and Cognitive Science. G F Marcus, MIT PressCambridge, MAMarcus, G. F. (2003). The Algebraic Mind: Integrating Connectionism and Cognitive Science. Cambridge, MA: MIT Press.</p>
<p>Emergence in Cognitive Science. J L Mcclelland, Topics in Cognitive Science. 24McClelland, J. L. (2010). Emergence in Cognitive Science. Topics in Cognitive Science, 2(4), 751-770.</p>
<p>The role of theories in conceptual coherence. G L Murphy, D L Medin, Psychological Review. 923Murphy, G. L., &amp; Medin, D. L. (1985). The role of theories in conceptual coherence. Psychological Review, 92(3), 289-316.</p>
<p>The learnability of abstract syntactic principles. A Perfors, J B Tenenbaum, T Regier, Cognition. 1183Perfors, A., Tenenbaum, J. B., &amp; Regier, T. (2011). The learnability of abstract syntactic principles. Cognition, 118(3), 306-338.</p>
<p>The logical primitives of thought: Empirical foundations for compositional cognitive models. S T Piantadosi, J B Tenenbaum, N D Goodman, Psych. Rev. Piantadosi, S. T., Tenenbaum, J. B., &amp; Goodman, N. D. (2016). The logical primitives of thought: Empirical foundations for compositional cognitive models. Psych. Rev..</p>
<p>A hierarchical recurrent encoder-decoder for generative context-aware query suggestion. A Sordoni, Y Bengio, H Vahabi, C Lioma, J G Simonsen, J Y Nie, CIKM. Sordoni, A., Bengio, Y., Vahabi, H., Lioma, C., Simonsen, J. G., &amp; Nie, J. Y. (2015). A hierarchical recurrent encoder-decoder for generative context-aware query sugges- tion. In CIKM.</p>
<p>Learning Structured Generative Concepts. A Stuhlmuller, J B Tenenbaum, N D Goodman, In CogSciStuhlmuller, A., Tenenbaum, J. B., &amp; Goodman, N. D. (2010). Learning Structured Generative Concepts. In CogSci.</p>
<p>How to grow a mind: Statistics, structure, and abstraction. J B Tenenbaum, C Kemp, T L Griffiths, N D Goodman, Science. 3316022Tenenbaum, J. B., Kemp, C., Griffiths, T. L., &amp; Goodman, N. D. (2011). How to grow a mind: Statistics, structure, and abstraction. Science, 331(6022), 1279-1285.</p>
<p>Matching networks for one shot learning. O Vinyals, C Blundell, T Lillicrap, D Wierstra, NIPS. Vinyals, O., Blundell, C., Lillicrap, T., &amp; Wierstra, D. (2016). Matching networks for one shot learning. In NIPS.</p>
<p>Show, attend and tell: Neural image caption generation with visual attention. K Xu, J L Ba, R Kiros, K Cho, A Courville, R Salakhutdinov, . . Bengio, Y , ICML. Xu, K., Ba, J. L., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., . . . Bengio, Y. (2016). Show, attend and tell: Neural image caption generation with visual attention. In ICML.</p>            </div>
        </div>

    </div>
</body>
</html>