<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2143 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2143</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2143</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-56.html">extraction-schema-56</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of circuit simulators used for training machine learning or reinforcement learning models, including details about simulation fidelity, component modeling accuracy, and transfer performance to real circuits or hardware.</div>
                <p><strong>Paper ID:</strong> paper-277104411</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2503.13301v1.pdf" target="_blank">LIMCA: LLM for Automating Analog In-Memory Computing Architecture Design Exploration</a></p>
                <p><strong>Paper Abstract:</strong> Resistive crossbars enabling analog In-Memory Computing (IMC) have emerged as a promising architecture for Deep Neural Network (DNN) acceleration, offering high memory bandwidth and in-situ computation. However, the manual, knowledge-intensive design process and the lack of high-quality circuit netlists have significantly constrained design space exploration and optimization to behavioral system-level tools. In this work, we introduce LIMCA, a novel fine-tune-free Large Language Model (LLM)-driven framework for automating the design and evaluation of IMC crossbar architectures. Unlike traditional approaches, LIMCA employs a No-Human-In-Loop (NHIL) automated pipeline to generate and validate circuit netlists for SPICE simulations, eliminating manual intervention. LIMCA systematically explores the IMC design space by leveraging a structured dataset and LLM-based performance evaluation. Our experimental results on MNIST classification demonstrate that LIMCA successfully generates crossbar designs achieving $\geq$96% accuracy while maintaining a power consumption $\leq$3W, making this the first work in LLM-assisted IMC design space exploration. Compared to existing frameworks, LIMCA provides an automated, scalable, and hardware-aware solution, reducing design exploration time while ensuring user-constrained performance trade-offs.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2143.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2143.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of circuit simulators used for training machine learning or reinforcement learning models, including details about simulation fidelity, component modeling accuracy, and transfer performance to real circuits or hardware.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IMAC-SIM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>IMAC-Sim: A circuit-level simulator for in-memory analog computing architectures</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A circuit-level simulation framework that generates SPICE netlists and obtains SPICE/HSPICE-level power, latency and accuracy metrics for analog IMC crossbar architectures while modeling interconnect parasitics and non-ideal device effects.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Imac-sim:: A circuit-level simulator for in-memory analog computing architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>circuit_type</strong></td>
                            <td>analog IMC crossbar (full analog crossbar arrays with digital component emulation)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_tool</strong></td>
                            <td>IMAC-SIM (front-end) driving HSPICE (back-end)</td>
                        </tr>
                        <tr>
                            <td><strong>component_models</strong></td>
                            <td>Full analog circuit models including memristive device models (supports MRAM, RRAM, PCM, CBRAM), bit‑cell transistor configurations (1T-1R, 2T-1R), technology node transistor models, interconnect parasitic resistance and capacitance, noise and process-variation modeling; generates SPICE netlists for HSPICE.</td>
                        </tr>
                        <tr>
                            <td><strong>parasitics_modeled</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>nonlinearities_modeled</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>tolerances_variations</strong></td>
                            <td>Process variations and noise are modeled (paper states IMAC-SIM facilitates modeling non-ideal effects including process variations and noise); exact Monte Carlo/percent tolerances not specified.</td>
                        </tr>
                        <tr>
                            <td><strong>ml_model_type</strong></td>
                            <td>supervised learning model (MLP for MNIST inference evaluation) and LLMs used for design generation (LLM is not trained inside IMAC-SIM but uses its outputs)</td>
                        </tr>
                        <tr>
                            <td><strong>training_task</strong></td>
                            <td>Evaluate inference accuracy and PAA (power/area/accuracy) of MLPs mapped to IMC crossbars; produce SPICE-level metrics for dataset generation used by LIMCA.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_performance</strong></td>
                            <td>LIMCA-generated IMC designs evaluated via IMAC-SIM/HSPICE achieved ≥96% MNIST classification accuracy while meeting ≤3 W power for selected designs (reported in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_tested</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_details</strong></td>
                            <td>Paper contrasts analytical/system-level simulators (e.g., NeuroSim, MNSIM) with circuit-level tools like IMAC-SIM: analytical tools are much faster but miss circuit-level analog behavior; IMAC-SIM obtains precise HSPICE-derived metrics and explicitly models interconnect parasitics, non-ideal effects, and device technologies.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_requirements_discussed</strong></td>
                            <td>Authors argue SPICE-level circuit simulation with explicit parasitics and non-ideal device effects (process variations, noise) is necessary to capture analog IMC behavior and obtain accurate PAA and accuracy metrics; IMAC-SIM was adopted for its HSPICE-backed precision.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_failure_cases</strong></td>
                            <td>No sim-to-real transfer experiments reported; paper does not report specific transfer failures attributable to missing fidelity features.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>physics_informed_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frequency_range</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>electromagnetic_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>thermal_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2143.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2143.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of circuit simulators used for training machine learning or reinforcement learning models, including details about simulation fidelity, component modeling accuracy, and transfer performance to real circuits or hardware.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HSPICE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HSPICE (Synopsys HSPICE circuit simulator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Industry-standard SPICE-level circuit simulator used as the back-end for IMAC-SIM to obtain accurate analog circuit metrics (power, latency, accuracy) from generated SPICE netlists.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>circuit_type</strong></td>
                            <td>analog IMC crossbar (full analog circuits)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_tool</strong></td>
                            <td>HSPICE</td>
                        </tr>
                        <tr>
                            <td><strong>component_models</strong></td>
                            <td>Technology node transistor BSIM-level models (via foundry models), device models for memristive technologies as included in IMAC-SIM netlists, interconnect parasitics (R,C).</td>
                        </tr>
                        <tr>
                            <td><strong>parasitics_modeled</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>nonlinearities_modeled</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>tolerances_variations</strong></td>
                            <td>Paper indicates process variations and noise can be modeled via SPICE-level simulations; specifics (e.g., Monte Carlo) not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>ml_model_type</strong></td>
                            <td>supervised learning model (MLP inference evaluated via SPICE simulations)</td>
                        </tr>
                        <tr>
                            <td><strong>training_task</strong></td>
                            <td>SPICE-level evaluation of MLP inference mapped to crossbar hardware — used to compute accuracy and PAA metrics for design selection.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_performance</strong></td>
                            <td>Used to generate the precise PAA metrics reported by IMAC-SIM; LIMCA-selected designs reported ≥96% accuracy with ≤3 W average power.</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_tested</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_details</strong></td>
                            <td>Paper uses HSPICE results as ground-truth for fidelity comparisons: analytical simulators approximate metrics but deviate (e.g., MNSIM ~5% deviation in power/energy/latency vs SPICE); hence HSPICE-level simulations are positioned as higher-fidelity reference.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_requirements_discussed</strong></td>
                            <td>HSPICE-level (SPICE) simulations including parasitics and non-ideal effects are presented as the minimal fidelity needed to capture analog IMC behavior reliably.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_failure_cases</strong></td>
                            <td>No real-hardware transfer experiments reported; no explicit sim-to-real failure cases discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>physics_informed_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frequency_range</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>electromagnetic_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>thermal_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2143.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2143.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of circuit simulators used for training machine learning or reinforcement learning models, including details about simulation fidelity, component modeling accuracy, and transfer performance to real circuits or hardware.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CCSS/CCCS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Customized spice-level crossbar-array circuit simulator (CCCS / CCSS)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A customized SPICE-level crossbar array simulator referenced/used by authors for manual design iterations; used as a circuit-level accelerator to obtain inference accuracy and PAA metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cccs: Customized spice-level crossbar-array circuit simulator for in-memory computing.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>circuit_type</strong></td>
                            <td>analog IMC crossbar</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_tool</strong></td>
                            <td>Customized SPICE-level simulator (referred to as CCSS/CCCS) driving MATLAB/SPICE in manual experiments</td>
                        </tr>
                        <tr>
                            <td><strong>component_models</strong></td>
                            <td>SPICE-level models appropriate for crossbar arrays; used in manual Matlab-SPICE workflow—details not deeply enumerated in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>parasitics_modeled</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>nonlinearities_modeled</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tolerances_variations</strong></td>
                            <td>Not specified; paper reports manual iteration and debugging overhead when using CCSS/CCCS for circuit optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>ml_model_type</strong></td>
                            <td>supervised learning model (MLP inference evaluation used as the goal of manual optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>training_task</strong></td>
                            <td>Manual optimization/verification of IMC crossbar designs and evaluation of inference accuracy and PAA via SPICE-level runs.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_performance</strong></td>
                            <td>Manual optimization using CCSS reported iteration times of 140–398 minutes for full optimization runs (paper reports time cost; accuracy results referenced via IMAC-SIM comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_tested</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_requirements_discussed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>physics_informed_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frequency_range</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>electromagnetic_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>thermal_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2143.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2143.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of circuit simulators used for training machine learning or reinforcement learning models, including details about simulation fidelity, component modeling accuracy, and transfer performance to real circuits or hardware.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NeuroSim</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NeuroSim: A circuit-level macro model for benchmarking neuro-inspired architectures in online learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An analytical/system-level simulator for IMC that integrates with ML simulators to assess learning and classification accuracy across emerging memory technologies, but lacks accurate circuit-level predictive analog behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neurosim: A circuit-level macro model for benchmarking neuro-inspired architectures in online learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>circuit_type</strong></td>
                            <td>architectural/behavioral IMC crossbar model (analytical/system-level)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_tool</strong></td>
                            <td>NeuroSim (analytical/system-level simulator)</td>
                        </tr>
                        <tr>
                            <td><strong>component_models</strong></td>
                            <td>Behavioral/analytical models for array-level metrics; does not provide detailed circuit-level analog models or SPICE-level parasitics.</td>
                        </tr>
                        <tr>
                            <td><strong>parasitics_modeled</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>nonlinearities_modeled</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>tolerances_variations</strong></td>
                            <td>Not detailed in paper; analytical tools typically omit detailed process variation modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>ml_model_type</strong></td>
                            <td>supervised learning (DNN training/inference can be evaluated in conjunction with NeuroSim)</td>
                        </tr>
                        <tr>
                            <td><strong>training_task</strong></td>
                            <td>Assess learning and classification accuracy at architecture/behavioral level (paper notes NeuroSim integrates with ML simulators for accuracy assessment).</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_performance</strong></td>
                            <td>Analytical estimates are fast but less accurate; no precise numeric accuracy vs hardware provided in paper (NeuroSim lacks circuit-level predictive power according to authors).</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_tested</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_details</strong></td>
                            <td>Paper contrasts NeuroSim (behavioral) with circuit-level tools: NeuroSim integrates with ML simulators but lacks accurate circuit-level predictive models; recommended to use SPICE-level tools for analog fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_requirements_discussed</strong></td>
                            <td>Paper implies NeuroSim alone is insufficient to capture analog non-idealities for transfer; SPICE-level parasitic and device modeling required for precise evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>physics_informed_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frequency_range</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>electromagnetic_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>thermal_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2143.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2143.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of circuit simulators used for training machine learning or reinforcement learning models, including details about simulation fidelity, component modeling accuracy, and transfer performance to real circuits or hardware.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MNSIM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MNSIM: Simulation platform for memristor-based neuromorphic computing system (and MNSIM 2.0)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A behavioral/system-level IMC simulator; the paper notes MNSIM reports approximately 5% deviation in power/energy/latency estimates compared to SPICE for a two-layer fully connected network but does not explicitly report classification accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mnsim: Simulation platform for memristor-based neuromorphic computing system.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>circuit_type</strong></td>
                            <td>behavioral/system-level IMC crossbar model</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_tool</strong></td>
                            <td>MNSIM (analytical/system-level simulator)</td>
                        </tr>
                        <tr>
                            <td><strong>component_models</strong></td>
                            <td>Behavioral/analytical models for power/energy/latency; fewer circuit-level details and limited parasitic modeling compared to SPICE.</td>
                        </tr>
                        <tr>
                            <td><strong>parasitics_modeled</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>nonlinearities_modeled</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>tolerances_variations</strong></td>
                            <td>Not specified; reported approximate deviation vs SPICE but no Monte Carlo/process-corner detail in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ml_model_type</strong></td>
                            <td>supervised DNN evaluation (used for architectural-level studies)</td>
                        </tr>
                        <tr>
                            <td><strong>training_task</strong></td>
                            <td>Architectural-level estimation of power/energy/latency for memristor-based networks; not focused on SPICE-accurate analog behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_performance</strong></td>
                            <td>Paper cites MNSIM ~5% deviation in power/energy/latency vs SPICE for a two-layer FC network; accuracy metrics not reported by MNSIM according to authors.</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_tested</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_details</strong></td>
                            <td>Paper positions MNSIM as faster but less precise relative to SPICE; highlights its ~5% deviation in some metrics and lack of explicit accuracy reporting.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_requirements_discussed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>physics_informed_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frequency_range</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>electromagnetic_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>thermal_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2143.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2143.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of circuit simulators used for training machine learning or reinforcement learning models, including details about simulation fidelity, component modeling accuracy, and transfer performance to real circuits or hardware.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AIHWKIT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Analog Hardware Acceleration Kit (AIHWKIT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source PyTorch-based toolkit that simulates analog crossbar arrays for AI applications, providing a user-friendly interface for training and inference on analog crossbar models at architecture/algorithmic level.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A flexible and fast pytorch toolkit for simulating training and inference on analog crossbar arrays.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>circuit_type</strong></td>
                            <td>analog crossbar (architecture-level simulation integrated with PyTorch)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_tool</strong></td>
                            <td>AIHWKIT (PyTorch toolkit)</td>
                        </tr>
                        <tr>
                            <td><strong>component_models</strong></td>
                            <td>High-level analog crossbar behavioral models suitable for training and inference in PyTorch; not SPICE-level device/interconnect detail.</td>
                        </tr>
                        <tr>
                            <td><strong>parasitics_modeled</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>nonlinearities_modeled</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tolerances_variations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ml_model_type</strong></td>
                            <td>supervised learning (training/inference of DNNs in PyTorch with analog crossbar models)</td>
                        </tr>
                        <tr>
                            <td><strong>training_task</strong></td>
                            <td>Train and evaluate neural networks using analog crossbar behavioral models (algorithmic training/inference experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_tested</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_details</strong></td>
                            <td>Paper notes AIHWKIT exists as an architectural-level simulator and does not provide SPICE-level circuit fidelity; implies it is faster but less detailed than IMAC-SIM/HSPICE.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_requirements_discussed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>physics_informed_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frequency_range</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>electromagnetic_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>thermal_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2143.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2143.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of circuit simulators used for training machine learning or reinforcement learning models, including details about simulation fidelity, component modeling accuracy, and transfer performance to real circuits or hardware.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DPE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dot-Product Engine for Neuromorphic Computing (DPE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A circuit-level work that programs 1T1M crossbars to accelerate matrix-vector multiplication; cited as part of circuit-level IMC simulators and hardware demonstrations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dot-product engine for neuromorphic computing: Programming 1t1m crossbar to accelerate matrix-vector multiplication.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>circuit_type</strong></td>
                            <td>analog IMC crossbar (1T1M crossbar arrays for dot-product operations)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_tool</strong></td>
                            <td>DPE design and evaluations (cited as circuit-level work; simulation tool specifics not detailed in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>component_models</strong></td>
                            <td>Circuit-level models for 1T1M crossbars (paper reference); exact modeling level in cited work not enumerated here.</td>
                        </tr>
                        <tr>
                            <td><strong>parasitics_modeled</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>nonlinearities_modeled</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tolerances_variations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ml_model_type</strong></td>
                            <td>used to accelerate matrix-vector multiply for neural networks (inference workloads)</td>
                        </tr>
                        <tr>
                            <td><strong>training_task</strong></td>
                            <td>Hardware acceleration of MVMs for neural network inference/training (contextual reference; not used in LIMCA experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_tested</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_requirements_discussed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>physics_informed_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frequency_range</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>electromagnetic_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>thermal_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Imac-sim:: A circuit-level simulator for in-memory analog computing architectures. <em>(Rating: 2)</em></li>
                <li>Cccs: Customized spice-level crossbar-array circuit simulator for in-memory computing. <em>(Rating: 2)</em></li>
                <li>Neurosim: A circuit-level macro model for benchmarking neuro-inspired architectures in online learning. <em>(Rating: 2)</em></li>
                <li>Mnsim: Simulation platform for memristor-based neuromorphic computing system. <em>(Rating: 2)</em></li>
                <li>A flexible and fast pytorch toolkit for simulating training and inference on analog crossbar arrays. <em>(Rating: 1)</em></li>
                <li>Dot-product engine for neuromorphic computing: Programming 1t1m crossbar to accelerate matrix-vector multiplication. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2143",
    "paper_id": "paper-277104411",
    "extraction_schema_id": "extraction-schema-56",
    "extracted_data": [
        {
            "name_short": "IMAC-SIM",
            "name_full": "IMAC-Sim: A circuit-level simulator for in-memory analog computing architectures",
            "brief_description": "A circuit-level simulation framework that generates SPICE netlists and obtains SPICE/HSPICE-level power, latency and accuracy metrics for analog IMC crossbar architectures while modeling interconnect parasitics and non-ideal device effects.",
            "citation_title": "Imac-sim:: A circuit-level simulator for in-memory analog computing architectures.",
            "mention_or_use": "use",
            "circuit_type": "analog IMC crossbar (full analog crossbar arrays with digital component emulation)",
            "simulator_tool": "IMAC-SIM (front-end) driving HSPICE (back-end)",
            "component_models": "Full analog circuit models including memristive device models (supports MRAM, RRAM, PCM, CBRAM), bit‑cell transistor configurations (1T-1R, 2T-1R), technology node transistor models, interconnect parasitic resistance and capacitance, noise and process-variation modeling; generates SPICE netlists for HSPICE.",
            "parasitics_modeled": true,
            "nonlinearities_modeled": true,
            "tolerances_variations": "Process variations and noise are modeled (paper states IMAC-SIM facilitates modeling non-ideal effects including process variations and noise); exact Monte Carlo/percent tolerances not specified.",
            "ml_model_type": "supervised learning model (MLP for MNIST inference evaluation) and LLMs used for design generation (LLM is not trained inside IMAC-SIM but uses its outputs)",
            "training_task": "Evaluate inference accuracy and PAA (power/area/accuracy) of MLPs mapped to IMC crossbars; produce SPICE-level metrics for dataset generation used by LIMCA.",
            "simulation_performance": "LIMCA-generated IMC designs evaluated via IMAC-SIM/HSPICE achieved ≥96% MNIST classification accuracy while meeting ≤3 W power for selected designs (reported in paper).",
            "real_hardware_tested": false,
            "real_hardware_performance": null,
            "fidelity_comparison": true,
            "fidelity_comparison_details": "Paper contrasts analytical/system-level simulators (e.g., NeuroSim, MNSIM) with circuit-level tools like IMAC-SIM: analytical tools are much faster but miss circuit-level analog behavior; IMAC-SIM obtains precise HSPICE-derived metrics and explicitly models interconnect parasitics, non-ideal effects, and device technologies.",
            "minimal_requirements_discussed": "Authors argue SPICE-level circuit simulation with explicit parasitics and non-ideal device effects (process variations, noise) is necessary to capture analog IMC behavior and obtain accurate PAA and accuracy metrics; IMAC-SIM was adopted for its HSPICE-backed precision.",
            "transfer_failure_cases": "No sim-to-real transfer experiments reported; paper does not report specific transfer failures attributable to missing fidelity features.",
            "domain_randomization_used": null,
            "physics_informed_approach": null,
            "frequency_range": null,
            "electromagnetic_effects": null,
            "thermal_effects": null,
            "uuid": "e2143.0"
        },
        {
            "name_short": "HSPICE",
            "name_full": "HSPICE (Synopsys HSPICE circuit simulator)",
            "brief_description": "Industry-standard SPICE-level circuit simulator used as the back-end for IMAC-SIM to obtain accurate analog circuit metrics (power, latency, accuracy) from generated SPICE netlists.",
            "citation_title": "",
            "mention_or_use": "use",
            "circuit_type": "analog IMC crossbar (full analog circuits)",
            "simulator_tool": "HSPICE",
            "component_models": "Technology node transistor BSIM-level models (via foundry models), device models for memristive technologies as included in IMAC-SIM netlists, interconnect parasitics (R,C).",
            "parasitics_modeled": true,
            "nonlinearities_modeled": true,
            "tolerances_variations": "Paper indicates process variations and noise can be modeled via SPICE-level simulations; specifics (e.g., Monte Carlo) not provided.",
            "ml_model_type": "supervised learning model (MLP inference evaluated via SPICE simulations)",
            "training_task": "SPICE-level evaluation of MLP inference mapped to crossbar hardware — used to compute accuracy and PAA metrics for design selection.",
            "simulation_performance": "Used to generate the precise PAA metrics reported by IMAC-SIM; LIMCA-selected designs reported ≥96% accuracy with ≤3 W average power.",
            "real_hardware_tested": false,
            "real_hardware_performance": null,
            "fidelity_comparison": true,
            "fidelity_comparison_details": "Paper uses HSPICE results as ground-truth for fidelity comparisons: analytical simulators approximate metrics but deviate (e.g., MNSIM ~5% deviation in power/energy/latency vs SPICE); hence HSPICE-level simulations are positioned as higher-fidelity reference.",
            "minimal_requirements_discussed": "HSPICE-level (SPICE) simulations including parasitics and non-ideal effects are presented as the minimal fidelity needed to capture analog IMC behavior reliably.",
            "transfer_failure_cases": "No real-hardware transfer experiments reported; no explicit sim-to-real failure cases discussed.",
            "domain_randomization_used": null,
            "physics_informed_approach": null,
            "frequency_range": null,
            "electromagnetic_effects": null,
            "thermal_effects": null,
            "uuid": "e2143.1"
        },
        {
            "name_short": "CCSS/CCCS",
            "name_full": "Customized spice-level crossbar-array circuit simulator (CCCS / CCSS)",
            "brief_description": "A customized SPICE-level crossbar array simulator referenced/used by authors for manual design iterations; used as a circuit-level accelerator to obtain inference accuracy and PAA metrics.",
            "citation_title": "Cccs: Customized spice-level crossbar-array circuit simulator for in-memory computing.",
            "mention_or_use": "use",
            "circuit_type": "analog IMC crossbar",
            "simulator_tool": "Customized SPICE-level simulator (referred to as CCSS/CCCS) driving MATLAB/SPICE in manual experiments",
            "component_models": "SPICE-level models appropriate for crossbar arrays; used in manual Matlab-SPICE workflow—details not deeply enumerated in paper.",
            "parasitics_modeled": null,
            "nonlinearities_modeled": null,
            "tolerances_variations": "Not specified; paper reports manual iteration and debugging overhead when using CCSS/CCCS for circuit optimization.",
            "ml_model_type": "supervised learning model (MLP inference evaluation used as the goal of manual optimization)",
            "training_task": "Manual optimization/verification of IMC crossbar designs and evaluation of inference accuracy and PAA via SPICE-level runs.",
            "simulation_performance": "Manual optimization using CCSS reported iteration times of 140–398 minutes for full optimization runs (paper reports time cost; accuracy results referenced via IMAC-SIM comparisons).",
            "real_hardware_tested": false,
            "real_hardware_performance": null,
            "fidelity_comparison": null,
            "fidelity_comparison_details": null,
            "minimal_requirements_discussed": null,
            "transfer_failure_cases": null,
            "domain_randomization_used": null,
            "physics_informed_approach": null,
            "frequency_range": null,
            "electromagnetic_effects": null,
            "thermal_effects": null,
            "uuid": "e2143.2"
        },
        {
            "name_short": "NeuroSim",
            "name_full": "NeuroSim: A circuit-level macro model for benchmarking neuro-inspired architectures in online learning",
            "brief_description": "An analytical/system-level simulator for IMC that integrates with ML simulators to assess learning and classification accuracy across emerging memory technologies, but lacks accurate circuit-level predictive analog behavior.",
            "citation_title": "Neurosim: A circuit-level macro model for benchmarking neuro-inspired architectures in online learning.",
            "mention_or_use": "mention",
            "circuit_type": "architectural/behavioral IMC crossbar model (analytical/system-level)",
            "simulator_tool": "NeuroSim (analytical/system-level simulator)",
            "component_models": "Behavioral/analytical models for array-level metrics; does not provide detailed circuit-level analog models or SPICE-level parasitics.",
            "parasitics_modeled": false,
            "nonlinearities_modeled": false,
            "tolerances_variations": "Not detailed in paper; analytical tools typically omit detailed process variation modeling.",
            "ml_model_type": "supervised learning (DNN training/inference can be evaluated in conjunction with NeuroSim)",
            "training_task": "Assess learning and classification accuracy at architecture/behavioral level (paper notes NeuroSim integrates with ML simulators for accuracy assessment).",
            "simulation_performance": "Analytical estimates are fast but less accurate; no precise numeric accuracy vs hardware provided in paper (NeuroSim lacks circuit-level predictive power according to authors).",
            "real_hardware_tested": false,
            "real_hardware_performance": null,
            "fidelity_comparison": true,
            "fidelity_comparison_details": "Paper contrasts NeuroSim (behavioral) with circuit-level tools: NeuroSim integrates with ML simulators but lacks accurate circuit-level predictive models; recommended to use SPICE-level tools for analog fidelity.",
            "minimal_requirements_discussed": "Paper implies NeuroSim alone is insufficient to capture analog non-idealities for transfer; SPICE-level parasitic and device modeling required for precise evaluation.",
            "transfer_failure_cases": null,
            "domain_randomization_used": null,
            "physics_informed_approach": null,
            "frequency_range": null,
            "electromagnetic_effects": null,
            "thermal_effects": null,
            "uuid": "e2143.3"
        },
        {
            "name_short": "MNSIM",
            "name_full": "MNSIM: Simulation platform for memristor-based neuromorphic computing system (and MNSIM 2.0)",
            "brief_description": "A behavioral/system-level IMC simulator; the paper notes MNSIM reports approximately 5% deviation in power/energy/latency estimates compared to SPICE for a two-layer fully connected network but does not explicitly report classification accuracy.",
            "citation_title": "Mnsim: Simulation platform for memristor-based neuromorphic computing system.",
            "mention_or_use": "mention",
            "circuit_type": "behavioral/system-level IMC crossbar model",
            "simulator_tool": "MNSIM (analytical/system-level simulator)",
            "component_models": "Behavioral/analytical models for power/energy/latency; fewer circuit-level details and limited parasitic modeling compared to SPICE.",
            "parasitics_modeled": false,
            "nonlinearities_modeled": false,
            "tolerances_variations": "Not specified; reported approximate deviation vs SPICE but no Monte Carlo/process-corner detail in paper.",
            "ml_model_type": "supervised DNN evaluation (used for architectural-level studies)",
            "training_task": "Architectural-level estimation of power/energy/latency for memristor-based networks; not focused on SPICE-accurate analog behavior.",
            "simulation_performance": "Paper cites MNSIM ~5% deviation in power/energy/latency vs SPICE for a two-layer FC network; accuracy metrics not reported by MNSIM according to authors.",
            "real_hardware_tested": false,
            "real_hardware_performance": null,
            "fidelity_comparison": true,
            "fidelity_comparison_details": "Paper positions MNSIM as faster but less precise relative to SPICE; highlights its ~5% deviation in some metrics and lack of explicit accuracy reporting.",
            "minimal_requirements_discussed": null,
            "transfer_failure_cases": null,
            "domain_randomization_used": null,
            "physics_informed_approach": null,
            "frequency_range": null,
            "electromagnetic_effects": null,
            "thermal_effects": null,
            "uuid": "e2143.4"
        },
        {
            "name_short": "AIHWKIT",
            "name_full": "Analog Hardware Acceleration Kit (AIHWKIT)",
            "brief_description": "An open-source PyTorch-based toolkit that simulates analog crossbar arrays for AI applications, providing a user-friendly interface for training and inference on analog crossbar models at architecture/algorithmic level.",
            "citation_title": "A flexible and fast pytorch toolkit for simulating training and inference on analog crossbar arrays.",
            "mention_or_use": "mention",
            "circuit_type": "analog crossbar (architecture-level simulation integrated with PyTorch)",
            "simulator_tool": "AIHWKIT (PyTorch toolkit)",
            "component_models": "High-level analog crossbar behavioral models suitable for training and inference in PyTorch; not SPICE-level device/interconnect detail.",
            "parasitics_modeled": false,
            "nonlinearities_modeled": null,
            "tolerances_variations": null,
            "ml_model_type": "supervised learning (training/inference of DNNs in PyTorch with analog crossbar models)",
            "training_task": "Train and evaluate neural networks using analog crossbar behavioral models (algorithmic training/inference experiments).",
            "simulation_performance": null,
            "real_hardware_tested": false,
            "real_hardware_performance": null,
            "fidelity_comparison": null,
            "fidelity_comparison_details": "Paper notes AIHWKIT exists as an architectural-level simulator and does not provide SPICE-level circuit fidelity; implies it is faster but less detailed than IMAC-SIM/HSPICE.",
            "minimal_requirements_discussed": null,
            "transfer_failure_cases": null,
            "domain_randomization_used": null,
            "physics_informed_approach": null,
            "frequency_range": null,
            "electromagnetic_effects": null,
            "thermal_effects": null,
            "uuid": "e2143.5"
        },
        {
            "name_short": "DPE",
            "name_full": "Dot-Product Engine for Neuromorphic Computing (DPE)",
            "brief_description": "A circuit-level work that programs 1T1M crossbars to accelerate matrix-vector multiplication; cited as part of circuit-level IMC simulators and hardware demonstrations.",
            "citation_title": "Dot-product engine for neuromorphic computing: Programming 1t1m crossbar to accelerate matrix-vector multiplication.",
            "mention_or_use": "mention",
            "circuit_type": "analog IMC crossbar (1T1M crossbar arrays for dot-product operations)",
            "simulator_tool": "DPE design and evaluations (cited as circuit-level work; simulation tool specifics not detailed in this paper)",
            "component_models": "Circuit-level models for 1T1M crossbars (paper reference); exact modeling level in cited work not enumerated here.",
            "parasitics_modeled": null,
            "nonlinearities_modeled": null,
            "tolerances_variations": null,
            "ml_model_type": "used to accelerate matrix-vector multiply for neural networks (inference workloads)",
            "training_task": "Hardware acceleration of MVMs for neural network inference/training (contextual reference; not used in LIMCA experiments).",
            "simulation_performance": null,
            "real_hardware_tested": null,
            "real_hardware_performance": null,
            "fidelity_comparison": null,
            "fidelity_comparison_details": null,
            "minimal_requirements_discussed": null,
            "transfer_failure_cases": null,
            "domain_randomization_used": null,
            "physics_informed_approach": null,
            "frequency_range": null,
            "electromagnetic_effects": null,
            "thermal_effects": null,
            "uuid": "e2143.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Imac-sim:: A circuit-level simulator for in-memory analog computing architectures.",
            "rating": 2
        },
        {
            "paper_title": "Cccs: Customized spice-level crossbar-array circuit simulator for in-memory computing.",
            "rating": 2
        },
        {
            "paper_title": "Neurosim: A circuit-level macro model for benchmarking neuro-inspired architectures in online learning.",
            "rating": 2
        },
        {
            "paper_title": "Mnsim: Simulation platform for memristor-based neuromorphic computing system.",
            "rating": 2
        },
        {
            "paper_title": "A flexible and fast pytorch toolkit for simulating training and inference on analog crossbar arrays.",
            "rating": 1
        },
        {
            "paper_title": "Dot-product engine for neuromorphic computing: Programming 1t1m crossbar to accelerate matrix-vector multiplication.",
            "rating": 1
        }
    ],
    "cost": 0.015698499999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LIMCA: LLM for Automating Analog In-Memory Computing Architecture Design Exploration
17 Mar 2025</p>
<p>Deepak Vungarala 
New Jersey Institute of Technology
NewarkNJUSA</p>
<p>MdHasibul Amin 
University of South Carolina
ColumbiaSCUSA</p>
<p>Pietro Mercati 
Intel Labs
HillsboroORUSA</p>
<p>Arnob Ghosh 
New Jersey Institute of Technology
NewarkNJUSA</p>
<p>Arman Roohi 
University of Illinois Chicago
ChicagoILUSA</p>
<p>Ramtin Zand 
University of South Carolina
ColumbiaSCUSA</p>
<p>Shaahin Angizi shaahin.angizi@njit.edu 
New Jersey Institute of Technology
NewarkNJUSA</p>
<p>LIMCA: LLM for Automating Analog In-Memory Computing Architecture Design Exploration
17 Mar 2025F669D27C9AE49AA3701AFE1FC1F309D6arXiv:2503.13301v1[cs.AR]
Resistive crossbars enabling analog In-Memory Computing (IMC) have emerged as a promising architecture for Deep Neural Network (DNN) acceleration, offering high memory bandwidth and in-situ computation.However, the manual, knowledge-intensive design process and the lack of highquality circuit netlists have significantly constrained design space exploration and optimization to behavioral system-level tools.In this work, we introduce LIMCA, a novel fine-tune-free Large Language Model (LLM)-driven framework for automating the design and evaluation of IMC crossbar architectures.Unlike traditional approaches, LIMCA employs a No-Human-In-Loop (NHIL) automated pipeline to generate and validate circuit netlists for SPICE simulations, eliminating manual intervention.LIMCA systematically explores the IMC design space by leveraging a structured dataset and LLM-based performance evaluation.Our experimental results on MNIST classification demonstrate that LIMCA successfully generates crossbar designs achieving ≥96% accuracy while maintaining a power consumption ≤3W, making this the first work in LLM-assisted IMC design space exploration.Compared to existing frameworks, LIMCA provides an automated, scalable, and hardware-aware solution, reducing design exploration time while ensuring user-constrained performance trade-offs.</p>
<p>I. INTRODUCTION</p>
<p>The increasing complexity and computational demands of Deep Neural Networks (DNNs) have highlighted the limitations of traditional von Neumann architectures, particularly the memory wall bottlenecks in data movement between processing and memory units [1], [2].To address this, Analog In-Memory Computing (IMC) crossbar architectures have emerged as a promising solution, offering the ability to perform computations directly within memory arrays, thereby significantly reducing data movement and energy consumption [3], [4], [5].These architectures leverage the physical properties of resistive devices to store DNN weight parameters and perform matrix operations in the analog domain, enabling massive parallelization of DNN computations [6].However, designing efficient analog IMC systems presents unique challenges.The process requires deep expertise in analog circuit design, an understanding of device physics, and careful consideration of various non-idealities such as parasitic effects, device variations, and noise [3], [7].</p>
<p>Traditional analog IMC design approaches [4], [8], [9], [10], [11], [12], [13] heavily rely on manual optimization and iterative refinement, making it difficult to efficiently explore the vast design space of possible implementations as shown in Table I.Furthermore, the lack of standardized How can we deploy LLMs without cost-intensive fine-tuning?and can we effectively perform and evaluate design space exploration?(RQ-3) Despite automating hardware generation via LLMs, the validation scheme requires human intervention.Can this be fully automated?To answer these questions, this work presents the following contributions.</p>
<p>• A Design Space Exploration framework, dubbed LIMCA with Automatic Design Generation that leverages LLMs to map domain knowledge and introduces a fine-tuningfree approach for generating user-constrained designs from the space and generating the design of their choice.• LIMCA implements an automated validation strategy, eliminating human intervention, a No-Human-In-Loop (NHIL) approach ensuring efficient and scalable design evaluation.</p>
<p>• An extensive open-source IMC dataset containing detailed variations of designs, along with PAA metrics for both analog and general IMC architectures, which can be used to fine-tune any model.</p>
<p>II. BACKGROUND, CHALLENGES, AND MOTIVATIONS</p>
<p>A. LLM for Hardware Design</p>
<p>LLMs show promise in generating Hardware Description Language (HDL) and High-Level Synthesis (HLS) code.Veri-Gen [17] and ChatEDA [21] refine hardware design workflows, automating the RTL to GDSII process with fine-tuned LLMs.AssertLLM incorporates three customized LLM and finally generates multiple system Verilog assertions, each performing different functionalities [22].UVLLM [23] integrates LLMs with the Universal Verification Methodology to automate the testing and repair of RTL designs, significantly boosting error fix rates and speeding up hardware verification.ChipGPT [15] and Autochip [24] integrate LLMs to generate and optimize hardware designs, with Autochip producing precise Verilog code through simulation feedback.SA-DS [19] generated an HLS dataset for DNN architectures and deployed using In-Context Learning (ICL) leveraging prompt engineering.MG-Verilog [25] created a hardware dataset with over 11,000 verilog code.Chip-Chat [26] demonstrates interactive LLMs like ChatGPT-4 in accelerating design space exploration.MEV-LLM [27] proposes multi-expert LLM architecture for Verilog code generation.DeepCircuitX [28] introduces a multi-level repository dataset enriched with Chainof-Thought annotations and synthesized circuit data to advance RTL code understanding, generation, and early PPA prediction in hardware design automation.RTLLM [29] and GPT4AIGChip [18] enhance design efficiency, showcasing LLMs' ability to manage complex design tasks and broaden access to AI accelerator design.In VerilogReader [30], the LLM accurately grasps the code logic and generates stimuli to reach the unexplored code branches.To the best of our knowledge, GPT4AIGChip [18], TPU-Gen [31], and SA-DS [19] are the only frameworks specifically aimed at the generation of domain-specific AI accelerator designs, while GPT4AIGChip works with HLS, TPU-Gen deals with Verilog Negative Array
G11+ G12+ G1j+ G21+ G22+ G2j+ Gi1+ Gi2+ Gij+ G11-G12-G1j- G21-G22-G2j- Gi1-Gi2- Gij-
Positive Array i X j Crossbar generation of the custom Tensor Processing Unit (TPU).</p>
<p>LLMCompass can describe and evaluate different hardware designs [32].However, the absence of prompt optimization, tailored datasets, model fine-tuning, and LLM hallucination pose a barrier to fully harnessing the potential of LLMs in such frameworks [21], [19].This limitation confines their application to standard LLMs without fine-tuning, or ICL [21], which are among the most promising methods for optimizing LLMs [33].AnalogCoder [34], SPICEPilot [16], and Masala-CHAI [35] to our knowledge, are among the first Analog circuit generators and generated the circuit through prompt engineering ICL.Other works such as [35] focus on creating a comprehensive detailed dataset from the existing knowledge base such as textbooks, open-sourced platforms for analog circuits, AmpAgent [36] is designed for multi-stage amplifier schematic design and process and performance porting.</p>
<p>B. Analog IMC Crossbar and Simulation Frameworks</p>
<p>The resistive crossbar array, illustrated in Fig. 2, serves as a fundamental computational unit in IMC-based DNN accelerators due to its ability to efficiently execute matrixvector multiplications.This architecture enables highly parallel Multiply-and-ACcumulate (MAC) operations by encoding the DNN weights as the conductance of resistive storage elements while feeding the activations as input voltages to the crossbar.As depicted, the n-bit binary bit-strings in i [n] are initially transformed into voltage levels V i via Digital-to-Analog Converters (DACs).The design employs separate arrays for storing positive and negative weights, where the reference voltage V ref is set to V DD /2.Consequently, the MAC operation results in a differential current directed toward the Analog-to-Digital Converter (ADC) in the j-th column pair.Here, G ± i,j represents the conductance of the resistive memory cells in the positive and negative arrays [37], [38].</p>
<p>The current IMC simulation frameworks fall into two primary categories as listed in Table I. (i) Analytical systemlevel simulators, such as NeuroSim [4], DNN+NeuroSim V2.0 [39], MNSIM [8], and MNSIM 2.0 [6] rely on behavioral models and analytical architectural computations to estimate area, power, and latency of IMC designs.MNSIM [8] indicates an approximate 5% deviation in power, energy, and latency estimates compared to SPICE circuit simulations for a twolayer fully connected neural network.However, it does not explicitly report accuracy metrics.On the other hand, Neu-roSim [4] integrates with machine learning simulators to assess learning and classification accuracy supporting a variety of emerging memory technologies but lacks an accurate circuitlevel predictive model for capturing the analog behavior of IMC arrays.Additionally, IBM's Analog Hardware Acceleration Kit (AIHWKIT) [12], an open-source toolkit with a user-friendly PYTORCH interface, simulates analog crossbar arrays for AI applications.While architecture-level tools offer significantly faster simulations, they do not provide an accurate model for the analog behavior of IMC crossbars and often overlook crucial design details.Conversely, (ii) circuit-level simulators, employ detailed circuit analysis techniques to evaluate the functionality and performance of IMC circuits such as DPE [11], CCCS [9], and IMAC-Sim [10].Such frameworks provide more accurate results at the expense of increased computational time.DPE [11] focuses on developing an optimized strategy for mapping pre-trained weights onto memristive crossbars while accounting for non-ideal effects.IMAC-Sim [10] is a sophisticated circuit-level simulation framework providing both full analog circuits with the ability to emulate the digital component designed to facilitate the exploration and optimization of IMC architectures.It provides a Python-based environment that automates the generation of SPICE netlists, enabling users to analyze circuit behavior with respect to various hyperparameters.By incorporating the effects of interconnect parasitic resistance and capacitance and implementing horizontal and vertical partitioning techniques, IMAC-Sim captures power, latency, and accuracy metrics directly from HSPICE, ensuring a precise evaluation of circuit performance.The framework supports a diverse range of memristive device technologies and bitcell configurations, allowing designers to fine-tune parameters such as resistance states, interconnect dimensions, and transistor technologies.IMAC-Sim also facilitates the modeling of non-ideal effects, including process variations and noise, which are crucial for ensuring robustness in large-scale IMAC deployments.It offers automated workload mapping and SPICE-level evaluations for deep neural network inference, enabling an accurate representation of real-world IMAC implementations.</p>
<p>Given the vast search space of analog only, digital circuit inclusion of the IMC crossbars-spanning various device parameters (e.g., non-volatile memory type, Ron-to-Roff ratio), circuit characteristics (e.g., technology node, bit-cell size, variations), architectural considerations (e.g., partitioning, interconnects), and neural network specifications (e.g., topology)-design space exploration is a time-consuming and tedious process.This challenge is further exacerbated when specific PAA conditions must be met.While static simulations fall short in addressing this complexity, we believe that our proposed framework, leveraging LLMs with an enhanced and well-developed dataset, enables efficient design space exploration to identify optimal solutions.</p>
<p>Input</p>
<p>User prompt User prompt</p>
<p>Generate an IMC with 16x16 crossbar under 3 W and best accuracy for the ...</p>
<p>User prompt</p>
<p>Generate an IMC with 16x16 crossbar under 3 W and best accuracy for the ...</p>
<p>IMC-Dataset
Design Space Exploration</p>
<p>C. Challenges in Automated SPICE Generation for IMC</p>
<p>Despite recent advancements in SPICE code generation [16], [34], [35], our observations have identified several critical errors and challenges while studying the IMC circuit topologies.First, the complexity of SPICE code generation results in an extensive number of lines, even for the smallest layer.Since most of these lines are repetitive, the core functionality is not efficiently captured, making generating an IMC with parasitic elements challenging.It is particularly noteworthy that even modestly sized networks (e.g., a minimal layer of 84 × 10) require approximately 4,000 lines of SPICE code, which is significantly constrained by output token limitations.</p>
<p>Second, with the existing output token limitation, a major bottleneck arises in effectively embedding domain knowledge and iteratively refining LLM to meet constrained PAA targets.These limitations severely hinder the scalability and practical deployment of automated SPICE generation techniques for complex analog IMC designs, necessitating novel approaches to overcome these constraints.To mitigate these challenges, we adopt the approach proposed in [10], which offers flexibility by leveraging Python toolboxes and supporting variations in hardware implementation.</p>
<p>III. LIMCA -THE PROPOSED FRAMEWORK</p>
<p>LIMCA enables the automated design of analog IMC crossbars by leveraging LLMs to streamline design selection, generation, and verification, ensuring efficiency and adaptability in hardware-constrained environments.As illustrated in Fig. 3, the framework enables both user-guided and autonomous design synthesis by dynamically interpreting user-defined constraints and optimizing IMC architectures accordingly.The process begins with a user-specified prompt ( 1 ), defining key design requirements such as performance metrics, hardware constraints, and optimization goals.The LLM extracts relevant parameters and formulates a weighted query ( 2 ), determining whether an existing design from the design repository satisfies the given constraints.If an appropriate design is available, the system ranks and selects the optimal configuration ( 8 ), presenting it to the user ( 10 ).If no suitable design exists or if the user requests a new configuration, the framework triggers the Design Generation process ( 3 ).The LLM synthesizes a novel IMC architecture that aligns with the specified constraints, generating a corresponding Python-based design representation.The generated design undergoes an Automated Verification phase ( 4), where a script-driven NHIL validation assesses its correctness.If the design meets the required specifications ( 6), it is integrated into the design space repository ( 7 ), ensuring continuous expansion of the available solution space.In cases where verification fails, diagnostic feedback is generated, pinpointing errors and guiding the LLM in refining subsequent iterations, thereby reducing hallucinations and redundant modifications ( 5 ).Unlike traditional design methodologies that rely on predefined architectures or manual fine-tuning, LIMCA dynamically adapts to evolving constraints, autonomously optimizing IMC designs while minimizing human intervention.This iterative and adaptive approach significantly enhances design efficiency, supporting various hardware configurations and enabling scalable, highperformance IMC solutions.The hugging face represents the ability of LIMCA and the adaptability of the choice of LLM supporting most of the LLM available in the Hugging face [40].</p>
<p>A. IMC-Dataset</p>
<p>For LIMCA to achieve user-constrained outputs, we construct a dedicated dataset, the IMC-Dataset, to support the language model.This dataset serves as a crucial component for integrating hardware-aware constraints into LLMs through either inference or fine-tuning.The heuristics of the dataset, depicted in Fig. 4, illustrate the relationship between hardware parameters and PAA, emphasizing variations in peak power and area across one axis while mapping the highest accuracy accordingly on the other axis.The dataset provides a structured means to explore the correlation between hardware metrics and performance from a hardware-aware perspective.The dataset is built on IMAC-SIM [10], which facilitates both full analog circuit simulation and digital component emulation.It operates on the HSPICE Compiler, ensuring the generation of precise values as outlined in Table I.To systematically explore the design space, we developed an automated framework to sweep key hardware parameters, capturing diverse configurations of IMC architectures.These parameters include different nonvolatile memory devices (MRAM, RRAM, PCM, CBRAM), bit-cell configurations (1T-1R, 2T-1R), technology nodes, and bit resolutions.The dataset is primarily categorized based on crossbar size, with three distinct sizes.For each crossbar configuration, the following variations are considered: 3 × 4 × 3 × 6 = 216, resulting in 3 × 216 = 648 unique IMC instances across all three crossbar sizes.</p>
<p>To extend the applicability of IMAC-SIM, we incorporate both digital and analog IMC variations.While the framework was initially designed for full analog simulations, we introduce an additional 216 analog data points by excluding the bitresolution parameter, given the computational complexity of obtaining precise HSPICE simulation metrics across different bit resolutions.This ensures a broader exploration space while maintaining computational efficiency.</p>
<p>To the best of our knowledge, this study presents the first open-source IMC dataset encompassing 400 analog and digital IMC variations.The dataset is generated based on a single Multi-Layer Perceptron (MLP) topology.However, as the architecture varies, the corresponding metrics will adjust, providing scalability for future extensions.Our planned dataset expansion includes additional MLP architectures and design metrics derived from different dataset classification tasks.This enhancement will allow for a more comprehensive exploration of the design space, enabling sophisticated evaluation and optimization strategies.</p>
<p>B. Ceaveats of IMC-Dataset</p>
<p>While the IMC dataset offers a diverse variation, it could be exponentially increased due to the complexities, such as input feature map size and the MLP architecture, increasing our computing time.For this study, we limit the scope to hardware exploration to avoid high-dimensional design space complexities associated with varying network topologies across different datasets.During the dataset creation process, we maintain specific fixed parameters: the MLP configuration (400 × 120 × 84 × 10), the dataset in use, and the number of images trained from the MNIST dataset [41], ensuring consistency in evaluation while maintaining computational feasibility.However, the design generation and automated validation process are not restricted to these constraints, ensuring adaptability to different user requirements.The dataset metrics are also heavily influenced by the image input dimensions, which in this study are 20 × 20, given the specified MLP topology.While conventional MLP models often utilize 784 input nodes, we explore alternative configurations to optimize dataset generation by structuring horizontal and vertical partitions of crossbar arrays efficiently.</p>
<p>IV. EXPERIMENTAL ANALYSIS</p>
<p>A. Design Space Exploration</p>
<p>The queries driving the design space exploration are generated by ChatGPT-4o [42].A total of 30 queries are systematically divided based on specific objectives and constraints.The first set of 10 queries strictly prioritizes power efficiency, placing it at the forefront of design decisions while maintaining relaxed constraints on the technology node.These queries also apply a weighted importance to crossbar modules or comparable hardware elements, reflecting the critical influence such components have on overall power consumption.A second set of 10 queries emphasizes the area of the design, where the constraints can be either rigorous or somewhat relaxed, depending on the hardware implementation strategy.Lastly, the final set of 10 queries centers on hard constraints that must be upheld, introducing more rigid limitations on the design's feasibility and performance.The results of the design space exploration for IMC accelerators, generated by the LIMCA tool, are summarized in Table II, as Fig. 3 shows this flow from ( 2 → 7 ).The selected designs are categorized across four process nodes, incorporating various non-volatile memory devices and bit-cell architectures.Considering the requirements of edge vision sensor applications [43], [44],</p>
<p>[45], a nominal power consumption limit of ≤3W is imposed while aiming to achieve the highest accuracy (≥96%).The entries in green font represent the designs that satisfy this power and accuracy constraint, thus providing a broader set of viable options for the IMC designer.However, for cases where the objective is to strictly identify near-optimal solutions1 , two specific options are highlighted in yellow for closer evaluation (i.e., 64×64 crossbar with 1T1R-PCM @ 9nm or 7nm).</p>
<p>From Table III, we observe the performance of LIMCA's DSE when processing constrained queries generated by Chat-GPT by various models.The evaluation examines how effectively different models satisfy user-defined constraints in selecting a design, specifically focusing on power efficiency, area optimization, and adherence to hard constraints.The results provide valuable insights into the models' capability to generate compliant solutions within a limited number of attempts.The key observation from the table is the consistently high performance across all models in the Pass@3 metric, where every model achieves a perfect score of 10/10 across all constraint categories.This indicates that when multiple attempts are allowed, each model can produce a design to satisfy the user with a valid solution that satisfies all constraints.However, there is some variability in Pass@1 performance, which measures the success rate on the first attempt.Models such as Qwen2.5-7B-Instruct-1Mand Qwen2.5-Coder-32B-Instructdemonstrate robust Pass@1 results, achieving 9/10 or higher in all categories, while others, like DeepSeek-R1-Distill-Qwen-1.5B and Mamba-Codestral-7B-v0.1, exhibit slightly lower scores, particularly for hard constraints.</p>
<p>Analyzing individual model performance, Qwen2.5-7B-Instruct-1Mmaintains strong results across all three focus areas, with a slight dip in hard constraints (8/10).DeepSeek-R1-Distill-Qwen-1.5B has a lower Pass@1 score for hard constraints (7.9/10) but compensates with perfect Pass@3 performance.Mamba-Codestral-7B-v0.1 consistently scores 8/10 in Pass@1, indicating slightly lower first-attempt success.Qwen2.5-Coder-32B-Instructstands out with the highest hard constraints Pass@1 score (9.3/10) while maintaining strong performance in power and area.Llama-3.1-8B-Instructexhibits minor variations in Pass@1 performance, particularly in area (8.6/10) and hard constraints (8.6/10), but aligns with the rest in achieving perfect Pass@3 scores.</p>
<p>B. Design Creation</p>
<p>This experiment highlights LIMCA's capability to synthesize IMC designs while providing automated validation.The design requests are from queries posed by ChatGPT, which are then processed by LIMCA for implementation.By handling these requests, LIMCA demonstrates its adaptability to diverse and sometimes stringent design requirements.The resulting</p>
<p>Model</p>
<p>Design Generation Design Verification Pass@1 Pass@3 Pass@1 Pass@3 Qwen2.designs undergo systematic validation to ensure compliance with the queried constraints, confirming its ability to efficiently manage both exploratory and highly constrained use cases with minimal human intervention.</p>
<p>To assess the efficacy of LIMCA, we benchmarked its performance in design generation and automated verification across various models.Table IV presents the results in terms of Pass@1 and Pass@3 for both tasks.The design generation results indicate high success rates across models, with a minimum Pass@1 accuracy of 89% and a consistent 100% success rate at Pass@3.This underscores LIMCA's capability to generate viable IMC designs with high reliability, even when faced with complex constraints.</p>
<p>For automated verification, we intentionally introduced erroneous designs to stress-test the framework.The results demonstrate that LIMCA effectively identifies and rectifies design errors, achieving an average Pass@1 rate of 91.5% and a 100% correction rate at Pass@3.This highlights the robustness of LIMCA's NHIL approach, which facilitates efficient design refinement and validation.The consistently strong performance across different models reinforces the ability to ensure design correctness while minimizing manual intervention.These results establish LIMCA as a reliable framework for automated IMC design generation and verification.Its NHILbased verification strategy significantly enhances the error correction process, ensuring high accuracy and robustness in automated IMC design workflows.The generation of design variations is governed by the output token speed of the LLM, while power and accuracy estimations rely solely on HSPICE simulations.</p>
<p>C. Design Exploration Cost</p>
<p>Manually optimizing an IMC architecture involves an iterative fine-tuning process that adjusts design parameters such as crossbar dimensions, device configurations, resistance states, etc.To assess the estimated design space exploration time (t DSE ) under the same constraints-achieving a power consumption of ≤3W and maintaining an accuracy of ≥96%-a circuit expert in our lab conducted iterations using both CCSS [9] and IMAC-SIM [10] to generate IMC crossbars.These two frameworks were selected as they serve as circuit-level accelerators capable of providing exact inference accuracy (Table I).Each iteration required debugging, reconfiguration, and reruns.The complete optimization process for CCSS and IMAC-SIM ranged from 140 to 398 minutes and 92 to 154 minutes, respectively, especially longer for large-scale crossbar designs with analog components.The necessity of expert intervention at every stage-design formulation, circuit verification, and performance tuning-further increases the overall time overhead.The results are reflected in Table V.</p>
<p>In contrast, LIMCA dramatically reduces design exploration time by automating design selection, generation, and verification through an LLM-driven pipeline.If a suitable IMC crossbar architecture already exists within the structured design space, LIMCA retrieves the optimal configuration in mere seconds, with the only delay stemming from the LLM's token generation speed (t k ).When a new design needs to be synthesized, LIMCA autonomously formulates and validates an optimized configuration.While digital designs may experience slight delays due to additional SPICE-level verification, whole circuit evaluations are completed in under 8 minutes, making the entire process significantly faster than manual optimization.By eliminating human intervention in circuit synthesis and validation, LIMCA accelerates design space exploration, achieving an 11.5× to 49.7× speedup compared to manual approaches while ensuring adherence to user-defined performance constraints.</p>
<p>D. Limitations and Future Works</p>
<p>Although LIMCA effectively addresses design space exploration of hardware components, it could be greatly beneficial when expanded to a comprehensive full-stack implementation.Such an implementation would encompass the entire software-to-hardware pipeline, including automation based on user specifications, selecting appropriate MLP architectures for specific applications, and developing mathematical models that elucidate the relationship between software modeling and hardware characteristics.This mathematical framework would enable systematic reasoning about how software design decisions propagate through hardware complexities and how SPICE-level parasitic effects impact key performance metrics.This approach would bridge the gap between high-level neural network design and low-level circuit implementation.</p>
<p>V. CONCLUSION</p>
<p>In conclusion, our work presents LIMCA, a novel opensourced framework that leverages LLMs to automate the design creation and evaluation of IMC crossbar architectures without human intervention.By systematically generating and validating SPICE netlists, LIMCA offers an effective way of design exploration by reducing time and complexity while ensuring that critical power, area, and accuracy constraints are satisfied.Experimental results on MNIST classification demonstrate that LIMCA design space exploration can quickly scale and achieve high accuracy (≥96%) with power consumption kept within a 3W threshold, offering a scalable and efficient solution for edge applications.</p>
<p>Fig. 2 .
2
Fig. 2.An analog IMC crossbar array pair (positive and negative arrays).</p>
<p>Fig. 3 .
3
Fig. 3. LIMCA framework.</p>
<p>Fig. 4 .
4
Fig. 4. Distribution of Power, Area, Accuracy across hardware parameters.</p>
<p>TABLE II DESIGN
II
SPACE EXPLORATION OF IMC ACCELERATORS GENERATED BY LIMCA ON MNIST TO MEET POWER CONSUMPTION OF ≤3W AND ACCURACY OF ≥96% FOR EDGE APPLICATIONS.
Config./Xbar Size16×1632×3264×64TechDeviceBitcellArea (µm 2 ) Accuracy (%) Average Power (W)Area (µm 2 ) Accuracy (%) Average Power (W)Area (µm 2 ) Accuracy (%) Average Power (W)7nmMRAM1T1R5286.615963.9378683006.403963.1012782156.134821.8472227nmRRAM1T1R5286.615788.2918563006.403625.4900122156.134182.9150787nmRRAM2T1R5602.122808.1618423329.135525.4584122541.486142.184647nmPCM1T1R5286.615920.534453006.403980.5215692156.1341000.457961 ✓7nmPCM2T1R5602.122920.5333033329.135980.5213742541.4861000.7788219nmMRAM1T1R5672.95944.0414623401.585963.2500923265.004721.9879029nmRRAM1T1R5672.951008.6181463401.585685.8942282627.994183.1716769nmRRAM2T1R6194.502867.3720283935.08627.892533265.004143.1531089nmPCM1T1R5672.95980.5355873401.585980.5258152627.9941000.469902 ✓9nmPCM2T1R6194.502820.5333613935.08980.5256453265.0041000.46974114nm MRAM1T1R7061.34984.0877624821.77963.4644164323.738962.22887614nmRRAM1T1R7061.34869.0624724821.77846.5287644323.738243.60613614nmRRAM2T1R8323.367844.2447776112.698646.4986985865.144183.58757414nmPCM1T1R7061.34900.5362434821.77980.5312664323.7381000.48609514nmPCM2T1R8323.367940.5422016112.698980.531135865.1441000.48594820nm MRAM1T1R9524.224984.1486787341.056963.5963367331.84962.3933620nmRRAM1T1R9524.224923.3049077341.056886.9548127331.84463.92475420nmRRAM2T1R12099.79902.4689129975.603706.78764410477.57223.90623620nmPCM1T1R9524.224960.5371937341.056980.5342857331.841000.49551120nmPCM2T1R12099.79980.5386469975.603980.53416910477.571000.495376</p>
<p>TABLE III LIMCA
III
PERFORMANCE RESULTS -DESIGN SPACE EXPLORATION.
ModelMetricPowerQuery Focus Area Hard ConstraintsQwen2.5-7B-Instruct-1MPass@19/109/108/10Pass@310/1010/1010/10DeepSeek-R1-Distill-Qwen-1.5B Pass@18.3/109/107.9/10Pass@310/1010/1010/10Mamba-Codestral-7B-v0.1Pass@18/108/108/10Pass@310/1010/1010/10Qwen2.5-Coder-32B-InstructPass@19/109/109.3/10Pass@310/1010/1010/10Llama-3.1-8B-InstructPass@19/108.6/108.6/10Pass@310/1010/1010/10</p>
<p>TABLE IV LIMCA
IV
EVALUATION ON DESIGN GENERATION AND AUTOMATED VERIFICATION.</p>
<p>TABLE V ESTIMATED
V
DESIGN SPACE EXPLORATION TIME.
FrameworksDesign Space ExplorationLanguageExperiment Time (minutes)CCSS [9]ManualMatlab-SPICE140 ≤ t DSE ≤ 398IMAC-Sim [10]ManualPython-SPICE92 ≤ t DSE ≤ 154LIMCAAutomatedPython-SPICEt
k ≤ t DSE ≤ 8</p>
<p>It should be noted that this is not necessarily the absolute optimal configuration, but the user desired configuration.</p>
<p>Prime: A novel processing-in-memory architecture for neural network computation in reram-based main memory. P Chi, S Li, C Xu, T Zhang, J Zhao, Y Liu, Y Wang, Y Xie, ACM SIGARCH Computer Architecture News. 4432016</p>
<p>Cmp-pim: an energy-efficient comparator-based processing-in-memory neural network accelerator. S Angizi, Z He, A S Rakin, D Fan, Proceedings of the 55th Annual Design Automation Conference. the 55th Annual Design Automation Conference2018</p>
<p>Isaac: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars. A Shafiee, A Nag, N Muralimanohar, R Balasubramonian, J P Strachan, M Hu, R S Williams, V Srikumar, ACM SIGARCH Computer Architecture News. 4432016</p>
<p>Neurosim: A circuit-level macro model for benchmarking neuro-inspired architectures in online learning. P.-Y Chen, X Peng, S Yu, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. 37122018</p>
<p>Mrima: An mram-based inmemory accelerator. S Angizi, Z He, A Awad, D Fan, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. 3952019</p>
<p>Mnsim 2.0: A behavior-level modeling tool for memristorbased neuromorphic computing systems. Z Zhu, GLSVLSI. 2020</p>
<p>Xbar-partitioning: a practical way for parasitics and noise tolerance in analog imc circuits. M H Amin, M E Elbtity, R Zand, IEEE Journal on Emerging and Selected Topics in Circuits and Systems. 1242022</p>
<p>Mnsim: Simulation platform for memristor-based neuromorphic computing system. L Xia, B Li, T Tang, P Gu, P.-Y Chen, S Yu, Y Cao, Y Wang, Y Xie, H Yang, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. 3752018</p>
<p>Cccs: Customized spice-level crossbar-array circuit simulator for in-memory computing. F Zhang, M Hu, Proceedings of the 39th International Conference on Computer-Aided Design. the 39th International Conference on Computer-Aided Design2020</p>
<p>Imac-sim:: A circuit-level simulator for in-memory analog computing architectures. M H Amin, M E Elbtity, R Zand, Proceedings of the Great Lakes Symposium on VLSI 2023. the Great Lakes Symposium on VLSI 20232023258212813</p>
<p>Dot-product engine for neuromorphic computing: Programming 1t1m crossbar to accelerate matrix-vector multiplication. M Hu, J P Strachan, Z Li, E M Grafals, N Davila, C Graves, S Lam, N Ge, J J Yang, R S Williams, Proceedings of the 53rd annual design automation conference. the 53rd annual design automation conference2016</p>
<p>A flexible and fast pytorch toolkit for simulating training and inference on analog crossbar arrays. M Rasch, D M Rodríguez, T Gokmen, M Gallo, F Carta, C Goldberg, K Maghraoui, A Sebastian, V Narayanan, </p>
<p>Mef-ram: A new non-volatile cache memory based on magneto-electric fet. S Angizi, N Khoshavi, A Marshall, P Dowben, D Fan, ACM Transactions on Design Automation of Electronic Systems (TODAES). 2722021</p>
<p>Chipyard: Integrated design, simulation, and implementation framework for custom socs. A Amid, IEEE Micro. 4042020</p>
<p>Chipgpt: How far are we from natural language hardware design. K Chang, Y Wang, H Ren, M Wang, S Liang, Y Han, H Li, X Li, arXiv:2305.140192023arXiv preprint</p>
<p>Spicepilot: Navigating spice code generation and simulation with ai guidance. D Vungarala, S Alam, A Ghosh, S Angizi, arXiv:2410.205532024arXiv preprint</p>
<p>Verigen: A large language model for verilog code generation. S Thakur, B Ahmad, H Pearce, B Tan, B Dolan-Gavitt, R Karri, S Garg, ACM Transactions on Design Automation of Electronic Systems. 2932024</p>
<p>Gpt4aigchip: Towards next-generation ai accelerator design automation via large language models. Y Fu, Y Zhang, Z Yu, S Li, Z Ye, C Li, C Wan, Y C Lin, IEEE/ACM International Conference on Computer Aided Design. 2023. 2023IEEE</p>
<p>D Vungarala, M Nazzal, M Morsali, C Zhang, A Ghosh, A Khreishah, S Angizi, Sa-ds: A dataset for large language modeldriven ai accelerator design generation. 20242404arXiv e-prints</p>
<p>Data is all you need: Finetuning llms for chip design via an automated design-data augmentation framework. K Chang, Proceedings of the 61st ACM/IEEE Design Automation Conference. the 61st ACM/IEEE Design Automation Conference2024</p>
<p>Chateda: A large language model powered autonomous agent for eda. H Wu, Z He, X Zhang, X Yao, S Zheng, H Zheng, B Yu, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. 2024</p>
<p>Assertllm: Generating and evaluating hardware verification assertions from design specifications via multi-llms. W Fang, M Li, M Li, Z Yan, S Liu, H Zhang, Z Xie, arXiv:2402.00386v12024</p>
<p>Uvllm: An automated universal rtl verification framework using llms. Y Hu, J Ye, K Xu, J Sun, S Zhang, X Jiao, D Pan, J Zhou, N Wang, W Shan, arXiv:2411.162382024arXiv preprint</p>
<p>Autochip: Automating hdl generation using llm feedback. S Thakur, J Blocklove, H Pearce, B Tan, S Garg, R Karri, arXiv:2311.048872023arXiv preprint</p>
<p>MG-Verilog: Multigrained Dataset Towards Enhanced LLM-assisted Verilog Generation. Y Zhang, Z Yu, Y Fu, C Wan, Y C Lin, 2024 IEEE LLM Aided Design Workshop (LAD). 2024</p>
<p>Chip-chat: Challenges and opportunities in conversational hardware design. J Blocklove, S Garg, R Karri, H Pearce, 2023 ACM/IEEE 5th Workshop on Machine Learning for CAD (MLCAD). IEEE2023</p>
<p>A multi-expert large language model architecture for verilog code generation. B Nadimi, H Zheng, arXiv:2404.080292024arXiv preprint</p>
<p>Deepcircuitx: A comprehensive repository-level dataset for rtl code understanding, generation, and ppa analysis. Z Li, C Xu, Z Shi, Z Peng, Y Liu, Y Zhou, L Zhou, C Ma, J Zhong, X Wang, arXiv:2502.182972025arXiv preprint</p>
<p>Rtllm: An open-source benchmark for design rtl generation with large language model. Y Lu, S Liu, Q Zhang, Z Xie, 2024 29th Asia and South Pacific Design Automation Conference (ASP-DAC). IEEE2024</p>
<p>Verilogreader: Llm-aided hardware test generation. R Ma, Y Yang, Z Liu, J Zhang, M Li, J Huang, G Luo, arXiv:2406.04373v12024</p>
<p>Tpu-gen: Llm-driven custom tensor processing unit generator. D Vungarala, M E Elbtity, S Syed, S Alam, K Pandit, A Ghosh, R Zand, S Angizi, 2025</p>
<p>LLMCompass: Enabling Efficient Hardware Design for Large Language Model Inference. H Zhang, A Ning, R B Prabhakar, D Wentzlaff, 2024 ACM/IEEE 51st Annual International Symposium on Computer Architecture (ISCA). </p>
<p>Why can gpt learn in-context? language models implicitly perform gradient descent as meta-optimizers. D Dai, Y Sun, L Dong, Y Hao, S Ma, Z Sui, F Wei, arXiv:2212.105592022arXiv preprint</p>
<p>Analogcoder: Analog circuit design via training-free code generation. Y Lai, S Lee, G Chen, S Poddar, M Hu, D Z Pan, P Luo, 2024</p>
<p>Masalachai: A large-scale spice netlist dataset for analog circuits by harnessing ai. J Bhandari, V Bhat, Y He, S Garg, H Rahmani, R Karri, 2025</p>
<p>Ampagent: An llm-based multi-agent system for multi-stage amplifier schematic design from literature for process and performance porting. C Liu, W Chen, A Peng, Y Du, L Du, J Yang, 2024</p>
<p>Deep mapper: A multi-channel single-cycle nearsensor dnn accelerator. M Morsali, 2023 IEEE International Conference on Rebooting Computing (ICRC). IEEE2023</p>
<p>Accelerating deep neural networks in processing-in-memory platforms: Analog or digital approach. S Angizi, Z He, D Reis, X S Hu, W Tsai, S J Lin, D Fan, 2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI). IEEE2019</p>
<p>Dnn+ neurosim v2. 0: An end-to-end benchmarking framework for compute-in-memory accelerators for on-chip training. X Peng, IEEE TCAD. 40112020</p>
<p>Hugging face -the ai community building the future. 2025</p>
<p>The mnist database of handwritten digit images for machine learning research. L Deng, IEEE signal processing magazine. 2962012best of the web</p>
<p>Open ai chatgpt. 2023</p>
<p>Macsen: A processing-in-sensor architecture integrating mac operations into image sensor for ultra-low-power bnn-based intelligent visual perception. H Xu, IEEE TCASII. 6822021</p>
<p>Mr-pipa: An integrated multilevel rram (hfox)-based processing-in-pixel accelerator. M Abedin, A Roohi, M Liehr, N Cady, S Angizi, IEEE JxCDC. 822022</p>
<p>Pisa: A nonvolatile processing-in-sensor accelerator for imaging systems. S Angizi, S Tabrizchi, D Z Pan, A Roohi, IEEE Transactions on Emerging Topics in Computing. 2023</p>            </div>
        </div>

    </div>
</body>
</html>