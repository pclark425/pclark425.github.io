<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5730 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5730</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5730</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-115.html">extraction-schema-115</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <p><strong>Paper ID:</strong> paper-9943bbb97a48d10b70453e62307c1c797ed64012</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/9943bbb97a48d10b70453e62307c1c797ed64012" target="_blank">Assess and Summarize: Improve Outage Understanding with Large Language Models</a></p>
                <p><strong>Paper Venue:</strong> ESEC/SIGSOFT FSE</p>
                <p><strong>Paper TL;DR:</strong> Results obtained show that Oasis can effectively and efficiently summarize outages, and lead Microsoft to deploy its first prototype which is currently under experimental adoption by some of the incident teams.</p>
                <p><strong>Paper Abstract:</strong> Cloud systems have become increasingly popular in recent years due to their flexibility and scalability. Each time cloud computing applications and services hosted on the cloud are affected by a cloud outage, users can experience slow response times, connection issues or total service disruption, resulting in a significant negative business impact. Outages are usually comprised of several concurring events/source causes, and therefore understanding the context of outages is a very challenging yet crucial first step toward mitigating and resolving outages. In current practice, on-call engineers with in-depth domain knowledge, have to manually assess and summarize outages when they happen, which is time-consuming and labor-intensive. In this paper, we first present a large-scale empirical study investigating the way on-call engineers currently deal with cloud outages at Microsoft, and then present and empirically validate a novel approach (dubbed Oasis) to help the engineers in this task. Oasis is able to automatically assess the impact scope of outages as well as to produce human-readable summarization. Specifically, Oasis first assesses the impact scope of an outage by aggregating relevant incidents via multiple techniques. Then, it generates a human-readable summary by leveraging fine-tuned large language models like GPT-3.x. The impact assessment component of Oasis was introduced in Microsoft over three years ago, and it is now widely adopted, while the outage summarization component has been recently introduced, and in this article we present the results of an empirical evaluation we carried out on 18 real-world cloud systems as well as a human-based evaluation with outage owners. The results obtained show that Oasis can effectively and efficiently summarize outages, and lead Microsoft to deploy its first prototype which is currently under experimental adoption by some of the incident teams.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5730.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5730.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OASIS (GPT-3.x)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OASIS outage summarization with fine-tuned GPT-3.x</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>OASIS is a production tool that aggregates relevant incident records and uses a fine-tuned GPT-3 family language model to generate human-readable outage summaries from structured incident fields transformed into textual context.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.x (Curie, DaVinci / GPT-3 and GPT-3.5 variants)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Generative Pre-trained Transformer family models (transformer-based autoregressive LMs). Paper reports two variants used: Curie (reported as a 6.7B-parameter GPT-3 variant in the paper) and DaVinci (reported as a 175B-parameter GPT-3.5 variant). Both were fine-tuned on incident→summary pairs from the internal incident management (IcM) corpus. Inputs are domain-processed text formed from structured incident fields (title, description, service, severity) with an appended generation prompt.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Curie: 6.7B (reported); DaVinci: 175B (reported)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Not used as an anomaly detector. The LM is fine-tuned (supervised) to generate textual outage summaries from aggregated incident records; domain-specific text processing prioritizes high-severity incidents and textual descriptions. Summarization is used to aid human understanding of incidents (which are themselves anomaly reports), not to perform explicit anomaly detection or classification on lists/sequences/tables.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured incident records (fields: title, description, service, severity, timestamps) transformed into a concatenated textual context (i.e., structured→unstructured text).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Not applicable as explicit anomaly detection; operates on incident reports which represent detected anomalies (incidents). Generates summaries of these anomaly records rather than detecting outliers or corrupt rows.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Internal Microsoft IcM dataset: incidents and outages from 18 cloud systems (Jan 1, 2020 - Oct 1, 2022); split 7:1:2 for training/validation/test.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Automatic generation metrics for summarization: BLEU-4, ROUGE-L, METEOR. Reported Top1 scores for summarization (DaVinci): BLEU-4 0.664, ROUGE-L 0.742, METEOR 0.734; Curie slightly lower (BLEU-4 0.654 / ROUGE-L 0.730 / METEOR 0.721). For title generation DaVinci: BLEU-4 0.857, ROUGE-L 0.883, METEOR 0.869. Human evaluation: majority preference for OASIS-DaVinci (32 of 54 outage owners ranked it top).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to three baselines: rule-based concatenation (concatenate incident fields), information retrieval (NNGen nearest-neighbor retrieval), and GPT-2 (117M). OASIS (fine-tuned GPT-3.x) outperformed baselines on automatic metrics (e.g., DaVinci improved BLEU-4 by at least ~32.3% over state-of-the-art baselines for summarization) and in human rankings. Rule-based had high METEOR but poor BLEU-4 (too verbose); IR performed poorly for summaries due to system evolution; GPT-2 was stronger than rule/IR but weaker than fine-tuned GPT-3.x.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>The paper does not apply the LLM to explicit anomaly detection on lists/sequences/tables; limitations reported for the summarization use-case include: missing domain-specific mappings (e.g., failing to infer impacted downstream systems when that requires mapping URL prefixes to system names), slight degradation when the (possibly ungrammatical) outage title is appended to the context, and limited external validity since models were fine-tuned on Microsoft IcM data (may require adaptation for other systems). Fine-tuning (rather than prompt-only) was necessary for best results. The LLM may hallucinate or omit domain-specific relations not present in incidents' text.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Assess and Summarize: Improve Outage Understanding with Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5730.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5730.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Incident-link prediction NN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural network incident-link prediction (text similarity model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A supervised neural network trained on pairs of incidents (titles and descriptions) to predict whether two incidents should be linked (i.e., are relevant to the same outage), producing a similarity score thresholded to form links used in impact scope assessment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Custom neural network (text similarity model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A deep learning model that takes two incidents' titles and descriptions as input and outputs a similarity score. Trained on historical incident pairs labeled by engineers (linked vs. not linked). Architecture details (e.g., specific encoder type) are not specified in the paper beyond being a neural network.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Supervised pairwise similarity prediction used to link incident reports (text pairs) so that incidents relevant to the same outage are aggregated; this is an instance of grouping/correlation of anomaly reports rather than explicit anomaly detection on structured lists/tables.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Textual fields of incident records (titles and descriptions), derived from structured incident entries.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Implicit: groups/links incidents that are manifestations of the same underlying problem (i.e., correlated anomaly reports); not framed as outlier detection.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Internal IcM incident pairs where engineers had previously created links (positives) and non-linked pairs (negatives); built from the same 18 cloud systems dataset and historical rule-based links.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>The paper does not report numeric performance metrics (e.g., accuracy, AUROC) for the prediction model in isolation; evaluation is reported at end-to-end level (impact scope assessment + summarization) and via human preference and summarization metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Used alongside two other linking approaches: rule-based linking (engineer-authored rules, highest confidence) and historical lookup (component linking graph). The prediction model complements the other two: IR/historical rules may fail for rapid evolution or lack of history; neural predictor adapts to evolution. No quantitative head-to-head metrics for the predictor alone are given.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Architecture and performance numbers for the predictor are not provided. The model depends on quality and coverage of training labels (historical linked pairs). It may produce false links if textual similarity does not correspond to real causal linkage, and may miss links when wording differs or new components are added without historical examples.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Assess and Summarize: Improve Outage Understanding with Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5730.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5730.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prior LLM root-cause recommendation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced prior work that applies large language models to recommend root causes and mitigation steps for cloud incidents; cited as evidence that GPT-3.x models have been explored for incident management tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.x (as reported in the cited work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Mentioned as prior use of GPT-3.x to recommend root causes and mitigations for cloud incidents; the paper does not report architecture or sizes beyond referencing GPT-3.x family.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Mentioned as an LLM-based recommendation system for incident root causes/mitigations; details of whether it was prompt-based, fine-tuned, or zero-shot are not provided in this paper (refer to cited work for specifics).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Incident reports and associated information (textual incident data); exact dataset not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Not explicitly stated here; the referenced work targets root-cause and mitigation recommendation for incidents (i.e., analysis of anomaly reports).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not reported in this paper; refer to the cited work for quantitative evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Not detailed in this paper; cited as an example in related work that LLMs have been used for incident-related recommendations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not discussed here; the current paper cites the prior work as motivation that LLMs can assist incident management but does not analyze its limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Assess and Summarize: Improve Outage Understanding with Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models <em>(Rating: 2)</em></li>
                <li>Identifying linked incidents in large-scale online service systems <em>(Rating: 2)</em></li>
                <li>Graph-based incident aggregation for large-scale online service systems <em>(Rating: 2)</em></li>
                <li>Fast outage analysis of large-scale production clouds with service correlation mining <em>(Rating: 2)</em></li>
                <li>Towards intelligent incident management: why we need it and how we make it <em>(Rating: 1)</em></li>
                <li>Fighting the Fog of War: Automated Incident Detection for Cloud Systems <em>(Rating: 2)</em></li>
                <li>Online Summarizing Alerts through Semantic and Behavior Information <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5730",
    "paper_id": "paper-9943bbb97a48d10b70453e62307c1c797ed64012",
    "extraction_schema_id": "extraction-schema-115",
    "extracted_data": [
        {
            "name_short": "OASIS (GPT-3.x)",
            "name_full": "OASIS outage summarization with fine-tuned GPT-3.x",
            "brief_description": "OASIS is a production tool that aggregates relevant incident records and uses a fine-tuned GPT-3 family language model to generate human-readable outage summaries from structured incident fields transformed into textual context.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.x (Curie, DaVinci / GPT-3 and GPT-3.5 variants)",
            "model_description": "Generative Pre-trained Transformer family models (transformer-based autoregressive LMs). Paper reports two variants used: Curie (reported as a 6.7B-parameter GPT-3 variant in the paper) and DaVinci (reported as a 175B-parameter GPT-3.5 variant). Both were fine-tuned on incident→summary pairs from the internal incident management (IcM) corpus. Inputs are domain-processed text formed from structured incident fields (title, description, service, severity) with an appended generation prompt.",
            "model_size": "Curie: 6.7B (reported); DaVinci: 175B (reported)",
            "anomaly_detection_method": "Not used as an anomaly detector. The LM is fine-tuned (supervised) to generate textual outage summaries from aggregated incident records; domain-specific text processing prioritizes high-severity incidents and textual descriptions. Summarization is used to aid human understanding of incidents (which are themselves anomaly reports), not to perform explicit anomaly detection or classification on lists/sequences/tables.",
            "data_type": "Structured incident records (fields: title, description, service, severity, timestamps) transformed into a concatenated textual context (i.e., structured→unstructured text).",
            "anomaly_type": "Not applicable as explicit anomaly detection; operates on incident reports which represent detected anomalies (incidents). Generates summaries of these anomaly records rather than detecting outliers or corrupt rows.",
            "dataset_name": "Internal Microsoft IcM dataset: incidents and outages from 18 cloud systems (Jan 1, 2020 - Oct 1, 2022); split 7:1:2 for training/validation/test.",
            "performance_metrics": "Automatic generation metrics for summarization: BLEU-4, ROUGE-L, METEOR. Reported Top1 scores for summarization (DaVinci): BLEU-4 0.664, ROUGE-L 0.742, METEOR 0.734; Curie slightly lower (BLEU-4 0.654 / ROUGE-L 0.730 / METEOR 0.721). For title generation DaVinci: BLEU-4 0.857, ROUGE-L 0.883, METEOR 0.869. Human evaluation: majority preference for OASIS-DaVinci (32 of 54 outage owners ranked it top).",
            "baseline_comparison": "Compared to three baselines: rule-based concatenation (concatenate incident fields), information retrieval (NNGen nearest-neighbor retrieval), and GPT-2 (117M). OASIS (fine-tuned GPT-3.x) outperformed baselines on automatic metrics (e.g., DaVinci improved BLEU-4 by at least ~32.3% over state-of-the-art baselines for summarization) and in human rankings. Rule-based had high METEOR but poor BLEU-4 (too verbose); IR performed poorly for summaries due to system evolution; GPT-2 was stronger than rule/IR but weaker than fine-tuned GPT-3.x.",
            "limitations_or_failure_cases": "The paper does not apply the LLM to explicit anomaly detection on lists/sequences/tables; limitations reported for the summarization use-case include: missing domain-specific mappings (e.g., failing to infer impacted downstream systems when that requires mapping URL prefixes to system names), slight degradation when the (possibly ungrammatical) outage title is appended to the context, and limited external validity since models were fine-tuned on Microsoft IcM data (may require adaptation for other systems). Fine-tuning (rather than prompt-only) was necessary for best results. The LLM may hallucinate or omit domain-specific relations not present in incidents' text.",
            "uuid": "e5730.0",
            "source_info": {
                "paper_title": "Assess and Summarize: Improve Outage Understanding with Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Incident-link prediction NN",
            "name_full": "Neural network incident-link prediction (text similarity model)",
            "brief_description": "A supervised neural network trained on pairs of incidents (titles and descriptions) to predict whether two incidents should be linked (i.e., are relevant to the same outage), producing a similarity score thresholded to form links used in impact scope assessment.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Custom neural network (text similarity model)",
            "model_description": "A deep learning model that takes two incidents' titles and descriptions as input and outputs a similarity score. Trained on historical incident pairs labeled by engineers (linked vs. not linked). Architecture details (e.g., specific encoder type) are not specified in the paper beyond being a neural network.",
            "model_size": null,
            "anomaly_detection_method": "Supervised pairwise similarity prediction used to link incident reports (text pairs) so that incidents relevant to the same outage are aggregated; this is an instance of grouping/correlation of anomaly reports rather than explicit anomaly detection on structured lists/tables.",
            "data_type": "Textual fields of incident records (titles and descriptions), derived from structured incident entries.",
            "anomaly_type": "Implicit: groups/links incidents that are manifestations of the same underlying problem (i.e., correlated anomaly reports); not framed as outlier detection.",
            "dataset_name": "Internal IcM incident pairs where engineers had previously created links (positives) and non-linked pairs (negatives); built from the same 18 cloud systems dataset and historical rule-based links.",
            "performance_metrics": "The paper does not report numeric performance metrics (e.g., accuracy, AUROC) for the prediction model in isolation; evaluation is reported at end-to-end level (impact scope assessment + summarization) and via human preference and summarization metrics.",
            "baseline_comparison": "Used alongside two other linking approaches: rule-based linking (engineer-authored rules, highest confidence) and historical lookup (component linking graph). The prediction model complements the other two: IR/historical rules may fail for rapid evolution or lack of history; neural predictor adapts to evolution. No quantitative head-to-head metrics for the predictor alone are given.",
            "limitations_or_failure_cases": "Architecture and performance numbers for the predictor are not provided. The model depends on quality and coverage of training labels (historical linked pairs). It may produce false links if textual similarity does not correspond to real causal linkage, and may miss links when wording differs or new components are added without historical examples.",
            "uuid": "e5730.1",
            "source_info": {
                "paper_title": "Assess and Summarize: Improve Outage Understanding with Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Prior LLM root-cause recommendation",
            "name_full": "Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models",
            "brief_description": "Referenced prior work that applies large language models to recommend root causes and mitigation steps for cloud incidents; cited as evidence that GPT-3.x models have been explored for incident management tasks.",
            "citation_title": "Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models",
            "mention_or_use": "mention",
            "model_name": "GPT-3.x (as reported in the cited work)",
            "model_description": "Mentioned as prior use of GPT-3.x to recommend root causes and mitigations for cloud incidents; the paper does not report architecture or sizes beyond referencing GPT-3.x family.",
            "model_size": null,
            "anomaly_detection_method": "Mentioned as an LLM-based recommendation system for incident root causes/mitigations; details of whether it was prompt-based, fine-tuned, or zero-shot are not provided in this paper (refer to cited work for specifics).",
            "data_type": "Incident reports and associated information (textual incident data); exact dataset not specified in this paper.",
            "anomaly_type": "Not explicitly stated here; the referenced work targets root-cause and mitigation recommendation for incidents (i.e., analysis of anomaly reports).",
            "dataset_name": null,
            "performance_metrics": "Not reported in this paper; refer to the cited work for quantitative evaluation.",
            "baseline_comparison": "Not detailed in this paper; cited as an example in related work that LLMs have been used for incident-related recommendations.",
            "limitations_or_failure_cases": "Not discussed here; the current paper cites the prior work as motivation that LLMs can assist incident management but does not analyze its limitations.",
            "uuid": "e5730.2",
            "source_info": {
                "paper_title": "Assess and Summarize: Improve Outage Understanding with Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models",
            "rating": 2
        },
        {
            "paper_title": "Identifying linked incidents in large-scale online service systems",
            "rating": 2
        },
        {
            "paper_title": "Graph-based incident aggregation for large-scale online service systems",
            "rating": 2
        },
        {
            "paper_title": "Fast outage analysis of large-scale production clouds with service correlation mining",
            "rating": 2
        },
        {
            "paper_title": "Towards intelligent incident management: why we need it and how we make it",
            "rating": 1
        },
        {
            "paper_title": "Fighting the Fog of War: Automated Incident Detection for Cloud Systems",
            "rating": 2
        },
        {
            "paper_title": "Online Summarizing Alerts through Semantic and Behavior Information",
            "rating": 1
        }
    ],
    "cost": 0.01157775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Assess and Summarize: Improve Outage Understanding with Large Language Models</h1>
<p>Pengxiang Jin*,<br>Shenglin Zhang<br>Nankai University<br>China<br>Chaoyun Zhang,<br>Pu Zhao, Shilin He<br>Microsoft<br>China</p>
<p>Minghua Ma<br>Microsoft<br>China<br>Federica Sarro<br>University College London<br>UK</p>
<h2>ABSTRACT</h2>
<p>Cloud systems have become increasingly popular in recent years due to their flexibility and scalability. Each time cloud computing applications and services hosted on the cloud are affected by a cloud outage, users can experience slow response times, connection issues or total service disruption, resulting in a significant negative business impact. Outages are usually comprised of several concurring events/source causes, and therefore understanding the context of outages is a very challenging yet crucial first step toward mitigating and resolving outages. In current practice, on-call engineers with in-depth domain knowledge, have to manually assess and summarize outages when they happen, which is time-consuming and labor-intensive. In this paper, we first present a large-scale empirical study investigating the way on-call engineers currently deal with cloud outages at Microsoft, and then present and empirically validate a novel approach (dubbed Oasis) to help the engineers in this task. Oasis is able to automatically assess the impact scope of outages as well as to produce human-readable summarization. Specifically, Oasis first assesses the impact scope of an outage by aggregating relevant incidents via multiple techniques. Then, it generates a human-readable summary by leveraging fine-tuned large language models like GPT-3.x. The impact assessment component of Oasis was introduced in Microsoft over three years ago, and it is now widely adopted, while the outage summarization component has been recently introduced, and in this article we present the results of an empirical evaluation we carried out on 18 real-world cloud systems as well as a human-based evaluation with outage owners. The results obtained show that Oasis can effectively and efficiently summarize outages, and lead Microsoft to deploy its first prototype which is currently under experimental adoption by some of the incident teams.</p>
<h2>CCS CONCEPTS</h2>
<ul>
<li>Computer systems organization $\rightarrow$ Cloud computing; $\cdot$ Software and its engineering $\rightarrow$ Maintaining software.</li>
</ul>
<h2>KEYWORDS</h2>
<p>Outage Understanding, Large Language Model, Cloud Systems</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>1 INTRODUCTION</h2>
<p>With the trend of large IT enterprises such as Microsoft, Amazon, and Google deploying services to the cloud platforms, cloud systems have had a booming development in recent years [4, 8, 23]. Tremendous efforts have been devoted to improving the reliability of cloud systems, however, unplanned incidents or performance degradation are still inevitable due to the complex and dynamic nature of cloud systems. Often these incidents escalate to a so called outage, which impacts multiple services and customers.</p>
<p>Once an outage occurs to a cloud system, it is crucial to understand its impact scope as soon as possible in order to promptly notify customers, mitigate issues [4, 24], and ultimately resolve the outage, aiming at reducing as much as possible the loss associate with it. Nevertheless, a cloud system is quite complex and involves many services such as across-region infrastructures, virtual machines, networking, and database systems, thus making this task very challenging. To support engineers in monitoring the reliability of the cloud system, each cloud system service has multiple monitors that create an incident each time something wrong occurs. For example, Figure 1 shows the timeline of an incident caused by a flawed configuration change in the Storage service. The failed storage affected several SQL databases, and the failure was further propagated to web application instances that depend on the impaired databases. Finally, the outage is declared and associated with the multiple incidents occurred in the storage, SQL, and web application services. Doing this job manually is not trivial, and in some cases not even feasible. Being able to efficiently aggregate all and only those incidents which are relevant to a given outage, would empower the engineers to promptly investigate the impact scope, as it greatly reduces the number of incidents that need to be investigated.</p>
<p>Previous studies [8, 11, 17, 29] have devoted a lot of efforts to dealing with incidents aggregation or linking the relevant incidents to the outage. However, based on our real-world experience in Microsoft, we observe that on-call engineers (OCEs) still need to manually check the detailed information of relevant incidents and write a summary of outages (a real-world example in Section 3.2), which is helpful to further handle the outage in terms of notification, mitigation, diagnosis, and resolution. To the best of our knowledge, extensive studies on outage understanding are lacking. Therefore, in this paper, we first empirically investigate the negative effects of outages in worldwide popular cloud systems in Microsoft and how engineers currently deal with them. To this end, we exploit data</p>
<p>collected from the usage of 18 real-world cloud systems (many of which are worldwide popular systems) over the past three years. We found that most outages have a huge negative impact on customers, and the median summarization time is 1 time unit (about one hour) . Therefore, in practice, engineers have to spend significant efforts to understand outages. Besides, the content of outage summaries often contains detailed when, where, who, what, and why. This information is complex and cannot simply adopt as a template because it must be readable by engineers from various component teams. Thus, it is necessary to automatically summarize outages for understanding quickly.</p>
<p>These results motivated us to explore automated ways to improve engineers' understanding of outages. To this end, we propose Oasis, which has two components: impact scope assessment and summary generation. As for impact scope assessment, we adopt three techniques i.e., rule-based, historical lookup, and deep learning based to aggregate relevant incidents to the outage. To embed domain knowledge of cloud systems, engineers implement some linking rules from incidents to outages. To automatically learn the correlations among components of cloud systems, we propose a historical lookup algorithm to form a component graph based on the historical incident linkage and match new incidents in the graph. To capture the rapid evolution of cloud systems, the deep learning based linking approach is used. The impact scope of an outage is composed of the relevant incidents aggregated by these three techniques. We have deployed the impact assessment component of Oasis in Microsoft, which is running for over three years and achieve significant results in impact scope assessment.</p>
<p>After we obtain relevant incidents of the outage, we adopt the most popular pre-trained large language models GPT-3.x (both GPT-3.0 and GPT-3.5), to automatically generate outage summaries. This task presents two main challenges: 1) identifying which information on relevant incidents is helpful to outage summarization; 2) identifying how to effectively generate domain-specific outage summaries with complex cloud-related information. For the first challenge, our empirical study provides some guidelines on summarizing outages, which reveals the importance of incident severity and description. To tackle the second challenge, we fine-tune the pre-trained large language model, which can generate human-readable sentences and embed with knowledge from cloud systems.</p>
<p>To investigate the effectiveness of Oasis, we conduct extensive experiments using real-world outages from Microsoft. The results show that Oasis is able to effectively and efficiently generate outage summaries and titles for cloud systems, and significantly outperform all the compared approaches [22, 27]. More specifically, Oasis achieves scores of 0.665 (BLEU-4), 0.742 (ROUGE-L), and 0.734 (METEOR) with its summarization which outperforms state-of-the-art approaches by at least 32.3%. Furthermore, to investigate the usefulness and readability of our generated summaries, we conduct a preliminary human evaluation involving 54 outage owners. Based on the rankings of summaries produced by models and the original OCEs, we find that Oasis can achieve human-level summaries much more quickly (251.2 times faster than the median of manual summarization).</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The timeline of handling an outage, where multiple incidents should be summarized when declare the outage.</p>
<p>Based on the above results, the Oasis outage assessment component has already been in usage for over three years at Microsoft, while the more recent summarization component has been now prototyped and used by some of the incident teams at Microsoft in a phase preceding the final rolling in production.</p>
<p>To sum up, our work has the following contributions:</p>
<ul>
<li>We are the first to identify outage understanding, a practical scenario for large-scale cloud services. We have conducted an empirical study of 18 cloud systems to investigate this scenario.</li>
<li>We propose Oasis, the first automated approach to tackle the problem of outage understanding based on impact scope assessment and large language models (LLMs). We are the first to propose LLM-based summary generation of outages.</li>
<li>Our impact scope assessment of Oasis has deployed in Microsoft for over three years and achieved significant impact. We conduct an extensive study and human evaluation to demonstrate the efficacy and potential usage of Oasis.</li>
</ul>
<h2>2 BACKGROUND</h2>
<p>Cloud systems. Cloud systems have become increasingly popular in recent years, as they offer a range of benefits such as scalability, accessibility, and cost-efficiency. To ensure the reliability of these systems, engineers use various monitoring tools and techniques, e.g., Azure Monitor, to track and analyze the performance and health of different levels and components of the cloud system [10, 14]. If the monitors detect anomalies, incidents will be reported.
Incidents. Incidents are unplanned interruptions to cloud service. Incident Management is the process of logging those interruptions, and resolving those in a timely manner [5, 7, 10, 16, 19, 20]. An incident is reported with many fields, for example, the service that the incident is defined on, the source of the incident creation, the time of the incident creation, and a text field describing the problem. The text description can be generated by the monitor based on predefined templates or filled in manually by the engineers. Moreover, engineers assign a severity level to each incident, ranging from 0 to 4 , where a severity of 0 means highest priority and large customer impact, and a severity of 4 means lowest priority.
Outages. Outages are severe incidents that require collaboration across many services or result in customer impact [9, 29]. Different products and teams may define outages differently depending on service level agreements (SLAs), customer expectations, or other criteria. When an outage happens, it tends to affect various aspects of the cloud system, causing many incidents to be reported. OCEs need to go through these incidents to fully understand the outage.</p>
<p>IcM system. To facilitate mitigating and resolving outages, our collaborated Microsoft has developed an Incident Management system (IcM) for cloud systems. After a monitor reports an incident, an associated incident is created on the IcM. Then engineers can discuss the incident, check the information, and update the status of the incidents on the IcM page, etc. An incident may escalate and is declared as an outage if it impacts multiple services or customers as shown in Figure 1. During these processes, records of incidents and logs of the actions are persistently stored in the IcM database.</p>
<h2>3 OUTAGE UNDERSTANDING: A CASE STUDY</h2>
<p>To better understand the impact of outages and the need for automatic support in outage scope and summary production, we conduct a case study on real-world outages and their summaries. To this end, we collect outages from 18 systems over three years in the IcM database of Microsoft, which serves millions of daily users worldwide, specifically, outages and relevant incidents that occurred between January 1, 2020 and October 1, 2022. To ensure that the outages have undergone careful examination and their summaries are ready, we keep over 6000 outages whose state is 'MITIGATED' or 'RESOLVED' during collection. We are not able to make all the details public due to the company's policy.</p>
<p>In this study, we address the following research questions:</p>
<ul>
<li>RQ1: What is the impact of outages?</li>
<li>RQ2: What are the information included in outage summaries?</li>
<li>RQ3: What is the cost (in terms of time) of manually summarizing outages?</li>
</ul>
<h3>3.1 RQ1: Impact of Outages</h3>
<p>Impact on customers. When OCEs deal with outages, it is important to decide the impact on customers, especially the number of customers affected. For each outage, OCEs determine whether it impacts a large number of users and record this determination. We statistically analyze the outages that OCEs considered as impacting a large number of users and found that such outages accounted for as much as $86.4 \%$ of all outages. Outages usually have a significant impact on cloud systems, resulting in a degraded user experience for a large number of customers. Therefore, it is crucial to quickly and effectively respond to outages.</p>
<p>Another aspect of the customer impact is whether an outage has resulted in persistent impacts. OCEs mark the outages that have persistent or intermittent impacts with a flag variable. The number of outages resulting in persistent impacts is 1.81 times more than the number of outages that have intermittent impacts. The impact of an outage on a cloud system is frequently severe.
Relevant incidents. Several incidents in cloud systems are continuously reported and escalate to one outage, as they share a common root cause. The distribution of incidents associated with outages is illustrated in Figure 2(a), with $25 \%$ of outages having more than 10 associated incidents. The average number of relevant incidents to an outage is 9.36 . Based on this data, the outages bring about many incidents, consuming the efforts and time of the OCEs.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: CDF of (a) Number of relevant incidents to outages. (b) Time to Summary (TTS).</p>
<h3>3.2 RQ2: Outage Summary Information</h3>
<p>To help understand what information needs to be summarized for an outage, we demonstrate a real-world outage summary written by OCEs and its relevant incidents. We mask several details due to confidentiality.</p>
<p>Incident 1 Title: Alert: email-api-batchevents-errors-production-allregions-exceeded
Description: The Email Service was experiencing connectivity issues to their replica database in the West US Region. Due to this issue, System-Cloud customers globally were not receiving any type of System-Cloud notifications.
Severity: 2
Start time: 14:28
Service: SQL</p>
<p>Incident 2 Title: No Success Signal in the last 60 minutes.
Description: Calls to the API-Sub failed with a 5xx HTTP error. Approximately $\alpha_{1}$ customers could not upgrade their subscriptions on URL-Cloud-Portal.
Severity: 2
Start time: 15:30
Service: Commercial</p>
<p>Incident 3 Title: System-Cloud Email Orchestrator Health in Cluster $_{1}$
Description: Email notifications sent to customers could be delayed.
Severity: 3
Start time: 14:33
Service: Business Intelligence</p>
<p>Incident 4 Title: Api request failed with multiple -1 responses. Target: URL-Cloud-Email
Description: Calls to the API-Marketplace service failed which prevented the service from sending emails to the customers and affected $\alpha_{2}$ customers.
Severity: 3
Start time: 17:06
Service: Marketplace</p>
<p>Incident 5 Title: Email Service calls are failing for Monitor-Email-Exceptions evaluated on MonitorRule ${ }_{1}$ unhealthy
Description: Customers could not view Customer renewal and subscription alerts were delayed. In addition, users were unable to get authentication codes to verify login and new account sign-ups.
Severity: 3
Start time: 14:44
Service: Notification</p>
<p>The title, times, and summary of the outage are listed below:</p>
<p>Outage Title: Outage for Email Service - Triage
Impact start time: 14:20
Outage declared time: 14:28
OCEs engage time: 14:29
Outage Summary: The Email Service experienced connectivity issues to their replica database in the West US Region. This affected customer email delivery for approximately $\alpha_{3}$ internal company services. Due to this issue, System-Cloud customers were not receiving notifications including purchase, renewal, and monitor alert notifications. The Portal team reported that approximately $\alpha_{1}$ customers were unable to upgrade their subscriptions on URL-Cloud-Portal.</p>
<p>We can see from the above example that each relevant incident describes various aspects of the outage, and the information about an outage fall into many different categories. For example, West US Region is a physical location, and [System-Cloud, Email Service, API-Marketplace] are software components at different layers that are affected, and $\left[\alpha_{1}, \alpha_{2}, \alpha_{3}\right]$ are specific numbers describing the number of impacted customers or services, and $5 x x$ HTTP error is a software bug that affects the service functionality. Formally, the information of an outage usually involves 5 W (when, where, who, what, why):
When. When does the outage start impact, get declared, and engaged? Engineers pay attention to several time points and periods of an outage. For example, the time when the outage starts to make an impact, when the outage is declared, and when the OCEs start to engage are important signals for assessing the availability and reliability of the system. Additionally, when assessing the impact of an outage, it is also useful to know the time window period when a certain function is unavailable.
Where. Where does the outage come from? The physical location of an outage can lie in various levels of the cloud infrastructure. The physical location can have an impact on the time required to resolve it and the potential for cascading failures. Additionally, the physical location of an outage can be a key factor in determining the impact on customers, as local or nearby customers may be affected more severely. The physical location of the cloud infrastructure at Microsoft is structured in a hierarchical manner [18] with regions and availability zones at the top level, which is directly accessible to customers. Each region can consist of up to three availability zones, each containing one or more datacenters. These datacenters
are further divided into clusters. Despite the fact that other cloud systems may exhibit different location hierarchies, it is as important to know the location of outages.
Who. Which services are suffering from the outage? Services of cloud systems can be divided into different layers: (1) application layer: this layer contains the actual code and functionality of the cloud system, where frontend and backend services are located, (2) platform layer: this layer provides the operating system, middleware, and runtime environment for the cloud system, which may include virtualization software, container orchestration software, or serverless computing framework, (3) data layer: this layer handles the storage and management of data used by the cloud system, which may include databases, data lakes, and data warehouses, (4) infrastructure layer: this layer provides the underlying physical and virtual resources that are used to run the cloud system, which includes host servers, storage, and networking. Each layer has its fine-grained components. Assessing which parts of the cloud system are affected by the outage is helpful to handle the outages.
What. What happens to the cloud system in the outage? Previous research has shown [14] some common symptoms of outages, including: (1) code bugs, such as buggy or incompatible code that generates error results, (2) dependency failures, such as an unhealthy dependent service that impacts the functioning of downstream services, (3) infrastructure issues, such as high CPU utilization of a server that prevents the service from functioning normally, (4) deployment errors, such as an engineer deploying an incorrect certificate. There are also other less frequent symptoms, such as configuration bugs, database/network issues, authentication failures, etc.
Why. Why did the outage happen? Previous research has investigated the four most common root causes of outages [21]: (1) insufficient or erroneous mechanism of fault handling (e.g., error component, unresponsive component, and silent corruption), (2) data format incompatibility between different software components, (3) timing(e.g., concurrent) bugs, and (4) misconfigured or outdated constant values. However, the bugs in production cloud systems are highly diversified. The underlying causes of misbehavior require thorough manual investigation by OCEs.
Focus of outage summarization. We can see from the example that the summary of an outage is not simply a list of information. OCEs when writing outage summaries are more favorable to highseverity incidents. Moreover, textual description is an important reference in the outage summarization process. For example, the dashed sentences are taken directly from the textual descriptions of two high-severity incidents, i.e., Incident 1 and 2.
Finding: High-severity incidents and their textual descriptions are important in outage summarization.</p>
<h3>3.3 RQ3: Time to Summary</h3>
<p>After an outage starts to make an impact on customers, OCEs need to quickly respond to the outage. One key step is to summarize the context of the outage. Therefore, we investigate the time to manually write outage summaries. Specifically, we retrieved the impact start time (T1 in Figure 1) of the outage and its summary completed time (T2). The time needed to summarize outages is calculated by $\mathrm{T} 2-\mathrm{T} 1$.</p>
<p>Figure 2(b) shows the CDF of the time needed to summarize outages. From this figure, there are nearly $23 \%$ of outages cannot be summarized within two time units after the outage starts. The median time needed to summarize outages is one time unit. Therefore, outage summarization is time-consuming and labor-intensive.</p>
<h3>3.4 Summary</h3>
<p>According to our empirical study, the impact summary of an outage may include domain specific terminology of physical or logical locations, service name, code change name, etc. Besides, what and why of outages are even more difficult to summarize simply using templates. OCEs must have a thorough grasp of the relevant incidents in order to effectively summarize an outage, and the text descriptions of these incidents provide crucial information for this comprehension. Nowadays, pretrained large language models (e.g., GPT-x) show their ability in many tasks, such as Q\&amp;A and summarization in ChatGPT. Therefore, we aim to employ large language models to help outage summarization. In this work, we aim to generate outage summaries with the following goals:
Usefulness. Usefulness measures whether the outage summary contains relevant and valuable information.
Readability. Readability measures whether the outage summary read fluently, especially considering the context information of the outage and the affected system.
Reducing TTS (time to summary). It is desirable to summarize outage in a short time because it helps improve the overall outage handling process, improve communnication, shorten the lifecycle of outage, and in turn, improve customers' satisfaction.</p>
<h2>4 OUR PROPOSAL: OASIS</h2>
<h3>4.1 Overview</h3>
<p>In this paper, we aim to automatically generate summaries for outages of cloud systems. However, outage summarization faces two challenges. The first challenge is determining which information on relevant incidents is helpful to outage summarization. Since the cloud system is complex and rapidly growing, it is not trivial to extract domain-specific terminologies of incidents. The second challenge is how to effectively generate human-readable outage summaries with complex cloud-related information.</p>
<p>To solve these challenges, we propose OASIs. The overview of OASIs is shown in Figure 3, which consists of the following two components. In the first component, i.e., impact scope assessment, OASIs identifies relevant incidents via three types of linking to comprehensively assess the impact of the outage. In the second component, i.e., summary generation, OASIs first performs domain-specific text processing to denoise and prioritize important information from the obtained relevant incidents, thus addressing the first challenge. Then OASIs employs a fine-tuned large language model, i.e., GPT3.x, to understand the incidents and generate a compact summary for the outage, thus addressing the second challenge.</p>
<h3>4.2 Impact Scope Assessment</h3>
<p>Assessing the impact scope of an outage is about comprehensively understanding different aspects of an outage such as the when, where, who, what, why, etc. As shown in Section 3, the impact
of these aspects of the outage is collectively described by many relevant incidents. However, there is no simple and direct way to identify the set of relevant incidents, since incidents with the same underlying root cause can have different properties and spread across services. Meanwhile, if an OCE determines two incidents are highly relevant to each other, she can formally link the two incidents together, which is a feature provided by the IcM system. Linking an incident with relevant incidents reduce the effort of OCEs in many ways, for example, reducing the number of incidents that require manual examination, auto-resolving less severe incident if a more severe linked incident is resolved, etc.</p>
<p>Inspired by the process, OASIs assesses the impact scope of an outage by linking its relevant incidents. To completely link the relevant incidents of an outage, OASIs incorporates domain knowledge and historical linking patterns. Specifically, OASIs performs three types of incident linking: linking by rule, linking by historical lookup, and linking by prediction model.
Linking by rules. Automated incident linking is a capability in IcM that correlates and de-duplicates incidents to reduce alert storms and noise. Engineers can set up specific rules to create links between incidents upon various triggers, which represent the domain knowledge of the engineers. For example, an engineer can set up a rule to have incidents that are triggered by the same KPI anomaly be linked. These are structural incident links that can be directly queried from the IcM database. During the operation of cloud systems and the corresponding IcM system, a large number of historical incidents and rule-based links are persistently recorded. These data are a natural source of labeling for learning, which facilitates the following two types of linking.
Linking by historical lookup. We propose a heuristic lookup mechanism to utilize the historical links between incidents. The mechanism consists of an offline phase to memorize the historical linking pattern, and an online phase to apply the patterns to current incidents. In each phase, we use the field of component that is reported along with the incident. Components are fine-grained parts of cloud systems that are defined by engineers. In the offline phase, we build a component linking graph by summing up links between incidents, i.e., if incident A and incident B are linked, then we link their component in the component graph. In the online phase, we check whether there are active incidents (incidents within a short time range) on the linked components.
Linking by prediction model. Another way to automatically discover the relationship between incidents is by employing deep learning techniques [8, 17]. It has the advantage of being highly automated and can be applied to a large number of incidents. Also, it can be applied to scenarios where new incident detection criteria are created and the engineers have not set up rules and historical links fail to apply because of the lack of historical data. We train a neural network to predict the link between incidents. The neural network takes the titles and descriptions of two incidents as input and outputs the similarities between the titles. If the similarity of two incidents is larger than a threshold, we determine the two incidents are linked. The neural network has been trained on pairs of incidents to learn the relationships between incident linking and incidents' titles and descriptions. In the training set, incident pairs</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Overview of OASIS.
that were actually linked by engineers are labeled positive and pairs that were not linked are labeled negative.
Put them together. OASIS periodically assesses relevant incidents to the outage by querying the information of incidents within a time window to the outage. We take advantage of three linking approaches: the rule-based linking has the highest confidence and interoperability; the historical lookup may find hidden dependencies; the prediction model can adapt to the rapid evolution of cloud systems. Together, these three linking approaches link an outage to a set of relevant incidents, which will be used to generate the outage summary.</p>
<h3>4.3 Summary Generation</h3>
<p>After gathering relevant incidents of an outage, OASIS generates a summary of the outage based on the incidents' information. To overcome the challenge of noisy information, we fine-tune an LLM, i.e., GPT-x, to summarize the relevant incidents.</p>
<p>GPT-x. Generative Pre-trained Transformer x (GPT-x) [3] is a large pretrained language model that can tackle a wide range of natural language processing (NLP) tasks. One typical usage scenario of GPT-x is text completion, where the model is given a block of text as context and generates text as the completion of the context. It has been explored to recommend the root causes of cloud incidents [2].</p>
<p>The GPT-x model is based on Transformers [28], which takes advantage of the attention mechanism to assign weights to different parts of the text. Thus it is suitable to summarize noisy information. There are different sizes (number of parameters) of GPT-x model. In our work, we implement OASIS with two parameter sizes: GPT-3-Curie and GPT-3.5-DaVinci (see Section 5.4 for more details).
Domain-specific text processing. In this step, we process the structural incident information into a paragraph of text so that the GPT-3 model can take it as input, i.e., context. Inspired by the findings from Section 3, we propose to process incidents in a way that the high-severity incidents and textual descriptions are emphasized. First, we sort the relevant incidents by their severity so that the incidents with higher severity precede the ones with lower severity. Then we transform the incidents into a piece of text in the following way: for the incident with sorted order $i$, the text is [ The title of $i^{\text {th }}$ incident is $\ldots$. The description of $i^{\text {th }}$ incident is $\ldots$. The
service of $i^{\text {th }}$ incidents is $\ldots \ldots$.] Finally, we append an instruction to the end of the text to hint the GPT-3 model to generate a summary: [The outage summary is:].
Fine-tuning. The GPT-3 model was trained on a general corpus that allows the model the learn various knowledge like linguistics, common knowledge, factual knowledge, basic logical inference ability, etc. To achieve better summary generation, we use our IcM-specific data to fine-tune the GPT-3 model so that it learns the domain knowledge of the applied cloud system and incidents. Moreover, the training samples presented to the model teach it to emphasize the aspects that are of interest to OCEs, thereby improving its ability to summarize information from noisy sources. The data we use to fine-tune the model is in the same form of summary generation, i.e., for each outage, we provide the relevant incidents as context and the outage summary written by engineers as the desired completion.</p>
<h3>4.4 System Implementation</h3>
<p>We have deployed OASIS as an aid to the IcM system of Microsoft. We will introduce the integration of OASIS with the IcM workflow and the underlying implementation details.</p>
<p>The implementation of OASIS in production consists of four parts, as shown in Figure 4. The OASIS backend periodically queries the local database to get active incidents within the time window, as well as rule-based and historical-lookup links of all current outages (1). On receiving the API call initiated by the IcM Backend querying a specific outage, the OASIS backend applies the prediction model to determine what other incidents should be linked to the outage (2). After that, it performs domain-specific text processing for the outage's relevant incidents and feeds the processed text to the finetuned GPT-3.x model (3). Finally, the backend returns the summary generated by GPT-3.x to the IcM Backend.</p>
<p>The local database of OASIS is ingested from the IcM database in a streaming manner. Compared to batch ingestion, streaming ingestion is more smooth in resource utilization. Moreover, the linking requires real-time data records of incidents. The prediction model has already been trained in ML-dedicated servers and exported as a binary file to minimize the operation effort of OASIS in production.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: OASIS in production. The upper part is the IcM system. The lower part is the architecture of OASIS.</p>
<h2>5 OASIS EVALUATION: EMPIRICAL STUDY DESIGN</h2>
<p>To assess the effectiveness of OASIS, we investigate the following:</p>
<ul>
<li>RQ4: Is OASIS effective at summarizing outages?</li>
</ul>
<p>Generating the summary of outages is the main task of OASIS. We are interested in the ability of OASIS to generate a reasonable outage summary with automatic impact scope assessment.</p>
<ul>
<li>RQ5: Is OASIS effective at proposing outage titles?</li>
</ul>
<p>The title of an outage is a short, highly abstracted piece of text stating the problem that is happening. Proposing outage titles also demonstrates the ability of OASIS to understand and summarize the outage.</p>
<ul>
<li>RQ6: Does OASIS get better at summarizing outages if the outage title is given?
In practical settings, OCEs first write the title of an outage and then write the summary of the outage. We are interested in whether OASIS can better summarize an outage if the title written by OCEs is also given as part of the context.</li>
<li>RQ7: What is the time efficiency of OASIS?</li>
</ul>
<p>Since OASIS needs to work in the production environment, it is important for OASIS to summarize outages efficiently.</p>
<h3>5.1 Study data</h3>
<p>In the study, we applied OASIS to the same 18 cloud systems and the same time range ( 3 years) in Section 3.1 to evaluate the effectiveness of OASIS. In particular, we split the data in chronological order using a 7:1:2 ratio for the training (fine-tuning), validation, and test sets, respectively. Each data point, representing an outage, is presented as a context-completion pair. The context consists of the processed text from relevant incidents linked by impact scope assessment. The completion, on the other hand, is provided as the summary of the outage written by OCEs.</p>
<h3>5.2 Compared approaches</h3>
<p>To better answer the RQ 4 to 7, we compare the performance of OASIS with some baseline approaches. We formulate the task as a text generation problem, therefore we compare with 3 methods that have been proven capable of generating summarization. In answering each research question, we provide the same context (information of relevant incidents) to the baselines and to the GPT-3 model of OASIS.</p>
<ul>
<li>Joint incident summary (Rule-based): A straightforward rulebased method that concatenates all the information of incidents.</li>
</ul>
<p>This method imitates the behavior that OCEs read through relevant incidents when handling outages.</p>
<ul>
<li>Information retrieval (IR): NNGen [22] leverages bag-of-words embedding and nearest neighbor to retrieve summaries from similar history outages.</li>
<li>GPT-2: Generative Pre-training Transformer 2 (GPT-2) is a language model that is trained to generate coherent text. We use GPT-2 with 117 M parameters.</li>
</ul>
<h3>5.3 Metrics</h3>
<p>Following the existing work [1, 2, 15], we use the BLEU-4, ROUGEL, and METEOR to evaluate OASIS and its baselines in terms of readability. The BLEU-4 compares the matching of n-grams between generated text and the ground truth. The ROUGE-L is widely used in Machine Translation evaluation, which measures the overlap of the longest sequence between hypothesis and reference. The METEOR calculates the harmonic mean of unigram precision and recall with consideration of stemming and synonym matching.</p>
<p>Specifically, we get five candidate generated texts from each model, except for the joint incident summary which can only give one piece of generation. To better evaluate the quality of generation models, we calculate the Top1 metrics using the first generated text, and the Top5 metrics using the best of five generated text.</p>
<p>We also measure the running time of each approach. Specifically, we record the overall time needed to train/fine-tune the model, and the average time spent on generating a summary for an outage.</p>
<p>To further evaluate usefulness and readability, we conduct a human evaluation in Section 7. When summarizing outages, the style of OCEs can vary from generic to specific. Automatic metrics only compare the models' suggestions with a single reference, while other versions of the summary can be useful and relevant as well, so these metrics may not fully capture the performance of models. To better evaluate the model's performance, we went to the owners (responsible engineers) of the outages and presented the outputs of our models and baselines. We will discuss our methodology and findings from the human evaluation in Section 7.</p>
<h3>5.4 Experiment environment</h3>
<p>Generation model. We implement OASIS with two GPT-3 variants, i.e., Curie and DaVinci:</p>
<p>Curie (GPT-3) is a fast GPT-3 model with 6.7 billion parameters, which was pre-trained on a natural language corpus.
DaVinci (GPT-3.5) is a large GPT-3 model with 175 billion parameters, which was pre-trained on both text and code.
We fine-tune these generation models using the training and validation set from Section 5.1.</p>
<p>Experiment environment. We implement all training with one NVIDIA GeForce A100 GPU, PyTorch 1.11, and CUDA toolkit 11.3.1.
Implementation of baselines. Baselines are implemented using Python 3.8 and scikit-learn 1.0.2. The number of GPT-2's training epochs is 20 . The temperature is GPT-2 is 0.7 , which is recommended by a previous study [2].</p>
<p>Table 1: Effectiveness of models at summarizing outages</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">BLEU-4</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">ROUGE-L</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">METEOR</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Top1</td>
<td style="text-align: center;">Top5</td>
<td style="text-align: center;">Top1</td>
<td style="text-align: center;">Top5</td>
<td style="text-align: center;">Top1</td>
<td style="text-align: center;">Top5</td>
</tr>
<tr>
<td style="text-align: center;">IR</td>
<td style="text-align: center;">0.042</td>
<td style="text-align: center;">0.051</td>
<td style="text-align: center;">0.144</td>
<td style="text-align: center;">0.180</td>
<td style="text-align: center;">0.115</td>
<td style="text-align: center;">0.146</td>
</tr>
<tr>
<td style="text-align: center;">Rule-based</td>
<td style="text-align: center;">0.277</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">0.508</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">0.629</td>
<td style="text-align: center;">NA</td>
</tr>
<tr>
<td style="text-align: center;">GPT-2</td>
<td style="text-align: center;">0.455</td>
<td style="text-align: center;">0.51</td>
<td style="text-align: center;">0.561</td>
<td style="text-align: center;">0.592</td>
<td style="text-align: center;">0.536</td>
<td style="text-align: center;">0.574</td>
</tr>
<tr>
<td style="text-align: center;">Curie</td>
<td style="text-align: center;">0.654</td>
<td style="text-align: center;">0.701</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.777</td>
<td style="text-align: center;">0.721</td>
<td style="text-align: center;">0.767</td>
</tr>
<tr>
<td style="text-align: center;">DaVinci</td>
<td style="text-align: center;">0.664</td>
<td style="text-align: center;">0.706</td>
<td style="text-align: center;">0.742</td>
<td style="text-align: center;">0.782</td>
<td style="text-align: center;">0.734</td>
<td style="text-align: center;">0.776</td>
</tr>
</tbody>
</table>
<h2>6 OASIS EVALUATION: EMPIRICAL STUDY RESULTS</h2>
<h3>6.1 RQ4: Performance of Summary Generation</h3>
<p>Table 1 lists the effectiveness of baselines and OASIS in summarizing outages. OASIS with DaVinci, the largest GPT-3 model, achieves the best metrics with both Top1 and Top5 summary generation. The advantage of DaVinci over Curie comes from the larger parameter size and the extra code corpus used in pretraining since some incidents contain API names or investigating code. However, the performance gain of DaVinci over Curie, the fastest GPT-3 model, is modest in both Top1 and Top5 generations.</p>
<p>We observe IR method is especially not suitable for outage summary generation. The major reason that the scores of IR are poor is that the rapid evolution of cloud systems has resulted in significant changes in the architecture of the systems over time, so similar outages are not likely to appear repeatedly, therefore historically useful summaries fail to depict the new outages. Although Rulebased summaries have a higher METEOR score than GPT-2, their BLEU-4 score is far lower than that of GPT-2. This is because the METEOR score takes into account the precision and recall of the unigram rather than subsequences, resulting in a more lenient evaluation of summaries. Rule-based summaries are often too long as the original incidents, which is not helpful for engineers to understand the context of outages.</p>
<h3>6.2 RQ5: Performance of Title Generation</h3>
<p>The title of an outage is a compact description of the outage. The example of an outage title and summary is shown in Section 3.2. The performance of baselines and OASIS at summarizing outages in the form of titles are listed in Table 2. By comparing Table 2 with Table 1, we achieve a higher generation score ( $0.826-0.857$ BLEU-4) at generating titles for outages than generating the whole summary ( $0.654-0.664$ BLEU-4). Similarly, GPT2, which is also a large Transformer based language model, scores higher in summarizing outages in the form of a title than the whole summary. The ROUGEL and METEOR score exhibit the same trend for OASIS and GPT-2. The reason for this performance improvement lies in the nature of outage title and summary. The title of outage has a stronger pattern than that of outage summary. Firstly, a large portion of outage titles starts with "Outage for". This pattern is easy for LLM to learn, so the titles generated by LLM tend to have more overlapping words, and consequently, higher scores. Secondly, the words used in titles are usually either in a dictionary (e.g., the "Triage" in the example title), or have been mentioned in incidents (e.g., the "Email Service" in the example title).</p>
<p>Table 2: Effectiveness of models at proposing outage titles</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">BLEU-4</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">ROUGE-L</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">METEOR</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Top1</td>
<td style="text-align: center;">Top5</td>
<td style="text-align: center;">Top1</td>
<td style="text-align: center;">Top5</td>
<td style="text-align: center;">Top1</td>
<td style="text-align: center;">Top5</td>
</tr>
<tr>
<td style="text-align: left;">IR</td>
<td style="text-align: center;">0.170</td>
<td style="text-align: center;">0.211</td>
<td style="text-align: center;">0.398</td>
<td style="text-align: center;">0.427</td>
<td style="text-align: center;">0.342</td>
<td style="text-align: center;">0.369</td>
</tr>
<tr>
<td style="text-align: left;">Rule-based</td>
<td style="text-align: center;">0.069</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">0.211</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">0.316</td>
<td style="text-align: center;">NA</td>
</tr>
<tr>
<td style="text-align: left;">GPT-2</td>
<td style="text-align: center;">0.624</td>
<td style="text-align: center;">0.673</td>
<td style="text-align: center;">0.672</td>
<td style="text-align: center;">0.694</td>
<td style="text-align: center;">0.639</td>
<td style="text-align: center;">0.688</td>
</tr>
<tr>
<td style="text-align: left;">Curie</td>
<td style="text-align: center;">0.826</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">0.84</td>
<td style="text-align: center;">0.894</td>
</tr>
<tr>
<td style="text-align: left;">DaVinci</td>
<td style="text-align: center;">$\mathbf{0 . 8 5 7}$</td>
<td style="text-align: center;">$\mathbf{0 . 8 9 3}$</td>
<td style="text-align: center;">$\mathbf{0 . 8 8 3}$</td>
<td style="text-align: center;">$\mathbf{0 . 9 1 3}$</td>
<td style="text-align: center;">$\mathbf{0 . 8 6 9}$</td>
<td style="text-align: center;">$\mathbf{0 . 9 0 7}$</td>
</tr>
</tbody>
</table>
<p>Another observation is that title generation is the only task where IR outperforms the Rule-based method. Since the Rule-based method performs simple concatenation, the generated title is long and contains unnecessary words, thus resulting in lower scores, while IR method retrieves titles from historical outages which conforms better with the pattern of outage titles in general. OASIS achieves significantly high scores, with considerable improvement over baselines (at least $30.0 \%$ of BLEU-4, $30.9 \%$ of ROUGE-L, $31.4 \%$ of METEOR), indicating that applying OASIS to production outages title generation is very promising.</p>
<h3>6.3 RQ6: Performance of Summary Generation Given Title</h3>
<p>We evaluate the performance of the outage summary generation when the title of the outage is given. Remember that we provide the information of relevant incidents to these methods as context. In this experiment, we include the title written by OCEs as part of the context. For GPT-2 and OASIS where there is an instruction in the context ([The outage summary is:]), we insert the outage title between incident information and the prompt.</p>
<p>The results of this experiment are listed in Table 3. Surprisingly, the performance of OASIS, GPT-2, and Rule-based degrade slightly in this setting, with the exception of IR, whose metrics remain as low as before. The relative order of methods in Table 3 keeps the same as Table 1, for their tasks are very similar. The performance degradation is because the title of the outage is not a grammaticallycomplete sentence.</p>
<h3>6.4 RQ7: Efficiency Comparison</h3>
<p>Table 4 lists the fine-tuning (if any) and summary generation times for each model. The fine-tuning time reflects the total time spent on all outages from the training set, while the summary generation time is the average time taken to generate a summary for one outage. Despite the differences in parameter size, all models have a very small generation time. The fine-tuning time for LLMs (GPT-2, Curie, DaVinci) increases as the parameter size increases, although not linearly. Please note that OASIS only needs to be fine-tuned once on historical outages and incidents and can then be used for outage summary generation. In other words, the time to generate an outage summary of OASIS is only 13.3 or $39.6\left(\times 10^{-5}\right)$ time units, which is at least 251.2 times faster than the median of manual summarization. In conclusion, the fine-tuning time for Oasis is reasonable, and its short generation time of summary demonstrates its practicality in cloud systems.</p>
<p>Table 3: Effectiveness of models at generating outage summaries given outage titles</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">BLEU-4</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">ROUGE-L</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">METEOR</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Top1</td>
<td style="text-align: center;">Top5</td>
<td style="text-align: center;">Top1</td>
<td style="text-align: center;">Top5</td>
<td style="text-align: center;">Top1</td>
<td style="text-align: center;">Top5</td>
</tr>
<tr>
<td style="text-align: center;">IR</td>
<td style="text-align: center;">0.037</td>
<td style="text-align: center;">0.055</td>
<td style="text-align: center;">0.156</td>
<td style="text-align: center;">0.189</td>
<td style="text-align: center;">0.109</td>
<td style="text-align: center;">0.142</td>
</tr>
<tr>
<td style="text-align: center;">Rule-based</td>
<td style="text-align: center;">0.247</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">0.505</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">0.614</td>
<td style="text-align: center;">NA</td>
</tr>
<tr>
<td style="text-align: center;">GPT-2</td>
<td style="text-align: center;">0.428</td>
<td style="text-align: center;">0.504</td>
<td style="text-align: center;">0.548</td>
<td style="text-align: center;">0.59</td>
<td style="text-align: center;">0.515</td>
<td style="text-align: center;">0.569</td>
</tr>
<tr>
<td style="text-align: center;">Curie</td>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">0.697</td>
<td style="text-align: center;">0.729</td>
<td style="text-align: center;">0.776</td>
<td style="text-align: center;">0.719</td>
<td style="text-align: center;">0.764</td>
</tr>
<tr>
<td style="text-align: center;">DaVinci</td>
<td style="text-align: center;">0.652</td>
<td style="text-align: center;">0.699</td>
<td style="text-align: center;">0.734</td>
<td style="text-align: center;">0.779</td>
<td style="text-align: center;">0.724</td>
<td style="text-align: center;">0.77</td>
</tr>
</tbody>
</table>
<p>Table 4: Average time cost of models</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Time</th>
<th style="text-align: left;">Rule</th>
<th style="text-align: left;">IR</th>
<th style="text-align: left;">GPT-2</th>
<th style="text-align: left;">Curie</th>
<th style="text-align: left;">DaVinci</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Fine-tuning <br> $\left(10^{-1} \times\right.$ time unit)</td>
<td style="text-align: left;">NA</td>
<td style="text-align: left;">NA</td>
<td style="text-align: left;">3.0</td>
<td style="text-align: left;">3.4</td>
<td style="text-align: left;">8.7</td>
</tr>
<tr>
<td style="text-align: left;">Generation <br> $\left(10^{-5} \times\right.$ time unit)</td>
<td style="text-align: left;">2.8</td>
<td style="text-align: left;">13.9</td>
<td style="text-align: left;">11.1</td>
<td style="text-align: left;">13.3</td>
<td style="text-align: left;">39.6</td>
</tr>
</tbody>
</table>
<h2>7 OASIS PRELIMINARY HUMAN EVALUATION</h2>
<h3>7.1 Methodology</h3>
<p>Summarizing an outage is a challenging task that requires a deep understanding of both the service and the specific outage, as well as a comprehensive knowledge of the relevant context and domain. To ensure the accuracy of the generated summaries, we ask the owners of these outages to evaluate the generated summaries from RQ4. The process is done through Email and eventually, a total of 54 outage owners respond to our email and provide their evaluations.</p>
<p>For each outage, we present the generated summaries from all the methods, with the output of OasIs with Curie and DaVinci treated as independent summaries. This results in five summaries for each outage. We present the outage and the summaries in the following order: (1) first we give the IcM link to the outage so that the outage owner can better recall the details of the outage, (2) next we present the original outage summary written by OCEs and tell the outage owners this is the human-written summarization, (3) then we present the five outage summaries generated by models (Oasis-Curie, Oasis-DaVinci, GPT-2, Rule-based, IR), and we shuffle the order of these summaries to minimize the effect of default ordering. To ensure the objectivity of the evaluation and avoid the subjectivity and bias of scoring for each summary, we ask the outage owners to rank the summaries from 1 to 5 , where 1 for the most useful and readable and 5 for the least useful and readable. Useful means that the summary contains useful and relevant information on the outage. Readable means the ease with which the summary can be understood, which may be characterized by clear and simple language, logical organization, grammatical correctness, etc. Besides ranking, we also ask outage owners to share their opinions and comments on model-generated summaries.</p>
<h3>7.2 Results</h3>
<p>Figure 5 shows the ranking of outage owners. In general, the results of human evaluation are in accordance with automatic metrics presented in Table 1. The outage owners report positive feedback regarding the readability and usefulness of OASIS. Notably, 32 out
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: The ranking given by outage owners. Rank #1 means the most preferred summary.
of 54 OCEs rank the summaries produced by OasIs-DaVinci as their top preference. To investigate whether the rankings of outage owners are consistent with each other, we conduct Friedman Test [12] at the significant level of 0.05 . The null hypothesis is that there is no significant difference between the rankings of outage owners. The calculated p-value on our rank by outage owner is larger than the level of significance, which means that the outage owners basically conform to each other in evaluating the summaries.</p>
<p>More encouragingly, the majority of outage owners have a favorable attitude toward the practice of generating outage summaries using OASIS: "I absolutely believe in the ability of AI to assist with incident management and outage summaries. "</p>
<h2>8 DISCUSSION</h2>
<h2>Case Study</h2>
<p>As described in Section 4.4, OasIs serves as a supportive tool in the production IcM, i.e., OCEs have the option to use or not use OASIS to generate a reference summary when handling outages. Since it is difficult to determine the extent to which OasIs contributes to the generated summary for outages where it is utilized, we randomly selected an outage from recent outages that were handled without the use of OasIs.</p>
<p>In this outage, a misconfiguration of the load balancer led to an overwhelming number of requests being directed to a single service endpoint. As a result, this endpoint was unable to function properly, causing the unified account API to fail. This failure cascaded to the downstream account APIs of the Cloud, Productivity, and Partner systems. As a result, the signup, ordering, and billing services of the Cloud and Productivity systems were affected. Below is the actual outage summary, written by an experienced OCE:</p>
<p>Outage Summary by OCE: The API account failed with HTTP 5xx errors (over $\sigma_{1}$ fall failures) because of bad gateway errors to the endpoint ${ }<em 2="2">{1}$. Due to this issue, commercial customers could not sign-up for System-Cloud or System-Productivity via endpoint ${ }</em>}$ or endpoint ${ <em 4="4">{3}$, and perform management related actions on endpoint ${ }</em>$. Additionally, customers could not complete purchases within these ecosystems. Partner system is also impacted.</p>
<p>Outage Summary by OASIS: The API ${ }<em 1="1">{\text {account }}$ failed with HTTP 5xx errors (over $\alpha</em>}$ fall failures) because of bad gateway errors to the endpoint ${ <em 2="2">{1}$. Due to this issue, commercial customers could not sign-up for System-Cloud or SystemProductivity via endpoint ${ }</em>}$ or endpoint ${ <em 4="4">{3}$, and perform management related actions on endpoint ${ }</em>$ unique users were impacted.}$. Additionally, System-Cloud users were not able to access their billing accounts and invoices on System-Cloud portal. Approximately $\alpha_{2</p>
<p>To study the ability of OASIS in summarizing online outages, we triggered OASIS manually, limiting it to only knowing the information at the time of the outage. OASIS managed to find six relevant incidents, and the generated summary is presented above. (We indicate sentences that diverge from the OCE outage summary by underlining them with wavy lines) In the above summaries, endpoints 1-4 are URLs that serve the API calls. We notice that OASIS failed to identify System-Partner as impacted because the impact of System-Partner can only be determined by knowing the prefix of endpoint ${ }_{4}$ refers to System-Partner. This knowledge is difficult to learn even after the LLM has been fine-tuned using incident and outage corpus. Despite this, we can see from the above example that OASIS is capable of generating reference summaries for outages. In this study, we adopt fine-tuning of the GPT-x models to generate outage summaries, which perform much better than prompt tuning according to our experiment. Because the outage summary is very domain-specific and fine-tuned models may capture the domain knowledge.</p>
<h2>Threats to Validity</h2>
<p>Threats to internal validity mainly lie in our implementation of OASIS and compared approaches. To reduce this threat, we implemented these approaches based on well-established frameworks, which have been described in Section 5.4. Additionally, two authors carefully examined the code and configurations.</p>
<p>Threats to external validity mainly lie in the subjects used in our study. Our study and evaluation are conducted on 18 major cloud systems of Microsoft. Since the incidents and outages we used are only from Microsoft, modifications may be necessary when applying to other incident management systems. However, the cloud systems we used in our experiments include a variety of types, such as infrastructure, productivity, communication, game, search engine, etc. Moreover, these cloud systems serve millions of customers, thus having a certain degree of representativeness. In the future, we plan to extend our evaluations to include more cloud systems.</p>
<p>Threats to the construct validity mainly lie in the evaluation metrics we adopted. Automated evaluation metrics (BLEU4, ROUGE-L, and METEOR) may not fully reflect the readability and usefulness of the outage summary. To address this limitation, we will consider using additional metrics in the future to better measure these factors. Moreover, we reached out to the owners of outages to conduct a human evaluation, and the evaluation results are basically aligned with automated metrics.</p>
<h2>9 RELATED WORK</h2>
<p>Incident storm / outage handling. Handling outages (incident storms) in cloud systems has been widely studied in previous work [8, 11, 17, 29]. A series of works perform incident linking to provide engineers with more relevant information. LiDAR [8] calculates both textual similarity and component similarity to determine whether two incidents should be linked. LinkCM [17] argues that linking customer incidents (reported by customers) with system incidents (reported by monitors) can lead to more efficient incident triage. The above works utilize neural networks to learn from historical linking patterns. GRLIA [11] also employs graph embedding, with additional concerns about node closeness with KPI trend similarities. COT [29] first builds a heuristic dependency graph for the cloud systems based on historical incidents and links. It then finds the corresponding incidents by searching connected nodes in the graph. Another series of works focuses on alert reduction or prioritization [6, 31]. OAS [6] combines semantic and behavioral features of alerts to decide the groups of alerts and then correlate alerts within a time window. Zhao et al. [31] first calculate the textual and topological similarity of alerts to reduce the number of alerts. They then use DBSCAN to group similar alerts and selected the centroid alert of each cluster as the representative incident to show to engineers. Our impact scope assessment is similar to these approaches, and we also include domain-specific knowledge via rule-based incident linking.
Large Language Models (LLM) for Software Engineering. In recent years, the rise of LLM has brought new opportunities to the field of software engineering [2, 13, 25, 26, 30]. Mastropaolo et al. [26] studied the ability of fine-tuned T5 in the following tasks: automatic bug fixing, generation of assert statements in test methods, code summarization, and injection of code mutants. LANCE [25] uses fine-tuned T5 to automatically generate logging statements for Java methods. VulRepair [13] also fine-tune T5 on vulnerability repairs datasets to automatically propose vulnerability fixes. The above works fine-tune LLM on task-specific datasets. Zhang et al. [30] propose to use prompting for LLM to improve code version control. They further integrate k-shot learning to resolve code merge conflicts. GPT-3.x models are used to recommend root causes and mitigation steps to facilitate cloud incident management [2]. Different from previous studies, OASIS is the first work to leverage the capabilities of LLM in to summarize outages for cloud systems.</p>
<h2>10 CONCLUSION</h2>
<p>In this paper, we identify the problem of outage understanding in real-world cloud systems. Through our empirical study on 18 industrial cloud systems, we show that understanding outage is time-consuming and involves complex contexts. To improve the process of outage understanding, we present OASIS, the first framework to automatically assess impacts and summarize outages. OASIS incorporates an assessment of outage impact scope and a fine-tuned large language model, i.e., GPT-3.x. Our experiments on 18 cloud systems within Microsoft demonstrate that OASIS outperforms baseline approaches. We also received feedback from outage owners, which further validates the effectiveness of OASIS.</p>
<h2>REFERENCES</h2>
<p>[1] Toufique Ahmed and Premkumar Devanbu. 2022. Multilingual training for software engineering. In Proceedings of the 44th International Conference on Software Engineering. 1443-1455.
[2] Toufique Ahmed, Supriyo Ghosh, Chetan Bansal, Thomas Zimmermann, Xuchao Zhang, and Saravan Rajmohan. 2023. Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models. In ICSE 2023.
[3] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dharowal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901.
[4] Junjie Chen, Xiaoting He, Qingwei Lin, Yong Xu, Hongyu Zhang, Dan Hao, Feng Gao, Zhangwei Xu, Yingnong Dang, and Dongmei Zhang. 2019. An empirical investigation of incident triage for online service systems. In IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP). IEEE, 111-120.
[5] Junjie Chen, Xiaoting He, Qingwei Lin, Hongyu Zhang, Dan Hao, Feng Gao, Zhangwei Xu, Yingnong Dang, and Dongmei Zhang. 2019. Continuous incident triage for large-scale online service systems. In 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 364-375.
[6] Jia Chen, Peng Wang, and Wei Wang. 2022. Online Summarizing Alerts through Semantic and Behavior Information. In Proceedings of the 44th International Conference on Software Engineering (Pittsburgh, Pennsylvania) (ICSE '22). 1646-1657. https://doi.org/10.1145/3510003.3510055
[7] Junjie Chen, Shu Zhang, Xiaoting He, Qingwei Lin, Hongyu Zhang, Dan Hao, Yu Kang, Feng Gao, Zhangwei Xu, Yingnong Dang, et al. 2020. How incidental are the incidents? characterizing and prioritizing incidents for large-scale online service systems. In Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering. 373-384.
[8] Yujun Chen, Xian Yang, Hang Dong, Xiaoting He, Hongyu Zhang, Qingwei Lin, Junjie Chen, Pu Zhao, Yu Kang, Feng Gao, et al. 2020. Identifying linked incidents in large-scale online service systems. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 304-314.
[9] Yujun Chen, Xian Yang, Qingwei Lin, Hongyu Zhang, Feng Gao, Zhangwei Xu, Yingnong Dang, Dongmei Zhang, Hang Dong, Yong Xu, et al. 2019. Outage prediction and diagnosis for cloud service systems. In The world wide web conference. $2659-2665$.
[10] Zhuangbin Chen, Yu Kang, Liqun Li, Xu Zhang, Hongyu Zhang, Hui Xu, Yangfan Zhou, Li Yang, Jeffrey Sun, Zhangwei Xu, et al. 2020. Towards intelligent incident management: why we need it and how we make it. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 1487-1497.
[11] Zhuangbin Chen, Jinyang Liu, Yuxin Su, Hongyu Zhang, Xuemin Wen, Xiao Ling, Yongqiang Yang, and Michael R Lyu. 2021. Graph-based incident aggregation for large-scale online service systems. In 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 430-442.
[12] Rob Esiinga, Tom Heskes, Ben Peltier, and Manfred Te Grotenhuis. 2017. Exact p-values for pairwise comparison of Friedman rank sums, with application to comparing classifiers. BMC bioinformatics 18, 1 (2017), 1-18.
[13] Michael Fu, Chakkrit Tantithanthavorn, Trung Le, Van Nguyen, and Dinh Phung. 2022. VulRepair: a T5-based automated software vulnerability repair. In Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 935-947.
[14] Supriyo Ghosh, Manish Shetty, Chetan Bansal, and Suman Nath. 2022. How to fight production incidents? an empirical study on a large-scale cloud service. In Proceedings of the 15th Symposium on Cloud Computing. 126-141.
[15] David Gros, Hariharan Sezhiyan, Prem Devanbu, and Zhou Yu. 2020. Code to comment' translation' data, metrics, baselining \&amp; evaluation. In Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering. $746-757$.
[16] Jiazhen Gu, Chuan Luo, Si Qin, Bo Qiao, Qingwei Lin, Hongyu Zhang, Ze Li, Yingnong Dang, Shaowei Cai, Wei Wu, et al. 2020. Efficient incident identification from multi-dimensional issue reports via meta-heuristic search. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and</p>
<p>Symposium on the Foundations of Software Engineering. 292-303.
[17] Jiazhen Gu, Jiaqi Wen, Zijian Wang, Pu Zhao, Chuan Luo, Yu Kang, Yangfan Zhou, Li Yang, Jeffrey Sun, Zhangwei Xu, et al. 2020. Efficient customer incident triage via linking with system incidents. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 1296-1307.
[18] Ori Hadary, Luke Marshall, Ishai Menache, Abhisek Pan, Esaiao E. Greeff, David Dism, Star Dorminey, Shailesh Joshi, Yang Chen, Mark Russinovich, and Thomas Moscibroda. 2020. Protean: VM Allocation Service at Scale. In 14th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2020, Virtual Event, November 4-6, 2020. USENIX Association, 845-861. https://www.usenix.org/conference/osdi20/presentation/hadary
[19] Jiajun Jiang, Weihai Lu, Junjie Chen, Qingwei Lin, Pu Zhao, Yu Kang, Hongyu Zhang, Yingfei Xiong, Feng Gao, Zhangwei Xu, et al. 2020. How to mitigate the incident? an effective troubleshooting guide recommendation technique for online service systems. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 1410-1420.
[20] Liqun Li, Xu Zhang, Xin Zhao, Hongyu Zhang, Yu Kang, Pu Zhao, Bo Qiao, Shilin He, Pochian Lee, Jeffrey Sun, et al. 2021. Fighting the Fog of War: Automated Incident Detection for Cloud Systems. In USENIX Annual Technical Conference. $131-146$.
[21] Haopeng Liu, Shan Lu, Madan Musuvathi, and Suman Nath. 2019. What bugs cause production cloud incidents?. In Proceedings of the Workshop on Hot Topics in Operating Systems. 155-162.
[22] Zhongxin Liu, Xin Xia, Ahmed E Hassan, David Lo, Zhenchang Xing, and Xinyu Wang. 2018. Neural-machine-translation-based commit message generation: how far are we?. In Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. 373-384.
[23] Minghua Ma, Yudong Liu, Yuang Tong, Haozhe Li, Pu Zhao, Yong Xu, Hongyu Zhang, Shilin He, Lu Wang, Yingnong Dang, Saravanakumar Rajmohan, and Qingwei Lin. 2022. An Empirical Investigation of Missing Data Handling in Cloud Node Failure Prediction. In Proceedings of the European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE). $1453-1464$.
[24] Minghua Ma, Zheng Yin, Shenglin Zhang, Sheng Wang, Christopher Zheng, Xinhao Jiang, Hanwen Hu, Cheng Luo, Yilin Li, Nengjun Qiu, et al. 2020. Diagnosing root causes of intermittent slow queries in cloud databases. Proceedings of the VLDB Endowment 13, 8 (2020), 1176-1189.
[25] Antonio Mastropaolo, Luca Pascarella, and Gabriele Bavota. 2022. Using Deep Learning to Generate Complete Log Statements. In Proceedings of the 44th International Conference on Software Engineering (ICSE '22). 2279-2290.
[26] Antonio Mastropaolo, Simone Scalabrino, Nathan Cooper, David Nader Palacio, Denys Poshyvanyk, Rocco Oliveto, and Gabriele Bavota. 2021. Studying the usage of text-to-text transfer transformer to support code-related tasks. In 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, $336-347$.
[27] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog 1, 8 (2019), 9.
[28] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems 30 (2017).
[29] Yaohui Wang, Guozheng Li, Zijian Wang, Yu Kang, Yangfan Zhou, Hongyu Zhang, Feng Gao, Jeffrey Sun, Li Yang, Pochian Lee, et al. 2021. Fast outage analysis of large-scale production clouds with service correlation mining. In 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, 885-896.
[30] Jialu Zhang, Todd Myrkowicz, Mike Kaufman, Ruzica Piskac, and Shavendu K Lahiri. 2022. Using pre-trained language models to resolve textual and semantic merge conflicts (experience paper). In Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis. 77-80.
[31] Nengwen Zhao, Junjie Chen, Xiao Peng, Honglin Wang, Xinya Wu, Yuanzong Zhang, Zikai Chen, Xiangzhong Zheng, Xiaohui Nie, Gang Wang, et al. 2020. Understanding and handling alert storm for online service systems. In 2020 IEEE/ACM 42nd International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP). IEEE, 162-171.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ Due to the company policy, we hide the actual time and normalize it as time unit.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>