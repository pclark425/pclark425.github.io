<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4189 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4189</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4189</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-97.html">extraction-schema-97</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <p><strong>Paper ID:</strong> paper-278710143</p>
                <p><strong>Paper Title:</strong> Large language models in oncology: a review</p>
                <p><strong>Paper Abstract:</strong> Abstract Large language models (LLMs) have demonstrated emergent human-like capabilities in natural language processing, leading to enthusiasm about their integration in healthcare environments. In oncology, where synthesising complex, multimodal data is essential, LLMs offer a promising avenue for supporting clinical decision-making, enhancing patient care, and accelerating research. This narrative review aims to highlight the current state of LLMs in medicine; applications of LLMs in oncology for clinicians, patients, and translational research; and future research directions. Clinician-facing LLMs enable clinical decision support and enable automated data extraction from electronic health records and literature to inform decision-making. Patient-facing LLMs offer the potential for disseminating accessible cancer information and psychosocial support. However, LLMs face limitations that must be addressed before clinical adoption, including risks of hallucinations, poor generalisation, ethical concerns, and scope integration. We propose the incorporation of LLMs within compound artificial intelligence systems to facilitate adoption and efficiency in oncology. This narrative review serves as a non-technical primer for clinicians to understand, evaluate, and participate as active users who can inform the design and iterative improvement of LLM technologies deployed in oncology settings. While LLMs are not intended to replace oncologists, they can serve as powerful tools to augment clinical expertise and patient-centred care, reinforcing their role as a valuable adjunct in the evolving landscape of oncology.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4189.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4189.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SEETrials</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SEETrials (LLM system for safety and efficacy extraction in oncology clinical trials)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-based system reported to automatically extract intervention outcomes (safety and efficacy data) from oncology conference abstracts, enabling rapid synthesis of trial results for clinicians.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Seetrials: leveraging large language models for safety and efficacy extraction in oncology clinical trials.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SEETrials</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An LLM-based information-extraction pipeline applied to oncology conference abstracts to identify and extract intervention outcomes (safety and efficacy). As described in this review, SEETrials processes unstructured abstracts and outputs extracted outcome attributes to facilitate early insight into novel interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>oncology / clinical trials</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>empirical quantitative outcome extraction (trial outcome metrics)</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Not specified in review beyond general 'intervention outcomes' (no explicit equations provided).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Automated text-mining of conference abstracts using an LLM-based extraction pipeline to identify and extract numeric and categorical intervention outcomes (safety and efficacy) from unstructured text.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Reported validation on extracted conference abstract outcomes as system-level specificity and sensitivity (as cited in the review).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>96% specificity, 94% sensitivity (values reported in this review for SEETrials' extraction of intervention outcomes).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not described as a single 'success rate'; reported performance metrics above indicate high specificity and sensitivity for the extraction task.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Review does not provide internal details of failure modes for SEETrials specifically; generic LLM limitations mentioned elsewhere include hallucinations, variable generalisability across institutions and possible extraction variability due to heterogeneous reporting styles in abstracts.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not specified in the review whether SEETrials was compared against human annotators or other baselines in detail.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models in oncology: a review', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4189.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4189.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CancerGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CancerGPT (few-shot drug pair synergy prediction using large pretrained language models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited work using large pretrained language models in a few-shot setting to predict drug pair synergies for oncology applications, leveraging literature and model priors to infer pairwise drug relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CancerGPT for few shot drug pair synergy prediction using large pretrained language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CancerGPT (as cited)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Described in the review as an example where LLM-based literature mining and few-shot learning are used to infer drug pair synergies from textual and/or curated data sources; the review mentions literature mining by LLMs as useful for drug synergy predictions and cites CancerGPT as a specific example.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>oncology / pharmacology / drug synergy prediction</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>empirical relationship/predictive relationship between drug pairs and synergistic effect (drug–drug interaction / synergy prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>No explicit quantitative laws or equations provided in the review; described at a high level as predictions of synergistic drug-pair relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Literature mining and few-shot prompting of large pretrained language models to infer relationships between drugs (text-derived evidence + model priors).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Not specified in the review text; the reviewed mention does not report the validation protocol or datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>The review warns generally about LLM hallucinations, variable accuracy across topics, and the need for clinician/expert oversight; specific limitations of CancerGPT are not detailed in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not reported in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models in oncology: a review', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4189.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4189.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Literature mining by LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Literature mining and evidence extraction using large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>General class of LLM applications that mine scientific literature to extract quantitative outcomes, relationships, or patterns (e.g., trial outcomes, driver mutations, drug synergies) to facilitate translational research and decision support.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Unspecified LLM literature-mining pipelines (general)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Generic pipelines where LLMs are prompted or fine-tuned to read and synthesise unstructured scientific literature (conference abstracts, papers, EHR-linked reports) to extract numeric outcomes, mutation–outcome associations, and infer patterns such as drug synergies or prognostic relationships. The review frames these systems as tools to automate extraction of driver mutations, clinical data, trial outcomes, and literature-derived hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>oncology (precision oncology), translational research, clinical trials</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>empirical relationships and correlations (e.g., mutation–prognosis associations, drug synergy relationships, intervention outcome statistics); structured outcome extraction from unstructured reports.</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>The review does not provide explicit equations; examples include extraction of driver mutation associations and trial intervention outcomes, and mining literature for drug synergy predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Text mining of unstructured literature using LLMs, including extraction of numerical values from text (outcome measures), identification of associations described in text, and aggregation/synthesis of findings.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Not universally specified; review cites examples where extraction systems are evaluated using sensitivity/specificity or comparison to expert annotations (e.g., SEETrials), but details vary by cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Varies by cited study; the review gives an example (SEETrials) with 96% specificity and 94% sensitivity for extracting intervention outcomes, and cites other extraction work (eg, driver mutation extraction) without listing numeric metrics in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Heterogeneous reporting across papers, variable generalisability, risk of hallucinated references or incorrect numeric extraction, dependency on reporting style and dataset quality, and the need for clinician/expert verification.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Cited work sometimes compares to human expert review or rule-based extraction; the review emphasizes the need for external validation against expert oncologist decision-making but does not report systematic comparative results for the general class.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models in oncology: a review', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4189.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4189.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Autonomous chemical research (LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Autonomous chemical research with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited body of work where LLMs are used in autonomous or semi-autonomous pipelines to design, plan, or interpret chemical experiments, demonstrating that LLM-based systems can contribute to discovery workflows (used as an analogy and inspiration for compound AI systems in oncology).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autonomous chemical research with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Autonomous chemical research LLM pipelines (as cited)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Described in the review as an example of prior system designs that can inform compound AI system roadmaps; these systems combine LLM capabilities with experimental planning and data interpretation to accelerate chemical discovery and may distill empirical relationships from literature and experimental data.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>chemistry / materials discovery (mentioned as an informing example for AI system design)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>empirical discovery of chemical relationships and synthesis planning (reaction rules, condition–outcome correlations)</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>No explicit quantitative laws are quoted in the review; cited work is referenced as demonstrating autonomous research capabilities in chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Combination of LLM-driven literature reasoning, experiment planning modules, and integration with experimental data (per the cited work; specific pipeline details are not described in the review).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Not described in this review; the cited literature (Boiko et al. and related works) would contain validation details.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Review uses this work as an inspiration but cautions that domain-specific validation, safety, and generalisability concerns remain; direct limitations of the chemical-autonomy papers are not enumerated in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not specified in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models in oncology: a review', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4189.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4189.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Geometry theorem LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLMs applied to theorem proving (solving olympiad geometry without human demonstrations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited work showing that LLMs can solve complex geometry problems and derive mathematical proofs without human demonstrations, used as an analogy for LLMs' capability to discover relationships and patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Solving olympiad geometry without human demonstrations.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM-based theorem-proving pipelines (as cited)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced in the review as an example of LLMs discovering structured mathematical relationships (geometry proofs) autonomously; cited work demonstrates LLMs finding sequences of logical steps that establish geometric relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mathematics / automated theorem proving (mentioned as an informing example)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>mathematical relationships and proofs (derivation of theorems and geometric relationships)</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>No specific theorems or equations are reproduced in the review; the cited work is given as an example of LLMs deriving formal mathematical relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Not applicable in the literature-extraction sense; involves LLM reasoning and chained inference to produce proofs from problem statements.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Cited work validates correctness of proofs; the review does not provide the validation details.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Mentioned as an example of capability but the review emphasizes domain differences when translating such capabilities to biomedical literature (clinical validation, safety, and generalisability concerns).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not detailed in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models in oncology: a review', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Seetrials: leveraging large language models for safety and efficacy extraction in oncology clinical trials. <em>(Rating: 2)</em></li>
                <li>CancerGPT for few shot drug pair synergy prediction using large pretrained language models. <em>(Rating: 2)</em></li>
                <li>Autonomous chemical research with large language models. <em>(Rating: 2)</em></li>
                <li>Solving olympiad geometry without human demonstrations. <em>(Rating: 1)</em></li>
                <li>Deep-GenMut: Automated genetic mutation classification in oncology: A deep learning comparative study. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4189",
    "paper_id": "paper-278710143",
    "extraction_schema_id": "extraction-schema-97",
    "extracted_data": [
        {
            "name_short": "SEETrials",
            "name_full": "SEETrials (LLM system for safety and efficacy extraction in oncology clinical trials)",
            "brief_description": "An LLM-based system reported to automatically extract intervention outcomes (safety and efficacy data) from oncology conference abstracts, enabling rapid synthesis of trial results for clinicians.",
            "citation_title": "Seetrials: leveraging large language models for safety and efficacy extraction in oncology clinical trials.",
            "mention_or_use": "mention",
            "system_name": "SEETrials",
            "system_description": "An LLM-based information-extraction pipeline applied to oncology conference abstracts to identify and extract intervention outcomes (safety and efficacy). As described in this review, SEETrials processes unstructured abstracts and outputs extracted outcome attributes to facilitate early insight into novel interventions.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "oncology / clinical trials",
            "number_of_papers": null,
            "law_type": "empirical quantitative outcome extraction (trial outcome metrics)",
            "law_examples": "Not specified in review beyond general 'intervention outcomes' (no explicit equations provided).",
            "extraction_method": "Automated text-mining of conference abstracts using an LLM-based extraction pipeline to identify and extract numeric and categorical intervention outcomes (safety and efficacy) from unstructured text.",
            "validation_approach": "Reported validation on extracted conference abstract outcomes as system-level specificity and sensitivity (as cited in the review).",
            "performance_metrics": "96% specificity, 94% sensitivity (values reported in this review for SEETrials' extraction of intervention outcomes).",
            "success_rate": "Not described as a single 'success rate'; reported performance metrics above indicate high specificity and sensitivity for the extraction task.",
            "challenges_limitations": "Review does not provide internal details of failure modes for SEETrials specifically; generic LLM limitations mentioned elsewhere include hallucinations, variable generalisability across institutions and possible extraction variability due to heterogeneous reporting styles in abstracts.",
            "comparison_baseline": "Not specified in the review whether SEETrials was compared against human annotators or other baselines in detail.",
            "uuid": "e4189.0",
            "source_info": {
                "paper_title": "Large language models in oncology: a review",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "CancerGPT",
            "name_full": "CancerGPT (few-shot drug pair synergy prediction using large pretrained language models)",
            "brief_description": "A cited work using large pretrained language models in a few-shot setting to predict drug pair synergies for oncology applications, leveraging literature and model priors to infer pairwise drug relationships.",
            "citation_title": "CancerGPT for few shot drug pair synergy prediction using large pretrained language models.",
            "mention_or_use": "mention",
            "system_name": "CancerGPT (as cited)",
            "system_description": "Described in the review as an example where LLM-based literature mining and few-shot learning are used to infer drug pair synergies from textual and/or curated data sources; the review mentions literature mining by LLMs as useful for drug synergy predictions and cites CancerGPT as a specific example.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "oncology / pharmacology / drug synergy prediction",
            "number_of_papers": null,
            "law_type": "empirical relationship/predictive relationship between drug pairs and synergistic effect (drug–drug interaction / synergy prediction)",
            "law_examples": "No explicit quantitative laws or equations provided in the review; described at a high level as predictions of synergistic drug-pair relationships.",
            "extraction_method": "Literature mining and few-shot prompting of large pretrained language models to infer relationships between drugs (text-derived evidence + model priors).",
            "validation_approach": "Not specified in the review text; the reviewed mention does not report the validation protocol or datasets.",
            "performance_metrics": null,
            "success_rate": null,
            "challenges_limitations": "The review warns generally about LLM hallucinations, variable accuracy across topics, and the need for clinician/expert oversight; specific limitations of CancerGPT are not detailed in the review.",
            "comparison_baseline": "Not reported in the review.",
            "uuid": "e4189.1",
            "source_info": {
                "paper_title": "Large language models in oncology: a review",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Literature mining by LLMs",
            "name_full": "Literature mining and evidence extraction using large language models",
            "brief_description": "General class of LLM applications that mine scientific literature to extract quantitative outcomes, relationships, or patterns (e.g., trial outcomes, driver mutations, drug synergies) to facilitate translational research and decision support.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_name": "Unspecified LLM literature-mining pipelines (general)",
            "system_description": "Generic pipelines where LLMs are prompted or fine-tuned to read and synthesise unstructured scientific literature (conference abstracts, papers, EHR-linked reports) to extract numeric outcomes, mutation–outcome associations, and infer patterns such as drug synergies or prognostic relationships. The review frames these systems as tools to automate extraction of driver mutations, clinical data, trial outcomes, and literature-derived hypotheses.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "oncology (precision oncology), translational research, clinical trials",
            "number_of_papers": null,
            "law_type": "empirical relationships and correlations (e.g., mutation–prognosis associations, drug synergy relationships, intervention outcome statistics); structured outcome extraction from unstructured reports.",
            "law_examples": "The review does not provide explicit equations; examples include extraction of driver mutation associations and trial intervention outcomes, and mining literature for drug synergy predictions.",
            "extraction_method": "Text mining of unstructured literature using LLMs, including extraction of numerical values from text (outcome measures), identification of associations described in text, and aggregation/synthesis of findings.",
            "validation_approach": "Not universally specified; review cites examples where extraction systems are evaluated using sensitivity/specificity or comparison to expert annotations (e.g., SEETrials), but details vary by cited work.",
            "performance_metrics": "Varies by cited study; the review gives an example (SEETrials) with 96% specificity and 94% sensitivity for extracting intervention outcomes, and cites other extraction work (eg, driver mutation extraction) without listing numeric metrics in this review.",
            "success_rate": null,
            "challenges_limitations": "Heterogeneous reporting across papers, variable generalisability, risk of hallucinated references or incorrect numeric extraction, dependency on reporting style and dataset quality, and the need for clinician/expert verification.",
            "comparison_baseline": "Cited work sometimes compares to human expert review or rule-based extraction; the review emphasizes the need for external validation against expert oncologist decision-making but does not report systematic comparative results for the general class.",
            "uuid": "e4189.2",
            "source_info": {
                "paper_title": "Large language models in oncology: a review",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Autonomous chemical research (LLMs)",
            "name_full": "Autonomous chemical research with large language models",
            "brief_description": "A cited body of work where LLMs are used in autonomous or semi-autonomous pipelines to design, plan, or interpret chemical experiments, demonstrating that LLM-based systems can contribute to discovery workflows (used as an analogy and inspiration for compound AI systems in oncology).",
            "citation_title": "Autonomous chemical research with large language models.",
            "mention_or_use": "mention",
            "system_name": "Autonomous chemical research LLM pipelines (as cited)",
            "system_description": "Described in the review as an example of prior system designs that can inform compound AI system roadmaps; these systems combine LLM capabilities with experimental planning and data interpretation to accelerate chemical discovery and may distill empirical relationships from literature and experimental data.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "chemistry / materials discovery (mentioned as an informing example for AI system design)",
            "number_of_papers": null,
            "law_type": "empirical discovery of chemical relationships and synthesis planning (reaction rules, condition–outcome correlations)",
            "law_examples": "No explicit quantitative laws are quoted in the review; cited work is referenced as demonstrating autonomous research capabilities in chemistry.",
            "extraction_method": "Combination of LLM-driven literature reasoning, experiment planning modules, and integration with experimental data (per the cited work; specific pipeline details are not described in the review).",
            "validation_approach": "Not described in this review; the cited literature (Boiko et al. and related works) would contain validation details.",
            "performance_metrics": null,
            "success_rate": null,
            "challenges_limitations": "Review uses this work as an inspiration but cautions that domain-specific validation, safety, and generalisability concerns remain; direct limitations of the chemical-autonomy papers are not enumerated in this review.",
            "comparison_baseline": "Not specified in the review.",
            "uuid": "e4189.3",
            "source_info": {
                "paper_title": "Large language models in oncology: a review",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Geometry theorem LLMs",
            "name_full": "LLMs applied to theorem proving (solving olympiad geometry without human demonstrations)",
            "brief_description": "Cited work showing that LLMs can solve complex geometry problems and derive mathematical proofs without human demonstrations, used as an analogy for LLMs' capability to discover relationships and patterns.",
            "citation_title": "Solving olympiad geometry without human demonstrations.",
            "mention_or_use": "mention",
            "system_name": "LLM-based theorem-proving pipelines (as cited)",
            "system_description": "Referenced in the review as an example of LLMs discovering structured mathematical relationships (geometry proofs) autonomously; cited work demonstrates LLMs finding sequences of logical steps that establish geometric relationships.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "mathematics / automated theorem proving (mentioned as an informing example)",
            "number_of_papers": null,
            "law_type": "mathematical relationships and proofs (derivation of theorems and geometric relationships)",
            "law_examples": "No specific theorems or equations are reproduced in the review; the cited work is given as an example of LLMs deriving formal mathematical relationships.",
            "extraction_method": "Not applicable in the literature-extraction sense; involves LLM reasoning and chained inference to produce proofs from problem statements.",
            "validation_approach": "Cited work validates correctness of proofs; the review does not provide the validation details.",
            "performance_metrics": null,
            "success_rate": null,
            "challenges_limitations": "Mentioned as an example of capability but the review emphasizes domain differences when translating such capabilities to biomedical literature (clinical validation, safety, and generalisability concerns).",
            "comparison_baseline": "Not detailed in the review.",
            "uuid": "e4189.4",
            "source_info": {
                "paper_title": "Large language models in oncology: a review",
                "publication_date_yy_mm": "2025-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Seetrials: leveraging large language models for safety and efficacy extraction in oncology clinical trials.",
            "rating": 2,
            "sanitized_title": "seetrials_leveraging_large_language_models_for_safety_and_efficacy_extraction_in_oncology_clinical_trials"
        },
        {
            "paper_title": "CancerGPT for few shot drug pair synergy prediction using large pretrained language models.",
            "rating": 2,
            "sanitized_title": "cancergpt_for_few_shot_drug_pair_synergy_prediction_using_large_pretrained_language_models"
        },
        {
            "paper_title": "Autonomous chemical research with large language models.",
            "rating": 2,
            "sanitized_title": "autonomous_chemical_research_with_large_language_models"
        },
        {
            "paper_title": "Solving olympiad geometry without human demonstrations.",
            "rating": 1,
            "sanitized_title": "solving_olympiad_geometry_without_human_demonstrations"
        },
        {
            "paper_title": "Deep-GenMut: Automated genetic mutation classification in oncology: A deep learning comparative study.",
            "rating": 1,
            "sanitized_title": "deepgenmut_automated_genetic_mutation_classification_in_oncology_a_deep_learning_comparative_study"
        }
    ],
    "cost": 0.01296625,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large language models in oncology: a review</p>
<p>David Chen 
Radiation Medicine Program
Princess Margaret Hospital Cancer Centre
TorontoOntarioCanada</p>
<p>Temerty Faculty of Medicine
University of Toronto
TorontoOntarioCanada</p>
<p>Rod Parsa 
Radiation Medicine Program
Princess Margaret Hospital Cancer Centre
TorontoOntarioCanada</p>
<p>Michael G. DeGroote School of Medicine
McMaster University
StockholmOntarioCanada</p>
<p>Karl Swanson 
Department of Medicine
University of California-San Francisco
San FranciscoCaliforniaUSA</p>
<p>John-Jose Nunez 
Department of Psychiatry
University of British Columbia
VancouverBritish ColumbiaCanada</p>
<p>BC Cancer Agency
VancouverBritish ColumbiaCanada</p>
<p>Andrew Critch 
Center for Human-Compatible Artificial Intelligence
Department of Electrical Engineering and Computer Sciences
UC Berkeley
BerkeleyCaliforniaUSA</p>
<p>Danielle S Bitterman 
Artificial Intelligence in Medicine (AIM) Program
Mass General Brigham
Harvard Medical School
BostonMassachusettsUSA</p>
<p>Department of Radiation Oncology
Dana-Farber Cancer Institute
BostonMassachusettsUSA</p>
<p>Computational Health Informatics Program
Boston Children's Hospital
BostonMassachusettsUSA</p>
<p>Fei-Fei Liu 
Radiation Medicine Program
Princess Margaret Hospital
TorontoOntarioCanada</p>
<p>Department of Radiation Oncology
University of Toronto
TorontoOntarioCanada</p>
<p>DrSrinivas Raman srinivas.raman@bccancer.bc.ca 
Radiation Medicine Program
Princess Margaret Hospital Cancer Centre
TorontoOntarioCanada</p>
<p>Temerty Faculty of Medicine
University of Toronto
TorontoOntarioCanada</p>
<p>Radiation Oncology
BC Cancer -Vancouver
VancouverBritish ColumbiaCanada</p>
<p>Large language models in oncology: a review
79EF4A0871E47CC2D3610EB8A68ADCCE10.1136/bmjonc-2025-000759Received 23 January 2025 Accepted 24 April 2025
Large language models (LLMs) have demonstrated emergent human-like capabilities in natural language processing, leading to enthusiasm about their integration in healthcare environments.In oncology, where synthesising complex, multimodal data is essential, LLMs offer a promising avenue for supporting clinical decisionmaking, enhancing patient care, and accelerating research.This narrative review aims to highlight the current state of LLMs in medicine; applications of LLMs in oncology for clinicians, patients, and translational research; and future research directions.Clinician-facing LLMs enable clinical decision support and enable automated data extraction from electronic health records and literature to inform decision-making.Patient-facing LLMs offer the potential for disseminating accessible cancer information and psychosocial support.However, LLMs face limitations that must be addressed before clinical adoption, including risks of hallucinations, poor generalisation, ethical concerns, and scope integration.We propose the incorporation of LLMs within compound artificial intelligence systems to facilitate adoption and efficiency in oncology.This narrative review serves as a non-technical primer for clinicians to understand, evaluate, and participate as active users who can inform the design and iterative improvement of LLM technologies deployed in oncology settings.While LLMs are not intended to replace oncologists, they can serve as powerful tools to augment clinical expertise and patientcentred care, reinforcing their role as a valuable adjunct in the evolving landscape of oncology.</p>
<p>CURRENT STATE OF LARGE LANGUAGE MODELS IN MEDICINE Introduction</p>
<p>Large language models (LLMs) are artificial intelligence (AI) systems focused on the generation of natural language.The field of oncology is well-positioned to benefit from the incorporation of LLM technologies, especially given its emphasis on the synthesis of diverse data types such as clinical, imaging, laboratory and genomic reports integrated with the psychosocial elements of patient-centred medicine.This narrative clinical primer aims to provide a background for the application of LLMs in cancer care and lay the groundwork for their adoption in clinical oncology.Our narrative review adopts a practical approach by offering step-by-step examples of LLM tool integration into clinical oncology workflows as well as discussion of contemporary trends including compound AI systems with humanin-the-loop designs, multi-modal LLMs, and emergent regulatory frameworks to fill the gap between conceptual overviews and clinical realities.We identified relevant studies and potential applications by conducting a comprehensive but non-systematic search of academic databases (PubMed, MEDLINE, EMBASE, Google Scholar) using variations of the keywords 'large language model', 'generative artificial intelligence', 'oncology' and 'cancer'.We also cross-referenced bibliographies of retrieved articles and drew on expert clinical and AI knowledge within the author team to ensure coverage of emerging and notable studies within the scope of large language model development and applications in oncology.</p>
<p>History of NLP and LLMs</p>
<p>Natural language processing (NLP) describes the computer-aided analysis that enables comprehension and generation of human language.In the early 2000s, the first iteration of language generators employed statistical models that estimated the likelihood of the next word in a sequence, based on frequency of occurrence in the training data. 1 To leverage the scale of large natural language datasets such as unstructured text in electronic health records (EHRs), machine learning-based NLP approaches used mathematical models to extract highlevel patterns from data to make inferences.The evolution of natural language processing from rule-based algorithms to contemporary large language models is shown as a timeline in figure 1.</p>
<p>Deep learning, inspired by biological neural networks, refers to a sub-field of machine learning models that learn high-level patterns from input data to mimic human-like data processing.Transformer-based LLMs, such as BERT 2 and RoBERTa 3 in the late 2010s as well as GPT in 2020, 4 were critical developments in NLP that exhibited human-like performance in sentiment analysis, question answering, feature extraction, language translation and text summarisation.In clinical contexts, this ability to ingest significant volumes of textual information was first applied to electronic medical records (EMRs); LLMs' ability to process and analyse free text elements enabled clinicians to rapidly create structured datasets, streamline clinical coding, mine academic literature and develop predictive models based on extractable patient features. 5Oncology-specific applications of NLP models focused initially on case identification (ie, identifying past patients with specific or rare medical characteristics not captured by structured data fields), enhanced cancer staging and codification of staging parameters and the identification of specific clinical outcomes. 6As conversational capabilities improved, NLP research in oncology turned towards patient-facing applications, including cancer screening campaigns and patient education after diagnosis. 7The significance of these advances in NLP, and their contribution to human advancement, was most recently underscored by the Nobel Committee's decision to award the 2024 Nobel Prize in Physics to Drs Hopfield and Hinton, pioneers in the development of the artificial neural networks employed in modern LLMs.</p>
<p>LLMs recently entered the public consciousness with OpenAI's 2022 release of ChatGPT 3.5, an AI chatbot based on the GPT LLM that is credited as the fastestgrowing consumer software application in history. 8Today, there are three common categories of clinical LLMs: (1) zero-shot, generalist LLMs that can perform diverse NLP tasks with no pre-training, (2) fine-tuned LLMs that have been trained on custom medical datasets to perform specialised tasks and (3) LLMs equipped with in-context learning or retrieval-augmented generation techniques to enable more accurate recall of medical information from a knowledge base.</p>
<p>Development and validation of clinical LLMs</p>
<p>Standard workflows for the development of clinical LLMs involve model selection, fine-tuning for domainspecific tasks, validation in clinical contexts and deployment in real-world settings as summarised in figure 2. First, clinical LLM applications are typically built using foundational LLMs developed by academic and industry developers, including Google (Gemini), Meta (Llama), OpenAI (GPT) and Anthropic (Claude). 9Some of the most popular LLMs are open-source (eg, Llama2 by Meta), allowing users to modify their underlying architecture, while others remain proprietary and allow limited interactions through an application programming interface (eg, GPT-4 by OpenAI).</p>
<p>Second, domain-specific LLMs are developed through transfer learning, where foundational LLMs are finetuned or trained on specialised datasets, such as clinical notes and EHRs, to function for specialised tasks.Examples of clinical-focused LLMs include Google's Med-PaLM, which focuses on providing high-quality responses to medical questions, 10 and ClinicalBERT, a model which predicts hospital readmission within 30 days by analysing clinical text. 11Furthermore, a recent study by Wang et al demonstrated superior performance of fine-tuned LLMs in the field of radiation oncology, where they outperformed baseline foundational LLMs on tasks related to treatment regimen generation, treatment modality selection and ICD-10 code generation. 12Likewise, Ferber et al demonstrated the superior performance of fine-tuned LLMs compared with baseline foundational LLMs in the field of medical oncology when assessed on management guidelines of pancreatic, colorectal and hepatocellular cancers. 13LLM outputs can be further optimised by providing model outputs with a few examples through few-shot learning as well as rewarded to steer LLMs towards more truthful and less toxic outputs based on human feedback through reinforcement learning. 14</p>
<p>Review Open access</p>
<p>Third, LLMs are commonly internally validated through one of three classes of metrics on a humanannotated benchmark dataset, including multipleclassification (classification of text into multiple groups), token-similarity (similarity of generated text with reference text) and question-answering (identifying the answer to a specific question). 15However, these methods do not capture real-world clinical efficacy, and external validation against expert oncologist decision-making remains essential.Extrinsic evaluations of LLM performance have included comparisons against trained healthcare professionals across test scores or standard of care, measures of clinical efficiency or subjective ratings of performance, 16 with recent recommendations that models be stresstested via exposure.to diverse clinical scenarios and patient populations to ensure generalisability before real-world deployment. 17Indeed, a recent crosssectional study analysing eight LLMs demonstrated an 85% accuracy rate on examination-style multiple choice questions from the American Society of Oncology; however, 81.8% of the incorrect questions were rated as having a medium to high likelihood of moderate to severe harm. 18Another validation study focused on molecular tumour boards found that LLMs offered equivalent treatment recommendations to clinicians 25% of the time, with a further 37.5% of recommendations as plausible alternative treatments.In generating these recommendations, however, 17% of articles referenced by LLMs were hallucinations, reinforcing the need for clinician supervision. 19Most recently, researchers have been working towards standardising the human evaluation of LLMs in healthcare.For example, the QUEST framework proposed by Tam was developed through a systematic review of prior evaluation guidelines and addresses gaps in reliability, generalisability and applicability of these guidelines across a variety of medical specialties. 20</p>
<p>APPLICATIONS OF LARGE LANGUAGE MODELS IN ONCOLOGY Clinician decision support</p>
<p>Emergent themes of clinician-facing applications of LLMs in oncology include serving as clinical decision support tools for diagnosis, screening and prevention, treatment and management, and automated data extraction and processing for clinician review. 9Common themes and highlighted examples of potential LLM applications in oncology across a diverse set of application scenarios are shown in figure 3 and online supplemental eTable 1, respectively.In figure 3, we outline three principal themes illustrating how LLMs are being applied in oncology: (1) clinician-facing applications for diagnosis, prognosis, screening, management, data extraction and reference information; (2) patient-facing applications for psychosocial support, communication and reference information; and (3) research facilitation such as screening of trial eligibility, literature evidence synthesis and precision medicine.Notably, this figure highlights the breadth of potential LLM applications grouped by distinct application domains that can help address the multifaceted challenges in modern oncology care.</p>
<p>Diagnosis</p>
<p>LLM-enabled tools have the potential to identify useful patterns from both text-only and multi-modal inputs to recommend clinical diagnoses.In an early evaluation of LLM diagnostic accuracy, Wang et al found GPT-4 performed well in generated report structure and clarity but performed worse than physicians in diagnostic accuracy 21 when tested on 109 ultrasound text descriptions of thyroid cancer.However, the Turing test evaluation found that physicians believed that 71% of GPT-generated reports were likely physician-generated, suggesting that GPT and physician-generated reports are largely indistinguishable.Compared with gold-standard clinician annotations, LLMs have shown promising diagnostic performance in exam-style, text-based assessments across several tumour sites including dermatological (85% accuracy), 22 bone (87% accuracy), 23 oropharyngeal (71% accuracy) 24 and neurological cancers (50% accuracy). 25otably, the advent of multi-modal LLMs that integrate image processing capabilities is uniquely positioned to analyse both clinical images, including photographs, 22 and multiple radiologic modalities including MRI, 26 CT 27 and ultrasound. 28While most studies demonstrate human-like performance, there remain concerns about generalisation such as variable diagnostic performance across different skin tones in melanoma, 22 suggesting that the accuracy in minority patient demographics and rare diseases should be evaluated with caution.Similar concerns arise in underrepresented cancer subtypes, where training data scarcity may lead to decreased model performance.Oncologists can use LLM predictions to aid diagnosis but should be cautious about their interpretability and alignment with clinical judgement.However, it is important to note that these findings are derived from early-stage pilot studies in controlled settings and require further validation, especially to assess performance consistency across diverse patient populations, heterogenous practice settings and various cancer diagnoses and stages.</p>
<p>Existing AI-driven approaches in radiology and histopathology have demonstrated high diagnostic accuracy for tasks like tumour localisation and malignancy classification, often through convolutional neural networks or other deep learning architectures that directly analyse imaging data. 29LLM-based solutions can complement these image-centric models by parsing clinical notes, radiology reports or pathology descriptors, providing a structured synopsis of relevant clinical factors that can enhance diagnostic workflows and communication between radiologists, pathologists and oncologists (60).In this way, LLMs may ultimately function synergistically with established computer vision algorithms to bridge the gap between raw imaging data and patient-level clinical decision-making (61).However, multi-modal LLMs are still in early development, and rigorous testing is needed to evaluate their ability to integrate imaging and text data reliably across diverse patient populations and clinical settings.</p>
<p>Screening and prevention</p>
<p>The integration of LLMs into screening and prevention efforts represents a nascent but rapidly evolving area of research, focusing on text-based knowledge synthesis and guideline-based recommendation. 30While most AI-based screening applications to date have emphasised image analysis for earlier detection of lesions or nodules, LLMs offer potential in complementary domains like patient risk stratification from EHRs, automated reminder systems for at-risk populations and the generation of patient-specific preventative measures. 31These text-driven functionalities could be especially valuable for oncologists seeking to optimise large-scale screening programmes or adapt guidelines to individual patient risk profiles.</p>
<p>Review Open access</p>
<p>The utility of LLMs in augmenting decisions related to screening and prevention has been investigated in prostate (85% and 100% accuracy for 30 easy and hard prostate cancer screening questions), 32 colorectal (100% accuracy in 20 colorectal cancer screening questions), 33 breast, ovarian and lung cancer (83% accuracy across 15 select-all-that-apply pan-cancer screening scenarios) contexts. 34Although these standardised screening evaluations show high accuracy, they are based on predefined question sets rather than real-world clinical scenarios.Chiarelli et al tested the reliability of GPT when queried with three prompt variations, showing that there was no difference in accuracy but noted that systematic evaluations of reliability are warranted given the probabilistic nature of LLMs. 32Despite attempts to ground LLM in evidence-based knowledge such as PubMedBERT and Med-PaLM, oncologists should validate that LLM-based screening recommendations coupled with explanations align with established clinical guidelines and generalise when integrated into patient screening programmes.</p>
<p>Treatment and management</p>
<p>While LLMs can suggest treatment options aligned with established guidelines, studies have found that they may also propose non-concordant treatments, requiring human oversight to align management with patient preferences and evidence-based guidelines. 35Marchi et al found that ChatGPT-3.5 provided accurate suggestions for primary treatment (85.3% accuracy, 100% sensitivity) and adjuvant treatment (96% accuracy, 100% sensitivity) for 68 head and neck cancer cases according to NCCN consensus expert-driven guidelines for cancer management. 36High sensitivity in treatment recommendations underscores the comprehensive nature of LLM outputs but may lead to over-inclusive lists that require oncologist judgement to refine.For example, in another study, Chen et al found that across 104 prompts for 26 pan-cancer diagnoses, GPT-3.5 provided at least 1 NCCN-concordant treatment in 98% of scenarios but also recommended non-concordant treatments in 34.3% of scenarios. 35Given the occurrence of non-guideline-concordant recommendations, it is critical to underscore that LLM outputs should complement-but not replace-human clinical judgement while future research continues to identify and address the knowledge deficiencies of LLM tools in clinical settings.For the oncologist, this means that LLMs can generate a differential list of treatments for future evaluation of guideline concordance and patient preference, but cannot replace human decision-making.LLMs in specialised oncology tasks have shown mixed performance, with examples in the literature demonstrating that LLMs prescribed chemotherapy protocols with inappropriate dosing (56% accuracy) 37 and were subject to hallucinations when recommending management for immune-related adverse events (44% accuracy). 38From a medical lens, LLMs may fail to consider important factors such as a patient's comorbid conditions or psychosocio-economic factors that may contraindicate certain regimens in practice.Similarly, while an LLM might produce a seemingly appropriate surgical recommendation, only a trained surgeon or multidisciplinary tumour board can balance tumour resectability, patient preferences, anatomical complexities and the associated risks unique to a specific patient.From a psychosocial lens in palliative scenarios, an LLM's suggestions may overlook family dynamics or cultural values-factors that carry substantial weight in deciding care goals.These examples illustrate how human judgement, guided by clinical expertise and empathy, remains central to comprehensive patient-centred care.</p>
<p>One of the most exciting applications of LLMs in oncology is the recommendation of treatments in complex settings outside of established clinical practice guidelines.These tasks may be ideally suited for LLMs given their ability to process vast amounts of medical literature and patient data to identify patterns that may not be apparent to human experts, but useful for generating novel treatment recommendations in complex and rare cancer cases.In complex breast 39 and colorectal 40 cancer settings, studies have reported 70% and 87% concordance of LLM-generated treatments with tumour board recommendations.Likewise, Chen et al found that LLMgenerated diagnosis and treatment recommendations of 79 clinical oncology cases with images achieved up to 72% accuracy. 41However, inaccurate referencing to established guidelines and generation of medically inaccurate outputs with confidence contribute to poor autonomous actionability of LLM-generated recommendations 42</p>
<p>Data extraction and processing</p>
<p>To enable synthesis of patient data for molecular tumour boards, oncologists may use LLMs to extract key tumour attributes rather than manually extracting this data from the patient EHR. 43Preston et al demonstrated that LLMbased data extraction of tumour attributes, including tumour site and the widely-adopted TNM cancer staging classification, can achieve 94-99% AUROC performance and generalise across multiple health systems and state registries. 43Notably, LLM-enabled data extractions for well-defined categories, such as TNM stage, can even correct human errors on expert review. 43eyond clinical features, automated extraction of social and behavioural determinants from clinical data 44 can be applied to address several humanistic elements of the cancer patient experience, including identifying at-risk patients who lack advance directives, surrogate decisionmakers and decision capacity, 45 and recommending online resources to address psychosocial needs. 46Instead of prompting LLMs to generate 'black box' predictions from clinical data, oncologists can prompt LLMs to extract important data points from large-scale clinical text, allowing oncologists to prioritise expert synthesis of medical knowledge and patient care over non-patient facing, administrative tasks.While the high performance in structured data extraction is encouraging, variability in EHR systems and documentation practices across</p>
<p>Review</p>
<p>Open access</p>
<p>institutions may affect extraction performance in external settings, motivating the need for robust, multi-centre evaluations to confirm generalisability in real-world settings.</p>
<p>Patient-facing applications</p>
<p>The familiarity and accessibility of chatbot LLMs with nearhuman levels of language competency underscore their potential as patient-facing health information resources and supportive management tools to help address patient educational and psychosocial factors of cancer care.</p>
<p>Health information resource</p>
<p>The accurate performance of conversational chatbots on standardised benchmarks of medical competency, such as the USMLE, 47 and common patient queries about cancer 48 49 suggests that LLM applications may serve as a readily accessible, supplementary patient resource for cancer information.Beyond responding to clinician-level queries, cross-sectional studies of ChatGPT-4 reported high accuracy and alignment to oncologists or guidelines if available, when tested on general patient-level questions about genetic counselling, 50 breast, 51 lung, 52 colon 53 and pancreatic 54 cancers.Moreover, pilot evaluations of LLMs for language translation 55 and biomedical text simplification 56 are emergent research directions of clinical LLMs that can facilitate patient education in oncology.LLMs can provide oncology knowledge as an accessible patient resource.However, we caution that the variable medical accuracy across various cancers and topics, 44 risks of misinterpretation, oversimplification of complex medical information, propagation of outdated or non-personalised advice and decreased readability of chatbot-generated responses compared with physicians may collectively pose serious risks to deploying patient-facing LLMs in real-world settings until effective safeguards for accuracy and misinformation are implemented.Despite the positive results of these pilot studies, oncologists should explain to patients that LLM tools may (1) generate unreliable and outdated information that can lead to harm, (2) fail to personalise recommendations to the individual patient, (3) harbour inherent biases based on their training datasets and (4) provide limited protections to personal health information privacy and security that have yet to be systematically regulated.</p>
<p>Supportive management</p>
<p>Conversational LLMs, known as chatbots, may act as a complementary agent for psychosocial and emotional support in oncology.Chatbots can provide empathetic responses to online patient questions about general medicine 16 and cancer-specific 48 topics in non-inferiority evaluations compared with physicians, supporting their use in generating empathetic template responses under clinician oversight when integrated into patient health portals. 57LLM tools also pose potential to improve patient communication during post-treatment care, such as improving dialogue rates for patients experiencing oncological aphasia. 58Combining LLM-enabled language competencies with hardware, such as assistive robots with functional language and physical capabilities, is a promising development towards more human-like levels of emotional connection. 59ncologists should establish clear protocols defining the scope of chatbot use that encompass two major components: development-focused guidelines and patient-facing usage guidelines.From a development perspective, these protocols can inform model creators and industry partners about the clinical and ethical parameters expected in an oncology setting, helping to ensure that chatbot features-such as data handling, language style and management plans-are compatible with current standards of care and privacy regulations.In parallel, usage guidelines aimed at clinicians and patients will clarify the chatbot's intended purposes (eg, providing supplementary educational information, screening for psychosocial support needs or summarising care instructions), limitations (eg, lack of personalised medical advice, potential for erroneous responses) and recommended follow-up actions.This dual approach enables a coordinated effort to shape the chatbot's capabilities during development while also providing straightforward guidelines that support safe, consistent and beneficial interactions between patients, oncology teams and AI-based tools.</p>
<p>Patient perceptions of LLMs</p>
<p>Recent studies show that patients often perceive AI-generated health advice, such as from ChatGPT, as helpful and empathetic, with evidence that users sometimes rate these responses even more favourably than physician-written answers. 60However, research indicates that patients have only moderately high trust in chatbot responses-Nov et al (2023) report average trust scores of around 3.4 out of 5, with confidence falling as question complexity increases. 61Platt et al (2024) similarly found that patients' comfort using ChatGPT for healthcare queries was below mid-range, highlighting accuracy and privacy concerns. 62 notable risk factor is that lay users cannot always identify when an LLM's advice is inaccurate or outdated, underscoring the potential for harm if chatbots are used without adequate oversight. 60Nevertheless, public surveys of online users suggest that, despite these reservations, members of the public, including patients, show willingness to adopt AI health tools in the future if privacy, safety and transparency standards are better established. 63 64cilitating and synthesising oncology research Automated processing of unstructured text is a unique competency of LLMs that can be used to facilitate translational research in oncology.For example, LLMs can structure clinical trial eligibility criteria for cancer patients that achieve moderate performance compared with physician recommendations, with mixed reports of both high false positives 65 and high false negatives. 66Similar to medical tumour board recommendations, LLMs applied to clinical trial recommendation should be used to generate an Review Open access inclusive selection of potentially eligible trials for oncologists to prioritise in their final recommendation.</p>
<p>Translation of oncology clinical trial results into actionable clinical recommendations requires expert synthesis of scientific knowledge prone to time lag between discovery and implementation. 67To address this problem, LLM systems such as SEETrials have demonstrated proficiency (96% specificity, 94% sensitivity) in automated extraction of intervention outcomes associated with cancer trials reported in conference abstracts, 68 enabling oncologists to glean early insights into the safety and efficacy of novel interventions.</p>
<p>Applied to precision oncology, LLMs have seen success in automating data extraction of driver mutations and clinical data from EHRs to evaluate the prognostic value of these mutations and functional effects. 69Likewise, literature mining by LLMs may be useful as a research tool for drug synergy predictions applied to complex cancer patient scenarios. 70Academic oncologists can stay up to date on advancements in LLM applications by engaging with emerging LLM in oncology research, attending interdisciplinary conferences and collaborating with AI experts to safely and effectively integrate these tools into modern oncology practice (table 1).</p>
<p>LIMITATIONS AND FUTURE DIRECTIONS OF LARGE LANGUAGE MODELS Technical limitations</p>
<p>The implementation of LLMs in medicine is limited both by AI-intrinsic and clinical workflow challenges.Training and testing models on sparse, incompletely labelled datasets risks generating insights that fail to generalise to broad use cases.Furthermore, LLM-based models are prone to generating convincing 'hallucinations', content that is entirely nonsensical or unfaithful to the provided source content, 9 which must be either actively detected or accounted for by healthcare providers.For example, Chen et al reported a 12.5% hallucination rate by LLM chatbots asked to generate cancer treatment information. 35As a result, there has been increasing focus on the development of LLM safeguards that prevent the generation of health disinformation. 71Other studies have found that LLM chatbots may provide inconsistent responses to the same question asked several times, 72 raising questions about their reliability and reproducibility.Finally, most modern LLM chatbots are trained on fixed time windows-for example, ChatGPT 3.5's initial release was trained on data up to September 2021.This training method may exclude more recent advances and risks generating outdated responses, especially in rapidly evolving fields such as oncology.</p>
<p>Ethical limitations</p>
<p>Collaborations between international institutions, as evidenced by a partnership between the WHO and the European Parliament, have garnered interest in producing ethical guidelines and frameworks for the application of AI in healthcare. 73These frameworks emphasise the preservation of patient autonomy, technological transparency, accountability and inclusiveness.Until international standards are formalised, significant discussion has focused on adherence to existing national standards, such as the US Health Insurance Portability and Accountability Act (HIPAA).Models that employ identifiable patient information may risk inadvertently storing or disclosing sensitive information in violation of HIPAA regulations or may be vulnerable to cybersecurity breaches. 74Furthermore, the use of identifiable patient information in the pre-training process may violate principles around informed consent and rights-of-data, especially if previously anonymised data can be re-identified.</p>
<p>Kapsali et al have highlighted discrepancies between the aforementioned principles and ChatGPT's features, 75 pointing to its black-box technology and insufficient documentation as causes for concern.Unsurprisingly, it</p>
<p>Review</p>
<p>Open access has been shown that patients may prefer human judgement and expertise over AI-generated recommendations, 76 especially when existing legal frameworks around liability and medical malpractice fail to fully address AI-driven outcomes. 77Indeed, emerging research has revealed the potential for LLMs to perpetuate societal biases, such as race, even without the explicit input of demographic data. 78A recent systematic review highlighted the prevalence of gender and racial bias in medical LLMs, describing model outputs that leaned on stereotypical gender roles, used gendered language and underrepresented women while overvaluing male competence.Mitigation strategies that limit these biases have relied primarily on prompt engineering methods with varying effectiveness, and there exists a need for standardised metrics that systematically reduce bias in all stages of model development and implementation. 79iven the historic and ongoing issues with diversity, as evidenced by clinical trial participation for example, 80 there exists an imperative for cancer researchers to interrogate oncology-focused LLMs for data-driven biases.</p>
<p>Resource limitations</p>
<p>Although the economic challenges of LLM deployment in healthcare systems remain underexplored, efforts have been made to estimate the computational, energy and financial costs associated with model development and implementation. 81The cost burden of LLMs in medicine is based on model training and fine-tuning, integration into existing electronic health systems, input data types and latency requirements.Carbon footprint estimates have been inferred at each lifecycle point of LLMspretraining, fine-tuning, and inference-with the inference stage dominating the long-term environmental impact. 82For example, a single query of a fine-tuned GPT-3 model uses 0.04 kW-h of electricity per 100 pages of generated text, 82 a power consumption that could rapidly balloon when scaled across thousands of patients that each warrant numerous clinician queries to medical records.However, there have been countervailing debates on the economic implications of LLM deployment, with some researchers proposing that the expected cost efficiencies and sustainable practices conferred by automation far outweigh the negative impacts. 83Cancer care in particular is likely to benefit from these efficiencies, given the longstanding capacity constraints as the number of cancer patients outpaces the number of clinicians available to support them. 84</p>
<p>Future directions</p>
<p>Emerging directions in LLM implementation will involve advances in technology and model complexity, cohesive regulatory and standardisation frameworks, greater emphasis placed on inclusivity and equity and the incorporation of clinician and patient feedback into development cycles to better align model outputs with desired outcomes (table 2).</p>
<p>Recent research has proposed a paradigm shift from increasing resource usage towards designing specialised component tools that work together as a compound AI system. 85Roadmaps for the design of compound AI systems in oncology can be informed by previous system designs used for chemical synthesis 86 and geometry theorem proofs. 87There exists additional potential for multimodal AI models that integrate oncology-focused models in collaboration with other disciplines, such as radiology and pathology, with potential to streamline tasks such as summarisation, patient education, differential diagnosis generation and interdisciplinary collaboration. 88In the era of precision medicine, the integration of multimodal datasets which combine textual data from medical records, oncology clinic visits, multidisciplinary discussions, genomic pathology reports and imaging findings is likely to enhance patientspecific recommendations.Fine-tuning techniques such as prompt engineering have also shown particular promise; prompts that provide additional clinical context have been shown to generate treatment plans Review Open access in concordance with cancer care guidelines. 89From a model evaluation perspective, some are proposing more realistic evaluation frameworks using agent-based modelling to create AI structured clinical examinations ('AI-SCE') that test varying degrees of self-governance in dynamic environments. 17eployment of AI in healthcare settings has also engendered ongoing discussion around maximising benefit and minimising risk through standardised regulation.While internationally recognised governance mechanisms for AI in healthcare do not currently exist, 90 there has been increasing consensus in focused areas of interest.For instance, a diverse set of academic, industry, funding agency and publishers has proposed the implementation of Findable, Accessible, Interoperable and Reusable Data Principles to define good data stewardship practices and facilitate data sharing that may be adopted in the precision oncology community. 91Standardised reporting guidelines for biomedical-focused LLM research, such as TRIPOD+LLM for primary research involving LLMs, 92 QUEST for human evaluation of LLMs 20 or CONSORT-AI for clinical trials involving AI, 93 aim to improve the consistency, reliability and verifiability of future advancements.</p>
<p>Patient-centric regulations for patient privacy, medical malpractice and informed consent lag behind technical innovation.To date, this has only been addressed within the confines of individual partnerships (eg, Google's HIPAA-compliant generative AI at the Mayo Clinic) and not at scale.With time, the adoption of widespread data sharing and ethics frameworks will permit existing models to train on large, open-source and more representative datasets while considering important principles of data privacy and right to use, intellectual property and risk of harm.This will in turn enable the development of accurate, purpose-built LLMs for cancer-specific applications, both via open-source collaborations (eg, RadOnc-GPT, CancerGPT) 70 94 and industry-sponsored offerings (eg, CareIntellect by GE Healthcare, Watson for Oncology by IBM and Intellispace Oncology by Phillips).</p>
<p>The design of human-in-the-loop training cycles, where LLMs are fine-tuned by engineers with clinician feedback, can optimise LLM outputs that are more clinically useful to the oncology care team.Explicit and implicit patient feedback may help LLMs better align outputs with the unique psychosocial experiences of cancer patients.Explicit feedback involves reports from patient users after interactions with the LLM application, such as numerical scores or binary ratings of the text output from the tool.Implicit feedback involves indirect reports from patient users based on user interactions and behaviour patterns with the LLM application, such as monitoring user reactions to LLM outputs through engagement time or characteristics of follow-up queries.The design of oncology LLM applications requires consideration of both emotional and cognitive empathy in order to address the psychosocial demands of the cancer patient experience and prioritise the clinical competencies that impact patient clinical outcomes.</p>
<p>CONCLUSION</p>
<p>LLMs have the potential to impact all aspects of cancer care due to their human-like ability to understand and generate natural language.Clinician and patient-facing applications of LLMs in oncology, ranging from diagnosis, management and emotional support, serve as promising directions of LLM research in oncology.Coupled with emergent multi-modal capabilities and integration into compound AI systems, state-of-the-art LLM applications are well-positioned to move towards addressing clinical and translational research challenges in oncology.However, there remain several limitations of LLM deployment in clinical practice, including medical accuracy, privacy and ethics, which remain to be systematically addressed in order to facilitate their widespread adoption.Validation of LLM applications should demonstrate sufficient benefit in real-world clinical settings necessary to prioritise patient care outcomes in oncology.While the mixed performance of LLMs across oncology-related competencies may suggest that oncologists will not be replaced by AI solutions anytime soon, LLM-based tools may serve as useful clinician decision support and patientfacing management tools under clinician oversight.</p>
<p>Figure 1
1
Figure 1 Timeline of Natural language processing development in medicine.</p>
<p>Figure 2
2
Figure 2 Development and validation process of clinical large language model applications.</p>
<p>Figure 3
3
Figure3Themes of large language model applications in oncology.</p>
<p>Table 1
1
How large language models are being used in oncology Generate differential diagnoses based on patient clinical notes and data for oncologist review ► Prognosticate patient based on risk and survival as a supportive tool ► Provide cancer screening information based on established guidelines ► Generate treatment recommendations for oncologist review ► Extraction of key cancer attributes from clinical text to inform clinical decision-making ► Generating summaries of clinical notes, consultations and diagnostic reports
DomainApplicationOncologist ► Cancer Patient ► Patient health information resource with clinician oversight► Language translation► Biomedical text simplification► Psychosocial and emotional support and counsellingCancer Research► Clinical trial matching for eligible cancer patients► Extraction of trial outcomes from literature for clinician education► Extraction of mutation and clinical data for precision oncology► Literature mining for drug synergiesAdministration► Draft work communications and patient messages► Transcribe and summarise patient and clinician meetings► Generate pre-filled administrative paperwork► Copy-edit and format administrative paperwork</p>
<p>Table 2
2
Limitations to large language model adoption in oncology and potential solutions Comprehensive data labelling requirements that employ diverse clinical and patient data ► Continually shifting training window that captures new studies and advancements as they are released ► LLM safeguards that detect and prevent hallucinations and health disinformation ► Development of AI reliability metrics to track output consistency Ethical ► Development of consensus ethical frameworks around the use of AI in clinical contexts ► Inclusion of both patient and clinician feedback on a continual basis, both into regulatory frameworks and model development ► Adoption of open-source and transparent development, along with clear documentation, to avoid the perception of a black-box technology ► Continual research and benchmarking of societal biases found in LLM inputs and outputs ► Anonymisation of all patient information by LLMs to preserve privacy and security
LimitationsPotential solutionsTechnical►
Economic► Careful consideration of build vs buy options for institutions considering LLM deployment ► Investment into sustainable energy options that fuel LLM energy consumption while minimising carbon footprint ► Judicious use of LLM model queries, limited to use cases where it improves clinical outcomes ► Comprehensive accounting of the cost efficiencies conferred by LLM deployment (eg, human resources) AI, artificial intelligence; LLM, Large language model.Chen D, et al.BMJ Oncology doi:10.1136/bmjonc-2025-000759</p>
<p>Chen D, et al. BMJ Oncology 2025;4:e000759. doi:10.1136/bmjonc-2025-000759
Funding This work was partially supported by the CARO CROF studentship and the Robert L. Tundermann and Christine E. Couturier philanthropic funds.Competing interests None declared.Patient and public involvement Patients and/or the public were not involved in the design, conduct, reporting or dissemination plans of this research.Patient consent for publication Not applicable.Ethics approval Not applicable.Provenance and peer review Not commissioned; externally peer reviewed.Data availability statement Data are available upon reasonable request.Supplemental material This content has been supplied by the author(s).It has not been vetted by BMJ Publishing Group Limited (BMJ) and may not have been
A survey on large language models: applications, challenges, limitations, and practical usage. M U Hadi, R Qureshi, 2023Preprint</p>
<p>BERT: pre-training of deep bidirectional transformers for language understanding. J Devlin, M W Chang, K Lee, 2019</p>
<p>RoBERTa: a robustly optimized bert pretraining approach. Y Liu, M Ott, N Goyal, 2019</p>
<p>Language models are few-shot learners. T B Brown, B Mann, N Ryder, 2020</p>
<p>Natural language processing in medicine: A review. S Locke, A Bashall, S Al-Adely, 10.1016/j.tacc.2021.02.007Trends in Anaesthesia and Critical Care. 382021</p>
<p>Natural language processing in oncology: a review. W-W Yim, M Yetisgen, W P Harris, 10.1001/jamaoncol.2016.0213JAMA Oncol. 22016</p>
<p>Patients facing large language models in oncology: a narrative review. C Raynaud, D Wu, J Levy, 10.1200/CCI-24-00149JCO Clin Cancer Inform. 8e24001492024</p>
<p>A brief overview of chatgpt: the history, status quo and potential future development. T Wu, S He, J Liu, 10.1109/JAS.2023.123618IEEE/CAA J Autom Sinica. 102023</p>
<p>Large language models in medicine. A J Thirunavukarasu, Dsj Ting, K Elangovan, 10.1038/s41591-023-02448-8Nat Med. 292023</p>
<p>Large language models encode clinical knowledge. K Singhal, S Azizi, T Tu, 10.1038/s41586-023-06291-2Nature. 6202023</p>
<p>Clinicalbert: modeling clinical notes and predicting hospital readmission. K Huang, J Altosaar, R Ranganath, 2020Preprint</p>
<p>Fine-Tuning Large Language Models for Radiation Oncology, A Specialized Health Care Domain. P Wang, Z Liu, Y Li, 10.1016/j.ijrobp.2024.07.1456Int J Radiat Oncol Biol Phy. 120e6642024</p>
<p>GPT-4 for Information retrieval and comparison of medical oncology guidelines. D Ferber, I C Wiest, G Wölflein, 10.1056/AIcs2300235NEJM AI. 12024</p>
<p>Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, 2022Preprint</p>
<p>Unveiling llm evaluation focused on metrics: challenges and solutions. T Hu, X H Zhou, Preprint] 2024</p>
<p>Comparing physician and artificial intelligence chatbot responses to patient questions posted to a public social media forum. J W Ayers, A Poliak, M Dredze, 10.1001/jamainternmed.2023.1838JAMA Intern Med. 1832023</p>
<p>Evaluating large language models as agents in the clinic. N Mehandru, B Y Miao, E R Almaraz, 10.1038/s41746-024-01083-yNPJ Digit Med. 7842024</p>
<p>Performance of large language models on medical oncology examination questions. J B Longwell, I Hirsch, F Binder, 10.1001/jamanetworkopen.2024.17641JAMA Netw Open. 7e24176412024</p>
<p>Retrieval augmented therapy suggestion for molecular tumor boards: algorithmic development and validation study. E Berman, Sundberg Malek, H Bitzer, M , 10.2196/64364J Med Internet Res. 27e643642025</p>
<p>A framework for human evaluation of large language models in healthcare derived from literature review. Tyc Tam, S Sivarajkumar, S Kapoor, 10.1038/s41746-024-01258-7NPJ Digit Med. 72582024</p>
<p>Assessing the role of GPT-4 in thyroid ultrasound diagnosis and treatment recommendations: enhancing interpretability with a chain of thought approach. Z Wang, Z Zhang, A Traverso, 10.21037/qims-23-1180Quant Imaging Med Surg. 142024</p>
<p>Assessing the utility of multimodal large language models (gpt-4 vision and large language and vision assistant) in identifying melanoma across different skin tones. K Cirone, M Akrout, L Abid, 10.2196/55508JMIR Dermatol. 7e555082024</p>
<p>Large-Scale assessment of ChatGPT's performance in benign and malignant bone tumors imaging report diagnosis and its potential for clinical applications. F Yang, D Yan, Z Wang, 10.1016/j.jbo.2024.100525J Bone Oncol. 441005252024</p>
<p>Diagnosis of malignancy in oropharyngeal confocal laser endomicroscopy using GPT 4.0 with vision. M Sievert, M Aubreville, S K Mueller, 10.1007/s00405-024-08476-5Eur Arch Otorhinolaryngol. 2812024</p>
<p>Accuracy of ChatGPT generated diagnosis from patient's medical history and imaging findings in neuroradiology cases. D Horiuchi, H Tatekawa, T Shimono, 10.1007/s00234-023-03252-4Neuroradiology. 662024</p>
<p>Auto-delineation of Treatment Target Volume for Radiation Therapy Using Large Language Model-Aided Multimodal Learning. P Rajendran, Y Chen, L Qiu, 10.1016/j.ijrobp.2024.07.2149Int J Radiat Oncol Biol Phy. 1212025</p>
<p>Outcome Prediction Using Multi-Modal Information: Integrating Large Language Model-Extracted Clinical Information and Image Analysis. D Sun, L Hadjiiski, J Gormley, 10.3390/cancers16132402Cancers (Basel). 162402</p>
<p>Performance evaluation of multimodal large language models (LLaVA and GPT-4-based chatGPT) in medical image classification tasks. Y Guo, Wan Z , IEEE 12th International Conference on Healthcare Informatics (ICHI). Orlando, FL, USAIEEE2024</p>
<p>Clinical-grade computational pathology using weakly supervised deep learning on whole slide images. G Campanella, M G Hanna, L Geneslaw, 10.1038/s41591-019-0508-1Nat Med. 252019</p>
<p>High-performance medicine: the convergence of human and artificial intelligence. E J Topol, 10.1038/s41591-018-0300-7Nat Med. 252019</p>
<p>Artificial intelligence and machine learning in cancer imaging. D-M Koh, N Papanikolaou, U Bick, 10.1038/s43856-022-00199-0Commun Med (Lond). 21332022</p>
<p>Adequacy of prostate cancer prevention and screening recommendations provided by an artificial intelligence-powered large language model. G Chiarelli, A Stephens, M Finati, 10.1007/s11255-024-04009-5Int Urol Nephrol. 562024</p>
<p>Applicability of Online Chat-Based Artificial Intelligence Models to Colorectal Cancer Screening. J Atarere, H Naqvi, C Haas, 10.1007/s10620-024-08274-3Dig Dis Sci. 692024</p>
<p>Evaluation of ChatGPT and Google Bard Using Prompt Engineering in Cancer Screening Algorithms. D Nguyen, D Swanson, A Newbury, 10.1016/j.acra.2023.11.002Acad Radiol. 312024</p>
<p>Use of Artificial Intelligence Chatbots for Cancer Treatment Information. S Chen, B H Kann, M B Foote, 10.1001/jamaoncol.2023.2954JAMA Oncol. 92023</p>
<p>Exploring the landscape of AI-assisted decision-making in head and neck cancer treatment: a comparative analysis of NCCN guidelines and ChatGPT responses. F Marchi, E Bellini, A Iandelli, 10.1007/s00405-024-08525-zEur Arch Otorhinolaryngol. 2812024</p>
<p>Accuracy and usability of artificial intelligence chatbot generated chemotherapy protocols. E C Erdat, M Yalciner, Y N Urun, 10.2217/fon-2023-0950Future Oncol. </p>
<p>Use of artificial intelligence chatbots in clinical management of immune-related adverse events. H Burnette, A Pabani, M S Von Itzstein, 10.1136/jitc-2023-008599J Immunother Cancer. 12e0085992024</p>
<p>Large language model (ChatGPT) as a support tool for breast tumor board. V Sorin, E Klang, M Sklair-Levy, 10.1038/s41523-023-00557-8NPJ Breast Cancer. 9442023</p>
<p>Conversational artificial intelligence (chatGPTTM) in the management of complex colorectal cancer patients: early experience. J M Choo, H S Ryu, J S Kim, 10.1111/ans.18749ANZ J Surg. 942024</p>
<p>Performance of Multimodal Artificial Intelligence Chatbots Evaluated on Clinical Oncology Cases. D Chen, R S Huang, J Jomy, 10.1001/jamanetworkopen.2024.37711JAMA Netw Open. 7e24377112024</p>
<p>Leveraging Large Language Models for Decision Support in Personalized Oncology. M Benary, X D Wang, M Schmidt, 10.1001/jamanetworkopen.2023.43689JAMA Netw Open. 6e23436892023</p>
<p>Toward structuring real-world data: Deep learning for extracting oncology information from clinical text with patient-level supervision. S Preston, M Wei, R Rao, 10.1016/j.patter.2023.100726Patterns (N Y). 41007262023</p>
<p>Large language models to identify social determinants of health in electronic health records. M Guevara, S Chen, S Thomas, 10.1038/s41746-023-00970-0NPJ Digit Med. 762024</p>
<p>Using natural language processing to identify acute care patients who lack advance directives, decisional capacity, and surrogate decision makers. J Song, M Topaz, A Y Landau, 10.1371/journal.pone.0270220PLoS ONE. 17e02702202022</p>
<p>Providing Care Beyond Therapy Sessions With a Natural Language Processing-Based Recommender System That Identifies Patients Who Experience Psychosocial Challenges and Provides Self-care Support: Pilot Study. Y W Leung, B Park, R Heo, 10.2196/35893JMIR Cancer. 8e358932022</p>
<p>How Does ChatGPT Perform on the United States Medical Licensing Examination (USMLE)? The Implications of Large Language Models for Medical Education and Knowledge Assessment. A Gilson, C W Safranek, T Huang, 10.2196/45312JMIR Med Educ. 9e453122023</p>
<p>Physician and Artificial Intelligence Chatbot Responses to Cancer Questions From Social Media. D Chen, R Parsa, A Hope, 10.1001/jamaoncol.2024.0836JAMA Oncol. 109562024</p>
<p>Assessment of Artificial Intelligence Chatbot Responses to Top Searched Queries About Cancer. A Pan, D Musheyev, D Bockelman, 10.1001/jamaoncol.2023.2947JAMA Oncol. 92023</p>
<p>ChatGPT accurately performs genetic counseling for gynecologic cancers. J M Patel, C E Hermann, W B Growdon, 10.1016/j.ygyno.2024.04.006Gynecol Oncol. 1832024</p>
<p>Consulting the Digital Doctor: Google Versus ChatGPT as Sources of Information on Breast Implant-Associated Anaplastic Large Cell Lymphoma and Breast Implant Illness. H Y Liu, Alessandri Bonetti, M , De Lorenzi, F , 10.1007/s00266-023-03713-4Aesth Plast Surg. 482024</p>
<p>How AI Responds to Common Lung Cancer Questions: ChatGPT vs Google Bard. A A Rahsepar, N Tavakoli, Ghj Kim, 10.1148/radiol.230922Radiology. 307e2309222023</p>
<p>How appropriate are answers of online chat-based artificial intelligence (ChatGPT) to common questions on colon cancer?. S H Emile, N Horesh, M Freund, 10.1016/j.surg.2023.06.005Surgery. 1742023</p>
<p>Quality of ChatGPT Responses to Questions Related to Pancreatic Cancer and its Surgical Care. Z Moazzam, J Cloyd, H A Lima, 10.1245/s10434-023-13777-wAnn Surg Oncol. 302023</p>
<p>Scaling neural machine translation to 200 languages. 10.1038/s41586-024-07335-xNature. 6302024</p>
<p>Biomedical text readability after hypernym substitution with fine-tuned large language models. K Swanson, S He, J Calvano, 10.1371/journal.pdig.0000489PLOS Digit Health. 3e00004892024</p>
<p>Artificial Intelligence-Generated Draft Replies to Patient Inbox Messages. P Garcia, S P Ma, S Shah, 10.1001/jamanetworkopen.2024.3201JAMA Netw Open. 7e2432012024</p>
<p>Integration of a large language model with augmentative and alternative communication tool for oncological aphasia rehabilitation. Y Zeng, Q Tang, S Chen, 10.1016/j.apjon.2023.100344Asia Pac J Oncol Nurs. 111003442024</p>
<p>Understanding large-language model (llm)-powered human-robot interaction. C Y Kim, C P Lee, B Mutlu, 2024</p>
<p>The Patient's Perspective: Cross-Sectional Study. J Armbruster, F Bussmann, C Rothhaas, 10.2196/58831J Med Internet Res. 26e588312024Doctor ChatGPT, Can You Help Me?</p>
<p>Putting chatgpt's medical advice to the (turing) test: survey study. O Nov, N Singh, D Mann, 10.2196/46939JMIR Med Educ. 9e469392023</p>
<p>Public comfort with the use of ChatGPT and expectations for healthcare. J Platt, P Nong, R Smiddy, 10.1093/jamia/ocae164J Am Med Inform Assoc. 312024</p>
<p>Perceptions of ChatGPT in healthcare: usefulness, trust, and risk. S Y Chen, H Y Kuo, S H Chang, 10.3389/fpubh.2024.1457131Front Public Health. 1214571312024</p>
<p>Investigating the Impact of User Trust on the Adoption and Use of ChatGPT: Survey Analysis. A Choudhury, H Shamszare, 10.2196/47184J Med Internet Res. 25e471842023</p>
<p>Performance of a trained large language model to provide clinical trial recommendation in a head and neck cancer population. T Hung, G Kuperman, E J Sherman, 10.1200/JCO.2024.42.16_suppl.11081JCO. 42110812024</p>
<p>Scaling clinical trial matching using large language models: a case study in oncology. C Wong, S Zhang, Y Gu, 2023Preprint</p>
<p>The answer is 17 years, what is the question: understanding time lags in translational research. Z S Morris, S Wooding, J Grant, 10.1258/jrsm.2011.110180J R Soc Med. 1042011</p>
<p>Seetrials: leveraging large language models for safety and efficacy extraction in oncology clinical trials. K Lee, H Paek, L-C Huang, 10.2139/ssrn.48822622024Preprint</p>
<p>Deep-GenMut: Automated genetic mutation classification in oncology: A deep learning comparative study. E A Elsamahy, A E Ahmed, T Shoala, 10.1016/j.heliyon.2024.e32279Heliyon. 10e322792024</p>
<p>CancerGPT for few shot drug pair synergy prediction using large pretrained language models. T Li, S Shetty, A Kamath, 10.1038/s41746-024-01024-9Digit Med. 7402024</p>
<p>Current safeguards, risk mitigation, and transparency measures of large language models against the generation of health disinformation: repeated cross sectional analysis. B D Menz, N M Kuderer, S Bacchi, 10.1136/bmj-2023-078538BMJ. 384e0785382024</p>
<p>ChatGPT's Response Consistency: A Study on Repeated Queries of Medical Examination Questions. P F Funk, C C Hoch, S Knoedler, 10.3390/ejihpe14030043EJIHPE. 142024</p>
<p>World Health Organization. Ethics and governance of artificial intelligence for health: WHO guidance. 1st edn. 2021. Available</p>
<p>Ethical and regulatory challenges of large language models in medicine. Jcl Ong, S-H Chang, W William, 10.1016/S2589-7500(24)00061-XLancet Digit Health. 62024</p>
<p>Ethical Concerns About ChatGPT in Healthcare: A Useful Tool or the Tombstone of Original and Reflective Thinking?. M Z Kapsali, E Livanis, C Tsalikidis, 10.7759/cureus.54759Cureus. 16e547592024</p>
<p>Patients' Trust in Artificial Intelligence-based Decision-making for Localized Prostate Cancer: Results from a Prospective Trial. S Rodler, R Kopliku, D Ulrich, 10.1016/j.euf.2023.10.020Eur Urol Focus. 102024</p>
<p>Medical malpractice liability in large language model artificial intelligence: legal review and policy recommendations. D O Shumway, H J Hartman, 10.1515/jom-2023-0229J Osteopath Med. 1242024</p>
<p>Large language models propagate race-based medicine. J A Omiye, J C Lester, S Spichak, 10.1038/s41746-023-00939-zNPJ Digit Med. 61952023</p>
<p>Evaluating and addressing demographic disparities in medical large language models: a systematic review. M Omar, V Sorin, R Agbareia, 10.1186/s12939-025-02419-0Int J Equity Health. 24572025</p>
<p>Increasing diversity in clinical trials: demographic trends at the National Cancer Institute, 2005-2020. N Choradia, F Karzai, R Nipp, 10.1093/jnci/djae018J Natl Cancer Inst. 1162024</p>
<p>A strategy for cost-effective large language model use at health system-scale. E Klang, D Apakama, E E Abbott, 10.1038/s41746-024-01315-1NPJ Digit Med. 73202024</p>
<p>Environmental impact of large language models in medicine. O Kleinig, S Sinhal, R Khurram, 10.1111/imj.16549Intern Med J. 542024</p>
<p>Reconciling the contrasting narratives on the environmental impact of large language models. S Ren, B Tomlinson, R W Black, 10.1038/s41598-024-76682-6Sci Rep. 14263102024</p>
<p>The Future of Cancer Care in the United States-Overcoming Workforce Capacity Limitations. L N Shulman, L K Sheldon, E J Benz, 10.1001/jamaoncol.2019.5358JAMA Oncol. 63272020</p>
<p>The shift from models to compound AI systems. M Zaharia, K Om, L Chen, </p>
<p>Autonomous chemical research with large language models. D A Boiko, R Macknight, B Kline, 10.1038/s41586-023-06792-0Nature New Biol. 6242023</p>
<p>Solving olympiad geometry without human demonstrations. T H Trinh, Y Wu, Q V Le, 10.1038/s41586-023-06747-5Nature. 6252024</p>
<p>Multi-modal large language models in radiology: principles, applications, and potential. Y Shen, Y Xu, J Ma, 10.1007/s00261-024-04708-8Abdom Radiol. 502024</p>
<p>Capacity of ChatGPT to Identify Guideline-Based Treatments for Advanced Solid Tumors. B Schulte, 10.7759/cureus.37938Cureus. 15e379382023</p>
<p>Governing Data and Artificial Intelligence for Health Care: Developing an International Understanding. J Morley, L Murphy, A Mishra, 10.2196/31623JMIR Form Res. 6e316232022</p>
<p>Implementing the FAIR Data Principles in precision oncology: review of supporting initiatives. C Vesteghem, R F Brøndum, M Sønderkaer, 10.1093/bib/bbz044Brief Bioinform. 212020</p>
<p>The tripod-llm statement: a targeted guideline for reporting large language models use. J Gallifant, M Afshar, S Ameen, 10.1101/2024.07.24.24310930medRxiv 2024</p>
<p>Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI extension. X Liu, Cruz Rivera, S Moher, D , 10.1038/s41591-020-1034-xNat Med. 262020</p>
<p>RadOnc-gpt: a large language model for radiation oncology. Z Liu, P Wang, Y Li, 2023Preprint</p>            </div>
        </div>

    </div>
</body>
</html>