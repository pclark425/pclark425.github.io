<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-748 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-748</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-748</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-257952674</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2304.02286v1.pdf" target="_blank">A step towards the applicability of algorithms based on invariant causal learning on observational data</a></p>
                <p><strong>Paper Abstract:</strong> Machine learning can benefit from causal discovery for interpretation and from causal inference for generalization. In this line of research, a few invariant learning algorithms for out-of-distribution (OOD) generalization have been proposed by using multiple training environments to find invariant relationships. Some of them are focused on causal discovery as Invariant Causal Prediction (ICP), which finds causal parents of a variable of interest, and some directly provide a causal optimal predictor that generalizes well in OOD environments as Invariant Risk Minimization (IRM). This group of algorithms works under the assumption of multiple environments that represent different interventions in the causal inference context. Those environments are not normally available when working with observational data and real-world applications. Here we propose a method to generate them in an efficient way. We assess the performance of this unsupervised learning problem by implementing ICP on simulated data. We also show how to apply ICP efficiently integrated with our method for causal discovery. Finally, we proposed an improved version of our method in combination with ICP for datasets with multiple covariates where ICP and other causal discovery methods normally degrade in performance.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e748.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e748.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DT-Env-ICP (ICPv1)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Decision-tree supervised clustering to generate environments combined with Invariant Causal Prediction (ICPv1)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method introduced in this paper that generates environments for invariant causal algorithms by fitting a decision tree per covariate (supervised clustering) to create latent environment clusters, then applies ICP tests across those environments to identify causal parents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Decision-tree supervised clustering + ICP (ICPv1)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>For each input Xi the method fits a decision tree predicting the target Y and uses tree leaf thresholds to define K environments (latent clusters) that induce dataset shift (P(Xi,Y) differs across environments). For each candidate subset S of covariates it fits a predictive model across all environments (linear regression in linear case), computes residuals R = Y - Xβ(S), and tests invariance of residual means (two-sample t-tests with Bonferroni correction) and variances (F-test) across environments. Subsets failing invariance are rejected; the intersection of not-rejected subsets yields candidate causal parents for Y. Uses two-sample KS tests to check dataset-shift between generated environments.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Simulated/observational datasets (synthetic datasets used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational synthetic datasets (multiple simulated datasets described in the paper). These are not interactive or open-ended virtual labs; environments are latent clusters produced from the observational data via supervised decision-tree splits and represent different (hypothesized) interventions/covariate shifts.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Exploitation of invariance: generate environment-induced distribution shifts and identify variables whose predictive relationship with Y remains invariant across environments; variable selection by intersection of invariant subsets (reject subsets showing environment-dependent residual statistics). Uses decision-tree splits to induce shifts so that spurious predictors (distractors) are likely non-invariant and can be rejected.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious correlations and irrelevant variables that change association with Y across environments; confounding is considered in dataset generation but method focuses on invariance to rule out non-causal predictors.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Dataset-shift detection with two-sample KS test on (Xi,Y) between environments; invariance detection via two-sample t-tests on residual means and F-tests on residual variances across environments (Bonferroni correction; combined p-value computed as twice the minimum).</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Statistical rejection of candidate subsets whose residuals' means or variances differ across environments (p-value threshold α). Final causal candidates are variables that appear in all non-rejected subsets (intersection).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Experiment 1 (using generated environments + ICP): reported very high True Positive Rate (TPR near 1.0 for many cases) and low False Discovery Rate (FDR ≈ 0.04 in best runs); in Experiment 2 (more complex graphs) ICPv1 degrades (lower TPR and higher FDR) relative to ICPv2 and some baselines (see paper tables).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Generating environments with decision-tree supervised clustering enables application of ICP on purely observational data by guaranteeing dataset-shift between environments; the approach effectively distinguishes invariant (likely causal) predictors from spurious ones in moderate-dimensional synthetic problems, yielding high TPR and low FDR in simpler datasets, but performance declines in high-dimensional / complex causal graphs (motivating ICPv2).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e748.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e748.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ICPv2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Improved ICP combined with decision-tree environment generation and voting (ICPv2)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An improved variant of the decision-tree environment generation + ICP pipeline introduced in the paper that constrains subset sizes and uses a voting (frequency) based confidence rule to be more robust when many covariates are present.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>ICPv2 (voting-based robust ICP)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Before exhaustive subset testing, limit inputs to subsets of size N=5 and test all such subsets; each subset yields candidate causal variables according to the same invariance tests (residual mean/variance equality across environments). Apply a voting procedure across repeated checks: only keep variables that are selected as candidates in a sufficiently high fraction of checks (e.g., for α=0.1 keep candidates selected in ≥90% of checks). This reduces conservativeness and improves robustness when number of covariates grows.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Simulated/observational datasets (synthetic datasets used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational synthetic datasets; environments are generated per-variable by decision-tree splits; still not an interactive/active experimental environment.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Same invariance-based selection as ICPv1, but uses constrained subset testing and a voting (frequency) rule to stabilize selection against distractors and noisy, non-invariant associations.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant variables, spurious correlations that are non-invariant across generated environments; to some extent confounders present in simulations are considered in evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Two-sample KS test for dataset shift between generated environments; invariance detection via t-tests on residual means and F-tests on residual variances across environments; Bonferroni correction and combined p-value rule used per check; final detection reinforced by voting across many subset checks.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Rejects subsets failing invariance tests; further refutes spurious candidates by requiring high-frequency selection across many constrained-subset checks (voting threshold tied to chosen α).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Reported strong performance in Experiment 2 (more complex graphs): ICPv2 achieved TPR = 1.0 on Dataset5 and Dataset6 in the reported tables; FDRs reported for ICPv2: Dataset5 FDR = 0.08, Dataset6 FDR = 0.21 (paper tables). ICPv2 outperformed ICPv1, FCI and LiNGAM on these simulated complex graphs according to the reported TPR/FDR.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>ICPv1 (the earlier version) showed substantially worse performance on the larger/more complex graphs (examples in paper: lower TPRs e.g., ~0.6-0.73 and FDRs in some cases 0.10-0.11), demonstrating the advantage of the voting/limited-subset approach in ICPv2.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Constraining subset size and using a voting-based acceptance rule substantially improves ICP's ability to recover causal parents in higher-dimensional/complex simulated datasets; the voting rule reduces false discoveries while maintaining or improving true positive detection compared to the original ICP pipeline with generated environments.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e748.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e748.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ICP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Invariant Causal Prediction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A causal discovery algorithm that searches for subsets of predictors whose conditional distribution of the target remains invariant across multiple environments; the intersection of such invariant subsets is taken as causal parents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal inference by using invariant prediction: identifi-cation and confidence intervals</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Invariant Causal Prediction (ICP)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>ICP enumerates subsets S of predictors and tests whether the conditional distribution P(Y | S) is identical across given environments; in linear cases this reduces to testing equality of regression coefficients and residual distributions across environments. Variables present in all invariant subsets are reported as causal parents. ICP is conservative (intersection-based) and relies on pre-specified environments representing different interventions or distributional shifts.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Environments provided or generated from observational data (in this paper: decision-tree-derived latent environments)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Originally requires multiple environments representing different interventions; in this paper ICP is applied using environments generated from observational data via decision-tree supervised clustering (latent clusters acting as environments). Not interactive/active experimentation.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detects and excludes distractors by requiring invariance across environments: spurious predictors that change relation to Y across environments will be rejected when testing subset invariance; selection occurs via intersection of invariant subsets.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious correlations (non-invariant associations), unstable predictors across environments; can mitigate some effects of confounding insofar as confounding induces environment-dependent associations.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Testing invariance of predictive models across environments — e.g., testing equality of regression coefficients and equality of residual statistics (means/variances) across environments using t-tests/F-tests or equivalent nonparametric tests.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Subsets are rejected if invariance tests fail at chosen significance level; final causal set is intersection of non-rejected subsets, which rules out variables showing non-invariant behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>When applied with the decision-tree generated environments in this paper, ICP (as used in experiments) achieved very high TPR in simple/moderate simulations (paper reports TPR near 1.0 in Experiment 1) and low FDR (~0.04), but performance degrades as number of covariates and causal complexity increase unless robustness modifications (ICPv2) are used.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>ICP's invariance principle is effective to separate causal predictors from spurious correlates when appropriate environments exist or can be generated; however, ICP is conservative and can suffer in high-dimensional settings without additional strategies (e.g., ICPv2 voting/limiting subsets).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e748.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e748.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IRM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Invariant Risk Minimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representation learning approach that seeks data representations on which a single predictor achieves simultaneously optimal (or near-optimal) performance across multiple environments, aiming for robust OOD generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Invariant risk minimization.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Invariant Risk Minimization (IRM)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>IRM optimizes for a representation φ and classifier w such that w ∘ φ minimizes risk in each environment and the optimal classifier w is the same across all environments; operationalized via a penalty encouraging invariance of optimal predictors across environments. IRM focuses on producing OOD-generalizable predictors rather than explicit causal parent set discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Not instantiated in this paper's experiments (mentioned only)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Originally formulated for settings with given environments (domains) reflecting interventions/shift; in related literature environments sometimes generated by data splits or domain labels.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Aims to avoid spurious correlations that vary across environments by enforcing invariance of predictors; implicitly addresses environment-dependent spurious features.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Implicit via representation learning and penalty that discourages environment-specific predictive features (not detailed in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as a related invariant-learning method aiming for OOD generalization; the paper notes IRM relies on multiple environments and is not directly applicable to many observational datasets without generating environments.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e748.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e748.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ISL / K-means splitting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Invariant Structure Learning (ISL) / K-means environment splitting (as referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior work referenced in the paper that incorporates unsupervised clustering (K-means) to create environments for invariant learning algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>ISL / K-means environment splitting</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>A technique (referenced) that generates environments by unsupervised clustering (K-means) of data points to create domains for invariant learning; mentioned as prior art for environment creation in deep learning contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Environments generated by K-means clustering on observational data (as in cited prior work)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Latent clusters produced by unsupervised K-means; not interactive or active experimentation. Unlike the decision-tree approach in this paper, K-means does not condition clusters on Y directly (unsupervised).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as an alternative approach to generate environments from observational data (unsupervised K-means); the paper positions its supervised decision-tree clustering as preferable because it conditions on Y to better guarantee dataset-shift in P(X,Y).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Invariant risk minimization. <em>(Rating: 2)</em></li>
                <li>Causal inference by using invariant prediction: identifi-cation and confidence intervals <em>(Rating: 2)</em></li>
                <li>Invariant structure learning for better generalization and causal explainability <em>(Rating: 2)</em></li>
                <li>Invariantcausalprediction python library icpy <em>(Rating: 1)</em></li>
                <li>Invariant risk minimization games <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-748",
    "paper_id": "paper-257952674",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "DT-Env-ICP (ICPv1)",
            "name_full": "Decision-tree supervised clustering to generate environments combined with Invariant Causal Prediction (ICPv1)",
            "brief_description": "A method introduced in this paper that generates environments for invariant causal algorithms by fitting a decision tree per covariate (supervised clustering) to create latent environment clusters, then applies ICP tests across those environments to identify causal parents.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Decision-tree supervised clustering + ICP (ICPv1)",
            "method_description": "For each input Xi the method fits a decision tree predicting the target Y and uses tree leaf thresholds to define K environments (latent clusters) that induce dataset shift (P(Xi,Y) differs across environments). For each candidate subset S of covariates it fits a predictive model across all environments (linear regression in linear case), computes residuals R = Y - Xβ(S), and tests invariance of residual means (two-sample t-tests with Bonferroni correction) and variances (F-test) across environments. Subsets failing invariance are rejected; the intersection of not-rejected subsets yields candidate causal parents for Y. Uses two-sample KS tests to check dataset-shift between generated environments.",
            "environment_name": "Simulated/observational datasets (synthetic datasets used in experiments)",
            "environment_description": "Observational synthetic datasets (multiple simulated datasets described in the paper). These are not interactive or open-ended virtual labs; environments are latent clusters produced from the observational data via supervised decision-tree splits and represent different (hypothesized) interventions/covariate shifts.",
            "handles_distractors": true,
            "distractor_handling_technique": "Exploitation of invariance: generate environment-induced distribution shifts and identify variables whose predictive relationship with Y remains invariant across environments; variable selection by intersection of invariant subsets (reject subsets showing environment-dependent residual statistics). Uses decision-tree splits to induce shifts so that spurious predictors (distractors) are likely non-invariant and can be rejected.",
            "spurious_signal_types": "Spurious correlations and irrelevant variables that change association with Y across environments; confounding is considered in dataset generation but method focuses on invariance to rule out non-causal predictors.",
            "detection_method": "Dataset-shift detection with two-sample KS test on (Xi,Y) between environments; invariance detection via two-sample t-tests on residual means and F-tests on residual variances across environments (Bonferroni correction; combined p-value computed as twice the minimum).",
            "downweighting_method": null,
            "refutation_method": "Statistical rejection of candidate subsets whose residuals' means or variances differ across environments (p-value threshold α). Final causal candidates are variables that appear in all non-rejected subsets (intersection).",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Experiment 1 (using generated environments + ICP): reported very high True Positive Rate (TPR near 1.0 for many cases) and low False Discovery Rate (FDR ≈ 0.04 in best runs); in Experiment 2 (more complex graphs) ICPv1 degrades (lower TPR and higher FDR) relative to ICPv2 and some baselines (see paper tables).",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Generating environments with decision-tree supervised clustering enables application of ICP on purely observational data by guaranteeing dataset-shift between environments; the approach effectively distinguishes invariant (likely causal) predictors from spurious ones in moderate-dimensional synthetic problems, yielding high TPR and low FDR in simpler datasets, but performance declines in high-dimensional / complex causal graphs (motivating ICPv2).",
            "uuid": "e748.0"
        },
        {
            "name_short": "ICPv2",
            "name_full": "Improved ICP combined with decision-tree environment generation and voting (ICPv2)",
            "brief_description": "An improved variant of the decision-tree environment generation + ICP pipeline introduced in the paper that constrains subset sizes and uses a voting (frequency) based confidence rule to be more robust when many covariates are present.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "ICPv2 (voting-based robust ICP)",
            "method_description": "Before exhaustive subset testing, limit inputs to subsets of size N=5 and test all such subsets; each subset yields candidate causal variables according to the same invariance tests (residual mean/variance equality across environments). Apply a voting procedure across repeated checks: only keep variables that are selected as candidates in a sufficiently high fraction of checks (e.g., for α=0.1 keep candidates selected in ≥90% of checks). This reduces conservativeness and improves robustness when number of covariates grows.",
            "environment_name": "Simulated/observational datasets (synthetic datasets used in experiments)",
            "environment_description": "Observational synthetic datasets; environments are generated per-variable by decision-tree splits; still not an interactive/active experimental environment.",
            "handles_distractors": true,
            "distractor_handling_technique": "Same invariance-based selection as ICPv1, but uses constrained subset testing and a voting (frequency) rule to stabilize selection against distractors and noisy, non-invariant associations.",
            "spurious_signal_types": "Irrelevant variables, spurious correlations that are non-invariant across generated environments; to some extent confounders present in simulations are considered in evaluation.",
            "detection_method": "Two-sample KS test for dataset shift between generated environments; invariance detection via t-tests on residual means and F-tests on residual variances across environments; Bonferroni correction and combined p-value rule used per check; final detection reinforced by voting across many subset checks.",
            "downweighting_method": null,
            "refutation_method": "Rejects subsets failing invariance tests; further refutes spurious candidates by requiring high-frequency selection across many constrained-subset checks (voting threshold tied to chosen α).",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Reported strong performance in Experiment 2 (more complex graphs): ICPv2 achieved TPR = 1.0 on Dataset5 and Dataset6 in the reported tables; FDRs reported for ICPv2: Dataset5 FDR = 0.08, Dataset6 FDR = 0.21 (paper tables). ICPv2 outperformed ICPv1, FCI and LiNGAM on these simulated complex graphs according to the reported TPR/FDR.",
            "performance_without_robustness": "ICPv1 (the earlier version) showed substantially worse performance on the larger/more complex graphs (examples in paper: lower TPRs e.g., ~0.6-0.73 and FDRs in some cases 0.10-0.11), demonstrating the advantage of the voting/limited-subset approach in ICPv2.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "Constraining subset size and using a voting-based acceptance rule substantially improves ICP's ability to recover causal parents in higher-dimensional/complex simulated datasets; the voting rule reduces false discoveries while maintaining or improving true positive detection compared to the original ICP pipeline with generated environments.",
            "uuid": "e748.1"
        },
        {
            "name_short": "ICP",
            "name_full": "Invariant Causal Prediction",
            "brief_description": "A causal discovery algorithm that searches for subsets of predictors whose conditional distribution of the target remains invariant across multiple environments; the intersection of such invariant subsets is taken as causal parents.",
            "citation_title": "Causal inference by using invariant prediction: identifi-cation and confidence intervals",
            "mention_or_use": "use",
            "method_name": "Invariant Causal Prediction (ICP)",
            "method_description": "ICP enumerates subsets S of predictors and tests whether the conditional distribution P(Y | S) is identical across given environments; in linear cases this reduces to testing equality of regression coefficients and residual distributions across environments. Variables present in all invariant subsets are reported as causal parents. ICP is conservative (intersection-based) and relies on pre-specified environments representing different interventions or distributional shifts.",
            "environment_name": "Environments provided or generated from observational data (in this paper: decision-tree-derived latent environments)",
            "environment_description": "Originally requires multiple environments representing different interventions; in this paper ICP is applied using environments generated from observational data via decision-tree supervised clustering (latent clusters acting as environments). Not interactive/active experimentation.",
            "handles_distractors": true,
            "distractor_handling_technique": "Detects and excludes distractors by requiring invariance across environments: spurious predictors that change relation to Y across environments will be rejected when testing subset invariance; selection occurs via intersection of invariant subsets.",
            "spurious_signal_types": "Spurious correlations (non-invariant associations), unstable predictors across environments; can mitigate some effects of confounding insofar as confounding induces environment-dependent associations.",
            "detection_method": "Testing invariance of predictive models across environments — e.g., testing equality of regression coefficients and equality of residual statistics (means/variances) across environments using t-tests/F-tests or equivalent nonparametric tests.",
            "downweighting_method": null,
            "refutation_method": "Subsets are rejected if invariance tests fail at chosen significance level; final causal set is intersection of non-rejected subsets, which rules out variables showing non-invariant behavior.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "When applied with the decision-tree generated environments in this paper, ICP (as used in experiments) achieved very high TPR in simple/moderate simulations (paper reports TPR near 1.0 in Experiment 1) and low FDR (~0.04), but performance degrades as number of covariates and causal complexity increase unless robustness modifications (ICPv2) are used.",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "ICP's invariance principle is effective to separate causal predictors from spurious correlates when appropriate environments exist or can be generated; however, ICP is conservative and can suffer in high-dimensional settings without additional strategies (e.g., ICPv2 voting/limiting subsets).",
            "uuid": "e748.2"
        },
        {
            "name_short": "IRM",
            "name_full": "Invariant Risk Minimization",
            "brief_description": "A representation learning approach that seeks data representations on which a single predictor achieves simultaneously optimal (or near-optimal) performance across multiple environments, aiming for robust OOD generalization.",
            "citation_title": "Invariant risk minimization.",
            "mention_or_use": "mention",
            "method_name": "Invariant Risk Minimization (IRM)",
            "method_description": "IRM optimizes for a representation φ and classifier w such that w ∘ φ minimizes risk in each environment and the optimal classifier w is the same across all environments; operationalized via a penalty encouraging invariance of optimal predictors across environments. IRM focuses on producing OOD-generalizable predictors rather than explicit causal parent set discovery.",
            "environment_name": "Not instantiated in this paper's experiments (mentioned only)",
            "environment_description": "Originally formulated for settings with given environments (domains) reflecting interventions/shift; in related literature environments sometimes generated by data splits or domain labels.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Aims to avoid spurious correlations that vary across environments by enforcing invariance of predictors; implicitly addresses environment-dependent spurious features.",
            "detection_method": null,
            "downweighting_method": "Implicit via representation learning and penalty that discourages environment-specific predictive features (not detailed in this paper).",
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Mentioned as a related invariant-learning method aiming for OOD generalization; the paper notes IRM relies on multiple environments and is not directly applicable to many observational datasets without generating environments.",
            "uuid": "e748.3"
        },
        {
            "name_short": "ISL / K-means splitting",
            "name_full": "Invariant Structure Learning (ISL) / K-means environment splitting (as referenced)",
            "brief_description": "Prior work referenced in the paper that incorporates unsupervised clustering (K-means) to create environments for invariant learning algorithms.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "ISL / K-means environment splitting",
            "method_description": "A technique (referenced) that generates environments by unsupervised clustering (K-means) of data points to create domains for invariant learning; mentioned as prior art for environment creation in deep learning contexts.",
            "environment_name": "Environments generated by K-means clustering on observational data (as in cited prior work)",
            "environment_description": "Latent clusters produced by unsupervised K-means; not interactive or active experimentation. Unlike the decision-tree approach in this paper, K-means does not condition clusters on Y directly (unsupervised).",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Cited as an alternative approach to generate environments from observational data (unsupervised K-means); the paper positions its supervised decision-tree clustering as preferable because it conditions on Y to better guarantee dataset-shift in P(X,Y).",
            "uuid": "e748.4"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Invariant risk minimization.",
            "rating": 2,
            "sanitized_title": "invariant_risk_minimization"
        },
        {
            "paper_title": "Causal inference by using invariant prediction: identifi-cation and confidence intervals",
            "rating": 2,
            "sanitized_title": "causal_inference_by_using_invariant_prediction_identification_and_confidence_intervals"
        },
        {
            "paper_title": "Invariant structure learning for better generalization and causal explainability",
            "rating": 2,
            "sanitized_title": "invariant_structure_learning_for_better_generalization_and_causal_explainability"
        },
        {
            "paper_title": "Invariantcausalprediction python library icpy",
            "rating": 1,
            "sanitized_title": "invariantcausalprediction_python_library_icpy"
        },
        {
            "paper_title": "Invariant risk minimization games",
            "rating": 1,
            "sanitized_title": "invariant_risk_minimization_games"
        }
    ],
    "cost": 0.0137955,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>A STEP TOWARDS THE APPLICABILITY OF ALGORITHMS BASED ON INVARIANT CAUSAL LEARNING ON OBSERVATIONAL DATA
March 30, 2023</p>
<p>Borja Guerrero Santillan b.guerrero@alumnos.upm.es 
Universidad Politécnica de Madrid(UPM)
ETSIINF
Spain</p>
<p>A STEP TOWARDS THE APPLICABILITY OF ALGORITHMS BASED ON INVARIANT CAUSAL LEARNING ON OBSERVATIONAL DATA
March 30, 2023Causal machine learning · Causal discovery · Out-of-distribution (OOD) generalization · Explainability
Machine learning can benefit from causal discovery for interpretation and from causal inference for generalization. In this line of research, a few invariant learning algorithms for out-ofdistribution (OOD) generalization have been proposed by using multiple training environments to find invariant relationships. Some of them are focused on causal discovery as Invariant Causal Prediction (ICP), which finds causal parents of a variable of interest, and some directly provide a causal optimal predictor that generalizes well in OOD environments as Invariant Risk Minimization (IRM). This group of algorithms works under the assumption of multiple environments that represent different interventions in the causal inference context. Those environments are not normally available when working with observational data and real-world applications. Here we propose a method to generate them in an efficient way. We assess the performance of this unsupervised learning problem by implementing ICP on simulated data. We also show how to apply ICP efficiently integrated with our method for causal discovery. Finally, we proposed an improved version of our method in combination with ICP for datasets with multiple covariates where ICP and other causal discovery methods normally degrade in performance.</p>
<p>Introduction</p>
<p>Current machine learning approaches suffer from a fundamental problem. They are limited to pattern recognition and learning complex prediction rules by minimizing a training error. As a consequence machine learning systems rely on data biases based on possible spurious correlations without understanding cause and effect relations in the data. This leads to a lack of generalizability with a limited ability to predict in unseen contexts. Causation is then key to achieve out of distribution generalizability and building more robust systems. that can answer interventional questions. Another important limitation of the current machine learning approaches is explainability. For the same reason, not really understand the causes and effects of the data. While methods based on model interpretation like LIME [22] and SHAP [17] can help on this issue, they do not really answer how data behave, just how a model does. Again to overcome this limitation causation is key. Then, we have seen how important is to infer cause and effect relationships. Generally, it is a standard procedure to implement a randomized controlled trial, whereby a random assignment of one population is applied and intervention(change in a variable of interest) while another population is not. From this experiment, the data is collected and used to measure the cause and effect of that intervention. However, these kinds of experiments can be difficult or impossible to conduct or simply not worthy due to cost, time, and other limitations. In those cases, we work with observational data and apply quantitative methods to discover causal relations, which is known as causal discovery.</p>
<p>Causal discovery is a challenging field and it is often performed by domain knowledge rather than quantitative tools. However, if there is no previous knowledge of possible causal relations we need mathematical methods to be applied. Causal discovery is based on the theory of structural causal models(SCM) [3], [24], [19] and causal graphs [16], [9], [27], [23], [25]. A causal graph is a directed acyclic graph denoting the dependency between variables. A structural causal 2 model also specifies the functional form of dependencies between variables. Between the computational methods based on graphical models, we can distinguish constraint-based and score-based methods versus the ones based on functional causal models. The PC and the Fast Causal Inference(FCI) [26] are constraint-based and work testing for conditional independence on a starting plausible causal graph. On the other hand, the Greedy Equivalence Search(GES) [5] aims to build the causal graph from zero checking if the causal relation to be added optimizes a defined score function. Also, we can find SCM algorithms based on non-gaussian models [25] and non-linear models [12], [21] which generally are able to distinguish between different Directed Acyclic Graphs but at the cost of making the additional assumptions of the SCM. However in general these methods have limitations since multiple causal structures can satisfy the same conditional independence. Therefore, often they can provide a set of plausible causal graphs which actually may not contain the true one.</p>
<p>More recently, a research wave has focused on the invariant property of causal relations for causal discovery and causal inference purposes. One of the first was the Invariant Causal Prediction (ICP) [20] which is a causal discovery algorithm based on considering all direct causes of a target variable of interest. This approach tries to exploit the well-known invariance property of causal relations as opposed to spurious correlations to infer causality. Specifically, the method hypothesis is that the conditional distribution of a target variable of interest given a set of direct causal predictors has to remain identical under different interventions. In this context, they define the concept of environments which are different datasets, each one representing a particular intervention. Then the algorithm iterates over multiple combinations of subsets of features to find the ones that are invariant as plausible causal parents of the target variable. Finally, the intersection of these sets of plausible causes, which are predictive in all environments, is then a subset of the true direct causes.</p>
<p>Invariant Risk minimization(IRM) [2] is another causal discovery algorithm based on the same idea of exploiting the invariant property of causal relation for inference. IRM also relies on the idea of training in multiple environments. However, IRM does not focus on retrieving the causal parents of the target in a causal graph. Rather, IRM aims to achieve out-of-distribution generalization for a predictive model in unseen environments. The IRM approach is based on optimizing a penalty function used to obtain a data representation, on which a model can perform optimally in all environments. Other related work has followed up with this concept and the ultimate goal of improving OOD generalization in different machine learning tasks [4], [7], [13], [1], [14]. Some of them are focused on specific cases such as non-linear ones [11] and robustness, especially in settings with high data shifts [10], [13], [18], [15].</p>
<p>In most of this work, the environment concept plays a central role. It is a general assumption to have given environments on the data. Following up with a realistic context and when working with observational data this is not normally the case and therefore it is not possible to apply these types of algorithms. Some recent work, specifically in the context of deep learning, has incorporated splitting methods to generate the environments [28]. Also, ISL [6] has been the first to incorporate unsupervised learning, in particular a K-means, into an invariant learning algorithm.</p>
<p>Here we proposed a method that is based on 'supervised clustering' to generate the environments which can be combined or not with ICP for causal discovery, and that can be combined with another algorithm that is based on the causal invariant property. We strictly interpret the assumptions made in the given environments of original work such as ICP and IRM. It is therefore an open door to implement these kinds of algorithms. It is suitable for observational data and real-world applications in general. Our method works well on mixed datasets with continuous, categorical, and binary features and also even when there are no high shifts in the data given, which can be often more challenging than the opposite case. We assess the performance of our method by combining it with ICP on multiple synthetic causal datasets with unknown environments so that we can check the real efficiency of the method.</p>
<p>Methodology</p>
<p>As we have seen, when working with observational data normally we do not know the environment needed to apply the invariant property. Hence we need a method to generate that environment for a given observational dataset.</p>
<p>Generating environments</p>
<p>In the context of causal discovery and ICP algorithms, we can define a set of inputs or covariates X and a target variable Y whose causal parents we want to study. Then, in the invariant causal algorithms, the main assumption that researchers take is that these environments represent different sources that could represent different interventions of a randomized experiment. Then these environments present by definition a change in the distribution of the covariates between them, which is known in the machine learning literature as covariate shift. Generally, this term refers to the shift between training and test set when in this context is between environments.</p>
<p>More strictly other researchers define these environments as presenting a change not only in the inputs but in the joint distribution between inputs and target i.e P(X, Y), which is generally addressed as dataset shifts. Since this assumption is necessary to apply ICP successfully it is our goal when generating environments. In this work, we propose a method based on a strict interpretation of this assumption that guarantees dataset shift between environments. This assumption can be written as P(Xi, Y)ej ≠ P(Xi, Y)ek when j ≠ k and ∀e ∈ E. A loose interpretation would be to generate a covariate shift between environments. The second interpretation could be not optimal and therefore have a higher risk of not finding the existing causal relations.</p>
<p>The environments are in other words latent clusters that are unknown. Since we have addressed the necessity to generate a dataset shift between them we propose a supervised clustering approach, an unsupervised classification that uses a supervised method. That way we can manage to obtain clusters with different joint distributions between inputs and target variables of interest. However, not all supervised models can provide identifiable clusters. Here we proposed a decision tree as the algorithm that can meet both requirements. First, a decision tree can be fitted as a supervised algorithm and it maximizes the heterogeneity between the nodes generated by each split. In other words, it maximizes the variance between nodes taking into account the input and its relations with the output, which is precisely what we want to achieve. On the other hand, the splits are perfectly defined by the threshold on the features which are known as the splitting conditions, and therefore we can obtain the clusters where each final node constitutes an environment. One important aspect is that each variable can meet the requirement. That is why the generation of the environment is conditional on each input variable and the target of interest. Hence, for a given fixed number E of environments, we will generate E environments for each Xi in X conditioning on Y . That way we can guarantee testing causality for each covariate. Regarding the number of clusters, we prefer a medium number of them rather than a small one. Informally that is because it is a more robust result and also can a better guarantee than having by instance only two environments. On the other hand, we have not seen the special advantages of using a high number of environments.</p>
<p>Theoretical Framework</p>
<p>Once we have generated the environments we can exploit the property of causal invariance to perform causal discovery on observational data. We recall the invariance assumption, as [20] originally defined, and discuss the notion of identifiable causal predictors. Let's define E as the space of all possible interventions and therefore E contains all the individual environments e. As stated above, we have variables (X)e, (Y )e with a joint distribution that will in general depend on the environment e ∈ E. </p>
<p>where ϵe is an error with mean zero, finite variance, and the same distribution F ∈ across all e ∈ E. Hence, the variables that have a direct causal effect on Y in a SEM form a set S ⋆ for which Proposition 1 is satisfied. Therefore the first implication of the invariant prediction assumption is that given a subset of variables S ⋆ that contain the real 4 causal parents of Y its vector of coefficients is constant between environments. The second implication is that the residuals of the model must have equal mean across environments and, in a strict interpretation, equal variance too.</p>
<p>More formally, and from a probabilistic point of view, we can define the invariant causal property as equality between environments of the conditional probability of the target variable given the causal parent. Then the complete theoretical framework that we propose for causal discovery has to meet two conditions:</p>
<ol>
<li>
<p>Inequality of joint distributions of target and input variables among environments, sometimes referred to as dataset shift.
P(Xi, Y )ej ≠ P(Xi, Y )ek, j ≠ k, ∀e ∈ E(2)
where i =1,2,...,N being N the number of covariates, and j, k = 1,2,...,K being K the number of environments.</p>
</li>
<li>
<p>Equality of conditional probability of the target variable given the causal parent.
P(Xi|Y )ej = P (Xi|Y )ek, j ≠ k, ∀e ∈ E(3)
where i =1,2,...,N being N the number of covariates, and j, k = 1,2,...,K being K the number of environments.</p>
</li>
</ol>
<p>Since our method generates environments associated with each variable individually to assure that condition 1 is met, we have to check also condition 2 individually for the corresponding environment e, and only when both conditions are met do we consider Xi to be a causal parent of the target variable Y .</p>
<p>The algorithm</p>
<p>Having understood the theoretical framework we can define the steps of the algorithm. Given a dataset where we select a target variable to be studied Y and the rest of the covariates as X, the steps are:</p>
<ol>
<li>Fit a decision tree on every Xi and Y with a fixed number K of environments, as a classifier for binary or categorical target variables and as a regressor otherwise. 2. Keep the thresholds defined by the tree for each variable to form the environment. With this, we obtain K environments (e1i, e2i, . . . , eki) for each Xi. We can perform a two-sample KS test to check the dataset shift between environments. 3. For all possible subsets of input variables:</li>
</ol>
<p>(a) Train a model using all environments, only the specific input features in that subset, and obtain the residuals. For the linear case, we fit a linear regression with estimated parameters β(S) and residuals R = Y − Xβ(S) ⋆ . (b) Test the null hypothesis that the mean of the residuals is equal for every environment using a two sample T-test and Bonferroni correction when combining all. For equal variance use an F-test and Bonferroni correction. Finally, combine both p-values using twice the minimum value and reject the subset if the final p-value is lower than a level of confidence α. 4. Find the features present in all the not rejected subsets as potential causal predictors. Only keep the variables Xi that are candidates to causal parent on its related environments (e1i, e2i, . . . , eki) as selected causal parent of the target variable Y .</p>
<p>For cases with multiple covariates, ICP can decrease in performance since the problem becomes more challenging due to its conservative nature. For these cases, we propose a different version of the same algorithm where the goal is to build a more robust procedure to find the candidates for causal parents. The differences are in steps:</p>
<ol>
<li>Before generating all possible subsets of input variables we limit the size of inputs to N=5 and we generate all possible subsets. Now each of these subsets becomes our original inputs and we apply step 3 as in the original version of the algorithm. 4. Since we have performed multiple checks we propose a voting approach. It consists of counting the number of each possible candidate(following the same logic as before) and we use a new confidence interval to keep the final selected parent. For instance, if we choose α = 0.1 we only accept as a causal parent a candidate that has been selected as a candidate in at least 90 % of checks performed.</li>
</ol>
<p>This second version has proved to achieve good results over the original version of the algorithm for cases with multiple covariates and more complex causal relations as we will see in the next section.</p>
<p>Numerical Results</p>
<p>In this section, we distinguish two experiments. Since we are solving an unsupervised learning problem when generating the environment we need a way to evaluate the method. For that purpose, we will use the environment to apply ICP following the algorithm described in the previous section. The implementation of ICP used in these experiments is an adapted version of the Python library ICPy [8]. Then, we apply the method to simulated data and measure the causal discovery capacity by the True Positive Rate (TPR) and the False Discovery Rate (FDR). As a benchmark of these metrics, we implement other traditional causal discovery algorithms including FCI y Lingam. The goal of this comparison is double, first, it allows us to test ICP´s power when finding causal relations and second and more importantly it can let us know if our algorithm is efficient when generating the environments.</p>
<p>In the first experiment, we generate 3 different datasets. Some of the covariates are randomly generated through a gaussian process or binomial process. The rest of the variables are generated through structural equations models (SEMs) and gaussian noise. The datasets go from simple to complex and cover different settings. In particular, the second dataset includes measuring confounding through variables that affect both cause and effect. The second dataset includes binary and categorical variables as well where our method is adapted to work well, both in the first part of the method and also the ICP algorithm.</p>
<p>Then we simulate each dataset 5 times and apply our method. Here we apply iteratively to every variable of each dataset. Therefore, each variable becomes the target variable of interest with the intention to try to rebuild the complete causal graph. This way we are testing the algorithm in a more challenging way and checking its reliability. Also, we can compare it easily with the other causal discovery algorithms. Finally, we measure the TPR and the FDR as the average of the 5 simulations to form a robust metric. Table 1 and Table 2    Regarding the interpretation, the TPR gives a percentage of how many causal parents of the graph have been detected by the algorithm where 1 is the best situation and 0 is the worst. And the FDR describes how many times a variable has been selected as a causal parent and it is actually not, being 0 the best scenario and 1 the worst one.</p>
<p>Looking at the results in  For the second experiment, we generate two new datasets. Following the same logic as before these datasets are more complex, they include more covariates and more causal relations. It is well known that when the number of covariates grows causal discovery algorithms decrease their performance. On the other hand, ICP is known to suffer from the same problem. Testing those limitations is precisely the goal of this second experiment. We will refer to the first method as ICPv1 and the second as ICPv2.</p>
<p>As a consequence of those limitations and the preliminary results, we have developed another version of our algorithm as we have explained already in section 3. This version of the algorithm is based on the same concepts and its main goal is to be more robust in datasets with multiple covariates. We include it in the comparison of this experiment and discuss the results of Tables 3 and 4 </p>
<p>Conclusion</p>
<p>Based on the results, we can claim that our method is suitable for generating environments efficiently on observational data. This opens a door to applying algorithms based on the invariant causal property, which is one of the main contributions of this paper and can be used to perform causal inference, causal discovery, or simply improved machine learning predictions(as IRM) on observational data. We also have seen how this can be implemented in combination with the ICP algorithm in a successful way to perform causal discovery on observational data. Finally, we have seen a new version of ICP in combination with our method suitable for datasets with multiple covariates and complex causal relations. This new version shows good TPR and FDR and has proved to outperform other causal discovery methods, hence it can become an alternative for causal discovery. Like other causal discovery algorithms, our method is not able to find the direction of the causal relation, which is a limitation and could be a goal for future work.</p>
<p>A Appendix</p>
<p>A.1 Experimental settings for numerical results</p>
<p>The datasets are generated according to the criteria specified in the numerical results section. Specifically, the five datasets are simulated according to the following equations: </p>
<p>Dataset1</p>
<p>Figure 1 :
1Decision Tree Clustering.</p>
<p>Proposition 1 of Invariant prediction:There exists a vector of coefficients γ⋆ of dimension p, where p is the number of real causal parents of y, that satisfies for all e ∈ E ::(Y )e = µ + (X)eγ ⋆ +(ϵ)e, ϵe ∼ Fϵ, ϵe ⊥⊥ Xe ∈ S ⋆</p>
<p>contain the TPR and the FDR of this experiment respectively.</p>
<p>6 Figure 2 :
62Causal Graph discovered by ICPv1 on Dataset 1, 2 and 3.</p>
<p>7 Figure 3 :
73Causal Graph discovered by ICPv2 on Dataset 5.</p>
<p>Table 1 :
1True Positive Rates Comparison of Experiment 1ICP FCI LINGAM 
Dataset1 0 
0.08 0.16 
Dataset2 0 
0 
0.14 
Dataset3 0.04 0 
0.20 </p>
<p>Table 2 :
2False Discovery Rates Comparison of Experiment 1.</p>
<p>table 1 we can see how ICP can compete with the other methods with True Positive Rates of 100% meaning that can find mostly all of the causal predictors of all the variables. On table 2 we also see results with the highest rate around 4% versus 8% for FCI and 20 % for LINGAM. Based on these results, we can claim that the generation of the environments is efficient to check for the invariant property of causal relations on the data.</p>
<p>. Table3: True Positive Rates Comparison of Experiment 2. Table4: False Discovery Rates Comparison of Experiment 2.Looking at tables 3 and 4 we can see how the previous version of the algorithm fails to perform causal discovery in an efficient way in this case showing poor TPR and FDR. In a similar way, FCI and LINGAM performance highly decrease as well showing also poor rates. Finally, we can see how the new version proposed achieves good rates for these complex graphs.FCI LINGAM ICPv1 ICPv2 
Dataset5 0.73 1.0 
.73 
1.0 
Dataset6 0.87 1.0 
0.6 
1.0 </p>
<p>FCI LINGAM ICPv1 ICPv2 
Dataset5 0 
0.21 
0.11 
0.08 
Dataset6 0 
0.38 
0.1 
0.21 </p>
<p>Invariant risk minimization games. Kartik Ahuja, Karthikeyan Shanmugam, Kush Varshney, Amit Dhurandhar, International Conference on Machine Learning. PMLRKartik Ahuja, Karthikeyan Shanmugam, Kush Varshney, and Amit Dhurandhar. Invariant risk minimization games. In International Conference on Machine Learning, pages 145-155. PMLR, 2020.</p>
<p>Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, David Lopez-Paz, arXiv:1907.02893Invariant risk minimization. arXiv preprintMartin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv preprint arXiv:1907.02893, 2019.</p>
<p>Structural equations with latent variables. A Kenneth, Bollen, John Wiley &amp; Sons210Kenneth A Bollen. Structural equations with latent variables, volume 210. John Wiley &amp; Sons, 1989.</p>
<p>Causal invariance as an essential constraint for creating representation of the world: generalizing the invariance of causal power. The Oxford handbook of causal reasoning. W Patricia, Hongjing Cheng, Lu, Patricia W Cheng and Hongjing Lu. Causal invariance as an essential constraint for creating representation of the world: generalizing the invariance of causal power. The Oxford handbook of causal reasoning, pages 65-84, 2017.</p>
<p>Statistically efficient greedy equivalence search. Max Chickering, Conference on Uncertainty in Artificial Intelligence. PMLRMax Chickering. Statistically efficient greedy equivalence search. In Conference on Uncertainty in Artificial Intelligence, pages 241-249. PMLR, 2020.</p>
<p>Yunhao Ge, Ö Sercan, Jinsung Arik, Ao Yoon, Xu, arXiv:2206.06469Laurent Itti, and Tomas Pfister. Invariant structure learning for better generalization and causal explainability. arXiv preprintYunhao Ge, Sercan Ö Arik, Jinsung Yoon, Ao Xu, Laurent Itti, and Tomas Pfister. Invariant structure learning for better generalization and causal explainability. arXiv preprint arXiv:2206.06469, 2022.</p>
<p>Learning causal structures using regression invariance. Amiremad Ghassami, Saber Salehkaleybar, Negar Kiyavash, Kun Zhang, Advances in Neural Information Processing Systems. 30AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash, and Kun Zhang. Learning causal structures using regression invariance. Advances in Neural Information Processing Systems, 30, 2017.</p>
<p>Invariantcausalprediction python library icpy. Jan Gleixner, Jan Gleixner. Invariantcausalprediction python library icpy. 2020.</p>
<p>Causal diagrams for epidemiologic research. Sander Greenland, Judea Pearl, James M Robins, Epidemiology. Sander Greenland, Judea Pearl, and James M Robins. Causal diagrams for epidemiologic research. Epidemiology, pages 37-48, 1999.</p>
<p>Christina Heinze, -Deml , Nicolai Meinshausen, arXiv:1710.11469Conditional variance penalties and domain shift robustness. arXiv preprintChristina Heinze-Deml and Nicolai Meinshausen. Conditional variance penalties and domain shift robustness. arXiv preprint arXiv:1710.11469, 2017.</p>
<p>Invariant causal prediction for nonlinear models. Christina Heinze-Deml, Jonas Peters, Nicolai Meinshausen, Journal of Causal Inference. 62Christina Heinze-Deml, Jonas Peters, and Nicolai Meinshausen. Invariant causal prediction for nonlinear models. Journal of Causal Inference, 6(2), 2018.</p>
<p>Nonlinear causal discovery with additive noise models. Patrik Hoyer, Dominik Janzing, M Joris, Jonas Mooij, Bernhard Peters, Schölkopf, Advances in neural information processing systems. 21Patrik Hoyer, Dominik Janzing, Joris M Mooij, Jonas Peters, and Bernhard Schölkopf. Nonlinear causal discovery with additive noise models. Advances in neural information processing systems, 21, 2008.</p>
<p>Generalization in anti-causal learning. Niki Kilbertus, Giambattista Parascandolo, Bernhard Schölkopf, Niki Kilbertus, Giambattista Parascandolo, and Bernhard Schölkopf. Generalization in anti-causal learning. 8</p>
<p>When is invariance useful in an out-of-distribution generalization problem?. arXiv:1812.00524arXiv:2008.01883arXiv preprintMasanori Koyama and Shoichiro YamaguchiarXiv preprint arXiv:1812.00524, 2018.Masanori Koyama and Shoichiro Yamaguchi. When is invariance useful in an out-of-distribution generalization problem? arXiv preprint arXiv:2008.01883, 2020.</p>
<p>Out-of-distribution generalization via risk extrapolation (rex). David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, Aaron Courville, International Conference on Machine Learning. PMLRDavid Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapolation (rex). In International Conference on Machine Learning, pages 5815-5826. PMLR, 2021.</p>
<p>Local computations with probabilities on graphical structures and their application to expert systems. L Steffen, David J Lauritzen, Spiegelhalter, Journal of the Royal Statistical Society: Series B (Methodological). 502Steffen L Lauritzen and David J Spiegelhalter. Local computations with probabilities on graphical structures and their application to expert systems. Journal of the Royal Statistical Society: Series B (Methodological), 50(2):157-194, 1988.</p>
<p>A unified approach to interpreting model predictions. M Scott, Su-In Lundberg, Lee, 30Advances in neural information processing systemsScott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. Advances in neural information processing systems, 30, 2017.</p>
<p>Causality from a distributional robustness point of view. Nicolai Meinshausen, IEEE Data Science Workshop (DSW). IEEENicolai Meinshausen. Causality from a distributional robustness point of view. In 2018 IEEE Data Science Workshop (DSW), pages 6-10. IEEE, 2018.</p>
<p>. Judea Pearl, Causality, Cambridge university pressJudea Pearl. Causality. Cambridge university press, 2009.</p>
<p>Causal inference by using invariant prediction: identifi-cation and confidence intervals. Jonas Peters, Peter Bühlmann, Nicolai Meinshausen, Journal of the Royal Statistical Society. Series B (Statistical Methodology). Jonas Peters, Peter Bühlmann, and Nicolai Meinshausen. Causal inference by using invariant prediction: identifi-cation and confidence intervals. Journal of the Royal Statistical Society. Series B (Statistical Methodology), pages 947-1012, 2016.</p>
<p>Causal discovery with continuous additive noise models. Jonas Peters, M Joris, Dominik Mooij, Bernhard Janzing, Schölkopf, Jonas Peters, Joris M Mooij, Dominik Janzing, and Bernhard Schölkopf. Causal discovery with continuous additive noise models. 2014.</p>
<p>why should i trust you?" explaining the predictions of any classifier. Sameer Marco Tulio Ribeiro, Carlos Singh, Guestrin, Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. the 22nd ACM SIGKDD international conference on knowledge discovery and data miningMarco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. " why should i trust you?" explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pages 1135-1144, 2016.</p>
<p>Single world intervention graphs (swigs): A unification of the counterfactual and graphical approaches to causality. S Thomas, James M Richardson, Robins, Center for the Statistics and the Social Sciences. 1282013University of Washington Series. Working PaperThomas S Richardson and James M Robins. Single world intervention graphs (swigs): A unification of the counterfactual and graphical approaches to causality. Center for the Statistics and the Social Sciences, University of Washington Series. Working Paper, 128(30):2013, 2013.</p>
<p>Marginal structural models and causal inference in epidemiology. M James, Miguel Angel Robins, Babette Hernan, Brumback, Epidemiology. James M Robins, Miguel Angel Hernan, and Babette Brumback. Marginal structural models and causal inference in epidemiology. Epidemiology, pages 550-560, 2000.</p>
<p>A linear nongaussian acyclic model for causal discovery. Shohei Shimizu, Patrik O Hoyer, Aapo Hyvärinen, Antti Kerminen, Michael Jordan, Journal of Machine Learning Research. 710Shohei Shimizu, Patrik O Hoyer, Aapo Hyvärinen, Antti Kerminen, and Michael Jordan. A linear non- gaussian acyclic model for causal discovery. Journal of Machine Learning Research, 7(10), 2006.</p>
<p>An anytime algorithm for causal inference. Peter Spirtes, International Workshop on Artificial Intelligence and Statistics. PMLRPeter Spirtes. An anytime algorithm for causal inference. In International Workshop on Artificial Intelligence and Statistics, pages 278-285. PMLR, 2001.</p>
<p>Causation, prediction, and search. Peter Spirtes, N Clark, Richard Glymour, David Scheines, Heckerman, MIT pressPeter Spirtes, Clark N Glymour, Richard Scheines, and David Heckerman. Causation, prediction, and search. MIT press, 2000.</p>
<p>Adversarial invariant learning. Nanyang Ye, Jingxuan Tang, Huayu Deng, Xiao-Yun Zhou, Qianxiao Li, Zhenguo Li, Guang-Zhong Yang, Zhanxing Zhu, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). IEEENanyang Ye, Jingxuan Tang, Huayu Deng, Xiao-Yun Zhou, Qianxiao Li, Zhenguo Li, Guang-Zhong Yang, and Zhanxing Zhu. Adversarial invariant learning. In 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 12441-12449. IEEE, 2021.</p>            </div>
        </div>

    </div>
</body>
</html>