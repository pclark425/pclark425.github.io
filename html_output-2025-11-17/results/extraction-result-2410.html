<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2410 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2410</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2410</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-265221492</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2311.09591v1.pdf" target="_blank">Accelerating material discovery with a threshold-driven hybrid acquisition policy-based Bayesian optimization</a></p>
                <p><strong>Paper Abstract:</strong> Advancements in materials play a crucial role in technological progress. However, the process of discovering and developing materials with desired properties is often impeded by substantial experimental costs, extensive resource utilization, and lengthy development periods. To address these challenges, modern approaches often employ machine learning (ML) techniques such as Bayesian Optimization (BO), which streamline the search for optimal materials by iteratively selecting experiments that are most likely to yield beneficial results. However, traditional BO methods, while beneficial, often struggle with balancing the trade-off between exploration and exploitation, leading to sub-optimal performance in material discovery processes. This paper introduces a novel Threshold-Driven UCB-EI Bayesian Optimization (TDUE-BO) method, which dynamically integrates the strengths of Upper Confidence Bound (UCB) and Expected Improvement (EI) acquisition functions to optimize the material discovery process. Unlike the classical BO, our method focuses on efficiently navigating the high-dimensional material design space (MDS). TDUE-BO begins with an exploration-focused UCB approach, ensuring a comprehensive initial sweep of the MDS. As the model gains confidence, indicated by reduced uncertainty, it transitions to the more exploitative EI method, focusing on promising areas identified earlier. The UCB-to-EI switching policy dictated guided through continuous monitoring of the model uncertainty during each step of sequential sampling results in navigating through the MDS more efficiently while ensuring rapid convergence. The effectiveness of TDUE-BO is demonstrated through its application on three different material datasets, showing significantly better approximation and optimization performance over the EI and UCB-based BO methods in terms of the RMSE scores and convergence efficiency, respectively.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2410.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2410.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TDUE-BO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Threshold-Driven UCB-EI Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid Bayesian optimization acquisition policy that begins with an exploration-focused UCB acquisition and switches to Expected Improvement (EI) once the Gaussian Process (GP) model's average predictive uncertainty falls below a user-chosen threshold, thereby allocating a fixed experimental budget between exploration and exploitation adaptively.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Threshold-Driven UCB-EI Bayesian Optimization (TDUE-BO)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>TDUE-BO is an active-learning / closed-loop experimental-design system built on a Gaussian Process surrogate. It maintains a candidate set of experimental points and a fixed experimental budget. The acquisition policy is hybrid: start iterations using UCB (mean + kappa * std) to prioritize exploration and model uncertainty, continuously compute the average predictive standard deviation across candidate points, and when that average uncertainty drops below a predefined threshold (set using domain knowledge), switch the acquisition function to EI to focus remaining budget on exploitation and local improvement. At each iteration one candidate is selected, evaluated (physical experiment / measurement), and the GP is updated; the process repeats until the budget is exhausted.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials science (material discovery, optimization of synthesis/process parameters), demonstrated on three high-throughput experimental datasets: Perovskite (instability score), P3HT/CNT (electrical conductivity), and AutoAM (3D printing shape score).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Sequential single-point selection from a candidate pool guided by an acquisition function: allocate early budget to exploration via UCB (which values high predictive std), monitor global (average) GP uncertainty, then reallocate remaining budget to exploitation via EI once average uncertainty drops below threshold. The threshold is set with domain knowledge and represents the point where additional exploration is judged unlikely to yield practically significant improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Not explicitly quantified as wall-clock time or FLOPs in the paper; the principal resource metric is the experimental budget (number of physical / sequential experiments performed). Computational costs of GP updates and acquisition evaluations are treated implicitly and not reported numerically.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Uses GP predictive uncertainty (standard deviation) as the core information measure; EI (expected improvement) and UCB (mean + kappa * std) are used as acquisition utilities—EI explicitly measures expected improvement over current best, UCB encodes optimism via uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Explicit threshold-driven switching: exploration via UCB during early iterations to cover the design space and reduce model uncertainty; when the average predictive standard deviation across candidate points falls below a preset threshold, switch to EI to exploit regions near the current best; UCB parameter kappa and EI's xi are the tunable knobs for tradeoff within each phase.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No additional explicit diversity-promotion mechanisms beyond the exploratory bias of UCB (which tends to sample uncertain/diverse regions). There is no explicit diversity regularizer, clustering, or determinantal point process used.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed experimental budget (fixed number of sequential experiments / samples to be performed).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>TDUE-BO divides the finite budget between an initial exploration phase (UCB) and a subsequent exploitation phase (EI) by monitoring average GP uncertainty; the switch is triggered by the threshold so remaining budget is concentrated on exploitation once model confidence is high.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Implicitly judged by improvement in the target objective value (e.g., finding the minimum/maximum target property) and by expected improvement (EI) during exploitation; no separate novelty or 'breakthrough potential' score is defined.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Root mean square error (RMSE) of GP predictions on held-out test sets (reported as mean/median/IQR over 30 runs) and number of iterations to reach the minimum (convergence iteration). Reported numeric examples (means from Table 2): Perovskite mean RMSE TDUE-BO = 0.108539 (EI 0.160957, UCB 0.137608); P3HT/CNT mean RMSE TDUE-BO = 0.120858 (EI 0.125170, UCB 0.124795); AutoAM mean RMSE TDUE-BO = 0.134824 (EI 0.156872, UCB 0.142149). Convergence iterations reported: Perovskite TDUE-BO reached minimum in 18 iterations (EI failed to converge within 40), P3HT/CNT TDUE-BO converged in 31 iterations (EI 39, UCB did not converge), AutoAM TDUE-BO converged in 13 iterations (EI 21, UCB did not converge).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>EI-based Bayesian Optimization (EI-BO) and UCB-based Bayesian Optimization (UCB-BO) run standalone for the same experimental budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>TDUE-BO achieved lower RMSE and faster convergence than both baselines across three datasets. Examples: Perovskite mean RMSE reduced from 0.160957 (EI) to 0.108539 (TDUE-BO) (~32.5% reduction vs EI) and from 0.137608 (UCB) to 0.108539 (~21% reduction vs UCB). For iterations-to-converge: Perovskite converged in 18 iterations under TDUE-BO vs no convergence for EI within 40 iterations; P3HT/CNT converged in 31 iterations vs 39 for EI; AutoAM converged in 13 iterations vs 21 for EI.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Reported gains include reductions in RMSE (examples above) and fewer sequential iterations to convergence: P3HT/CNT required ~8 fewer iterations (≈20% fewer than EI), AutoAM required ~8 fewer iterations (≈38% fewer than EI); Perovskite achieved convergence in 18 iterations while EI did not converge within the allotted 40 iterations. No wall-clock or monetary cost reductions are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>The paper provides a qualitative and empirical analysis of the exploration vs exploitation tradeoff: UCB promotes exploration and avoids early local optima while EI promotes focused improvement but can over-exploit; TDUE-BO uses average GP uncertainty as a control signal to reallocate remaining budget from exploration to exploitation. There is no formal analysis that quantifies tradeoffs involving computational cost, diversity, and breakthrough probability beyond empirical RMSE and convergence results.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Key recommendation: allocate early experimental budget to exploration (UCB) until the GP's average predictive uncertainty falls below a domain-informed threshold, then switch to exploitation (EI) to concentrate remaining budget on candidate refinement; threshold should be chosen using domain knowledge and signifies the point where further exploration is unlikely to yield practically significant gains. No closed-form optimal allocation or theoretical guarantee beyond empirical demonstration is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerating material discovery with a threshold-driven hybrid acquisition policy-based Bayesian optimization', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2410.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2410.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian Optimization (BO)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A sequential, model-based optimization approach for expensive black-box functions that alternates between updating a probabilistic surrogate (commonly a Gaussian Process) and maximizing an acquisition function to select next evaluations balancing exploration and exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bayesian Optimization (general framework)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Iterative framework composed of a surrogate probabilistic model (GP commonly) and an acquisition function (e.g., EI, UCB) that encodes expected utility for sampling; used to select the next experimental point(s) by trading off predicted value and uncertainty. In this paper BO is the underlying paradigm upon which TDUE-BO is built and compared.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General; in this paper applied to materials discovery and optimization problems (high-throughput experimental datasets).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Acquisition functions (EI or UCB) score candidate experiments; BO allocates the next single experiment to the highest-scoring candidate at each iteration under a fixed-budget constraint. Variants (not all used here) include batched BO or multi-fidelity BO which allocate resources across multiple sources.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Not specified in the paper for the general BO description; typically measured as number of expensive function evaluations (experiments) and GP computational cost, but the paper focuses on experimental budget (number of experiments) rather than computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Common BO acquisition functions employed: Expected Improvement (EI) and Upper Confidence Bound (UCB) which use GP predictive mean and variance; BO uses these to approximate information/value of sampling. The paper uses these standard metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Encapsulated by the choice of acquisition function: EI tends to exploit near current bests; UCB explicitly adds uncertainty-weighted exploration via mean + kappa*std. The paper leverages these mechanisms and mixes them in TDUE-BO.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Standard BO does not require an explicit diversity mechanism beyond uncertainty-driven exploration; the paper does not claim additional diversity procedures in the generic BO description.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed-number-of-experiments budget is considered in experimental setup.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>BO proceeds sequentially until the fixed budget is exhausted; TDUE-BO adapts the allocation within that budget by switching acquisition functions.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Typically measured by objective improvement (best observed function value) or expected improvement; in this paper breakthroughs correspond to finding lower/higher target property values via BO selection.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>RMSE of GP predictions on held-out test sets and iterations-to-reach-minimum are reported in experiments comparing BO variants.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Within the paper, BO variants (EI-only and UCB-only) serve as baselines; outside references include many BO advances but not used experimentally here.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>General BO baseline performance is dataset-dependent; in this paper a hybrid TDUE-BO outperformed pure EI or pure UCB on the three datasets studied.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>See TDUE-BO gains; generic BO efficiency gains depend on acquisition choice and problem.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper discusses qualitatively that BO's performance is determined by exploration-exploitation balance and shows empirically that hybrid switching can improve performance under fixed-budget constraints. No quantitative cost-vs-information tradeoff formalism is provided for BO generally.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>The paper's practical finding is that a dynamic allocation between exploration and exploitation (via switching acquisition) can better utilize a fixed experimental budget than either extreme alone; precise optimal allocation depends on problem and threshold selection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerating material discovery with a threshold-driven hybrid acquisition policy-based Bayesian optimization', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2410.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2410.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cost-aware multi-source BO (Herbol et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cost-effective materials discovery: Bayesian optimization across multiple information sources</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A literature-cited method (Herbol et al.) that addresses cost-aware Bayesian optimization by allocating evaluations across multiple information sources with differing costs and fidelities to reduce overall expense of materials discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cost-effective materials discovery: Bayesian optimization across multiple information sources</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Multi-information-source / cost-aware Bayesian optimization</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited prior work that formulates Bayesian optimization across multiple information sources, each with its own cost and fidelity, to make resource-allocation decisions that trade evaluation cost against expected information gain; typically uses multi-fidelity GP models and acquisition functions that normalize utility by cost or explicitly model value-of-information.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials discovery (cost-effective selection between experiments and simulations of different costs/fidelities).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate evaluations across information sources based on expected improvement per unit cost or value-of-information metrics, selecting where to sample (which source and which input) to maximize information gain for a given cost budget.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Typically measured in monetary or time cost per information source; the paper cites this work but does not report these metrics itself.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Value of information, expected improvement normalized by cost, or other acquisition objectives combining expected utility and cost; specifics are in the cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Balanced by acquisition that accounts for uncertainty and expected improvement across fidelities and costs; not implemented in the focal paper but cited as related work.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Monetary / cost and/or experiment count budgets typically; referenced work addresses cost budgets explicitly.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handled by optimizing expected information gain per unit cost or similar cost-aware acquisition; the focal paper only cites this as related research and does not implement it.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Cited as addressing the tradeoff between cost and information by allocating across multiple sources; the focal paper suggests cost-aware BO literature as relevant but does not analyze it.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerating material discovery with a threshold-driven hybrid acquisition policy-based Bayesian optimization', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2410.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2410.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>On-the-fly closed-loop BO (Kusne et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>On-the-fly closed-loop materials discovery via Bayesian active learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited closed-loop Bayesian active learning system that runs on-the-fly with live experiments to accelerate materials discovery, coupling experiment execution and BO-driven selection in real time.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>On-the-fly closed-loop materials discovery via Bayesian active learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>On-the-fly closed-loop Bayesian active learning</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced prior system where Bayesian active learning is integrated with experimental hardware to perform real-time sequential experiments; decisions consider current model uncertainty and expected improvement to pick next experiments, enabling autonomous, closed-loop materials optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials discovery with real-time experimental platforms and high-throughput experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Sequential selection based on acquisition functions (BO) integrated with experiment automation; emphasis on using model uncertainty and acquisition utility to allocate physical experimental resources in real time.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Operational experimental budgets/time; cited work addresses closed-loop experimental allocation but the focal paper does not implement every aspect.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerating material discovery with a threshold-driven hybrid acquisition policy-based Bayesian optimization', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2410.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2410.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RL-guided acquisition selection</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reinforcement learning for acquisition-function selection / multi-step lookahead BO</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A future-direction idea mentioned in the paper: using reinforcement learning (RL) to select acquisition functions adaptively (or to implement multi-step lookahead) to overcome BO's myopic behavior and improve allocation of experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Reinforcement-learning-guided Bayesian acquisition selection</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Suggested extension where an RL agent chooses among multiple acquisition functions (or selects acquisition hyperparameters) at each sequential step, enabling multi-step planning and potentially better global allocation of experimental budget; intended to provide non-myopic, policy-level decision-making over sequences of experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials discovery and other experimental design domains that benefit from multi-step planning under budget constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Policy learned by RL that trades immediate expected improvement against long-term discovery potential and reallocates budget across exploration/exploitation actions over multiple steps; specific reward or cost functions are not defined in this paper (it's proposed future work).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Would be implemented via the RL policy's learned action preferences (select acquisition functions or parameters) balancing exploration/exploitation over the episode; details not implemented in the current paper.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed experimental budget or episode length envisioned; paper suggests RL to better utilize budgets but gives no implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Proposed to be learned by the RL policy (multi-step lookahead), but specifics are left as future work.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Suggested as a way to manage BO's myopia and better trade off short-term vs long-term gains, but no empirical tradeoff analysis is provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerating material discovery with a threshold-driven hybrid acquisition policy-based Bayesian optimization', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Cost-effective materials discovery: Bayesian optimization across multiple information sources <em>(Rating: 2)</em></li>
                <li>On-the-fly closed-loop materials discovery via Bayesian active learning <em>(Rating: 2)</em></li>
                <li>Autonomous intelligent agents for accelerated materials discovery <em>(Rating: 1)</em></li>
                <li>Bayesian optimization with adaptive surrogate models for automated experimental design <em>(Rating: 1)</em></li>
                <li>Autonomous efficient experiment design for materials discovery with Bayesian model averaging <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2410",
    "paper_id": "paper-265221492",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "TDUE-BO",
            "name_full": "Threshold-Driven UCB-EI Bayesian Optimization",
            "brief_description": "A hybrid Bayesian optimization acquisition policy that begins with an exploration-focused UCB acquisition and switches to Expected Improvement (EI) once the Gaussian Process (GP) model's average predictive uncertainty falls below a user-chosen threshold, thereby allocating a fixed experimental budget between exploration and exploitation adaptively.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Threshold-Driven UCB-EI Bayesian Optimization (TDUE-BO)",
            "system_description": "TDUE-BO is an active-learning / closed-loop experimental-design system built on a Gaussian Process surrogate. It maintains a candidate set of experimental points and a fixed experimental budget. The acquisition policy is hybrid: start iterations using UCB (mean + kappa * std) to prioritize exploration and model uncertainty, continuously compute the average predictive standard deviation across candidate points, and when that average uncertainty drops below a predefined threshold (set using domain knowledge), switch the acquisition function to EI to focus remaining budget on exploitation and local improvement. At each iteration one candidate is selected, evaluated (physical experiment / measurement), and the GP is updated; the process repeats until the budget is exhausted.",
            "application_domain": "Materials science (material discovery, optimization of synthesis/process parameters), demonstrated on three high-throughput experimental datasets: Perovskite (instability score), P3HT/CNT (electrical conductivity), and AutoAM (3D printing shape score).",
            "resource_allocation_strategy": "Sequential single-point selection from a candidate pool guided by an acquisition function: allocate early budget to exploration via UCB (which values high predictive std), monitor global (average) GP uncertainty, then reallocate remaining budget to exploitation via EI once average uncertainty drops below threshold. The threshold is set with domain knowledge and represents the point where additional exploration is judged unlikely to yield practically significant improvements.",
            "computational_cost_metric": "Not explicitly quantified as wall-clock time or FLOPs in the paper; the principal resource metric is the experimental budget (number of physical / sequential experiments performed). Computational costs of GP updates and acquisition evaluations are treated implicitly and not reported numerically.",
            "information_gain_metric": "Uses GP predictive uncertainty (standard deviation) as the core information measure; EI (expected improvement) and UCB (mean + kappa * std) are used as acquisition utilities—EI explicitly measures expected improvement over current best, UCB encodes optimism via uncertainty.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Explicit threshold-driven switching: exploration via UCB during early iterations to cover the design space and reduce model uncertainty; when the average predictive standard deviation across candidate points falls below a preset threshold, switch to EI to exploit regions near the current best; UCB parameter kappa and EI's xi are the tunable knobs for tradeoff within each phase.",
            "diversity_mechanism": "No additional explicit diversity-promotion mechanisms beyond the exploratory bias of UCB (which tends to sample uncertain/diverse regions). There is no explicit diversity regularizer, clustering, or determinantal point process used.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed experimental budget (fixed number of sequential experiments / samples to be performed).",
            "budget_constraint_handling": "TDUE-BO divides the finite budget between an initial exploration phase (UCB) and a subsequent exploitation phase (EI) by monitoring average GP uncertainty; the switch is triggered by the threshold so remaining budget is concentrated on exploitation once model confidence is high.",
            "breakthrough_discovery_metric": "Implicitly judged by improvement in the target objective value (e.g., finding the minimum/maximum target property) and by expected improvement (EI) during exploitation; no separate novelty or 'breakthrough potential' score is defined.",
            "performance_metrics": "Root mean square error (RMSE) of GP predictions on held-out test sets (reported as mean/median/IQR over 30 runs) and number of iterations to reach the minimum (convergence iteration). Reported numeric examples (means from Table 2): Perovskite mean RMSE TDUE-BO = 0.108539 (EI 0.160957, UCB 0.137608); P3HT/CNT mean RMSE TDUE-BO = 0.120858 (EI 0.125170, UCB 0.124795); AutoAM mean RMSE TDUE-BO = 0.134824 (EI 0.156872, UCB 0.142149). Convergence iterations reported: Perovskite TDUE-BO reached minimum in 18 iterations (EI failed to converge within 40), P3HT/CNT TDUE-BO converged in 31 iterations (EI 39, UCB did not converge), AutoAM TDUE-BO converged in 13 iterations (EI 21, UCB did not converge).",
            "comparison_baseline": "EI-based Bayesian Optimization (EI-BO) and UCB-based Bayesian Optimization (UCB-BO) run standalone for the same experimental budgets.",
            "performance_vs_baseline": "TDUE-BO achieved lower RMSE and faster convergence than both baselines across three datasets. Examples: Perovskite mean RMSE reduced from 0.160957 (EI) to 0.108539 (TDUE-BO) (~32.5% reduction vs EI) and from 0.137608 (UCB) to 0.108539 (~21% reduction vs UCB). For iterations-to-converge: Perovskite converged in 18 iterations under TDUE-BO vs no convergence for EI within 40 iterations; P3HT/CNT converged in 31 iterations vs 39 for EI; AutoAM converged in 13 iterations vs 21 for EI.",
            "efficiency_gain": "Reported gains include reductions in RMSE (examples above) and fewer sequential iterations to convergence: P3HT/CNT required ~8 fewer iterations (≈20% fewer than EI), AutoAM required ~8 fewer iterations (≈38% fewer than EI); Perovskite achieved convergence in 18 iterations while EI did not converge within the allotted 40 iterations. No wall-clock or monetary cost reductions are provided.",
            "tradeoff_analysis": "The paper provides a qualitative and empirical analysis of the exploration vs exploitation tradeoff: UCB promotes exploration and avoids early local optima while EI promotes focused improvement but can over-exploit; TDUE-BO uses average GP uncertainty as a control signal to reallocate remaining budget from exploration to exploitation. There is no formal analysis that quantifies tradeoffs involving computational cost, diversity, and breakthrough probability beyond empirical RMSE and convergence results.",
            "optimal_allocation_findings": "Key recommendation: allocate early experimental budget to exploration (UCB) until the GP's average predictive uncertainty falls below a domain-informed threshold, then switch to exploitation (EI) to concentrate remaining budget on candidate refinement; threshold should be chosen using domain knowledge and signifies the point where further exploration is unlikely to yield practically significant gains. No closed-form optimal allocation or theoretical guarantee beyond empirical demonstration is provided.",
            "uuid": "e2410.0",
            "source_info": {
                "paper_title": "Accelerating material discovery with a threshold-driven hybrid acquisition policy-based Bayesian optimization",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Bayesian Optimization (BO)",
            "name_full": "Bayesian Optimization",
            "brief_description": "A sequential, model-based optimization approach for expensive black-box functions that alternates between updating a probabilistic surrogate (commonly a Gaussian Process) and maximizing an acquisition function to select next evaluations balancing exploration and exploitation.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Bayesian Optimization (general framework)",
            "system_description": "Iterative framework composed of a surrogate probabilistic model (GP commonly) and an acquisition function (e.g., EI, UCB) that encodes expected utility for sampling; used to select the next experimental point(s) by trading off predicted value and uncertainty. In this paper BO is the underlying paradigm upon which TDUE-BO is built and compared.",
            "application_domain": "General; in this paper applied to materials discovery and optimization problems (high-throughput experimental datasets).",
            "resource_allocation_strategy": "Acquisition functions (EI or UCB) score candidate experiments; BO allocates the next single experiment to the highest-scoring candidate at each iteration under a fixed-budget constraint. Variants (not all used here) include batched BO or multi-fidelity BO which allocate resources across multiple sources.",
            "computational_cost_metric": "Not specified in the paper for the general BO description; typically measured as number of expensive function evaluations (experiments) and GP computational cost, but the paper focuses on experimental budget (number of experiments) rather than computational cost.",
            "information_gain_metric": "Common BO acquisition functions employed: Expected Improvement (EI) and Upper Confidence Bound (UCB) which use GP predictive mean and variance; BO uses these to approximate information/value of sampling. The paper uses these standard metrics.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Encapsulated by the choice of acquisition function: EI tends to exploit near current bests; UCB explicitly adds uncertainty-weighted exploration via mean + kappa*std. The paper leverages these mechanisms and mixes them in TDUE-BO.",
            "diversity_mechanism": "Standard BO does not require an explicit diversity mechanism beyond uncertainty-driven exploration; the paper does not claim additional diversity procedures in the generic BO description.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed-number-of-experiments budget is considered in experimental setup.",
            "budget_constraint_handling": "BO proceeds sequentially until the fixed budget is exhausted; TDUE-BO adapts the allocation within that budget by switching acquisition functions.",
            "breakthrough_discovery_metric": "Typically measured by objective improvement (best observed function value) or expected improvement; in this paper breakthroughs correspond to finding lower/higher target property values via BO selection.",
            "performance_metrics": "RMSE of GP predictions on held-out test sets and iterations-to-reach-minimum are reported in experiments comparing BO variants.",
            "comparison_baseline": "Within the paper, BO variants (EI-only and UCB-only) serve as baselines; outside references include many BO advances but not used experimentally here.",
            "performance_vs_baseline": "General BO baseline performance is dataset-dependent; in this paper a hybrid TDUE-BO outperformed pure EI or pure UCB on the three datasets studied.",
            "efficiency_gain": "See TDUE-BO gains; generic BO efficiency gains depend on acquisition choice and problem.",
            "tradeoff_analysis": "Paper discusses qualitatively that BO's performance is determined by exploration-exploitation balance and shows empirically that hybrid switching can improve performance under fixed-budget constraints. No quantitative cost-vs-information tradeoff formalism is provided for BO generally.",
            "optimal_allocation_findings": "The paper's practical finding is that a dynamic allocation between exploration and exploitation (via switching acquisition) can better utilize a fixed experimental budget than either extreme alone; precise optimal allocation depends on problem and threshold selection.",
            "uuid": "e2410.1",
            "source_info": {
                "paper_title": "Accelerating material discovery with a threshold-driven hybrid acquisition policy-based Bayesian optimization",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Cost-aware multi-source BO (Herbol et al.)",
            "name_full": "Cost-effective materials discovery: Bayesian optimization across multiple information sources",
            "brief_description": "A literature-cited method (Herbol et al.) that addresses cost-aware Bayesian optimization by allocating evaluations across multiple information sources with differing costs and fidelities to reduce overall expense of materials discovery.",
            "citation_title": "Cost-effective materials discovery: Bayesian optimization across multiple information sources",
            "mention_or_use": "mention",
            "system_name": "Multi-information-source / cost-aware Bayesian optimization",
            "system_description": "Cited prior work that formulates Bayesian optimization across multiple information sources, each with its own cost and fidelity, to make resource-allocation decisions that trade evaluation cost against expected information gain; typically uses multi-fidelity GP models and acquisition functions that normalize utility by cost or explicitly model value-of-information.",
            "application_domain": "Materials discovery (cost-effective selection between experiments and simulations of different costs/fidelities).",
            "resource_allocation_strategy": "Allocate evaluations across information sources based on expected improvement per unit cost or value-of-information metrics, selecting where to sample (which source and which input) to maximize information gain for a given cost budget.",
            "computational_cost_metric": "Typically measured in monetary or time cost per information source; the paper cites this work but does not report these metrics itself.",
            "information_gain_metric": "Value of information, expected improvement normalized by cost, or other acquisition objectives combining expected utility and cost; specifics are in the cited work.",
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Balanced by acquisition that accounts for uncertainty and expected improvement across fidelities and costs; not implemented in the focal paper but cited as related work.",
            "diversity_mechanism": null,
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Monetary / cost and/or experiment count budgets typically; referenced work addresses cost budgets explicitly.",
            "budget_constraint_handling": "Handled by optimizing expected information gain per unit cost or similar cost-aware acquisition; the focal paper only cites this as related research and does not implement it.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": "Cited as addressing the tradeoff between cost and information by allocating across multiple sources; the focal paper suggests cost-aware BO literature as relevant but does not analyze it.",
            "optimal_allocation_findings": null,
            "uuid": "e2410.2",
            "source_info": {
                "paper_title": "Accelerating material discovery with a threshold-driven hybrid acquisition policy-based Bayesian optimization",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "On-the-fly closed-loop BO (Kusne et al.)",
            "name_full": "On-the-fly closed-loop materials discovery via Bayesian active learning",
            "brief_description": "A cited closed-loop Bayesian active learning system that runs on-the-fly with live experiments to accelerate materials discovery, coupling experiment execution and BO-driven selection in real time.",
            "citation_title": "On-the-fly closed-loop materials discovery via Bayesian active learning",
            "mention_or_use": "mention",
            "system_name": "On-the-fly closed-loop Bayesian active learning",
            "system_description": "Referenced prior system where Bayesian active learning is integrated with experimental hardware to perform real-time sequential experiments; decisions consider current model uncertainty and expected improvement to pick next experiments, enabling autonomous, closed-loop materials optimization.",
            "application_domain": "Materials discovery with real-time experimental platforms and high-throughput experiments.",
            "resource_allocation_strategy": "Sequential selection based on acquisition functions (BO) integrated with experiment automation; emphasis on using model uncertainty and acquisition utility to allocate physical experimental resources in real time.",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": null,
            "diversity_mechanism": null,
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Operational experimental budgets/time; cited work addresses closed-loop experimental allocation but the focal paper does not implement every aspect.",
            "budget_constraint_handling": null,
            "breakthrough_discovery_metric": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": null,
            "optimal_allocation_findings": null,
            "uuid": "e2410.3",
            "source_info": {
                "paper_title": "Accelerating material discovery with a threshold-driven hybrid acquisition policy-based Bayesian optimization",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "RL-guided acquisition selection",
            "name_full": "Reinforcement learning for acquisition-function selection / multi-step lookahead BO",
            "brief_description": "A future-direction idea mentioned in the paper: using reinforcement learning (RL) to select acquisition functions adaptively (or to implement multi-step lookahead) to overcome BO's myopic behavior and improve allocation of experiments.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Reinforcement-learning-guided Bayesian acquisition selection",
            "system_description": "Suggested extension where an RL agent chooses among multiple acquisition functions (or selects acquisition hyperparameters) at each sequential step, enabling multi-step planning and potentially better global allocation of experimental budget; intended to provide non-myopic, policy-level decision-making over sequences of experiments.",
            "application_domain": "Materials discovery and other experimental design domains that benefit from multi-step planning under budget constraints.",
            "resource_allocation_strategy": "Policy learned by RL that trades immediate expected improvement against long-term discovery potential and reallocates budget across exploration/exploitation actions over multiple steps; specific reward or cost functions are not defined in this paper (it's proposed future work).",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Would be implemented via the RL policy's learned action preferences (select acquisition functions or parameters) balancing exploration/exploitation over the episode; details not implemented in the current paper.",
            "diversity_mechanism": null,
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Fixed experimental budget or episode length envisioned; paper suggests RL to better utilize budgets but gives no implementation.",
            "budget_constraint_handling": "Proposed to be learned by the RL policy (multi-step lookahead), but specifics are left as future work.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": "Suggested as a way to manage BO's myopia and better trade off short-term vs long-term gains, but no empirical tradeoff analysis is provided in this paper.",
            "optimal_allocation_findings": null,
            "uuid": "e2410.4",
            "source_info": {
                "paper_title": "Accelerating material discovery with a threshold-driven hybrid acquisition policy-based Bayesian optimization",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Cost-effective materials discovery: Bayesian optimization across multiple information sources",
            "rating": 2,
            "sanitized_title": "costeffective_materials_discovery_bayesian_optimization_across_multiple_information_sources"
        },
        {
            "paper_title": "On-the-fly closed-loop materials discovery via Bayesian active learning",
            "rating": 2,
            "sanitized_title": "onthefly_closedloop_materials_discovery_via_bayesian_active_learning"
        },
        {
            "paper_title": "Autonomous intelligent agents for accelerated materials discovery",
            "rating": 1,
            "sanitized_title": "autonomous_intelligent_agents_for_accelerated_materials_discovery"
        },
        {
            "paper_title": "Bayesian optimization with adaptive surrogate models for automated experimental design",
            "rating": 1,
            "sanitized_title": "bayesian_optimization_with_adaptive_surrogate_models_for_automated_experimental_design"
        },
        {
            "paper_title": "Autonomous efficient experiment design for materials discovery with Bayesian model averaging",
            "rating": 1,
            "sanitized_title": "autonomous_efficient_experiment_design_for_materials_discovery_with_bayesian_model_averaging"
        }
    ],
    "cost": 0.014878249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Accelerating material discovery with a threshold-driven hybrid acquisition policy-based Bayesian optimization</p>
<p>Ahmed Shoyeb Raihan 
Department of Industrial and Management Systems Engineering
West Virginia University
26506MorgantownWV</p>
<p>Hamed Khosravi 
Department of Industrial and Management Systems Engineering
West Virginia University
26506MorgantownWV</p>
<p>Srinjoy Das 
School of Mathematical and Data Sciences
West Virginia University
26506MorgantownWV</p>
<p>Imtiaz Ahmed 
Department of Industrial and Management Systems Engineering
West Virginia University
26506MorgantownWV</p>
<p>Accelerating material discovery with a threshold-driven hybrid acquisition policy-based Bayesian optimization
15ECDDA0D2E38F1B87A99453759DFD9FBayesian OptimizationActive LearningExploitation and ExplorationMaterial DiscoveryData-driven Manufacturing, Smart Manufacturing
Advancements in materials play a crucial role in technological progress.However, the process of discovering and developing materials with desired properties is often impeded by substantial experimental costs, extensive resource utilization, and lengthy development periods.To address these challenges, modern approaches often employ machine learning (ML) techniques such as Bayesian Optimization (BO), which streamline the search for optimal materials by iteratively selecting experiments that are most likely to yield beneficial results.However, traditional BO methods, while beneficial, often struggle with balancing the trade-off between exploration and exploitation, leading to suboptimal performance in accelerated material discovery processes.This paper introduces a novel Threshold-Driven UCB-EI Bayesian Optimization (TDUE-BO) method, which dynamically integrates the strengths of Upper Confidence Bound (UCB) and Expected Improvement (EI) acquisition functions to optimize the material discovery process.Unlike the classical BO, our method focuses on efficiently navigating the high-dimensional material design space (MDS).TDUE-BO begins with an exploration-focused UCB approach, ensuring a comprehensive initial sweep of the MDS.As the model gains confidence, indicated by reduced uncertainty, it transitions to the more exploitative EI method, focusing on promising areas identified earlier.The UCB-to-EI switching policy dictated guided through continuous monitoring of the model uncertainty during each step of sequential sampling results in navigating through the MDS more efficiently while ensuring rapid convergence.The effectiveness of TDUE-BO is demonstrated through its application on three different material science datasets, showing significantly better approximation and optimization performance over traditional EI and UCB-based BO methods in terms of the RMSE scores and convergence efficiency, respectively.</p>
<p>Introduction</p>
<p>Scientific advancement in the field of material science is entering its fourth paradigm, marked by the integration of big data and artificial intelligence [1].Initially, the study of materials relied solely on intuitive observation and judgement without scientific quantification [2].This gradually evolved with the introduction of mathematical models like thermodynamics, providing a theoretical foundation [3].Following this, the advent of computers enabled simulations of complex problems, with the emergence of methods like density functional theory and molecular dynamics [4].Despite these significant advancements, the actual process of manufacturing, discovering, and developing new materials with desired properties is still plagued with high experimental costs as well as significant time and resource consumption [5].There are several reasons behind this slow progress.First and foremost, in most of the problems related to material development and discovery, the underlying relationship between the process parameters or conditions and the desired material properties is very complex [6].Additionally, during the process of finding the optimal set of these parameters that result in some desired material properties, a high dimensional design space with innumerous combinations must be searched meticulously [7].Traditional processes require a plethora of physical experiments to be conducted before a desired property can be achieved.However, such processes often cannot generate desired solutions as these physical experiments are expensive and requires significant effort and time [8], [9].Moreover, the nature of current research methods for manufacturing and developing material with desired properties stems from the heavy reliance on human involvement, which further impedes the process of accelerated discovery.</p>
<p>The current shift to the fourth paradigm, driven by the advent and widespread use of artificial intelligence aims to resolve these issues through data-driven discovery processes.The intersection of materials science and computer science, particularly with the application of machine learning, is transforming the field, allowing for faster and more efficient predictions of material properties and the discovery of new materials [10], [11].This transformation is fueled by the vast amount of data generated from experiments and computational methods, accelerated by high-throughput computing [12].Moreover, in light of growing sustainability concerns, including reducing carbon footprints, minimizing resource and energy use, waste reduction, and preserving critical materials, scientists and researchers are increasingly focused on data-driven approaches to accelerate the process of material discovery [13].The material discovery process is essentially an optimization challenge where the aim is to enhance or reduce certain properties of a material [14].This is achieved by adjusting specific features or parameters, which are influenced by the material's chemistry and processing conditions.As we dive deeper, we observe that the process of identifying the optimal set of these parameters which results in some desired material property is equivalent to solving the global optimization problem, often represented mathematically as [15]:
𝑥𝑥 * = 𝑎𝑎𝑎𝑎𝑎𝑎 max 𝑥𝑥∈𝜒𝜒 𝑓𝑓(𝑥𝑥)(1)
where  * represents the specific action or optimal set parameters that optimizes the function ().This is like searching for a needle in a haystack, given the high dimensional material design space (MDS) denoted by  with countless combinations or inputs denoted by .The challenge here is that the function () -indicative of the outcome of an action or process parameter -lacks an explicit form and is termed as black-box function [16].To decipher (), material scientists and engineers have traditionally resorted to physical experiments at certain MDS locations.However, these experiments, pivotal for understanding the landscape of material properties, are both resource-intensive and timeconsuming [17].A transformative approach to materials discovery and development is thus necessary, one that requires intelligently navigating through the vast MDS and finding configurations that align with the desired target properties.Such an approach, presumably autonomous in nature, involves navigating the MDS by adeptly balancing between exploitation, which means taking opportunistic steps for immediate improvement based on current knowledge, and exploration, which pertains to venturing into unexplored regions of the MDS to possibly gain better rewards.Under resource constrained environments, where conducting multiple physical experiments are deemed infeasible, achieving the proper balance between exploitation and exploration may be the only way to discover and develop materials with desired properties efficiently.Consequently, active or sequential learning has emerged offering a structured method to determine the most effective combination of process parameters in order to iteratively select and obtain the desired material property efficiently and effectively [18].Perhaps, the most popular active learning strategy is Bayesian Optimization (BO), acclaimed for its potential to revolutionize material discovery, development, and optimization [19].By fusing data-driven methodologies with domain expertise, BO-based active learning techniques endeavor to efficiently explore and pinpoint optimal materials through a synergetic relationship between a surrogate model and an acquisition function [20], [21].As a result, BO and its variants have found widespread application in a variety of research areas including material discovery and development [5], [13], [15], [22], drug discovery and pharmacology [23]- [25], robotics [26], [27], aerospace engineering [28], [29], automotive industry [30], [31], chemical science [32]- [34] and so on.</p>
<p>In the BO literature, while Gaussian Process (GP) has always been the most obvious choice as the surrogate model for (), there has been much debate about the choice of acquisition functions which enable the determination of  * as per Equation 1 [35].The performance of these sequential learning algorithms almost always boils down to achieving the balance between the exploitation and exploration of the MDS.Too much exploitation causes the algorithm to get trapped in local optima whereas too much exploration can cause the algorithm to waste valuable resources in less promising regions of the MDS without finding the optimum value or desired property [36].Two of the most popular acquisition functions in the BO literature are Expected Improvement (EI) and the Upper Confidence Bound (UCB).While both functions serve to achieve a good exploitation-exploration tradeoff balance, the EI is inherently more exploitative in nature while the UCB is more explorative [37], [38].In material discovery, where it is crucial to get an overall understanding of the vast MDS besides reaching the optimal value under the constraint of limited resources and time, the EI-based BO and the UCB-based BO by themselves often deliver sub-optimal performance.Keeping the idea about the strengths and weaknesses of both these acquisition functions, in this work we propose to develop a hybrid approach where both UCB and EI are utilized to efficiently explore and exploit the MDS as required.Our proposed approach named as Threshold-Driven UCB-EI BO or in short TDUE-BO aims to guide the sequential experiments by maintaining a better balance between exploration and exploitation.By starting with UCB, TDUE-BO ensures adequate exploration of the design space, which is particularly important in the initial phases of optimization to avoid missing out on unexplored high-potential regions.Once the uncertainty falls below a certain threshold, indicating that the model has a reliable understanding of the function's behavior, the strategy switches to EI.This shift allows for a more focused exploitation of the most promising regions identified during the exploration phase.We have applied our proposed methodology in three different material science datasets and achieved significantly better performance in terms of RMSE scores compared to when we applied EI-based BO and UCB-based BO separately in these datasets.We have also shown how the threshold-guided switching between the UCB and EI in the sequential learning environment can generate better approximation of the MDS by providing the iterative learning of a one-dimensional function with TDUE-BO versus the other two conventional approaches.</p>
<p>The rest of the paper is organized as follows.Section 2 provides a short discussion on the three material datasets we have used in our work.The working of the traditional BO with GP as the surrogate model, and EI and UCB as acquisition functions is presented in Section 3 with our proposed active learning framework (TDUE-BO).In Section 4, we first present an illustrative example showing how TDUE-BO adaptively switches between UCB and EI to optimize and approximate an unknown function outperforming both the EI and UCB-based BO.Next, we present the results of our proposed approach, along with the competing EI and UCB guided BO approaches when applied to the three material datasets.We analyze our findings at the end of this section.Finally, we conclude our work in Section 5, providing directions for future research.</p>
<p>Data Understanding</p>
<p>In this study, we considered three datasets from three distinct material domains, each with its own size, dimension, and material system characteristics [18].There are multiple materials science domains represented in these datasets, each with an optimization goal and specific synthesis method.The first dataset is the P3HT/CNT dataset where the target property is the 'Electrical Conductivity' has 233 samples and was synthesized using the drop-casting method.Residing in the domain of composite blends, this dataset has 5 input features [39].The second dataset is the Perovskite dataset with 3 input features (process parameters) and the output target is the 'Instability Score' [40].Belonging to the domain of thin-film perovskite, this dataset contains 139 data points for these input features and their corresponding output.The AutoAM dataset with 100 samples from the field of materials manufacturing is the third dataset we have used in our work [41] and it is related to 3D printing.This dataset has 4 process parameters, and the 'Shape Score' is the output target.All the three datasets are derived from high-throughput experimental platforms.</p>
<p>As a result of the diversity of these datasets, we can assess the effectiveness of our proposed method within the field of experimental materials science, emphasizing its versatility and adaptability to a wide range of high-throughput experiments.In order to improve our analysis and gain a comprehensive perspective, we conducted a detailed exploration of the data.To capture the predominant variance observed across the datasets, we used the largely used Principal Component Analysis (PCA) methodology to analyse the complexity of these datasets into two principal components, PC 1 and PC 2 [42].Through this reduction, we are able to visualize and interpret the datasets more easily, enabling us to identify the patterns and relationships pertinent to our study, which focuses on the optimization objectives.Using PCA, Figure 1 illustrates the transformed feature space of the P3HT/CNT dataset, focusing on the 5 features 'P3HT content (%)', 'D1 content (%)', 'D2 content (%)', 'D6 content (%)', and 'D8 content (%)'.Upon examination of the plot, there appears to be a concentration of data points around the highest peak, which possibly represents the optimal material properties.As conductivity (target property) values increase, the color gradient transitions from cool to warm colors, indicating an increase in conductivity.In particular, the warmest color zones are aligned with the peaks of the plot, suggesting that these regions correspond to higher conductivity levels.The same analysis has been conducted for the two other datasets, as well.Figure 2 shows the feature space for the Perovskite dataset where the dynamic range of values for the target 'Instability Index' shows the variable nature of the materials used in the process.</p>
<p>With its multiple peaks and troughs, this surface reaches a maximum stability index of about 1.2M at the highest peak, which contrasts strikingly with lower index values of nearly 0.8M at the lower peaks.This color spectrum reflects the degree of instability, shifting from a deep, rich purple at the lower end of the spectrum to a bright, intense orange at the upper end.The warmer colors indicate higher levels of instability.Throughout the base are contour lines showing a distribution of data points at varying levels of 'Instability Index', indicating a non-uniform distribution of material properties.There may be a concentration of points in an area where the contour lines are densely packed, which may indicate a common manufacturing setting or material composition, while sparser contour lines may indicate less explored or more variable conditions.Finally, Figure 3 shows the 3D surface plot for the AutoAM dataset which indicates the parameters that have been evaluated, including the 'Prime Delay', 'Print Speed', 'X Offset Correction', and 'Y Offset Correction' with the aim of optimizing the 'Score'.As can be seen in the surface plot, there is a prominent peak in the center of the plot, which quickly increases to a score of approximately 60, thereby indicating a concentration of data points around which optimal manufacturing conditions exist.The peak is surrounded by a plateau of moderate scores that range from 20 to 40, beyond which the scores gradually decrease to near zero levels as one moves further out along the PC 1 and PC 2 axes.'Score' spectrum, where purple is located at the bottom and yellow is located at the top, has a vibrant gradient transition that visually emphasizes the regions of high and low scores.In addition to illustrating the density and spread of data points, the contour lines extending across the base illustrate the variability within the manufacturing process parameters.By using this graphical representation, we are not only able to simplify the multivariate analysis but also to identify areas where conductivity is enhanced, thereby providing a strategic direction for future experiments and material development.</p>
<p>Methodology</p>
<p>BO is an efficient method for the optimization of black-box functions that are expensive or time-consuming to evaluate [17].It is particularly useful in scenarios where the objective function does not have a closed-form expression, is costly to evaluate, and where derivatives are not available or are unreliable.The core concept behind BO is to use a probabilistic model to estimate the function.This model is used to make predictions about the function's behavior and to quantify the uncertainty in these predictions.The probabilistic nature of the model makes it well-suited to guiding the search for the optimum in a principled and efficient manner.The process of BO is iterative; it alternates between modeling and optimizing which calls for dividing its framework into two parts: a surrogate function for modeling and an acquisition function for optimizing [20].During each iteration, BO attempts to approximate the unknown function  by refining the surrogate model and uses the acquisition function to determine the next design point to assess.</p>
<p>Surrogate Model</p>
<p>A surrogate model is a predictive model that approximates the objective function of interest.The key purpose of a surrogate model is to provide a computationally cheap and analytically tractable estimate of the objective function, which is typically expensive, time-consuming, or difficult to evaluate directly.Surrogate models approximate the behavior of the complex objective function based on available data (sampled points).They predict what the objective function's output would be at unsampled points.Besides providing predictions, good surrogate models also quantify the uncertainty or confidence in their predictions.This uncertainty plays a crucial role in decision-making in BO.Gaussian Processes (GPs) are a popular choice for surrogate models in BO due to their robustness and effectiveness in capturing the uncertainty of predictions.A Gaussian Process is a collection of random variables, any finite number of which have a joint Gaussian distribution [43].It is fully specified by its mean function () and covariance function (, ′) which is given by the following equation:
𝑓𝑓(𝑥𝑥)~𝐺𝐺𝐺𝐺�𝑚𝑚(𝑥𝑥), 𝑘𝑘(𝑥𝑥, 𝑥𝑥 ′ )�(2)
The mean function represents the average value of the function, and the covariance function, also known as the kernel, defines the similarity between different points in the input space.For a set of input points  * where predictions are required, and given a set of training points  with corresponding target values , the joint distribution of the observed targets  and the function values at the new input points  * under the GP prior is:
� 𝑦𝑦 𝑓𝑓 * � ~Ν �� 𝑚𝑚(𝑋𝑋) 𝑚𝑚(𝑋𝑋 * ) � , � 𝐾𝐾(𝑋𝑋, 𝑋𝑋) 𝐾𝐾(𝑋𝑋, 𝑋𝑋 * ) 𝐾𝐾(𝑋𝑋 * , 𝑋𝑋) 𝐾𝐾(𝑋𝑋 * , 𝑋𝑋 * ) ��(3)
The predictive distribution for  * is then a Gaussian with mean  * and covariance Σ * , which is given by:
𝜇𝜇 * = 𝑚𝑚(𝑋𝑋 * ) + 𝐾𝐾(𝑋𝑋 * , 𝑋𝑋)[𝐾𝐾(𝑋𝑋, 𝑋𝑋) + 𝜎𝜎 𝑛𝑛 2 𝐼𝐼] −1 �𝑦𝑦 − 𝑚𝑚(𝑋𝑋)�(4)Σ * = 𝐾𝐾(𝑋𝑋 * , 𝑋𝑋 * ) − 𝐾𝐾(𝑋𝑋 * , 𝑋𝑋)[𝐾𝐾(𝑋𝑋, 𝑋𝑋) + 𝜎𝜎 𝑛𝑛 2 𝐼𝐼] −1 𝐾𝐾(𝑋𝑋, 𝑋𝑋 * )(5)
where,   2 is the noise term added to the diagonal of (, ) for numerical stability and to account for observation noise.One of the key advantages of GPs is their ability to provide not only predictions but also quantify uncertainty in these predictions, a feature crucial for effective exploration-exploitation trade-offs in optimization.As non-parametric models, GPs adaptively increase their complexity with the availability of more data, making them suitable for a wide range of functions, from simple to highly complex.The use of kernel functions in GPs allows for the incorporation of prior knowledge and assumptions about the function's behavior, such as smoothness or periodicity, enhancing their adaptability [44].Additionally, GPs offer analytical tractability, enabling closed-form expressions for predictions and uncertainties, which are computationally efficient.</p>
<p>Acquisition Function</p>
<p>In BO, the acquisition function plays a pivotal role in guiding the sampling process.It is essentially a strategy or heuristic used to decide where to sample next, balancing the need for exploration (sampling in areas with high uncertainty) and exploitation (sampling in areas where the model predicts accurate values) [16].Using the uncertainty information provided by the surrogate model, the acquisition function helps to make informed decisions about where to sample next.There are many popular choices for acquisition functions in the literature of BO.However, Expected Improvement (EI) and Upper Confidence Bound (UCB) are two popularly used acquisition functions [45].</p>
<p>Expected Improvement (EI): EI is a widely used acquisition function in Bayesian Optimization (BO) for guiding the selection of the next sampling point.It is particularly effective in striking a balance between exploring new areas and exploiting the known promising regions of the search space.EI focuses on regions of the input space where there's the highest expected improvement over the current best observation [16].It essentially quantifies the expected amount by which a given point  could improve over the current best-known value ( + ) [37].EI at a point  is defined as the expectation of the improvement function (), which is the positive difference between the current best value ( + ) and the potential function value at .Mathematically, it's expressed as:
𝐼𝐼(𝑥𝑥) = max(0, 𝑓𝑓(𝑥𝑥 + ) − 𝑓𝑓(𝑥𝑥))(6)
The EI at point  under a Gaussian Process (GP) model is then given by:
𝐸𝐸𝐼𝐼(𝑥𝑥) = 𝐸𝐸<a href="7">𝐼𝐼(𝑥𝑥)</a>
For a GP, this expectation can be calculated analytically.Assuming the GP prediction at point  is normally distributed with mean () and standard deviation (), the EI can be computed as:
𝐸𝐸𝐼𝐼(𝑥𝑥) = (𝜇𝜇(𝑥𝑥) − 𝑓𝑓(𝑥𝑥 + ) − 𝜉𝜉)Φ(𝑍𝑍) + 𝜎𝜎(𝑥𝑥)𝜙𝜙(𝑍𝑍)(8)
where, () and () are the mean and standard deviation of the GP's predictions at , Φ and  are the cdf and pdf of the standard normal distribution, respectively,  is a small non-negative parameter that introduces a trade-off between exploitation and exploration. is a standardization of the improvement function given by:
𝑍𝑍 = 𝜇𝜇(𝑥𝑥)−𝑓𝑓(𝑥𝑥 + )−𝜉𝜉 𝜎𝜎(𝑥𝑥)(9)
Upper Confidence Bound (UCB): UCB is another key acquisition function used in Bayesian Optimization (BO), particularly known for its ability to balance exploration and exploitation efficiently.Unlike some other acquisition functions that primarily focus on regions of high expected value or improvement, UCB explicitly incorporates the uncertainty of the surrogate model predictions into the decision-making process.UCB is based on the principle of "optimism in the face of uncertainty" [46].It selects the next point to sample by considering not only the expected value of the function at each point (exploitation) but also the uncertainty or variance associated with that prediction (exploration) [47].The idea is to sample points where the surrogate model predicts high values or where the uncertainty of the prediction is high, thus potentially discovering better maxima than currently known.Mathematically, the UCB at a point  in the input space is defined as a sum of the predicted mean and a confidence interval around the mean:
𝑈𝑈𝑈𝑈𝑈𝑈(𝑥𝑥) = 𝜇𝜇(𝑥𝑥) + 𝜅𝜅 ⋅ 𝜎𝜎(𝑥𝑥)(10)
where, () and () are the mean prediction and the standard deviation or the uncertainty of the surrogate model, respectively at point , and  is a tunable parameter that determines the trade-off between exploration and exploitation.</p>
<p>Proposed Methodology (TDUEBO)</p>
<p>EI tends to focus on regions close to the best observed outputs, making it inherently exploitative.While this is beneficial for refining the search around promising areas, it can lead to premature convergence and missing out on potentially better regions that haven't been sufficiently explored.On the other hand, UCB, with its emphasis on uncertainty, inherently leans towards exploration.While this is advantageous for discovering new regions of the search space, it can result in excessive exploration, especially in later stages of optimization when refining the solution is more critical.In our proposed framework, these limitations are addressed by intelligently combining UCB and EI in a hybrid acquisition function strategy which switches from being more explorative in the initial phase (UCB-based) to being more exploitative (EI-based) in the later phase.We employ a threshold guided strategy to dictate the dynamic UCB-EI switching during the closed-loop active learning process.The rationale for using a threshold-driven approach in BO hinges on effectively balancing the two fundamental aspects of the optimization process: exploring the design space to find regions of potential interest and exploiting known regions to refine the search around promising areas.Initially, when the surrogate model has limited data, the uncertainty across the design space is high.Using UCB initially emphasizes exploration, which is vital to avoid local optima and discover diverse regions of potential interest.As more data points are gathered, the model's uncertainty decreases, and a more exploitation-focused strategy becomes beneficial.The threshold for switching from UCB to EI is based on the level of average uncertainty in the model's predictions.When the average uncertainty drops below a certain level, it indicates that the model has a relatively more confident understanding of the function's behavior.At this point, switching to EI is rational because it focuses more on exploiting the regions around the current best observations, which is more efficient once the model is sufficiently informed.We resort to domain knowledge and expertise to guide the setting of this threshold.Based on the property of the process parameters and the desired output, the threshold is set to reflect the point at which further exploration is unlikely to yield practically significant improvements.The average uncertainty or standard deviation across the input space in a GP model can be calculated by averaging the standard deviation of the GP's predictions at a set of points.This average gives an overall measure of the model's uncertainty about the function it's approximating.For any point  * , the variance can be calculated using the GP model as Equation 11.The standard deviation or uncertainty for  * is calculated simply taking the square root of this variance which is given by Equation 12.
𝜎𝜎 2 (𝑥𝑥 * ) = 𝐾𝐾(𝑥𝑥 * , 𝑥𝑥 * ) − 𝐾𝐾(𝑥𝑥 * , 𝑋𝑋)[𝐾𝐾(𝑋𝑋, 𝑋𝑋) + 𝜎𝜎 𝑛𝑛 2 𝐼𝐼] −1 𝐾𝐾(𝑋𝑋, 𝑥𝑥 * ) (11) 𝜎𝜎(𝑥𝑥 * ) = �𝜎𝜎 2 (𝑥𝑥 * )(12)
Finally, the average uncertainty or average standard deviation across all the  points ( * ) is calculated using Equation (13) where  is the number of points in  * , and  *  represents the i-th point in  * .We have divided our proposed methodology into five unique steps which are described in the following:
𝜎𝜎 � = 1 𝑁𝑁 ∑ 𝜎𝜎(𝑥𝑥 * 𝑖𝑖 ) 𝑁𝑁 𝑖𝑖=1(13)
Step 1 (Initialization): Start with a set of initial samples,   = {  ,   } to fit the GP model using Equation ( 2).The initial samples are obtained after dividing each dataset into three parts.One part is used to fit the initial GP model, another part is used as the candidate locations for the sequential updates during the closed-loop BO process.The third part is reserved to test the performance of all the approaches.For instance, for the P3HT/CNT dataset, out of 233 original samples, 30 were used for initial model fitting, 144 samples were allocated for the sequential experiment candidates and the remaining 59 samples were kept for testing the approaches.</p>
<p>Step 2 (Sequential Sampling with UCB): Begin the active learning or sequential experiment process using UCB as the acquisition function using.This phase emphasizes exploring the design space to uncover regions with high uncertainty or potential.The available candidate samples for this sequential process are selected from the second part of the original dataset which can be represented by   = �  ,   �.In the P3HT/CNT dataset, out of 144 allocated candidate samples, 50 samples were used for updating the models sequentially.This means that considering the initial 30 samples and now 50 sequential samples, the experimental budget for the P3HT/CNT dataset is limited to 80 samples.</p>
<p>Step 3 (Monitoring Uncertainty): Continuously monitor the uncertainty in the GP model's predictions.This involves assessing the average standard deviation of the predictions across the design space using Equations (11)(12)(13).</p>
<p>Step 4 (Switching to EI): Once the uncertainty falls below a predefined threshold, switch the acquisition function from UCB to EI.This marks the transition to a more exploitative phase, focusing on refining the search in the most promising areas.</p>
<p>Step 5 (Iterative Update): Continue the iterative process of selecting new sample points based on EI from the set   , updating the GP model, and re-evaluating until our experimental budget is exhausted.In this work, this experimental budget varies depending on the dataset we use.The framework of TDUE-BO is illustrated in Figure 4.</p>
<p>Figure 5 shows the pseudocode of the proposed TDUE-BO algorithm.</p>
<p>Results and Discussion</p>
<p>An Illustrative Example</p>
<p>To visualize the working of our proposed framework, in this section, we have attempted to approximate a simple univariate function using our approach.We have also shown how our methodology performs better in approximating an unknown function than the widely used EI-based and UCB-based BO frameworks.The univariate function that we attempted to predict has a very simple form which can be expressed by Equation (14) where () = − sin 3 −  2 + 0.7 and  is used to denote a Gaussian noise. = () +  The function has a very simple structure with two peaks as shown in Figure 2 with the green curve.The noisy samples are the blue dots where the mean and standard deviation of the Gaussian noise is chosen to be 0 and 0.2, respectively.</p>
<p>In the absence of knowledge about the underlying true function, our proposed sequential algorithm would start with two initial experiments (one at -0.9 and the other at 1.1) as seen in the figure.This is necessary to construct a statistical model.In simple words, to approximate the above function, we need to start with some known input values along the  axis and their corresponding  or () values.The range of the input values in this case is [-1.0, 2.0].For the sequential updates, we decided to work with an experiment budget of 11 candidate locations or experiments.As the statistical model, we fit a Gaussian Process with Matern kernel using these two initial experiments.We present the approximation of this univariate function with EI-based BO, UCB-based BO and then our proposed hybrid UCB-EIbased BO.Note that we are showing the first and the last 4 iterations of each of this approach.As seen from Figure 7 where we approximated the one-dimensional function, the final approximation using EI-based BO after 12 iterations although identified the maxima of the function, could not however approximate the right most peak of the function (see Iteration 12).We can also see from Figure 7 that EI is more exploitative in nature, overexploiting the region around the left peak of the function and as a result could not give us an overall idea about the entire response surface.In Figure 8, where we approximated the similar function with UCB-based BO, we see that UCB does a better job in giving us a decent understanding of the response surface by exploring more.However, it could not correctly determine the optima.</p>
<p>Our proposed TDUE-BO, on the other hand, successfully achieved a balance by doing the right amount of both exploration and exploitation and consequently, we see in the Figure 9 that after 12 iterations, the entire response surface was approximated as well as the optima has been identified.</p>
<p>Application in Materials Datasets</p>
<p>Our proposed framework, Threshold-Driven-UCB-EI BO (TDUE-BO) is applied in three different material science datasets.All these three datasets (Perovskite, P3HT/CNT, and AutoAM) are obtained through high throughput experiments (HTE).After data normalization has been applied, the datasets became ready for use in our proposed methodology.Table 1 shows the classification of these datasets into training and test sets as well as the number of samples or points used from the training sets to fit the initial GP and to perform the sequential experiments.For instance, the Perovskite dataset has a total of 139 samples.We split it into training (75%) and test (25%) sets.Out of the 104 samples in the training set, we used 20 samples for the initial model fitting using GP and used the remaining 84 samples as candidates for the sequential experiments.Out of these 84 samples, we decided to keep the experimental budget to 40 sequential iterations which indicates that the initial GP model has been updated sequentially 40 times, each time with one sample added to the surrogate model.We followed a similar procedure for the other two datasets (P3HT/CNT and AutoAM).Based on the dataset size, different number of samples were used for the initial model fitting and the sequential iterations.We compared the performance of our proposed TDUE-BO framework with the existing UCB-based BO and EI-based BO, respectively.As the performance metric, we employed the root mean square error (RMSE) score defined as the square root of the average of the squared differences between the predicted values and the actual values.It can be expressed as mathematically as:
𝑅𝑅𝑅𝑅𝑅𝑅𝐸𝐸 = � ∑ (𝑦𝑦 𝑖𝑖 −𝑦𝑦 � 𝑖𝑖 ) 2 𝑛𝑛 𝑖𝑖=1 𝑛𝑛(15)
where,   and  �  represents the actual observed and the predicted values, respectively and  represents the total number of observations.To reduce the uncertainty while assessing the performance, we have calculated the RMSE scores for these three datasets 30 times.The boxplots of the RMSE scores for the three competing approaches are also illustrated in the following figures.Figure 10 (a) shows the boxplot for the Perovskite dataset.We can see that in addition to obtaining a significantly reduced RMSE value, the dispersion of the RMSE values for 30 runs is also much less.From Figure 10 (b), for the P3HT/CNT dataset, the boxplot shows lower RMSE scores for our approach.The boxplot for the AutoAM dataset once again underscores the superior performance of TDUE-BO over the other two approaches in Figure 10 (c).In terms of RMSE score, our proposed approach TDUE-BO does a better job at approximating the underlying relationship between the process parameters and the desired property in the three material datasets.However, convergence is also another crucial aspect in these sequential learning algorithms.Keeping this in mind, we also attempted to analyze the convergence of our approach compared to the two traditional approaches.To achieve this, for each of the datasets, we checked how TDUE-BO performs in determining the minimum value of the target property which is the desired property for all these datasets.The results are shown in the following figures.Figure 11 shows the convergence of all the three methods for the Perovskite dataset.We can see TDUE-BO is able to determine the minimum value within 18 iterations which is the quickest.EI-based BO, in this case, failed to converge even after 40 sequential updates.Continuing from iteration number 17 till 40, EI was exploiting around the same region due to its over-exploiting tendency and therefore could not locate the optimal target property.Figure 12 shows the convergence for the P3HT/CNT dataset.We can once again see the superior convergence of TDUE-BO over the two other methods which successfully reached the minimum within 31 iterations.In this case, UCB-BO, due to prioritizing exploration more than exploitation, failed to identify the minimum value whereas it took 39 iterations for EI-BO to converge.Finally, for the AutoAM dataset, TDUE-BO converged much earlier taking only 13 iterations compared to its counterpart EI-based BO which took 21 iterations.UCB-based BO once again could not converge for this dataset.</p>
<p>Conclusion</p>
<p>In this work, we have proposed a novel approach of performing the sequential experiments using the BO active learning framework.We have augmented the performance of the classical BO, which uses EI or UCB as the means to guide the iterative process of choosing subsequent samples, by a threshold guided method based on the uncertainty quantified by the GP model.By taking advantage of the strengths of UCB and EI, our proposed method overcomes the weaknesses of the UCB and EI-based BO.In TDUE-BO, the use of UCB at the outset capitalizes on its exploratory strengths, ensuring a comprehensive initial sweep of the MDS.This is crucial in material science applications where the objective functions often exhibit multi-modal and intricate behaviors.As our GP model accrues data and refines its understanding, reflected by a decrease in the average standard deviation of predictions, we seamlessly transition to the EI acquisition function.This shift marks a transition to a more exploitation-focused phase, concentrating our search around the most promising areas identified during the initial exploration.We have employed our proposed methodology in three different datasets from the field of material science and the results have reflected the advantages of this adaptive approach.We observed a better realization of the relationship between the process parameters and the target output using the TDUE-BO approach in all three datasets compared to conventional BO methods that rely on a single type of acquisition function throughout.The threshold-driven switch from UCB to EI ensures that our method not only approximates the MDS efficiently but also converges to the optimal region with lower number of sequential updates, adapting its focus from exploration to exploitation.This adaptability is particularly beneficial in material science, where the diversity of datasets and the complexity of their underlying phenomena demand a flexible optimization approach.</p>
<p>Future directions of this work could include trying our proposed framework with high-dimensional datasets as the performance of BO continues to deteriorate when the dimension of the input features increases.Besides, since BO is often criticized for being myopic in nature, reinforcement learning (RL) could be incorporated to achieve the multistep lookahead capability in BO.RL could also be employed to choose a different acquisition function for each sequential update from a large set of available acquisition functions to get a much better convergence and approximation.</p>
<p>Figure 1 :
1
Figure 1: 3D surface representation of 'Conductivity' distribution across the principal components in the P3HT/CNT dataset</p>
<p>Figure 2 :
2
Figure 2: 3D surface representation of 'Instability Index' distribution across the principal components in the Perovskite dataset</p>
<p>Figure 3 :
3
Figure 3: 3D surface representation of 'Score' distribution across the principal components in the AutoAM dataset</p>
<p>Figure 4 :Figure 5 :
45
Figure 4: Flow diagram of the proposed TDUE-BO framework Algorithm 1: Threshold-Driven UCB-EI Bayesian Optimization (TDUE-BO) Inputs: Material Dataset, ; Uncertainty Threshold,  ℎℎ , Experimental Budget Output: Optimized Response Surface with Desired Material Property // Initializing 01: Split  into   = {  ,   } (initial samples),   = �  ,   � (sequential samples),   = {  ,   } (test samples) 02: Fit initial GP model (  ) to   = {  ,   } // Iterative Update 03: While not exhausted experimental budget do 04: IF acquisition function is UCB Then: //Sequential Sampling with UCB 05: Select   from   using UCB 06: ELSE IF acquisition function is EI Then 07: Select   from   using EI 08: END IF 09: Obtain   for sample   10: Update GP model with {  ,   } // Monitoring Uncertainty 11: Calculate (  ) = (((  ))) 12: IF  &lt;  ℎℎ Then //Switching to EI 13: Switch acquisition function to EI 14: END IF 15: END While 16: Use optimized GP model to predict desired material property 17: RETURN Optimized GP Model, Desired Material Property 18: END Figure 5: Pseudocode of the proposed TDUE-BO sequential learning approach</p>
<p>Figure 6 :
6
Figure 6: A 1-dimensional function with noisy samples</p>
<p>Figure 7 :Figure 8 :Figure 9 :
789
Figure 7: Approximation of a 1-dimensional function with EI-based BO</p>
<p>Figure 10 :
10
Figure 10: (a) Boxplots for the RMSE scores of three competing approaches for (a) Perovskite dataset (b) P3HT/CNT dataset and (c) AutoAM dataset</p>
<p>Figure 11 :
11
Figure 11: Iterations to reach the minimum for the three competing approaches for the Perovskite dataset</p>
<p>Figure 12 :
12
Figure 12: Iterations to reach the minimum for the three competing approaches for the P3HT/CNT dataset</p>
<p>Figure 13 :
13
Figure 13: Iterations to reach the minimum for the three competing approaches for the AutoAM dataset</p>
<p>Table 1 :
1
Description of the three datasets
DatasetTraining SetInitial Model Fitting Sequential ExperimentsTest SetPerovskite1042040 (84)39P3HT/CNT1743050 (144)59AutoAM751530 (60)25</p>
<p>Table 2 :
2
Table2compares the mean, median and the interquartile range (IQR) for these three datasets with the EI-BO, UCB-BO and our proposed methodology (TDUE-BO) over 30 RMSE score calculations.A lower RMSE score indicates a better approximation performance.From the table, we can see that for the Perovskite dataset, our method (TDUE-BO) achieved better results in terms of all the metrics (highlighted in red).IQR, measuring the statistical dispersion, is significantly lower (0.015459) which indicates a better consistency and reliability in prediction performance for our approach.For the P3HT/CNT dataset, TDUE-BO outperformed both the EI and UCBbased BO in terms of the mean and median achieving lower RMSE values.Finally, in the AutoAM dataset, TDUE-BO once again achieved superior performance achieving lower values of mean, median and IQR for the RMSE scores.Performance comparison of the three competing approaches for the three datasets using RMSE scores
StatisticEI-BOUCB-BOTDUE-BOPerovskite DatasetMean0.1609570.1376080.108539Median0.1717250.1131140.109779IQR0.0911040.0823150.015459P3HT/CNT DatasetMean0.125170.1247950.120858Median0.1242010.123330.120856IQR0.0251070.0240280.025467AutoAM DatasetMean0.1568720.1421490.134824Median0.151810.1364130.129976IQR0.0585070.0442310.026041
AcknowledgementsWe extend our sincere gratitude to the Department of Industrial and Management Systems Engineering (IMSE) for their unwavering support throughout the duration of this research.Additionally, we are deeply grateful to our fellow professors and researchers specializing in the field of additive manufacturing.Their collaborative spirit, shared expertise, and insightful feedback have significantly enriched this study.
Accelerating materials discovery using artificial intelligence, high performance computing and robotics. E O Pyzer-Knapp, 10.1038/s41524-022-00765-znpj Comput. Mater. 812022</p>
<p>Accelerating materials discovery using machine learning. Y Juan, Y Dai, Y Yang, J Zhang, 10.1016/j.jmst.2020.12.010J. Mater. Sci. Technol. 792021</p>
<p>Thermodynamics and kinetics of phase transformation in rare earth-magnesium alloys: A critical review. Q Luo, 10.1016/j.jmst.2020.01.022J. Mater. Sci. Technol. 442020</p>
<p>Density functional theory calculations: A powerful tool to simulate and design high-performance energy storage and conversion materials. X Wu, F Kang, W Duan, J Li, 10.1016/j.pnsc.2019.04.003Prog. Nat. Sci. Mater. Int. 2932019</p>
<p>Autonomy in materials research: a case study in carbon nanotube growth. P Nikolaev, 10.1038/npjcompumats.2016.31Comput. Mater. 21160312016</p>
<p>On-the-fly closed-loop materials discovery via Bayesian active learning. A G Kusne, 10.1038/s41467-020-19597-wNat. Commun. 11159662020</p>
<p>Cost-effective materials discovery: Bayesian optimization across multiple information sources. H C Herbol, M Poloczek, P Clancy, 10.1039/D0MH00062KMater. Horizons. 782020</p>
<p>Guiding the Sequential Experiments in Autonomous Experimentation Platforms through EI-based Bayesian Optimization and Bayesian Model Averaging. A S Raihan, I Ahmed, 10.48550/arXiv.2302.133602023</p>
<p>Bayesian optimization for material discovery processes with noise. S Diwale, M K Eisner, C Carpenter, W Sun, G C Rutledge, R D Braatz, Mol. Syst. Des. Eng. 762022</p>
<p>Recent progress in the simulation of microstructure evolution in titanium alloys. J Zhang, X Li, D Xu, R Yang, 10.1016/j.pnsc.2019.05.006Prog. Nat. Sci. Mater. Int. 2932019</p>
<p>SEHC: A high-throughput materials computing framework with automatic self-evaluation filtering. W Zhu, Y Xu, J Ni, G Hu, X Wang, W Zhang, 10.1016/j.mseb.2019.114474Mater. Sci. Eng. B. 2521144742020</p>
<p>Autonomous intelligent agents for accelerated materials discovery. J H Montoya, K T Winther, R A Flores, T Bligaard, J S Hummelshøj, M Aykol, Chem. Sci. 11322020</p>
<p>Autonomous materials discovery and manufacturing (AMDM): A review and perspectives. S T S Bukkapatnam, 10.1080/24725854.2022.2089785IISE Trans. 551Jan. 2023</p>
<p>Bayesian optimization with adaptive surrogate models for automated experimental design. B Lei, 10.1038/s41524-021-00662-xComput. Mater. 712021</p>
<p>Autonomous efficient experiment design for materials discovery with Bayesian model averaging. A Talapatra, S Boluki, T Duong, X Qian, E Dougherty, R Arróyave, 10.1103/PhysRevMaterials.2.113803Phys. Rev. Mater. 2112018</p>
<p>Efficient Global Optimization of Expensive Black-Box Functions. D R Jones, M Schonlau, W J Welch, 10.1023/A:1008306431147J. Glob. Optim. 1341998</p>
<p>Bayesian optimization for materials design. P I Frazier, J Wang, 10.1007/978-3-319-23871-5_3Springer Ser. Mater. Sci. 2252015</p>
<p>Benchmarking the performance of Bayesian optimization across multiple experimental materials science domains. Q Liang, 10.1038/s41524-021-00656-9Comput. Mater. 712021</p>
<p>Taking the Human Out of the Loop: A Review of Bayesian Optimization. B Shahriari, K Swersky, Z Wang, R P Adams, N De Freitas, 10.1109/JPROC.2015.2494218Proc. IEEE. IEEE2016104</p>
<p>A Tutorial on Bayesian Optimization. P I Frazier, 10.48550/arXiv.1807.02811arXiv Prepr. arXiv1807.028112018</p>
<p>A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning. E Brochu, V M Cora, N De Freitas, 2010</p>
<p>Materials Acceleration Platforms: On the way to autonomous experimentation. M M Flores-Leonar, 10.1016/j.cogsc.2020.100370Curr. Opin. Green Sustain. Chem. 251003702020</p>
<p>Bayesian optimization for accelerated drug discovery. E O Pyzer-Knapp, 10.1147/JRD.2018.2881731IBM J. Res. Dev. 6262018</p>
<p>Batched Bayesian Optimization for Drug Design in Noisy Environments. H Bellamy, A A Rehim, O I Orhobor, R King, 10.1021/acs.jcim.2c00602J. Chem. Inf. Model. 6217Sep. 2022</p>
<p>Bayesian Optimization in Drug Discovery BT -High Performance Computing for Drug Discovery and Biomedicine. L Colliandre, C Muller, A. Heifetz2024Springer USNew York, NY</p>
<p>Bayesian optimization with safety constraints: safe and automatic parameter tuning in robotics. F Berkenkamp, A Krause, A P Schoellig, 10.1007/s10994-021-06019-1Mach. Learn. 112102023</p>
<p>Improving Robotic Cooking Using Batch Bayesian Optimization. K Junge, J Hughes, T G Thuruthel, F Iida, 10.1109/LRA.2020.2965418IEEE Robot. Autom. Lett. 522020</p>
<p>Advances in Bayesian Optimization with Applications in Aerospace Engineering. R Lam, M Poloczek, P Frazier, K E Willcox, 2018 AIAA Non-Deterministic Approaches Conference. American Institute of Aeronautics and Astronautics2018</p>
<p>Bayesian optimization using deep Gaussian processes with applications to aerospace system design. A Hebbal, L Brevault, M Balesdent, E.-G Talbi, N Melab, 10.1007/s11081-020-09517-8Optim. Eng. 2212021</p>
<p>Multi-Objective Stochastic Bayesian Optimization for Iterative Engine Calibration. A Pal, L Zhu, Y Wang, G G Zhu, 10.23919/ACC45564.2020.91479832020 American Control Conference (ACC). 2020</p>
<p>Adaptive Design of Experiments for Automotive Engine Applications Using Concurrent Bayesian Optimization. L Zhu, Y Wang, A Pal, G G Zhu, 10.1115/1.4054222ASME Lett. Dyn. Syst. Control. 23Apr. 2022</p>
<p>Bayesian optimization for chemical products and functional materials. K Wang, A W Dowling, 10.1016/j.coche.2021.100728Curr. Opin. Chem. Eng. 362022</p>
<p>Multi-objective Bayesian optimization of chemical reactor design using computational fluid dynamics. S Park, J Na, M Kim, J M Lee, 10.1016/j.compchemeng.2018.08.005Comput. Chem. Eng. 1192018</p>
<p>Constrained Bayesian optimization for automatic chemical design using variational autoencoders. R R Griffiths, J M Hernández-Lobato, Chem. Sci. 1122020</p>
<p>Multi-step lookahead Bayesian optimization with active learning using reinforcement learning and its application to data-driven batch-to-batch optimization. H.-E Byun, B Kim, J H Lee, 10.1016/j.compchemeng.2022.107987Comput. Chem. Eng. 1672022</p>
<p>Towards Futuristic Autonomous Experimentation--A Surprise-Reacting Sequential Experiment Policy. I Ahmed, S Bukkapatnam, B Botcha, Y Ding, 2021</p>
<p>Convergence rates of efficient global optimization algorithms. A D Bull, J. Mach. Learn. Res. 122011</p>
<p>A Hierarchical Expected Improvement Method for Bayesian Optimization. Z Chen, S Mak, C F J Wu, 10.1080/01621459.2023.2210803J. Am. Stat. Assoc. 2023</p>
<p>Multi-Fidelity High-Throughput Optimization of Electrical Conductivity in P3HT-CNT Composites. D Bash, 10.1002/adfm.202102606Adv. Funct. Mater. 31362102606Sep. 2021</p>
<p>A data fusion approach to optimize compositional stability of halide perovskites. S Sun, 10.1016/j.matt.2021.01.00820214Matter</p>
<p>Toward autonomous additive manufacturing: Bayesian optimization on a 3D printer. J R Deneault, 10.1557/s43577-021-00051-1MRS Bull. 4672021</p>
<p>Principal component analysis. H Abdi, L J Williams, 10.1002/wics.101WIREs Comput. Stat. 24Jul. 2010</p>
<p>Gaussian processes for machine learning. C E Rasmussen, C K Williams, 2006MIT pressCambridge, MA</p>
<p>A Gaussian Process Model-Guided Surface Polishing Process in Additive Manufacturing. S Jin, A Iquebal, S Bukkapatnam, A Gaynor, Y Ding, 10.1115/1.4045334J. Manuf. Sci. Eng. 1421Nov. 2019</p>
<p>Bayesian Optimization with Exponential Convergence. K Kawaguchi, L P Kaelbling, T Lozano-Pérez, Advances in Neural Information Processing Systems. 201528</p>
<p>Greed Is Good: Exploration and Exploitation Trade-Offs in Bayesian Optimisation. G De Ath, R M Everson, A A M Rahat, J E Fieldsend, 10.1145/3425501ACM Trans. Evol. Learn. Optim. 11Apr. 2021</p>
<p>Tuning Confidence Bound for Stochastic Bandits with Bandit Distance. X Zhang, S Das, K Kreutz-Delgado, 10.48550/arXiv.2110.02690arXiv Prepr. arXiv2110.026902021</p>            </div>
        </div>

    </div>
</body>
</html>