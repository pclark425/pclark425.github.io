<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-709 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-709</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-709</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-270559890</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.11517v1.pdf" target="_blank">Revisiting Spurious Correlation in Domain Generalization</a></p>
                <p><strong>Paper Abstract:</strong> Without loss of generality, existing machine learning techniques may learn spurious correlation dependent on the domain, which exacerbates the generalization of models in out-of-distribution (OOD) scenarios. To address this issue, recent works build a structural causal model (SCM) to describe the causality within data generation process, thereby motivating methods to avoid the learning of spurious correlation by models. However, from the machine learning viewpoint, such a theoretical analysis omits the nuanced difference between the data generation process and representation learning process, resulting in that the causal analysis based on the former cannot well adapt to the latter. To this end, we explore to build a SCM for representation learning process and further conduct a thorough analysis of the mechanisms underlying spurious correlation. We underscore that adjusting erroneous covariates introduces bias, thus necessitating the correct selection of spurious correlation mechanisms based on practical application scenarios. In this regard, we substantiate the correctness of the proposed SCM and further propose to control confounding bias in OOD generalization by introducing a propensity score weighted estimator, which can be integrated into any existing OOD method as a plug-and-play module. The empirical results comprehensively demonstrate the effectiveness of our method on synthetic and large-scale real OOD datasets.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e709.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e709.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PSW</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Propensity Score Weighted estimator (Propensity-Scored ERM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A plug-and-play importance-weighting estimator for domain generalization that approximates the interventional distribution P(Y | do(C)) by reweighting observational samples by the inverse propensity P(C=c | S=s), and is integrated as a regularizer into existing OOD methods.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Propensity Score Weighted estimator (PSW) / Propensity-Scored ERM</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Builds on backdoor adjustment: P(Y|do(C=c)) = sum_s P(Y, C=c, S=s)/P(C=c|S=s). The paper implements this by (1) estimating a per-sample propensity score π(x)=P(C=c|S=s) for the observed representation (c,s); (2) using importance-weighted empirical risk RP_SW(f|π)= (1/N) sum_i ℓ(f(x_i),y_i) * π(x_i) (equivalently weights proportional to 1/π appear in derivation); (3) adding this PSW loss L_PSW as a regularizer to any base OOD method. The paper provides a theoretical generalization/error bound for the PSW estimator, and integrates it with practical propensity estimation (FFT-based decomposition + clustering + pairing augmentation).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Domain generalization benchmarks (ColoredMNIST, RotatedMNIST, VLCS, PACS, OfficeHome, TerraIncognita)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Standard observational image-domain generalization datasets (multi-domain image corpora). These are not open-ended interactive labs — they are static datasets collected from different domains/environments used to evaluate OOD generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Identifies spurious/distractor components S via frequency decomposition and clustering, then reduces their confounding via propensity-score based importance weighting (backdoor-style reweighting).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Domain-dependent spurious features (S) that create spurious correlations and collider-specific confounding / selection bias between invariant feature C and label Y.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Extracts spurious signal S by FFT-based frequency separation (low-frequency → S) followed by encoder g(·) feature extraction and K-means clustering to categorize S; uses these clusters to compute population propensity estimates P(C cluster | S cluster).</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Importance weighting via propensity score π(x)=P(C=c|S=s); samples are reweighted in the empirical risk by factor π(x) (equivalently derived as 1/P(C|S) amplification of joint (Y,C,S) in derivation), implemented as a PSW regularizer L_PSW.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Implements backdoor-style reweighting to approximate P(Y|do(C)), thereby attempting to refute/deconfound spurious C–Y associations arising from S; theoretical analysis shows adjusting S via PSW approximates intervention without experiments when propensities are accurate.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Applying PSW as a plug-in improved downstream generalization: e.g., BalancingERM+Ours average accuracy increased ≈1.1% over BalancingERM baseline (reported per-paper: BalancingERM baseline avg 72.3 -> BalancingERM+Ours 73.4) and BalancingCORAL improved ≈0.8% (74.0 -> 74.8). Significant gains reported on ColoredMNIST, PACS, OfficeHome benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baselines (no PSW): BalancingERM avg ~72.3, BalancingCORAL avg ~74.0 (values reported in the paper's tables).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>PSW reduces confounding introduced by spurious features S in collider-specific SCMs and yields consistent OOD accuracy gains when combined with base methods; success depends on accurate propensity estimation (bias-variance tradeoff). Ablation shows removing the PSW term degrades performance, indicating the estimator contributes to robustness against spurious correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Revisiting Spurious Correlation in Domain Generalization', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e709.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e709.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FFT-based separation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FFT frequency-domain decomposition for invariant vs spurious feature separation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A practical pipeline that separates an input image into high-frequency (assumed invariant/causal) and low-frequency (assumed spurious/domain-dependent) components using FFT masks, then extracts representation-level c and s via an encoder.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>FFT-based high/low frequency separation with masking and inverse transform</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Compute the 2D FFT spectrum F(x), apply binary low-pass and high-pass masks (parameterized by filter size S) to obtain F_l and F_h, inverse-FFT to get x_l and x_h, then pass each through encoder g(·) to obtain spurious feature s=g(x_l) and invariant candidate c=g(x_h). These representations are then clustered (K-means) to produce discrete C and S categories for propensity estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same image-domain benchmarks (ColoredMNIST, PACS, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Static image datasets; method is applied as preprocessing/representation-splitting step — not an interactive environment.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Separates distractor signals by spectral filtering (low-frequency content is treated as spurious/distractor S).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Low-frequency domain-specific style/background signals (e.g., background color) and other domain-style artifacts.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Spectral decomposition: the low-frequency component is taken as the candidate spurious signal; encoder + clustering used to operationalize detection into discrete S clusters.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Contributes to improved propensity estimation and downstream PSW performance; the paper’s ablation shows that removing the pairing/propensity estimation pipeline (which includes FFT separation) reduces OOD accuracy, indicating practical value, but no isolated numeric metric for FFT alone is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Frequency decomposition is an effective, practical heuristic to disentangle invariant (high-frequency) and spurious (low-frequency) signals for image-domain OOD tasks; it enables downstream propensity estimation used by PSW.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Revisiting Spurious Correlation in Domain Generalization', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e709.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e709.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pairing scheme</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pairing augmentation for propensity completeness</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A data-augmentation method that simulates additional combinations of invariant and spurious features by mixing low-frequency parts across images to expand the observed support of S and improve propensity score estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Pairing (low-frequency interpolation) augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>For a sample x_i and a randomly sampled x_j, keep x_i's high-frequency part F_h(x_i) but linearly interpolate the low-frequency parts F_l(x_i) and F_l(x_j) with mixing coefficient λ~U(0,δ), then inverse-FFT to obtain a 'simulated' sample whose c is from x_i and s is a mixture; include both original and simulated samples during training to enlarge the available S domain and improve K-means clustering and propensity estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same static image datasets (ColoredMNIST, PACS, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Offline augmentation scheme applied to training data to simulate broader spurious variation; not an interactive experiment-selection method.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Data augmentation that increases coverage of spurious feature values (S), enabling more accurate estimation of P(C|S).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Low-frequency background/style distractors and domain-specific spurious attributes.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Indirect: by improving the estimated propensities π(x) used by PSW, it improves downstream downweighting via importance weights.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Including the pairing augmentation (loss L_PS) yields better propensity estimates and improves PSW-regularized OOD performance; ablation removing L_PS lowers performance in reported experiments (see Table 2 in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Without L_PS, PSW-based methods perform worse (paper reports that removing L_PS reduces accuracy more than removing L_PSW in some settings).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Pairing augmentation increases the range of observed S values, stabilizes propensity estimation, and thereby improves the effectiveness of PSW debiasing; it is an inexpensive simulation-based alternative to active experimentation for expanding support.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Revisiting Spurious Correlation in Domain Generalization', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e709.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e709.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Collider-specific SCM + Backdoor adjustment</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Collider-specific structural causal model and backdoor-based adjustment for representation learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A causal-modeling contribution arguing that in representation learning for OOD, many spurious correlations are best modeled as collider structures; this motivates adjusting spurious feature S (via backdoor adjustment/PSW) rather than incorrectly adjusting other covariates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Collider-specific SCM identification and backdoor adjustment</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>The authors construct an SCM for representation learning that distinguishes fork-specific (latent common cause) and collider-specific spurious correlations; they show collider-specific structure (C ← X → S → E ← Y, conditioning on E opens confounding) is consistent with OOD phenomena in practice, and that correct adjustment for confounding of C→Y requires conditioning/adjusting on S (operationalized via PSW), while improper adjustment of incorrect covariates can introduce bias. The backdoor formula P(Y|do(C)) = sum_s P(Y|C,S)P(S) is the basis for their weighting estimator.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Observational representation-learning setting / image-domain datasets used in domain generalization</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Static datasets where representation learning is trained on multiple domains and causal relationships among learned representation components are analyzed; not an interactive experimental platform.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Causal graph analysis to identify S as the confounder (detection by reasoning about d-separation), and then adjustment via backdoor formula instantiated with propensity-score weighting.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Collider-induced confounding, selection bias arising from conditioning on colliders, domain-dependent spurious features that correlate with labels via selection.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Graphical causal analysis (SCM, d-separation) and empirical observation (e.g., ColoredMNIST failures) motivate modeling choice; no automated detector proposed beyond representation separation and clustering.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>PSW (importance-weighting derived from backdoor adjustment) to simulate intervention on C.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Theoretical argument and empirical experiments (e.g., biased ColoredMNIST) are used to refute fork-specific latent-common-cause explanations and support collider-specific SCM; demonstration that incorrect covariate adjustment introduces bias.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper argues and empirically supports that collider-specific spurious correlation is the correct representation for many OOD settings in representation learning; thus, appropriate adjustment of spurious S (not arbitrary covariates) is necessary, and PSW instantiated on S can control confounding.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Revisiting Spurious Correlation in Domain Generalization', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e709.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e709.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IRM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Invariant Risk Minimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representative causal-inference-inspired domain generalization method that seeks predictors whose optimality is invariant across environments; cited in related work as background.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Revisiting Spurious Correlation in Domain Generalization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Invariant Risk Minimization (IRM)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>A method that formalizes the search for a feature representation and classifier such that the classifier is simultaneously optimal across training environments, aiming to capture invariant causal structure; discussed in related work as a canonical causal DG approach.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>N/A (mentioned as a prior method in domain generalization literature)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Referenced generically; IRM has been evaluated on domain generalization benchmarks but is not used or re-implemented in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as a foundational causal approach to OOD/generalization; paper contrasts its SCM-for-representation-learning perspective and plug-in PSW approach with IRM and notes IRM-related limitations (e.g., failures in nonlinear tasks, optimization difficulties).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Revisiting Spurious Correlation in Domain Generalization', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Invariant risk minimization <em>(Rating: 2)</em></li>
                <li>The central role of the propensity score in observational studies for causal effects <em>(Rating: 2)</em></li>
                <li>Frequency space domain randomization for domain generalization <em>(Rating: 2)</em></li>
                <li>Deep frequency filtering for domain generalization <em>(Rating: 2)</em></li>
                <li>Causal balancing for domain generalization <em>(Rating: 2)</em></li>
                <li>Causal inference in statistics: A primer <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-709",
    "paper_id": "paper-270559890",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "PSW",
            "name_full": "Propensity Score Weighted estimator (Propensity-Scored ERM)",
            "brief_description": "A plug-and-play importance-weighting estimator for domain generalization that approximates the interventional distribution P(Y | do(C)) by reweighting observational samples by the inverse propensity P(C=c | S=s), and is integrated as a regularizer into existing OOD methods.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Propensity Score Weighted estimator (PSW) / Propensity-Scored ERM",
            "method_description": "Builds on backdoor adjustment: P(Y|do(C=c)) = sum_s P(Y, C=c, S=s)/P(C=c|S=s). The paper implements this by (1) estimating a per-sample propensity score π(x)=P(C=c|S=s) for the observed representation (c,s); (2) using importance-weighted empirical risk RP_SW(f|π)= (1/N) sum_i ℓ(f(x_i),y_i) * π(x_i) (equivalently weights proportional to 1/π appear in derivation); (3) adding this PSW loss L_PSW as a regularizer to any base OOD method. The paper provides a theoretical generalization/error bound for the PSW estimator, and integrates it with practical propensity estimation (FFT-based decomposition + clustering + pairing augmentation).",
            "environment_name": "Domain generalization benchmarks (ColoredMNIST, RotatedMNIST, VLCS, PACS, OfficeHome, TerraIncognita)",
            "environment_description": "Standard observational image-domain generalization datasets (multi-domain image corpora). These are not open-ended interactive labs — they are static datasets collected from different domains/environments used to evaluate OOD generalization.",
            "handles_distractors": true,
            "distractor_handling_technique": "Identifies spurious/distractor components S via frequency decomposition and clustering, then reduces their confounding via propensity-score based importance weighting (backdoor-style reweighting).",
            "spurious_signal_types": "Domain-dependent spurious features (S) that create spurious correlations and collider-specific confounding / selection bias between invariant feature C and label Y.",
            "detection_method": "Extracts spurious signal S by FFT-based frequency separation (low-frequency → S) followed by encoder g(·) feature extraction and K-means clustering to categorize S; uses these clusters to compute population propensity estimates P(C cluster | S cluster).",
            "downweighting_method": "Importance weighting via propensity score π(x)=P(C=c|S=s); samples are reweighted in the empirical risk by factor π(x) (equivalently derived as 1/P(C|S) amplification of joint (Y,C,S) in derivation), implemented as a PSW regularizer L_PSW.",
            "refutation_method": "Implements backdoor-style reweighting to approximate P(Y|do(C)), thereby attempting to refute/deconfound spurious C–Y associations arising from S; theoretical analysis shows adjusting S via PSW approximates intervention without experiments when propensities are accurate.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Applying PSW as a plug-in improved downstream generalization: e.g., BalancingERM+Ours average accuracy increased ≈1.1% over BalancingERM baseline (reported per-paper: BalancingERM baseline avg 72.3 -&gt; BalancingERM+Ours 73.4) and BalancingCORAL improved ≈0.8% (74.0 -&gt; 74.8). Significant gains reported on ColoredMNIST, PACS, OfficeHome benchmarks.",
            "performance_without_robustness": "Baselines (no PSW): BalancingERM avg ~72.3, BalancingCORAL avg ~74.0 (values reported in the paper's tables).",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "PSW reduces confounding introduced by spurious features S in collider-specific SCMs and yields consistent OOD accuracy gains when combined with base methods; success depends on accurate propensity estimation (bias-variance tradeoff). Ablation shows removing the PSW term degrades performance, indicating the estimator contributes to robustness against spurious correlations.",
            "uuid": "e709.0",
            "source_info": {
                "paper_title": "Revisiting Spurious Correlation in Domain Generalization",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "FFT-based separation",
            "name_full": "FFT frequency-domain decomposition for invariant vs spurious feature separation",
            "brief_description": "A practical pipeline that separates an input image into high-frequency (assumed invariant/causal) and low-frequency (assumed spurious/domain-dependent) components using FFT masks, then extracts representation-level c and s via an encoder.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "FFT-based high/low frequency separation with masking and inverse transform",
            "method_description": "Compute the 2D FFT spectrum F(x), apply binary low-pass and high-pass masks (parameterized by filter size S) to obtain F_l and F_h, inverse-FFT to get x_l and x_h, then pass each through encoder g(·) to obtain spurious feature s=g(x_l) and invariant candidate c=g(x_h). These representations are then clustered (K-means) to produce discrete C and S categories for propensity estimation.",
            "environment_name": "Same image-domain benchmarks (ColoredMNIST, PACS, etc.)",
            "environment_description": "Static image datasets; method is applied as preprocessing/representation-splitting step — not an interactive environment.",
            "handles_distractors": true,
            "distractor_handling_technique": "Separates distractor signals by spectral filtering (low-frequency content is treated as spurious/distractor S).",
            "spurious_signal_types": "Low-frequency domain-specific style/background signals (e.g., background color) and other domain-style artifacts.",
            "detection_method": "Spectral decomposition: the low-frequency component is taken as the candidate spurious signal; encoder + clustering used to operationalize detection into discrete S clusters.",
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Contributes to improved propensity estimation and downstream PSW performance; the paper’s ablation shows that removing the pairing/propensity estimation pipeline (which includes FFT separation) reduces OOD accuracy, indicating practical value, but no isolated numeric metric for FFT alone is provided.",
            "performance_without_robustness": null,
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "Frequency decomposition is an effective, practical heuristic to disentangle invariant (high-frequency) and spurious (low-frequency) signals for image-domain OOD tasks; it enables downstream propensity estimation used by PSW.",
            "uuid": "e709.1",
            "source_info": {
                "paper_title": "Revisiting Spurious Correlation in Domain Generalization",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Pairing scheme",
            "name_full": "Pairing augmentation for propensity completeness",
            "brief_description": "A data-augmentation method that simulates additional combinations of invariant and spurious features by mixing low-frequency parts across images to expand the observed support of S and improve propensity score estimation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Pairing (low-frequency interpolation) augmentation",
            "method_description": "For a sample x_i and a randomly sampled x_j, keep x_i's high-frequency part F_h(x_i) but linearly interpolate the low-frequency parts F_l(x_i) and F_l(x_j) with mixing coefficient λ~U(0,δ), then inverse-FFT to obtain a 'simulated' sample whose c is from x_i and s is a mixture; include both original and simulated samples during training to enlarge the available S domain and improve K-means clustering and propensity estimation.",
            "environment_name": "Same static image datasets (ColoredMNIST, PACS, etc.)",
            "environment_description": "Offline augmentation scheme applied to training data to simulate broader spurious variation; not an interactive experiment-selection method.",
            "handles_distractors": true,
            "distractor_handling_technique": "Data augmentation that increases coverage of spurious feature values (S), enabling more accurate estimation of P(C|S).",
            "spurious_signal_types": "Low-frequency background/style distractors and domain-specific spurious attributes.",
            "detection_method": null,
            "downweighting_method": "Indirect: by improving the estimated propensities π(x) used by PSW, it improves downstream downweighting via importance weights.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Including the pairing augmentation (loss L_PS) yields better propensity estimates and improves PSW-regularized OOD performance; ablation removing L_PS lowers performance in reported experiments (see Table 2 in paper).",
            "performance_without_robustness": "Without L_PS, PSW-based methods perform worse (paper reports that removing L_PS reduces accuracy more than removing L_PSW in some settings).",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "Pairing augmentation increases the range of observed S values, stabilizes propensity estimation, and thereby improves the effectiveness of PSW debiasing; it is an inexpensive simulation-based alternative to active experimentation for expanding support.",
            "uuid": "e709.2",
            "source_info": {
                "paper_title": "Revisiting Spurious Correlation in Domain Generalization",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Collider-specific SCM + Backdoor adjustment",
            "name_full": "Collider-specific structural causal model and backdoor-based adjustment for representation learning",
            "brief_description": "A causal-modeling contribution arguing that in representation learning for OOD, many spurious correlations are best modeled as collider structures; this motivates adjusting spurious feature S (via backdoor adjustment/PSW) rather than incorrectly adjusting other covariates.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Collider-specific SCM identification and backdoor adjustment",
            "method_description": "The authors construct an SCM for representation learning that distinguishes fork-specific (latent common cause) and collider-specific spurious correlations; they show collider-specific structure (C ← X → S → E ← Y, conditioning on E opens confounding) is consistent with OOD phenomena in practice, and that correct adjustment for confounding of C→Y requires conditioning/adjusting on S (operationalized via PSW), while improper adjustment of incorrect covariates can introduce bias. The backdoor formula P(Y|do(C)) = sum_s P(Y|C,S)P(S) is the basis for their weighting estimator.",
            "environment_name": "Observational representation-learning setting / image-domain datasets used in domain generalization",
            "environment_description": "Static datasets where representation learning is trained on multiple domains and causal relationships among learned representation components are analyzed; not an interactive experimental platform.",
            "handles_distractors": true,
            "distractor_handling_technique": "Causal graph analysis to identify S as the confounder (detection by reasoning about d-separation), and then adjustment via backdoor formula instantiated with propensity-score weighting.",
            "spurious_signal_types": "Collider-induced confounding, selection bias arising from conditioning on colliders, domain-dependent spurious features that correlate with labels via selection.",
            "detection_method": "Graphical causal analysis (SCM, d-separation) and empirical observation (e.g., ColoredMNIST failures) motivate modeling choice; no automated detector proposed beyond representation separation and clustering.",
            "downweighting_method": "PSW (importance-weighting derived from backdoor adjustment) to simulate intervention on C.",
            "refutation_method": "Theoretical argument and empirical experiments (e.g., biased ColoredMNIST) are used to refute fork-specific latent-common-cause explanations and support collider-specific SCM; demonstration that incorrect covariate adjustment introduces bias.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "The paper argues and empirically supports that collider-specific spurious correlation is the correct representation for many OOD settings in representation learning; thus, appropriate adjustment of spurious S (not arbitrary covariates) is necessary, and PSW instantiated on S can control confounding.",
            "uuid": "e709.3",
            "source_info": {
                "paper_title": "Revisiting Spurious Correlation in Domain Generalization",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "IRM",
            "name_full": "Invariant Risk Minimization",
            "brief_description": "A representative causal-inference-inspired domain generalization method that seeks predictors whose optimality is invariant across environments; cited in related work as background.",
            "citation_title": "Revisiting Spurious Correlation in Domain Generalization",
            "mention_or_use": "mention",
            "method_name": "Invariant Risk Minimization (IRM)",
            "method_description": "A method that formalizes the search for a feature representation and classifier such that the classifier is simultaneously optimal across training environments, aiming to capture invariant causal structure; discussed in related work as a canonical causal DG approach.",
            "environment_name": "N/A (mentioned as a prior method in domain generalization literature)",
            "environment_description": "Referenced generically; IRM has been evaluated on domain generalization benchmarks but is not used or re-implemented in this paper.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Cited as a foundational causal approach to OOD/generalization; paper contrasts its SCM-for-representation-learning perspective and plug-in PSW approach with IRM and notes IRM-related limitations (e.g., failures in nonlinear tasks, optimization difficulties).",
            "uuid": "e709.4",
            "source_info": {
                "paper_title": "Revisiting Spurious Correlation in Domain Generalization",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Invariant risk minimization",
            "rating": 2,
            "sanitized_title": "invariant_risk_minimization"
        },
        {
            "paper_title": "The central role of the propensity score in observational studies for causal effects",
            "rating": 2,
            "sanitized_title": "the_central_role_of_the_propensity_score_in_observational_studies_for_causal_effects"
        },
        {
            "paper_title": "Frequency space domain randomization for domain generalization",
            "rating": 2,
            "sanitized_title": "frequency_space_domain_randomization_for_domain_generalization"
        },
        {
            "paper_title": "Deep frequency filtering for domain generalization",
            "rating": 2,
            "sanitized_title": "deep_frequency_filtering_for_domain_generalization"
        },
        {
            "paper_title": "Causal balancing for domain generalization",
            "rating": 2,
            "sanitized_title": "causal_balancing_for_domain_generalization"
        },
        {
            "paper_title": "Causal inference in statistics: A primer",
            "rating": 1,
            "sanitized_title": "causal_inference_in_statistics_a_primer"
        }
    ],
    "cost": 0.015982,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Revisiting Spurious Correlation in Domain Generalization
17 Jun 2024</p>
<p>Bin Qin 
Institute of Software
Chinese Academy of Sciences
BeijingChina</p>
<p>Jiangmeng Li jiangmeng2019@iscas.ac.cn 
Institute of Software
Chinese Academy of Sciences
BeijingChina</p>
<p>Yi Li 
Institute of Software
Chinese Academy of Sciences
BeijingChina</p>
<p>Xuesong Wu 
Institute of Software
Chinese Academy of Sciences
BeijingChina</p>
<p>Yupeng Wang 
Institute of Software
Chinese Academy of Sciences
BeijingChina</p>
<p>Wenwen Qiang 
Institute of Software
Chinese Academy of Sciences
BeijingChina</p>
<p>Jianwen Cao jianwen@iscas.ac.cn 
Institute of Software
Chinese Academy of Sciences
BeijingChina</p>
<p>Revisiting Spurious Correlation in Domain Generalization
17 Jun 20243F789430EAC59568470CFF090F86E095arXiv:2406.11517v1[cs.LG]
Without loss of generality, existing machine learning techniques may learn spurious correlation dependent on the domain, which exacerbates the generalization of models in out-of-distribution (OOD) scenarios.To address this issue, recent works build a structural causal model (SCM) to describe the causality within data generation process, thereby motivating methods to avoid the learning of spurious correlation by models.However, from the machine learning viewpoint, such a theoretical analysis omits the nuanced difference between the data generation process and representation learning process, resulting in that the causal analysis based on the former cannot well adapt to the latter.To this end, we explore to build a SCM for representation learning process and further conduct a thorough analysis of the mechanisms underlying spurious correlation.We underscore that adjusting erroneous covariates introduces bias, thus necessitating the correct selection of spurious correlation mechanisms based on practical application scenarios.In this regard, we substantiate the correctness of the proposed SCM and further propose to control confounding bias in OOD generalization by introducing a propensity score weighted estimator, which can be integrated into any existing OOD method as a plug-and-play module.The empirical results comprehensively demonstrate the effectiveness of our method on synthetic and large-scale real OOD datasets.</p>
<p>Introduction</p>
<p>Machine learning techniques excel at finding correlations between the input data and the task-related labels in various real-world applications (1; 2).However, conventional approaches perform well towards in-distribution (ID) scenarios, i.e., the target data are i.i.d. with the seen training set data, while falls short of generalizing to out-of-distribution (OOD) scenarios, encompassing the unseen data obeying a distribution that is heterogeneous with the seen training set distribution.To understand the intrinsic mechanism behind such an issue, recent works (3; 4) explore that canonical learning paradigm unavoidably leads the model to learn the spurious correlation between the domain-dependent feature of input data and the task-related label, resulting in that the inconsistency of OOD domains widely degenerates the generalization performance of the model.For instance, typical machine learning models overly rely on spurious correlations (5; 6) between background or minor objects and labels to exploit shortcuts for prediction in ID scenarios, e.g., camels stand on deserts, metal markers appear on specific positions of chest X-ray scans (7; 8).</p>
<p>State-of-the-art methods dedicate to mitigate or eliminate the undesired spurious correlation by exploring the latent causal mechanism (9; 10; 11; 12) of machine learning paradigms and further introducing practical approaches to learn the invariance of causal features in OOD scenarios (13; 14; 15).Concretely, such methods primarily build a structural causal model (SCM) (16; 17) behind the data generation process, which divides the feature contained by the input data into two separated parts: the invariant feature involving the domain-agnostic information and the spurious feature involving domain-dependent information, and the latter incurs in a certain spurious correlation.Inspired by the causal analysis, benchmark methods aim to find invariant features by introducing new loss functions or regularization designs that incorporate specific invariance restrictions across variant domains into the representation learning process (18; 19; 20).However, there exists a focal issue challenging the improvement of such methods stemming from the deficiency of solid and thorough causal analysis.In this regard, for the construction of SCM (10; 21), existing methods unexpectedly omit the nuanced difference between the data generation process and representation learning process, leading to that the causal analysis based on the former cannot well adapt to the latter.For the implementation of SCMbased adjustment (22), the mechanisms underlying spurious correlation require scrutinizing, since adjusting erroneous covariates introduces bias, thus necessitating the correct selection of spurious correlation mechanisms based on practical application scenarios.</p>
<p>To this end, we propose to develop a novel SCM for representation learning process, and further demonstrate that the candidate spurious correlation mechanisms include: 1) fork-specific spurious correlation caused by latent common cause; 2) collider-specific spurious correlation caused by conditional common effect.For the proposed SCM, we substantiate the correctness of collider-specific spurious correlation based on OOD applications.Hence, motivated by the causal analysis, we propose a practical approach to control confounding bias in OOD generalization problems.Concretely, we introduce a propensity score weighted (PSW) estimator to rescale the observed distribution, simulating sampling from the post-intervention distribution without extra experiments.The PSW regularization term can be integrated into any existing OOD method as a plug-and-play module, and our experimental results on synthetic and large-scale real datasets empirically demonstrate that the PSW regularizer can enhance the performance of various state-of-the-art OOD methods.</p>
<p>Our contributions are as follows: 1) We propose a general SCM demonstrating the representation learning process for the domain generalization problem; 2) We provide a thorough analysis upon the consistency and inconsistency between spurious correlation mechanisms, and substantiate the correctness of collider-specific spurious correlation for OOD-oriented SCM; 3) We rigorously demonstrate that by expanding the set of available values for adjusted variables, it is guaranteed to identify the strength of the selection propensity of latent spurious features towards invariant features.This allows us to assign a propensity score weight to each observed sample, thereby reweighting the observational distribution; 4) The well-conducted empirical validation proves that our method can widely obtain consistent performance gains compared to baselines on sufficient benchmarks, encompassing PACS (23), OfficeHome (24), and etc.</p>
<p>Spurious Correlation on OOD Generalization</p>
<p>Problem Setting</p>
<p>Assuming that a domain set, including different domains, is denoted as
D = {D v } m v=1 , where D v = {(x v i , y v i )} Nv i=1
represents a domain indexed by v ∈ V , containing the collected data and corresponding labels.N v is the number of samples in domain D v .Let X v = {x v i } be the non-empty input space, and Y v = {y v i } be the true labels, where
x v i ∈ X v ⊂ R d ,andy v i ∈ Y v ⊂ N. We assume that the samples in D v follow the distribution P v (X v , Y v ), where generally P v (X v , Y v ) ≠ P v ′ (X v ′ , Y v ′ ),min f E (x,y)∈Dtest [ℓ(f (x), y)].
(1)</p>
<p>Learning Representation Process</p>
<p>We formally model the OOD generalization from the perspective of representation learning.ground truth, respectively.We depict the SCM graph in Figure 1(a) based on the causal relationships between these variables.Each set of parent-child nodes in the directed acyclic graph (DAG) G represents a deterministic function
x i = f i (pa i , ϵ i )
, where pa i is the parent node of x i in G, and ϵ i is a jointly independent, arbitrarily distributed random disturbance.In Appendix A, we provide detailed causal background knowledge (25).</p>
<p>We take the ColoredMNIST (26) dataset as an example, and provide a detailed explanation:</p>
<ol>
<li>C ← X → S.This fork structure (27) indicates that invariant features C (digit) and spurious features S (color) are learned from the data X (image).The variables C and S can be determined by functions
C = f C (X, ϵ C ) and S = f S (X, ϵ S ), respectively. 2. C → Y . The invariant feature C is the only explicit parent node of the ground truth label Y , implying that we can determine Y = f Y (C, ϵ Y ) through C. 3. S − Y .
The dash indicates a correlation between variables, without a clear causation determination, i.e., which variable is the parent is undetermined.This is because the causal relationship between spurious features and ground truth labels cannot be definitively established (11): Y → S possibly holds, for instance (28), if we stipulate that small digits (less than or equal to 4) are associated with red color and large digits (greater than or equal to 5) with green color; S → Y possibly holds, as humans might use background color as an aid in determining labels when digits are too blurry to discern (13), or random colors might be added to digit images.The mixing of data from different domains obscures the causal relationship between S and Y , leading to a spurious correlation between S and Y .Thus, we can derive the following theoretical definition: Definition 1. (Spurious correlation (25)) Two variables, X and Y , exhibit spurious correlation if they are dependent under certain conditions, and there exist two other variables (Z 1 and Z 2 ) and two scenarios (S 1 and S 2 ) such that:</li>
<li>Given S 1 , Z 1 is dependent of X (Z 1 ̸ X | S 1 ), and Z 1 is independent of Y (Z 1 Y | S 1 ). 2. Given S 2 , Z 2 is dependent of Y (Z 2 ̸ Y | S 2 ), and Z 2 is independent of X (Z 2 X | S 2 ).
For ease of understanding, we demonstrate the explanation of Definition 1 by introducing Figure 1(a).Concretely, utilizing condition 1, given S 1 = C and Z 1 = X, X is dependent of S but independent of Y , thus ruling out S → Y .Using condition 2, given S 2 = X and Z 2 = C, C is dependent of Y but independent of S, thus ruling out Y → S, such that S and Y exhibits a spurious correlation.</li>
</ol>
<p>Fork-Specific Spurious Correlation.We aim to learn domain-invariant representations, denoted as C, which are not confounded by spurious factors when identifying the causal effect C → Y .Identification of the direct causal effect C → Y requires inference within a DAG, where the direction of arrows between variables must be explicitly known.However, the presence of spurious correlation S − Y in Figure 1(a) prevents us from determining the direction of arrows.To this end, we propose to explore the intrinsic causal mechanism behind the spurious correlation as follows: Proposition 1. (Latent common cause ( 29)) In causal model M , the spurious correlation between variables S and Y : S − Y represents a latent common cause S ← L → Y .</p>
<p>Proposition 1 leads us to the DAG depicted in Figure 1(b), eliminating S − Y , thus enabling the analysis of backdoor paths in the causal graph.For ease of understanding, we construct a biased ColoredMNIST example to demonstrate the fork-specific spurious correlation caused by latent common cause.L represents a domain-specific rule that specifies the combination of a particular color and a specific label.Under this setting, we observe that the correlation between S and Y varies with different values of L = l.L = 0, 1, 2, 3, respectively, yielding combinations (Y = 0, S = Red), (Y = 0, S = Green), (Y = 1, S = Red), (Y = 1, S = Green).However, the dataset X is biased, resulting in a scenario where 90% of digit 0 is red and 10% is green, while 90% of digit 1 is green and 10% is red.In this case, the bias degree is 0.9.</p>
<p>Theoretical Analysis of Fork-Specific Spurious Correlation.To determine the correctness of the fork-specific spurious correlation in OOD generalization, we impose the following causal analysis.Definition 2. (Non-confounding (30; 31)) Let T be the set of all variables unaffected by X, composed of two disjoint subsets T 1 and T 2 .X and Y are non-confounding if and only if:
1. T 1 is independent of X: P(X) = P(X | T 1 ) 2. Given X and T 1 , T 2 is independent of Y : P(Y | T 1 , X) = P(Y | T 1 , T 2 , X)
By Definition 2, we know that in Figure 1(b), when T 1 = L and T 2 = {X, S}, C is independent of L, and given {C, L}, {X, S} is independent of Y .Therefore, we can conclude that C → Y is non-confounding in the fork-specific spurious correlation.Details of the proof are provided in Appendix B.1.</p>
<p>Theorem 1. (Non-confounding can achieve OOD generalization) For each domain
D v ∈ D, the data (X v , Y v ) follows the distribution P v (X, Y ). If C → Y v satisfies the assumption of non- confounding, then the invariant features C = Φ * (X v ), learned from X v , satisfy the property that E(Y v | Φ * (X v )) is consistent across all domains D v ∈ D.
An intuitive explanation is that in identifying C → Y , without interference from confounder, it is akin to a randomized controlled experiment.All factors affecting the variation in Y , except for C, are randomly changing, satisfying the definition of exogenous variables (27).Therefore, the invariant features C, learned from dataset X, are not influenced by the spurious features S across different domains.See Appendix B.2 for detailed proof.Theoretical Analysis of Collider-Specific Spurious Correlation.We first analyze the confounding of C → Y in collider-specific spurious correlation.Consider its backdoor path:
C ← X → S → E ← Y . Since E is a collider, conditioning on E opens the backdoor path from C to Y , indicating that C → Y is confounded.
According to Theorem 1, the model cannot address the OOD generalization problem.This is also consistent with the empirical results of our experiments on biased ColoredMNIST.</p>
<p>To correctly identify the causal effect of C → Y , we need to perform the adjustment on confounder using the backdoor criterion (32).Specifically, conditioning on S can block the backdoor path from C to Y , and thus we perform the adjustment on the spurious feature S. It is worth emphasizing the theoretical contribution of determining the collider-specific spurious correlation, since adjusting incorrect covariates may lead to biased results (33; 34; 35).For instance, in the model depicted in Figure 1(b) under the assumption of a latent common cause, if we perform the adjustment on the covariate S, conditioning on S will open the path C ← X → S ← L → Y .This path is not a causal path from C to Y , since it is a spurious path.In Appendix C, we provide a detailed explanation of the issues that arise from incorrectly adjusting covariates.Therefore, we need to carefully consider the correct modeling for the correlation between variables.Accordingly, we explore to perform the adjustment on S to control confounding bias in OOD generalization problems.</p>
<p>Controlling Confounding Bias on OOD Generalization</p>
<p>In this section, we firstly define the empirical risk minimization (ERM) model based on propensity scores for the OOD generalization problem.Secondly, we employ Fast Fourier Transform (FFT) (36) and K-means clustering to estimate the propensity scores.We apply the pairing scheme to expand the available samples, thereby obtaining a more accurate estimation of the propensity scores.Finally, our proposed method can be integrated into any existing OOD generalization model.</p>
<p>Propensity-Scored ERM for OOD Generalization</p>
<p>Based on the theoretical analysis above, we identified the spurious feature S as the confounder in C → Y .We employ backdoor adjustment (32) to eliminate the influence of the confounder S in order to maximize the probability of the invariant feature C = c with respect to the label Y = y:
P (Y = y | do(C = c)) = ∑ S=s P(Y = y | C = c, S = s)P(S = s).(2)
Multiply the expression inside the summation by the propensity score (37) P(C = c | S = s), and then divide by this score to obtain:
P (Y = y | do(C = c)) = ∑ S=s P(Y = y | C = c, S = s)P(S = s)P(C = c | S = s) P(C = c | S = s) .(3)
In fact, the numerator represents the distribution of (Y, C, S) before intervention, and the equation can be written as:
P (Y = y | do(C = c) = ∑ S=s P(Y = y, C = c, S = s) P(C = c | S = s) . (4)
The
R P SW (f |π) = E (x,y)∈D v [ ℓ(f (x), y) π (x) ].(5)
Definition 4. (Propensity-scored ERM for OOD generalization) Let f ∈ H, where H ⊂ {f ∶ X → N} is the hypothesis space of the invariant function f .Let ℓ ∶ Y v × N → R + be the loss function.Then, given a specific domain dataset D v , we compute its empirical risk:
RP SW (f |π) = 1 N v ∑ (x i ,yi)∈D v [ ℓ(f (x i ), y i ) π (x i ) ].(6)
Therefore, given the propensity score π(x i ), we can learn a cross-domain invariant predictor from domain-specific data by minimizing the empirical risk:
f ← arg min f ∈H RP SW (f |π).(7)</p>
<p>Calculation of Propensity Scores</p>
<p>Separate Invariant Features and Spurious Features via FFT.The literature (38) reports that domain-specific features are mainly contained in the extremely high-frequency and low-frequency signals of images, with the high-frequency signals containing more semantic information.In the domain generalization literature, many FFT-based techniques (39; 40) have been proposed to separate causal components from domain-specific information.We posit that the invariant feature C can be represented by the high-frequency components of images, while the spurious feature S is represented by their low-frequency components.</p>
<p>We adopt FFT to extract the spectrum F (x i ) of the input image x i ∈ R H×W .Subsequently, we separate the low-frequency part F l (x i ) and high-frequency part F h (x i ) in the frequency domain using two binary mask matrices m ∈ {0, 1} H×W , resulting in corresponding high-pass filtering M S h and low-pass filtering M S l , where the filter size is denoted by S:
M S l (F (x)) = m ⊙ F (x), where m i,j = { 1, if min(|i − H 2 |, |j − W 2 |) ⩽ S 2 0, otherwise(8)M S h (F (x)) = m ⊙ F (x), where m i,j = { 0, if min(|i − H 2 |, |j − W 2 |) ⩽ min(H,W )−S 2 1, otherwise .(9)
Here, ⊙ denotes element-wise multiplication, and m i,j denotes the value of m at position (i, j).Then, we have F l (x i ) = M S l (F (x)) and F h (x i ) = M S h (F (x)).We perform inverse Fourier transforms on F l (x i ) and F h (x i ) separately to obtain the low-frequency image
x l i = F −1 ○ F l (x i )
and the high-frequency image x h i = F −1 ○ F h (x i ).Then, we use the encoder g(⋅) of the invariant function f (⋅) to extract invariant features and spurious features.Therefore, we obtain the invariant feature c i = g(x h i ) and the spurious feature s i = g(x l i ) of the image x i , denoted as x i ∼ (c i , s i ).The propensity score P(C = c i | S = s i ) for an individual sample point x i is difficult to compute.Hence, we first consider a mechanism for designing propensity scores for the population.Initially, we employ the K-means algorithm (41) to cluster the feature sets {c i } Nv i=1 and {s i } Nv i=1 .The categories of the invariant feature C are classified based on the number of categories m of the label Y ∈ {1, 2, ..., m}.As for the spurious feature S, we use a hyperparameter n to adjust its categories.Let the set of clusters for the invariant feature C be denoted as {C (1) , C (2) , ..., C (m) }, where c i ∈ C (k) .Similarly, for the spurious feature S, the set of clusters after clustering is denoted as {S (1) , S (2) , ..., S (n) }, where s i ∈ S (l) .Then, the propensity score for the sample point x i corresponds to the population is:
π (x i ) = P(C = C (k) | S = S (l) ). (10)
Pairing Scheme for Improving Propensity Score Estimation.To improve the accuracy of estimating the propensity score π (x i ), we aim to enhance the encoder g(⋅)'s ability to identify potential spurious features.Therefore, we augment the samples by randomly pairing of C and S to increase the completeness of the available value set of data.Formally, given an original image x i and an image x j randomly sampled from any source domains, their spectra in the frequency domain are denoted as F (x i ) = F l (x i ) + F h (x i ) and F (x j ) = F l (x j ) + F h (x j ) respectively.We perform linear interpolation on the low-frequency parts of x i and x j , while retaining the high-frequency parts of the original image x i to obtain the spectrum of the "simulated sample" xi :
F (x i ) = F h (x i ) + (1 − λ)F l (x i ) + λF l (x j )(11)
where λ ∼ U (0, δ), with δ controlling the mixing ratio.Applying the inverse Fourier transform to F (x i ), we obtain the "simulated sample
" xi = F −1 ○ F (x i ). For each sample x v i in the training dataset D v = {(x v i , y v i )} Nv i=1 , we add its corresponding xv i to obtain Dv = {(x v i , y v i ) , (x v i , y v i )} Nv i=1
. By training the invariant function f (⋅) on Dv , we can update the parameters of the encoder g(⋅), thereby more accurately extracting c i and s i :
L P S = 1 2N v ∑ (x i ,yi)∈ Dv ℓ(f (x i ), y i ). (12)
Learning Objectives.For any existing OOD method, we assume that the learned invariant function is denoted as f (⋅) and the encoder for the original images x i is g(⋅).Utilizing the PSW estimator, we obtain the loss term L P SW (D v ) in the original training domain D v .L P S ( Dv ) is trained on the augmented samples Dv for a more precise estimation of the propensity score π (x).L(D v ) preserves the training loss of the original method.The final learning objective is defined as:
L our = L(D v ) + αL P SW (D v ) + βL P S ( Dv ). (13)</p>
<p>Theoretical Analysis for PSW Estimator</p>
<p>We analyze the Error Bound of the PSW estimator on the OOD generalization through Corollary 1, quantifying the gap between the true risk R( f ) and the empirical risk RP SW ( f |π) caused by the propensity score π(x).The detailed proof is provided in Appendix D, following the approach outlined in (42).Corollary 1. (Propensity-scored ERM for OOD generalization error bound) For any finite hypothesis space H = { f1 , ..., f|H| } of invariant functions f , and a loss 0 ≤ ℓ( f (x), y) ≤ Ω, the true risk R( f ) of the f that minimizes empirical risk in hypothesis space H, has an upper bound with probability 1 − δ on a specific domain D v :
R( f ) ≤ RP SW ( f |π) + Ω N v √ log(2 |H| /δ) 2 Nv ∑ i=1 1 π 2 (x i ) .(14)</p>
<p>Experiments</p>
<p>Datasets and baselines.To evaluate the performance of our proposed method, we select six canonical domain generalization benchmarks, which include ColoredMNIST (28), RotatedMNIST (62), VLCS (63), PACS (23), OfficeHome (24), and TerraIncognita (7).For a comprehensive comparison, 21 benchmark domain generalization methods are chosen as our baselines.It is noteworthy that Balancing ( 61) is the prior state-of-the-art method, which proposes a balanced mini-batch sampling method.To regulate the influence exerted by the foundational algorithms, a uniform set of hyperparameters is employed across both the baselines and our proposed methods.We utilize train domain validation for model selection due to its practical applicability as a validation technique.A comprehensive exposition regarding the datasets is provided in the Appendix E.</p>
<p>Domian generalization results</p>
<p>. Functioning as a plug-and-play module, our method is applied to two representative base algorithms: BalancingERM and BalancingCORAL.BalancingERM and BalancingCORAL change the sampling strategy of ERM and CORAL without altering the loss function of base models.As shown in Table 1, our method can significantly improve the domain generalization performance of benchmark methods, e.g., our method improves the average performance of BalancingERM by 1.1% and the average performance of CORAL by 0.8%.Furthermore, we achieve the sota domain generalization performance on ColoredMNIST, PACS, and OfficeHome.</p>
<p>The observations demonstrate the superiority of proposed method.Meanwhile, the results showcase that the adjustment of variable S can improve the performance of domain generalization, which con- 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 Hyper-parameter research.There are two hyper-parameters in our method, i.e., α and β. α, β are searched in {1, 0.1, 0.01} and {1, 0.1, 0.01, 0.001}, respectively.We determine their specific values through experimental results.In Figure 4, we depict the results on ColoredMNIST, PACS, and VLCS.The lighter the color, the higher the classification performance.As shown in Figure 4, the best combination of α and β varies with the baselines and datasets, e.g., BalanceERM+Ours achieves its best performance on ColoredMNIST with {α = 0.1, β = 0.1} and on PACS with {α = 0.01, β = 0.001}.Therefore, a detailed assignment of hyper-parameters can help to improve the performance of our model.</p>
<p>Case study.Classifying the background semantics is a critical step in computing the loss L P SW , and classification accuracy determines the estimation precision of the propensity scores.We conduct a case study on a batch of randomly selected samples from the ColoredMNIST dataset to assess the precision of calculating propensity scores.As illustrated in Figure 5, our method not only delineates the background semantics clearly but also classifies them accurately.In the ColoredMNIST dataset, where backgrounds are either red or green, therefore the predicted classification labels are 0 and 1.The results of case study demonstrate that our method can accurately estimate the propensity scores.</p>
<p>Related Work</p>
<p>Causal inference-based methods (64; 65; 66; 67; 68; 15) have made significant strides in the field of domain generalization, offering a novel perspective on addressing the out-of-distribution (OOD) problem.These approaches construct appropriate causal models for the data generation process (26; 69; 13; 70; 71; 10), severing the spurious correlations between causal and spurious features to capture stable causal representations invariant across domains or environments, leveraging information from multiple environments.Among these works, the most representative method is Invariant Risk Minimization (IRM), which has strong theoretical guarantees in linear systems.Building upon IRM, numerous variants have emerged (72; 18; 19; 73; 74; 75; 76), aiming to address some of IRM's challenges, such as its failure in nonlinear tasks (69), the requirement for extensive domain information (14), and optimization difficulties in deep neural networks (77; 78).Beyond analyzing the fundamental causal mechanisms of OOD data generation, there are also causal methods involving interventions (22; 79; 67; 80).These methods include robust feature learning through data augmentation by intervening on spurious features (67) or achieving interventional distributions through frontdoor/backdoor adjustments (22; 80; 79).</p>
<p>Conclusions and Limitations</p>
<p>In this paper, we model the phenomenon of spurious correlations in domain generalization from a novel perspective within the representation learning process.We analyze the underlying causal mechanisms that generate spurious correlations and identify two types: fork-specific and colliderspecific spurious correlations.We clarify that the non-confounding between invariant features and true labels is key to addressing OOD problems.Based on this premise, we demonstrate that collider-specific spurious correlation is the correct OOD-oriented SCM.Therefore, motivated by the causal analysis, we control confounding bias by adjusting spurious features, introducing a propensity score weighted estimator to ensure that the causal effect of invariant features on true labels is non-confounding.However, we cannot entirely eliminate the confounding bias introduced by spurious features, as this requires perfect propensity score calculation.Therefore, achieving accurate propensity score estimation necessitates a bias-variance trade-off, where we aim to avoid excessively small propensity scores to reduce variance while sacrificing some accuracy.</p>
<p>A Causal Background Knowledge</p>
<p>Structural Causal Models and Intervention.A structural causal model (SCM) (25) is a triple M = ⟨X, U, F ⟩, where U is known as the exogenous variable, determined by external factors of the model.X = {X 1 , X 2 , ..., X n } is referred to as the endogenous variable, whose changes are determined by the functions F = {f 1 , f 2 , ..., f n }.Each f i represents {f i ∶ U i ∪ P A i → X i }, where U i ⊆ U , P A i ⊆ X/X i , satisfying:
x i = f i (pa i , u i ) , i = 1, 2, ..., n.(15)
Each causal model M corresponds to a directed acyclic graph (DAG) G, where each node corresponds to a variable in X ∪ U , and directed edges point from U i ∪ P A i to X i .</p>
<p>An intervention refers to forcing a variable X i to take a fixed value x i .This equivalently removes X i from the influence of its original functional mechanism x i = f i (pa i , u i ) and replaces it with a constant function X i = x i .Formally, we denote the intervention as do(X i = x i ), or simply do(x i ).</p>
<p>After the intervention on X i , the corresponding causal graph G xi is obtained by removing all arrows pointing to X i in G to represent the post-intervention world.</p>
<p>Path and d-separation.We summarize two classic definitions (27) to help us determine the independence between variables in the SCM graph.They enable us to avoid cumbersome probability calculations and instead obtain independence between variables directly from the graph.If Z blocks every path between two nodes X and Y , then X and Y are d-separated, conditional on Z, and thus are independent conditional on Z, denoted as X Y | Z.</p>
<p>Backdoor and Backdoor Adjustment.</p>
<p>Definition 7. (Backdoor) In a DAG G, a set of variables Z satisfies the backdoor criterion for an ordered pair of variables (X i , X j ) if:</p>
<p>1.No node in Z is a descendant of X i .</p>
<ol>
<li>Z blocks all paths between X i and X j that are directed into X i .</li>
</ol>
<p>Similarly, if X and Y are two disjoint subsets of nodes in G, then Z is said to satisfy the backdoor criterion for (X, Y ) if Z satisfies the backdoor criterion for any pair of variables (X i , X j ), where X i ∈ X and X j ∈ Y .</p>
<p>Definition 8. (Backdoor adjustment) If a set of variables Z satisfies the backdoor criterion for (X, Y ), then the causal effect of X on Y is identifiable and can be given by the following formula:
P(Y = y | do(X = x)) = ∑ z P(Y = y | X = x, Z = z)P(Z = z).(16)
B Theoretical Analysis of Causal Models Since our definition of non-confounding is a mathematically formalized definition from the perspective of statistical associations, we can determine whether the required independencies in the two conditions are satisfied through independence tests, even without using the d-separation criterion mentioned above.</p>
<p>B.2 Non-Confounding Can Achieve OOD Generalization</p>
<p>We provide a mathematically formalized causal definition of non-confounding, which addresses the limitations of using statistical methods to test for confounding.</p>
<p>The meaning of the probability P(y | do(c)) can be explained by structural equations.This is equivalent to removing C from its original functional mechanism C = f C (pa C , ϵ C ), and modifying this function to a constant function C = c.That is, any variables influencing the value of C become independent of C in the intervened world.This intervened world can be understood as a randomized controlled experiment with respect to C, and we denote the probability in this world as the manipulated probability P m .</p>
<p>In different domains D v1 and D v2 , domain-specific spurious features S are independent of C, i.e., P m (C) = P m (C | S v1 ) = P m (C | S v2 ).For example, in the case of fork-specific spurious correlation, the intervened world is represented as in Figure 6(b), where we can see that S and C are d-separated.Thus, E (C,S)∼Pm (Y v | Φ * (X v )) is invariant across domains.From the Eq.( 17), we have
P(y | do(c)) = P m (Y | C) = P(Y | C). Therefore, we can conclude that E (C,S)∼P (Y v | Φ * (X v )
) is also invariant across domains.</p>
<p>C Discussion on Adjusting Erroneous Covariates</p>
<p>In this section, we discuss the distinction between statistical correlation and causal confounding: the correlation between covariate Z and variables C and Y does not imply confounding between C and Y .Incorrect adjustment for covariate Z may result in bias.Therefore, when analyzing the</p>
<p>Therefore, without clearly understanding the type of correlation denoted by the symbol −, one should not arbitrarily use the involved covariates for adjustment.Instead, we perform the adjustment on other variables on the path to control for confounding bias.For instance, in Figures 7(b) and 7(c), adjusting T yields the correct result:   ColoredMNIST is a modified version of the MNIST dataset designed for handwritten digit classification, where each domain within the set [0.1, 0.3, 0.9] features digits spuriously correlated with color.This dataset includes 70,000 samples with dimensions (2, 28, 28) across two classes, distinguishing whether digits are less than 5, with 25% noise incorporated.RotatedMNIST, another MNIST variant, comprises domains with digits rotated by α degrees, for α ∈ {0, 15, 30, 45, 60, 75}.It contains 70,000 instances of dimensions (1,28,28) classified into 10 categories based on the digit.The PACS dataset encompasses four domains-art, cartoons, photos, and sketches-with 9,991 instances of dimensions (3,224,224)
∑ t P(Y = y | C = c, T = t)P (T = t) = P (Y = y | do(c)).(19)</p>
<p>E.2 Detailed results</p>
<p>All experiments were conducted on Nvidia A100 and Nvidia A800.Here we report detailed results on each domain of all six datasets.We also use the training domain validation for model selection.</p>
<p>indicating that the elements in D are out-of-distribution (OOD).Given s training domains D train = {D v ∈ D | v = 1, 2, ..., s}, we aim to minimize prediction loss on unseen test domains D test = D/D train by learning an invariant function f ∶ X → Y on D train as follows:</p>
<p>Figure 1 :
1
Figure 1: The SCM graph of representation learning for OOD.In Figure (a), the dash between S and Y represents the complex spurious correlation, where the direction of causal arrows cannot be determined.Figure (b) illustrates fork-specific spurious correlation, replacing S −Y with S ← L → Y , which is widely accepted as the latent common cause proposition in causal inference.</p>
<p>Figure 2 :
2
Figure2: On ColoredMNIST dataset, when the distribution of the training and test sets is consistent (i.e., no bias), ERM achieves an accuracy rate of over 95%, even the labels are associated with colors to varying degrees.However, when the dataset is biased, associating labels with colors leads to a sharp decline in the accuracy of ERM.However, experiments conducted on biased ColoredMNIST reveal that when the bias level of the training set is 0.9, and the test set remains unbiased, the model fails to address the OOD generalization problem.Detailed experimental results are shown in Figure2.This contradicts the property of non-confounding in the forkspecific spurious correlation (Figure1(b)).This phenomenon prompts us to question whether the proposition that spurious correlation is caused by latent common cause in the field of causal inference is erroneous.In the next section, we propose a new model for spurious correlation: colliderspecific spurious correlation, to model the general OOD generalization.</p>
<p>Figure 3 :
3
Figure 3: The SCM graph of collider-specific spurious correlation model, with grey nodes indicating conditioning on that variable.Figure (b) is the extracted confounding path that introduces bias in estimating C → Y .</p>
<p>probability of each (Y = y, C = c, S = s) in the overall data is amplified by the factor 1/P(C = c | S = s).This motivates us to derive a straightforward method to estimate P (Y = y | do(C = c) when using finite samples.By weighting each available sample with the factor 1/P(C = c | S = s), we achieve estimation of causal effects.Following the derivation above, we propose the Propensity Score Weighted (PSW) estimator.Definition 3. (PSW estimator) The Propensity Score Weighted (PSW) estimator utilizes the propensity scores π(x v i ) = P(C = c i | S = s i ) corresponding to the samples x v i in D v to estimate the expected ℓ-risk of the invariant function f in a specific domain:</p>
<p>Figure 4 :
4
Figure 4: The results of hyper-parameters.</p>
<p>Figure 5 :
5
Figure 5: The results of case study on a batch of randomly selected samples.tradicts the fork-specific spurious correlation in Figure 1 (b), thereby further verifying the correctness of collider-specific spurious correlation in Figure 3(b).Ablation study.We propose two loss functions for domain generalization, i.e., L P SW and L P S .We conduct ablation study to demonstrate the effectiveness of each proposed technique.Concretely, we trained two variants for both BalancingERM+Ours and BalancingCORAL+Ours, i.e., BalancingERM+Ours w/o L P SW , BalancingERM+Ours w/o L P S , BalancingCORAL+Ours w/o L P SW , and BalancingCORAL+Ours w/o L P S .The results are depicted in Table2.We can observe that regardless of which loss function is removed, the performance of the model decreases, thereby demonstrating the effectiveness of each proposed technique.Furthermore, BalancingERM+Ours w/o L P S (BalancingCORAL+Ours w/o L P S ) typically outperforms BalancingERM+Ours w/o L P SW (BalancingCORAL+Ours w/o L P SW ), indicating that debiasing methods based on propensity scores are benifical for enhancing the model's generalizability.</p>
<p>Definition 5 .
5
(Path)  In the SCM graph, the paths from variable X to Y include three types of structures: 1) Chain Structure:A → B → C or A ← B ← C, 2) Fork Structure: A ← B → C,and 3) Collider Structure: A → B ← C. Definition 6. (d-separation) A path p is blocked by a set of nodes Z if and only if: 1. p contains a chain of nodes A → B → C or a fork A ← B → C such that the middle node B is in Z (i.e., B is conditioned on), or 2. p contains a collider A → B ← C such that the collider node B is not in Z, and no descendant of B is in Z.</p>
<p>B. 1 Figure 6 :
16
Figure 6: After intervening on variable C, remove all arrows pointing to C. In the post-intervention world, variables follow the manipulated distribution P m , meaning that C and S are d-separated.</p>
<p>Definition 9 .
9
(Non-confounding: causal definition) Let P(y | do(c)) denote the probability of the response event Y = y under the intervention C = c.We say that C and Y are non-confounding if and only if: P(y | do(c)) = P(y | c).</p>
<p>Figure 7 :
7
Figure 7: Z and C form a spurious correlation Z − C as shown in Figure (a).Figures (b) and (c) model this correlation according to fork-specific spurious correlation and collider-specific spurious correlation, respectively.Although the variable correlations in (b) and (c) are the same, the confounding between C and Y is completely different.Figure (b) is non-confounding, whereas Figure (c) is confounding.</p>
<p>Figure 8 :
8
Figure 8: Y and Z form a spurious correlation Y − Z as shown in Figure (a).Figures (b) and (c) model this correlation according to fork-specific spurious correlation and collider-specific spurious correlation, respectively.Although the variable correlations in (b) and (c) are the same, the confounding between C and Y is completely different.Figure (b) is non-confounding, whereas Figure (c) is confounding.For the case of Y − Z, we model it according to fork-specific spurious correlation and collider-specific spurious correlation, resulting in Figures 8(b) and 8(c), respectively.In Figures 8(b), the backdoor path for C → Y is C ← T → Z ← L → Y .This path is blocked by the covariate Z, so C and Y are non-confounding.In Figure 8(c), conditioning on E opens the path C ← T → Z → E ← Y , resulting in confounding between C and Y .</p>
<p>spread across seven classes denoting the type of object depicted.VLCS features photographic domains including Caltech101, LabelMe, SUN09, and VOC2007, comprising 10,729 samples with dimensions (3, 224, 224) distributed among five classes indicating the primary object in the photograph.OfficeHome includes four domains: art, clipart, product, and real, containing 15,588 samples with dimensions (3, 224, 224) categorized into 65 classes based on the object type.TerraIncognita, designed for wildlife research, consists of 24,788 photographs taken by camera traps at locations L100, L38, L43, and L46, with dimensions (3, 224, 224) and 10 classes identifying the animal type.</p>
<p>Table 1 :
1
The domain generalization accuracy beyond the training domain are evaluated across six distinct datasets.Results are presented as the average accuracy across all test environments, with the standard deviation determined over three independent runs.The validation approach employed adheres to the training domain validation protocol commonly utilized in OOD field.
AlgorithmColoredMNIST RotatedMNISTVLCSPACSOfficeHome TerraIncognita AvgERM (2) IRM (26) GroupDRO (43) Mixup (44) MLDG (45) CORAL (46) MMD (47) DANN (48) CDANN (49) MTL (50) SagNet (51) ARM (52) VREx (53) RSC (54) Fish (55) Fishr (56) AND-mask (57) SAND-mask (58) SelfReg (59) 1 ColoredMNIST CausIRL High 51.5 ± 0.1 98.0 ± 0.0 77.5 ± 0.4 85.5 ± 0.2 66.5 ± 0.3 70.9 46.1 ± 1.8 52.0 ± 0.1 97.7 ± 0.1 78.5 ± 0.5 83.5 ± 0.8 64.3 ± 2.2 70.6 47.6 ± 0.8 52.1 ± 0.0 98.0 ± 0.0 76.7 ± 0.6 84.4 ± 0.8 66.0 ± 0.7 70.1 43.2 ± 1.1 52.1 ± 0.2 98.0 ± 0.1 77.4 ± 0.6 84.6 ± 0.6 68.1 ± 0.3 71.4 47.9 ± 0.8 51.5 ± 0.1 97.9 ± 0.0 77.2 ± 0.4 84.9 ± 1.0 66.8 ± 0.6 71.0 47.7 ± 0.9 51.5 ± 0.1 98.0 ± 0.1 78.8 ± 0.6 86.2 ± 0.3 68.7 ± 0.3 71.8 47.6 ± 1.0 51.5 ± 0.2 97.9 ± 0.0 77.5 ± 0.9 84.6 ± 0.5 66.3 ± 0.1 70.0 42.2 ± 1.6 51.5 ± 0.3 97.8 ± 0.1 78.6 ± 0.4 83.6 ± 0.4 65.9 ± 0.6 70.7 46.7 ± 0.5 51.7 ± 0.1 97.9 ± 0.1 77.5 ± 0.1 82.6 ± 0.9 65.8 ± 1.3 70.2 45.8 ± 1.6 51.4 ± 0.1 97.9 ± 0.0 77.2 ± 0.4 84.6 ± 0.5 66.4 ± 0.5 70.5 45.6 ± 1.2 51.7 ± 0.0 98.0 ± 0.0 77.8 ± 0.5 86.3 ± 0.2 68.1 ± 0.1 71.8 48.6 ± 1.0 56.2 ± 0.2 98.2 ± 0.1 77.6 ± 0.3 85.1 ± 0.4 64.8 ± 0.3 71.2 45.5 ± 0.3 51.8 ± 0.1 97.9 ± 0.1 78.3 ± 0.2 84.9 ± 0.6 66.4 ± 0.6 71.0 46.4 ± 0.6 51.7 ± 0.2 97.6 ± 0.1 77.1 ± 0.5 85.2 ± 0.9 65.5 ± 0.9 70.6 46.6 ± 1.0 51.6 ± 0.1 98.0 ± 0.0 77.8 ± 0.3 85.5 ± 0.3 68.6 ± 0.4 71.1 45.1 ± 1.3 52.0 ± 0.2 97.8 ± 0.0 77.8 ± 0.1 85.5 ± 0.4 67.8 ± 0.1 71.4 47.4 ± 1.6 51.3 ± 0.2 97.6 ± 0.1 78.1 ± 0.9 84.4 ± 0.9 65.6 ± 0.4 70.3 44.6 ± 0.3 51.8 ± 0.2 97.4 ± 0.1 77.4 ± 0.2 84.6 ± 0.9 65.8 ± 0.4 70.0 42.9 ± 1.7 52.1 ± 0.2 98.0 ± 0.1 77.8 ± 0.9 85.6 ± 0.4 67.9 ± 0.7 71.4 47.0 ± 0.3 PACS VLCS ColoredMNIST PACS VLCS RMNIST OfficeHome TerraInc RMNIST OfficeHome TerraInc0.1β0.011e-310.10.01BalanceERM+OursαBalanceCORAL+OursLow
CORAL (60) 51.7 ± 0.1 97.9 ± 0.1 77.5 ± 0.6 85.8 ± 0.1 68.6 ± 0.3 47.3 ± 0.8 71.5 CausIRL MMD (60) 51.6 ± 0.1 97.9 ± 0.0 77.6 ± 0.4 84.0 ± 0.8 65.7 ± 0.6 46.3 ± 0.9 70.5 BalancingERM (61) 60.1 ± 1.0 97.7 ± 0.0 76.1 ± 0.3 85.2 ± 0.4 67.1 ± 0.4 48.0 ± 1.7 72.3 BalancingCORAL (61) 66.6 ± 1.2 97.7 ± 0.1 76.4 ± 0.5 86.7 ± 0.1 69.6 ± 0.2 47.0 ± 1.2 74.0 BalancingERM+Ours 62.5 ± 2.5 98.1 ± 0.2 77.1 ± 2.2 86.3 ± 1.2 68.2 ± 0.8 48.2 ± 0.6 73.4 BalancingCORAL+Ours 67.8 ± 1.6 97.8 ± 0.1 77.3 ± 1.8 87.4 ± 0.4 70.1 ± 1.2 48.3 ± 1.3 74.8</p>
<p>Table 2 :
2
The ablation study on five datasets.
AlgorithmColoredMNIST VLCS PACS OfficeHome TerraIncognitaBalancingERM w/o L P S BalancingERM w/o L P SW61.8 60.575.7 75.685.4 84.667.7 67.146.2 47.1BalancingERM62.577.186.368.248.2BalancingCORAL w/o L P S BalancingCORAL w/o L P SW67.4 6776.4 76.186.8 86.369.7 86.446.7 47.7BalancingCORAL67.877.387.470.148.3</p>
<dl>
<dt>Table 3</dt>
<dt>3</dt>
<dt>± 0.3 71.2 ± 0.2 37.6 ± 2.9 60.1 BalancingCORAL 70.5 ± 0.6 72.0 ± 0.2 57.2 ± 3.4 66.6 BalancingERM + Ours 71.7 ± 0.2 71.7 ± 0.3 44.2 ± 7.2 62.5 BalancingCORAL + Ours 71.6 ± 0.2 72.0 ± 0.2 59.7 ± 4.5 67.8</dt>
<dd>ColoredMNISTAlgorithm+90%+80%-90%AvgBalancingERM71.5</dd>
</dl>
<p>Table 4 :
4
RotatedMNIST ± 0.3 98.4 ± 0.1 98.7 ± 0.0 98.8 ± 0.0 98.8 ± 0.0 96.4 ± 0.1 97.7 BalancingCORAL 94.5 ± 0.4 98.7 ± 0.0 98.8 ± 0.1 99.0 ± 0.0 98.9 ± 0.0 96.2 ± 0.2 97.7 BalancingERM + Ours 95.4 ± 0.2 98.8± 0.0 99.1± 0.0 99.0 ±0.1 99.1 ± 0.0 96.9 ± 0.1 98.1 BalancingCORAL + Ours 95.2 ± 0.5 98.7 ±0.0 98.9 ± 0.0 99.1 ± 0.1 98.8 ± 0.0 96.0 ± 0.4 97.8
Algorithm01530456075AvgBalancingERM 94.8 E Experiment DetailsE.1 Datasets</p>
<dl>
<dt>Table 5</dt>
<dt>5</dt>
<dt>± 0.4 64.8 ± 1.2 70.2 ± 0.8 72.6 ± 1.3 76.1 BalancingCORAL 98.3 ± 0.1 63.9 ± 0.2 69.6 ± 1.1 73.7 ± 1.3 76.4 BalancingERM + Ours 96.7 ± 0.1 65.8 ±0.0 69.1 ± 0.0 76.8 ± 0.2 77.1 BalancingCORAL + Ours 98.0 ± 0.5 65.3 ± 0.1 70.3 ± 2.0 75.8 ± 0.4 77.3</dt>
<dd>VLCSAlgorithmCLSVAvgBalancingERM96.9</dd>
<dt>Table 6</dt>
<dt>6</dt>
<dt>± 1.8 76.7 ± 2.5 97.1 ± 0.3 80.1 ± 0.4 85.2 BalancingCORAL 87.8 ± 0.8 81.0 ± 0.1 97.1 ± 0.4 81.1 ± 0.8 86.7 BalancingERM + Ours 86.6 ± 2.4 80.6 ± 1.0 97.0 ± 0.6 80.9 ± 0.6 86.3 BalancingCORAL + Ours 88.6 ± 0.4 81.5 ± 0.2 97.6 ± 0.5 82.1 ± 1.0 87.4</dt>
<dd>PACSAlgorithmACPSAvgBalancingERM87.1</dd>
<dt>Table 7</dt>
<dt>7</dt>
<dt>± 0.4 53.8 ± 0.5 75.9 ± 0.2 77.4 ± 0.5 67.1 BalancingCORAL 65.6 ± 0.6 56.5 ± 0.6 77.6 ± 0.3 78.8 ± 0.5 69.6 BalancingERM + Ours 63.8 ± 0.8 55.9 ± 0.4 75.7 ± 0.6 77.2 ± 1.0 68.2 BalancingCORAL + Ours 66.0 ± 0.1 57.1 ± 0.3 77.7 ± 0.5 79.5 ± 0.2 70.1</dt>
<dd>OfficeHomeAlgorithmACPRAvgBalancingERM61.5</dd>
<dt>Table 8</dt>
<dt>8</dt>
<dt>± 0.8 47.2 ± 1.9 55.3 ± 0.7 36.2 ± 1.0 48.0 BalancingCORAL 55.2 ± 0.3 42.3 ± 3.6 54.7 ± 0.4 36.0 ± 1.0 47.0 BalancingERM + Ours 57.9 ± 1.8 42.6 ± 2.7 54.8 ± 1.3 37.5 ± 0.9 48.2 BalancingCORAL + Ours 54.7 ± 2.1 47.8 ± 2.9 51.9 ± 1.4 38.9 ± 1.6 48.3</dt>
<dd>TerraIncognitaAlgorithmACPSAvgBalancingERM53.3
E represents conditioning on E, i.e., E is given.
D Theoretical Analysis for Robustness of Propensity Score EstimationProof of Corollary 1.For any fixed function f , based on the analysis in Appendix B.2, we consider that when C and Y are non-confounding under the manipulated probability P m , the true risk is defined as R( f ) = E (x,y)∈Pm ℓ( f (x), y).The expected risk using the PSW estimator isLet v 1 , v 2 , . . ., v n be independent random variables such thatThen, by Hoeffding's inequality(81), we have:Assume the variable v i follows a Bernoulli distribution, withThen we have:From equations (20) and (21), we obtain:The above expression is equivalent to:, solving for:Suppose fh ∈ H is an invariant function in the hypothesis space.Let. Since. Combining with equation (22), we obtain:Then, we have:⇒P(maxBy solving equation(26), we obtain the generalization error as:
Towards out-of-distribution generalization: A survey. Jiashuo Liu, Zheyan Shen, Yue He, Xingxuan Zhang, Renzhe Xu, Han Yu, Peng Cui, arXiv:2108.136242021arXiv preprint</dd>
</dl>
<p>Statistical learning theory. Naumovich Vladimir, Vlamimir Vapnik, Vapnik, 1998</p>
<p>Robust learning with progressive data expansion against spurious correlation. Yihe Deng, Yu Yang, Baharan Mirzasoleiman, Quanquan Gu, Advances in Neural Information Processing Systems. 202436</p>
<p>Understanding and improving feature learning for out-of-distribution generalization. Yongqiang Chen, Wei Huang, Kaiwen Zhou, Yatao Bian, Bo Han, James Cheng, Advances in Neural Information Processing Systems. 202436</p>
<p>Shortcut learning in deep neural networks. Robert Geirhos, Jörn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, Felix A Wichmann, Nature Machine Intelligence. 2112020</p>
<p>Towards non-iid image classification: A dataset and baselines. Yue He, Zheyan Shen, Peng Cui, Pattern Recognition. 1101073832021</p>
<p>Recognition in terra incognita. Sara Beery, Grant Van Horn, Pietro Perona, Proceedings of the European conference on computer vision (ECCV). the European conference on computer vision (ECCV)2018</p>
<p>Last layer re-training is sufficient for robustness to spurious correlations. Polina Kirichenko, Pavel Izmailov, Andrew Gordon, Wilson , ICLR 20232023</p>
<p>Yonggang Zhang, Mingming Gong, Tongliang Liu, Gang Niu, Xinmei Tian, Bo Han, Bernhard Schölkopf, Kun Zhang, Causaladv, arXiv:2106.06196Adversarial robustness through the lens of causality. 2021arXiv preprint</p>
<p>José Miguel Hernández-Lobato, and Bernhard Schölkopf. Invariant causal representation learning for out-of-distribution generalization. Chaochao Lu, Yuhuai Wu, International Conference on Learning Representations. 2021</p>
<p>Learning causal semantic representation for out-of-distribution prediction. Chang Liu, Xinwei Sun, Jindong Wang, Haoyue Tang, Tao Li, Tao Qin, Wei Chen, Tie-Yan Liu, Advances in Neural Information Processing Systems. 202134</p>
<p>Causal inference by using invariant prediction: identification and confidence intervals. Jonas Peters, Peter Bühlmann, Nicolai Meinshausen, Journal of the Royal Statistical Society Series B: Statistical Methodology. 7852016</p>
<p>Invariance principle meets information bottleneck for out-of-distribution generalization. Kartik Ahuja, Ethan Caballero, Dinghuai Zhang, Jean-Christophe Gagnon-Audet, Yoshua Bengio, Ioannis Mitliagkas, Irina Rish, Advances in Neural Information Processing Systems. 342021</p>
<p>Zin: When and how to learn invariance without environment partition?. Yong Lin, Shengyu Zhu, Lu Tan, Peng Cui, Advances in Neural Information Processing Systems. 202235</p>
<p>Invariant learning via probability of sufficient and necessary causes. Mengyue Yang, Yonggang Zhang, Zhen Fang, Yali Du, Furui Liu, Jean-Francois Ton, Jianhong Wang, Jun Wang, Advances in Neural Information Processing Systems. 202436</p>
<p>Graphs, causality, and structural equation models. Judea Pearl, Sociological Methods &amp; Research. 2721998</p>
<p>The causal foundations of structural equation modeling. Handbook of structural equation modeling. Judea Pearl, 2012</p>
<p>Out-of-distribution generalization via risk extrapolation (rex). David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, Aaron Courville, International Conference on Machine Learning. PMLR2021</p>
<p>When is invariance useful in an out-of-distribution generalization problem?. Masanori Koyama, Shoichiro Yamaguchi, arXiv:2008.018832020arXiv preprint</p>
<p>Fair mixup: Fairness via interpolation. Youssef Mroueh, International Conference on Learning Representations. 2021</p>
<p>Debiasing graph neural networks via learning disentangled causal substructure. Xiao Shaohua Fan, Yanhu Wang, Chuan Mo, Jian Shi, Tang, Advances in Neural Information Processing Systems. 202235</p>
<p>Generative interventions for causal learning. Chengzhi Mao, Augustine Cha, Amogh Gupta, Hao Wang, Junfeng Yang, Carl Vondrick, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2021</p>
<p>Measuring the tendency of cnns to learn surface statistical regularities. Jason Jo, Yoshua Bengio, arXiv:1711.115612017arXiv preprint</p>
<p>Deep hashing network for unsupervised domain adaptation. Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, Sethuraman Panchanathan, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2017</p>
<p>. Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, David Lopez-Paz, arXiv:1907.028932019Invariant risk minimization. arXiv preprint</p>
<p>Judea Pearl, Madelyn Glymour, Nicholas P Jewell, Causal inference in statistics: A primer. John Wiley &amp; Sons2016</p>
<p>Kartik Ahuja, Jun Wang, Amit Dhurandhar, Karthikeyan Shanmugam, Kush R Varshney, arXiv:2010.16412Empirical or invariant risk minimization? a sample complexity perspective. 2020arXiv preprint</p>
<p>Graphical aspects of causal models. UCLA Cognitive Systems Laboratory. T S Verma, 1993Technical ReportR-191</p>
<p>The assumptions on which causal inferences rest. Richard Stone, Journal of the Royal Statistical Society Series B: Statistical Methodology. 5521993</p>
<p>Causal inference from complex longitudinal data. M James, Robins, Latent variable modeling and applications to causality. Springer1997</p>
<p>Comment: graphical models, causality and intervention. Judea Pearl, Statistical Science. 831993bayesian analysis in expert systems</p>
<p>Confounding confounding. Da Grayson, American journal of epidemiology. 12631987</p>
<p>Confounding by indication in clinical research. N Demetrios, Roger J Kyriacou, Lewis, Jama. 316172016</p>
<p>Toward a clearer definition of confounding. Clarice R Weinberg, 1993137American journal of epidemiology</p>
<p>The fast Fourier transform. J Henri, Henri J Nussbaumer, Nussbaumer, 1982Springer</p>
<p>The central role of the propensity score in observational studies for causal effects. R Paul, Donald B Rosenbaum, Rubin, Biometrika. 7011983</p>
<p>Frequency space domain randomization for domain generalization. Jiaxing Huang, Dayan Guan, Aoran Xiao, Shijian Lu, Fsdr , Proc. of CVPR. of CVPR2021</p>
<p>Deep frequency filtering for domain generalization. Shiqi Lin, Zhizheng Zhang, Zhipeng Huang, Yan Lu, Cuiling Lan, Peng Chu, Quanzeng You, Jiang Wang, Zicheng Liu, Amey Parulkar, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2023</p>
<p>A fourier-based framework for domain generalization. Qinwei Xu, Ruipeng Zhang, Ya Zhang, Yanfeng Wang, Qi Tian, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognition2021</p>
<p>Least squares quantization in pcm. Stuart Lloyd, IEEE transactions on information theory. 2821982</p>
<p>Learning bounds for importance weighting. Corinna Cortes, Yishay Mansour, Mehryar Mohri, Advances in neural information processing systems. 232010</p>
<p>Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, Percy Liang, arXiv:1911.087312019arXiv preprint</p>
<p>Improve unsupervised domain adaptation with mixup training. Huan Shen Yan, Nanxiang Song, Lincan Li, Liu Zou, Ren, arXiv:2001.006772020arXiv preprint</p>
<p>Learning to generalize: Metalearning for domain generalization. Da Li, Yongxin Yang, Yi-Zhe Song, Timothy Hospedales, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence201832</p>
<p>Deep coral: Correlation alignment for deep domain adaptation. Baochen Sun, Kate Saenko, European conference on computer vision. Springer2016</p>
<p>Domain generalization with adversarial feature learning. Haoliang Li, Sinno Jialin Pan, Shiqi Wang, Alex C Kot, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)June 2018</p>
<p>Domain-adversarial training of neural networks. Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, Mario Marchand, Victor Lempitsky, The journal of machine learning research. 1712016</p>
<p>Deep domain generalization via conditional invariant adversarial networks. Ya Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang, Dacheng Tao, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)September 2018</p>
<p>Domain generalization by marginal transfer learning. Gilles Blanchard, Aniket Anand Deshmukh, Ürun Dogan, Gyemin Lee, Clayton Scott, The Journal of Machine Learning Research. 2212021</p>
<p>Reducing domain gap by reducing style bias. Hyeonseob Nam, Hyunjae Lee, Jongchan Park, Wonjun Yoon, Donggeun Yoo, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2021</p>
<p>Adaptive risk minimization: Learning to adapt to domain shift. Henrik Marvin Mengxin Zhang, Nikita Marklund, Abhishek Dhawan, Sergey Gupta, Chelsea Levine, Finn, Advances in Neural Information Processing Systems. A Beygelzimer, Y Dauphin, P Liang, J Wortman Vaughan, 2021</p>
<p>Out-of-distribution generalization via risk extrapolation (rex). David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, Aaron Courville, International Conference on Machine Learning. PMLR2021</p>
<p>Self-challenging improves crossdomain generalization. Zeyi Huang, Haohan Wang, Eric P Xing, Dong Huang, European Conference on Computer Vision. Springer2020</p>
<p>Gradient matching for domain generalization. Yuge Shi, Jeffrey Seely, Philip Torr, N Siddharth, Awni Hannun, Nicolas Usunier, Gabriel Synnaeve, International Conference on Learning Representations. 2022</p>
<p>Fishr: Invariant gradient variances for out-of-distribution generalization. Alexandre Rame, Corentin Dancette, Matthieu Cord, International Conference on Machine Learning. PMLR2022</p>
<p>Learning explanations that are hard to vary. Giambattista Parascandolo, Alexander Neitz, Antonio Orvieto, Luigi Gresele, Bernhard Schölkopf, International Conference on Learning Representations. 2021</p>
<p>Sand-mask: An enhanced gradient masking strategy for the discovery of invariances in domain generalization. Soroosh Shahtalebi, Jean-Christophe Gagnon-Audet, Touraj Laleh, Mojtaba Faramarzi, Kartik Ahuja, Irina Rish, arXiv:2106.022662021arXiv preprint</p>
<p>Selfreg: Selfsupervised contrastive regularization for domain generalization. Daehee Kim, Youngjun Yoo, Seunghyun Park, Jinkyu Kim, Jaekoo Lee, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2021</p>
<p>Invariant causal mechanisms through distribution matching. Mathieu Chevalley, Charlotte Bunne, Andreas Krause, Stefan Bauer, arXiv:2206.116462022arXiv preprint</p>
<p>Causal balancing for domain generalization. Xinyi Wang, Michael Saxon, Jiachen Li, Hongyang Zhang, Kun Zhang, William Yang, Wang , arXiv:2206.052632022arXiv preprint</p>
<p>Domain generalization for object recognition with multi-task autoencoders. Muhammad Ghifary, Mengjie Bastiaan Kleijn, David Zhang, Balduzzi, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer vision2015</p>
<p>Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias. Chen Fang, Ye Xu, Daniel N Rockmore, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer Vision2013</p>
<p>Invariant causal prediction for sequential data. Niklas Pfister, Peter Bühlmann, Jonas Peters, Journal of the American Statistical Association. 1145272019</p>
<p>Causal inference meets machine learning. Peng Cui, Zheyan Shen, Sheng Li, Liuyi Yao, Yaliang Li, Zhixuan Chu, Jing Gao, Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery &amp; data mining. the 26th ACM SIGKDD international conference on knowledge discovery &amp; data mining2020</p>
<p>Learning causally invariant representations for out-ofdistribution generalization on graphs. Yongqiang Chen, Yonggang Zhang, Yatao Bian, Han Yang, M A Kaili, Binghui Xie, Tongliang Liu, Bo Han, James Cheng, Advances in Neural Information Processing Systems. 202235</p>
<p>Ying-Xin Wu, Xiang Wang, An Zhang, arXiv:2201.12872Xiangnan He, and Tat-Seng Chua. Discovering invariant rationales for graph neural networks. 2022arXiv preprint</p>
<p>Stable learning establishes some common ground between causal inference and machine learning. Peng Cui, Susan Athey, Nature Machine Intelligence. 422022</p>
<p>The risks of invariant risk minimization. Elan Rosenfeld, Pradeep Ravikumar, Andrej Risteski, arXiv:2010.057612020arXiv preprint</p>
<p>Active invariant causal prediction: Experiment selection through stability. L Juan, Christina Gamella, Heinze-Deml, Advances in Neural Information Processing Systems. 202033</p>
<p>Regularizing towards causal invariance: Linear models with proxies. Michael Oberst, Nikolaj Thams, Jonas Peters, David Sontag, International Conference on Machine Learning. PMLR2021</p>
<p>Invariant risk minimization games. Kartik Ahuja, Karthikeyan Shanmugam, Kush Varshney, Amit Dhurandhar, International Conference on Machine Learning. PMLR2020</p>
<p>An online learning approach to interpolation and extrapolation in domain generalization. Elan Rosenfeld, Pradeep Ravikumar, Andrej Risteski, International Conference on Artificial Intelligence and Statistics. PMLR2022</p>
<p>Model-based domain generalization. Alexander Robey, George J Pappas, Hamed Hassani, Advances in Neural Information Processing Systems. 202134</p>
<p>Provable domain generalization via invariant-feature subspace recovery. Haoxiang Wang, Haozhe Si, Bo Li, Han Zhao, International Conference on Machine Learning. PMLR2022</p>
<p>Taskoriented low-dose ct image denoising. Jiajin Zhang, Hanqing Chao, Xuanang Xu, Chuang Niu, Ge Wang, Pingkun Yan, Medical Image Computing and Computer Assisted Intervention-MICCAI 2021: 24th International Conference. Strasbourg, FranceSpringerSeptember 27-October 1, 2021. 2021Proceedings, Part VI 24</p>
<p>Domain extrapolation via regret minimization. Wengong Jin, Regina Barzilay, Tommi Jaakkola, arXiv:2006.0390820203arXiv preprint</p>
<p>Pareto invariant risk minimization: Towards mitigating the optimization dilemma in out-of-distribution generalization. Yongqiang Chen, Kaiwen Zhou, Yatao Bian, Binghui Xie, Bingzhe Wu, Yonggang Zhang, Kaili Ma, Han Yang, Peilin Zhao, Bo Han, arXiv:2206.077662022arXiv preprint</p>
<p>Show, deconfound and tell: Image captioning with causal inference. Bing Liu, Dong Wang, Xu Yang, Yong Zhou, Rui Yao, Zhiwen Shao, Jiaqi Zhao, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022</p>
<p>Causal transportability for visual recognition. Chengzhi Mao, Kevin Xia, James Wang, Hao Wang, Junfeng Yang, Elias Bareinboim, Carl Vondrick, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022</p>
<p>Probability inequalities for sums of bounded random variables. The collected works of Wassily Hoeffding. Wassily Hoeffding, 1994</p>            </div>
        </div>

    </div>
</body>
</html>