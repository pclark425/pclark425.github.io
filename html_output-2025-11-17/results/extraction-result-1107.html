<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1107 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1107</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1107</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-25.html">extraction-schema-25</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-264072630</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2402.04557v1.pdf" target="_blank">An Artificial Intelligence (AI) workflow for catalyst design and optimization</a></p>
                <p><strong>Paper Abstract:</strong> In the pursuit of novel catalyst development to address pressing environmental concerns and energy demand, conventional design and optimization methods often fall short due to the complexity and vastness of the catalyst parameter space. The advent of Machine Learning (ML) has ushered in a new era in the field of catalyst optimization, offering potential solutions to the shortcomings of traditional techniques. However, existing methods fail to effectively harness the wealth of information contained within the burgeoning body of scientific literature on catalyst synthesis. To address this gap, this study proposes an innovative Artificial Intelligence (AI) workflow that integrates Large Language Models (LLMs), Bayesian optimization, and an active learning loop to expedite and enhance catalyst optimization. Our methodology combines advanced language understanding with robust optimization strategies, effectively translating knowledge extracted from diverse literature into actionable parameters for practical experimentation and optimization. In this article, we demonstrate the application of this AI workflow in the optimization of catalyst synthesis for ammonia production. The results underscore the workflow's ability to streamline the catalyst development process, offering a swift, resource-efficient, and high-precision alternative to conventional methods.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1107.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1107.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI-Workflow (BO + LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>An Artificial Intelligence workflow for catalyst design and optimization (LLM + Bayesian active learning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An integrated pipeline that uses a Large Language Model (ChatGPT) to extract and construct a multi-dimensional chemical search space from literature, coupled with a Bayesian optimization active-learning loop (Gaussian Process surrogate, Matern-5/2 kernel, EI/EHVI acquisition) to propose experimental conditions for catalyst synthesis and refinement via iterative experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>AI-driven Bayesian active learning workflow (LLM + BO)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A composite agent consisting of (1) an LLM (ChatGPT) for automated literature mining and construction/vectorization of the experimental search space, and (2) a Bayesian optimization engine using a Gaussian Process surrogate (constant mean, Matern 5/2 kernel) with one-hot encoding for categorical inputs, and acquisition functions (EI for single-objective, EHVI for multi-objective). Initial sampling uses Latin Hypercube Sampling (LHS). The agent cycles proposed experiments through a physical lab and ingests measured outcomes to update the surrogate.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Bayesian optimization (active learning) with Gaussian Process surrogate; EI for single-objective; EHVI for multi-objective</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Starts with an LHS-initialized set of experiments to seed a GP surrogate. The GP provides predictive mean and uncertainty; acquisition functions (EI/EHVI) combine mean and uncertainty (and inter-objective correlation for EHVI) to pick next experimental points, balancing exploration and exploitation. After experiments are run, measured performance metrics are fed back to update the GP, iteratively refining predictions and reducing uncertainty until convergence criteria (performance threshold or experiment budget) are met.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Co3Mo3N (CMN) catalyst activation optimization for ammonia synthesis (activation step experiment space)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Unknown/partially-known mapping from synthesis parameters to performance (ammonia concentration); continuous dominant variables (activation temperature, duration, heating rate, pressure), possible categorical variables in broader search space; noisy and expensive-to-evaluate physical experiments; limited initial data (low-data regime); multi-objective tradeoffs (activity, stability, selectivity) considered.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Moderate-high: 4 primary continuous dimensions optimized in the case study (Activation Temperature: expanded up to 900°C; Activation Duration: ~0.5–8 h range, case study suggested 286.235 min for optimum; Heating Rate: 1–20 °C/min; Activation Pressure: 3–10 MPa), plus categorical choices in larger literature-derived space; evaluations are single-shot physical experiments (expensive), with measurement noise; no explicit state/action cardinalities reported.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Predicted (surrogate) optimal: ammonia concentration = 730.43 ppm at activation temperature = 787.782 °C, activation duration = 286.235 min, heating rate = 14.239 °C/min, activation pressure = 5.002 MPa; this is a model prediction from the GP surrogate and is explicitly reported as not yet experimentally validated.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Qualitative: described as sample-efficient and suitable for low-data regimes because GP surrogates and BO acquisition functions prioritize informative experiments; no numerical sample counts or rates to quantify efficiency are reported in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Managed by acquisition functions: Expected Improvement (EI) for single-objective balances exploitation (high predicted mean) and exploration (high predictive variance); Expected Hypervolume Improvement (EHVI) for multi-objective balances improvement across Pareto front taking into account correlations between objectives. LHS initialization is used to ensure broad initial exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Contrasted with conventional approaches in text: One-Factor-At-a-Time (OFAT), Design of Experiments (DoE), random sampling for initialization (explicit LHS vs Random comparison shown visually), and referenced prior BO-plus-DFT literature; no head-to-head experimental numeric comparisons reported.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>Demonstrated a practical pipeline that (a) uses ChatGPT to extract 774 catalysts and 737 procedure steps from literature to construct a vectorized search space, (b) uses LHS for initial sampling to provide broad coverage, (c) employs a GP surrogate (constant mean, Matern 5/2 kernel) with BO acquisition (EI/EHVI) to iteratively propose experiments, and (d) produced a model-suggested optimal condition predicting 730.43 ppm NH3 for the Co3Mo3N activation-step optimization; visualizations show surrogate uncertainty shrinks as more experimental points are included. The approach emphasizes adaptability via iterative model updates and literature-informed search-space construction.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>No experimental validation of the model-suggested optimum is reported; the paper acknowledges limited and potentially inconsistent literature data used to build the search space, leading to incomplete representation; categorical input handling is via one-hot encoding and authors note need for improved handling and multi-objective expansion; no quantitative benchmarks, sample counts, or baseline performance metrics are provided; real-world laboratory constraints, measurement noise effects, and full multi-objective tradeoffs remain untested in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'An Artificial Intelligence (AI) workflow for catalyst design and optimization', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1107.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1107.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT (LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT (Large Language Model used for literature mining and chemical space construction)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transformer-based large language model applied to automatically extract catalyst preparation procedures, parameters, and numeric values from XML-formatted literature to build a conceptual/vectorized chemical search space used by the Bayesian optimization loop.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ChatGPT (LLM used for data extraction)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Large pre-trained transformer LLM used to parse method sections from ~603 Elsevier science articles via designed prompts; extracts process variables (activation temperature, pressure, duration, heating rate, etc.), numeric values and units, and outputs structured tables; outputs are then curated with domain-expert quality control and integrated into a Neo4j conceptual map and vectorized for BO.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Not an adaptive experimental design agent itself; provides literature-derived search-space construction and parameter priors used by the BO agent</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Does not adapt experimental design over time; instead it generates a static, literature-derived representation of candidate variables and ranges that feed the adaptive BO loop. The LLM output is post-processed by experts and converted into normalized vectors / one-hot encodings.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Literature corpus / extracted chemical procedure database (used to define experimental environment)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Textual database of catalyst synthesis literature (XML articles), heterogeneous in format and completeness; not an experimental environment but used to define the parameter search space with variable ranges and categorical options.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Large corpus: initially 2410 search results for 'ammonia synthesis' reduced to 603 XML-available articles; extracted dataset includes 774 distinct catalysts and 737 unique procedure steps; converted into a multi-dimensional vector space including continuous and categorical variables.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Paper compares LLM-based search-space construction against traditional expert-defined search spaces (qualitative discussion); no quantitative comparison provided.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>ChatGPT successfully parsed literature and produced structured experimental parameters enabling construction of a diverse chemical search space; domain experts applied quality control filters and the extracted variables informed BO ranges (e.g., activation temperature expanded to 900 °C, heating rate to 20 °C/min).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Authors note LLMs are still maturing in fully understanding experimental procedure context and that expert review is necessary; potential propagation of inconsistencies from published data into the search space; reliance on Elsevier XML-accessible subset (603 of 2410 results) may bias the constructed space.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'An Artificial Intelligence (AI) workflow for catalyst design and optimization', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>AlphaFlow: autonomous discovery and optimization of multi-step chemistry using a self-driven fluidic lab guided by reinforcement learning <em>(Rating: 2)</em></li>
                <li>Bayesian optimization for adaptive experimental design: A review <em>(Rating: 2)</em></li>
                <li>Bayesian reaction optimization as a tool for chemical synthesis <em>(Rating: 2)</em></li>
                <li>Chimera: enabling hierarchy based multi-objective optimization for self-driving laboratories <em>(Rating: 1)</em></li>
                <li>A multi-objective active learning platform and web app for reaction optimization <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1107",
    "paper_id": "paper-264072630",
    "extraction_schema_id": "extraction-schema-25",
    "extracted_data": [
        {
            "name_short": "AI-Workflow (BO + LLM)",
            "name_full": "An Artificial Intelligence workflow for catalyst design and optimization (LLM + Bayesian active learning)",
            "brief_description": "An integrated pipeline that uses a Large Language Model (ChatGPT) to extract and construct a multi-dimensional chemical search space from literature, coupled with a Bayesian optimization active-learning loop (Gaussian Process surrogate, Matern-5/2 kernel, EI/EHVI acquisition) to propose experimental conditions for catalyst synthesis and refinement via iterative experiments.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "AI-driven Bayesian active learning workflow (LLM + BO)",
            "agent_description": "A composite agent consisting of (1) an LLM (ChatGPT) for automated literature mining and construction/vectorization of the experimental search space, and (2) a Bayesian optimization engine using a Gaussian Process surrogate (constant mean, Matern 5/2 kernel) with one-hot encoding for categorical inputs, and acquisition functions (EI for single-objective, EHVI for multi-objective). Initial sampling uses Latin Hypercube Sampling (LHS). The agent cycles proposed experiments through a physical lab and ingests measured outcomes to update the surrogate.",
            "adaptive_design_method": "Bayesian optimization (active learning) with Gaussian Process surrogate; EI for single-objective; EHVI for multi-objective",
            "adaptation_strategy_description": "Starts with an LHS-initialized set of experiments to seed a GP surrogate. The GP provides predictive mean and uncertainty; acquisition functions (EI/EHVI) combine mean and uncertainty (and inter-objective correlation for EHVI) to pick next experimental points, balancing exploration and exploitation. After experiments are run, measured performance metrics are fed back to update the GP, iteratively refining predictions and reducing uncertainty until convergence criteria (performance threshold or experiment budget) are met.",
            "environment_name": "Co3Mo3N (CMN) catalyst activation optimization for ammonia synthesis (activation step experiment space)",
            "environment_characteristics": "Unknown/partially-known mapping from synthesis parameters to performance (ammonia concentration); continuous dominant variables (activation temperature, duration, heating rate, pressure), possible categorical variables in broader search space; noisy and expensive-to-evaluate physical experiments; limited initial data (low-data regime); multi-objective tradeoffs (activity, stability, selectivity) considered.",
            "environment_complexity": "Moderate-high: 4 primary continuous dimensions optimized in the case study (Activation Temperature: expanded up to 900°C; Activation Duration: ~0.5–8 h range, case study suggested 286.235 min for optimum; Heating Rate: 1–20 °C/min; Activation Pressure: 3–10 MPa), plus categorical choices in larger literature-derived space; evaluations are single-shot physical experiments (expensive), with measurement noise; no explicit state/action cardinalities reported.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Predicted (surrogate) optimal: ammonia concentration = 730.43 ppm at activation temperature = 787.782 °C, activation duration = 286.235 min, heating rate = 14.239 °C/min, activation pressure = 5.002 MPa; this is a model prediction from the GP surrogate and is explicitly reported as not yet experimentally validated.",
            "performance_without_adaptation": null,
            "sample_efficiency": "Qualitative: described as sample-efficient and suitable for low-data regimes because GP surrogates and BO acquisition functions prioritize informative experiments; no numerical sample counts or rates to quantify efficiency are reported in the paper.",
            "exploration_exploitation_tradeoff": "Managed by acquisition functions: Expected Improvement (EI) for single-objective balances exploitation (high predicted mean) and exploration (high predictive variance); Expected Hypervolume Improvement (EHVI) for multi-objective balances improvement across Pareto front taking into account correlations between objectives. LHS initialization is used to ensure broad initial exploration.",
            "comparison_methods": "Contrasted with conventional approaches in text: One-Factor-At-a-Time (OFAT), Design of Experiments (DoE), random sampling for initialization (explicit LHS vs Random comparison shown visually), and referenced prior BO-plus-DFT literature; no head-to-head experimental numeric comparisons reported.",
            "key_results": "Demonstrated a practical pipeline that (a) uses ChatGPT to extract 774 catalysts and 737 procedure steps from literature to construct a vectorized search space, (b) uses LHS for initial sampling to provide broad coverage, (c) employs a GP surrogate (constant mean, Matern 5/2 kernel) with BO acquisition (EI/EHVI) to iteratively propose experiments, and (d) produced a model-suggested optimal condition predicting 730.43 ppm NH3 for the Co3Mo3N activation-step optimization; visualizations show surrogate uncertainty shrinks as more experimental points are included. The approach emphasizes adaptability via iterative model updates and literature-informed search-space construction.",
            "limitations_or_failures": "No experimental validation of the model-suggested optimum is reported; the paper acknowledges limited and potentially inconsistent literature data used to build the search space, leading to incomplete representation; categorical input handling is via one-hot encoding and authors note need for improved handling and multi-objective expansion; no quantitative benchmarks, sample counts, or baseline performance metrics are provided; real-world laboratory constraints, measurement noise effects, and full multi-objective tradeoffs remain untested in experiments.",
            "uuid": "e1107.0",
            "source_info": {
                "paper_title": "An Artificial Intelligence (AI) workflow for catalyst design and optimization",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "ChatGPT (LLM)",
            "name_full": "ChatGPT (Large Language Model used for literature mining and chemical space construction)",
            "brief_description": "A transformer-based large language model applied to automatically extract catalyst preparation procedures, parameters, and numeric values from XML-formatted literature to build a conceptual/vectorized chemical search space used by the Bayesian optimization loop.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "ChatGPT (LLM used for data extraction)",
            "agent_description": "Large pre-trained transformer LLM used to parse method sections from ~603 Elsevier science articles via designed prompts; extracts process variables (activation temperature, pressure, duration, heating rate, etc.), numeric values and units, and outputs structured tables; outputs are then curated with domain-expert quality control and integrated into a Neo4j conceptual map and vectorized for BO.",
            "adaptive_design_method": "Not an adaptive experimental design agent itself; provides literature-derived search-space construction and parameter priors used by the BO agent",
            "adaptation_strategy_description": "Does not adapt experimental design over time; instead it generates a static, literature-derived representation of candidate variables and ranges that feed the adaptive BO loop. The LLM output is post-processed by experts and converted into normalized vectors / one-hot encodings.",
            "environment_name": "Literature corpus / extracted chemical procedure database (used to define experimental environment)",
            "environment_characteristics": "Textual database of catalyst synthesis literature (XML articles), heterogeneous in format and completeness; not an experimental environment but used to define the parameter search space with variable ranges and categorical options.",
            "environment_complexity": "Large corpus: initially 2410 search results for 'ammonia synthesis' reduced to 603 XML-available articles; extracted dataset includes 774 distinct catalysts and 737 unique procedure steps; converted into a multi-dimensional vector space including continuous and categorical variables.",
            "uses_adaptive_design": false,
            "performance_with_adaptation": null,
            "performance_without_adaptation": null,
            "sample_efficiency": null,
            "exploration_exploitation_tradeoff": null,
            "comparison_methods": "Paper compares LLM-based search-space construction against traditional expert-defined search spaces (qualitative discussion); no quantitative comparison provided.",
            "key_results": "ChatGPT successfully parsed literature and produced structured experimental parameters enabling construction of a diverse chemical search space; domain experts applied quality control filters and the extracted variables informed BO ranges (e.g., activation temperature expanded to 900 °C, heating rate to 20 °C/min).",
            "limitations_or_failures": "Authors note LLMs are still maturing in fully understanding experimental procedure context and that expert review is necessary; potential propagation of inconsistencies from published data into the search space; reliance on Elsevier XML-accessible subset (603 of 2410 results) may bias the constructed space.",
            "uuid": "e1107.1",
            "source_info": {
                "paper_title": "An Artificial Intelligence (AI) workflow for catalyst design and optimization",
                "publication_date_yy_mm": "2024-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "AlphaFlow: autonomous discovery and optimization of multi-step chemistry using a self-driven fluidic lab guided by reinforcement learning",
            "rating": 2,
            "sanitized_title": "alphaflow_autonomous_discovery_and_optimization_of_multistep_chemistry_using_a_selfdriven_fluidic_lab_guided_by_reinforcement_learning"
        },
        {
            "paper_title": "Bayesian optimization for adaptive experimental design: A review",
            "rating": 2,
            "sanitized_title": "bayesian_optimization_for_adaptive_experimental_design_a_review"
        },
        {
            "paper_title": "Bayesian reaction optimization as a tool for chemical synthesis",
            "rating": 2,
            "sanitized_title": "bayesian_reaction_optimization_as_a_tool_for_chemical_synthesis"
        },
        {
            "paper_title": "Chimera: enabling hierarchy based multi-objective optimization for self-driving laboratories",
            "rating": 1,
            "sanitized_title": "chimera_enabling_hierarchy_based_multiobjective_optimization_for_selfdriving_laboratories"
        },
        {
            "paper_title": "A multi-objective active learning platform and web app for reaction optimization",
            "rating": 1,
            "sanitized_title": "a_multiobjective_active_learning_platform_and_web_app_for_reaction_optimization"
        }
    ],
    "cost": 0.010199,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>An Artificial Intelligence (AI) workflow for catalyst design and optimization</p>
<p>Nung Siong 
Department of Chemical Engineering
Tsinghua University
100084BeijingChina</p>
<p>Yi Shen Tew 
Xialin Zhong 
Department of Chemical Engineering
Tsinghua University
100084BeijingChina</p>
<p>Jun Yin 
Department of Chemical and Biomolecular Engineering
National University of Singapore
117576Singapore</p>
<p>Jiali Li 
Department of Chemical and Biomolecular Engineering
National University of Singapore
117576Singapore</p>
<p>Binhang Yan 
Department of Chemical Engineering
Tsinghua University
100084BeijingChina</p>
<p>Xiaonan Wang wangxiaonan@tsinghua.edu.cn 
Department of Chemical Engineering
Tsinghua University
100084BeijingChina</p>
<p>An Artificial Intelligence (AI) workflow for catalyst design and optimization
3750250064D2B70CCCA5EFCF503682CDCatalystsLarge Language ModelsActive LearningBayesian OptimizationAmmonia Synthesis
In the pursuit of novel catalyst development to address pressing environmental concerns and energy demand, conventional design and optimization methods often fall short due to the complexity and vastness of the catalyst parameter space.The advent of Machine Learning (ML) has ushered in a new era in the field of catalyst optimization, offering potential solutions to the shortcomings of traditional techniques.However, existing methods fail to effectively harness the wealth of information contained within the burgeoning body of scientific literature on catalyst synthesis.To address this gap, this study proposes an innovative Artificial Intelligence (AI) workflow that integrates Large Language Models (LLMs), Bayesian optimization, and an active learning loop to expedite and enhance catalyst optimization.Our methodology combines advanced language understanding with robust optimization strategies, effectively translating knowledge extracted from diverse literature into actionable parameters for practical experimentation and optimization.In this article, we demonstrate the application of this AI workflow in the optimization of catalyst synthesis for ammonia production.The results underscore the workflow's ability to streamline the catalyst development process, offering a swift, resource-efficient, and highprecision alternative to conventional methods.</p>
<p>Introduction</p>
<p>The development of novel catalysts to address increasing energy demand and consumption has become an urgent task in the realm of renewable energy 1 .The impetus for this development is illustrated by the growth in the global catalyst market, which was valued at USD 29.7 billion in 2022 and is projected to grow at a compound annual growth rate (CAGR) of 4.6% from 2023 to 2030.This surge is driven not only by escalating demands from applications in process optimization, yield improvement, and energy saving but also by a heightened awareness and concern for environmental issues, particularly the increase in carbon dioxide emissions.The proposition of carbon neutrality has illustrated the transformation path for the chemical industry over the coming decades, and set forth new challenges regarding the use of renewable energy and the catalytic conversion of carbon dioxide into high-value chemical products 2,3 .Undeniably, the development of novel catalysts is crucial in addressing our energy needs and environmental concerns, yet it presents an arduous task, owing to the multifaceted nature of the problem at hand 4 .</p>
<p>The path to new catalyst development is beset with three salient challenges 5 .First, the traditional catalyst development process, especially in the context of solid catalysts, requires extensive preliminary efforts.The sequence of catalyst synthesis, activity testing, characterization, and industrial scale-up form a complex and time-consuming process 6,7 .Identifying optimal synthesis methods and process parameters requires extensive experimental data.The second challenge arises from the limitations imposed by time and material resources 7 .These constraints restrict chemists to exploring only the tip of the iceberg of the vast, high-dimensional chemical parameter space, thereby leaving potentially superior catalysts undiscovered 8 .The complexity of navigating this parameter space is underscored in the multi-step catalyst development process, where the crucial interrelation between catalytic activity and process variables is often neglected 9,10 .Lastly, the advancement of parallel screening and high-throughput experimental technologies, while promising, presents its challenges.These methods, though more efficient than traditional trial-anderror techniques, demand greater resources in terms of cost and data volume 11 , while given the lack of extensive data on new catalysts in lab conditions, the importance of small-scale data optimization is further highlighted 12 .The rapid synthesis of catalysts under various conditions, subsequent performance-based screening and optimization, and catalyst characterization all contribute to these escalating demands.</p>
<p>Several optimization strategies are conventionally employed to identify the optimal set of condition parameters, thereby enhancing the performance of the catalyst.The 'One Factor At a Time' (OFAT) method is frequently employed as an alternative technique for chemical process optimization and comprehension 13 .The OFAT approach often misinterprets chemical processes due to its inefficiency, inaccuracy, and neglect of synergistic effects and nonlinear responses among experimental variables 14 .Design of Experiments (DoE), a robust and extensively utilized optimization technique especially within the pharmaceutical and fine chemical sectors, serves to address these shortcomings 15 .DoE comprises a suite of statistical methodologies that endeavor to construct a mathematical model capable of describing the output of a chemical reaction (e.g., reaction yield, purity, etc.) based on the experimental inputs (e.g., temperature, reaction time) associated with the reaction.While these conventional optimization methods and their advancements have undeniably made significant contributions to the field, certain gaps persist that limit their full potential in optimizing catalyst synthesis.The predominant reliance on the empirical knowledge and intuition of seasoned chemists, while invaluable, is not systematically scalable and transferable.Techniques like OFAT and DoE, though statistically rigorous, are often unable to keep pace with the sheer complexity and vastness of the catalyst parameter space, leaving much of it unexplored and underutilized.These methods can struggle to account for the nuanced interdependencies among experimental variables and the nonlinear nature of chemical reactions 16,17 .</p>
<p>With the advent of machine learning (ML), the field of catalyst optimization is entering a new era.</p>
<p>ML techniques are gaining traction due to their capability to model complex, nonlinear systems and find correlations in vast datasets that might otherwise be overlooked 18,19 .Active learning based on Bayesian optimization (BO) 20 , a type of ML, presents a promising solution to the shortcomings of conventional optimization techniques.This strategy is based on constructing a probabilistic model for the objective function and then using it to select the most promising parameters to evaluate in the actual objective function, based on a balance between exploration and exploitation 21 .This allows for more efficient sampling of the parameter space compared to OFAT and DoE, which can accelerate the optimization process and potentially discover better solutions.In a recent study, Rossmeisl et al. demonstrated a novel application of Bayesian optimization in catalyst design, aiming to optimize multinary metal alloy catalysts for fuel cells 22 .</p>
<p>They employed a computational framework combining density functional theory (DFT) calculations, machine learning-driven kinetic modeling, and Bayesian optimization, efficiently identifying optimal catalyst compositions in vast multi-metallic spaces, thereby accelerating catalyst optimization processes.Kazuki and Yuta demonstrate the effective combination of Bayesian optimization and density functional theory calculations to find the optimal binary alloy catalyst for nitrogen activation, a critical step in ammonia synthesis 23 .Their study showcased how Bayesian optimization surpasses random search in efficiency, highlighting the benefits of data science and computational chemistry in accelerating catalyst research, and underscores plans for future exploration of multi-objective optimization for ammonia synthesis.</p>
<p>However, conventional techniques such as OFAT, DoE, and Bayesian optimization cannot efficiently leverage and synthesize the wealth of information embedded in the rapidly expanding body of scientific literature on catalyst synthesis.To bridge the gap mentioned above, many scientists have utilized the power of Artificial Intelligence (AI) to retrieve information from broad corpora of scientific literature.The Large Language Model (LLM) is a type of transformer model that is capable of modeling the probability of a sequence of tokens in texts 24 .By leveraging largescale data and massive models, it has effectively overcome several long-standing challenges in the field of Natural Language Processing (NLP), such as occasional fluency issues, lack of common knowledge, and unable to remember the context from previous sentences.ChatGPT and its successor, GPT-4, presented by OpenAI, are leading LLMs that are capable of understanding, generating, and translating human language, performing sentiment analysis, and answering questions 25 .Approaching human-level ability across many expert domains, GPT-4 can accomplish complex tasks in chemistry purely from human instructions, potentially setting the stage for transformative advancements in the field of catalyst synthesis.Jablonka et al.'s work demonstrated GPT-3's impressive capability to match conventional machine learning models in chemical property prediction and molecule design tasks, despite using fewer data points, by effectively identifying correlations within textual data 26 .On the other hand, researchers successfully utilized LLMs and particularly developed MolReGPT, which leverages prompts and retrieval methods for translation between molecules and text descriptions, surpassing other models in performance without the need for fine-tuning 27 .</p>
<p>By addressing the limitations of traditional chemical space construction and leveraging the strengths of active learning and Bayesian Optimization, the proposed AI workflow to expedite catalyst optimization at the particle scale could prove transformative, offering avenues for swift, resource-efficient, and high-precision catalyst synthesis.This workflow hinges on the convergence of advanced language understanding, Bayesian optimization, and active learning loop methodologies, operating in harmony to ascertain optimal solutions for synthesis parameters that will affect the structure of catalyst particles, consequently affecting their activity.This AI workflow enables the effective integration of knowledge extracted from a wide range of literature with practical experimentation.By fusing the text-understanding capabilities of LLMs, parameter optimization of BO, and the adaptive sampling of an active learning loop, this workflow offers a highly adaptive, robust, and efficient approach to optimizing the synthesis of catalysts.This article is structured as follows: detailed methodology can be found in Section 2; the results of a demonstrative case study are presented and discussed in Section 3; and conclusions are provided in Section 4.</p>
<p>Methodology</p>
<p>An illustration of the proposed AI-driven workflow is shown in Figure 1.The backbone of this workflow consists of two key components: the utilization of a large language model for constructing the chemical space and the application of Bayesian active learning for multi-objective optimization within that space.The large language model, ChatGPT trained on an extensive corpus, including scientific literature, is capable of understanding, analyzing, and extracting crucial data and concepts from a vast number of research papers pertinent to catalyst synthesis.This capability enables the AI to build a comprehensive and multi-dimensional search space for catalyst synthesis, encompassing various catalyst types, synthesis methods, reaction conditions, and their corresponding performance metrics.The Bayesian optimization methodology is brought to bear, which uses the information gathered by the large language model to direct the exploration and exploitation of the search space.Bayesian optimization techniques exploit probabilistic models, primarily Gaussian Processes, to approximate the unknown and complex function that maps catalyst synthesis parameters to performance metrics.The AI workflow is then augmented by an active learning loop, which functions to iteratively improve the optimization model.The loop initiates with the Bayesian optimization proposing an optimal set of condition parameters based on the current understanding of the objective function.These suggested parameters are then employed in real-life experiments to synthesize and evaluate catalysts.The performance metrics gathered from these experiments are fed back into the AI model, updating the understanding of the search space and the performance mapping function.Consequently, the loop allows for the AI system to learn dynamically from each experiment, constantly refining its predictions and progressively converging to the global optimum.Typically, the search space in Bayesian optimization is designed by experts according to their experiences.However, scientific literature contains rich and in-depth information about catalyst preparation and associated variables, which we aim to utilize for the construction of our search space.We place particular emphasis on the diversity of the input data to ensure a comprehensive search space.</p>
<p>Large Language Model (LLM) in Chemical Space Construction</p>
<p>The Elsevier Text Mining API was utilized to search the Science Direct database for academic articles relevant to the study.A generalized query string template, TITLE-ABS-KEY('Reaction Type' AND 'catalyst'), was used to capture a diverse range of articles.This template was applied using the demonstrative example of TITLE-ABS-KEY('ammonia synthesis' AND 'catalyst'), which initially yielded 2410 entries.Although the broad search term allows for a comprehensive collection, it may also include articles of varying relevance to the core research questions.The primary criterion for inclusion was the availability of articles in XML format to facilitate more efficient and precise text cleaning and segmentation, reducing the dataset to 603 articles that met this XML criterion.Additionally, while ACS Publications indeed hosts a large number of relevant articles, this study relied solely on Elsevier's Science Direct due to limitations in accessing ACS's text mining API.It should be noted that no manual screening was applied; instead, keyword-based automated filtering identified articles related to catalyst preparation.</p>
<p>After automatically gathering articles on ammonia synthesis catalysts, each literature is segmented into sections that focus on methods and experimental procedures.The filtering process was conducted using a list of keywords to detect catalyst preparation-related phrases, which was designed by sampling the section title from the literature dataset.</p>
<p>Designing Prompts for Data Extraction</p>
<p>Prompts, in the context of LLMs, are structured inputs designed to guide the model in generating specific and desirable outputs.Given that LLMs require guidance to understand the type and structure of the information to be extracted, we created specific prompts to assist in this process.</p>
<p>The design of these prompts was influenced by a thorough literature review and expert consultations.Each step in this process was tailored to set a context and provide clear instructions to guide the LLMs, in our case the ChatGPT model.</p>
<p>• Context Setting: You are a researcher in the field of [ammonia catalyst synthesis] who is good at extracting information from text.</p>
<p>• Text Introduction: This is the text which may or may not include the catalyst preparation methods.+ <input text> • Task Instructions: A comprehensive multi-step guide directs the model to analyze the text and extract relevant information, structured depending on the text content.</p>
<p>• Action Clarification: The model's capabilities and tasks are reiterated, clearly defining its role in identifying, extracting, and organizing relevant information.</p>
<p>• Output Structure Provision: A sample table is provided, offering a template for the desired output, guiding the structure and organization of the extracted information.</p>
<p>An example of the prompt used is shown below:</p>
<p>"You are a researcher in the field of [ammonia catalyst synthesis] who is good at extracting information from text.This is the text which may or may not include the catalyst preparation methods."+ <paragraph> + "Please follow these steps to extract information from the given text: Start:</p>
<ol>
<li>
<p>Analyze the text whether it is about catalyst preparation or not.</p>
</li>
<li>
<p>IF the text is about catalyst preparation THEN proceed to step 3 ELSE go to step 6.</p>
</li>
<li>
<p>Identify the process variables: temperature, pressure, duration of each step, rate of temperature change, reactant proportions, order of reactant addition, stirring speed, pH, concentrations, and additional parameters.4. Extract these values along with their units.5. Organize these into a table with the following columns: Catalyst Name, Specific Procedure Step, Process Variable, Numeric Value, and Unit.Then, END.</p>
</li>
<li>
<p>IF the text is not about catalyst preparation, output a blank table.</p>
</li>
</ol>
<p>END</p>
<p>You can perform the following actions:</p>
<p>• Identify whether the text is about preparing or synthesizing catalysts.</p>
<p>• Extract related information from the given text and given sample table format.</p>
<p>• Organize related information into the desired format.</p>
<p>• Extract the number and unit from the related information.</p>
<p>• Fill in the table with the desired information.</p>
<p>• Write down the condition of extracted properties in the condition column.</p>
<p>• Output the table.Recognizing the critical role of variable relationships in catalyst preparation, we organized the extracted data into a conceptual map.This map was created using Neo4j, a graph database management system, and parameters were selected based on frequency analysis and expert opinion 28 .The map effectively illustrates relationships between catalyst types, preparation procedures, procedure variables, numeric values, units, and applied conditions, as shown in Figure 2.</p>
<p>Sample Table:</p>
<p>Quality Control</p>
<p>At present, the Large Language Models (LLMs) are in the initial stages of fully understanding the context of catalyst preparation procedures and associated variables.To ensure the reliability and applicability of the information generated by ChatGPT, domain experts meticulously review extracted parameters, such as Activation Temperature (AT) and Activation Duration (AD).Their expertise aids in determining the range and feasibility of these parameters in real-world chemical processes, thereby aligning the AI-extracted data with current scientific understanding.To enhance the robustness of the information extraction process, two distinct filters have been designed to systematically categorize procedures and variables into their relevant categories.For a more concrete understanding, the following examples are provided.</p>
<p>For the process of melting iron oxides with structural promoters such as AlO, and CaO, and an activating promoter like KO, the specific procedure is classified as 'Combustion'.Similarly, in the 'Wet impregnation method', the specific procedure is 'Impregnation', and the variables such as 'Calcination temperature' and 'Drying temperature' are classified as 'Temperature', while 'Stirring time' is classified as 'Duration'.</p>
<p>Vectorization for Optimization</p>
<p>Given the need for a mathematical representation of our data to input into Bayesian optimization models, we converted our structural data into a multi-dimensional vector space.The min-max normalization method was used for continuous variables to define the range of space.For discrete variables, we included all options mentioned in the literature.This strategy facilitates an exhaustive representation of potential solutions within the "chemical space" associated with our catalyst.</p>
<p>Bayesian Active Learning</p>
<p>Active learning, a crucial aspect of machine learning, is particularly instrumental in the area of optimal experimental design 29,30 .The proposed Bayesian optimization loop is shown in Figure 3.This systematic approach helps identify the most beneficial experiments to be conducted next based on predefined objectives.One technique that has gained considerable attention recently is Bayesian Optimization (BO), an active learning technique that guides experimentalists in the lab to optimize unknown functions 31 .BO balances the exploration of the unknown function with experiments that exploit prior knowledge to pinpoint extrema.They operate with minimal data and use heuristic-based searches for the most informative observations 32 .This approach is versatile and can be applied to diverse search spaces, including arbitrary parameterized reaction domains, making it well-suited for optimizing the variables of catalyst synthesis.The strength of BO lies in its capacity to handle noise, high dimensionality, and the nonlinearity of the objective function, making it highly suitable for optimizing complex processes such as catalyst synthesis.</p>
<p>Initial Sampling Strategies</p>
<p>In the realm of Bayesian Optimization, the selection of initial sampling points plays a pivotal role in determining the overall effectiveness and efficiency of the optimization process 30 .These initial points from the search space form the foundation for the subsequent iterative learning and optimization steps, essentially guiding the model's exploration of the search space.This leads to the importance of employing robust initial sampling strategies, as they can significantly influence the optimization outcome.</p>
<p>Among the various initial sampling strategies available, Latin Hypercube Sampling (LHS) 33 has been utilized in this work.LHS, a stratified sampling technique, stands out due to its capability to generate a well-distributed set of initial points across the entire search space.Unlike other methods that randomly select initial points, LHS ensures that the sampled points span the search space as evenly as possible, which ensures a balanced exploration of the search space right from the outset, thus increasing the probability of identifying the optimal solution.Given the vastness and the highdimensional nature of the catalyst parameter space, a well-distributed initial sampling, as afforded by LHS, ensures a broad and diverse representation of the search space 34 .This is especially advantageous when dealing with complex, multi-step catalyst synthesis processes that involve numerous interrelated parameters.</p>
<p>Surrogate Model of BO</p>
<p>The implementation of a surrogate model is a fundamental facet of BO, with the Gaussian Process (GP) model adopted in this research because of its proficiency in managing uncertainty and the multifaceted nature inherent to catalyst synthesis optimization 35 .
[ f(x 1 ) ⋮ f(x n ) ] ~N ([ m(x 1 ) ⋮ m(x n ) ] , [ k(x 1 , x 1 ) ⋯ k(x 1 , x n ) ⋮ ⋱ ⋮ k(x n , x 1 ) ⋯ k(x n , x n ) ])(1)
A GP surrogate model offers a non-parametric, probabilistic technique to model the elusive function connecting the parameters of catalyst synthesis to performance metrics 21 .GP is formally defined as eq (1), where X = {x 1 , … , x n } is the vector of process variables.In this formulation, m(X) represents the mean function, encapsulating the expected value of GP across all elements of X. k (X, X ′ )is the covariance matrix, providing a measure of interrelation for all possible pairs within the set of process variables (X, X ′ ).The GP model's distinct advantage is its capability to estimate prediction-associated uncertainty, making it ideal for Bayesian Optimization that intrinsically requires balancing exploration and exploitation.This quantification of uncertainty enables the intelligent selection of subsequent data points, harmonizing the necessity for further exploration with optimization goals.The choice of mean function and covariance (or kernel) function in the GP model is instrumental in shaping the model's properties and subsequent performance.In this study, a constant mean function was selected for our Gaussian Process surrogate model, premising that the average value across the entire search space remains constant.</p>
<p>This assumption, while seemingly simple, is often a practical and effective starting point, particularly when undertaking new catalyst development projects.In such scenarios, the prior knowledge about the catalyst's performance landscape is typically sparse or even absent, making it challenging to substantiate more complex assumptions about the mean function.Therefore, a constant mean function provides a reasonable and unbiased baseline from which to start our optimization process and allows the model to learn and update its understanding of the objective function as more data is gathered.
k (X, X ′ ) = σ 2 (1 + √5r ℓ + 5r 2 5ℓ 2 ) exp (− √5r ℓ )(2)
Additionally, for the covariance function, a comparative assessment was carried out among a selection of Matern functions characterized by differing degrees of smoothness, denoted by ν.The Matern 5/2 kernel, expressed in eq 2, where r is the Euclidean distance between the points X and Moreover, GP predominantly operates on continuous variables, necessitating the conversion of categorical variables into a continuous format 36,37 .During the initial stages of optimization catalyst synthesis, the volume of experimental data is typically limited, especially in the field of the development of new catalysts.In these low-data regimes, simpler representation methods such as one-hot encodings (OHE) often yield significant results, or even surpass, the performance of more complex and resource-intensive descriptors 38,39 .The handling of categorical variables which are identified by the first step of the AI workflow as some of the important variables, using the method of one-hot encoding adds to the flexibility of the GP model, broadening its applicability to a wider range of scenarios.For example, in the synthesis of catalysts, where various solvents and metals are used, these categorical variables can be suitably represented in binary form via onehot encoding.This binary representation designates the presence or absence of specific solvents and metals.Beyond a binary representation, one-hot encoding can also accommodate the representation of multiple types of solvents and metals.Therefore, it does not just provide binary inclusion-exclusion information but extends to symbolize a multitude of categories within each variable.This way, the use of one-hot encoding contributes to an increasingly flexible Gaussian Process model, accommodating a broader span of input scenarios and enhancing its performance within the complex and multifaceted landscape of catalyst synthesis.This incorporation further bolsters the robustness of our GP-based Bayesian optimization framework.
X ′ , r = ‖X − X ′ ‖ 2 ,
Hence, the integration of the Gaussian Process surrogate model, a constant mean function, the Matern 5/2 covariance function, and effective handling of categorical inputs generate a robust, adaptable, and potent framework to model the intricate, high-dimensional, and uncertain search space intrinsic to catalyst synthesis.This firm foundation enhances the effectiveness of subsequent optimization stages, thus improving the likelihood of converging towards the global optimum.</p>
<p>Acquisition Function of MOBO</p>
<p>Bayesian optimization methodology centers around the acquisition function, a key component that determines the next set of experimental parameters to investigate.For single-objective optimization, the Expected Improvement (EI) acquisition function is often used due to its ability to balance exploration, targeting areas with significant predictive uncertainty, and exploitation, focusing on regions predicted to offer high performance 40 .This balance ensures effective and systematic use of resources.However, catalyst synthesis represents a complex, multi-objective optimization task, which is influenced by a variety of performance factors such as catalyst activity, selectivity, stability, and adaptability under various reaction conditions.The relationship between these often conflicting parameters is well-captured by the concept of Pareto optimality, which represents a set of non-dominated solutions where improvement in one objective invariably affects others 41 .By aiming to find solutions on or close to the Pareto front, a set of optimal solutions can be found where a decision-maker can choose depending on their specific preferences or requirements 40 .This provides a more comprehensive view of the possible optimal solutions, rather than a single "best" solution, which might not exist in multi-objective problems due to the conflicting nature of the objectives.To elaborate, activity and stability are the two parameters to be optimized.Any solution that increases the activity without decreasing the stability, or increases the stability without decreasing the activity, is considered Pareto optimal.</p>
<p>When dealing with multi-objective optimization, a more nuanced approach to the acquisition function is needed.This approach must balance multiple objectives, either by assigning specific weights to the objectives or by applying the principle of Pareto optimality.This is where the Expected Hypervolume Improvement (EHVI), a multi-objective acquisition function, comes into play 42 .The EHVI function considers the entire Pareto front, providing a comprehensive view of all optimal solutions.It is similar to the improvement in the EI acquisition function used for singleobjective optimization, the difference is that in EHVI, the improvement refers to the expected increase in the dominated hypervolume if a new sampling point were to be incorporated 43,44 .This means that EHVI considers not just the mean and variance predictions of the underlying Gaussian Process model, but also the correlation between multiple objectives.It guides the exploration through the high-dimensional parameter space to find the next promising point for exploration.</p>
<p>Active Learning Loop</p>
<p>In the Bayesian optimization framework applied to catalyst synthesis parameter optimization, the active learning loop is the crucial phase that bridges the gap between theoretical predictions and practical implementation 44 .Here, the selected set of parameters provided by the acquisition function is translated into a tangible experimental setup.Initially, experiments are conducted using the suggested combination of parameters.This step embodies the process of exploration and exploitation as indicated by the Gaussian Process surrogate model's predictive framework, which provides statistical estimates based on accumulated knowledge.This stage entails meticulous catalyst synthesis according to stipulated parameters and conditions, offering practical validation for the theoretical predictions of the model.</p>
<p>Once the catalyst is synthesized, its performance is subjected to a comprehensive evaluation.</p>
<p>Various performance metrics, such as catalyst activity, selectivity, stability, and adaptability under diverse reaction conditions, are measured.The precision in determining these metrics is of significant importance as they are incorporated back into the model, thereby directly influencing future predictions and optimization steps.Following the catalyst performance evaluation, the GP surrogate model is updated with the newly obtained experimental data.By accommodating this fresh information, the model's capability to predict the performance of different parameters is continually refined.A defining aspect of the active learning loop is the decision of when to terminate the process.The loop can conclude when the optimization process reaches a predetermined threshold of catalyst performance or a specific level of improvement.Alternatively, the loop might cease when the maximum allowable number of experiments is reached.The convergence criteria, while generally pre-established, should also incorporate practical factors such as resource constraints and the urgency of achieving the desired performance.</p>
<p>The active learning loop thus forms the backbone of the Bayesian optimization methodology.It fosters a systematic and efficient trajectory through the complex, high-dimensional parameter space of the catalyst synthesis process.By facilitating a robust cycle of prediction, experimentation, and learning, it paves the way for optimizing catalyst performance, offering significant potential to enhance the effectiveness of catalyst synthesis.</p>
<p>Result and Discussion</p>
<p>In this section, we explore the practical implementation and implications of the delineated AI Workflow for Catalyst Synthesis.We demonstrate the method's effectiveness and potential in new catalyst design through an Ammonia Synthesis case study.</p>
<p>The rising clean energy trend has spurred intense research into green hydrogen generation and its conversion into green ammonia.The drive towards decentralized green ammonia production necessitates equipment miniaturization and a reduction in reaction temperature and pressure This need aligns with contemporary catalyst requirements that prioritize milder operating conditions, robustness to potential catalyst poisoning from trace water oxygen in green hydrogen, and costeffectiveness.Notably, nitride catalysts are emerging as significant players in ammonia synthesis.</p>
<p>For instance, efforts have been made to construct a Ni/LaN system, leveraging the nitrogen vacancies of LaN to weaken N-N triple bonds, promoting N 2 dissociation assisted by Ni's facilitation of H 2 dissociation, a synergic approach albeit hindered by Ni's weak interaction with N 2 , restricting further enhancement of the catalytic activity of the system 45 .Besides, the Co 3 Mo 3 N catalyst stands out, exhibiting promising attributes aided by Cs or K promoters, nearing the performance of commercial Fe-based catalysts, although grappling with cost impediments and gaps in high-pressure activity data and resilience against water and oxygen 46 .In this study, we focused on the synthesis of the CoMo bimetallic nitride catalyst known for its higher ammonia synthesis activity 47 .This initiative involves the optimization of the activation step parameters to find an optimal set, promising a rich yield of ammonia.The process, characterized by a multitude of phases contributing to the catalyst's activity, requires parameter tuning to find the optimal parameter combination.Addressing these high-dimensional tasks necessitates the utilization of data-driven approaches and advanced machine-learning models.In this regard, the AI Workflow outlined in this study could be instrumental in overcoming these challenges.Such a method has the potential to streamline the design and synthesis of new catalysts, thereby improving the efficiency and reducing the time and cost associated with catalyst development.</p>
<p>Catalyst Preparation</p>
<p>The genesis of the Co 3 Mo 3 N (CMN) catalyst, central to ammonia production, begins with the preparation of CoMo bimetallic oxide, CoMoO 4 precursor through the hydrothermal method.We find the Co/Mo catalyst preparation process at a feed ratio of 1:1 to be a fitting example.Precisely</p>
<p>Data Extraction for Search Space Construction</p>
<p>Our study encompasses a diverse dataset by extracting information from literature using ChatGPT, that accounts for 774 distinct catalysts and 737 unique procedure steps, offering a comprehensive overview of various catalysts and procedures involved in ammonia synthesis processes.Table 1 and Table 2 serve as an illustrative summary of the dataset.</p>
<p>As shown in Table 1, the analysis of catalyst frequencies reveals that "Ammonia Catalyst" appears to be the most prevalent, finding use in 437 instances.This is succeeded by "Ru/MgO" and "Ammonia Synthesis Catalyst", appearing in 47 and 43 instances, respectively.Despite the considerable variety in the dataset, certain catalysts emerge as common across processes, with these three showing the highest frequency of usage.</p>
<p>Similarly, Table 2 outlines the frequency of different procedural steps.The "Impregnation method" stands as the most common, with 240 instances.This is followed by the "Synthesis" (187 instances), and "Reduction" (104 instances) methods, underscoring their significance in the analyzed chemical processes.Among the less frequent procedures, "Fixed-bed flow reactor" and "Synthesis with aqueous solutions of MnSO• HO and KMnO" appear in 24 instances each.Our data analysis from 603 articles on ammonia synthesis catalysts yielded significant insights into the multidimensional parameters shaping catalyst synthesis.These parameters included Activation Pressure (AP), Activation Duration (AD), Activation Temperature (AT), and Heating Rate (HR).</p>
<p>The optimization procedure targets key variables within this reduction step: activation pressure, activation temperature, heating rate, and activation duration, which emerged as dominant forces shaping the catalyst's structure and consequently, its performance in ammonia synthesis.These variables were identified as impactful parameters through the application of the large language model ChatGPT, which intelligently parses through extensive literature to discern the most influential factors in the catalyst synthesis process.</p>
<p>We observed that the Activation Pressure ranged from 3 to 10 MPa, which underscores the importance of accurate pressure control for optimal catalyst synthesis.Activation Duration, another crucial variable, presented a broader range from 0.5 to 8 hours, reflecting a wide temporal span for catalyst activation.The parameter of Activation Temperature showcased substantial variation, ranging from 200°C to 700°C.Meanwhile, the presence of lower temperatures suggests that certain catalysts can be synthesized and activated under relatively mild conditions.The Heating Rate, presented in °C/min, had a narrower range of values, primarily between 1 and 10.</p>
<p>Due to the limited amount of literature collected, the results extracted do not fully represent the entire search space.Enlarging the search space in terms of Activation Temperature is conceptualized with a foresight that higher temperatures could foster the formation of different phase structures, which in turn might influence the catalytic activity positively.This exploration promises the discovery of potentially favorable conditions that were not contemplated within the original bounds, possibly leading to groundbreaking insights into the activation parameters and their roles in synthesizing efficient catalysts.On a parallel note, initial rounds of experimentation suggested potential improvements in catalytic performance at different Heating Rates However, initial rounds of experimentation suggested potential improvements in catalytic performance at higher Activation temperatures and different Heating Rates.Therefore, in our effort to explore a larger space, we have appropriately expanded the search parameters.Specifically, we have increased the Activation Temperature up to 900°C and the Heating Rate up to 20 °C/min.This expansion will hopefully provide a broader understanding of catalyst activation, beyond the constraints of our initial findings.From this graphical representation, it is apparent that LHS ensures a more uniformly dispersed coverage across the parameter space in contrast to Random Sampling.This superior attribute of LHS for the initialization step effectively minimizes the clustering of sample points, reducing the potential for neglecting important regions of the parameter space.By generating a comprehensive initial exploration of the space, we set a robust foundation for the subsequent steps in the Bayesian Optimization process, enhancing its efficacy and efficiency in locating the optimum.The number The algorithm works towards finding the set of parameters that yield the highest concentration, effectively navigating the balance between the exploitation of areas of the parameter space known to yield good results and the exploration of less known areas that may offer further improvements.</p>
<p>The final result of this process is an optimized set of conditions that yield the maximum concentration of NH 3 , given the constraints of the problem.7a, in the initial iteration, the surrogate model provides a basic estimation of the system's behavior.Given the sparse data, the model is limited in its ability to capture the complexity of the parameter interactions.Despite this limitation, the GP model offers a good starting point for understanding the system's dynamics, focusing on areas that the model perceives as having the most potential for improvement based on the available data.As we move to a later iteration that incorporates a larger number of data points (Figure 7b), the surrogate model becomes significantly more refined.With this additional data, the model is better equipped to capture the system's behavior accurately and construct a more intricate understanding of the underlying relationships between parameters.Consequently, the surrogate model gains increased confidence in its predictions, as indicated by a decrease in the uncertainty around the estimated output.</p>
<p>Figure 7c provides a multi-dimensional representation of the parametric space of the ammonia production process.This visual representation elucidates the correlations between various operating conditions-namely activation temperature, activation duration, and heating rate-and the resultant ammonia concentration.The colors indicate the heating rate of the catalyst, while the size of each data point is proportional to the concentration of NH 3 produced under those conditions.</p>
<p>The star symbol in red represents the suggested optimal point proposed by the Bayesian optimization algorithm.The proposed optimal point, as determined by the Bayesian optimization algorithm, is graphically depicted within the explored parameter space.This point, characterized by an activation temperature of 787.782 ℃, an activation duration of 286.235 minutes, a heating rate of 14.239 ℃/min,, and an activation pressure of 5.002, is predicted by the surrogate model to yield an ammonia concentration of 730.43 ppm.Importantly, while this point is indeed suggested based on the algorithm's current understanding of the chemical space, its effectiveness, and true performance remain to be validated through further experimental testing.</p>
<p>Conclusion</p>
<p>In conclusion, the AI workflow proposed for catalyst synthesis optimization represents a compelling intersection of advanced language understanding, Bayesian optimization, and an active learning loop.ChatGPT, as a representative Large language model, has been used to construct a comprehensive and multidimensional search space.We then employed Bayesian optimization for effective multi-objective optimization within this space.Together, these methods demonstrated the potential to streamline the design and synthesis process for new catalysts.</p>
<p>In practical terms, this study has revealed substantial insights into catalyst synthesis for ammonia productiona burgeoning area of clean energy research.Through our analysis of 603 articles on ammonia synthesis catalysts, we have illuminated the significant role of factors such as Activation Pressure, Activation Duration, Activation Temperature, and Heating Rate in the synthesis process.</p>
<p>We have also showcased the expansive nature of the catalyst and procedural steps used in ammonia synthesis, reflecting the potential of our methodology to accommodate a diverse range of catalysts and synthesis processes.The practical implications of our work extend far beyond the mere understanding of catalyst design and synthesis.Our results have given us unique insights into the optimization of the ammonia production process.The Bayesian optimization algorithm proposed a set of conditions that, according to the GP surrogate model, and EI as an acquisition function, could result in an enhanced ammonia concentration.Specifically, the model suggested a combination of the parameters, forecasting an ammonia concentration of 730.43 ppm.This prediction, while yet to be verified experimentally, underscores the potential of AI-driven methods in guiding future experimental design.</p>
<p>While this study marks a considerable advancement in utilizing AI for catalyst synthesis, it is imperative to acknowledge the potential challenges and limitations encountered in the current framework.Future work should look at the reliability of published data, which forms the foundation of the LLM model.Any inconsistencies in data could potentially affect the output.</p>
<p>Therefore, validations should be made beyond the domain knowledge of the chemist.In addition, there is a clear necessity to expand the AI workflow to deal with multi-objective optimization problems that are frequently encountered in catalyst synthesis.This expansion should also include the ability to handle categorical input parameters, a feature critical for navigating the complexity of chemical spaces.Nevertheless, the AI workflow showcased in this study is a substantial leap forward in the quest for streamlined catalyst design.By effectively distilling insights from an extensive corpus of literature, this workflow demonstrates the potential of AI to supplement, if not replace, the domain knowledge traditionally required in this field.As we venture further into the era of clean energy, AI stands poised to play an increasingly prominent role in catalyzing advancements in catalyst synthesis and beyond.</p>
<p>Looking ahead, our goal is to evolve this AI workflow into an automatic loop capable of performing smart synthesis of new catalysts.This would leverage the power of the iterative active learning process coupled with the usage of large language models like ChatGPT.In this envisioned framework, once an initial set of parameters and a target objective are defined, the system would autonomously navigate through multiple iterations of experimentation and learning.At each stage, the AI system would analyze the outcomes of past iterations, discern trends and correlations, and generate predictions for the next most promising sets of parameters to test.This is where the integration of large language models comes into play.By constantly ingesting new scientific literature and research findings in real-time, the AI system could continually expand its knowledge base and refine its understanding of the catalyst synthesis process.This continual learning would allow the system to make increasingly informed and sophisticated decisions about the direction of experimentation, effectively "learning" its way toward optimal synthesis parameters.With such a system in place, the optimization process becomes a continual, autonomous loop of learning and refining, capable of swiftly identifying optimal catalyst synthesis strategies.This could substantially accelerate the discovery of novel catalysts and streamline their deployment in addressing our global energy challenges.</p>
<p>Figure 1 .
1
Figure 1.Schematic diagram of the proposed AI-driven workflow for catalyst synthesis optimization.</p>
<p>Figure 2 .
2
Figure 2. Process flow diagram of information extraction</p>
<p>|</p>
<p>Catalyst Name | Specific Procedure Step/Method | Process Variable | Numeric Value | Unit | | ZnCrOx and MnZnCrOx | Co-precipitation method | Temperature | 343 | K | | ZnCrOx and MnZnCrOx | Co-precipitation method | Duration | 30 | min | | ZnCrOx and MnZnCrOx | Co-precipitation method | pH | 8 | | | ZnCrOx and MnZnCrOx | Co-precipitation method | Aging | 3 | h | | ZnCrOx and MnZnCrOx | Co-precipitation method | Calcination temperature | 500 | °C | | MnZnCrOx | Addition of Mn(NO3)2 aqueous solution | Mass of Mn(NO3)2 | 0.26 | g | | MnZnCrOx | Addition of Mn(NO3)2 aqueous solution | Concentration of Mn(NO3)2 solution | 50 | wt% | | ZSM-5 zeolite | Hydrothermal method | Temperature | 180 | °C | | ZSM-5 zeolite | Hydrothermal method | Duration | 48 | h | | ZSM-5 zeolite | Hydrothermal method | Calcination temperature | 550 | °C | | OX-ZEO catalysts | Dual-bed mixing method | Mass ratio of oxide/zeolite | 1 | | | OX-ZEO catalysts | Granule mixing method | Mass ratio of oxide/zeolite | 1 | | | OX-ZEO catalysts | Powder mixing method | Mixing duration | 30 | min | | OX-ZEO catalysts | Powder mixing method | Pellet size | 20-40 | mesh |" 2.1.3.Conceptual Mapping of Extracted Information</p>
<p>Figure 3 .
3
Figure 3. Detailed depiction of the Bayesian optimization loop utilized within the proposed AI workflow.</p>
<p>σ 2 is the signal variance and ℓ is the length scale.Kernel emerged as the optimal choice for this particular catalyst synthesis optimization issue, striking an effective balance between model adaptability and computational efficiency.The Matern 5/2 kernel, with its intermediate level of smoothness, tends to perform well in practice, especially when handling noisy data or navigating high-dimensional search spaces.The parameter ν = 0.5, 1.5, 2.5 determines the smoothness of the function.The ν = 0.5 case corresponds to an absolute exponential (Laplace) kernel, representing a very non-smooth process.On the other end, infinity corresponds to the Radial Basis Function (RBF) kernel, representing an infinitely smooth process.The other two cases (ν = 1.5 and ν = 2.5) offer a balance between smoothness and flexibility, with the Matérn ν = 2.5 kernel being particularly highlighted due to its robustness in handling noisy data and highdimensional spaces.</p>
<p>weigh 5 .
5
8026 g of Co(NO 3 ) 2 • 6H 2 O and 4.8390 g of NaMoO 4 • 2H 2 O .Each is dissolved separately in 60 mL of deionized water, then stirred for 5 minutes at a speed of 500 rpm.Following this, the two solutions are combined and stirred continuously for an additional 10 minutes at the same speed.The mixed solution is then transferred into two 100 mL hydrothermal kettles, each containing approximately 60 mL of the solution.Place the hydrothermal kettles in a blast drying oven to undergo a hydrothermal reaction at 160 °C for 6 hours.Remove the kettles once they have completely cooled.The precipitate slurry obtained from the hydrothermal kettles is subjected to solid-liquid separation using a centrifuge operating at 5000 rpm for 5 minutes.Following centrifugation, discard the supernatant and add a certain amount of deionized water to mix evenly with the precipitate at the bottom of the centrifuge tube.Disperse ultrasonically for 5 minutes to thoroughly wash the precipitate before centrifuging again.Repeat this washing step three times.Transfer the thoroughly washed precipitate into a blast drying oven and dry for 12 hours at a set temperature of 100 °C.After drying, grind the violet blocky solid into a powder.Transfer this powder into a crucible for calcination in a muffle furnace at 450 °C for 6 hours, with a heating rate of 10 °C/min.After calcination, allow it to cool naturally to room temperature in the open air to obtain a light violet catalyst powder.Transfer the solid from the crucible to a sample bottle, marking the completion of the catalyst precursor preparation.</p>
<p>Figure 4
4
Figure4showcases the multi-stage synthesis process of the CoMo bimetallic nitride catalyst.Each phase, marked by distinct parameters illustrated in the figure, holds a role in determining the overall catalyst performance, albeit not equally.It should be noted that while there are other parameters influencing the synthesis process, including those at the hydrothermal stage, we strategically elected to focus on the activation step because modifying parameters in the hydrothermal stage generally necessitates a substantially extended timeframe to observe the resultant activity alterations, from several days to weeks.Consequently, it induces an exponential increase in both time and material costs.the activation step is where nitride is incorporated into the catalyst, a process in determining the structure of the resultant catalyst.The parameters chosen for optimization in our study are intrinsically linked to the control of this nitride introduction process, thereby holding a direct influence over the catalyst's final structure.</p>
<p>Figure 4 .
4
Figure 4. Schematic diagram illustrating the multi-stage Co 3 Mo 3 N(CMN) catalyst synthesis process for ammonia production.</p>
<p>Figure 5 .
5
Figure 5. Statistical analysis of catalyst synthesis parameters collected from the literature</p>
<p>Figure 6 .
6
Figure 6.Pairwise distribution of four critical parameters: Activation Pressure (MPa), Activation Duration (mins), Heating Rate (°C/min), and Activation Temperature (°C) visualized through two sampling strategies: Random Sampling (RS, teal) and Latin Hypercube Sampling (LHS, blue).</p>
<p>Figure 7 .
7
Figure 7. a.The Surrogate model's initial state incorporates just a few data points.b.Transitions to a later stage in the optimization process, where the model has been refined by a significantly larger set of data points.c.Suggested optimal point as indicated by the Bayesian optimization algorithm, along with the set of experimental data points obtained thus far.</p>
<p>Table 1
1
Frequency of Catalyst Names Extracted by ChatGPT from Literature
Catalyst Name</p>
<p>Table 2
2
Frequency of Procedure Steps Extracted by ChatGPT from Literature
Procedure Step
ACKNOWLEDGEMENTThis work is supported by the National Key R&amp;D Program of China (No. 2022ZD0117501).
. J S Hargreaves, L Li, Heterogeneous Catalysis for Sustainable Energy</p>
<p>A statistical review of considerations on the implementation path of China's "double carbon" goal. Sustainability. J Hao, L Chen, N Zhang, 20221411274</p>
<p>A quantitative roadmap for China towards carbon neutrality in 2060 using methanol and ammonia as energy carriers. Y Li, S Lan, M Ryberg, J Pérez-Ramírez, X Wang, Iscience. 2021624</p>
<p>The past, present and future of heterogeneous catalysis. I Fechete, Y Wang, J C Védrine, Catalysis Today. 18912012</p>
<p>Handbook of heterogeneous catalysis. G Ertl, H Knözinger, J Weitkamp, 1997VCH Weinheim</p>
<p>Innovation in process development: From catalyst to industrial process. J.-F Joly, F Giroudière, F Bertoncini, Catalysis today. 2182013</p>
<p>Developing Catalysts via Structure-Property Relations Discovered by Machine Learning: An Industrial Perspective. H Joshi, N Wilde, T S Asche, D Wolf, Chemie Ingenieur Technik. 202211</p>
<p>Bayesian optimization of high-entropy alloy compositions for electrocatalytic oxygen reduction. J K Pedersen, C M Clausen, O A Krysiak, B Xiao, T A Batchelor, T Löffler, V A Mints, L Banko, M Arenz, A Savan, Angewandte Chemie. 202145</p>
<p>Dynamic programming. R Bellman, Science. 15337311966</p>
<p>AlphaFlow: autonomous discovery and optimization of multi-step chemistry using a self-driven fluidic lab guided by reinforcement learning. A A Volk, R W Epps, D T Yonemoto, B S Masters, F N Castellano, K G Reyes, M Abolhasani, Nature Communications. 202311403</p>
<p>Microscale high-throughput experimentation as an enabling technology in drug discovery: Application in the discovery of (Piperidinyl) pyridinyl-1 H-benzimidazole diacylglycerol acyltransferase 1 inhibitors. T Cernak, N J Gesmundo, K Dykstra, Y Yu, Z Wu, Z.-C Shi, P Vachal, D Sperbeck, S He, B A Murphy, Journal of Medicinal Chemistry. 6092017</p>
<p>Chimera: enabling hierarchy based multi-objective optimization for self-driving laboratories. F Häse, L M Roch, A Aspuru-Guzik, Chemical science. 9392018</p>
<p>DOE (design of experiments) in development chemistry: Potential obstacles. D Lendrem, M Owen, S Godbert, Organic Process Research &amp; Development. 532001</p>
<p>A Brief Introduction to Chemical Reaction Optimization. C J Taylor, A Pomberger, K C Felton, R Grainger, M Barecka, T W Chamberlain, R A Bourne, C N Johnson, A A Lapkin, Chemical Reviews. 20236</p>
<p>Efficiency by design: optimisation in process research. M R Owen, C Luscombe, S Lai; Godbert, D L Crookes, D Emiabata-Smith, Organic Process Research &amp; Development. 532001</p>
<p>. R Panday, Modeling, </p>
<p>Stability of micro dry wire EDM: OFAT and DOE method. A Banu, M Y Ali, M A Rahman, M Konneh, The International Journal of Advanced Manufacturing Technology. 1062020</p>
<p>Machine learning: the new AI. E Alpaydin, 2016MIT press</p>
<p>Machine-learning atomic simulation for heterogeneous catalysis. D Chen, C Shang, Z.-P Liu, npj Computational Materials. 20231</p>
<p>Practical bayesian optimization of machine learning algorithms. J Snoek, H Larochelle, R P Adams, 201225Advances in neural information processing systems</p>
<p>Bayesian optimization. R Garnett, </p>
<p>Towards the computational design of solid catalysts. J K Nørskov, T Bligaard, J Rossmeisl, C H Christensen, Nature chemistry. 112009</p>
<p>Exploring the Optimal Alloy for Nitrogen Activation by Combining Bayesian Optimization with Density Functional Theory Calculations. K Okazawa, Y Tsuji, K Kurino, M Yoshida, Y Amamoto, K Yoshizawa, ACS omega. 202249</p>
<p>W X Zhao, K Zhou, J Li, T Tang, X Wang, Y Hou, Y Min, B Zhang, J Zhang, Z Dong, arXiv [cs.CL] 2023A Survey of Large Language Models. </p>
<p>. Introducing Openai, Chatgpt, 2022. 2023 2023-06-25</p>
<p>Is GPT-3 all you need for low-data discovery in chemistry? ChemRxiv Theoretical and Computational Chemistry. K M Jablonka, P Schwaller, A Ortega-Guerrero, B Smit, 10.26434/chemrxiv-2023-fw8n42023-05-16</p>
<p>Empowering Molecule Discovery for Molecule-Caption Translation with Large Language Models: A ChatGPT Perspective. J Li, Y Liu, W Fan, X.-Y Wei, H Liu, J Tang, Q Li, arXiv [cs.CL] 2023</p>
<p>Neo4j graph database realizes efficient storage performance of oilfield ontology. F Gong, Y Ma, W Gong, X Li, C Li, X Yuan, 10.1371/journal.pone.0207595PLOS ONE. 1311e02075952018-11-16. 2023-05-20</p>
<p>A multi-objective active learning platform and web app for reaction optimization. J A G Torres, S H Lau, P Anchuri, J M Stevens, J E Tabora, J Li, A Borovika, R P Adams, A G Doyle, 10.1021/jacs.2c08592Journal of the American Chemical Society. 144432022-11-02</p>
<p>Bayesian optimization for adaptive experimental design: A review. S Greenhill, S Rana, S Gupta, P Vellanki, S Venkatesh, IEEE. 2020</p>
<p>Bayesian reaction optimization as a tool for chemical synthesis. B J Shields, J Stevens, J Li, M Parasram, F Damani, J I M Alvarado, J M Janey, R P Adams, A G Doyle, 10.1038/s41586-021-03213-yNature. 20217844</p>
<p>Multi-objective materials bayesian optimization with active learning of design constraints: Design of ductile refractory multiprincipal-element alloys. D Khatamsaz, B Vela, P Singh, D D Johnson, D Allaire, R Arróyave, Acta Materialia. 2361181332022</p>
<p>On Latin hypercube sampling. The annals of statistics. W.-L Loh, 199624</p>
<p>Large sample properties of simulations using Latin hypercube sampling. M Stein, Technometrics. 2921987</p>
<p>Gaussian processes for machine learning. M Seeger, 200414International journal of neural systems</p>
<p>Bayesian optimisation over multiple continuous and categorical inputs. B Ru, A Alvi, V Nguyen, M A Osborne, S Roberts, International Conference on Machine Learning. 2020PMLR</p>
<p>Dealing with categorical and integer-valued variables in bayesian optimization with gaussian processes. E C Garrido-Merchán, D Hernández-Lobato, Neurocomputing. 3802020</p>
<p>Equipping data-driven experiment planning for Self-driving Laboratories with semantic memory: case studies of transfer learning in chemical reaction optimization. R J Hickman, J Ruža, H Tribukait, L M Roch, A García-Durán, Reaction Chemistry &amp; Engineering. 2023</p>
<p>The effect of chemical representation on active machine learning towards closed-loop optimization. A Pomberger, A P Mccarthy, A Khan, S Sung, C Taylor, M Gaunt, L Colwell, D Walz, A Lapkin, Reaction Chemistry &amp; Engineering. 20226</p>
<p>Fast calculation of multiobjective probability of improvement and expected improvement criteria for Pareto optimization. I Couckuyt, D Deschrijver, T Dhaene, Journal of Global Optimization. 602014</p>
<p>A review of multi-objective optimization: Methods and its applications. N Gunantara, Cogent Engineering. 5115022422018</p>
<p>Parallel bayesian optimization of multiple noisy objectives with expected hypervolume improvement. S Daulton, M Balandat, E Bakshy, Advances in Neural Information Processing Systems. 202134</p>
<p>Differentiable expected hypervolume improvement for parallel multi-objective Bayesian optimization. S Daulton, M Balandat, E Bakshy, Advances in Neural Information Processing Systems. 202033</p>
<p>Bayesian optimization with active learning of design constraints using an entropy-based approach. D Khatamsaz, B Vela, P Singh, D D Johnson, D Allaire, R Arróyave, Computational Materials. 2023149</p>
<p>Vacancy-enabled N2 activation for ammonia synthesis on an Ni-loaded catalyst. T.-N Ye, S.-W Park, Y Lu, J Li, M Sasase, M Kitano, T Tada, H Hosono, Nature. 20207816</p>
<p>Development and recent progress on ammonia synthesis catalysts for Haber-Bosch process. J Humphreys, R Lan, S Tao, Advanced Energy and Sustainability Research. 202112000043</p>
<p>Dual functionalized interstitial N atoms in Co3Mo3N enabling CO2 activation. K Feng, J Tian, J Zhang, Z Li, Y Chen, K H Luo, B Yang, B Yan, ACS Catalysis. 20228</p>            </div>
        </div>

    </div>
</body>
</html>