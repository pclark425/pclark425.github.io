<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3493 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3493</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3493</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-78.html">extraction-schema-78</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-c28e95a06dfcf13fc65a1cac83722f53e34f12a5</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/c28e95a06dfcf13fc65a1cac83722f53e34f12a5" target="_blank">Autoformalization with Large Language Models</a></p>
                <p><strong>Paper Venue:</strong> Neural Information Processing Systems</p>
                <p><strong>Paper TL;DR:</strong> It is shown large language models provide new prospects towards the long-term goal of autoformalization, and the surprising observation that LLMs can correctly translate a significant portion of mathematical competition problems perfectly to formal specifications in Isabelle/HOL.</p>
                <p><strong>Paper Abstract:</strong> Autoformalization is the process of automatically translating from natural language mathematics to formal specifications and proofs. A successful autoformalization system could advance the fields of formal verification, program synthesis, and artificial intelligence. While the long-term goal of autoformalization seemed elusive for a long time, we show large language models provide new prospects towards this goal. We make the surprising observation that LLMs can correctly translate a significant portion ($25.3\%$) of mathematical competition problems perfectly to formal specifications in Isabelle/HOL. We demonstrate the usefulness of this process by improving a previously introduced neural theorem prover via training on these autoformalized theorems. Our methodology results in a new state-of-the-art result on the MiniF2F theorem proving benchmark, improving the proof rate from $29.6\%$ to $35.2\%$.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3493.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3493.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Codex (autoformalization)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Codex (OpenAI) used for autoformalization to Isabelle/HOL</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Codex is a large code-trained language model used in this paper to translate natural-language mathematical competition problems into formal Isabelle/HOL statements; outputs were evaluated by BLEU, manual inspection, and used to generate corpora for neural proof search.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autoformalization with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Codex</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A large language model trained on code and text (described in Chen et al., 2021). In this work Codex is used with greedy decoding to generate Isabelle/HOL formalizations from natural-language mathematics prompts and to informalize Isabelle statements.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Autoformalization to Isabelle/HOL (translation) and generation of formal theorem statements for downstream proof search</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Translate natural-language mathematical problem statements (from MATH / miniF2F) into formal Isabelle/HOL theorem statements (syntactic/formal alignment). Generated statements were then used as targets for automated proof search (neural theorem proving) on theorem-proving benchmarks (e.g., miniF2F).</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Few-shot in-context prompting with two- or ten-example prompts (subject-specific prompts), greedy decoding (temperature 0), and use of the generated corpus as training targets for expert-iteration fine-tuning of a neural prover; Codex outputs were filtered by syntactic correctness before use.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>BLEU (compared to human formalizations) -- algebra: 57.13 BLEU; number_theory: 43.33 BLEU. Human-evaluated perfect formalizations: 38/150 = 25.3% perfect translations. From a pool of 3,908 Codex-autoformalized problems, 3,363 were syntactically correct (86.0%).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>Codex produced higher BLEU scores than PaLM variants (see PaLM entry), and provided the autoformalized dataset that enabled neural prover improvements (see Thor entry). Quantitatively, Codex BLEU exceeded PaLM 540B on the reported subjects.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Common failure modes: misalignment of informal and formal definitions (e.g., "greatest possible value" not mapped to Isabelle's Greatest/Max), wrong naming of concepts (inventing names like linear f), syntactic/type errors, inconsistent or missing assumptions, missing definitions in Isabelle, wrong application of functions, and other miscellaneous errors. In advanced mathematics Codex sometimes misinterprets notation (e.g., confusing products of sets vs. products of topological spaces). Overall formalization success low relative to informalization (25% formalization vs 76% reasonable informalization).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Human case-study and failure-mode analysis (Table 2) performed on 150 Codex translations; Codex outperformed PaLM on BLEU, possibly due to more formal-data in its training corpus. The authors attempted web searches to rule out memorization of specific formalizations. No controlled ablation (e.g., varying decoding temperature) beyond model-scale and prompt composition analyses reported for this model.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Autoformalization with Large Language Models', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3493.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3493.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PaLM (autoformalization, 3 scales)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PaLM (Pathways Language Model) at multiple parameter scales (8B, 64B, 540B) used for autoformalization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PaLM models of varying sizes were evaluated for translating natural-language math problems into Isabelle/HOL; model scale strongly affected translation quality and syntactic correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autoformalization with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PaLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>PaLM is a Pathways-trained large transformer language model family; in this work three sizes were probed (8B, 64B, 540B) using few-shot in-context prompts to generate Isabelle/HOL formalizations.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>8B / 64B / 540B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Autoformalization to Isabelle/HOL (translation) from MATH / miniF2F problems</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Translate natural-language competition math problems into formal statements usable by the Isabelle theorem prover; requires mapping informal mathematical language and conventions to precise formal constructs and types.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Few-shot in-context prompting (subject-specific prompts built from randomly sampled problems; 10-shot for each subject in BLEU experiments), greedy decoding (temperature 0). No fine-tuning; relied on in-context learning and model scale.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>BLEU scores (compared to human formalizations): PaLM 8B -- algebra: 31.49, number_theory: 22.10; PaLM 64B -- algebra: 43.13, number_theory: 31.43; PaLM 540B -- algebra: 50.30, number_theory: 36.16. Case studies: PaLM 540B succeeded on some problems where smaller PaLMs failed (e.g., grade-school modulus problem).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>Clear scaling trend: BLEU improves substantially with model size (8B -> 64B -> 540B). Codex still outperformed PaLM 540B on reported BLEU numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Smaller PaLM models (8B, 64B) produced many syntactic or semantic errors; common failures mirror Codex: misalignment of definitions, syntactic/type errors, incorrect or missing assumptions. The model struggles when background definitions are absent or the prompt lacks relevant exemplars (Case study 3 showed adding a tangential prompt example enabling correct formalization of a "linear function").</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Analysis highlights a strong scale effect and sensitivity to prompt examples: adding relevant few-shot exemplars improved performance on subject-specific problems; no formal ablation studies beyond size and example selection reported. The paper includes qualitative case studies demonstrating how prompts influence success.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Autoformalization with Large Language Models', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3493.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3493.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Thor + Expert Iteration (neural theorem proving)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Thor neural theorem prover (GPT-2-style 700M LM) used with expert-iteration training on autoformalized theorems</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Thor is a neural theorem-proving agent (decoder-only transformer ~700M parameters) fine-tuned for predicting proof steps in Isabelle/HOL; in this work Thor is iteratively improved by proof-search on autoformalized statements and fine-tuning on successfully found proofs (expert iteration), yielding state-of-the-art results on the miniF2F benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autoformalization with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Thor (GPT-2-style backbone)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A transformer decoder-only language model (24 layers, 24 heads, hidden dim 1536, ~700M non-embedding parameters) pre-trained on GitHub+arXiv subsets of The Pile and fine-tuned on Isabelle proof steps (PISA dataset); during inference it predicts next proof steps and can emit a special <hammer> token to invoke Sledgehammer (external ATP) with timeout.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>700M</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Automated theorem proving / proof search on the miniF2F benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Given formalized Isabelle/HOL problems (miniF2F), perform proof search to find machine-checkable proofs; this is strict formal logical reasoning within higher-order logic, combining neural prediction of tactics/steps and selective invocation of automated tactics (Sledgehammer).</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Expert iteration: (1) use base prover M0 to attempt proofs on a large set of autoformalized problems (generated by Codex), (2) collect successful proofs S_i, (3) augment training data with S_i and fine-tune base model for one epoch to produce M_i, (4) repeat; best-first search for proof search, deduplication of successful proofs by statement, special <hammer> token to trigger Sledgehammer, and fine-tuning on PISA + newly found proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>miniF2F success rates (validation / test): Base model M0 -- 28.3% / 29.9% (this work's checkpoint); After 1 expert iteration (M1) -- 36.1% / 34.0%; After 2 iterations (M2) -- 37.3% / 35.2% (state-of-the-art reported in paper). On the autoformalized dataset (3363 syntactically correct problems), M0 proved 782 (23.3%), M1 proved 1011 (30.1%) in second iteration runs.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Prior reported baselines on miniF2F: PACT -- valid 23.9% / test 24.6%; FMSCL -- valid 33.6% / test 29.6%; the base Thor M0 in this work: valid 28.3% / test 29.9%.</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>Expert iteration on autoformalized theorems improved test success from M0 29.9% to M2 35.2% (absolute +5.3 percentage points over M0), surpassing previous best FMSCL (29.6% test) by 5.6 percentage points. The first iteration produced the largest gain (+4.1 pp test), second iteration added +1.2 pp.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Dependence on quality and syntactic correctness of autoformalized statements (only 3,363/3,908 Codex outputs were syntactically correct). Resource-intensive: large TPU usage and many CPU cores for Isabelle; limited by context window and inability to formalize large theories end-to-end without additional methods. Neural prover improvements rely on the autoformalized corpus and assembler mechanics (deduplication, one-epoch fine-tuning), so systemic errors in autoformalization can limit gains. The approach may not generalize to very advanced mathematics because of missing contextual definitions and the LLMs' context/window limits.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Empirical analysis shows that adding verified proofs found via proof search into training (expert iteration) yields consistent improvements; the majority of gains come from the first iteration. No detailed ablation isolating individual components (e.g., <hammer> vs. no <hammer>, or different search algorithms) is reported beyond the multi-iteration expert-iteration procedure. The authors also provide an analysis of computational costs (TPU hours breakdown).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Autoformalization with Large Language Models', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Evaluating large language models trained on code <em>(Rating: 2)</em></li>
                <li>PaLM: Scaling language modeling with pathways <em>(Rating: 2)</em></li>
                <li>Generative language modeling for automated theorem proving <em>(Rating: 2)</em></li>
                <li>MiniF2F: a cross-system benchmark for formal olympiad-level mathematics <em>(Rating: 2)</em></li>
                <li>Thor: Wielding hammers to integrate language models and automated theorem provers <em>(Rating: 2)</em></li>
                <li>Formal mathematics statement curriculum learning <em>(Rating: 2)</em></li>
                <li>Language models are few-shot learners <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3493",
    "paper_id": "paper-c28e95a06dfcf13fc65a1cac83722f53e34f12a5",
    "extraction_schema_id": "extraction-schema-78",
    "extracted_data": [
        {
            "name_short": "Codex (autoformalization)",
            "name_full": "Codex (OpenAI) used for autoformalization to Isabelle/HOL",
            "brief_description": "Codex is a large code-trained language model used in this paper to translate natural-language mathematical competition problems into formal Isabelle/HOL statements; outputs were evaluated by BLEU, manual inspection, and used to generate corpora for neural proof search.",
            "citation_title": "Autoformalization with Large Language Models",
            "mention_or_use": "use",
            "model_name": "Codex",
            "model_description": "A large language model trained on code and text (described in Chen et al., 2021). In this work Codex is used with greedy decoding to generate Isabelle/HOL formalizations from natural-language mathematics prompts and to informalize Isabelle statements.",
            "model_size": null,
            "reasoning_task_name": "Autoformalization to Isabelle/HOL (translation) and generation of formal theorem statements for downstream proof search",
            "reasoning_task_description": "Translate natural-language mathematical problem statements (from MATH / miniF2F) into formal Isabelle/HOL theorem statements (syntactic/formal alignment). Generated statements were then used as targets for automated proof search (neural theorem proving) on theorem-proving benchmarks (e.g., miniF2F).",
            "method_or_intervention": "Few-shot in-context prompting with two- or ten-example prompts (subject-specific prompts), greedy decoding (temperature 0), and use of the generated corpus as training targets for expert-iteration fine-tuning of a neural prover; Codex outputs were filtered by syntactic correctness before use.",
            "performance": "BLEU (compared to human formalizations) -- algebra: 57.13 BLEU; number_theory: 43.33 BLEU. Human-evaluated perfect formalizations: 38/150 = 25.3% perfect translations. From a pool of 3,908 Codex-autoformalized problems, 3,363 were syntactically correct (86.0%).",
            "baseline_performance": null,
            "improvement_over_baseline": "Codex produced higher BLEU scores than PaLM variants (see PaLM entry), and provided the autoformalized dataset that enabled neural prover improvements (see Thor entry). Quantitatively, Codex BLEU exceeded PaLM 540B on the reported subjects.",
            "limitations_or_failures": "Common failure modes: misalignment of informal and formal definitions (e.g., \"greatest possible value\" not mapped to Isabelle's Greatest/Max), wrong naming of concepts (inventing names like linear f), syntactic/type errors, inconsistent or missing assumptions, missing definitions in Isabelle, wrong application of functions, and other miscellaneous errors. In advanced mathematics Codex sometimes misinterprets notation (e.g., confusing products of sets vs. products of topological spaces). Overall formalization success low relative to informalization (25% formalization vs 76% reasonable informalization).",
            "ablation_or_analysis": "Human case-study and failure-mode analysis (Table 2) performed on 150 Codex translations; Codex outperformed PaLM on BLEU, possibly due to more formal-data in its training corpus. The authors attempted web searches to rule out memorization of specific formalizations. No controlled ablation (e.g., varying decoding temperature) beyond model-scale and prompt composition analyses reported for this model.",
            "uuid": "e3493.0",
            "source_info": {
                "paper_title": "Autoformalization with Large Language Models",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "PaLM (autoformalization, 3 scales)",
            "name_full": "PaLM (Pathways Language Model) at multiple parameter scales (8B, 64B, 540B) used for autoformalization",
            "brief_description": "PaLM models of varying sizes were evaluated for translating natural-language math problems into Isabelle/HOL; model scale strongly affected translation quality and syntactic correctness.",
            "citation_title": "Autoformalization with Large Language Models",
            "mention_or_use": "use",
            "model_name": "PaLM",
            "model_description": "PaLM is a Pathways-trained large transformer language model family; in this work three sizes were probed (8B, 64B, 540B) using few-shot in-context prompts to generate Isabelle/HOL formalizations.",
            "model_size": "8B / 64B / 540B",
            "reasoning_task_name": "Autoformalization to Isabelle/HOL (translation) from MATH / miniF2F problems",
            "reasoning_task_description": "Translate natural-language competition math problems into formal statements usable by the Isabelle theorem prover; requires mapping informal mathematical language and conventions to precise formal constructs and types.",
            "method_or_intervention": "Few-shot in-context prompting (subject-specific prompts built from randomly sampled problems; 10-shot for each subject in BLEU experiments), greedy decoding (temperature 0). No fine-tuning; relied on in-context learning and model scale.",
            "performance": "BLEU scores (compared to human formalizations): PaLM 8B -- algebra: 31.49, number_theory: 22.10; PaLM 64B -- algebra: 43.13, number_theory: 31.43; PaLM 540B -- algebra: 50.30, number_theory: 36.16. Case studies: PaLM 540B succeeded on some problems where smaller PaLMs failed (e.g., grade-school modulus problem).",
            "baseline_performance": null,
            "improvement_over_baseline": "Clear scaling trend: BLEU improves substantially with model size (8B -&gt; 64B -&gt; 540B). Codex still outperformed PaLM 540B on reported BLEU numbers.",
            "limitations_or_failures": "Smaller PaLM models (8B, 64B) produced many syntactic or semantic errors; common failures mirror Codex: misalignment of definitions, syntactic/type errors, incorrect or missing assumptions. The model struggles when background definitions are absent or the prompt lacks relevant exemplars (Case study 3 showed adding a tangential prompt example enabling correct formalization of a \"linear function\").",
            "ablation_or_analysis": "Analysis highlights a strong scale effect and sensitivity to prompt examples: adding relevant few-shot exemplars improved performance on subject-specific problems; no formal ablation studies beyond size and example selection reported. The paper includes qualitative case studies demonstrating how prompts influence success.",
            "uuid": "e3493.1",
            "source_info": {
                "paper_title": "Autoformalization with Large Language Models",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "Thor + Expert Iteration (neural theorem proving)",
            "name_full": "Thor neural theorem prover (GPT-2-style 700M LM) used with expert-iteration training on autoformalized theorems",
            "brief_description": "Thor is a neural theorem-proving agent (decoder-only transformer ~700M parameters) fine-tuned for predicting proof steps in Isabelle/HOL; in this work Thor is iteratively improved by proof-search on autoformalized statements and fine-tuning on successfully found proofs (expert iteration), yielding state-of-the-art results on the miniF2F benchmark.",
            "citation_title": "Autoformalization with Large Language Models",
            "mention_or_use": "use",
            "model_name": "Thor (GPT-2-style backbone)",
            "model_description": "A transformer decoder-only language model (24 layers, 24 heads, hidden dim 1536, ~700M non-embedding parameters) pre-trained on GitHub+arXiv subsets of The Pile and fine-tuned on Isabelle proof steps (PISA dataset); during inference it predicts next proof steps and can emit a special &lt;hammer&gt; token to invoke Sledgehammer (external ATP) with timeout.",
            "model_size": "700M",
            "reasoning_task_name": "Automated theorem proving / proof search on the miniF2F benchmark",
            "reasoning_task_description": "Given formalized Isabelle/HOL problems (miniF2F), perform proof search to find machine-checkable proofs; this is strict formal logical reasoning within higher-order logic, combining neural prediction of tactics/steps and selective invocation of automated tactics (Sledgehammer).",
            "method_or_intervention": "Expert iteration: (1) use base prover M0 to attempt proofs on a large set of autoformalized problems (generated by Codex), (2) collect successful proofs S_i, (3) augment training data with S_i and fine-tune base model for one epoch to produce M_i, (4) repeat; best-first search for proof search, deduplication of successful proofs by statement, special &lt;hammer&gt; token to trigger Sledgehammer, and fine-tuning on PISA + newly found proofs.",
            "performance": "miniF2F success rates (validation / test): Base model M0 -- 28.3% / 29.9% (this work's checkpoint); After 1 expert iteration (M1) -- 36.1% / 34.0%; After 2 iterations (M2) -- 37.3% / 35.2% (state-of-the-art reported in paper). On the autoformalized dataset (3363 syntactically correct problems), M0 proved 782 (23.3%), M1 proved 1011 (30.1%) in second iteration runs.",
            "baseline_performance": "Prior reported baselines on miniF2F: PACT -- valid 23.9% / test 24.6%; FMSCL -- valid 33.6% / test 29.6%; the base Thor M0 in this work: valid 28.3% / test 29.9%.",
            "improvement_over_baseline": "Expert iteration on autoformalized theorems improved test success from M0 29.9% to M2 35.2% (absolute +5.3 percentage points over M0), surpassing previous best FMSCL (29.6% test) by 5.6 percentage points. The first iteration produced the largest gain (+4.1 pp test), second iteration added +1.2 pp.",
            "limitations_or_failures": "Dependence on quality and syntactic correctness of autoformalized statements (only 3,363/3,908 Codex outputs were syntactically correct). Resource-intensive: large TPU usage and many CPU cores for Isabelle; limited by context window and inability to formalize large theories end-to-end without additional methods. Neural prover improvements rely on the autoformalized corpus and assembler mechanics (deduplication, one-epoch fine-tuning), so systemic errors in autoformalization can limit gains. The approach may not generalize to very advanced mathematics because of missing contextual definitions and the LLMs' context/window limits.",
            "ablation_or_analysis": "Empirical analysis shows that adding verified proofs found via proof search into training (expert iteration) yields consistent improvements; the majority of gains come from the first iteration. No detailed ablation isolating individual components (e.g., &lt;hammer&gt; vs. no &lt;hammer&gt;, or different search algorithms) is reported beyond the multi-iteration expert-iteration procedure. The authors also provide an analysis of computational costs (TPU hours breakdown).",
            "uuid": "e3493.2",
            "source_info": {
                "paper_title": "Autoformalization with Large Language Models",
                "publication_date_yy_mm": "2022-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Evaluating large language models trained on code",
            "rating": 2
        },
        {
            "paper_title": "PaLM: Scaling language modeling with pathways",
            "rating": 2
        },
        {
            "paper_title": "Generative language modeling for automated theorem proving",
            "rating": 2
        },
        {
            "paper_title": "MiniF2F: a cross-system benchmark for formal olympiad-level mathematics",
            "rating": 2
        },
        {
            "paper_title": "Thor: Wielding hammers to integrate language models and automated theorem provers",
            "rating": 2
        },
        {
            "paper_title": "Formal mathematics statement curriculum learning",
            "rating": 2
        },
        {
            "paper_title": "Language models are few-shot learners",
            "rating": 1
        }
    ],
    "cost": 0.01392975,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Autoformalization with Large Language Models</h1>
<p>Yuhuai $\mathbf{W u}^{1,2 \dagger} \quad$ Albert Q. Jiang ${ }^{3} \quad$ Wenda $\mathbf{L i}^{3}$<br>Markus N. Rabe ${ }^{1} \quad$ Charles Staats ${ }^{1} \quad$ Mateja Jamnik ${ }^{3} \quad$ Christian Szegedy ${ }^{1}$<br>${ }^{1}$ Google Research<br>${ }^{2}$ Stanford University<br>${ }^{3}$ University of Cambridge</p>
<h4>Abstract</h4>
<p>Autoformalization is the process of automatically translating from natural language mathematics to formal specifications and proofs. A successful autoformalization system could advance the fields of formal verification, program synthesis, and artificial intelligence. While the long-term goal of autoformalization seemed elusive for a long time, we show large language models provide new prospects towards this goal. We make the surprising observation that LLMs can correctly translate a significant portion ( $25.3 \%$ ) of mathematical competition problems perfectly to formal specifications in Isabelle/HOL. We demonstrate the usefulness of this process by improving a previously introduced neural theorem prover via training on these autoformalized theorems. Our methodology results in a new state-of-the-art result on the MiniF2F theorem proving benchmark, improving the proof rate from $29.6 \%$ to $35.2 \%$.</p>
<h2>1 Introduction</h2>
<p>Autoformalization refers to the task of automatically translating from natural language mathematics to a formal language [48, 44]. The implication of a successful autoformalization tool is huge in both practical and philosophical terms. It would reduce the currently excessive cost of formalization efforts [27], and in the long-term it could connect the various research fields that automate aspects of mathematical reasoning, such as automated theorem proving and computer algebra, to the vast body of mathematical knowledge exclusively written up in natural language. Moreover, autoformalization would be a true testament to machine understanding, grasping both the fuzziness of natural language and the preciseness of formal language.
Recent advances in large language models [7, 9] showed promising capabilities of understanding formal languages [8, 32]. However, the existing successes are limited to formal languages where there exists a large body of corpus on the web (e.g., Python language). Formal mathematics data is very scarce. For example, one of the largest formal mathematics libraries, the Archive of Formal Proofs, is only 180 MB in size, that is less than $0.18 \%$ of the training data for the large language model Codex [8]. Moreover, unlike in the case of commonly used programming languages, where natural language docstrings are broadly available, there is almost zero aligned data between natural language and formal mathematics. Therefore, it is unclear the recent successes can directly contribute to the development of autoformalization.</p>
<p>In this work, we explore the prospects of autoformalization with large language models. To our surprise, we find that large language models already have a decent capability of formalizing natural</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Case Study 1 Question:
"Prove that there is no function $f$ from the set of non-negative integers into itself such that $f(f(n))=n+1987$ for every $n$."</p>
<h1>Codex Output:</h1>
<p>theorem
fixes f : : "nat \<Rightarrow> nat"
assumes "\<forall>n.f (f n) $=n+1987$ "
shows False</p>
<p>Figure 1: Case study 1: An example of a perfect translation from natural language to Isabelle code.
language mathematics in an interactive theorem prover. See Figure 1 for a perfect autoformalization example. The model not only translates into syntactically correct Isabelle code, but also grasps the non-trivial reasoning in natural language. We randomly pick 150 formalizations and manually evaluate their correctness. Among them, LLMs are capable of producing 38 perfect formalizations! As an application, we further demonstrate that autoformalization can provide useful training data for neural theorem provers. We use autoformalized statements as targets for proof search with a neural theorem prover for Isabelle/HOL. After fine-tuning our neural theorem prover on the proofs it found, its success rate on the MiniF2F benchmark [54] increases significantly, achieving a new state-of-the-art result of 35.2\% theorems proven.</p>
<h2>2 Related Work</h2>
<p>Early applications of machine learning in theorem proving include the works by Schulz [42] and Urban [45], and later, directly guiding interactive proof assistants using machine learning techniques [14]. The revolution of deep learning then kicked off a new wave of interest in the topic starting with DeepMath [1, 33].
Several approaches have been suggested to address data scarcity: Imitation-free reinforcement learning was used to avoid the need for training on human proofs [31, 5, 14, 51]. Also, hindsight experience replay [2] was used to generate additional training data [4]. Hahn et al. [18], Schmitt et al. [41], Kreber \&amp; Hahn [29] and Wu et al. [52] have shown that training on synthetic formulas can be successful for temporal logics and inequalities. Rabe et al. [39] masked out different subexpressions from formal mathematical statements and generated 100 training examples for each source statement. Skip-tree data can also be used to improve the performance of neural theorem provers [21].
Wang et al. [48] explored the use of supervised and unsupervised translation techniques for autoformalization. Supervised translation yielded interesting results, but relied on synthetic (naturallooking) data that was generated by the Mizar theorem prover, while we rely on models trained via self-supervised language modeling, not trained for this particular purpose.</p>
<h2>3 Background</h2>
<p>Formal Mathematics A few important and complex results of mathematics and computer science have been formalized manually using interactive theorem provers, such as the four color theorem [15], the Kepler conjecture [19], the odd-order theorem [16] and the verification of a microkernel [27]. This gives us almost complete certainty about the correctness of proofs, which can be of great value to resolve doubt about the correctness of complicated mathematical proofs or proving certain properties of software used in safety-critical applications, such as aircraft components [28].
These projects relied on interactive theorem provers, such as Isabelle [50], Coq [11], HOL Light [22], and Lean [12], which are essentially programming languages that enable users to enter their statements and proofs in a formal language, and which can then be checked automatically for correctness. Interactive theorem provers offer a limited amount of automation, but projects that formalize complex problems typically span many years of tedious work by specialists. Only in narrow domains</p>
<p>like chip design and the verification of drivers in operating systems has the automation of logic made sufficient progress to find commercial applications.</p>
<p>Progress in autoformalization and the automation of proofs might eventually make mathematics a universally available tool and enable a paradigm shift in science and the development of (safetycritical) software. Our interest in formalizing mathematics, however, has an additional aspect. We believe that autoformalization will serve a dual purpose and will not only accelerate the development of tools for mathematical reasoning, but also provide a means to ground machine learning systems, enabling a positive feedback loop between machine learning and formal systems (cf. [44]).</p>
<p>Large Language Models Our work relies heavily on large language models (LLMs), in particular on PaLM [9] and Codex [8]. The training goal of these models is to predict the next word given some prefix. This allows us to train these models on arbitrary text, which is available in vast quantities. After training the models on hundreds of billions of words (cf. [24]), they are often able to generate high-quality text. We can also give these models an arbitrary prefix (the prompt) that they are then supposed to continue, which gives us some control over what they generate. This has been demonstrated with news articles, conversations, summaries, jokes, and poems. LLMs have also been evaluated on natural language word problems on datasets such as GSM8K [10] and MATH [23], and have been shown to make progress on these benchmarks with increasing scale [9].</p>
<p>In-context Learning Large language models have shown a remarkable ability to learn patterns and tasks within the current input (context) that they are given [7]: this is called in-context learning or few-shot learning. For example, if we prompt a language model with a few pairs of English and matching French sentences, and end with a new English sentence, then the language model is very likely to pick up on the translation task and attempt a translation of the last English sentence. This observation has been used, for example, to achieve strong translation performance without access to large corpora of matching sentence pairs [20].
This allows us to specify the task of autoformalization simply by giving a couple of example formalizations. In Section 4 we will detail how exactly we use in-context learning for autoformalization.</p>
<h1>4 Autoformalization for Mathematical Competition Problems</h1>
<p>Inspired by the success of LLMs for synthesizing computer code by co-training on both natural language and code on web-scale data, we explore the capabilities of LLMs to turn natural language mathematics into formalized theorems for the interactive theorem prover Isabelle. This can be seen as a machine translation task (cf. [49]) in which the input language is English and output language is formal code used by the interactive proof assistant Isabelle [50].
We first study autoformalization in a constrained setting - formalizing mathematical competition problem statements. This setting has the advantage that most of the required background theory and definition has been formalized in the current libraries of Isabelle, so that formalizations are often possible without introducing additional definitions.
We start assessing LLMs' abilities to do autoformalization with a case study. We manually pick two interesting natural language mathematical statements, and prompt PaLM models of various scales [9] as well as Codex [8] to translate them into a formal statement in Isabelle. Next, we study a dataset in which we have human ground truth formalizations. The dataset is a subset of the miniF2F [23] dataset consisting of 140 algebra problems and 120 number theory problems. Using human formalizations as the reference, we compute the BLEU scores of the formalizations produced by several LLMs. Lastly, we perform human evaluations on failure cases in autoformalization on 150 problems.</p>
<p>Note that many mathematical competition statements are often of the form in which one asks to find the answer to a certain problem, instead of proving a given proposition. However, formal mathematical statements are in the form of propositions, instead of questions. To transform a question into a proposition, we append the final answer after the question:
\$Problem_Statement The final answer is \$Answer.</p>
<p>Natural language version: "Let $z=\frac{1+j}{\sqrt{2}}$, find $\left(\sum_{i=1}^{1} 2\left(z^{i^{2}}\right)\right) \cdot\left(\sum_{i=1}^{1} 2\left(\frac{1}{z^{i^{2}}}\right)\right)$. The final answer is 36." Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes z::complex
    assumes h0: &quot;z = (Complex (1/sqrt 2) (1/sqrt 2))&quot;
    shows &quot;(\&lt;Sum&gt;k::nat=1..12. (z^(k^2)))
        <span class="k">*</span> (\&lt;Sum&gt; k::nat=1..12. 1/(z^(k^2)))=36&quot;
</code></pre></div>

<p>Natural language version: "Determine the value of $a b$ if $\log <em 4="4">{8} a+\log </em>=5$ and $\log } b^{2<em 4="4">{8} b+$ $\log </em>=7$. The final answer is 512". Translate the natural language version to an Isabelle version:} a^{2</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes a b ::real
    assumes &quot;(ln a) / (ln 8) + (ln (b^2)) / (ln 4) = 5&quot;
        &quot;(ln b) / (ln 8) + (ln (a^2)) / (ln 4) = 7&quot;
        shows &quot;a * b = 512&quot;
</code></pre></div>

<p>Figure 2: The two few-shot examplars used in case studies: both examples are merely an illustration of a syntactical translation from from $\mathrm{ET}_{\mathrm{E}} \mathrm{X}$ to Isabelle, without much sophistication in natural language understanding or reasoning.</p>
<p>The format of the prompt we use to do autoformalization is:
Natural language version: \$Natural_Language_Statement.
Translate the natural language version to an Isabelle version:</p>
<h1>4.1 Mathematical Competition Datasets</h1>
<p>MATH [23] contains in total 12,500 (7,500 training and 5,000 test) middle school and high school mathematical competition problems. Problems are taken from past mathematical competitions, including AMC 10, AMC 12, AIME, and more, and many can be found at http://aops.com/community/c3158_usa_contests. The dataset contains seven categories: algebra, pre-algebra, intermediate algebra, number_theory, precalculus, probability, geometry. Problem statements are written in LaTeX.
MiniF2F [54] is a recently introduced benchmark containing 488 mathematical competition statements manually formalized by humans in three different formal languages. Its goal is to compare and benchmark methods across different theorem provers for machine learning research. Some of these problems come from the valid and test set of MATH algebra and number_theory, and others come from previous International Mathematical Olympiad competitions or AoPS ${ }^{1}$. Note that the Isabelle formalizations of the miniF2F benchmark were committed to the repository during March, 2022. According to the public information on the large language models, we think it is highly unlikely these formalizations were included in the pre-training corpus.</p>
<h3>4.2 Case Studies</h3>
<p>Experimental setup For all our experiments, we use the standard greedy decoding (i.e., temperature $0, p=1$ ) to obtain the autoformalizations. We randomly select two mathematical statements for constructing the prompt. No prompt engineering / tuning is performed when constructing the prompt. The examples are shown in Figure 2. The natural language problem statements used in the case studies are taken from the miniF2F dataset. In the case studies below, we highlight the output of language models in red to distinguish it from the prompt.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<div class="codehilite"><pre><span></span><code><span class="nv">Case</span><span class="w"> </span><span class="nv">Study</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="nv">Question</span>:
<span class="nv">Natural</span><span class="w"> </span><span class="nv">Language</span><span class="w"> </span><span class="nv">version</span>:<span class="w"> </span><span class="err">&quot;When all</span>
<span class="err">the girls at Madeline&#39;s school line up</span>
<span class="err">in rows of eight, there are seven left</span>
<span class="err">over. If instead they line up in rows of</span>
<span class="err">four, how many are left over? The final</span>
<span class="nv">answer</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="mi">3</span>.<span class="err">&quot; Translate the natural lan-</span>
<span class="err">guage version to an Isabelle version:</span>
<span class="err">PaLM output:</span>
<span class="err">theorem</span>
<span class="err">    fixes n::nat</span>
<span class="w">    </span><span class="nv">assumes</span><span class="w"> </span><span class="s2">&quot;n mod 8 = 7&quot;</span>
<span class="w">    </span><span class="nv">shows</span><span class="w"> </span><span class="s2">&quot;n mod 4 = 3&quot;</span>
</code></pre></div>

<p>Case Study 3 Question:
Natural language version: "Let $f$ be a linear function for which $f(6)-f(2)=12$. What is $f(12)-f(2)$ ? The final answer is 30." Translate the natural language version to an Isabelle version:</p>
<h2>Codex output:</h2>
<p>theorem
fixes f : : "real \<Rightarrow> real" assumes "linear f" "f 6 - f 2 = 12" shows "f 12 - f 2 = 30"</p>
<p>Figure 3: Autoformalizations from natural language to Isabelle code. Left: Case study 2 - perfect formalization by PaLM. Right: Case study 3 - incorrect formalization by Codex.</p>
<p>Case Study 1 (Figure 1) We study the example shown in Figure 1, in which we ask LLMs to autoformalize an International Mathematical Olympiad problem ${ }^{2}$ in natural language. Surprisingly, Codex is able to autoformalize the natural language statement as an Isabelle theorem perfectly, with output given. This is surprising for the following reasons.
First of all, the amount of Isabelle code is very scarce on the internet. The entire AFP library, the largest formal library that contains most of Isabelle proofs, is only 180 MB in size. Even assuming that all of this data was included in the training of Codex, this makes at most $0.18 \%$ of the pretraining data on which Codex was trained. The fact that the model can write syntactically correct Isabelle code at all is already fascinating.
Second, there is almost zero aligned data from natural language to Isabelle on the web. While some Isabelle files have comments, they typically only give a very high level description of what the theory being formalized is about. So either LLMs are able to transfer knowledge quite successfully between natural language and formal mathematics, or the task was learned mostly via few-shot learning.
Last but not least, the model is capable of understanding and formalizing nontrivial reasoning. First, the model is able to formalize the non-existence statement via proof-by-contradiction. To formalize "there is no function $f \ldots$... it assumes there is such a function, and aims to prove "False". Second, the model understands what it means by the phrase "to itself", and correctly infers the domain of function: f : : "nat \<Rightarrow> nat".
On the other hand, PaLM made some syntactic mistakes while getting most of the structure of the proof correctly, with outputs shown in Appendix B.1.</p>
<p>Case Study 2 (Figure 3) In the next example, we ask LLMs to autoformalize a grade school mathematical word problem. Remarkably, PaLM and Codex are both capable of formalizing the statement perfectly. This is surprising because formalizations of grade school math problems in interactive theorem provers are rare (if they exist at all), as this type of mathematics is not of interest to formal mathematicians. Even more, none of the examples in the prompt (see Figure 2) that we provide are of this type. It is hence remarkable that the model is capable of extrapolating to this type of statement, showing a great promise of using LLMs for autoformalization.
To study this problem in more depth, we probe PaLM models of various sizes ( $8 \mathrm{~B}, 64 \mathrm{~B}, 540 \mathrm{~B}$ ) with outputs shown in Appendix B.2, and notice that scale is crucial for the LLMs ability to formalize. We observe that the 8 B and 64 B models are incapable of formalizing this problem, but the largest 540B model is able to produce a correct formalization.</p>
<p>Case Study 3 (Figure 3) In our third case study, Codex gives an incorrect formalization in Isabelle. The mathematical statement involves a concept of "linear function", which the model fails to</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Table 1: BLEU scores between the autoformalized statements and human formalized ground truth.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Models $\backslash$ Subject</th>
<th style="text-align: center;">algebra</th>
<th style="text-align: center;">number_theory</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">PaLM 8B</td>
<td style="text-align: center;">31.49</td>
<td style="text-align: center;">22.10</td>
</tr>
<tr>
<td style="text-align: left;">PaLM 64B</td>
<td style="text-align: center;">43.13</td>
<td style="text-align: center;">31.43</td>
</tr>
<tr>
<td style="text-align: left;">PaLM 540B</td>
<td style="text-align: center;">50.30</td>
<td style="text-align: center;">36.16</td>
</tr>
<tr>
<td style="text-align: left;">Codex</td>
<td style="text-align: center;">$\mathbf{5 7 . 1 3}$</td>
<td style="text-align: center;">$\mathbf{4 3 . 3 3}$</td>
</tr>
</tbody>
</table>
<p>formalize correctly. Codex assumes this is already a known concept in Isabelle, and made up a name: linear f. Can the model learn to formalize such problems if the prompt contains an example that explains the concept of a line? We explore this and give an affirmative answer to the question (see Appendix B.3). Once seeing a tangentially related problem that explains the concept of a "line", Codex is able to perfectly formalize a "linear function". This shows the importance of the few shot examples we include, and also how good a few-shot learners these models are!</p>
<p>Has the model memorized these formalizations? Whilst we do not have access to the training set of Codex, we attempted to find any occurrences of the formalizations produced in the case studies on the internet. We Googled them in different variants and inspected the first page of the search results. We tried variants with and without an "Isabelle" prefix, with and without quotation marks and other special characters, and also individual parts of it, such as "Isabelle "n mod $8=7$ "", but we did not find any occurrences of related statements. We also tested that we are indeed able to find occurrences of Isabelle formalizations on the web with this methodology, using pieces of formalizations picked from several websites, including the Archive of Formal Proofs. Hence, we are confident that the model has not memorized the formalizations it generated.</p>
<h1>4.3 BLEU for Model Comparisons</h1>
<p>The miniF2F benchmark contains 140 algebra problems and 120 number theory problems from the MATH dataset. For these problems, we have human ground truth formalizations in Isabelle, which gives us an evaluation set with pairs of natural language statements (from MATH) and their formalizations. We use this dataset to quantitatively compare different LLMs.
Given the observation about few shot learning in Case study 3, we decided to add more relevant examples to each subject to improve the quality of autoformalization. For each subject (i.e., algebra and number_theory), we randomly sample 10 problems to construct the few shot prompt. The rest of the problems are used for evaluation (i.e., 130 for algebra and 110 for number_theory. We provide the prompt used in the Appendix A. 1 and A.2.
We use PaLM models of varying sizes and Codex to perform the autoformalization, and compute the BLEU scores of the formalizations, shown in Table 1. Confirming our observation in Case study 2, we see a clear trend that scaling improves translation, as the BLEU scores consistently improve when we scale PaLM models from 8B to 540B, for both subjects. In addition, we see that the Codex model is better at autoformalization measured by BLEU, possibly due to the fact that Codex was trained on more formal data than PaLM.</p>
<h3>4.4 Human Evaluation of Failure cases</h3>
<p>To better understand LLMs' ability to do autoformalization, we manually inspect Codex's autoformalizations of 150 random problems from the MATH dataset [23]. 50 of the problem statements are sampled from the algebra training set, 50 from number_theory and 50 from intermediate_algebra. For algebra and number_theory, we use their corresponding prompt as in the last section, shown in Appendix A. 1 and A.2. For intermediate_algebra, we use the prompt we used for algebra (Appendix A.1). We classify the failure modes of these translations, shown in Table 2.</p>
<p>We see that out of 150 problems, Codex is capable of translating 38 problems perfectly - a success rate of $25.3 \%$. The majority of the failures are due to the misalignment of informal and formal definitions. For example, when seeing the phrase "the greatest possible value", the LLMs often fail to align it with the function Greatest/Max in Isabelle. Another example is the failure to align the fac-</p>
<p>Table 2: Failure case study of 150 problems formalized by Codex.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Failure cases $\backslash$ Subjects</th>
<th style="text-align: center;">algebra</th>
<th style="text-align: center;">number_theory</th>
<th style="text-align: center;">inter_alg</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Perfect translation</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">8</td>
</tr>
<tr>
<td style="text-align: left;">Incomplete/ill-formed/unclear prompt</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">14</td>
</tr>
<tr>
<td style="text-align: left;">Fail to align definitions or concepts</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">18</td>
</tr>
<tr>
<td style="text-align: left;">Inconsistent/missing assumption</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">9</td>
</tr>
<tr>
<td style="text-align: left;">Syntactical/type error</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">11</td>
</tr>
<tr>
<td style="text-align: left;">Missing definition in Isabelle</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: left;">Wrong application of functions</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">16</td>
</tr>
<tr>
<td style="text-align: left;">Other</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>torial of $n$ (i.e., !n) to fact n in Isabelle. Other common failure modes include the misapplication of functions (e.g., applying a prefix function in an infix way).</p>
<h1>5 Autoformalization for Neural Theorem Proving</h1>
<p>To demonstrate the usefulness of the formalized statements, we explore if one can improve neural theorem provers by training the neural models on proofs of automatically translated theorems. In this section, we combine autoformalization with expert iteration algorithms [3], and achieve a new state of the art in miniF2F benchmark.</p>
<h3>5.1 Expert Iteration with Autoformalization</h3>
<p>The basic idea of expert iteration [3] is to iteratively generate a better dataset using the model, and use the data to improve the model quality. This allows the model to generate an even better quality of the dataset and hence a better model, forming a self-improvement cycle.
In neural theorem proving, one way to get better quality data is to use feedback from the proof checker to run many proof searches (or generate multiple proofs) and check the proof attempts for correctness. Newly found correct proofs can then be used as the new training data to improve the neural prover $[6,37,38]$. The main critical ingredient that is needed is a set of problem statements on which the model can perform proof search to obtain new training data. However, unlike in Polu et al. [38], where one asks humans to manually formalize a set of problems to get formal statements, here we use LLMs to autoformalize the theorems in order to kick off the self-improvement cycle.
More formally, denote a base neural theorem prover as $M_{0}$. Let the set of autoformalized problems be $\mathcal{A}$. For each iteration $i=1 \ldots N$, we carry out the following procedure: use the language model $M_{i-1}$ with best-first search to prove as many theorems as possible in $\mathcal{A}$, collect the set of successful proofs $S_{i}$, concatenate successful problems from all iterations with the formal mathematics problems to create the set $\mathcal{A}<em _leq="\leq" i="i" j="j">{i}=\left(\bigcup</em>$. When we take the union of successful proofs from all past iterations, we perform deduplication by problem statements, similar to Polu et al. [38].} S_{i}\right) \cup \mathcal{B}$, and fine-tune $M_{0}$ on it for exactly one epoch to get a new model $M_{i</p>
<h3>5.2 Neural Theorem Provers</h3>
<p>To demonstrate the effectiveness of the approach, we start with a recently introduced neural theorem prover for Isabelle, Thor [26]. The Thor agent is fine-tuned on the PISA dataset [25] (extraction and interaction code under a BSD license), which consists of 2.49 million proof steps from the Isabelle/HOL library (under a BSD-style license) and the Archive of Formal Proofs (under various licenses as described here). The model is trained with the objective to predict the next token in a proof step, given the proof state and the last proof step. When the ground truth proof step contains any of the keywords metis, meson, and smt, the model learns to predict a special token <hammer>. In evaluation, whenever the special token is emitted, Thor invokes the proof method Sledgehammer [36] in Isabelle with a 30 second timeout.
We use a pre-trained and fine-tuned Thor agent as the base model $\left(M_{0}\right)$. The agent's language model uses Wang [47]'s implementation (under an Apache license 2.0) of a GPT-2 [40] style decoder-only</p>
<p>Table 3: Proof success rates on miniF2F.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>valid</th>
<th>test</th>
</tr>
</thead>
<tbody>
<tr>
<td>PACT [21]</td>
<td>$23.9\%$</td>
<td>$24.6\%$</td>
</tr>
<tr>
<td>FMSCL [38]</td>
<td>$33.6\%$</td>
<td>$29.6\%$</td>
</tr>
<tr>
<td>Base model $\left(M_{0}\right)$ [26]</td>
<td>$28.3\%$</td>
<td>$29.9\%$</td>
</tr>
<tr>
<td>After 1 expert iteration $\left(M_{1}\right)$</td>
<td>$36.1\%$</td>
<td>$34.0\%$</td>
</tr>
<tr>
<td>After 2 expert iterations $\left(M_{2}\right)$</td>
<td>$\mathbf{3 7 . 3 \%}$</td>
<td>$\mathbf{3 5 . 2 \%}$</td>
</tr>
</tbody>
</table>
<p>ransformer [46] model with 700M non-embedding parameters. The model has 24 layers, 24 attention heads, a hidden dimension of 1536, and a vocabulary size of 50400. It uses the AdamW [35] optimizer and is pre-trained on the GitHub + arXiv subsets of The Pile [13] for 200,000 steps, with a context length of 2048 tokens. In pre-training a warmup strategy [17] raises the learning rate linearly from 0 to $2 \times 10^{-4}$ in 3,000 steps. Then a cosine learning rate scheduler [34] is used for the rest of the pre-training, with a final learning rate of $1.2 \times 10^{-5}$. The training has a global batch size of 32 sequences, or 65,536 tokens. For fine-tuning the learning rate strategy is the same, with 10,000 warmup steps, 90,000 annealing steps, maximum learning rate $3 \times 10^{-4}$ and final learning rate $3 \times 10^{-5}$. The global batch size is 144 sequences, or 294,912 tokens. The model's evaluation loss reaches a minimum after 13,000 steps and that checkpoint is used.</p>
<p>Machine specification For experiments in this paper, we use a TPUv3 with 8 cores from Google Cloud Platform. The Isabelle process has access to up to 32 CPU cores. Running all the experiments in this paper requires a total of 3920 TPU hours. Of the 3920 TPU hours, 3200 are for running the proof search on the autoformalized theorems, 240 are for training the model on the successful proofs, and 480 are for evaluating the model on miniF2F.</p>
<h1>5.3 Result</h1>
<p>We use Codex with greedy decoding to formalize 3908 mathematical problems in algebra, intermediate algebra, and number theory from the training set of MATH [23], with the same few shot prompts used in Section 4.4. Out of them, 3363 of the autoformalized theorems are syntactically correct. We then perform expert iteration on this dataset.</p>
<p>We start with a neural theorem prover $\left(M_{0}\right)$ as described in Section 5.2. In our first iteration, $M_{0}$ proves 782 theorems, with a success rate of $23.3 \%$ (out of 3363). This gives us a new set of verified proofs to further train the neural theorem prover. We proceed to fine-tune our neural theorem prover in the fashion described in Section 5.1 to get a new prover $\left(M_{1}\right)$. This process is repeated in the second iteration, giving us 1011 successful proofs from the autoformalized theorems ( $30.1 \%$ ). We fine-tuned $M_{0}$ again, but on the deduplicated concatenation of problems from PISA and successful proofs found for the autoformalized theorems.</p>
<p>After each stage of fine-tuning, we evaluate the neural theorem prover on miniF2F [54]. The results are shown in Table 3. The base model $\left(M_{0}\right)$ has a success rate of $28.3 \%$ and $29.9 \%$ on the validation and test fractions of miniF2F respectively. It can be observed that the first expert iteration increases the success rate of the neural prover by $7.8 \%$ and $4.1 \%$ to $36.1 \%$ and $34.0 \%$ on the valid and test sets. The second iteration further improves them both by $1.2 \%$, to $37.3 \%$ and $35.2 \%$. By doing two expert iterations on the autoformalized theorems, the neural prover achieves a success rate that is $5.6 \%$ higher than the previous state-of-the-art.</p>
<h2>6 An Outlook on Autoformalizing Advanced Mathematics</h2>
<p>So far, we focused on mathematical competition problems, in which we achieve significant results using autoformalization. Not only can LLMs autoformalize non-trivial theorems, the autoformalized theorems can also improve neural prover performance. In this section, we take a peek into more advanced mathematics. We hope to identify some of the limitations of our methods when it comes to autoformalizing mathematics in the wild.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Question</span><span class="o">:</span><span class="w"> </span><span class="n">An</span><span class="w"> </span><span class="n">arbitrary</span><span class="w"> </span><span class="n">product</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">compact</span><span class="w"> </span><span class="n">spaces</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">compact</span><span class="o">.</span>
<span class="n">Codex</span><span class="w"> </span><span class="n">Output</span><span class="o">:</span>
<span class="n">theorem</span>
<span class="w">    </span><span class="n">fixes</span><span class="w"> </span><span class="n">X</span><span class="w"> </span><span class="o">::</span><span class="w"> </span><span class="s2">&quot; &#39;a set set&quot;</span>
<span class="w">    </span><span class="n">assumes</span><span class="w"> </span><span class="s2">&quot;\&lt;forall&gt;x \&lt;in&gt;X. compact x&quot;</span>
<span class="w">    </span><span class="n">shows</span><span class="w"> </span><span class="s2">&quot;compact (\&lt;Prod&gt; x \&lt;in&gt; X. x)&quot;</span>
</code></pre></div>

<p>Figure 4: A formalization for an advanced mathematical statement by Codex.</p>
<h1>6.1 Autoformalization: from Natural Language to Isabelle</h1>
<p>Autoformalization is extremely challenging in the sense that the model needs to (1) bridge the logical gaps left in pen-and-paper proofs, (2) assume the implicit contexts and assumptions, and (3) align informal definitions/concepts to formal ones. This task is further complicated considering the context can change from time to time and the same mathematical object can be formalized in subtly different ways. In this paper, we only deal with autoformalization of theorem statements, where the model is mainly challenged by definition alignments. Compared to competition problems in Section 4.4, advanced mathematical statements assume more context information that additionally obscures the alignment.
Figure 4 shows a typical case where the model fails to align the informal definition to the formal one. Based on the notation used, the model does not correctly distinguish between products of numbers, products of sets, and products of topological spaces. In Isabelle, the correct conclusion for the statement should be compact_space (product_topology X I), where $I$ is an index set that ought to have been introduced in the fixes and assumes sections.</p>
<h3>6.2 Informalization: from Isabelle to Natural Language</h3>
<p>So far, we explored one direction of translation: from natural language statement to formal statement in Isabelle. The other direction, informalization, is also of great importance for two reasons: (1) the informal texts are much easier for humans to comprehend and communicate, and (2) we can align translated informal statements with formal ones to create data, and use the back-translation techniques [43] to potentially boost the translator's performance further. In this section, we explore Codex's capability of translating formal Isabelle statement to natural language.
A corpus of 38 formal-language theorems, lemmas, and definitions is selected by an Isabelle expert. These statements are automatically translated to informal mathematics using Codex; to see the prompt we used and the results for all 38 examples, see Appendix A. 3 and D.2. We present two examples of informalization in Figure 5. Of the 38 examples, 36 were translated to a reasonably coherent statement, and 29 of these statements ( $76 \%$ ) were more-or-less correct, giving a vastly better success rate than the $25 \%$ success rate of formalization (Section 4.4). Our main conclusion is that for advanced mathematics, the model is better at informalization than formalization, showing the prospect of backtranslation style algorithms.
Note that the standard is more relaxed here since we assume a human reader will supply the obvious context and correct mistakes when the intended meaning is obvious (intended by the hypothetical human writer of these sentences). To illustrate, an example of a minor "acceptable" error: assuming that " $w, z$ are in the same connected component of the plane" when, in context, it is clear that $w, z$ should be assumed to be in the same connected component of the complement of a previously specified curve. (The assumption as originally stated is trivial.) For an example of a major error: almost-perfect translation of the Central Limit Theorem that omits the assumption of identical distributions.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 5: Two perfect translations from Isabelle code to natural language by Codex.</p>
<h1>7 Discussion</h1>
<p>Promise of Autoformalization with LLMs We have seen that automated formalization of informally given natural language statements is generally possible, even with language models not trained for this particular task. Also, automatically formalized statements are useful for training and improving the reasoning capabilities of automated neural provers. Our hope is that improved versions of this methodology will be capable of enabling a positive feedback loop involving formalization and formal reasoning that has the potential of reaching human level capabilities in both respects, as was suggested by [44].</p>
<p>Limitations and future directions We use a static model for the formalization process. For largescale autoformalization, we will need to formalize larger theories, preferably without fine tuning the model, as training it could be cumbersome and resource consuming. However, in order to utilize the newly added notions, the model would need to keep whole large theories in the current context window, which exceeds those of the current LLMs. This limits our approach to the generation of fairly small pieces of formal mathematics and the automatic formalization of entire theories including their definitions will require new research ideas. One path towards this goal might be the use of continuous training or expert iteration, cycle-consistency-based training [30, 48], or novel uses of in-context learning. To generate larger theories we will also need neural networks that can recall longer sequences (current LLMs are typically limited to a few thousand words). Retrievalaugmented language models, such as the memorizing transformer [53] offer one path to overcome this limitation.</p>
<p>Societal Impact While the potential of creating negative societal impact through formalizations is small, the use of LLMs always comes with risks. For example, for deploying an autoformalization tool using LLMs we would need to consider the inclusivity of variable and lemma names, and of the attribution of scientific ideas.</p>
<h2>References</h2>
<p>[1] Alexander A. Alemi, Franois Chollet, Niklas En, Geoffrey Irving, Christian Szegedy, and Josef Urban. Deepmath - deep sequence models for premise selection. In Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon, and Roman Garnett (eds.), Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain, pp. 2235-2243, 2016. URL http://papers.nips.cc/paper/6280-deepmath-deep-sequence-models-for-premise-selection.
[2] Marcin Andrychowicz, Dwight Crow, Alex Ray, Jonas Schneider, Rachel Fong, Peter Welinder, Bob McGrew, Josh Tobin, Pieter Abbeel, and Wojciech Zaremba. Hindsight experience replay. In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett (eds.), Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing</p>
<p>Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pp. 5048-5058, 2017. URL https://proceedings.neurips.cc/paper/2017/hash/453fadbd8a1a3af50a9df4df899537b5-Abstract.html
[3] Thomas Anthony, Zheng Tian, and David Barber. Thinking fast and slow with deep learning and tree search. In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett (eds.), Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pp. 5360-5370, 2017. URL https://proceedings.neurips.cc/paper/2017/hash/d8e1344e27a5b08cdfd5d027d9b8d6de-Abstract.html
[4] Eser Aygn, Laurent Orseau, Ankit Anand, Xavier Glorot, Vlad Firoiu, Lei M. Zhang, Doina Precup, and Shibl Mourad. Proving theorems using incremental learning and hindsight experience replay. CoRR, abs/2112.10664, 2021. URL https://arxiv.org/abs/2112.10664.
[5] Kshitij Bansal, Sarah M. Loos, Markus N. Rabe, and Christian Szegedy. Learning to reason in large theories without imitation. CoRR, abs/1905.10501, 2019. URL http://arxiv.org/abs/1905.10501.
[6] Kshitij Bansal, Sarah M. Loos, Markus N. Rabe, Christian Szegedy, and Stewart Wilcox. Holist: An environment for machine learning of higher order logic theorem proving. In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research, pp. 454-463. PMLR, 2019. URL http://proceedings.mlr.press/v97/bansal19a.html.
[7] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In NeurIPS, 2020.
[8] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models trained on code. CoRR, abs/2107.03374, 2021. URL https://arxiv.org/abs/2107.03374.
[9] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. PaLM: Scaling language modeling with pathways. CoRR, abs/2204.02311, 2022. doi: 10.48550/arXiv.2204.02311. URL https://doi.org/10.48550/arXiv.2204.02311.</p>
<p>[10] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems. CoRR, abs/2110.14168, 2021. URL https://arxiv.org/abs/2110.14168.
[11] Coq. The Coq Proof Assistant. http://coq.inria.fr. URL http://coq.inria.fr.
[12] Leonardo Mendona de Moura, Soonho Kong, Jeremy Avigad, Floris van Doorn, and Jakob von Raumer. The lean theorem prover (system description). In Amy P. Felty and Aart Middeldorp (eds.), Automated Deduction - CADE-25 - 25th International Conference on Automated Deduction, Berlin, Germany, August 1-7, 2015, Proceedings, volume 9195 of Lecture Notes in Computer Science, pp. 378-388. Springer, 2015. doi: 10.1007/978-3-319-21401-6_26. URL https://doi.org/10.1007/978-3-319-21401-6_26.
[13] Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. The Pile: An 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:2101.00027, 2020.
[14] Thibault Gauthier, Cezary Kaliszyk, Josef Urban, Ramana Kumar, and Michael Norrish. Tactictoe: Learning to prove with tactics. J. Autom. Reason., 65(2):257-286, 2021. doi: 10.1007/s10817-020-09580-x. URL https://doi.org/10.1007/s10817-020-09580-x.
[15] Georges Gonthier. The four colour theorem: Engineering of a formal proof. In Deepak Kapur (ed.), Computer Mathematics, 8th Asian Symposium, ASCM 2007, Singapore, December 1517, 2007. Revised and Invited Papers, volume 5081 of Lecture Notes in Computer Science, pp. 333. Springer, 2007. doi: 10.1007/978-3-540-87827-81_28.
[16] Georges Gonthier, Andrea Asperti, Jeremy Avigad, Yves Bertot, Cyril Cohen, Franois Garillot, Stphane Le Roux, Assia Mahboubi, Russell OConnor, Sidi Ould Biha, Ioana Pasca, Laurence Rideau, Alexey Solovyev, Enrico Tassi, and Laurent Thry. A machine-checked proof of the odd order theorem. In Sandrine Blazy, Christine Paulin-Mohring, and David Pichardie (eds.), Interactive Theorem Proving - 4th International Conference, ITP 2013, Rennes, France, July 22-26, 2013. Proceedings, volume 7998 of Lecture Notes in Computer Science, pp. 163179. Springer, 2013. doi: 10.1007/978-3-642-39634-2_14.
[17] Priya Goyal, Piotr Dollr, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv preprint arXiv:1706.02677, 2017.
[18] Christopher Hahn, Frederik Schmitt, Jens U. Kreber, Markus N. Rabe, and Bernd Finkbeiner. Teaching temporal logics to neural networks. In $I C L R, 2021$.
[19] Thomas Hales, Mark Adams, Gertrud Bauer, Tat Dat Dang, John Harrison, Hoang Le Truong, Cezary Kaliszyk, Victor Magron, Sean McLaughlin, Tat Thang Nguyen, et al. A formal proof of the Kepler conjecture. In Forum of Mathematics, Pi, volume 5, pp. e2. Cambridge University Press, 2017.
[20] Jesse Michael Han, Igor Babuschkin, Harrison Edwards, Arvind Neelakantan, Tao Xu, Stanislas Polu, Alex Ray, Pranav Shyam, Aditya Ramesh, Alec Radford, and Ilya Sutskever. Unsupervised neural machine translation with generative language models only. CoRR, abs/2110.05448, 2021. URL https://arxiv.org/abs/2110.05448.
[21] Jesse Michael Han, Jason Rute, Yuhuai Wu, Edward Ayers, and Stanislas Polu. Proof artifact co-training for theorem proving with language models. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=rpxJc9j04U.
[22] John Harrison. HOL Light: A tutorial introduction. In Mandayam K. Srivas and Albert John Camilleri (eds.), Formal Methods in Computer-Aided Design, First International Conference, FMCAD '96, Palo Alto, California, USA, November 6-8, 1996, Proceedings, volume 1166 of Lecture Notes in Computer Science, pp. 265-269. Springer, 1996.
[23] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the MATH dataset. CoRR, abs/2103.03874, 2021. URL https://arxiv.org/abs/2103.03874.</p>
<p>[24] Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, and Laurent Sifre. Training compute-optimal large language models. CoRR, abs/2203.15556, 2022. doi: 10.48550/arXiv.2203.15556. URL https://doi.org/10.48550/arXiv.2203.15556.
[25] Albert Q. Jiang, Wenda Li, Jesse Michael Han, and Yuhuai Wu. Lisa: Language models of isabelle proofs. 6th Conference on Artificial Intelligence and Theorem Proving, 2021.
[26] Albert Q. Jiang, Szymon Tworkowski Wenda Li, Konrad Czechowski, Tomasz Odrzygd, Piotr Mio, Yuhuai Wu, and Mateja Jamnik. Thor: Wielding hammers to integrate language models and automated theorem provers. arXiv preprint arXiv:2205.10893, 2022. URL https://arxiv.org/abs/2205.10893.
[27] Gerwin Klein, Kevin Elphinstone, Gernot Heiser, June Andronick, David Cock, Philip Derrin, Dhammika Elkaduwe, Kai Engelhardt, Rafal Kolanski, Michael Norrish, Thomas Sewell, Harvey Tuch, and Simon Winwood. seL4: formal verification of an OS kernel. In Jeanna Neefe Matthews and Thomas E. Anderson (eds.), Proceedings of the 22nd ACM Symposium on Operating Systems Principles 2009, SOSP 2009, Big Sky, Montana, USA, October 11-14, 2009, pp. 207-220. ACM, 2009. doi: 10.1145/1629575.1629596.
[28] Gerwin Klein, June Andronick, Matthew Fernandez, Ihor Kuz, Toby C. Murray, and Gernot Heiser. Formally verified software in the real world. Commun. ACM, 61(10):68-77, 2018. doi: 10.1145/3230627. URL https://doi.org/10.1145/3230627.
[29] Jens U. Kreber and Christopher Hahn. Generating symbolic reasoning problems with transformer GANs. CoRR, abs/2110.10054, 2021. URL https://arxiv.org/abs/2110.10054.
[30] Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc'Aurelio Ranzato. Unsupervised machine translation using monolingual corpora only. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings. OpenReview.net, 2018. URL https://openreview.net/forum?id=rkYTTf-AZ.
[31] Gil Lederman, Markus N. Rabe, Sanjit Seshia, and Edward A. Lee. Learning heuristics for quantified boolean formulas through reinforcement learning. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020. URL https://openreview.net/forum?id=BJluxREKDB.
[32] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rmi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de Masson d'Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, and Oriol Vinyals. Competitionlevel code generation with alphacode. DeepMind, 2022.
[33] Sarah M. Loos, Geoffrey Irving, Christian Szegedy, and Cezary Kaliszyk. Deep network guided proof search. In Thomas Eiter and David Sands (eds.), LPAR-21, 21st International Conference on Logic for Programming, Artificial Intelligence and Reasoning, Maun, Botswana, May 7-12, 2017, volume 46 of EPiC Series in Computing, pp. 85-105. EasyChair, 2017. doi: 10.29007/8mwc. URL https://doi.org/10.29007/8mwc.
[34] Ilya Loshchilov and Frank Hutter. SGDR: stochastic gradient descent with warm restarts. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net, 2017. URL https://openreview.net/forum?id=Skq89Scxx.
[35] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net, 2019. URL https://openreview.net/forum?id=Bkg6RiCqY7.</p>
<p>[36] Lawrence Paulson and Jasmin Blanchette. Three years of experience with sledgehammer, a practical link between automatic and interactive theorem provers. 02 2015. doi: 10.29007/tnfd.
[37] Stanislas Polu and Ilya Sutskever. Generative language modeling for automated theorem proving. CoRR, abs/2009.03393, 2020. URL https://arxiv.org/abs/2009.03393.
[38] Stanislas Polu, Jesse Michael Han, Kunhao Zheng, Mantas Baksys, Igor Babuschkin, and Ilya Sutskever. Formal mathematics statement curriculum learning, 2022. URL https://arxiv.org/abs/2202.01344.
[39] Markus N. Rabe, Dennis Lee, Kshitij Bansal, and Christian Szegedy. Mathematical reasoning via self-supervised skip-tree training. In $I C L R, 2021$.
[40] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.
[41] Frederik Schmitt, Christopher Hahn, Markus N. Rabe, and Bernd Finkbeiner. Neural circuit synthesis from specification patterns. In Marc'Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan (eds.), Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pp. 15408-15420, 2021. URL https://proceedings.neurips.cc/paper/2021/hash/8230bea7d54bcdf99cdfe85cb07313d5-Abstract.html.
[42] Stephan Schulz. Learning search control knowledge for equational theorem proving. In Franz Baader, Gerhard Brewka, and Thomas Eiter (eds.), KI 2001: Advances in Artificial Intelligence, Joint German/Austrian Conference on AI, Vienna, Austria, September 19-21, 2001, Proceedings, volume 2174 of Lecture Notes in Computer Science, pp. 320-334. Springer, 2001. doi: $10.1007 / 3-540-45422-5 \backslash 23$.
[43] Rico Sennrich, Barry Haddow, and Alexandra Birch. Improving neural machine translation models with monolingual data. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers. The Association for Computer Linguistics, 2016. doi: 10.18653/v1/p16-1009. URL https://doi.org/10.18653/v1/p16-1009.
[44] Christian Szegedy. A promising path towards autoformalization and general artificial intelligence. In Christoph Benzmller and Bruce R. Miller (eds.), Intelligent Computer Mathematics - 13th International Conference, CICM 2020, Bertinoro, Italy, July 26-31, 2020, Proceedings, volume 12236 of Lecture Notes in Computer Science, pp. 3-20. Springer, 2020. doi: 10.1007/ 978-3-030-53518-61_1. URL https://doi.org/10.1007/978-3-030-53518-6_1.
[45] Josef Urban. MPTP - motivation, implementation, first experiments. J. Autom. Reason., 33 (3-4):319-339, 2004. doi: 10.1007/s10817-004-6245-1.
[46] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett (eds.), Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pp. 5998-6008, 2017. URL https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html.
[47] Ben Wang. Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer Language Model with JAX. https://github.com/kingoflolz/mesh-transformer-jax, May 2021.
[48] Qingxiang Wang, Cezary Kaliszyk, and Josef Urban. First experiments with neural translation of informal to formal mathematics. In Florian Rabe, William M. Farmer, Grant O. Passmore, and Abdou Youssef (eds.), Intelligent Computer Mathematics - 11th International Conference, CICM 2018, Hagenberg, Austria, August 13-17, 2018, Proceedings, volume 11006 of Lecture Notes in Computer Science, pp. 255-270. Springer, 2018. doi: 10.1007/978-3-319-96812-41 _22. URL https://doi.org/10.1007/978-3-319-96812-4_22.</p>
<p>[49] Qingxiang Wang, Chad Brown, Cezary Kaliszyk, and Josef Urban. Exploration of neural machine translation in autoformalization of mathematics in mizar. In International Conference on Certified Programs and Proofs, 2020.
[50] Makarius Wenzel, Lawrence C. Paulson, and Tobias Nipkow. The Isabelle framework. In Otmane At Mohamed, Csar A. Muoz, and Sofine Tahar (eds.), Theorem Proving in Higher Order Logics, 21st International Conference, TPHOLs 2008, Montreal, Canada, August 18-21, 2008. Proceedings, volume 5170 of Lecture Notes in Computer Science, pp. 33-38. Springer, 2008. doi: $10.1007 / 978-3-540-71067-7 \backslash 7$.
[51] Minchao Wu, Michael Norrish, Christian Walder, and Amir Dezfouli. Tacticzero: Learning to prove theorems from scratch with deep reinforcement learning. In Marc'Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan (eds.), Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pp. 9330-9342, 2021. URL https://proceedings.neurips.cc/paper/2021/hash/4dea382d82666332fb564f2e711cbc71-Abstract.html.
[52] Yuhuai Wu, Albert Jiang, Jimmy Ba, and Roger Baker Grosse. INT: an inequality benchmark for evaluating generalization in theorem proving. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021. URL https://openreview.net/forum?id=06LPudowNQm.
[53] Yuhuai Wu, Markus N Rabe, DeLesley Hutchins, and Christian Szegedy. Memorizing transformers. In 10th International Conference on Learning Representations, ICLR 2022. OpenReview.net, 2022.
[54] Kunhao Zheng, Jesse Michael Han, and Stanislas Polu. MiniF2F: a cross-system benchmark for formal olympiad-level mathematics. arXiv preprint arXiv:2109.00110, 2021.</p>
<h1>Appendix</h1>
<h2>A Few-shot Prompts</h2>
<h2>A. 1 Prompt used to formalize algebra problems</h2>
<p>Natural language version: "Simplify $\left(\frac{4}{x}\right)^{-1}\left(\frac{3 x^{2}}{x}\right)^{2}\left(\frac{1}{2 x}\right)^{-3}$. The final answer is $18 x^{8}$ ". Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes x :: real
    assumes h0 : &quot;x \&lt;noteq&gt; 0&quot;
    shows &quot;1/(4/x)*((3*x^3)/x)^2*(1/(1 / (2 <span class="gs">* x)))^3 = 18 *</span> x^8&quot;
</code></pre></div>

<p>Natural language version: "For integers $n$, let</p>
<p>$$
f(n)=\left{\begin{array}{cl}
n^{2} &amp; \text { if } n \text { is odd } \
n^{2}-4 n-1 &amp; \text { if } n \text { is even }
\end{array}\right.
$$</p>
<p>Find $f(f(f(f(f(4)))))$. The final answer is 1". Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code><span class="nx">theorem</span>
<span class="w">    </span><span class="nx">fixes</span><span class="w"> </span><span class="nx">f</span><span class="w"> </span><span class="o">::</span><span class="w"> </span><span class="s">&quot;int \&lt;Rightarrow&gt; int&quot;</span>
<span class="w">    </span><span class="nx">assumes</span><span class="w"> </span><span class="s">&quot;\&lt;forall&gt;n. odd n \&lt;longrightarrow&gt; f n = n^2&quot;</span>
<span class="w">        </span><span class="k">and</span><span class="w"> </span><span class="s">&quot;\&lt;forall&gt; n. even n \&lt;longrightarrow&gt; f n = n^2 - 4*n -1&quot;</span>
<span class="w">    </span><span class="nx">shows</span><span class="w"> </span><span class="s">&quot;f 4 = -1&quot;</span>
</code></pre></div>

<p>Natural language version: "The volume of a cone is given by the formula $V=\frac{1}{3} B h$, where $B$ is the area of the base and $h$ is the height. The area of the base of a cone is 30 square units, and its height is 6.5 units. What is the number of cubic units in its volume? The final answer is 65". Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes b h v ::real
    assumes &quot;0 &lt; b \&lt;and&gt; 0 &lt; h \&lt;and&gt; 0 &lt; v&quot;
        and &quot;v = 1 / 3*(b*h)&quot;
        and &quot;b = 30&quot;
        and &quot;h = 13 / 2&quot;
    shows &quot;v = 65&quot;
</code></pre></div>

<p>Natural language version: "If $3 a+b+c=-3, a+3 b+c=9, a+b+3 c=19$, then find $a b c$. The final answer is $-56^{\prime \prime}$.
Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes a b c :: real
    assumes &quot;3 <span class="gs">* a + b + c = -3&quot;</span>
<span class="gs">        and &quot;a + 3 *</span> b + c = 9&quot;
        and &quot;a + b + 3 <span class="gs">* c = 19&quot;</span>
<span class="gs">    shows &quot;a *</span> b * c = -56&quot;
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="nx">Natural</span><span class="w"> </span><span class="nx">language</span><span class="w"> </span><span class="nx">version</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;If \(f(x)=5 x-12\), find a value for \(x\) so that \(f^{-1}(x)=f(x+1)\).</span>
<span class="s">The final answer is \(\frac{47}{21}\). Translate the natural language version to an Isabelle version:</span>
<span class="s">theorem</span>
<span class="s">    fixes x :: real and \&lt;sigma&gt;::&quot;</span><span class="nx">real</span><span class="w"> </span><span class="err">\</span><span class="p">&lt;</span><span class="nx">Rightarrow</span><span class="p">&gt;</span><span class="w"> </span><span class="nx">real</span><span class="s">&quot;</span>
<span class="s">    assumes &quot;</span><span class="nx">bij</span><span class="w"> </span><span class="err">\</span><span class="p">&lt;</span><span class="nx">sigma</span><span class="p">&gt;</span><span class="s">&quot;</span>
<span class="s">        and \(\backslash&lt;\) sigma&gt;:&quot;</span><span class="err">\</span><span class="p">&lt;</span><span class="k">forall</span><span class="p">&gt;</span><span class="w"> </span><span class="nx">x</span><span class="p">.</span><span class="w"> </span><span class="err">\</span><span class="p">&lt;</span><span class="nx">sigma</span><span class="p">&gt;</span><span class="w"> </span><span class="nx">x</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">12</span><span class="s">&quot;</span>
<span class="s">        and &quot;</span><span class="err">\</span><span class="p">&lt;</span><span class="nx">sigma</span><span class="p">&gt;</span><span class="w"> </span><span class="p">(</span><span class="nx">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="p">(</span><span class="nx">inv</span><span class="w"> </span><span class="err">\</span><span class="p">&lt;</span><span class="nx">sigma</span><span class="p">&gt;)</span><span class="w"> </span><span class="nx">x</span><span class="s">&quot;</span>
<span class="s">    shows &quot;</span><span class="nx">x</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="mi">47</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">24</span><span class="err">&quot;</span>
</code></pre></div>

<p>Natural language version: "What is the $x$-coordinate for the $x$-intercept of the line containing the points $(7,4)$ and $(6,3)$ ? The final answer is 3". Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes a b :: real
        and f :: &quot;real \&lt;Rightarrow&gt; real&quot;
    assumes h0 : &quot;\&lt;And&gt;x. f x = a * x + b&quot;
        and h1 : &quot;f 7 = 4&quot;
        and h2 : &quot;f 6 = 3&quot;
    shows &quot;f 3 = 0&quot;
</code></pre></div>

<p>Natural language version: "Given $2^{a}=32$ and $a^{b}=125$ find $b^{a}$. The final answer is 243 ". Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes a b :: real
    assumes &quot;2 powr a = 32&quot;
        and &quot;a powr b = 125&quot;
    shows &quot;b powr a = 243&quot;
</code></pre></div>

<p>Natural language version: "Let</p>
<p>$$
f(x)= \begin{cases}x^{2}+9 &amp; \text { if } x&lt;-5 \ 3 x-8 &amp; \text { if } x \geq-5\end{cases}
$$</p>
<p>If $f(x)=10$, find the sum of all possible values of $x$. The final answer is 6 ". Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code><span class="nx">theorem</span>
<span class="w">    </span><span class="nx">fixes</span><span class="w"> </span><span class="nx">f</span><span class="w"> </span><span class="o">::</span><span class="w"> </span><span class="s">&quot;real \&lt;Rightarrow&gt; real&quot;</span>
<span class="w">    </span><span class="nx">assumes</span><span class="w"> </span><span class="s">&quot;\&lt;forall&gt; x &lt; -5. f x = x^2 + 5&quot;</span>
<span class="w">        </span><span class="k">and</span><span class="w"> </span><span class="s">&quot;\&lt;forall&gt; x \&lt;ge&gt; -5. f x = 3 * x -8&quot;</span>
<span class="w">    </span><span class="nx">shows</span><span class="w"> </span><span class="s">&quot;(\&lt;Sum&gt; k \&lt;in&gt; (f -&#39; {10}). k) = 6&quot;</span>
</code></pre></div>

<p>Natural language version: "Simplify $(9-4 i)-(-3-4 i)$. The final answer is 12 ". Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes q e :: complex
    assumes h0 : &quot;q = Complex (Re 9) (Im (-4))&quot;
        and h1 : &quot;e = Complex (Re (-3)) (Im (-4))&quot;
    shows &quot;q - e = 12&quot;
</code></pre></div>

<p>Natural language version: "What is the minimum possible value for $y$ in the equation $y=$ $x^{2}-6 x+13$ ? The final answer is 4 ".
Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes x y :: real
    assumes h0 : &quot;y = x^2 - 6 * x + 13&quot;
    shows &quot;4 \&lt;le&gt; y&quot;
</code></pre></div>

<h1>A. 2 Prompt used to formalize number theory problems</h1>
<p>Natural language version: "If $n$ is a positive integer such that $2 n$ has 28 positive divisors and $3 n$ has 30 positive divisors, then how many positive divisors does $6 n$ have? The final answer is 35 ". Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes n :: nat
    assumes &quot;n&gt;0&quot;
        and &quot;card ({k. k dvd (2*n)}) = 28&quot;
        and &quot;card ({k. k dvd (3*n)}) = 30&quot;
    shows &quot;card ({k. k dvd (6*n)}) = 35&quot;
</code></pre></div>

<p>Natural language version: "Let $n$ be the number of integers $m$ in the range $1 \leq m \leq 8$ such that $\operatorname{gcd}(m, 8)=1$. What is the remainder when 3 " is divided by 8 ? The final answer is 1 ". Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes n :: nat
    assumes &quot;n = card {k::nat. gcd k 8 = 1 \&lt;and&gt; 1\&lt;le&gt;k \&lt;and&gt; k &lt; 8}&quot;
    shows &quot;(3^n) mod 8 = (1::nat)&quot;
</code></pre></div>

<p>Natural language version: "What is the remainder when $1+2+3+4+\cdots+9+10$ is divided by 9? The final answer is 1 ".
Translate the natural language version to an Isabelle version:
theorem
"(\<Sum> k&lt; 11. k) mod 9 = (1::nat)"</p>
<p>Natural language version: "Cards are numbered from 1 to 100. One card is removed and the values on the other 99 are added. The resulting sum is a multiple of 77. What number was on the card that was removed? The final answer is 45".
Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes x :: nat
    assumes h0 : &quot;1 \&lt;le&gt; x \&lt;and&gt; x \&lt;le&gt; 100&quot;
        and h1 : &quot;77 dvd ((\&lt;Sum&gt;k::nat=0..100. k)-x)&quot;
    shows &quot;x=45&quot;
</code></pre></div>

<p>Natural language version: "Find $9^{-1}(\bmod 100)$, as a residue modulo 100. (Give an answer between 0 and 99, inclusive.) The final answer is $89(\bmod 100)$ ".
Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes x::nat
    assumes &quot;x &lt; 100&quot;
        and &quot;x*9 mod 100 = 1&quot;
    shows &quot;x = 89&quot;
</code></pre></div>

<p>Natural language version: "Suppose $m$ is a two-digit positive integer such that $6^{-1}$ $(\bmod m)$ exists and $6^{-1} \equiv 6^{2}(\bmod m)$. What is $m$ ? The final answer is 43 ".
Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes m x :: nat
    assumes h0 : &quot;10 \&lt;le&gt; m&quot;
        and h1 : &quot;m \&lt;le&gt; 99&quot;
        and h2 : &quot;(6 * x) mod m = 1&quot;
        and h3 : &quot;(x - 6^2) mod m = 0&quot;
    shows &quot;m = 43&quot;
</code></pre></div>

<p>Natural language version: "Find $24^{-1}\left(\bmod 11^{2}\right)$. That is, find the residue $b$ for which $24 b \equiv 1\left(\bmod 11^{2}\right)$. Express your answer as an integer from 0 to $11^{2}-1$, inclusive. The final answer is 116 ".
Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code><span class="nx">theorem</span>
<span class="w">    </span><span class="nx">fixes</span><span class="w"> </span><span class="nx">b</span><span class="o">::</span><span class="nx">int</span>
<span class="w">    </span><span class="nx">assumes</span><span class="w"> </span><span class="s">&quot;\&lt;forall&gt;b::int. 0\&lt;le&gt;b \&lt;and&gt; b\&lt;le&gt;11^2 \&lt;and&gt; [b * 24 = 1]</span>
<span class="s">        (mod (11^2))&quot;</span>
<span class="w">    </span><span class="nx">shows</span><span class="w"> </span><span class="s">&quot;b = 116&quot;</span>
</code></pre></div>

<p>Natural language version: "Given that $p \geq 7$ is a prime number, evaluate</p>
<p>$$
1^{-1} \cdot 2^{-1}+2^{-1} \cdot 3^{-1}+3^{-1} \cdot 4^{-1}+\cdots+(p-2)^{-1} \cdot(p-1)^{-1} \quad(\bmod p)
$$</p>
<p>The final answer is $2(\bmod p)$ ".
Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes p :: nat
    assumes &quot;prime p&quot;
    and &quot;7 \&lt;le&gt; p&quot;
shows &quot;(\&lt;Sum&gt; k \&lt;in&gt; {1..&lt;p-1}. (inv_mod k p)* (inv_mod (k+1) p)) = 2&quot;
</code></pre></div>

<p>Natural language version: "What is the remainder when $2000+2001+2002+2003+2004+$ $2005+2006$ is divided by 7? The final answer is 0 ". Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    &quot;(2000 + 2001 + 2002 + 2003 + 2004 + 2005 + 2006) mod 7 = (0::nat)&quot;
</code></pre></div>

<p>Natural language version: "One morning each member of Angela's family drank an 8-ounce mixture of coffee with milk. The amounts of coffee and milk varied from cup to cup, but were never zero. Angela drank a quarter of the total amount of milk and a sixth of the total amount of coffee. How many people are in the family? The final answer is 5". Translate the natural language version to an Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes x y n ::nat
    assumes &quot;x / 4 + y / 6 = (x + y) / n&quot;
        and &quot;n\&lt;noteq&gt;0&quot;
        &quot;x\&lt;noteq&gt;0&quot; &quot;y\&lt;noteq&gt;0&quot;
    shows &quot;n = 5&quot;
</code></pre></div>

<h1>A. 3 Prompt used for informalization</h1>
<div class="codehilite"><pre><span></span><code>Isabelle version:
theorem
    fixes z::complex
    assumes h0: &quot;z = (Complex (1/sqrt 2) (1/sqrt 2))&quot;
    shows &quot;(\&lt;Sum&gt;k::nat=1..12. (z^(k^2)))
        <span class="k">*</span> (\&lt;Sum&gt; k::nat=1..12. 1/(z^(k^2))) =36&quot;
</code></pre></div>

<p>Translate the Isabelle version to a natural language version: "Let $z=\frac{1+i}{\sqrt{2}}$, find $\left(\sum_{i=1}^{1} 2\left(z^{i^{2}}\right)\right) \cdot\left(\sum_{i=1}^{1} 2\left(\frac{1}{z^{i^{2}}}\right)\right)$. The final answer is 36 ."
Isabelle version:</p>
<div class="codehilite"><pre><span></span><code>theorem
    fixes a b ::real
    assumes &quot;(ln a) / (ln 8) + (ln (b^2)) / (ln 4) = 5&quot;
        &quot;(ln b) / (ln 8) + (ln (a^2)) / (ln 4) = 7&quot;
        shows &quot;a * b = 512&quot;
</code></pre></div>

<p>Translate the Isabelle version to a natural language version: "Determine the value of $a b$ if $\log <em 4="4">{8} a+\log </em>=5$ and $\log } b^{2<em 4="4">{8} b+\log </em>=7$. The final answer is 512 ".} a^{2</p>
<h2>B More on case Studies</h2>
<h2>B. 1 Case Study 1</h2>
<p>Here we show the output given by PaLM model 540B. The model got the most structure correctly, but made some syntactical errors.</p>
<h2>Question:</h2>
<p>Natural language version: "Prove that there is no function $f$ from the set of non-negative integers into itself such that $f(f(n))=n+1987$ for every $n$." Translate the natural language version to an Isabelle version:</p>
<h2>PaLM 540B Output:</h2>
<div class="codehilite"><pre><span></span><code><span class="nx">theorem</span>
<span class="w">    </span><span class="nx">fixes</span><span class="w"> </span><span class="nx">f</span><span class="w"> </span><span class="o">::</span><span class="w"> </span><span class="s">&quot;nat -&gt; nat&quot;</span>
<span class="w">    </span><span class="nx">assumes</span><span class="w"> </span><span class="s">&quot;forall n::nat. f(f(n)) = n + 1987&quot;</span>
<span class="w">    </span><span class="nx">shows</span><span class="w"> </span><span class="s">&quot;false&quot;</span>
</code></pre></div>

<h1>B. 2 Case Study 2</h1>
<p>We show below the output given by PaLM models of different sizes.</p>
<h2>Question:</h2>
<p>Natural Language version: "When all the girls at Madeline's school line up in rows of eight, there are seven left over. If instead they line up in rows of four, how many are left over? The final answer is 3."
Translate the natural language version to an Isabelle version:</p>
<h2>PaLM 540B output:</h2>
<div class="codehilite"><pre><span></span><code>theorem
    fixes n::nat
    assumes &quot;n mod 8 = 7&quot;
    shows &quot;n mod 4 = 3&quot;
</code></pre></div>

<h2>Question:</h2>
<p>Natural Language version: "When all the girls at Madeline's school line up in rows of eight, there are seven left over. If instead they line up in rows of four, how many are left over? The final answer is 3."
Translate the natural language version to an Isabelle version:</p>
<h2>PaLM 64B output:</h2>
<div class="codehilite"><pre><span></span><code>theorem
    fixes girls :: nat
    assumes &quot;(girls / 8) + 7 = girls&quot;
    shows &quot;girls = 3&quot;
</code></pre></div>

<h2>Question:</h2>
<p>Natural Language version: "When all the girls at Madeline's school line up in rows of eight, there are seven left over. If instead they line up in rows of four, how many are left over? The final answer is 3."
Translate the natural language version to an Isabelle version:</p>
<h2>PaLM 8B output:</h2>
<div class="codehilite"><pre><span></span><code>theorem
    fixes a b ::real
    assumes &quot;(ln a) / (ln 8) + (ln (b^2)) / (ln 4) = 7&quot;
        &quot;(ln b) / (ln 8) + (ln (a^2)) / (ln 4) = 3&quot;}}
    shows &quot;a * b = 3&quot;
</code></pre></div>

<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2} \mathrm{~A}$ problem from IMO 1987.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>