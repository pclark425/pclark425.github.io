<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1992 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1992</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1992</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-46.html">extraction-schema-46</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <p><strong>Paper ID:</strong> paper-279324251</p>
                <p><strong>Paper Title:</strong> Llm-Assisted Crossover in Genetic Improvement of Software</p>
                <p><strong>Paper Abstract:</strong> This study explores the use of Large Language Models to improve the crossover process in genetic programming, as applied in the genetic improvement domain. Traditional crossover techniques typically combine parent variants by selecting modifications uniformly or even randomly, without consideration of contextual relevance, often resulting in inefficient searches and suboptimal solutions due to incompatible or redundant modifications. In contrast, our LLM-assisted crossover leverages context to select and combine edits from parent solutions that are more likely to work well together, with the goal of producing higher quality variants, accelerating optimization. We implemented this approach within MAGPIE, a unified genetic improvement framework. We evaluated against five traditional crossover methods across seven benchmarks, measuring performance on four key metrics: average ranking, best variant execution time, efficiency in reaching performance milestones, and viable variant count. Results show that LLM-assisted crossover achieved an average ranking of 2.27 (on a scale where 1 is best and 6 is worst), making it the top-performing method across benchmarks based on the quality of the optimal variants produced. The LLM-based approach also improved the fitness (execution time) by an average of 8.5 % over the best variant produced by the traditional methods. In terms of efficiency, the LLM-assisted crossover required on average 25.6 % fewer variants to reach $25 \%, 50 \%, 75 \%$, and 100 % of the final performance improvement compared to the traditional methods. Additionally, the LLM-assisted crossover produced 4.8 % more viable variants across scenarios, including both source code modification and parameter tuning cases. These findings suggest that LLMs can significantly enhance genetic improvement by guiding the crossover process toward more effective and viable solutions, providing motivation for further research in LLM-assisted search algorithms.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1992.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1992.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-Assisted Crossover</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-Assisted Crossover (this work)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-driven GP crossover operator that uses GPT-4o-mini to contextually select and combine edits from parent variants (source code edits or parameter settings), with a post-processing step to ensure no novel edits are introduced.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM-Assisted Crossover (GPT-4o-mini-2024-07-18)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>The operator issues an API prompt to GPT-4o-mini containing: optimization objective (minimize runtime), parent variants expressed as lists of edits with fitness scores, and optional contextual information (file contents for source edits; documentation for parameters). The LLM recommends which edits to include from parents to form a child. A deterministic post-processing stage enforces that all child edits are drawn from at least one parent (prevents hallucinated edits). No additional model training or fine-tuning was performed.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Genetic improvement of software across 7 benchmarks (MiniSAT, MiniSAT_hack, SAT4J, Weka, LPG, scipy.optimize.minimize, zlib.compress) spanning source code modification and parameter tuning (11 scenarios total).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>UniformConcat, Concat, 1Point, 2Point, UniformInter (traditional GP crossover methods)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Average optimal fitness (AOF) = 4.477 s; Average fitness across all variants = 5.834 s; Average ranking across benchmarks = 2.27 (1 best, 6 worst); Best-variant execution time improved by 8.5% on average over traditional methods; average variant 6.1% faster than average of traditional methods.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td>Best traditional method (UniformConcat) AOF = 4.598 s, average fitness = 6.094 s, avg ranking = 3.00. Traditional methods' AOF range: 4.598–5.169 s; avg fitness range: 5.841–6.463 s (see Table II).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td>LLM-Assisted: avg viable variants = 194.45 out of 220 (≈88.4%). Traditional methods: UniformConcat = 187.73/220 (≈85.3%); average across the five traditional methods ≈185.6/220 (≈84.3%). Paper reports LLM produced on average 4.8% more viable variants than traditional methods.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td>Not directly measured. Authors note only one pre-trained LLM was used (GPT-4o-mini) and the limited benchmarks mean potential biases toward patterns in LLM training data are unassessed; thus no empirical evidence of training-distribution bias is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>LLM API calls: average input tokens = 1,980, output tokens = 103; cost per call = $0.0003618; ~120 API calls per benchmark; total cost per benchmark <$0.005. Average API latency = 2.92 s per call; total LLM time overhead ≈350.4 s per benchmark. Fitness evaluation/test time per mutant typically >20 s, so LLM overhead considered modest. Traditional crossovers incur no LLM API cost and negligible extra inference time.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>No online fine-tuning reported. Variation arises from LLM probabilistic responses; context in prompts is adapted per crossover decision but the model is not adapted/updated during runs.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Potential hallucination of new edits by the LLM (mitigated by post-processing that rejects edits not present in parents). Probabilistic nondeterminism can produce suboptimal suggestions; single-model, single-run experiments may not capture variance. Limited benchmark set and single LLM used may limit generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Context-aware, pretrained LLMs can substantially improve crossover by selecting compatible, high-value edits: (1) produce better final variants (AOF 4.477 s vs 4.598–5.169 s for baselines); (2) accelerate search (25.6% fewer variants to reach milestone improvements; example: 25% milestone reached at 39.82 variants vs 56.45 for UniformConcat); (3) yield more viable variants (~88.4% viable vs ~84.3% for traditional). Overhead in cost/time from API calls is small relative to testing time, and no task-specific pretraining was required—making LLM-based operators practical but requiring broader evaluation to confirm generalization.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1992.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1992.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Traditional Crossovers</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Traditional Genetic Programming Crossover Operators (UniformConcat, Concat, 1Point, 2Point, UniformInter)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Five conventional GP crossover strategies used as baselines: UniformConcat, Concat, 1Point, 2Point, and UniformInter, differing in how edits from parents are combined (interleaving, concatenation, fixed single/two-point swaps, or uniform interleaving).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>UniformConcat / Concat / 1Point / 2Point / UniformInter</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>traditional GP</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Hand-designed operators that combine parent edit sequences by fixed rules: UniformConcat interleaves edits uniformly; Concat appends one parent's edits to the other's; 1Point/2Point choose crossover point(s) and swap segments; UniformInter selects edits in an interleaved uniform manner. No learned component or external context was used.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Same 7 benchmarks and 11 scenarios used in this paper (GI experiments in MAGPIE).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against LLM-Assisted Crossover (this paper) and discussed relative to semantic/learned crossovers in related work.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td>Per-method figures: UniformConcat AOF = 4.598 s, AF = 6.094 s, avg ranking = 3.00; Concat AOF = 4.734 s, AF = 5.841 s, ranking = 3.55; 1Point AOF = 4.971 s, AF = 6.333 s, ranking = 3.82; 2Point AOF = 5.169 s, AF = 6.463 s, ranking = 4.27; UniformInter AOF = 4.991 s, AF = 6.348 s, ranking = 4.09 (Table II).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td>Average viable variants across traditional methods ≈185.6/220 (≈84.3%); UniformConcat reported 187.73/220 (≈85.3%).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>No LLM API cost; traditional operators have negligible inference cost compared to LLM-based operator (no network/API latency), making them cheaper per-crossover. Exact runtime/memory differences for operator execution not quantitatively reported.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>Operators are static hand-designed rules; no online adaptation or learning reported.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Random/unaware combination of edits can lead to incompatible modifications, causing compilation/test failures and reduced viability. Less contextual awareness can slow convergence and produce fewer high-quality variants.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Traditional operators are inexpensive and simple but lack contextual integration, leading to more incompatible combinations and slower convergence; in this work they were outperformed by an LLM-based operator on quality, efficiency, and viability metrics.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1992.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1992.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DNC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep Neural Crossover (DNC)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A learned crossover operator using deep reinforcement learning and an LSTM-based encoder-decoder with attention to guide gene selection, reported to improve offspring fitness and convergence in prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Deep neural crossover.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Deep Neural Crossover (Shem-Tov & Elyasaf)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>neural network / learned from data</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>DNC leverages deep reinforcement learning with an LSTM-based encoder-decoder and attention mechanism to select genes during crossover according to a learned policy aimed at maximizing offspring fitness. It requires significant pre-training and fine-tuning tailored to problem domains.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Not specified in detail within this paper; discussed in related work as a GP operator (see original DNC paper for exact benchmarks).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared in its original work to traditional crossover methods (reported to achieve higher solution quality and faster convergence).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Reported by its authors to achieve higher solution quality and convergence rates relative to traditional operators; no numerical metrics are provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td>Described qualitatively as inferior in the original DNC report (no numbers here).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td>This paper notes DNC's limitation: requires significant pre-training and fine-tuning, making it resource-intensive and potentially narrowly specialized to training domains.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>Described as resource-intensive due to substantial pre-training and fine-tuning requirements; no quantitative cost reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>DNC uses a learned policy which can be adapted during training but is not presented here as being fine-tuned online during evolution; original work required domain-specific training.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Requires significant pretraining and fine-tuning which limits immediate applicability; potential overfitting to training distributions is implied but not empirically reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Learned neural crossover operators like DNC can outperform traditional operators in quality and convergence but often come with high training cost and domain-specific tuning; contrastingly, LLM-based crossover in this paper achieves improvements without domain-specific training, suggesting different trade-offs between pretraining cost and out-of-the-box applicability.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1992.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1992.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Semantic Crossovers (SDC & LGX)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Semantically Driven Crossover (SDC) and Locally Geometric Semantic Crossover (LGX)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Context- or semantics-aware crossover operators that use program behavior or semantic mappings to guide recombination, aiming to reduce redundancy and produce behaviorally meaningful offspring.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Semantically Driven Crossover (SDC); Locally Geometric Semantic Crossover (LGX)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>semantic/context-aware (hand-designed)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>SDC uses reduced ordered BDDs to ensure behaviorally different children and avoid redundant crossover, reducing code bloat but incurring high computational cost. LGX selects homologous regions in parent programs to produce behaviorally intermediate offspring by leveraging geometric/semantic relationships. Both are not learned from data but are semantics-aware recombination methods.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Mentioned in related work; not evaluated in this paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Discussed as alternatives to traditional structural crossovers and contrasted to learned approaches; not experimentally compared in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>SDC is described as computationally expensive for large-scale applications due to fine-grained semantic checking. LGX is tied to geometric semantic mappings and thus less generally adaptable.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>High computational overhead (SDC) and dependence on semantic/geometric problem structure (LGX) limit scalability and general applicability.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Semantics-aware crossovers can improve meaningful recombination and reduce redundancy, but their computational cost and domain-specific requirements contrast with learned (DNC) or pretrained LLM approaches that trade off training cost for either upfront model training (DNC) or broad pretraining (LLMs).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1992.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1992.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MAGPIE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MAGPIE (Machine Automated General Performance Improvement via Evolution of Software)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A language-agnostic genetic improvement framework that represents programs as edit sequences and was used to implement and evaluate the LLM-assisted crossover and the traditional crossover baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Magpie: Machine automated general performance improvement via evolution of software.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MAGPIE framework</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>framework (hosts GP search and operators)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>MAGPIE represents programs in an XML format and captures modifications as edits (insert/replace/delete statements or parameter changes). It was used with a GP search configuration (pop_size=20, epochs=11, crossover rate=0.6) to compare crossover methods and evaluate fitness by runtime.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Used to run the 7 benchmarks and 11 scenarios for genetic improvement experiments in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Serves as the experimental platform for comparing LLM-based and traditional crossover operators.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Results are specific to experiments within MAGPIE; the paper notes potential lack of generalizability to other GI frameworks.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>MAGPIE enabled controlled comparison showing LLM-assisted crossover improvements; however, framework-specific representations and operations mean observed gains should be validated across other GI systems.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Deep neural crossover. <em>(Rating: 2)</em></li>
                <li>Semantically driven crossover in genetic programming. <em>(Rating: 2)</em></li>
                <li>Locally Geometric Semantic Crossover : A Study on the Roles of Semantics and Homology in Recombination Operators. <em>(Rating: 2)</em></li>
                <li>Magpie: Machine automated general performance improvement via evolution of software. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1992",
    "paper_id": "paper-279324251",
    "extraction_schema_id": "extraction-schema-46",
    "extracted_data": [
        {
            "name_short": "LLM-Assisted Crossover",
            "name_full": "LLM-Assisted Crossover (this work)",
            "brief_description": "An LLM-driven GP crossover operator that uses GPT-4o-mini to contextually select and combine edits from parent variants (source code edits or parameter settings), with a post-processing step to ensure no novel edits are introduced.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "LLM-Assisted Crossover (GPT-4o-mini-2024-07-18)",
            "operator_type": "LLM-based",
            "operator_description": "The operator issues an API prompt to GPT-4o-mini containing: optimization objective (minimize runtime), parent variants expressed as lists of edits with fitness scores, and optional contextual information (file contents for source edits; documentation for parameters). The LLM recommends which edits to include from parents to form a child. A deterministic post-processing stage enforces that all child edits are drawn from at least one parent (prevents hallucinated edits). No additional model training or fine-tuning was performed.",
            "training_data_description": null,
            "domain_or_benchmark": "Genetic improvement of software across 7 benchmarks (MiniSAT, MiniSAT_hack, SAT4J, Weka, LPG, scipy.optimize.minimize, zlib.compress) spanning source code modification and parameter tuning (11 scenarios total).",
            "comparison_baseline": "UniformConcat, Concat, 1Point, 2Point, UniformInter (traditional GP crossover methods)",
            "performance_learned_operator": "Average optimal fitness (AOF) = 4.477 s; Average fitness across all variants = 5.834 s; Average ranking across benchmarks = 2.27 (1 best, 6 worst); Best-variant execution time improved by 8.5% on average over traditional methods; average variant 6.1% faster than average of traditional methods.",
            "performance_traditional_operator": "Best traditional method (UniformConcat) AOF = 4.598 s, average fitness = 6.094 s, avg ranking = 3.00. Traditional methods' AOF range: 4.598–5.169 s; avg fitness range: 5.841–6.463 s (see Table II).",
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": "LLM-Assisted: avg viable variants = 194.45 out of 220 (≈88.4%). Traditional methods: UniformConcat = 187.73/220 (≈85.3%); average across the five traditional methods ≈185.6/220 (≈84.3%). Paper reports LLM produced on average 4.8% more viable variants than traditional methods.",
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": "Not directly measured. Authors note only one pre-trained LLM was used (GPT-4o-mini) and the limited benchmarks mean potential biases toward patterns in LLM training data are unassessed; thus no empirical evidence of training-distribution bias is reported.",
            "computational_cost_comparison": "LLM API calls: average input tokens = 1,980, output tokens = 103; cost per call = $0.0003618; ~120 API calls per benchmark; total cost per benchmark &lt;$0.005. Average API latency = 2.92 s per call; total LLM time overhead ≈350.4 s per benchmark. Fitness evaluation/test time per mutant typically &gt;20 s, so LLM overhead considered modest. Traditional crossovers incur no LLM API cost and negligible extra inference time.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": "No online fine-tuning reported. Variation arises from LLM probabilistic responses; context in prompts is adapted per crossover decision but the model is not adapted/updated during runs.",
            "failure_modes": "Potential hallucination of new edits by the LLM (mitigated by post-processing that rejects edits not present in parents). Probabilistic nondeterminism can produce suboptimal suggestions; single-model, single-run experiments may not capture variance. Limited benchmark set and single LLM used may limit generalization.",
            "key_findings_for_theory": "Context-aware, pretrained LLMs can substantially improve crossover by selecting compatible, high-value edits: (1) produce better final variants (AOF 4.477 s vs 4.598–5.169 s for baselines); (2) accelerate search (25.6% fewer variants to reach milestone improvements; example: 25% milestone reached at 39.82 variants vs 56.45 for UniformConcat); (3) yield more viable variants (~88.4% viable vs ~84.3% for traditional). Overhead in cost/time from API calls is small relative to testing time, and no task-specific pretraining was required—making LLM-based operators practical but requiring broader evaluation to confirm generalization.",
            "uuid": "e1992.0"
        },
        {
            "name_short": "Traditional Crossovers",
            "name_full": "Traditional Genetic Programming Crossover Operators (UniformConcat, Concat, 1Point, 2Point, UniformInter)",
            "brief_description": "Five conventional GP crossover strategies used as baselines: UniformConcat, Concat, 1Point, 2Point, and UniformInter, differing in how edits from parents are combined (interleaving, concatenation, fixed single/two-point swaps, or uniform interleaving).",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "UniformConcat / Concat / 1Point / 2Point / UniformInter",
            "operator_type": "traditional GP",
            "operator_description": "Hand-designed operators that combine parent edit sequences by fixed rules: UniformConcat interleaves edits uniformly; Concat appends one parent's edits to the other's; 1Point/2Point choose crossover point(s) and swap segments; UniformInter selects edits in an interleaved uniform manner. No learned component or external context was used.",
            "training_data_description": null,
            "domain_or_benchmark": "Same 7 benchmarks and 11 scenarios used in this paper (GI experiments in MAGPIE).",
            "comparison_baseline": "Compared against LLM-Assisted Crossover (this paper) and discussed relative to semantic/learned crossovers in related work.",
            "performance_learned_operator": null,
            "performance_traditional_operator": "Per-method figures: UniformConcat AOF = 4.598 s, AF = 6.094 s, avg ranking = 3.00; Concat AOF = 4.734 s, AF = 5.841 s, ranking = 3.55; 1Point AOF = 4.971 s, AF = 6.333 s, ranking = 3.82; 2Point AOF = 5.169 s, AF = 6.463 s, ranking = 4.27; UniformInter AOF = 4.991 s, AF = 6.348 s, ranking = 4.09 (Table II).",
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": "Average viable variants across traditional methods ≈185.6/220 (≈84.3%); UniformConcat reported 187.73/220 (≈85.3%).",
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": "No LLM API cost; traditional operators have negligible inference cost compared to LLM-based operator (no network/API latency), making them cheaper per-crossover. Exact runtime/memory differences for operator execution not quantitatively reported.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": "Operators are static hand-designed rules; no online adaptation or learning reported.",
            "failure_modes": "Random/unaware combination of edits can lead to incompatible modifications, causing compilation/test failures and reduced viability. Less contextual awareness can slow convergence and produce fewer high-quality variants.",
            "key_findings_for_theory": "Traditional operators are inexpensive and simple but lack contextual integration, leading to more incompatible combinations and slower convergence; in this work they were outperformed by an LLM-based operator on quality, efficiency, and viability metrics.",
            "uuid": "e1992.1"
        },
        {
            "name_short": "DNC",
            "name_full": "Deep Neural Crossover (DNC)",
            "brief_description": "A learned crossover operator using deep reinforcement learning and an LSTM-based encoder-decoder with attention to guide gene selection, reported to improve offspring fitness and convergence in prior work.",
            "citation_title": "Deep neural crossover.",
            "mention_or_use": "mention",
            "system_name": "Deep Neural Crossover (Shem-Tov & Elyasaf)",
            "operator_type": "neural network / learned from data",
            "operator_description": "DNC leverages deep reinforcement learning with an LSTM-based encoder-decoder and attention mechanism to select genes during crossover according to a learned policy aimed at maximizing offspring fitness. It requires significant pre-training and fine-tuning tailored to problem domains.",
            "training_data_description": null,
            "domain_or_benchmark": "Not specified in detail within this paper; discussed in related work as a GP operator (see original DNC paper for exact benchmarks).",
            "comparison_baseline": "Compared in its original work to traditional crossover methods (reported to achieve higher solution quality and faster convergence).",
            "performance_learned_operator": "Reported by its authors to achieve higher solution quality and convergence rates relative to traditional operators; no numerical metrics are provided in this paper.",
            "performance_traditional_operator": "Described qualitatively as inferior in the original DNC report (no numbers here).",
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": "This paper notes DNC's limitation: requires significant pre-training and fine-tuning, making it resource-intensive and potentially narrowly specialized to training domains.",
            "computational_cost_comparison": "Described as resource-intensive due to substantial pre-training and fine-tuning requirements; no quantitative cost reported here.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": "DNC uses a learned policy which can be adapted during training but is not presented here as being fine-tuned online during evolution; original work required domain-specific training.",
            "failure_modes": "Requires significant pretraining and fine-tuning which limits immediate applicability; potential overfitting to training distributions is implied but not empirically reported here.",
            "key_findings_for_theory": "Learned neural crossover operators like DNC can outperform traditional operators in quality and convergence but often come with high training cost and domain-specific tuning; contrastingly, LLM-based crossover in this paper achieves improvements without domain-specific training, suggesting different trade-offs between pretraining cost and out-of-the-box applicability.",
            "uuid": "e1992.2"
        },
        {
            "name_short": "Semantic Crossovers (SDC & LGX)",
            "name_full": "Semantically Driven Crossover (SDC) and Locally Geometric Semantic Crossover (LGX)",
            "brief_description": "Context- or semantics-aware crossover operators that use program behavior or semantic mappings to guide recombination, aiming to reduce redundancy and produce behaviorally meaningful offspring.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Semantically Driven Crossover (SDC); Locally Geometric Semantic Crossover (LGX)",
            "operator_type": "semantic/context-aware (hand-designed)",
            "operator_description": "SDC uses reduced ordered BDDs to ensure behaviorally different children and avoid redundant crossover, reducing code bloat but incurring high computational cost. LGX selects homologous regions in parent programs to produce behaviorally intermediate offspring by leveraging geometric/semantic relationships. Both are not learned from data but are semantics-aware recombination methods.",
            "training_data_description": null,
            "domain_or_benchmark": "Mentioned in related work; not evaluated in this paper's experiments.",
            "comparison_baseline": "Discussed as alternatives to traditional structural crossovers and contrasted to learned approaches; not experimentally compared in this paper.",
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": "SDC is described as computationally expensive for large-scale applications due to fine-grained semantic checking. LGX is tied to geometric semantic mappings and thus less generally adaptable.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": "High computational overhead (SDC) and dependence on semantic/geometric problem structure (LGX) limit scalability and general applicability.",
            "key_findings_for_theory": "Semantics-aware crossovers can improve meaningful recombination and reduce redundancy, but their computational cost and domain-specific requirements contrast with learned (DNC) or pretrained LLM approaches that trade off training cost for either upfront model training (DNC) or broad pretraining (LLMs).",
            "uuid": "e1992.3"
        },
        {
            "name_short": "MAGPIE",
            "name_full": "MAGPIE (Machine Automated General Performance Improvement via Evolution of Software)",
            "brief_description": "A language-agnostic genetic improvement framework that represents programs as edit sequences and was used to implement and evaluate the LLM-assisted crossover and the traditional crossover baselines.",
            "citation_title": "Magpie: Machine automated general performance improvement via evolution of software.",
            "mention_or_use": "use",
            "system_name": "MAGPIE framework",
            "operator_type": "framework (hosts GP search and operators)",
            "operator_description": "MAGPIE represents programs in an XML format and captures modifications as edits (insert/replace/delete statements or parameter changes). It was used with a GP search configuration (pop_size=20, epochs=11, crossover rate=0.6) to compare crossover methods and evaluate fitness by runtime.",
            "training_data_description": null,
            "domain_or_benchmark": "Used to run the 7 benchmarks and 11 scenarios for genetic improvement experiments in this paper.",
            "comparison_baseline": "Serves as the experimental platform for comparing LLM-based and traditional crossover operators.",
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": null,
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": "Results are specific to experiments within MAGPIE; the paper notes potential lack of generalizability to other GI frameworks.",
            "key_findings_for_theory": "MAGPIE enabled controlled comparison showing LLM-assisted crossover improvements; however, framework-specific representations and operations mean observed gains should be validated across other GI systems.",
            "uuid": "e1992.4"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Deep neural crossover.",
            "rating": 2
        },
        {
            "paper_title": "Semantically driven crossover in genetic programming.",
            "rating": 2
        },
        {
            "paper_title": "Locally Geometric Semantic Crossover : A Study on the Roles of Semantics and Homology in Recombination Operators.",
            "rating": 2
        },
        {
            "paper_title": "Magpie: Machine automated general performance improvement via evolution of software.",
            "rating": 2
        }
    ],
    "cost": 0.015278,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LLM-Assisted Crossover in Genetic Improvement of Software</p>
<p>st Dimitrios Stamatios Bouras Peking University
BeijingChina</p>
<p>Sergey Mechtaev Peking University
BeijingChina</p>
<p>Justyna Petke University College London
LondonUK</p>
<p>LLM-Assisted Crossover in Genetic Improvement of Software
12A419671AD41CD54F84DCC8D9AF73C7CrossoverGenetic ImprovementGenetic ProgrammingLarge Language ModelsSBSESearch-Based Software EngineeringParameter Tuning
This study explores the use of Large Language Models to improve the crossover process in genetic programming, as applied in the genetic improvement domain.Traditional crossover techniques typically combine parent variants by selecting modifications uniformly or even randomly, without consideration of contextual relevance, often resulting in inefficient searches and suboptimal solutions due to incompatible or redundant modifications.In contrast, our LLM-assisted crossover leverages context to select and combine edits from parent solutions that are more likely to work well together, with the goal of producing higher quality variants, accelerating optimization.We implemented this approach within MAGPIE, a unified genetic improvement framework.We evaluated against five traditional crossover methods across seven benchmarks, measuring performance on four key metrics: average ranking, best variant execution time, efficiency in reaching performance milestones, and viable variant count.Results show that LLM-assisted crossover achieved an average ranking of 2.27 (on a scale where 1 is best and 6 is worst), making it the top-performing method across benchmarks based on the quality of the optimal variants produced.The LLM-based approach also improved the fitness (execution time) by an average of 8.5% over the best variant produced by the traditional methods.In terms of efficiency, the LLM-assisted crossover required on average 25.6% fewer variants to reach 25%, 50%, 75%, and 100% of the final performance improvement compared to the traditional methods.Additionally, the LLM-assisted crossover produced 4.8% more viable variants across scenarios, including both source code modification and parameter tuning cases.These findings suggest that LLMs can significantly enhance genetic improvement by guiding the crossover process toward more effective and viable solutions, providing motivation for further research in LLM-assisted search algorithms.</p>
<p>I. INTRODUCTION</p>
<p>The continuous drive for software performance optimization has become increasingly vital as hardware advancement rates have plateaued over the past two decades [1].This shift has redirected focus toward enhancing software's non-functional properties to meet the increasing demand for improved software performance.Given the escalating complexity of modern software, research in software engineering has emphasized automated strategies to optimize software without manual intervention [2].These strategies include program transformations, software parameter tuning, and compiler flag optimization, each aiming to navigate a vast search space of potential software variants to improve efficiency, execution speed, and robustness.Tools such as genetic improvement frameworks like PyGGI [3] and parameter tuning utilities like irace [4] and ParamILS [5] exemplify some of these approaches, offering structured methods for automated optimization across a wide array of software applications.</p>
<p>Genetic improvement (GI) is a prominent technique for optimizing software, offering a structured approach to evolving software variants toward optimal solutions.At the heart of GI lies the search strategy, most frequently genetic programming (GP) [6].The crossover operation plays a crucial role in GP -modifications from parent variants are combined to produce new offspring variants.However, traditional crossover methods, which typically rely on random or uniform selection of modifications from parent variants, often struggle to yield high-quality results efficiently.In the context of source code modification, randomly combining edits can lead to poorly integrated code, resulting in compilation or test failures.Similarly, in parameter tuning, incompatible parameter combinations may be selected, further hindering the effectiveness of crossover.Consequently, traditional crossover approaches can be both ineffective at identifying beneficial edits and inefficient at navigating the solution space, underscoring the need for more intelligent, context-aware crossover mechanisms.</p>
<p>The recent advancements in Large Language Models (LLMs) offer a promising solution to this challenge.LLMs such as GPT-4, trained on vast amounts of text and code, are capable of generating complex code structures, taking into account their context.By leveraging this contextual power, an LLM-assisted crossover approach could theoretically overcome the limitations of conventional crossover methods.Specifically, an LLM could be used to select and combine only those modifications that are likely to integrate well (as such patterns have been observed in large amounts of code), resulting in higher-quality, compilable variants and parameter combinations that have multiplicative effects on the fitness.We hypothesize that LLM-assisted crossover not only has the potential to produce more performant variants but also to increase the number of viable variants by avoiding code combinations that lead to compilation or runtime errors.Furthermore, as AI technology has rapidly advanced in recent years, we now have access to powerful models that can be integrated into genetic improvement frameworks to enhance traditional search-based optimization techniques.</p>
<p>In this work, we implement and evaluate LLM-assisted crossover within the MAGPIE [7] framework.MAGPIE is a flexible and extensible framework for search-based software improvement, designed to support a wide range of modification types, including statement-level changes and parameter tuning.In our experiments, we apply the LLM-assisted crossover to 7 benchmark programs, using both parameter tuning and direct source code modification to assess its effectiveness.</p>
<p>We aim to answer the following questions: Can LLMassisted crossover improve the quality of generated software variants?Can it accelerate the discovery of optimal solutions compared to traditional crossover techniques and can it lead to more viable variants?By exploring these questions, we aim to demonstrate that LLMs can enhance the genetic improvement process, making it a more efficient and effective tool for software performance optimization.</p>
<p>Our results show that LLM-assisted crossover achieved an average ranking of 2.27 (on a scale where 1 is best and 6 is worst), making it the top-performing method across benchmarks based on the quality of the optimal variants produced.The LLM-based approach also improved the fitness (execution time) by an average of 8.5% over the best variant produced by the traditional methods.In terms of efficiency, the LLM-assisted crossover required 25.6% fewer variants to reach 25%, 50%, 75%, and 100% of the final performance improvement compared to the average of the traditional methods.Additionally, the LLM-assisted crossover produced 4.8% more viable variants across scenarios, including both source code modification and parameter tuning cases.Hence we recommend its use in future work.</p>
<p>II. BACKGROUND</p>
<p>In this section we introduce genetic improvement, role of crossover, and the MAGPIE framework.</p>
<p>A. Genetic Improvement and Crossover</p>
<p>Genetic Improvement (GI) is a subset of search-based software engineering that uses evolutionary algorithms to enhance software by modifying its source code, parameters, or other configurations.Genetic programming (GP) is a core technique in GI, employing operations like mutation and crossover to evolve software variants that exhibit improved performance or functionality.Crossover, specifically, is a key operation in GP where modifications from two or more parent solutions are combined to create offspring solutions.This process is integral to exploring the solution space, as it enables beneficial traits from multiple parents to be recombined in novel ways.</p>
<p>Numerous crossover methods have been explored in genetic programming [8].In this study, we focus on five prevalent crossover techniques to evaluate their effectiveness in generating viable, high-performing variants, comparing them to an LLM-assisted approach.</p>
<p>• UniformConcat: This method interleaves edits from two parent variants uniformly, aiming for a balanced combination of traits.</p>
<p>• Concat: Here, edits from one parent are appended with edits from the other, allowing for a straightforward concatenation of traits.• 1Point: A single crossover point is chosen in both parents, with edits swapped at this point to create new variants.• 2Point: Two crossover points are selected, allowing for a more flexible crossover where edits between the points are exchanged.</p>
<p>• UniformInter: This method selects edits from both parents in a uniform yet interleaved manner, aiming to combine traits without fixed crossover points.</p>
<p>These methods represent a variety of traditional approaches to crossover, offering different ways of blending parental modifications.However, as discussed earlier, they may lack the contextual awareness needed for integrating complex modifications effectively.</p>
<p>B. Large Language Models (LLMs)</p>
<p>Large Language Models (LLMs) are advanced machine learning models trained on massive datasets, allowing them to generate human-like text and complex language structures.LLMs like GPT-4 and its variants have been trained on extensive datasets that include both natural language and source code, enabling them to leverage context to produce human-like code snippets.This capability makes LLMs highly valuable for tasks that require context to be taken into account.</p>
<p>In this study, we utilize GPT-4o-mini, a streamlined variant of the GPT-4 model that maintains much of the original model's performance in code-related tasks while operating with reduced computational requirements.GPT-4o-mini serves as the core of our LLM-assisted crossover approach, where it is tasked with selecting and combining beneficial edits from parent solutions.By leveraging the LLM's contextual awareness, we aim to produce not only higher-quality variants but also a greater number of viable ones, as the LLM can potentially avoid incompatible modifications that might lead to compilation errors or test failures.</p>
<p>C. MAGPIE Framework</p>
<p>MAGPIE is a flexible framework for search-based software improvement [7], offering a structured platform for exploring both structural and parametric optimizations.Modifications are captured as edits, which represent the changes applied to source code or parameter files.An edit may involve actions such as inserting, replacing, or deleting code statements or adjusting parameter values.</p>
<p>MAGPIE represents programs in a language-agnostic XML format, enabling it to handle benchmarks in various programming languages.This edit-sequence-based approach decouples the search process from specific improvement techniques, making MAGPIE adaptable to a broad range of optimization tasks.Our experiments utilize MAGPIE's GP search strategy, enhanced by an LLM-assisted crossover implementation.This setup enables us to compare traditional crossover techniques with our LLM-driven approach, assessing its ability to produce high-quality solutions efficiently.To evaluate fitness, we employ the Linux time command, aiming to reduce the runtime of the selected benchmarks.By integrating LLMs into MAGPIE, we leverage contextual knowledge to improve the selection and combination of edits, enhancing the overall optimization process.</p>
<p>III. LLM-ASSISTED CROSSOVER OPERATOR</p>
<p>The LLM-assisted crossover operator introduces an API call at the heart of the crossover process, where the LLM is used to intelligently select and combine edits from parent solutions.The LLM receives a selection of parent solutions, in the form of a list of modifications, along with their fitness scores, and evaluates which modifications from each parent, if any, should be applied to create an optimized child variant.</p>
<p>To enhance the LLM's decision-making, we also provide optional contextual information, which varies based on the type of optimization task.For source code modifications, the LLM receives the file being modified, allowing it to evaluate the parent modifications in the context of the code structure and syntax.For parameter tuning, we include relevant documentation describing each parameter, including its purpose, possible values, and constraints.This contextual information helped ensure that the LLM applied modifications correctly, especially in cases where certain parameter combinations could lead to non-viable configurations.</p>
<p>A critical consideration in designing the LLM-assisted crossover was preventing unwanted mutations.Since the goal of crossover is to combine existing modifications rather than introduce new ones, we introduce a post-processing stage to verify that all edits in the child variant were sourced from at least one of the selected parent solutions.This postprocessing step ensures that the LLM does not introduce hallucinations or extraneous modifications that could lead to unintended behavior, particularly in scenarios where the LLM might attempt to apply a novel change outside the scope of parent modifications.</p>
<p>Overall, the LLM-assisted crossover method allows for a more context-aware selection of edits, with the LLM using parent fitness scores and optionally provides documentation to guide the choices.This setup enabled us to evaluate whether LLM-driven crossover could generate more effective and viable variants compared to traditional methods.</p>
<p>A. Motivational Example: LLM-Assisted Crossover in Parameter Tuning for Zlib Compression</p>
<p>To illustrate the potential of LLM-assisted crossover, consider the task of tuning parameters to increase runtime speed in the Zlib compression library.Zlib offers various configuration parameters, such as 'level' and 'memLevel', which control aspects of compression quality and memory usage.While achieving the fastest possible speed would obviously affect the compression quality, our focus on this example is on achieving some level of compression while prioritizing speed as the primary and only objective.</p>
<p>Suppose we have two promising parent configurations: Parent 1:</p>
<p>• ParamSetting(('zlib.params', 'param', 'wbits'), 30) • ParamSetting(('zlib.params', 'param', 'level'), 2)</p>
<p>Parent 2:</p>
<p>• ParamSetting(('zlib.params', 'param', 'strategy'), 2) • ParamSetting(('zlib.params', 'param', 'memLevel'), 8)</p>
<p>In these configurations, Parent 1 sets 'level' to a low value (2), favoring speed over compression quality, while Parent 2 sets 'memLevel' to a high value (8), allowing for faster processing at the expense of increased memory usage.Both configurations effectively prioritize speed, each addressing a different aspect: compression level and memory allocation.</p>
<p>With many traditional crossover techniques, a child variant generated from these parents might appear as follows:</p>
<p>• ParamSetting(('zlib.params', 'param', 'strategy'), 2) • ParamSetting(('zlib.params', 'param', 'wbits'), 30)</p>
<p>This child variant loses both of the beneficial configurations related to 'level' and 'memLevel', potentially resulting in a less optimal solution for runtime improvement.</p>
<p>In contrast, with LLM-assisted crossover, especially when provided with documentation context, the LLM is more likely to connect 'level' and 'memLevel' with execution speed.Consequently, it has a high probability of including both of these modifications in the child variant.By selecting configurations that are contextually relevant to speed optimization, the LLM-assisted crossover can create a more effective child variant faster, reducing the need to experiment with suboptimal configurations.</p>
<p>LLM's Explanation:</p>
<p>To create a child program that optimizes runtime based on the provided parents and their edits, I will select the following edits:</p>
<p>• ParamSetting(('zlib.params', 'param', 'level'), 2) is beneficial because it lowers the compression level, resulting in faster compression.</p>
<p>• ParamSetting(('zlib.params', 'param', 'memLevel'), 8) is advantageous as it increases the memory level, which can improve performance and thus lower runtime.</p>
<p>IV. RESEARCH QUESTIONS</p>
<p>This study examines the potential of LLM-assisted crossover in genetic programming within the MAGPIE framework by addressing the following research questions:</p>
<p>A. RQ1: Does LLM-assisted crossover lead to higher-quality variants than traditional crossover operators?</p>
<p>Our first objective is to determine if LLM-assisted crossover produces higher-quality software variants compared to traditional crossover methods.Specifically, we aim to assess whether LLM-assisted crossover achieves lower fitness values (execution times), indicating better-performing solutions across various benchmarks.We will not only be comparing the optimal variant that the GP process produces but all the variants that are produced along the way.Additionally, we compare the overall ranking of each crossover method for each benchmark, with the goal of identifying whether the LLMbased approach consistently outperforms traditional methods in generating high-quality variants.</p>
<p>B. RQ2: Which crossover method finds improved variants most efficiently?</p>
<p>The second research question focuses on the efficiency of each crossover method in quickly identifying improved variants.Here, we aim to understand whether LLM-assisted crossover can reach significant performance milestones, such as partial or full achievement of the best possible improvement, more rapidly than traditional approaches.Our goal is to establish whether the LLM approach enables faster convergence to optimized solutions.</p>
<p>C. RQ3: Does LLM-assisted crossover generate more viable variants than traditional crossover operators?</p>
<p>The final research question investigates the viability of the generated variants.We seek to determine whether LLMassisted crossover produces a higher proportion of viable solutions, variants that successfully compile, run and pass tests, across both source code modification and parameter tuning scenarios.By assessing viability across different modification types, we aim to understand if the LLM approach enhances the reliability of generated solutions, particularly in scenarios where traditional crossovers may struggle with functional integration.</p>
<p>V. METHODOLOGY</p>
<p>Next, we present our methdology to answer our RQs.</p>
<p>A. Experimental Design</p>
<p>To evaluate the effectiveness of LLM-assisted crossover, we conducted experiments using the MAGPIE framework on a set of carefully selected benchmarks.The experimental setup was designed to assess both the quality and efficiency of the generated variants across various crossover methods.</p>
<p>1) Benchmarks: Our experiments with MAGPIE utilized benchmarks from Blot and Petke [7]: MiniSAT, MiniSAT_hack, SAT4J, Weka, and LPG, selected for their proven suitability for meaningful optimizations within MAGPIE.We also included scipy.optimize.minimizeand zlib.compress to introduce diverse computational challenges.While all scenarios yielded mutants with improvements over the initial configuration, our focus lies on comparing the performance of different crossover methods rather than assessing MAGPIE's overall optimization capabilities.</p>
<p>In total, we configured and executed 7 different benchmarks across various functionality and programming languages.For three benchmarks (scipy, zlib, and LPG), only parameter tuning was conducted, as scipy and zlib lack obvious source code improvement opportunities, and LPG was incompatible with our system's compiler.For the remaining four benchmarks, both parameter tuning and direct source code modifications were performed, resulting in a total of 11 distinct scenarios.More details for the benchmarks are presented in Table I.We start with the default parameter values and allow for all configurable parameters to be tuned.</p>
<p>2) LLM Model: The LLM-assisted crossover used in this study relies on GPT-4o-mini-2024-07-18, a lightweight version of GPT-4 specifically designed to balance model complexity and computational efficiency.GPT-4o-mini was selected for its good performance in code-related tasks and reduced computational requirements, making it feasible to incorporate in, iterative crossover operations.</p>
<p>3) Genetic Programming Configuration: The genetic programming (GP) configuration used in our experiments was as follows:
• pop_size = 20 • offspring_elitism = 0.2 • offspring_crossover = 0.6 • offspring_mutation = 0.2
The experiments were conducted over a total of 11 epochs, so that crossover would be performed 10 times.This configuration, particularly the high crossover rate of 0.6, was chosen to emphasize the crossover operation's influence on the generated variants.By setting the crossover rate relatively high, we aimed to create a wide but shallow search, where the effects of an effective crossover method would be more apparent.</p>
<p>In each epoch, crossover plays a significant role in the generation of new variants, with 60% of the offsprings resulting from crossover rather than mutation or elitism.This setup allows us to directly assess the effectiveness of the LLM-assisted crossover compared to traditional methods, particularly in its ability to generate high-quality and viable variants efficiently.All the new variants are tested to ensure that the changes don't break functionality.</p>
<p>4) LLM-Assisted Crossover Implementation: In addition to running MAGPIE with five traditional crossover methods, we created a sixth version of crossover driven by an LLM, specifically GPT-4o-mini-2024-07-18.The implementation follows the approach outlined in Section III.Specifically, our LLM prompts include the following elements:</p>
<p>• Optimization Objective and Fitness Metric: Information on what we are optimizing for, with the fitness defined as runtime.• Parent Variants: Each parent variant is provided as a list of modifications, along with its respective fitness score, to guide the LLM in selecting beneficial edits.constraints or dependencies between parameters.This additional context helps the LLM make informed decisions about parameter combinations.The LLM is then instructed to generate a child variant by combining modifications from the parent variants to create the fittest possible child, specifically aimed to minimize runtime.</p>
<p>B. Computational Environment and Overhead</p>
<p>All experiments were conducted on a Ubuntu Linux 22.04 desktop machine equipped with an 8-core AMD Ryzen 7 4700 CPU and 16 GB of RAM.This setup provided sufficient computational resources to execute the experiments within a reasonable timeframe.</p>
<p>The LLM API calls to GPT-4o-mini-2024-07-18 incurred minimal financial and time overhead.On average, each API call involved 1980 input tokens and 103 output tokens, resulting in a cost of $0.0003618 per call.With 120 API calls required per benchmark, the total cost per benchmark was less than half a penny ($0.0043618), making the approach highly affordable for iterative experiments.</p>
<p>Regarding time overhead, the average time per API call was measured at 2.92 seconds, leading to a total time overhead of approximately 350.4 seconds per benchmark.Given that the testing and the evaluation of the fitness of each mutant typically takes over 20 seconds, this additional overhead is relatively low, particularly since only 60% of the generated mutants undergo crossover.This balance between efficiency and cost demonstrates the feasibility of integrating LLMassisted crossover into genetic programming workflows without significant resource consumption.</p>
<p>VI. RESULTS AND DISCUSSION</p>
<p>Next, we present and analyse the results of our study.</p>
<p>A. RQ1: Does LLM-assisted crossover lead to higher-quality variants than traditional crossover operators?</p>
<p>To address RQ1, we compared the quality of the final variants produced by each crossover method.We used the average optimal fitness of the best variants as the primary quality measure and included the average fitness across all variants to evaluate overall performance.The average fitness was firstly calculated per benchmark and then the average for all benchmarks was produced, to avoid giving higher weights to benchmarks with more viable variants.Additionally, we ranked each method from best to worst on each benchmark based on the optimal variant's execution time, then calculated an average ranking across all benchmarks.A crossover method with lower average optimal fitness, lower average fitness, and higher rankings (closer to 1 than 6) indicates a more effective approach.</p>
<p>Table II presents a summary of the average optimal fitness, average fitness scores, and average rankings for each of the six crossover methods across the benchmarks.</p>
<p>The results in Table II show that the LLM-assisted crossover method achieved the lowest average optimal fitness time at 4.477 seconds and the highest average ranking at 2.27 across all benchmarks.Additionally, it produced the lowest average fitness score across all variants (5.834 s), indicating that it consistently generated high-quality variants, not just a single top-performing variant.In comparison, the UniformConcat method achieved the second-best average ranking (3.0) but had a higher average best execution time and average fitness score (4.598 and 6.094 seconds, respectively).</p>
<p>These results suggest that LLM-assisted crossover is not only effective in finding the best-performing variants but also reliable in generating multiple high-quality variants on average, outperforming traditional methods in both quality and consistency.</p>
<p>Answer to RQ1: The LLM-assisted crossover method produced higher-quality variants.It led to the lowest average execution time, being 8.5% faster on average than the 5 traditional crossover methods, while the average variant from the LLM-assisted experiments was 6.1% faster than the average variant in the experiments with the traditional crossover methods.The LLM-assisted approach also accomplished the best average ranking (2.27) demonstrating its effectiveness in generating both high-performing and consistent variant quality across benchmarks.</p>
<p>B. RQ2: Which crossover method finds improved variants most efficiently?</p>
<p>To evaluate the efficiency of each crossover method in reaching improved variants, we analyzed the number of variants required to achieve incremental improvements relative to the optimal variant found in each benchmark.Specifically, we measured how many variants each crossover method needed, on average, to reach 25%, 50%, 75%, and 100% of the best possible improvement in execution speed.Here, 25% improvement signifies that the variant achieved 25% of the total potential improvement in speed reduction relative to the optimal variant.For each crossover method, we calculated the average index of the variant at which these milestones were reached and then averaged the results across all benchmarks.</p>
<p>If a crossover method failed to reach any of these milestones (25%, 50%, 75%, or 100%) in a benchmark, it was assigned a value of 250 variants for that milestone, as the maximum number of variants allowed was 220.This penalty discourages methods that failed to reach specific improvement milestones, emphasizing the importance of finding efficient paths toward high-performing variants.</p>
<p>Table III presents the average variant index required by each crossover method to reach each improvement milestone across all benchmarks.</p>
<p>The results in Table III indicate that the LLM-assisted crossover method reached each performance milestone faster than traditional crossover methods, as evidenced by the lower average variant indices across all improvement levels, with the LLM method needing on average 25.6% less variants.For example, LLM-assisted crossover required an average of 39.82 variants to reach 25% of the best improvement and 209.18 variants to reach 100% of the best improvement, outperforming the next closest method, UniformConcat, which required 56.45 and 227.27 variants, respectively, for these milestones.In cases where a method did not reach certain milestones within the benchmark constraints, the penalty of 250 variants was applied, impacting the overall efficiency score.Answer to RQ2: The LLM-assisted crossover method found improved variants more quickly than traditional methods, reaching performance milestones with 25.6% fewer generated variants on average.</p>
<p>C. RQ3: Does LLM-assisted crossover generate more viable variants than traditional crossover operators?</p>
<p>To answer RQ3, we compared the number of viable variants (which are variants that successfully compiled, run and passed tests), produced by each crossover method across both source code modification and parameter tuning scenarios.While parameter tuning typically results in a higher proportion of viable variants, certain parameter combinations can still lead to non-viable outcomes due to compatibility constraints.In the case of source code modifications, structural incompatibilities often pose a greater challenge, leading to non-viable variants.Therefore, the number of viable variants serves as a key metric for evaluating the effectiveness of the LLM-assisted crossover in generating functional solutions across a variety of modification types.</p>
<p>Given our experimental setup of 11 epochs with a population size of 20, the theoretical maximum number of viable variants for each crossover method is 220.Table IV presents the average number of viable variants generated by each crossover method across all modification scenarios.</p>
<p>The results in Table IV show that the LLM-assisted crossover generated the highest average number of viable variants (194.45),approaching the theoretical maximum of 220.This suggests that LLM-assisted crossover is more effective at maintaining functionality across both source code and parameter modifications, likely due to its context-aware selection process, which minimizes structural and compatibility issues.In comparison, the next highest average number of viable variants was achieved by UniformConcat (187.73),which, while effective, still produced 3.5% fewer viable outcomes than the LLM-assisted approach.On average the LLM-assisted approach produced 4.8% more viable variants than the other methods.Answer to RQ3: The LLM-assisted crossover generated the highest number of viable variants across all modification scenarios, with an average of 4.8% more viable variants generated compared to the traditional crossover methods, demonstrating its ability to effectively maintain functionality in both source code and parameter tuning cases.</p>
<p>VII. THREATS TO VALIDITY</p>
<p>Several factors may affect the generalizability and robustness of our findings in this initial exploration of LLMassisted crossover in GP.First, all experiments were conducted on a single computer with limited computational and financial resources, which restricted us to using only one LLM model, GPT-4o-mini.The potential impact of different LLMs on crossover effectiveness remains unexplored, and in future work we plan to evaluate additional models to provide broader insights.</p>
<p>The scope of benchmarks and scenarios is also limited, as our experiments were performed on seven benchmarks across 11 distinct scenarios, covering both parameter tuning and source code modification cases.Although these benchmarks provide a varied sample, they do not encompass the full range of possible optimization contexts or programming languages, which may affect the generalizability of the results.Moreover, this study was conducted exclusively within the MAGPIE framework, without testing on other search-based software improvement tools.As MAGPIE's representations, fitness evaluations, and genetic operators are specific to its design, evaluating LLM-assisted crossover within other frameworks could provide additional perspectives on its effectiveness.</p>
<p>Another factor to consider is the inherent randomness in genetic programming, particularly in selection, mutation, and crossover processes.Due to time and resource constraints, we conducted only a single run of each experiment, without The values in each column represent the average number of variants required by each crossover method to reach 25%, 50%, 75%, and 100% of the maximum observed speed improvement across benchmarks.If a crossover method failed to reach a specific milestone within the allowed 220 variants, a penalty value of 250 variants was assigned for that milestone.repetitions to account for random variations.As a result, our findings may be influenced by specific random outcomes, and repeating these experiments in future work would help confirm the consistency of the results.Additionally, while LLM responses are not strictly deterministic, some degree of variance in LLM-assisted crossover can actually be beneficial.The probabilistic nature of LLMs introduces variability in responses, which may occasionally lead to highly beneficial edits or, conversely, to suboptimal modifications.However, this diversity allows genetic programming to explore a broader range of solutions, increasing the chance of discovering effective variants over time.Our approach does not rely on consistently optimal responses from the LLM; rather, it aims to produce variants that, on average, are of higher quality than those generated by traditional crossover methods.Running the same benchmarks multiple times would provide additional data on the robustness of LLM-assisted crossover, but in this specific context, the natural variance can enrich the search process and contribute positively to genetic programming's overall effectiveness.</p>
<p>This study serves as an initial investigation to gauge the potential of LLM-assisted crossover.Our findings suggest promising benefits for variant quality and viability, motivating further research in this direction.Future work will expand this study by including additional benchmarks, experimenting with different LLM models, and conducting multiple repetitions to enhance the robustness and generalizability of the results.</p>
<p>VIII. RELATED WORK</p>
<p>Genetic algorithms (GAs) are optimization methods inspired by the principles of natural evolution, initially developed by Holland [9].Within GAs, crossover is a crucial operator that facilitates both exploration and exploitation of the solution space by combining genetic information from parent solutions.Numerous crossover methods, such as single-point, two-point, multi-point, and uniform crossover, have been proposed, each offering different benefits depending on problem context and population characteristics [10], [11].For instance, Hasanc ¸ebi and Erbatur [12] found that two-point crossover often yields better outcomes for larger populations, while Syswerda [10] suggests that uniform crossover can be advantageous in certain scenarios.These insights underscore the importance of selecting appropriate crossover techniques to suit the specific requirements of a problem.</p>
<p>While traditional crossover techniques rely on structural manipulations, recent research has focused on integrating semantic or context-aware knowledge into the crossover process.Beadle and Johnson's Semantically Driven Crossover (SDC) [13] is a notable example, using reduced ordered binary decision diagrams to ensure that child programs exhibit behavioral differences from their parents.This semantically guided approach reduces redundancy in crossover operations, leading to improved performance and reduced code bloat.However, SDC is specifically tailored for semantic equivalence checking, which makes it computationally expensive for largescale applications.In contrast, our LLM-assisted crossover operates at a higher level, leveraging domain knowledge and contextual information to produce effective solutions without the overhead of fine-grained semantic checks.</p>
<p>Similarly, Krawiec and Pawlak's Locally Geometric Semantic Crossover (LGX) [14] introduces a method that considers semantic properties when creating offspring, generating behaviorally intermediate solutions by selecting homologous regions in parent programs.While LGX enhances search efficiency by focusing on semantically meaningful regions, it is inherently tied to geometric relationships in the program's semantic space.Our LLM-assisted crossover, by contrast, uses pre-trained language models to interpret high-level contextual information, making it more adaptable across diverse problem domains without requiring explicit semantic mappings.</p>
<p>Shem-Tov and Elyasaf propose a Deep Neural Crossover (DNC) operator that leverages deep reinforcement learning and an LSTM-based encoder-decoder to guide gene selection in crossover operations [15].DNC applies an attention-driven policy that dynamically selects genes to maximize offspring fitness, achieving higher solution quality and convergence rates.However, DNC requires significant pre-training and fine-tuning for specific problem domains, which can be resourceintensive and limits its immediate applicability.Our LLMassisted crossover, in contrast, is designed to work out of the box, requiring minimal setup and no additional training, making it a more practical solution for a wide range of optimization tasks.</p>
<p>The study by Hameed and Kanbar [16] also highlights the importance of adaptive crossover strategies, demonstrating that the performance of different crossover operators varies significantly depending on problem characteristics.Their findings reinforce the need for customized crossover techniques, supporting the motivation for our LLM-assisted approach, which dynamically adapts to diverse optimization scenarios through its ability to leverage contextual insights.</p>
<p>IX. CONCLUSION</p>
<p>This study provides an initial exploration into using LLMs to assist in the crossover process of genetic programming, aiming to enhance variant quality and accelerate optimization.</p>
<p>By integrating an LLM into the MAGPIE framework, we observed several key improvements with LLM-assisted crossover compared to traditional methods: LLM-assisted crossover achieved an average ranking of 2.27 across benchmarks (where 1 is best and 6 is worst), making it the topperforming method based on the quality of the optimal variants produced.The LLM-based approach improved the execution time of the best variant by an average of 8.5% over the best variant produced by traditional crossover methods.In terms of efficiency, LLM-assisted crossover required 25.6% fewer variants on average to reach 25%, 50%, 75%, and 100% of the final performance improvement, compared to the average of traditional methods.Additionally, the LLMassisted crossover produced 4.8% more viable variants across all scenarios, encompassing both source code modification and parameter tuning cases.</p>
<p>These results suggest that LLMs can effectively leverage contextual information to guide the search process toward optimal solutions, producing not only higher-quality variants but also a greater number of viable solutions and with greater efficiency in reaching performance milestones.</p>
<p>While our findings are promising, this work serves primarily as motivation for further investigation into LLMassisted crossover.Expanding this approach with a broader range of benchmarks, additional LLM models, and repeated experiments will help validate and refine the benefits observed here.Future research can also explore integrating LLMs into other stages of genetic programming like mutation, or testing on diverse optimization frameworks.This study lays the groundwork for continued exploration of LLM-assisted techniques, encouraging broader applications and more consistent use of LLMs in genetic improvement and other evolutionary computation methods.</p>
<p>Average Fitness of all variants in seconds.
TABLE IICOMPARISON OF CROSSOVER METHODS BASED ON EXECUTION TIME,AVERAGE FITNESS, AND RANKING ACROSS BENCHMARKS (RQ1)Crossover MethodAOF(s)AF(s) Avg RankingUniformConcat4.5986.0943.00Concat4.7345.8413.551Point4.9716.3333.822Point5.1696.4634.27UniformInter4.9916.3484.09LLM-Assisted4.4775.8342.27AOF (s): Average Optimal Fitness in seconds.AF (s):</p>
<p>TABLE III COMPARISON
III
OF CROSSOVER METHODS BASED ON EFFICIENCY IN REACHING IMPROVEMENT MILESTONES (RQ2)
Crossover Method25% Improvement 50% Improvement75% Improvement100% ImprovementUniformConcat56.45 variants68.55 variants112.27 variants227.27 variantsConcat72.91 variants105.82 variants140.73 variants228.73 variants1Point70.18 variants78.55 variants179.45 variants242.27 variants2Point97.73 variants129.64 variants170.18 variants230.73 variantsUniformInter77.36 variants130.27 variants135.18 variants244.91 variantsLLM-Assisted Crossover39.82 variants48.27 variants119.00 variants209.18 variantsNote:
X. DATA AVAILABILITY All code, documentation, results and complimentary material for this work is available in our repository: https://github.com/SOLAR-group/LLMAssisted Crossover.
More than moore. M M Waldrop, Nature. 5302016</p>
<p>Towards fully automated test management for large complex systems. S Eldh, J Brandt, M Street, H Hansson, S Punnekkat, 2010 Third International Conference on Software Testing, Verification and Validation. 2010</p>
<p>Pyggi 2.0: language independent genetic improvement framework. G An, A Blot, J Petke, S Yoo, 10.1145/3338906.3341184ser. ESEC/FSE 2019Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software EngineeringNew York, NY, USAAssociation for Computing Machinery2019</p>
<p>The irace package: Iterated racing for automatic algorithm configuration. M López-Ibáñez, J Dubois-Lacoste, L Pérez Cáceres, T Stützle, M Birattari, Operations Research Perspectives. 32016</p>
<p>Paramils: An automatic algorithm configuration framework. F Hutter, H H Hoos, K Leyton-Brown, T Stuetzle, 10.1613/jair.2861Journal of Artificial Intelligence Research. 36Oct. 2009</p>
<p>Genetic improvement of software: A comprehensive survey. J Petke, S O Haraldsson, M Harman, W B Langdon, D R White, J R Woodward, IEEE Transactions on Evolutionary Computation. 2232018</p>
<p>Magpie: Machine automated general performance improvement via evolution of software. A Blot, J Petke, 2022</p>
<p>Simple evolutionary algorithms. X Yu, M Gen, 10.1007/978-1-84996-129-5_22010</p>
<p>Adaptation in Natural and Artificial Systems. J Holland, 1975University of Michigan Press</p>
<p>Uniform crossover in genetic algorithms. G Syswerda, Proceedings of the Third International Conference on Genetic Algorithms. the Third International Conference on Genetic AlgorithmsMorgan Kaufmann1989</p>
<p>An analysis of the interacting roles of population size and crossover in genetic function optimization. D Jong, W Spears, Parallel Problem Solving from Nature. Springer1990</p>
<p>A revised comparison of crossover and mutation in genetic programming. O Hasanc, F Erbatur, Computers &amp; Structures. 7842000</p>
<p>Semantically driven crossover in genetic programming. L Beadle, C G Johnson, 2008 IEEE Congress on Evolutionary Computation. 2008</p>
<p>Locally Geometric Semantic Crossover : A Study on the Roles of Semantics and Homology in Recombination Operators. K Krawiec, T Pawlak, 2013</p>
<p>Deep neural crossover. E Shem-Tov, A Elyasaf, 10.48550/arXiv.2403.11159arXiv:2403.11159Genetic and Evolutionary Computation Conference. 2024arXiv preprintGECCO 2024), pp. 7 pages, 3 figures, 4 tables</p>
<p>A comparative study on crossover operators of genetic algorithm for traveling salesman problem. X.-A Dou, Q Yang, X.-D Gao, Z.-Y Lu, J Zhang, 2023 15th International Conference on Advanced Computational Intelligence (ICACI). 2023</p>            </div>
        </div>

    </div>
</body>
</html>