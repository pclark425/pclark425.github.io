<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4828 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4828</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4828</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-106.html">extraction-schema-106</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <p><strong>Paper ID:</strong> paper-235358778</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2106.03121v1.pdf" target="_blank">End-to-End Neuro-Symbolic Architecture for Image-to-Image Reasoning Tasks</a></p>
                <p><strong>Paper Abstract:</strong> Neural models and symbolic algorithms have recently been combined for tasks requiring both perception and reasoning. Neural models ground perceptual input into a conceptual vocabulary, on which a classical reasoning algorithm is applied to generate output. A key limitation is that such neural-to-symbolic models can only be trained end-to-end for tasks where the output space is symbolic. In this paper, we study neural-symbolic-neural models for reasoning tasks that require a conversion from an image input (e.g., a partially filled sudoku) to an image output (e.g., the image of the completed sudoku). While designing such a three-step hybrid architecture may be straightforward, the key technical challenge is end-to-end training -- how to backpropagate without intermediate supervision through the symbolic component. We propose NSNnet, an architecture that combines an image reconstruction loss with a novel output encoder to generate a supervisory signal, develops update algorithms that leverage policy gradient methods for supervision, and optimizes loss using a novel subsampling heuristic. We experiment on problem settings where symbolic algorithms are easily specified: a visual maze solving task and a visual Sudoku solver where the supervision is in image form. Experiments show high accuracy with significantly less data compared to purely neural approaches.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4828.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4828.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NSNnet (Visual Maze)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural-Symbolic-Neural network (NSNnet) applied to Visual Maze</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An end-to-end trainable neuro-symbolic-neural architecture that maps input images of grid mazes to output images marking the shortest path by (1) a neural encoder that grounds pixels to symbols, (2) a symbolic shortest-path solver (Dijkstra), and (3) a neural decoder (array of VAEs) that renders the solution image; trained with a REINFORCE-like policy-gradient plus a subsampling heuristic and an output-style encoder for reconstruction supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>NSNnet</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Three-stage hybrid: (a) input encoder M_e implemented per-cell (LeNet-style CNN for digits in Sudoku tasks; for Visual Maze a small fully-connected classifier for 0/1), which outputs a distribution over discrete cell symbols; (b) symbolic module SYM (Dijkstra's algorithm for shortest path) that consumes sampled symbols and emits symbolic solution ŷ; (c) output decoder M_d implemented as an array of variational autoencoders (one VAE per symbol) that take the symbolic solution and a style latent z from output encoder M_oe to reconstruct an output image. Training uses Monte-Carlo sampling of symbol assignments (K=128), a REINFORCE-like gradient for M_e, reward-gradient (backprop) for M_d and M_oe, and a subsampling heuristic that keeps only top η fraction of sampled symbol assignments to mitigate sparse-reward cold-start. Exact parameter counts are not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Visual Maze (grid shortest-path)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Grid mazes whose cells contain MNIST-digit images representing wall/empty; the task is to output an image of the same maze where cells on the unique shortest path (top-left to bottom-right) are marked with a different digit. Solving requires spatial reasoning about adjacency and path connectivity on the grid.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Neuro-symbolic pipeline: per-cell neural classification to discrete symbols → symbolic graph algorithm (Dijkstra) to compute shortest path → per-cell VAE decoder to render solution image; end-to-end training via policy-gradient (REINFORCE-like) where reconstruction loss of final image serves as reward signal; output-style encoder M_oe extracts style latents from ground-truth output during training; subsampling heuristic keeps top η fraction of Monte-Carlo samples to bias learning toward high-reward samples and overcome sparse-reward cold-start.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Spatial reasoning is explicit in the symbolic module: SYM runs Dijkstra's shortest-path algorithm on the grid of decoded symbols, so correct behavior requires identifying cell roles (wall/empty) and globally computing connectivity. Empirical evidence: NSNnet achieves high path (task completion) accuracy (TCR) while VIN baseline degrades with larger mazes (VIN TCR < 5% at 19×19); ablation studies show that removing the symbolic/reward-gradient components yields zero TCR, indicating the model relies on the symbolic spatial reasoning step. Qualitative outputs (sample images) and path-accuracy metrics reported in tables provide additional evidence (tables cited in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics: task completion rate (TCR: fraction of mazes where exact symbolic path was found) and classification accuracy (CA) of per-cell symbol labeling. Exact numeric values for NSNnet per-size are reported in the paper tables (not reproduced in-text), but authors state 'high' CA and high TCR across maze sizes tested; VIN baseline drops to <5% TCR for 19×19. Training/dev/test sets each contained 1000 maze instances per grid size; K (samples) = 128; subsampling fraction η varied (e.g., 1, 1/2, 1/16, 1/32, 1/128).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Cold-start/sparse-reward problem requires the subsampling heuristic; without it or without the reward-gradient term the method gets zero TCR (ablation). The approach assumes a highly structured grid input (cell segmentation known) and a known symbol dictionary size; not evaluated on unstructured/naturalistic images. Computational cost: symbolic module makes workloads CPU-intensive (no GPUs used in experiments). When classifier accuracy drops slightly, task completion (0/1) degrades sharply because the metric requires all path cells to be correct. SYM may fail to find a path if sampled symbols are inconsistent with a path (early training), causing zero reconstruction reward for those samples.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against Value Iteration Networks (VIN) as a purely neural baseline for shortest-path; NSNnet maintains high TCR as maze size increases while VIN scales poorly (TCR <5% at 19×19). NSNnet's per-cell classification accuracy and path accuracy are reported close to an ad-hoc system that uses pretrained classifiers and symbolic solvers (upper bound).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Neuro-Symbolic Architecture for Image-to-Image Reasoning Tasks', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4828.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4828.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NSNnet (Visual Sudoku)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural-Symbolic-Neural network (NSNnet) applied to Visual Sudoku</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>NSNnet trained end-to-end to map images of partially filled Sudoku grids (cells containing MNIST digit samples) to images of the completed Sudoku by learning a per-cell classifier, invoking a symbolic constraint solver to compute the unique grid solution, and decoding rendered digit images via a per-symbol VAE array; training uses a REINFORCE-like gradient with a subsampling heuristic and an output-style encoder for reconstruction supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>NSNnet</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Same overall NSNnet architecture: per-cell input encoder M_e implemented as a LeNet-style digit classifier (10 symbols: digits 1–9 and blank), symbolic solver SYM implemented via CP-SAT (Google OR-Tools) constraint solver to produce completed Sudoku symbolic layout, and output decoder M_d consisting of an array of VAEs (B=9 for digits 1–9) that reconstruct per-cell digit images using style latents from M_oe. Training via Monte-Carlo sampling of symbol assignments (K=128), policy-gradient for encoder, reward-gradient for decoder, and subsampling fraction η to mitigate sparse rewards. Exact model sizes not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Visual Sudoku (image-to-image Sudoku solving)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Partially filled 9×9 Sudoku grids where each filled cell contains an MNIST digit sample; the task is to output an image of the completed Sudoku using sampled instances of the correct digit in each cell. This requires reasoning over global row/column/box constraints (spatial / structural constraints across the grid).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Neuro-symbolic pipeline: per-cell neural digit classifier outputs distributions → symbolic constraint solver (OR-Tools CP-SAT) attempts to solve sampled symbolic grids (well-formedness enforced during sampling) to obtain unique solution ŷ → per-symbol VAEs decode ŷ and training-only output encoder M_oe provides style latents z to help reconstruction. End-to-end learning via REINFORCE-like gradient on encoder with reconstruction loss as reward, plus reward-gradient updates to decoder; critical subsampling of high-reward samples (keeping top η fraction) to escape sparse-reward cold-start.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Evidence is primarily behavioral: the symbolic solver enforces global Sudoku constraints (rows, columns, boxes), so successful task completion (TCR) indicates the system learned to ground visual digits into symbols in a way that enables the symbolic solver to satisfy spatial/structural constraints. Ablation studies show removing reward gradient or subsampling yields zero TCR and chance-level classification accuracy, indicating the necessity of the end-to-end training plus subsampling for learning to exploit the spatial constraints. The authors compare to purely neural SAT-Net (Wang et al.) and report that SAT-Net achieved 63.2% in its setting using 9× more training data, while NSNnet achieves high CA and TCR with much less data (exact NSNnet numeric values are in the paper tables).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Metrics reported: classification accuracy (CA) per-cell and task completion rate (TCR: exact-solution 0/1 metric). Datasets: 1000 train / 1000 dev / 1000 test Sudoku puzzles, reported across three difficulty tiers (easy/medium/hard). Paper reports 'high' CA and TCR across difficulty levels and notes a nonlinear relation: even very high CA may still yield lower 0/1 TCR because a single misclassified input digit breaks the solution. Exact numeric CA/TCR per difficulty are given in the paper tables (not reproduced verbatim in the text). Also quoted: SAT-Net (pure neural, image→symbol) reported 63.2% using 9× the training data.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Key limitations: cold-start sparse-reward issue must be addressed via subsampling; the model learns symbol identities only up to a permutation (no intermediate supervision), so measured CA uses the best matching permutation; small classifier errors can catastrophically reduce 0/1 TCR; symbolic solver failures (when sampled x is unsolvable) yield zero reconstruction reward; approach assumes known grid/cell segmentation and fixed symbol dictionary; not yet evaluated on naturalistic (unsegmented) images or larger Sudoku variants.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to SAT-Net (purely neural differentiable SAT solver) and a pretrained-classifier + symbolic-solver upper bound. Authors state NSNnet achieves performance close to the pretrained-classifier upper bound while being trained image-to-image, and is more data-efficient than SAT-Net (which needed 9× training data to achieve 63.2%). Ablations show other policy-gradient variants (max-entropy REINFORCE, UREX) do not overcome cold-start in these tasks, while NSNnet with subsampling does.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Neuro-Symbolic Architecture for Image-to-Image Reasoning Tasks', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4828.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4828.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VIN (Value Iteration Networks)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Value Iteration Networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A purely neural differentiable architecture designed to learn planning/value-iteration-like computations end-to-end from images for tasks such as shortest-path; cited and used as a baseline for Visual Maze experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Value iteration networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Value Iteration Network (VIN)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Convolutional neural-network architecture that embeds a differentiable planning module by approximating value iteration via convolutions and max operations; exact model-size and hyperparameters depend on implementation and were chosen in the paper's experiments (authors tuned number of value-iteration steps to be slightly larger than maze dimension).</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Maze shortest-path (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Used here as a purely neural baseline for grid shortest-path problems (same Visual Maze problem): learns to map maze images to actions/paths without an explicit symbolic graph algorithm.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>End-to-end differentiable approximation of dynamic programming/value iteration via CNN layers representing transition and reward structure; no symbolic solver. In the paper VIN was trained as a baseline with hyperparameters tuned and early stopping used due to overfitting on small datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>VIN encodes spatial structure via convolutional planning layers and learned value propagation; in this paper the evidence of spatial reasoning is empirical: VIN's performance (TCR) drops sharply as maze size increases (poor scaling), indicating limitations in learning global shortest-path reasoning compared to NSNnet's explicit symbolic solver.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported in-paper behavior: VIN scales poorly; TCR falls below 5% for 19×19 mazes. VIN required early stopping due to overfitting on small datasets; exact numeric metrics per-size are shown in the paper's tables (not all numbers reproduced in text).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Struggles to scale to larger mazes in the experiments; training time becomes very large for large mazes; more prone to overfitting on small datasets compared to NSNnet which leverages symbolic solver.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Presented as a purely neural baseline; NSNnet outperforms VIN in the Visual Maze testbeds in terms of scaling and TCR by leveraging an exact symbolic shortest-path solver.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Neuro-Symbolic Architecture for Image-to-Image Reasoning Tasks', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4828.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4828.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SAT-Net</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A differentiable neural architecture that incorporates a differentiable satisfiability solver layer to perform reasoning tasks like Sudoku as a neural image-to-symbolic pipeline; cited here as a related approach and comparison for Sudoku solving.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SAT-Net</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A neural model integrating a differentiable relaxation of a satisfiability solver (SAT) into a network, enabling end-to-end training for problems expressed as constraints; exact architecture and parameterization are in the original SATNet paper (Wang et al.).</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Sudoku (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Used as a prior purely-neural image→symbol baseline for solving Sudoku puzzles by mapping images to symbolic outputs and applying a differentiable constraint layer.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Differentiable relaxation of SAT solving embedded in a neural network allowing gradient-based training for constraint satisfaction tasks; in contrast to NSNnet, SATNet's outputs are symbolic (not image outputs) and the approach is fully neural end-to-end.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>SATNet learns to respect Sudoku constraints via its differentiable SAT layer (implicit spatial/structural reasoning). In this paper SATNet is cited for comparison: it reported 63.2% accuracy on an image→symbol Sudoku solver task but required 9× more training data than the NSNnet experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported (from Wang et al., cited in this paper): 63.2% accuracy on their purely neural image→symbol Sudoku solver using 9× the training data used by NSNnet experiments. No direct head-to-head numeric comparison on identical settings is provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>As discussed in this paper, purely neural approaches like SATNet can be data-intensive; in the cited result SATNet required substantially more data to reach its reported performance. SATNet operates in an image→symbol setting and does not address image→image training as NSNnet does.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Cited as a purely neural baseline for Sudoku; NSNnet claims higher data efficiency and comparable or better end-to-end (image→image) performance despite the additional challenge of output-image generation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Neuro-Symbolic Architecture for Image-to-Image Reasoning Tasks', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Value iteration networks <em>(Rating: 2)</em></li>
                <li>SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver <em>(Rating: 2)</em></li>
                <li>Hybrid classification and reasoning for image-based constraint solving <em>(Rating: 2)</em></li>
                <li>Top-k training of gans: Improving GAN performance by throwing away bad samples <em>(Rating: 1)</em></li>
                <li>Reward augmented maximum likelihood for neural structured prediction <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4828",
    "paper_id": "paper-235358778",
    "extraction_schema_id": "extraction-schema-106",
    "extracted_data": [
        {
            "name_short": "NSNnet (Visual Maze)",
            "name_full": "Neural-Symbolic-Neural network (NSNnet) applied to Visual Maze",
            "brief_description": "An end-to-end trainable neuro-symbolic-neural architecture that maps input images of grid mazes to output images marking the shortest path by (1) a neural encoder that grounds pixels to symbols, (2) a symbolic shortest-path solver (Dijkstra), and (3) a neural decoder (array of VAEs) that renders the solution image; trained with a REINFORCE-like policy-gradient plus a subsampling heuristic and an output-style encoder for reconstruction supervision.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "NSNnet",
            "model_description": "Three-stage hybrid: (a) input encoder M_e implemented per-cell (LeNet-style CNN for digits in Sudoku tasks; for Visual Maze a small fully-connected classifier for 0/1), which outputs a distribution over discrete cell symbols; (b) symbolic module SYM (Dijkstra's algorithm for shortest path) that consumes sampled symbols and emits symbolic solution ŷ; (c) output decoder M_d implemented as an array of variational autoencoders (one VAE per symbol) that take the symbolic solution and a style latent z from output encoder M_oe to reconstruct an output image. Training uses Monte-Carlo sampling of symbol assignments (K=128), a REINFORCE-like gradient for M_e, reward-gradient (backprop) for M_d and M_oe, and a subsampling heuristic that keeps only top η fraction of sampled symbol assignments to mitigate sparse-reward cold-start. Exact parameter counts are not reported.",
            "puzzle_name": "Visual Maze (grid shortest-path)",
            "puzzle_description": "Grid mazes whose cells contain MNIST-digit images representing wall/empty; the task is to output an image of the same maze where cells on the unique shortest path (top-left to bottom-right) are marked with a different digit. Solving requires spatial reasoning about adjacency and path connectivity on the grid.",
            "mechanism_or_strategy": "Neuro-symbolic pipeline: per-cell neural classification to discrete symbols → symbolic graph algorithm (Dijkstra) to compute shortest path → per-cell VAE decoder to render solution image; end-to-end training via policy-gradient (REINFORCE-like) where reconstruction loss of final image serves as reward signal; output-style encoder M_oe extracts style latents from ground-truth output during training; subsampling heuristic keeps top η fraction of Monte-Carlo samples to bias learning toward high-reward samples and overcome sparse-reward cold-start.",
            "evidence_of_spatial_reasoning": "Spatial reasoning is explicit in the symbolic module: SYM runs Dijkstra's shortest-path algorithm on the grid of decoded symbols, so correct behavior requires identifying cell roles (wall/empty) and globally computing connectivity. Empirical evidence: NSNnet achieves high path (task completion) accuracy (TCR) while VIN baseline degrades with larger mazes (VIN TCR &lt; 5% at 19×19); ablation studies show that removing the symbolic/reward-gradient components yields zero TCR, indicating the model relies on the symbolic spatial reasoning step. Qualitative outputs (sample images) and path-accuracy metrics reported in tables provide additional evidence (tables cited in paper).",
            "performance_metrics": "Reported metrics: task completion rate (TCR: fraction of mazes where exact symbolic path was found) and classification accuracy (CA) of per-cell symbol labeling. Exact numeric values for NSNnet per-size are reported in the paper tables (not reproduced in-text), but authors state 'high' CA and high TCR across maze sizes tested; VIN baseline drops to &lt;5% TCR for 19×19. Training/dev/test sets each contained 1000 maze instances per grid size; K (samples) = 128; subsampling fraction η varied (e.g., 1, 1/2, 1/16, 1/32, 1/128).",
            "limitations_or_failure_cases": "Cold-start/sparse-reward problem requires the subsampling heuristic; without it or without the reward-gradient term the method gets zero TCR (ablation). The approach assumes a highly structured grid input (cell segmentation known) and a known symbol dictionary size; not evaluated on unstructured/naturalistic images. Computational cost: symbolic module makes workloads CPU-intensive (no GPUs used in experiments). When classifier accuracy drops slightly, task completion (0/1) degrades sharply because the metric requires all path cells to be correct. SYM may fail to find a path if sampled symbols are inconsistent with a path (early training), causing zero reconstruction reward for those samples.",
            "comparison_baseline": "Compared against Value Iteration Networks (VIN) as a purely neural baseline for shortest-path; NSNnet maintains high TCR as maze size increases while VIN scales poorly (TCR &lt;5% at 19×19). NSNnet's per-cell classification accuracy and path accuracy are reported close to an ad-hoc system that uses pretrained classifiers and symbolic solvers (upper bound).",
            "uuid": "e4828.0",
            "source_info": {
                "paper_title": "End-to-End Neuro-Symbolic Architecture for Image-to-Image Reasoning Tasks",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "NSNnet (Visual Sudoku)",
            "name_full": "Neural-Symbolic-Neural network (NSNnet) applied to Visual Sudoku",
            "brief_description": "NSNnet trained end-to-end to map images of partially filled Sudoku grids (cells containing MNIST digit samples) to images of the completed Sudoku by learning a per-cell classifier, invoking a symbolic constraint solver to compute the unique grid solution, and decoding rendered digit images via a per-symbol VAE array; training uses a REINFORCE-like gradient with a subsampling heuristic and an output-style encoder for reconstruction supervision.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "NSNnet",
            "model_description": "Same overall NSNnet architecture: per-cell input encoder M_e implemented as a LeNet-style digit classifier (10 symbols: digits 1–9 and blank), symbolic solver SYM implemented via CP-SAT (Google OR-Tools) constraint solver to produce completed Sudoku symbolic layout, and output decoder M_d consisting of an array of VAEs (B=9 for digits 1–9) that reconstruct per-cell digit images using style latents from M_oe. Training via Monte-Carlo sampling of symbol assignments (K=128), policy-gradient for encoder, reward-gradient for decoder, and subsampling fraction η to mitigate sparse rewards. Exact model sizes not provided.",
            "puzzle_name": "Visual Sudoku (image-to-image Sudoku solving)",
            "puzzle_description": "Partially filled 9×9 Sudoku grids where each filled cell contains an MNIST digit sample; the task is to output an image of the completed Sudoku using sampled instances of the correct digit in each cell. This requires reasoning over global row/column/box constraints (spatial / structural constraints across the grid).",
            "mechanism_or_strategy": "Neuro-symbolic pipeline: per-cell neural digit classifier outputs distributions → symbolic constraint solver (OR-Tools CP-SAT) attempts to solve sampled symbolic grids (well-formedness enforced during sampling) to obtain unique solution ŷ → per-symbol VAEs decode ŷ and training-only output encoder M_oe provides style latents z to help reconstruction. End-to-end learning via REINFORCE-like gradient on encoder with reconstruction loss as reward, plus reward-gradient updates to decoder; critical subsampling of high-reward samples (keeping top η fraction) to escape sparse-reward cold-start.",
            "evidence_of_spatial_reasoning": "Evidence is primarily behavioral: the symbolic solver enforces global Sudoku constraints (rows, columns, boxes), so successful task completion (TCR) indicates the system learned to ground visual digits into symbols in a way that enables the symbolic solver to satisfy spatial/structural constraints. Ablation studies show removing reward gradient or subsampling yields zero TCR and chance-level classification accuracy, indicating the necessity of the end-to-end training plus subsampling for learning to exploit the spatial constraints. The authors compare to purely neural SAT-Net (Wang et al.) and report that SAT-Net achieved 63.2% in its setting using 9× more training data, while NSNnet achieves high CA and TCR with much less data (exact NSNnet numeric values are in the paper tables).",
            "performance_metrics": "Metrics reported: classification accuracy (CA) per-cell and task completion rate (TCR: exact-solution 0/1 metric). Datasets: 1000 train / 1000 dev / 1000 test Sudoku puzzles, reported across three difficulty tiers (easy/medium/hard). Paper reports 'high' CA and TCR across difficulty levels and notes a nonlinear relation: even very high CA may still yield lower 0/1 TCR because a single misclassified input digit breaks the solution. Exact numeric CA/TCR per difficulty are given in the paper tables (not reproduced verbatim in the text). Also quoted: SAT-Net (pure neural, image→symbol) reported 63.2% using 9× the training data.",
            "limitations_or_failure_cases": "Key limitations: cold-start sparse-reward issue must be addressed via subsampling; the model learns symbol identities only up to a permutation (no intermediate supervision), so measured CA uses the best matching permutation; small classifier errors can catastrophically reduce 0/1 TCR; symbolic solver failures (when sampled x is unsolvable) yield zero reconstruction reward; approach assumes known grid/cell segmentation and fixed symbol dictionary; not yet evaluated on naturalistic (unsegmented) images or larger Sudoku variants.",
            "comparison_baseline": "Compared to SAT-Net (purely neural differentiable SAT solver) and a pretrained-classifier + symbolic-solver upper bound. Authors state NSNnet achieves performance close to the pretrained-classifier upper bound while being trained image-to-image, and is more data-efficient than SAT-Net (which needed 9× training data to achieve 63.2%). Ablations show other policy-gradient variants (max-entropy REINFORCE, UREX) do not overcome cold-start in these tasks, while NSNnet with subsampling does.",
            "uuid": "e4828.1",
            "source_info": {
                "paper_title": "End-to-End Neuro-Symbolic Architecture for Image-to-Image Reasoning Tasks",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "VIN (Value Iteration Networks)",
            "name_full": "Value Iteration Networks",
            "brief_description": "A purely neural differentiable architecture designed to learn planning/value-iteration-like computations end-to-end from images for tasks such as shortest-path; cited and used as a baseline for Visual Maze experiments.",
            "citation_title": "Value iteration networks",
            "mention_or_use": "mention",
            "model_name": "Value Iteration Network (VIN)",
            "model_description": "Convolutional neural-network architecture that embeds a differentiable planning module by approximating value iteration via convolutions and max operations; exact model-size and hyperparameters depend on implementation and were chosen in the paper's experiments (authors tuned number of value-iteration steps to be slightly larger than maze dimension).",
            "puzzle_name": "Maze shortest-path (baseline)",
            "puzzle_description": "Used here as a purely neural baseline for grid shortest-path problems (same Visual Maze problem): learns to map maze images to actions/paths without an explicit symbolic graph algorithm.",
            "mechanism_or_strategy": "End-to-end differentiable approximation of dynamic programming/value iteration via CNN layers representing transition and reward structure; no symbolic solver. In the paper VIN was trained as a baseline with hyperparameters tuned and early stopping used due to overfitting on small datasets.",
            "evidence_of_spatial_reasoning": "VIN encodes spatial structure via convolutional planning layers and learned value propagation; in this paper the evidence of spatial reasoning is empirical: VIN's performance (TCR) drops sharply as maze size increases (poor scaling), indicating limitations in learning global shortest-path reasoning compared to NSNnet's explicit symbolic solver.",
            "performance_metrics": "Reported in-paper behavior: VIN scales poorly; TCR falls below 5% for 19×19 mazes. VIN required early stopping due to overfitting on small datasets; exact numeric metrics per-size are shown in the paper's tables (not all numbers reproduced in text).",
            "limitations_or_failure_cases": "Struggles to scale to larger mazes in the experiments; training time becomes very large for large mazes; more prone to overfitting on small datasets compared to NSNnet which leverages symbolic solver.",
            "comparison_baseline": "Presented as a purely neural baseline; NSNnet outperforms VIN in the Visual Maze testbeds in terms of scaling and TCR by leveraging an exact symbolic shortest-path solver.",
            "uuid": "e4828.2",
            "source_info": {
                "paper_title": "End-to-End Neuro-Symbolic Architecture for Image-to-Image Reasoning Tasks",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "SAT-Net",
            "name_full": "SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver",
            "brief_description": "A differentiable neural architecture that incorporates a differentiable satisfiability solver layer to perform reasoning tasks like Sudoku as a neural image-to-symbolic pipeline; cited here as a related approach and comparison for Sudoku solving.",
            "citation_title": "SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver",
            "mention_or_use": "mention",
            "model_name": "SAT-Net",
            "model_description": "A neural model integrating a differentiable relaxation of a satisfiability solver (SAT) into a network, enabling end-to-end training for problems expressed as constraints; exact architecture and parameterization are in the original SATNet paper (Wang et al.).",
            "puzzle_name": "Sudoku (baseline)",
            "puzzle_description": "Used as a prior purely-neural image→symbol baseline for solving Sudoku puzzles by mapping images to symbolic outputs and applying a differentiable constraint layer.",
            "mechanism_or_strategy": "Differentiable relaxation of SAT solving embedded in a neural network allowing gradient-based training for constraint satisfaction tasks; in contrast to NSNnet, SATNet's outputs are symbolic (not image outputs) and the approach is fully neural end-to-end.",
            "evidence_of_spatial_reasoning": "SATNet learns to respect Sudoku constraints via its differentiable SAT layer (implicit spatial/structural reasoning). In this paper SATNet is cited for comparison: it reported 63.2% accuracy on an image→symbol Sudoku solver task but required 9× more training data than the NSNnet experiments.",
            "performance_metrics": "Reported (from Wang et al., cited in this paper): 63.2% accuracy on their purely neural image→symbol Sudoku solver using 9× the training data used by NSNnet experiments. No direct head-to-head numeric comparison on identical settings is provided in this paper.",
            "limitations_or_failure_cases": "As discussed in this paper, purely neural approaches like SATNet can be data-intensive; in the cited result SATNet required substantially more data to reach its reported performance. SATNet operates in an image→symbol setting and does not address image→image training as NSNnet does.",
            "comparison_baseline": "Cited as a purely neural baseline for Sudoku; NSNnet claims higher data efficiency and comparable or better end-to-end (image→image) performance despite the additional challenge of output-image generation.",
            "uuid": "e4828.3",
            "source_info": {
                "paper_title": "End-to-End Neuro-Symbolic Architecture for Image-to-Image Reasoning Tasks",
                "publication_date_yy_mm": "2021-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Value iteration networks",
            "rating": 2,
            "sanitized_title": "value_iteration_networks"
        },
        {
            "paper_title": "SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver",
            "rating": 2,
            "sanitized_title": "satnet_bridging_deep_learning_and_logical_reasoning_using_a_differentiable_satisfiability_solver"
        },
        {
            "paper_title": "Hybrid classification and reasoning for image-based constraint solving",
            "rating": 2,
            "sanitized_title": "hybrid_classification_and_reasoning_for_imagebased_constraint_solving"
        },
        {
            "paper_title": "Top-k training of gans: Improving GAN performance by throwing away bad samples",
            "rating": 1,
            "sanitized_title": "topk_training_of_gans_improving_gan_performance_by_throwing_away_bad_samples"
        },
        {
            "paper_title": "Reward augmented maximum likelihood for neural structured prediction",
            "rating": 1,
            "sanitized_title": "reward_augmented_maximum_likelihood_for_neural_structured_prediction"
        }
    ],
    "cost": 0.013466249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>End-to-End Neuro-Symbolic Architecture for Image-to-Image Reasoning Tasks</p>
<p>Ananye Agarwal ananayagarwal@gmail.com 
IIT Delhi
Google Research
India</p>
<p>Pradeep Shenoy shenoypradeep@google.com 
IIT Delhi
Google Research
India</p>
<p>End-to-End Neuro-Symbolic Architecture for Image-to-Image Reasoning Tasks
Mausam IIT Delhi mausam@cse.iitd.ac.in
Neural models and symbolic algorithms have recently been combined for tasks requiring both perception and reasoning. Neural models ground perceptual input into a conceptual vocabulary, on which a classical reasoning algorithm is applied to generate output. A key limitation is that such neural-to-symbolic models can only be trained end-to-end for tasks where the output space is symbolic. In this paper, we study neural-symbolic-neural models for reasoning tasks that require a conversion from an image input (e.g., a partially filled sudoku) to an image output (e.g., the image of the completed sudoku). While designing such a threestep hybrid architecture may be straightforward, the key technical challenge is end-to-end training -how to backpropagate without intermediate supervision through the symbolic component. We propose NSNnet, an architecture that combines an image reconstruction loss with a novel output encoder to generate a supervisory signal, develops update algorithms that leverage policy gradient methods for supervision, and optimizes loss using a novel subsampling heuristic. We experiment on problem settings where symbolic algorithms are easily specified: a visual maze solving task and a visual Sudoku solver where the supervision is in image form. Experiments show high accuracy with significantly less data compared to purely neural approaches.Preprint. Under review.</p>
<p>Introduction</p>
<p>The human brain has long served as functional and architectural inspiration for the design of machine learning systems, from highly stylized abstractions of biological neurons [1,2] to proposals of dichotomous systems of intelligence ("fast/instinctive and slow/deliberative" [3]). Artificial neural networks show universal approximability, handle uncertainty, and support end-to-end training, making them the model of choice for many tasks processing noisy, ambiguous real-world inputs such as language and vision. Unfortunately, they do not yet match up to traditional algorithms on cognitive reasoning tasks such as Sudoku. Current neural reasoning [4,5,6] models are data-intensive, approximate, and generalize poorly across problem sizes.</p>
<p>A recent line of inquiry combines neural and symbolic approaches for perceptuo-reasoning tasks [7,8,9]. This approach combines the core strengths of each individual system -neural systems ground noisy, uncertain, complex perceptual signals into abstract symbols, on which symbolic reasoners perform exact, algorithmic computations to produce the desired (symbolic) output. Such neuralto-symbolic (NS) models offer many advantages over purely neural systems; in particular they are interpretable, and can be trained with limited data in an end-to-end fashion (i.e., with no supervision on the intermediate abstract problem constructed from the perceptual input); however, they are only applicable for problems where the output space is symbolic.</p>
<p>Our goal is to push the boundaries of such neuro-symbolic systems, by studying reasoning tasks where both inputs and outputs are in the physical/perceptual layer. We believe this is a small but necessary step for broadening the mechanisms by which embodied agents can interact with and learn from the natural world. We study image to image reasoning tasks such as Visual Sudoku, where partially-and fully filled Sudoku boards are presented as images, and Visual Maze where the output image overlays the shortest path on the maze. We naturally extend NS models to neural-symbolicneural (NSN) architectures, where the symbolic solution is converted by an additional neural layer to produce an image. A key technical challenge in realizing such an architecture is end-to-end (E2E) training. E2E training regimes are useful for reducing the need for data annotation and are a particular strength of modern ML systems. But, since there is a symbolic component in the middle of the model, it is not clear how to backpropagate the loss from the output image to the input encoder.</p>
<p>We address this challenge via NSNnet, our unique architecture and training routine ( Figure 1C). The symbolic computation module (SYM) is sandwiched between an encoder-decoder pair (M e , M d ) that parse the input and produce output images respectively. M d provides a reconstruction loss by reconciling SYM's output with the supervisory image. Simultaneously, the supervisory image is parsed and combined with SYM's output by a second encoder M oe , used only during the training phase, to provide additional signal to M d ; this auxiliary regularization significantly improves the quality of the learned reconstructions. We derive update equations to train the parameters of input encoder M e and show that they lead to a policy gradient-like training procedure. This combination of enhanced policy gradient and regularization enables E2E training of the NSN framework.</p>
<p>We found that existing enhancements to policy gradient algorithms were insufficient for addressing the sparse reward distributions in our problem domains. To address this, we propose a subsampling heuristic for approximating the policy gradient, and show that it significantly improves upon previous exploration strategies, and in some cases is necessary for learning in these tasks. We demonstrate our model's performance in solving the testbed problems in Figure 1A;B. We compare against purely neural architectures that work in an image-to-symbolic-solution setting (strictly weaker than our proposed setting) and demonstrate significantly better accuracy with much lesser training data. In particular, we show that encoding and task completion accuracy in NSNnet closely tracks that of an ad-hoc system using pretrained classifiers and symbolic solvers, despite our image-to-image training paradigm and additional goal of generating output images. Taken together, we give a proof of concept on how to effectively build E2E hybrid NSN architectures for image-to-image reasoning tasks. We hope that our results form a basis for further research in this important area.</p>
<p>Related work</p>
<p>Purely neural reasoning: Recent works propose E2E neural architectures for classically symbolic computations and reasoning frameworks: e.g., satisfiability [5], constraint satisfaction [10], inductive logic programming [6], and value iteration [4]. These models incorporate continuous (differentiable) relaxations of discrete algorithms and hence can be trained using backpropagation in E2E supervised fashion. Although early results show promise, these architectures incur high training cost, perform approximate/black-box computations, and typically generalize poorly across problem sizes.</p>
<p>Neural models with background knowledge: Adding domain insights into data-trained neural models is a common pursuit in current ML systems. A popular approach for this is via constraints in output space [11,12]. They are used in a separate inference step over the output of neural model, or converted to a differentiable loss added to the neural model's objective. These ideas have been applied in diverse domains such as sequence labeling in NLP [13], and recovering crystalline structure from multiple x-ray diffraction measurements of a material [14]. Our proposal is similar in that we also provide additional domain knowledge to the model, but different, because we provide it in the form of an arbitrary (black-box) symbolic reasoner, which cannot be made differentiable. We also do not require pre-trained decoders unlike some prior work ( e.g., Chen et al. [14]).</p>
<p>Neural parsing of visual input: Recent work examines self-supervision in learning symbolic representations for visual input. Often, they are applied in video settings, e.g., where pixel similarities in consecutive frames in Atari games can help decode object identities [15], or the underlying objectlayout map [16]. As with most unsupervised/self-supervised learning, there are no guarantees of learning a specific, complete symbolic parse of a scene. In contrast, end-to-end accuracy in our setting heavily depends on precisely identifying and explicitly representing all symbols in the input, without which the symbolic computation may fail catastrophically. 1 Neural to symbolic architectures: There is an emerging body of work in NS architectures, where neural components extract symbolic representations on which symbolic computations are performed. An example is visual question answering (QA) where textual questions are neurally converted to symbolic programs operating on representations extracted from an image [17,18] -they use a small, domain-specific language tailored towards benchmark tasks. Within textual QA, N2S models convert mathematical questions to mathematical expressions, which are directly executed to compute an answer [19], and convert knowledge questions to a query that is run over a knowledge-base [20]. Similar ideas are explored in other NLP tasks, e.g., dialog systems [21]. Probably closest to our work are N2S models that have been trained to perform perceptuo-reasoning, e.g., number addition, multiplication, where images represent the input, but outputs are symbolic (numeric) answers [7].</p>
<p>The main approaches to train such NS models include (1) the use of continuous relaxations of symbolic programs so that they can be differentiated end-to-end [8,18], (2) a careful enumeration of possible inputs (or programs) corresponding to an observed symbolic output, which can provide weak supervision [20,7], and (3) pre-training neural components separately using intermediate supervision [17]. In contrast our work differs in multiple ways. First, we build a novel neuro-symbolic-neuro (NSN) architecture where input and supervision are both in the image domain and require training of two neural components, on either side of symbolic. Second, we aim to support black-box symbolic computations of arbitrary complexity (here, a graph algorithm and a constraint satisfaction program). Third, we handle highly structured intermediate and output spaces. Finally, we wish to train the whole model end-to-end, instead of using heuristic labeling or intermediate annotation to train components. To the best of our knowledge, this is the first demonstration of an E2E-trained NSN architecture. 2 </p>
<p>Problem formulation and approach</p>
<p>We are given a training dataset of the form
D = {I i , J i } N i=1 ,
where I i is an input image and J i is a correct output image for I i . Our goal is to induce a function f Θ , such that f Θ (I) = J only if J is a correct output for image I. Our work focuses on tasks that require an intermediate reasoning step, for which a symbolic solver may be the most appropriate. So, we propose f Θ as a novel NSN architecture -a pipeline of neural, symbolic and neural components (see Figure 1C). The input I is mapped by a neural encoder M e (x|I; Θ e ) to a distribution over symbolsx, which in turn is proceesed by a symbolic program SYM(x) to output symbolsŷ. Finally, a neural decoder M d (ŷ; Θ d ) generates output imageĴ from supplied symbols.</p>
<p>At training time, the only available feedback is the similarity betweenĴ and J. However, given only the symbolŷ, it is impossible to reconstruct J exactly, due to potential variations in the representation J ofŷ (see Fig. 2). We therefore need access to style informationẑ implicit in J, and disentangled from its symbolic representation, allowing us to reconstruct J. We require another neural module M oe (ŷ, J; Θ oe ) to extract style informationẑ. The decoder M d must be modified to accept bothẑ andŷ,Ĵ = M d (ŷ,ẑ; Θ d ). At testing time, since the true output J is hidden,ẑ is sampled randomly. Since M oe is only relevant at training time, it is indicated with dotted lines in Fig.1. The task requires optimizing Θ = Θ e ∪ Θ d ∪ Θ oe to induce the best f Θ , given only D -no intermediate supervision (data mapping I to x or y to J, or style information z) is made available to the model.</p>
<p>In our experiments, we consider highly structured input and output spaces (mazes and sudoku puzzles, Figure 1A;B), where each image is a grid of cells (sub-images). While our exposition of the NSNnet architecture is general, for our problems, we implement M e and M d at the cell level. The exact architectural details of M e , M oe , M d are described in Sec. 4.1.</p>
<p>Optimization objectives and update equations</p>
<p>In the forward pass, the encoder M e (x|I; Θ e ) transforms input image I into a probability distribution over symbolic representationsx, which in turn is processed by the symbolic algorithm SYM to produce a symbolic outputŷ. During training, output encoder M oe (ŷ, J; Θ oe ) extracts style information z from the ground truth output image J 3 . The symbolic output is decoded by another model M d (ŷ,ẑ; Θ d ) to produce a candidate output imageĴ. This is compared to the supervisory image J to provide feedback to the models M e (·), M d (·), M oe (·). Therefore, we require the output encoderdecoder pair M d , M oe to expose a reconstruction loss function l rec (ŷ,Ĵ, J; Θ d , Θ oe ) that compares generated imageĴ with J and returns a loss based on some measure of similarity between them. We can define the expected reconstruction loss used during training as
L rec (I, J; Θ e , Θ d , Θ oe ) = E Me(x|I;Θe) l rec (ŷ,Ĵ, J; Θ d , Θ oe ) (1) whereĴ = M d (ŷ,ẑ; Θ d ),ẑ = M oe (ŷ, J; Θ oe ) andŷ = SYM (x)
. In addition to l rec , the neural decoder may supply additional loss terms for regularization l reg (ŷ,ẑ,Ĵ, J; Θ d , Θ oe ). l reg is not directly related to quality of reconstruction and depends on the specific architecture being used for M d . It is usually required to prevent overfitting or enforce certain properties. For instance, VAEs [23] use a KL divergence term to enforce a continuous latent space (see Sec. 4.1) Accordingly, we define L reg :
L reg (I, J; Θ e , Θ d , Θ oe ) = E Me(x|I;Θe) l reg (ŷ,ẑ,Ĵ, J; Θ d , Θ oe )(2)
Putting together these two components, we have the overall loss for an example (I, J)
L(I, J) = L reg (I, J; Θ e , Θ d , Θ oe ) + L rec (I, J; Θ e , Θ d , Θ oe )(3)
We will now omit specifying parameters Θ e , Θ d , Θ oe in subsequent equations for brevity.</p>
<p>Training the neural modules: We train the parameters (Θ e , Θ d , Θ oe ) using supervision from the target image J; in other words, the training procedure is performed end-to-end, with no access to supervision on the correct values of (internal) symbolic representations (x, y). We can rewrite the expectation in the loss as
L(I, J) = E Me(x|I) l rec (ŷ,Ĵ, J) + l reg (ŷ,ẑ,Ĵ, J) = x l rec (ŷ,Ĵ, J) + l reg (ŷ,ẑ,Ĵ, J) M e (x | I)(4)
where the sum is taken over all possiblex and M e (x | I) is the probability of samplingx. Gradients with respect to the parameters Θ e in the neural encoder can now be approximated using Monte-Carlo samples. Notice thatẑ andĴ only depend on Θ d , Θ oe and therefore can be treated as scalar constants as far as the operation ∇ Θe is concerned.
∇ Θe L(I, J) = x l rec (ŷ,Ĵ, J) + l reg (ŷ,ẑ,Ĵ, J) · ∇ Θe M e (x | I) = x l rec (ŷ,Ĵ, J) + l reg (ŷ,ẑ,Ĵ, J) · M e (x | I) · ∇ Θe log M e (x | I) ≈ 1 K K i=1 l rec (ŷ i ,Ĵ i , J) + l reg (ŷ i ,ẑ i ,Ĵ i , J) · ∇ Θe log M e (x i | I)(5)
where the last step in Eq. 7 is a Monte Carlo approximation of the sum by averaging K iid samples
{x i } K i=1
drawn from the distribution given by M e andẑ i ,Ĵ i ,ŷ i are obtained in the usual way. Note that Eq. 7 is structurally identical to the REINFORCE [24] algorithm for calculating policy gradient. To draw parallels with a one-step RL problem (or equivalently, a contextual bandits problem),
l rec (ŷ i ,Ĵ i , J) + l reg (ŷ i ,ẑ i ,Ĵ i , J)
corresponds to the reward,x to the action and M e (x | I) to the policy with I as the initial state (more details in appendix). However, updates to Θ d , Θ oe cannot be made using policy gradients alone and a separate calculation is needed that yields a new term. Eq. 6 shows that updates to Θ d follow conventional backpropagation rules, weighted by input distribution M e (I).
∇ Θ d L(I, J) = x ∇ Θ d l rec (ŷ,Ĵ, J) + l reg (ŷ,ẑ,Ĵ, J) · M e (x | I) ≈ 1 K K i=1 ∇ Θ d l rec (ŷ i ,Ĵ i , J) + l reg (ŷ i ,ẑ i ,Ĵ i , J)(6)
where the last line is again a Monte Carlo approximation. Since M e only takes Θ e as input, the probabilities M e (x | I) in Eq. 6 above are treated as constants with respect to the operation ∇ Θ d . The update equations for Θ oe are identical to Eq. 6. Since Eq. 6 and its counterpart for Θ oe may be viewed as expectated gradients of the reward function l rec (ŷ i ,Ĵ i , J) + l reg (ŷ i ,ẑ i ,Ĵ i , J), we henceforth refer to these together as the reward gradient. In practice, we find that when updating Θ e it is beneficial to drop the l reg losses since they are primarily used to prevent decoder overfitting and do not give useful information about the reconstruction quality. The gradient for Θ e then becomes
∇ Θe L(I, J) ≈ 1 K K i=1 l rec (ŷ i ,Ĵ i , J) · ∇ Θe log M e (x i | I)(7)</p>
<p>Subsampling Heuristic for Policy Gradient</p>
<p>A challenge with policy gradient methods is the difficulty of learning in large, sparse-reward spaces, especially when reward distributions are non-smooth. Many previous approaches stress the need for effective exploration of the policy space, especially in the early stages of learning [25,26,20]; we sketch a couple below. Consider an RL problem with reward function r, policy π θ , initial state s 0 and prior over initial states p. Let π θ (a | s 0 ) denote the probability of executing action sequence a under π θ . The RL objective maximizes expected reward O RL = Ep(s 0 ) a π θ (a | s 0 )r(a | s 0 ) . Williams &amp; Peng [25] propose adding an entropy-based regularization term −τ π θ (a|s 0 )logπ θ (a|s 0 ) to the objective O RL in order to encourage exploration. Norouzi et al. [26] show that π θ (a|s 0 ) maximizes this regularized expected reward, when it is directly proportional to the exponentiallyscaled reward distribution, and propose to optimize a reward-scaled predictive probability distribution:
O RAM L = E p(s0) τ a π * τ (a|s 0 )log π θ (a|s 0 )(8)
where π * τ (a|s 0 ) ∝ exp 1 τ r(a|s 0 ) represents a probability distribution over exponentiated rewards. UREX [27] uses a self-normalized importance sampling for Monte Carlo estimation of this objective, since it is often difficult or impossible to sample directly from the reward distribution, as is the case in our problem settings. They find that the UREX objective promotes the exploration of high-reward regions.</p>
<p>In early experiments, we found that these exploration strategies did not work in our problem domains; the models were stuck in cold-start (Sec. 5.4). Instead, we propose to bias the gradient calculation towards high-reward regions, by means of a subampling algorithm for policy gradient. From the Monte Carlo samples used to calculate the expectation in O RL , we keep only the top η fraction of the samples, and discard the rest (see appendix for pseudocode). We refer to the combination of REINFORCE, the reward gradient and subsampling as the NSNnet gradient. This builds on the ideas of reward-scaled policy gradient; low-reward samples are unlikely to have useful gradient information in sparse reward spaces, and therefore we discard them entirely. Although this leads to biased gradients, we hypothesize that in large action spaces the resulting bias-variance trade-off is favourable and mitigates the cold-start issue. 4 Recent work [28] uses a similar approach in the context of training the generators in GANs, and finds that performance is significantly improved by discarding samples rated by the discriminator as less realistic.</p>
<p>Experimental testbeds</p>
<p>We evaluate our proposed framework in the context of two experimental testbeds: Visual Maze and Visual Sudoku (Figure 1A,B). In the Visual Maze task, the input is a maze where the walls and empty spaces are samples of the digits "1" and "0" from the MNIST handwritten digits dataset. The expected output is another image of the maze, with the cells on the shortest path from top-left to bottom-right are marked with samples of the digit "2" from the same dataset. Mazes are designed such that there is a unique shortest path between these two points. In the Visual Sudoku task, the input is an unsolved (i.e., partially filled in) sudoku with exactly one solution, and the digits 1-9 in each cell are, again, samples from the MNIST dataset. The expected output is the same puzzle correctly completed using a sampled instance of the correct digit in each cell.</p>
<p>Other works have used similar settings: Tamar et al. [4] evaluate their deep learning approach for value iteration on a shortest-path problem for mazes. Mulamba et al. [29] combine a neural classifier's predictions and uncertainty estimates both in a constraint satisfaction based solver for visual sudoku. Wang et al. [5] use sudoku to demonstrate their neural implementation of satisfiability solvers. In all these cases, the supervision (and network output) is symbolic in nature, and therefore they address only a portion of the problem we pose here: that of image-to-image learning.</p>
<p>Modeling details</p>
<p>Here we describe the implementations of neural modules M e , M d and M oe that we use in our two tasks. Recall that our input and output images are a grid of cells, so apply encoder and decoder at celllevel, instead of image level. Let input image I be a grid of known width W and height H. Let I w,h represent the sub-image of a single digit at location (w, h) in the grid. M e (x w,h |I w,h ; Θ e ) computes the symbolx w,h , which are pieced together for all cells to outputx. Similarly,ŷ comprises ofŷ w,h andẑ ofẑ w,h , each independently extracted from each sub-image J w,h as M oe (ŷ w,h , J w,h ; Θ oe ). Eachŷ w,h is independently decoded to a sub-imageĴ w,h as M d (ŷ w,h ,ẑ w,h ; Θ d ).Ĵ is constructed by putting togetherĴ w,h in the grid. As an example, for Sudoku, the model applies the decoder on each cell of the 9x9 grid, and passes the classifier output and symbol layout to SYM. Since SYM has a well-specified input and output characteristic, the size of the symbol dictionary is assumed to be known -Sudoku puzzles contain 10 different symbols (9 digits and a blank space). However, the mapping from visual input to symbol ID is not annotated; as a result, M e may learn permutations of the symbol dictionary in Sudoku, since the semantics of each digit are interchangeable.</p>
<p>Input Encoder: In the Visual Sudoku problem, we learn a LeNet [30] digit classifier as part of our encoder model M e (x w,h |I w,h ) -given the contents of each cell, they classify the input as one of 10 digits (0-9). For the Visual Maze task we use a fully connected network with a single hidden layer since only two digits need to be classified (0-1).</p>
<p>Output Encoder-Decoder: The encoder and decoder models M d , M oe in both tasks reconstruct each digit given a discrete label and ground truth image J w,h . We choose an array of variational autoencoders (VAE) [23] for the output encoder-decoder pair
{V i } B i=1
where V i s are VAEs and there are B of them. When generating output, the array is indexed by the symbolic inputŷ w,h i.e. Vŷ w,h is selected to generate the image.</p>
<p>Each V i consists of probability distributions p θ i and q φ i parametrized by θ i and φ i respectively. Image data J is characterized by a space of latent variables v with joint probability distribution
p θ i (J, v). The distribution q φ i (v | J) is optimized to approximate the posterior p θ i (v | J). The evidence lower bound (ELBO) for V i is L θ i ,φ i (J) = log p θ i (J) − D KL (q φ i (v | J) p θ i (v | J))(9)
During training the ELBO is maximized, and therefore the loss function is −L θ i ,φ i (J). The first term in the loss, − log p θ i (I) can be interpreted as a measure of quality of reconstruction, whereas the second
D KL (q φ i (v | J) p θ i (v | J)) is a regularization term that forces q φ i (v | J) ≈ p θ i (v | J). Latent variables v encode style informationẑ w,h . We therefore have M oe := {q φ i } B i=1 and M d := {p θ i } B i=1
along with the following expressions for l reg and l rec .
l rec (ŷ w,h ,Ĵ w,h , J w,h ) = − log p θŷ w,h (J w,h ) (10) l reg (ŷ w,h ,ẑ w,h ,Ĵ w,h , J w,h ) = D KL (q φŷ w,h (ẑ w,h | J w,h ) p θŷ w,h (ẑ w,h | J w,h ))(11)
where the parameters
Θ d = B i=1 θ i and Θ oe = B i=1 φ i .
In the Visual Sudoku task the size of the VAE array is B = 9, whereas in the Visual Maze task it is B = 3.</p>
<p>Symbolic Algorithm: For the Visual Maze problem,x represents a maze as a 2D array of labels ({wall, empty}) for each cell, generated by running the M e on each cell and independently sampling each label. SYM is Dijkstra's shortest path algorithm, which finds a shortest path from source to the closest reachable point to the sink, and marks the shortest-path cells to create the symbolic representation x → y. The shortest path is not guaranteed to exist in each sample, even if it exists in the ground truth; in such cases, SYM finds a path to the closest reachable point to the sink. By design, we do not have access to the correspondence between input digits and labels; this correspondence, in addition to the classifier itself, is learned via supervision from the image J.</p>
<p>For the Visual Sudoku problem, similar to the above procedure, the symbolic inputx, is a sampled symbol from M e 's output distribution on each filled-in cell, with the {empty} symbol everywhere else. When sampling symbols to generate the input, we place a well-formedness constraint: we follow a fixed order, and resample the next cell until we produce a symbol that does not match any already sampled symbol in the same row or column (this is part of the Sudoku constraint set). We note that despite this partial well-formedness constraint, only a very small fraction of samplesx are solvable in the early stages of training. SYM uses a constraint solver (see appendix) to solve the Sudoku and generate the missing digits for the output representationŷ. It is possible that the sampled Sudoku does not have a solution, in which case the solver fails and both l reg , l rec are identically zero. We use two metrics to measure the performance of NSNnet at end-to-end training: task completion rate (TCR), i.e., fraction of mazes / sudoku puzzles where the exact symbolic solution was found by the E2E system, and classification accuracy (CA), where we measure the fraction of input symbols correctly identified. 5 Since to the best of our knowledge, no current system accomplishes image-to-image training, we instead use purely neural image-to-symbolic models as our external baselines -neural semidefinite programming for sudoku (SAT-Net [5]), and value iteration networks for maze (VIN [4]). These baselines are an overestimate, since training them as-is in an NSN setting will yield worse performance, and potentially even be infeasible. We also compare against a M e that is pretrained on dataset</p>
<p>Results</p>
<p>Comparison and metrics
{I i w,h , x i w,h } N i=1 where x i
w,h is the true label of digit I i w,h . This represents an upper bound on NSNnet accuracy which has no access to true labels. Finally, we perform ablations to highlight the importance of the subsampling heuristic and also compare against existing RL approaches designed for sparse reward spaces. NSNnet (ours) classifies input symbols accurately (digit accuracy DA) and has high path accuracy (PA), even as maze sizes increase; VIN scales poorly in contrast. Our results are close to that of a system using pretrained classifiers.</p>
<p>Visual</p>
<p>Data and training: We generated mazes by constructing random spanning trees on nxn grids, with grid points as walls and edges between as empty spaces. This guarantees a unique shortest path between any two points; for our experiments we only used the top left cell, and the bottom right cell, as entry and exit points. We tested a range of maze sizes but not solution complexity or multiplicity; we anticipate no significant qualitative change in the results under those manipulations. Hyperparameters for each method were determined by a grid search over batch size ∈ {25, 50, 100, 250}, learning rate ∈ 10 −3 , 10 −4 . For subsampling, we tried fraction η ∈ 1, 1 2 , 1 16 , 1 32 , 1 128 while the number of samples K was fixed at 128. For VIN, the number of value iterations was chosen to be slightly larger than the maze dimension. All experiments using NSNnet were run for 80 epochs whereas for VIN we used early stopping based on a dev set since it is prone to overfitting when the dataset is small. We do not report numbers on large mazes for VIN, since train time becomes extremely large and TCR has already dropped to &lt; 5% for 19 × 19. The train, dev and test set each contained 1000 maze problems for each grid size.</p>
<p>Results: Table 1 shows the performance of NSNnet on the Visual Maze problem as the size of the mazes are varied. Classifier accuracy remains high even as mazes grow large. We also see that while task completion rate (path accuracy) remains high, small changes in classifier accuracy leads to large degradations in task completion rates; this is because we consider a 0-1 metric for task completion, where all path cells need to be correctly identified, partially correct paths are not rewarded.  Data and training: Sudoku problems are generated by starting with a random 9 × 9 grid G that satisfies sudoku constraints. A problem P is constructed by performing a local search over the space of sudoku problems with G as a unique solution. The difficulty of P is estimated by computing a linear combination of the square of branching factors B ij at each cell and the number of empty cells E ( details in appendix). In general, problems of higher difficulty have fewer filled cells. Note that the symbolic constraint solver SYM always gives the correct solution regardless of problem difficulty. We report numbers on three difficulty levels -easy, medium and hard (details in appendix on how these are defined). Train, test and val datasets contain 1000 sudoku puzzles. The best hyperparameters were determined by a grid search as in the Visual Maze setting.</p>
<p>Visual Sudoku solving</p>
<p>Results: Table 2 shows results on Visual Sudoku demonstrating high classification accuracy and task completion rates across problem hardness. In particular, despite the image-to-image training, and additional challenge of output image generation, our performance is close to that of a system using pre-trained classifiers for parsing the input. Again, we see a strongly nonlinear relationship between classifier accuracy and task completion, with even very high classifier accuracies insufficient for proportionately high 0/1 task-completion rates. This is because a classifier must identify all input digits in the Sudoku correctly to get credit. Finally, Wang el al. [5] reports an accuracy of 63.2% on their purely neural image-to-symbolic Sudoku solver SAT-Net, using 9x our training data.  We try various values of subsampling fraction η and observe its effect on accuracy (Table 3) for Visual Sudoku and Visual Maze on 13 × 13 mazes. For η = 1 the classifier accuracy is no better than chance and accuracy significantly increases as η is lowered. Note that η = 1 K = 1 128 is the lowest value of η where we pick just one sample. This shows that subsampling is indeed effective at solving the coldstart problem.</p>
<p>Ablations</p>
<p>Fraction</p>
<p>We try various policy gradient alternatives to the NSNnet gradient. One of these simply omits the reward gradient term (Eq. 6). This method is not able to get non-zero TCR on either task, illustrating that training requires supervision from the decoder in the form of reconstruction loss. We also try REINFORCE with maximum entropy regularization [25] and UREX [27], adding a reward gradient term to each of these and find that they also do not give non-zero TCR on both tasks (detailed tables in appendix). This is because they cannot overcome the cold start problem as discussed in Sec. 3.2.</p>
<p>All experiments were run on a cloud VM based on the Intel Xeon Scalable Processor with 60 vCPUs and 240 GB memory and an internal cluster containing nodes with 40 Intel Xeon Gold CPUs and 100 GB memory. No GPUs were used since workloads were primarily CPU intensive because of the symbolic module SYM. Each experiment was restricted to using atmost 12 threads.</p>
<p>Discussion</p>
<p>We proposed a novel learning paradigm of image-to-image training involving symbolic reasoning over the contents of the images. We designed NSNnet, an architecture for solving such problems; derived the learning rules for our system as an extension of policy-gradient-style algorithms; proposed and implemented optimizations to policy gradient to enable it to succeed on our learning problems. Finally, we showed via experimentation on two testbed problems the efficacy of our end-to-end training paradigm, and the advantage obtained, by design, over purely neural systems. Many lines of work in deep learning involve symbolic manipulation and processing of perceptual inputs, whether via implicit representations ("purely neural" systems), or by explicit extraction and processing of symbolic inputs (neuro-symbolic systems). We argue that our proposed learning paradigm is a natural next step in the evolution of hybrid neuro-symbolic architectures, where both input and supervision are obtained from naturalistic sources such as images. The broad promise of this line of research is the ability to train agents and AI systems with less dependence on annotation, intermediate supervision, or large amounts of training data. In addition, systems that maintain and manipulate explicit symbolic representations have the powerful advantages of interpretability and verifiability -both properties that are increasingly necessary as we design complex AI systems. In future work, we aim to examine broader problems in this NSN space, extending our work to naturalistic problems, and towards developing general principles of blending neural and symbolic computations in a seamless manner.</p>
<p>Limitations of our work: This is one of many possible new directions for neuro-symbolic architectures that blend neural and symbolic components. Also, we chose simple, controlled testbeds for prototyping purposes. We expect the design, implementation, and real-world applicability of such systems will need to be refined through future work. Societal impact: We present an abstract/conceptual proposal for learning systems. The intent and broad direction of our effort is to make learning systems more expressive and easier to train; an expected positive outcome. As noted above under limitations, the real-world value of our work is still to be determined and difficult to anticipate. We see no immediate ethical concerns of our work.
∇ θ O RL ≈ 1 N K N n=1 K k=1 r(a k |s (n) 0 )∇ θ logπ θ (a k |s (n) 0 )(15)
This equation is structurally similar to Eqs. 7, where the model M e and the symbolic representationŝ x correspond to the policy and actions, respectively, and the loss can be considered as a reward with a sign change. The outer sum in the above equation is simply the aggregation of the pointwise gradient over training instances, to compute batch gradient. We therefore use policy gradient for learning the parameters of the encoder network M e . The reward gradient (Eq. 6) is an additional term that must be included to train M d and M oe as the policy gradient makes no updates to their parameters.</p>
<p>Appendix B Pseudocode</p>
<p>We describe the algorithm (algorithm 1) for training a general NSNnet architecture. This shows how to compute the reward gradient and update Θ d , Θ oe , and also how subsampling is used.</p>
<p>Note that the difficulty score is simply |E| for a problem that has B ij = 1, i.e. requires no backtracking. In general, problems with scores less than 100 are easy and require no backtracking and scores in the 300+ range are fairly challenging. In Table 2, easy puzzles correspond to scores of roughly 100, medium to scores of 400 and hard ones to scores of 600.</p>
<p>D.2 Generating Sudokus</p>
<p>As mentioned previously, Sudoku problems are generated by starting with a random 9 × 9 grid G that satisfies Sudoku constraints. G is generated by a random backtracking search over {1, 2, . . . , 9} 9×9 , the space of 9 × 9 grids of single digit positive integers. A problem P is obtained from G by clearing certain cells, ensuring that G is the only solution of P . This is done by a local search -cells are randomly cleared from the grid and it is checked if G is the only possible solution to the new problem. If this is the case, then the difficulty score is estimated and the problem is stored in the dataset. Table 4 includes samples for the symbols 0, 1 and 2 for mazes of different dimensions. Table 5 includes samples for digits 1-9 for Sudoku problems of different hardness levels. Note that in   </p>
<p>Appendix E Digit Samples</p>
<p>Appendix F Ablation Numbers</p>
<p>We include numbers for modified versions of NSNnet in Table 6 for the Visual Sudoku task. Note that for all modified versions we get zero task completion rate and no better than chance classification accuracy indicating that both the reward gradient and subsampling heuristic are necessary to solve the cold-start issue. REINFORCE with maxent regularization adds a maximum entropy regularization term −τ π θ (a|s 0 )logπ θ (a|s 0 ) to the O RL objective in Eq 13 to encourage exploration. We try τ ∈ {1, 10, 100, 1000}. UREX [27] also uses a hyperparameter τ to characterize the reward-scaled probability distribution. We try τ ∈ {0.005, 0.01, 0.1, 1}, values in the neighborhood of the optimal value τ = 0.1 recommended in the official implementation.  </p>
<p>Figure 1 :
1(A,B) Two image-to-image reasoning tasks-maze solving, and sudoku solving, respectivelywhere input and supervision are both in image form. (C) Schematic of NSNnet, our neural-symbolicneural system -see Section 3 for details.</p>
<p>Figure 2 :
2Sample digits generated by the maze solver (right) and sudoku model (left). More in appendix.</p>
<p>Table 2 :
2Results on Visual Sudoku tasks for 
different puzzle hardness levels. NSNnet shows 
high input symbol classification accuracy (CA) 
and task completion rate (TCR) across levels. </p>
<p>Table 3 :
3Accuracies for Visual Sudoku and 
Visual Maze (13 × 13) with varying sub-
sampling fraction. Accuracy significantly in-
creases when this fraction is lowered. </p>
<p>table 5the digits do not correspond to the symbols since NSNnet has no way of knowing the correspondence between symbols and images due to the lack of intermediate supervision. Therefore, in general, some permutation of symbols to MNIST images is learnt by the classifier and VAEs.E.1 Visual Maze </p>
<p>Dimension 
0 
1 
2 </p>
<p>7 × 7 </p>
<p>13 × 13 </p>
<p>19 × 18 </p>
<p>28 × 28 </p>
<p>43 × 43 </p>
<p>Table 4 :
4Sample images for Visual Maze E.2 Visual SudokuSymbol 
Easy 
Medium 
Hard </p>
<p>1 </p>
<p>2 </p>
<p>3 </p>
<p>4 </p>
<p>5 </p>
<p>6 </p>
<p>7 </p>
<p>8 </p>
<p>9 </p>
<p>Table 5 :
5Sample images for Visual Sudoku</p>
<p>Table 6 :
6TCR and CA values for NSNnet with ablations
In the testbeds we explore, we have assumed highly structured input formats; however, this is not a necessary part of the general architecture proposed inFigure 1.2 see a recent compilation (Sarker et al.[22] Figure 2) for a summary of existing neuro-symbolic architectures, which does not include NSN.
Moe is written as a deterministic function here for simplicity, however, it could in general also output a distribution overẑ
Although we do not consider it in this work, a suitable schedule such that η → 1 can remove bias after overcoming cold start. We leave this as an open question for future work.
Since our system receives no intermediate feedback, NSNnet has no knowledge of the ordering of symbols, for example, that slot 1 should correspond to the symbol zero. It therefore identifies symbols accurately upto a permutation; for measuring classification accuracy, we use the appropriate permutation for each trained model. For Visual Maze, however, each symbol has a distinct role, necessary for the path solver, and so the network identifies symbols in the correct ordering.
Appendix A Policy GradientWe describe the policy gradient approach in the original reinforcement learning formulation[24], and various recent approaches; subsequently, we make connections to our learning problem. In policy gradient methods, the goal is to learn an action policy for an agent, π θ (a t |s) -a probability distribution over actions a t associated with a sequence of states s = (s 0 , s 1 , . . . , s t ) -in order to maximize reward. In classical RL formulations, states evolve in Markov fashion, conditioned on the agent's action at each state, and starting from some initial condition s 0 , so we can calculate π θ (a | s 0 ), the probability of the action sequence a = (a 0 , . . . , a t ) given initial state s 0where the states s t+1 = f (s t , a t ) evolve according to some transition function f (·). The REINFORCE objective equals the expected reward when following a policy π θwhere p is a prior over initial states and r is a reward function. The last sum is derived using the identity ∇ θ f (θ) = f (θ)∇ θ log f (θ).[24]proposed Monte Carlo sampling to estimate this gradient, by averaging weighted rewards over samples drawn from the current policy, i.e., over initial states sInitialize empty array A, δ e ← 0, δ d ← 0, δ oe ← 0 Let π θ ← M e (I) be a probability distribution for i = 1 to K do Draw random samplex from π θ with probability π θ (x)Appendix C Sudoku Constraint SolverWe use Google OR-Tools, an open source library for optimization to solve Sudokus. In particular, we use the CP-SAT Solver which can be used to create and solve constraint satisfaction problems. OR-Tools is available under the Apache license.Appendix D Sudoku GeneratorWe use code available on Daniel Beer's blog to generate Sudokus of varied difficulty levels.D.1 Estimating difficulty scoresDifficulty scores are estimated by looking at the branching factors B ij at empty cells (i, j) that the Sudoku solver encounters at each step of the path from the root of the search tree to the solution. If E is the set of empty cells then the difficulty score is estimated as 100 · (i,j)∈E
The perceptron: A probabilistic model for information storage and organization in the brain. Frank Rosenblatt, Psychological review. 656Frank Rosenblatt. The perceptron: A probabilistic model for information storage and organiza- tion in the brain. Psychological review, 65(6):386-408, 1958.</p>
<p>Learning representations by back-propagating errors. Geoffrey E David E Rumelhart, Ronald J Hinton, Williams, Nature. 3236088David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning representations by back-propagating errors. Nature, 323(6088):533-536, 1986.</p>
<p>Thinking, fast and slow. Daniel Kahneman, MacmillanDaniel Kahneman. Thinking, fast and slow. Macmillan, 2011.</p>
<p>Value iteration networks. Aviv Tamar, Sergey Levine, Pieter Abbeel, Yi Wu, Garrett Thomas, Advances in Neural Information Processing Systems (NeurIPS) 29. Aviv Tamar, Sergey Levine, Pieter Abbeel, Yi Wu, and Garrett Thomas. Value iteration networks. In Advances in Neural Information Processing Systems (NeurIPS) 29, pages 2146-2154, 2016.</p>
<p>SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver. Po-Wei Wang, Priya L Donti, Bryan Wilder, J Zico Kolter, Proceedings of the 36th International Conference on Machine Learning. the 36th International Conference on Machine LearningPo-Wei Wang, Priya L. Donti, Bryan Wilder, and J. Zico Kolter. SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver. In Proceedings of the 36th International Conference on Machine Learning, (ICML), 2019, 2019.</p>
<p>Inductive logic programming via differentiable deep neural logic networks. Ali Payani, Faramarz Fekri, abs/1906.03523CoRRAli Payani and Faramarz Fekri. Inductive logic programming via differentiable deep neural logic networks. CoRR, abs/1906.03523, 2019.</p>
<p>Neural-symbolic integration: A compositional perspective. Efthymia Tsamoura, Loizos Michael, proceedings of the AAAI conference on artificial Intelligence (AAA). the AAAI conference on artificial Intelligence (AAA)Efthymia Tsamoura and Loizos Michael. Neural-symbolic integration: A compositional perspective. In In proceedings of the AAAI conference on artificial Intelligence (AAA), 2020, volume abs/2010.11926, 2020.</p>
<p>Deepproblog: Neural probabilistic logic programming. Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, Luc De Raedt, Advances in Neural Information Processing Systems (NeurIPS) 31. Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, and Luc De Raedt. Deepproblog: Neural probabilistic logic programming. In Advances in Neural Informa- tion Processing Systems (NeurIPS) 31, pages 3753-3763, 2018.</p>
<p>Neurasp: Embracing neural networks into answer set programming. Zhun Yang, Adam Ishay, Joohyung Lee, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence. the Twenty-Ninth International Joint Conference on Artificial Intelligence2020Zhun Yang, Adam Ishay, and Joohyung Lee. Neurasp: Embracing neural networks into answer set programming. In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, 2020.</p>
<p>Neural learning of one-of-many solutions for combinatorial problems in structured output spaces. Yatin Nandwani, Deepanshu Jindal, Mausam , Parag Singla, International Conference on Learning Representations (ICLR). 2021Yatin Nandwani, Deepanshu Jindal, Mausam, and Parag Singla. Neural learning of one-of-many solutions for combinatorial problems in structured output spaces. In International Conference on Learning Representations (ICLR), 2021.</p>
<p>A semantic loss function for deep learning with symbolic knowledge. Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, Guy Van Den Broeck, Proceedings of the 35th International Conference on Machine Learning. Jennifer G. Dy and Andreas Krausethe 35th International Conference on Machine LearningStockholmsmässan, Stockholm, SwedenPMLR80Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, and Guy Van den Broeck. A semantic loss function for deep learning with symbolic knowledge. In Jennifer G. Dy and Andreas Krause, editors, Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmässan, Stockholm, Sweden, July 10-15, 2018, volume 80 of Proceedings of Machine Learning Research, pages 5498-5507. PMLR, 2018.</p>
<p>A primal dual formulation for deep learning with constraints. Yatin Nandwani, Abhishek Pathak, Mausam , Parag Singla, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems. Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d'Alché-Buc, Emily B. Fox, and Roman GarnettNeurIPS; Vancouver, BC, CanadaYatin Nandwani, Abhishek Pathak, Mausam, and Parag Singla. A primal dual formulation for deep learning with constraints. In Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Flo- rence d'Alché-Buc, Emily B. Fox, and Roman Garnett, editors, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 12157-12168, 2019.</p>
<p>Openie6: Iterative grid labeling and coordination analysis for open information extraction. Keshav Kolluru, Vaibhav Adlakha, Samarth Aggarwal, Mausam , Soumen Chakrabarti, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liuthe 2020 Conference on Empirical Methods in Natural Language ProcessingOnlineAssociation for Computational Linguistics2020Keshav Kolluru, Vaibhav Adlakha, Samarth Aggarwal, Mausam, and Soumen Chakrabarti. Openie6: Iterative grid labeling and coordination analysis for open information extraction. In Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu, editors, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, pages 3748-3761. Association for Computational Linguistics, 2020.</p>
<p>Deep reasoning networks for unsupervised pattern de-mixing with constraint reasoning. Di Chen, Yiwei Bai, Wenting Zhao, Sebastian Ament, John M Gregoire, Carla P Gomes, Proceedings of the 37th International Conference on Machine Learning. the 37th International Conference on Machine LearningPMLR2020Di Chen, Yiwei Bai, Wenting Zhao, Sebastian Ament, John M. Gregoire, and Carla P. Gomes. Deep reasoning networks for unsupervised pattern de-mixing with constraint reasoning. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research, pages 1500-1509. PMLR, 2020.</p>
<p>Unsupervised state representation learning in atari. Ankesh Anand, Evan Racah, Sherjil Ozair, Yoshua Bengio, Marc-Alexandre Côté, R Devon Hjelm, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems. Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d'Alché-Buc, Emily B. Fox, and Roman GarnettNeurIPS; Vancouver, BC, CanadaAnkesh Anand, Evan Racah, Sherjil Ozair, Yoshua Bengio, Marc-Alexandre Côté, and R. Devon Hjelm. Unsupervised state representation learning in atari. In Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d'Alché-Buc, Emily B. Fox, and Roman Garnett, editors, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 8766-8779, 2019.</p>
<p>Contrastive learning of structured world models. Thomas N Kipf, Elise Van Der Pol, Max Welling, 8th International Conference on Learning Representations. Addis Ababa, Ethiopia2020Thomas N. Kipf, Elise van der Pol, and Max Welling. Contrastive learning of structured world models. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020.</p>
<p>Neural-symbolic VQA: disentangling reasoning from vision and language understanding. Kexin Yi, Jiajun Wu, Chuang Gan, Antonio Torralba, Pushmeet Kohli, Josh Tenenbaum, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems. Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman GarnettNeurIPS; Montréal, CanadaKexin Yi, Jiajun Wu, Chuang Gan, Antonio Torralba, Pushmeet Kohli, and Josh Tenenbaum. Neural-symbolic VQA: disentangling reasoning from vision and language understanding. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman Garnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada, pages 1039-1050, 2018.</p>
<p>The neurosymbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. Jiayuan Mao, Chuang Gan, Pushmeet Kohli, Joshua B Tenenbaum, Jiajun Wu, 7th International Conference on Learning Representations, ICLR 2019. New Orleans, LA, USAOpenReview.netJiayuan Mao, Chuang Gan, Pushmeet Kohli, Joshua B. Tenenbaum, and Jiajun Wu. The neuro- symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net, 2019.</p>
<p>Mapping natural-language problems to formal-language solutions using structured neural representations. Kezhen Chen, Qiuyuan Huang, Hamid Palangi, Paul Smolensky, Kenneth D Forbus, Jianfeng Gao, Proceedings of the 37th International Conference on Machine Learning. the 37th International Conference on Machine LearningPMLR2020Kezhen Chen, Qiuyuan Huang, Hamid Palangi, Paul Smolensky, Kenneth D. Forbus, and Jianfeng Gao. Mapping natural-language problems to formal-language solutions using structured neural representations. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research, pages 1566-1575. PMLR, 2020.</p>
<p>Memory augmented policy optimization for program synthesis and semantic parsing. Chen Liang, Mohammad Norouzi, Jonathan Berant, Quoc V Le, Ni Lao, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems. Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman GarnettNeurIPS; Montréal, CanadaChen Liang, Mohammad Norouzi, Jonathan Berant, Quoc V. Le, and Ni Lao. Memory aug- mented policy optimization for program synthesis and semantic parsing. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman Garnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada, pages 10015-10027, 2018.</p>
<p>Unsupervised learning of KB queries in taskoriented dialogs. Dinesh Raghu, Nikhil Gupta, Mausam , Trans. Assoc. Comput. Linguistics. 9Dinesh Raghu, Nikhil Gupta, and Mausam. Unsupervised learning of KB queries in task- oriented dialogs. Trans. Assoc. Comput. Linguistics, 9:374-390, 2021.</p>
<p>Neuro-symbolic artificial intelligence: Current trends. CoRR. Kamruzzaman Md, Lu Sarker, Aaron Zhou, Pascal Eberhart, Hitzler, abs/2105.05330Md. Kamruzzaman Sarker, Lu Zhou, Aaron Eberhart, and Pascal Hitzler. Neuro-symbolic artificial intelligence: Current trends. CoRR, abs/2105.05330, 2021.</p>
<p>Auto-encoding variational bayes. P Diederik, Max Kingma, Welling, 2nd International Conference on Learning Representations. Banff, AB, CanadaConference Track ProceedingsDiederik P. Kingma and Max Welling. Auto-encoding variational bayes. In Yoshua Bengio and Yann LeCun, editors, 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings, 2014.</p>
<p>Simple statistical gradient-following algorithms for connectionist reinforcement learning. Ronald J Williams, Mach. Learn. 8Ronald J. Williams. Simple statistical gradient-following algorithms for connectionist reinforce- ment learning. Mach. Learn., 8:229-256, 1992.</p>
<p>Function optimization using connectionist reinforcement learning algorithms. J Ronald, Jing Williams, Peng, Connection Science. 33Ronald J Williams and Jing Peng. Function optimization using connectionist reinforcement learning algorithms. Connection Science, 3(3):241-268, 1991.</p>
<p>Reward augmented maximum likelihood for neural structured prediction. Mohammad Norouzi, Samy Bengio, Zhifeng Chen, Navdeep Jaitly, Mike Schuster, Yonghui Wu, Dale Schuurmans, Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems. Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon, and Roman GarnettBarcelona, SpainMohammad Norouzi, Samy Bengio, Zhifeng Chen, Navdeep Jaitly, Mike Schuster, Yonghui Wu, and Dale Schuurmans. Reward augmented maximum likelihood for neural structured prediction. In Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon, and Roman Garnett, editors, Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain, pages 1723-1731, 2016.</p>
<p>Improving policy gradient by exploring under-appreciated rewards. Ofir Nachum, Mohammad Norouzi, Dale Schuurmans, 5th International Conference on Learning Representations. Toulon, FranceConference Track Proceedings. OpenReview.netOfir Nachum, Mohammad Norouzi, and Dale Schuurmans. Improving policy gradient by explor- ing under-appreciated rewards. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net, 2017.</p>
<p>Top-k training of gans: Improving GAN performance by throwing away bad samples. Samarth Sinha, Zhengli Zhao, Anirudh Goyal, Colin Raffel, Augustus Odena, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020. Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin2020Samarth Sinha, Zhengli Zhao, Anirudh Goyal, Colin Raffel, and Augustus Odena. Top-k training of gans: Improving GAN performance by throwing away bad samples. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020.</p>
<p>Hybrid classification and reasoning for image-based constraint solving. Maxime Mulamba, Jayanta Mandi, Integration of Constraint Programming, Artificial Intelligence, and Operations Research -17th International Conference. Emmanuel Hebrard and Nysret MusliuVienna, AustriaSpringer2020ProceedingsMaxime Mulamba, Jayanta Mandi, Rocsildes Canoy, and Tias Guns. Hybrid classification and reasoning for image-based constraint solving. In Emmanuel Hebrard and Nysret Musliu, editors, Integration of Constraint Programming, Artificial Intelligence, and Operations Research -17th International Conference, CPAIOR 2020, Vienna, Austria, September 21-24, 2020, Proceedings, volume 12296 of Lecture Notes in Computer Science, pages 364-380. Springer, 2020.</p>
<p>Backpropagation applied to handwritten zip code recognition. Yann Lecun, Bernhard E Boser, John S Denker, Donnie Henderson, Richard E Howard, Wayne E Hubbard, Lawrence D Jackel, Neural Comput. 14Yann LeCun, Bernhard E. Boser, John S. Denker, Donnie Henderson, Richard E. Howard, Wayne E. Hubbard, and Lawrence D. Jackel. Backpropagation applied to handwritten zip code recognition. Neural Comput., 1(4):541-551, 1989.</p>            </div>
        </div>

    </div>
</body>
</html>