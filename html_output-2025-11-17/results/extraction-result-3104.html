<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3104 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3104</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3104</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-77.html">extraction-schema-77</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving puzzle games that require spatial knowledge (such as Sudoku), including details about the models, the puzzles, the methods used, performance, and any analysis of how the models solve these tasks.</div>
                <p><strong>Paper ID:</strong> paper-265609823</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2312.01054v1.pdf" target="_blank">Exploring and Improving the Spatial Reasoning Abilities of Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs) represent formidable tools for sequence modeling, boasting an innate capacity for general pattern recognition. Nevertheless, their broader spatial reasoning capabilities, especially applied to numerical trajectory data, remain insufficiently explored. In this paper, we investigate the out-of-the-box performance of ChatGPT-3.5, ChatGPT-4 and Llama 2 7B models when confronted with 3D robotic trajectory data from the CALVIN baseline and associated tasks, including 2D directional and shape labeling. Additionally, we introduce a novel prefix-based prompting mechanism, which yields a 33% improvement on the 3D trajectory data and an increase of up to 10% on SpartQA tasks over zero-shot prompting (with gains for other prompting types as well). The experimentation with 3D trajectory data offers an intriguing glimpse into the manner in which LLMs engage with numerical and spatial information, thus laying a solid foundation for the identification of target areas for future enhancements.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3104.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3104.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving puzzle games that require spatial knowledge (such as Sudoku), including details about the models, the puzzles, the methods used, performance, and any analysis of how the models solve these tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT-3.5 (2D)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT-3.5 (evaluated on 2D direction and shape labeling)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>OpenAI ChatGPT-3.5 evaluated as a zero-/few-shot labeler for 2D path direction labeling and zero-shot shape identification; performs acceptably on short directional sequences but poorly on shape labeling and long sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploring and Improving the Spatial Reasoning Abilities of Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A large language model from OpenAI (chat-optimized GPT-3 family). Used here as an off-the-shelf text-only model to perform numeric-sequence to label mapping via prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>2D direction labeling; 2D shape identification</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Direction labeling: given a sequence of 2D Cartesian coordinates, predict segment-wise directions (left/right/up/down). Shape identification: given a sequence of 2D coordinates (hand-gesture traces), identify the overall shape (e.g., circle, checkmark); requires spatial pattern recognition over noisy trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>input_representation</strong></td>
                            <td>Numeric sequences of coordinates presented as text lists (x,y) normalized to [0,100], sometimes integer or floating-point; sequences of varying length (short: 6-8 segments, long: 35-40).</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Few-shot in-context learning for direction labeling; zero-shot prompting for shape identification.</td>
                        </tr>
                        <tr>
                            <td><strong>spatial_reasoning_analysis</strong></td>
                            <td>Qualitative analysis in the paper: model leverages few-shot pattern examples to match simple directional patterns; succeeds on short repetitive/clear segment movements but fails when sequences are longer or noisier. No internal attention or representation analysis was performed; reasoning assessment is based on outputs and human evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>From Table 1: Direction labeling — integer(short) accuracy 0.50 with average error per sequence (Err.#) 0.15; float(short) accuracy 0.50 Err.# 0.25; integer(long) accuracy 0.00 Err.# 0.70. Shape identification — integer-normalized dataset accuracy 0.31; float-normalized accuracy 0.23.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Fails on long-horizon directional sequences (near-zero accuracy on the long integer sequences tested); poor shape identification in zero-shot setting, especially with noisy human demonstration data; sensitive to sequence length and noise.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models_or_humans</strong></td>
                            <td>Underperforms ChatGPT-4 on the same 2D tasks (ChatGPT-4 reached perfect classification on short trajectories and substantially better performance on long ones). No direct human baseline numbers provided for these tasks in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring and Improving the Spatial Reasoning Abilities of Large Language Models', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3104.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3104.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving puzzle games that require spatial knowledge (such as Sudoku), including details about the models, the puzzles, the methods used, performance, and any analysis of how the models solve these tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT-4 (2D)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT-4 (evaluated on 2D direction and shape labeling)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>OpenAI ChatGPT-4 evaluated on the same 2D tasks; substantially stronger than ChatGPT-3.5 on short directional sequences and better on longer sequences and shape labeling.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploring and Improving the Spatial Reasoning Abilities of Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI's GPT-4 family chat model, larger and trained with broader data and reinforcement learning from human feedback compared to GPT-3.5; used off-the-shelf for numeric-sequence classification via prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>2D direction labeling; 2D shape identification</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Same as above: segment-wise direction classification and whole-path shape identification from sequences of 2D coordinates.</td>
                        </tr>
                        <tr>
                            <td><strong>input_representation</strong></td>
                            <td>Text sequences of numeric (x,y) coordinates normalized to [0,100], both integer and floating point representations; short and long horizon sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Few-shot in-context learning for direction labeling; zero-shot for shape identification.</td>
                        </tr>
                        <tr>
                            <td><strong>spatial_reasoning_analysis</strong></td>
                            <td>Paper-level qualitative conclusions: ChatGPT-4 seems to exploit repeated, simple numerical patterns better and generalizes from few-shot directional examples to new short sequences; performance degrades with irregular/noisy inputs. No internal probing of representations was reported.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>From Table 1: Direction labeling — integer(short) accuracy 1.00 Err.# 0.00; float(short) accuracy 1.00 Err.# 0.00; integer(long) accuracy 0.60 Err.# 0.13. Shape identification — integer-normalized accuracy 0.46; float-normalized accuracy 0.46.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Although very strong on short directional sequences (perfect in these experiments), performance drops on long noisy sequences and on shape identification in zero-shot; sensitive to dataset noise and irregular patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models_or_humans</strong></td>
                            <td>Outperforms ChatGPT-3.5 on the reported 2D tasks; no direct human baseline reported. Authors note parameter size and larger pretraining likely contribute to ChatGPT-4's superior performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring and Improving the Spatial Reasoning Abilities of Large Language Models', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3104.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3104.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving puzzle games that require spatial knowledge (such as Sudoku), including details about the models, the puzzles, the methods used, performance, and any analysis of how the models solve these tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT-3.5 (3D Trajectories)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT-3.5 (evaluated on 3D CALVIN trajectories)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>ChatGPT-3.5 used to classify 3D robotic end-effector trajectories into motion categories (lift, rotate, slide) under several prompting strategies; shows limited performance on raw noisy trajectories and improves modestly with Spatial Prefix-Prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploring and Improving the Spatial Reasoning Abilities of Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI ChatGPT-3.5; used as an off-the-shelf text-only model to label sequences of 3D coordinates via prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>3D trajectory classification (CALVIN & CALVIN-Cleaned)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Given a time-ordered sequence of 3D end-effector coordinates from robotic demonstrations, classify the overall motion into one of {lifting, rotating, sliding}. Requires reasoning about 3D coordinate changes, temporal patterns (e.g., changes in z for lift), and differentiating noise from meaningful motion.</td>
                        </tr>
                        <tr>
                            <td><strong>input_representation</strong></td>
                            <td>Sequences of (x,y,z) coordinates extracted from the CALVIN benchmark. Coordinates were normalized (range [0,300] integers) and provided as text lists. Two dataset variants: raw CALVIN (noisy, long trajectories) and CALVIN-Cleaned (human-trimmed subsequences matching action).</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Zero-shot, In-context Learning (few-shot), Chain-of-Thought (few-shot + step-by-step reasoning), Spatial Prefix-Prompting (SPP — ask a simpler spatial question first to prime the model).</td>
                        </tr>
                        <tr>
                            <td><strong>spatial_reasoning_analysis</strong></td>
                            <td>Authors' analysis: models struggle more on high-dimensional, irregular sequences; they excel on repetitive/simple patterns; CoT prompting was volatile and sometimes detrimental (dependent on example selection), while Spatial Prefix-Prompting often improved generalization by priming fundamental spatial concepts. No internal attention/representation probing performed.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>From Table 2 (selected values reported in paper): CALVIN (raw) zero-shot F1 ≈ 0.19, accuracy ≈ 0.26; with SPP F1 ≈ 0.32, accuracy ≈ 0.43. CALVIN-Cleaned zero-shot F1 ≈ 0.24, accuracy ≈ 0.30; with SPP F1 ≈ 0.38, accuracy ≈ 0.43. Overall performance on raw trajectories is described as 'subpar' and unlikely to be sufficient for real robotic trajectory classification.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Per paper: high irregularity and extraneous movements in raw trajectories confuse the model; CoT can mislead when noisy sub-patterns resemble other motion types; small evaluation subset (30 samples) limits statistical strength; models appear to rely on pre-trained semantic priors (e.g., simple up/down in z for 'lift') so when trajectories don't match these priors they fail.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models_or_humans</strong></td>
                            <td>ChatGPT-3.5 underperforms ChatGPT-4 on these 3D tasks (ChatGPT-4 achieves substantially higher F1/accuracy in several prompting modes). No human baseline numbers reported for these specific experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring and Improving the Spatial Reasoning Abilities of Large Language Models', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3104.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3104.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving puzzle games that require spatial knowledge (such as Sudoku), including details about the models, the puzzles, the methods used, performance, and any analysis of how the models solve these tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT-4 (3D Trajectories)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT-4 (evaluated on 3D CALVIN trajectories)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>ChatGPT-4 applied to 3D trajectory labeling (lift/rotate/slide) and evaluated with zero-shot, ICL, CoT, and Spatial Prefix-Prompting; shows improved performance versus ChatGPT-3.5 and benefits notably from Spatial Prefix-Prompting, especially on cleaned trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploring and Improving the Spatial Reasoning Abilities of Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI GPT-4 based chat model; used off-the-shelf to label sequences of 3D coordinates via textual prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>3D trajectory classification (CALVIN & CALVIN-Cleaned)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Classification of sequences of 3D end-effector positions into motion classes requiring temporal and spatial reasoning about coordinate changes and overall trajectory morphology.</td>
                        </tr>
                        <tr>
                            <td><strong>input_representation</strong></td>
                            <td>Textual lists of (x,y,z) coordinates normalized to integer ranges; both raw CALVIN trajectories and human-cleaned subsequences were used.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Zero-shot, In-context Learning (few-shot), Chain-of-Thought, Spatial Prefix-Prompting (SPP).</td>
                        </tr>
                        <tr>
                            <td><strong>spatial_reasoning_analysis</strong></td>
                            <td>Paper's analysis: ChatGPT-4 better leverages few-shot examples and benefits more from SPP than CoT in noisy settings; CoT gains are smaller and volatile compared to other domains. The authors hypothesize that SPP helps by invoking simpler pretrained numeric-difference calculations (e.g., computing deltas) that transfer to more complex tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Selected reported values from Table 2: CALVIN (raw): zero-shot F1 ≈ 0.19 accuracy ≈ 0.27; SPP F1 ≈ 0.55 accuracy ≈ 0.60. CALVIN-Cleaned: zero-shot F1 ≈ 0.42 accuracy ≈ 0.47; CoT and ICL show mixed results, and SPP achieves F1 ≈ 0.80 accuracy ≈ 0.80 on the cleaned subset (largest reported improvements). The paper notes the highest F1 on raw data was capped at 0.63 in some prompting settings.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Still struggles on raw noisy trajectories; large improvements on cleaned data suggest sensitivity to noise and the portion of trajectory that corresponds to the labeled action. Chain-of-Thought can be brittle and example-dependent; dataset size is small (30 samples) so results may not generalize.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models_or_humans</strong></td>
                            <td>Outperforms ChatGPT-3.5 on the same tasks and prompting methods; SPP produced the largest gains among the prompting strategies in these experiments. No direct human performance numbers provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring and Improving the Spatial Reasoning Abilities of Large Language Models', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3104.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3104.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving puzzle games that require spatial knowledge (such as Sudoku), including details about the models, the puzzles, the methods used, performance, and any analysis of how the models solve these tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama-2-7B (SpartQA)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama 2 7B (evaluated on SPARTQA spatial QA benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Meta's Llama 2 7B evaluated on the SPARTQA textual spatial reasoning benchmark (four subtypes); Spatial Prefix-Prompting improves accuracy over zero-shot and Chain-of-Thought prompting for several question types.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploring and Improving the Spatial Reasoning Abilities of Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama 2 7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source Llama 2 family model with ~7 billion parameters; used here because of faster evaluation time on the 510-instance SPARTQA test set.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>SPARTQA (textual spatial question answering) subtypes: Find Relation (FR), Find Blocks (FB), Choose Object (CO), Yes/No (YN)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Textual QA tasks requiring deeper spatial reasoning about relations and attributes of objects described in text (e.g., determining which object is 'above' another, which block meets constraints). Requires understanding of spatial relations and attributes from textual descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>input_representation</strong></td>
                            <td>Natural-language textual questions from the SPARTQA dataset (no visual inputs); answers are text labels/choices.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Zero-shot, Chain-of-Thought prompting, Spatial Prefix-Prompting (SPP).</td>
                        </tr>
                        <tr>
                            <td><strong>spatial_reasoning_analysis</strong></td>
                            <td>Paper reports that SPP often surpasses CoT and zero-shot on FR and CO subtypes; authors interpret this as SPP priming simple spatial concepts (like direction identification) that transfer to more abstract textual spatial reasoning. No gradient/attention probing was done.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>From Table 3 (reported): SPP accuracies (per-subtype) — FR: 0.42, FB: 0.44, CO: 0.42, YN: 0.40, Overall: 0.41. Chain-of-Thought and zero-shot rows in the table are lower; overall CoT/zero-shot combined accuracy reported ~0.36 in that table (dataset-level).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Despite improvements from SPP, absolute accuracies remain moderate (~0.41 overall). The model still fails many spatial reasoning questions, indicating limited deeper spatial understanding from text-only prompts. Heuristic evaluation was used for some SpartQA answers, and human evaluation was used for others, which may affect evaluation fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models_or_humans</strong></td>
                            <td>Only Llama-2-7B was evaluated on the full SPARTQA test set in this paper; SPP improved results compared to CoT and zero-shot for this model. No human baselines or non-language-model comparisons provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring and Improving the Spatial Reasoning Abilities of Large Language Models', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Calvin: A benchmark for languageconditioned policy learning for long-horizon robot manipulation tasks <em>(Rating: 2)</em></li>
                <li>SPARTQA: A textual question answering benchmark for spatial reasoning <em>(Rating: 2)</em></li>
                <li>Large language models as general pattern machines <em>(Rating: 1)</em></li>
                <li>Chain-ofthought prompting elicits reasoning in large language models <em>(Rating: 1)</em></li>
                <li>3d-llm: Injecting the 3d world into large language models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3104",
    "paper_id": "paper-265609823",
    "extraction_schema_id": "extraction-schema-77",
    "extracted_data": [
        {
            "name_short": "ChatGPT-3.5 (2D)",
            "name_full": "ChatGPT-3.5 (evaluated on 2D direction and shape labeling)",
            "brief_description": "OpenAI ChatGPT-3.5 evaluated as a zero-/few-shot labeler for 2D path direction labeling and zero-shot shape identification; performs acceptably on short directional sequences but poorly on shape labeling and long sequences.",
            "citation_title": "Exploring and Improving the Spatial Reasoning Abilities of Large Language Models",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_description": "A large language model from OpenAI (chat-optimized GPT-3 family). Used here as an off-the-shelf text-only model to perform numeric-sequence to label mapping via prompting.",
            "model_size": null,
            "puzzle_name": "2D direction labeling; 2D shape identification",
            "puzzle_description": "Direction labeling: given a sequence of 2D Cartesian coordinates, predict segment-wise directions (left/right/up/down). Shape identification: given a sequence of 2D coordinates (hand-gesture traces), identify the overall shape (e.g., circle, checkmark); requires spatial pattern recognition over noisy trajectories.",
            "input_representation": "Numeric sequences of coordinates presented as text lists (x,y) normalized to [0,100], sometimes integer or floating-point; sequences of varying length (short: 6-8 segments, long: 35-40).",
            "prompting_method": "Few-shot in-context learning for direction labeling; zero-shot prompting for shape identification.",
            "spatial_reasoning_analysis": "Qualitative analysis in the paper: model leverages few-shot pattern examples to match simple directional patterns; succeeds on short repetitive/clear segment movements but fails when sequences are longer or noisier. No internal attention or representation analysis was performed; reasoning assessment is based on outputs and human evaluation.",
            "performance_metrics": "From Table 1: Direction labeling — integer(short) accuracy 0.50 with average error per sequence (Err.#) 0.15; float(short) accuracy 0.50 Err.# 0.25; integer(long) accuracy 0.00 Err.# 0.70. Shape identification — integer-normalized dataset accuracy 0.31; float-normalized accuracy 0.23.",
            "limitations_or_failure_modes": "Fails on long-horizon directional sequences (near-zero accuracy on the long integer sequences tested); poor shape identification in zero-shot setting, especially with noisy human demonstration data; sensitive to sequence length and noise.",
            "comparison_to_other_models_or_humans": "Underperforms ChatGPT-4 on the same 2D tasks (ChatGPT-4 reached perfect classification on short trajectories and substantially better performance on long ones). No direct human baseline numbers provided for these tasks in the paper.",
            "uuid": "e3104.0",
            "source_info": {
                "paper_title": "Exploring and Improving the Spatial Reasoning Abilities of Large Language Models",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "ChatGPT-4 (2D)",
            "name_full": "ChatGPT-4 (evaluated on 2D direction and shape labeling)",
            "brief_description": "OpenAI ChatGPT-4 evaluated on the same 2D tasks; substantially stronger than ChatGPT-3.5 on short directional sequences and better on longer sequences and shape labeling.",
            "citation_title": "Exploring and Improving the Spatial Reasoning Abilities of Large Language Models",
            "mention_or_use": "use",
            "model_name": "ChatGPT-4",
            "model_description": "OpenAI's GPT-4 family chat model, larger and trained with broader data and reinforcement learning from human feedback compared to GPT-3.5; used off-the-shelf for numeric-sequence classification via prompting.",
            "model_size": null,
            "puzzle_name": "2D direction labeling; 2D shape identification",
            "puzzle_description": "Same as above: segment-wise direction classification and whole-path shape identification from sequences of 2D coordinates.",
            "input_representation": "Text sequences of numeric (x,y) coordinates normalized to [0,100], both integer and floating point representations; short and long horizon sequences.",
            "prompting_method": "Few-shot in-context learning for direction labeling; zero-shot for shape identification.",
            "spatial_reasoning_analysis": "Paper-level qualitative conclusions: ChatGPT-4 seems to exploit repeated, simple numerical patterns better and generalizes from few-shot directional examples to new short sequences; performance degrades with irregular/noisy inputs. No internal probing of representations was reported.",
            "performance_metrics": "From Table 1: Direction labeling — integer(short) accuracy 1.00 Err.# 0.00; float(short) accuracy 1.00 Err.# 0.00; integer(long) accuracy 0.60 Err.# 0.13. Shape identification — integer-normalized accuracy 0.46; float-normalized accuracy 0.46.",
            "limitations_or_failure_modes": "Although very strong on short directional sequences (perfect in these experiments), performance drops on long noisy sequences and on shape identification in zero-shot; sensitive to dataset noise and irregular patterns.",
            "comparison_to_other_models_or_humans": "Outperforms ChatGPT-3.5 on the reported 2D tasks; no direct human baseline reported. Authors note parameter size and larger pretraining likely contribute to ChatGPT-4's superior performance.",
            "uuid": "e3104.1",
            "source_info": {
                "paper_title": "Exploring and Improving the Spatial Reasoning Abilities of Large Language Models",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "ChatGPT-3.5 (3D Trajectories)",
            "name_full": "ChatGPT-3.5 (evaluated on 3D CALVIN trajectories)",
            "brief_description": "ChatGPT-3.5 used to classify 3D robotic end-effector trajectories into motion categories (lift, rotate, slide) under several prompting strategies; shows limited performance on raw noisy trajectories and improves modestly with Spatial Prefix-Prompting.",
            "citation_title": "Exploring and Improving the Spatial Reasoning Abilities of Large Language Models",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_description": "OpenAI ChatGPT-3.5; used as an off-the-shelf text-only model to label sequences of 3D coordinates via prompting.",
            "model_size": null,
            "puzzle_name": "3D trajectory classification (CALVIN & CALVIN-Cleaned)",
            "puzzle_description": "Given a time-ordered sequence of 3D end-effector coordinates from robotic demonstrations, classify the overall motion into one of {lifting, rotating, sliding}. Requires reasoning about 3D coordinate changes, temporal patterns (e.g., changes in z for lift), and differentiating noise from meaningful motion.",
            "input_representation": "Sequences of (x,y,z) coordinates extracted from the CALVIN benchmark. Coordinates were normalized (range [0,300] integers) and provided as text lists. Two dataset variants: raw CALVIN (noisy, long trajectories) and CALVIN-Cleaned (human-trimmed subsequences matching action).",
            "prompting_method": "Zero-shot, In-context Learning (few-shot), Chain-of-Thought (few-shot + step-by-step reasoning), Spatial Prefix-Prompting (SPP — ask a simpler spatial question first to prime the model).",
            "spatial_reasoning_analysis": "Authors' analysis: models struggle more on high-dimensional, irregular sequences; they excel on repetitive/simple patterns; CoT prompting was volatile and sometimes detrimental (dependent on example selection), while Spatial Prefix-Prompting often improved generalization by priming fundamental spatial concepts. No internal attention/representation probing performed.",
            "performance_metrics": "From Table 2 (selected values reported in paper): CALVIN (raw) zero-shot F1 ≈ 0.19, accuracy ≈ 0.26; with SPP F1 ≈ 0.32, accuracy ≈ 0.43. CALVIN-Cleaned zero-shot F1 ≈ 0.24, accuracy ≈ 0.30; with SPP F1 ≈ 0.38, accuracy ≈ 0.43. Overall performance on raw trajectories is described as 'subpar' and unlikely to be sufficient for real robotic trajectory classification.",
            "limitations_or_failure_modes": "Per paper: high irregularity and extraneous movements in raw trajectories confuse the model; CoT can mislead when noisy sub-patterns resemble other motion types; small evaluation subset (30 samples) limits statistical strength; models appear to rely on pre-trained semantic priors (e.g., simple up/down in z for 'lift') so when trajectories don't match these priors they fail.",
            "comparison_to_other_models_or_humans": "ChatGPT-3.5 underperforms ChatGPT-4 on these 3D tasks (ChatGPT-4 achieves substantially higher F1/accuracy in several prompting modes). No human baseline numbers reported for these specific experiments.",
            "uuid": "e3104.2",
            "source_info": {
                "paper_title": "Exploring and Improving the Spatial Reasoning Abilities of Large Language Models",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "ChatGPT-4 (3D Trajectories)",
            "name_full": "ChatGPT-4 (evaluated on 3D CALVIN trajectories)",
            "brief_description": "ChatGPT-4 applied to 3D trajectory labeling (lift/rotate/slide) and evaluated with zero-shot, ICL, CoT, and Spatial Prefix-Prompting; shows improved performance versus ChatGPT-3.5 and benefits notably from Spatial Prefix-Prompting, especially on cleaned trajectories.",
            "citation_title": "Exploring and Improving the Spatial Reasoning Abilities of Large Language Models",
            "mention_or_use": "use",
            "model_name": "ChatGPT-4",
            "model_description": "OpenAI GPT-4 based chat model; used off-the-shelf to label sequences of 3D coordinates via textual prompts.",
            "model_size": null,
            "puzzle_name": "3D trajectory classification (CALVIN & CALVIN-Cleaned)",
            "puzzle_description": "Classification of sequences of 3D end-effector positions into motion classes requiring temporal and spatial reasoning about coordinate changes and overall trajectory morphology.",
            "input_representation": "Textual lists of (x,y,z) coordinates normalized to integer ranges; both raw CALVIN trajectories and human-cleaned subsequences were used.",
            "prompting_method": "Zero-shot, In-context Learning (few-shot), Chain-of-Thought, Spatial Prefix-Prompting (SPP).",
            "spatial_reasoning_analysis": "Paper's analysis: ChatGPT-4 better leverages few-shot examples and benefits more from SPP than CoT in noisy settings; CoT gains are smaller and volatile compared to other domains. The authors hypothesize that SPP helps by invoking simpler pretrained numeric-difference calculations (e.g., computing deltas) that transfer to more complex tasks.",
            "performance_metrics": "Selected reported values from Table 2: CALVIN (raw): zero-shot F1 ≈ 0.19 accuracy ≈ 0.27; SPP F1 ≈ 0.55 accuracy ≈ 0.60. CALVIN-Cleaned: zero-shot F1 ≈ 0.42 accuracy ≈ 0.47; CoT and ICL show mixed results, and SPP achieves F1 ≈ 0.80 accuracy ≈ 0.80 on the cleaned subset (largest reported improvements). The paper notes the highest F1 on raw data was capped at 0.63 in some prompting settings.",
            "limitations_or_failure_modes": "Still struggles on raw noisy trajectories; large improvements on cleaned data suggest sensitivity to noise and the portion of trajectory that corresponds to the labeled action. Chain-of-Thought can be brittle and example-dependent; dataset size is small (30 samples) so results may not generalize.",
            "comparison_to_other_models_or_humans": "Outperforms ChatGPT-3.5 on the same tasks and prompting methods; SPP produced the largest gains among the prompting strategies in these experiments. No direct human performance numbers provided.",
            "uuid": "e3104.3",
            "source_info": {
                "paper_title": "Exploring and Improving the Spatial Reasoning Abilities of Large Language Models",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Llama-2-7B (SpartQA)",
            "name_full": "Llama 2 7B (evaluated on SPARTQA spatial QA benchmark)",
            "brief_description": "Meta's Llama 2 7B evaluated on the SPARTQA textual spatial reasoning benchmark (four subtypes); Spatial Prefix-Prompting improves accuracy over zero-shot and Chain-of-Thought prompting for several question types.",
            "citation_title": "Exploring and Improving the Spatial Reasoning Abilities of Large Language Models",
            "mention_or_use": "use",
            "model_name": "Llama 2 7B",
            "model_description": "Open-source Llama 2 family model with ~7 billion parameters; used here because of faster evaluation time on the 510-instance SPARTQA test set.",
            "model_size": "7B",
            "puzzle_name": "SPARTQA (textual spatial question answering) subtypes: Find Relation (FR), Find Blocks (FB), Choose Object (CO), Yes/No (YN)",
            "puzzle_description": "Textual QA tasks requiring deeper spatial reasoning about relations and attributes of objects described in text (e.g., determining which object is 'above' another, which block meets constraints). Requires understanding of spatial relations and attributes from textual descriptions.",
            "input_representation": "Natural-language textual questions from the SPARTQA dataset (no visual inputs); answers are text labels/choices.",
            "prompting_method": "Zero-shot, Chain-of-Thought prompting, Spatial Prefix-Prompting (SPP).",
            "spatial_reasoning_analysis": "Paper reports that SPP often surpasses CoT and zero-shot on FR and CO subtypes; authors interpret this as SPP priming simple spatial concepts (like direction identification) that transfer to more abstract textual spatial reasoning. No gradient/attention probing was done.",
            "performance_metrics": "From Table 3 (reported): SPP accuracies (per-subtype) — FR: 0.42, FB: 0.44, CO: 0.42, YN: 0.40, Overall: 0.41. Chain-of-Thought and zero-shot rows in the table are lower; overall CoT/zero-shot combined accuracy reported ~0.36 in that table (dataset-level).",
            "limitations_or_failure_modes": "Despite improvements from SPP, absolute accuracies remain moderate (~0.41 overall). The model still fails many spatial reasoning questions, indicating limited deeper spatial understanding from text-only prompts. Heuristic evaluation was used for some SpartQA answers, and human evaluation was used for others, which may affect evaluation fidelity.",
            "comparison_to_other_models_or_humans": "Only Llama-2-7B was evaluated on the full SPARTQA test set in this paper; SPP improved results compared to CoT and zero-shot for this model. No human baselines or non-language-model comparisons provided in this paper.",
            "uuid": "e3104.4",
            "source_info": {
                "paper_title": "Exploring and Improving the Spatial Reasoning Abilities of Large Language Models",
                "publication_date_yy_mm": "2023-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Calvin: A benchmark for languageconditioned policy learning for long-horizon robot manipulation tasks",
            "rating": 2,
            "sanitized_title": "calvin_a_benchmark_for_languageconditioned_policy_learning_for_longhorizon_robot_manipulation_tasks"
        },
        {
            "paper_title": "SPARTQA: A textual question answering benchmark for spatial reasoning",
            "rating": 2,
            "sanitized_title": "spartqa_a_textual_question_answering_benchmark_for_spatial_reasoning"
        },
        {
            "paper_title": "Large language models as general pattern machines",
            "rating": 1,
            "sanitized_title": "large_language_models_as_general_pattern_machines"
        },
        {
            "paper_title": "Chain-ofthought prompting elicits reasoning in large language models",
            "rating": 1,
            "sanitized_title": "chainofthought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "3d-llm: Injecting the 3d world into large language models",
            "rating": 1,
            "sanitized_title": "3dllm_injecting_the_3d_world_into_large_language_models"
        }
    ],
    "cost": 0.01580725,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Exploring and Improving the Spatial Reasoning Abilities of Large Language Models
2 Dec 2023</p>
<p>Manasi Sharma manasis@cs.stanford.edu 
Stanford University</p>
<p>Exploring and Improving the Spatial Reasoning Abilities of Large Language Models
2 Dec 2023636E69B66B5F2E9616592854B09FBAFAarXiv:2312.01054v1[cs.RO]
Large Language Models (LLMs) represent formidable tools for sequence modeling, boasting an innate capacity for general pattern recognition.Nevertheless, their broader spatial reasoning capabilities, especially applied to numerical trajectory data, remain insufficiently explored.In this paper, we investigate the out-of-the-box performance of ChatGPT-3.5,ChatGPT-4 and Llama 2 7B models when confronted with 3D robotic trajectory data from the CALVIN baseline and associated tasks, including 2D directional and shape labeling.Additionally, we introduce a novel prefix-based prompting mechanism, which yields a 33% improvement on the 3D trajectory data and an increase of up to 10% on SpartQA tasks over zero-shot prompting (with gains for other prompting types as well).The experimentation with 3D trajectory data offers an intriguing glimpse into the manner in which LLMs engage with numerical and spatial information, thus laying a solid foundation for the identification of target areas for future enhancements.</p>
<p>Introduction</p>
<p>Large Language Models (LLMs), e.g.&amp; PaLM [4], are massive models trained on diverse corpora with billions of tokens of text.Recent works have established the competence of LLMs in extrapolating more abstract, non-linguistic patterns, thus allowing them to serve as "general pattern machines [15].As such, in addition to the text-based tasks for which they were trained, LLMs successfully demonstrate cross-disciplinary capabilities, such as high-level planning for robotic policies [9,23,1], reward function design [10,8], and math &amp; logic puzzles.</p>
<p>Labeling of various kinds of data [6] falls under the paradigm of general pattern matching, and is of utmost practical use in the prospective organization of unlabeled raw datasets.One such application is in the space of language &amp; robotics; there are a limited number of datasets that supply language annotations for each demonstration (e.g. the trajectory is described by the instruction "pick up the blue cup"), as human labeling is costly.Intrigued by the potential for LLMs in annotating large-scale robotic datasets, we investigate LLM labeling as applied to 2D and 3D robotic trajectory data, i.e. the ability to describe a sequence of n-dimensional points with the type of motion it embodies, such as "lifting".While it is possible to explicitly train models for these capabilities, this work instead focuses on the inherent abilities of LLMs out-of-the-box, which may have downstream implications for broader numerical and spatial queries, e.g.trend analysis or time-series data.</p>
<p>Additionally, considering that LLMs appear to struggle with spatial reasoning abilities [2,23,5] (as defined by an understanding of shapes and relationships between different objects and spaces), we also gauge whether there are unique factors about this kind of numerical &amp; spatial data that impact the improvements furnished by prompting techniques like In-context Learning (ICL) and Figure 1: Illustrations of the Various Spatial Tasks: 2D Path Labeling of both directions (e.g."up", "left", etc.) and shapes, 3D Trajectory Labeling of "lifting", "rotating" and "sliding" motions (as well as the cleaned versions), and relationship identification between blocks in an imagined setup.</p>
<p>Chain-of-Thought (CoT) prompting.Subsequently, we propose a strategy to pre-fix a prompt with a more general example to achieve greater performance gains for this type of application.</p>
<p>To summarize, we are overall interested in empirically answering the following research questions: RQ1 Can LLMs be used to identify simple spatial patterns (e.g.circles or straightforward directions)?RQ2 Can LLMs be used to identify and label more complex spatial patterns (such as more irregular 3D trajectories)?As such, does the irregularity of the pattern make it difficult to CoT-type reasoningbased prompting?RQ3 Is there any knowledge transfer that can happen from simpler spatial tasks to more complex ones that can impact overall performance?</p>
<p>Related works</p>
<p>LLMs and Spatial Pattern Matching.Previous work has shown that LLMs can improve and complete low-level robotic action sequences or repetitive progressions like a sinusoid [15].However, labeling of a sequence in its entirety has not been addressed, which requires long-form context retention, semantic comprehension to link a sequence to its textual annotation, and generalization to non-repetitive, complex patterns.Some works show that LLMs acceptably label one-dimensional time-series data [25,11], but assess much shorter sequences, exclude higher dimensional analysis, or use additional token embedding models.Furthermore, on the whole, prevailing examinations of LLMs' spatial reasoning abilities [2,23,5] have revealed a considerably poor performance.We extend these works by tackling the inherent performance of LLMs on the underexplored subproblem of higher-dimensional trajectory identification.</p>
<p>LLMs &amp; 3D Robotics.LLMs have been applied across a number of areas in robotics, most recently in originating high level step-by-step plans from task descriptions [1, 9] and robot policy code publication [10,11].However, our work falls into the bucket of whether LLMs can directly understand control (e.g., at the level of trajectories) in a zero-shot manner, which remains an open problem.There are also works in the embodied robotics domain where LLMs are used to reason about a 3D point-cloud scene [7,19,24], but these papers either use a vision model (or joint vision-language model) to integrate visual embeddings or append a finite number of 3D object positions acquired using a detection model to the prompt.Our approach is distinguished by focusing on understanding continuous sequences of 3D points on the prompt-side.</p>
<p>LLMs &amp; Prompting Several prompting approaches have been shown to improve results, such as Incontext Learning [3], which supplies few-shot examples that guide the model, and Chain-of-Thought [21], which harnesses the ability of LLMs to adhere to a guided thought process for problem solving.The presence of symbols, patterns and texts are crucial to the effectiveness of CoT and ICL [12], but whether spatial trends follow such an archetype has yet to be explicitly examined.</p>
<p>3 Language Models as Trajectory Labelers 3.1 2D Path Labeling</p>
<p>Direction Labeling</p>
<p>As discussed in [15] the ability of an LLM to pattern match is driven by in-context learning on the provided numerical tokens, which can be formulated as the problem of using the context s 1:k = (s 1 , ..., s k ), where each s i is a symbol and using it to autoregressively predict s k+1 by using the factorized conditional probability p(s 1:k ) = Π n i=1 p(s i |s 1 , ..., s i−1 ).Usual in-context learning examples segment the prompt into continuations of multiple examples, each a variable length sequence:
x 1:k = (x 1 , ..., x k ) where each x i = (s i 1 , s i 2 , ..., s i m i ).
We adapt this paradigm for directional labeling by having x 1 state the model's expertise in spatial analysis and prompt it to generate direction labels for a newly provided sequence given the examples.Then each x i from i = 2 onwards is an example, an input-output pair D i ; L i where D i is the sequence of symbol aggregates
(d i 1 , d i 2 , ...d i j ) of length j, with each d i k further being separated out into the symbols (d i kx , d i ky ), representing a coordinate in 2D Cartesian space. L i is similarly a sequence of words (l i 1 , l i 2 , ...l i j−1 ) of length j − 1,
where each l i k is a word representing the direction that describes the movement from d i k to d i k+1 and is one of [left, right, up, down].There are thus j points and j − 1 segment labels (see Fig. 1).</p>
<p>Shape Identification</p>
<p>Using a similar prompt framework to the one described above, x 1 states the model's expertise in spatial analysis and prompts it to identify the overall shape of the movement represented by the list of 2D coordinates; for example, "moves along a path that mirrors the pattern of a checkmark" or "moves in a circular path".Since the dataset size is fairly limited, no in-context learning is applied and the model is evaluated zero-shot by specifying x 2 as the input sequence of (x, y) coordinates (d i 1 , d i 2 , ...d i j ) (see Fig. 1).</p>
<p>3D Trajectory Labeling</p>
<p>Zero-shot Prompting</p>
<p>To provide a baseline for the various prompting mechanisms probed, we initially implement zeroshot prompting, in which no exemplars are imparted to the model.Therefore, analogous to 2D experiments, x 1 states the model's expertise in spatial analysis and prompts it to classify the type of motion exemplified by the sequence into one of N categories, but there are no further sequences (see Fig. 2).For our set of experiments, we designate three classes that correspond to meaningfully and spatially disparate motions -lifting, rotating and sliding.</p>
<p>In-context Learning</p>
<p>In-context Learning (ICL) [1] supplies a few samples that the model can generalize from.x 1 declares that the model that it is an expert in 3D trajectory labeling and prompts the model to classify the type of motion exemplified by the sequence into one of N categories.Then each x i from i = 2 onwards is an input-output pair D i ; l i where D i is the sequence of symbol aggregates one representing a coordinate in 3D Cartesian space (d i kx , d i ky ), d i kz ).l i is a single word describing the motion and belongs to one of the N classes (see Fig. 2).
(d i 1 , d i 2 , ...d i j ), with each</p>
<p>Chain-of-Thought Prompting</p>
<p>Chain-of-Thought Prompting (CoT) [21], in which the few-shot examples are augmented by a stepby-step reasoning, has superseded In-context Learning on an array of textual and mathematical reasoning tasks.We extend it to our task as follows.The starting guideline for x 1 is the same as in-context learning, with the declaration that the model is an expert in 3D trajectory labeling and a prompt for the model to classify the type of motion exemplified by the sequence into one of N categories.However in CoT, successive pairs x 2 , x 3 , ..., x 2t , x 2t+1 for some t, represent the few-shot examples.The even x 2t is the representative sequence of 3D coordinates and the odd x 2t+1 is its associated answer, which is the motion-type label and accompanying reasoning steps (such as the fact that back-and-forth changes in the x and y coordinates can hint at a rotating motion, see Fig. 2).</p>
<p>Spatial Prefix-Prompting</p>
<p>Anticipating the challenge with generalizing from irregular examples and bolstered by the model's performance on simpler 2D data, we also propose a new method of prompting called "Spatial Prefix-Prompting" (SPP).The method draws from a prior selection of fixed questions that instigate the model to first ponder a tangentially related spatial problem (e.g.identifying the single direction an object is moving in or checking whether a point is in the center of a circle), and then use the "knowledge gained" to answer an adjacent question, such as labeling a new, more complex 3D trajectory (see Fig. 2).This technique does not necessitate the more intensive CoT-style curation of step-by-step examples, and we hypothesize that it may build upon the more fundamental spatial concepts a model is trained on to generalize better than few-shot learning (wherein the selected examples may not be representative of all the trajectories).</p>
<p>Experiments</p>
<p>Implementation Details</p>
<p>2D Labeling and Description</p>
<p>There aren't many datasets for elementary 2D shapes and directions, and given the ease of generating such data, we decided to autogenerate the datasets.For the direction labeling task, a dataset of size 30 is generated with 10 short-horizon sequences of 2D coordinates (of length 6-8 segments), 10 long-horizon long sequences (length 35 -40), and 10 short floating-point sequences using Python's NumPy package, with each segment's size and the directions randomly chosen based on a fixed seed.We experiment with both 1) scaling the values to integers between [0, 100] (to use fewer tokens to represent a single number) 2) scaling the values to double-digit fractions between [0, 100] (to test whether the higher token representation translates to higher precision).Only Zero-shot and In-context Learning are applied for Shape and Direction Labeling respectively.For the shape identification, we use some previously collected hand-gesture data in which human demonstrators sign a variety of shapes, including circles and check marks, and 2D positions of the finger are recorded; the dataset tests the model on the inherent noise from human demonstrations.A subset of the dataset is "cleaned" for use by having an expert to remove extraneous points that don't belong to the shape, and it is normalized to the range [0, 100] (both integer and floating point).The size of the dataset is 13.</p>
<p>3D Trajectory Labeling</p>
<p>We use the CALVIN benchmark [13], a dataset for learning long-horizon language-conditioned tasks for robotics.It includes 3D end-effector positions (can be extracted from the low-dimensional state vector) and associated language descriptions of the action the robot is attempting to complete.Due to time and resource constraints from the human evaluations, we select only a small subset of the CALVIN dataset (30 samples) and three disparate subtasks ("rotate", "lift", "slide").The trajectories are often complex and may not intuitively always resemble the action being completed, with many extraneous movements (see Fig. 1).Therefore, we also create a version of this dataset called "CALVIN-Cleaned" in which a human annotator extracts the parts of the trajectory that match with the specific action (e.g.only the lifting portion, see Fig. 1).Note, the CALVIN-Cleaned dataset retains the original "rotate" trajectories, as the task description is linked to the back-and-forth changes in the entirety of the motion, not any particular subsection.Finally, the dataset is normalized to the range [0, 300] ∈ Z to increase the granularity of the trajectory but optimize for token conservation due to the long-range of many CALVIN trajectories (upwards of 50 -100 points).</p>
<p>Spatial Relationship Identification</p>
<p>In order to demonstrate the efficacy of the Spatial Prefix-Prompting mechanism beyond just 3D trajectory classification, we also run experiments with Llama-2-7B on the entire test set of the SpartQA dataset [16] (of size 510 instances), a textual QA benchmark for deeper spatial reasoning questions of four types: find relation (FR), find blocks (FB), choose object (CO) (see Fig. 1).</p>
<p>Metrics and Models</p>
<p>As all of the tasks are classification / labeling tasks, we opt for traditional classification metrics, i.e. accuracy and F1-score, to reflect the balanced metrics of precision and recall.For the direction labeling, we also analyze the average number of direction misclassifications / errors per sequence, normalized by sequence length, calling this metric Err # -this is effectively how many of the directions in a single sequence are erroneously predicted.Human evaluators evaluate the ChatGPT responses for correctness while heuristics (when the answer appears in the first or last line) are used for SpartQA.We use three models for our experiments: the first two are ChatGPT 3.5 and 4 [17] and the third is Llama-7B [20] for SpartQA, chosen due to the quicker evaluation time for the size of the test dataset.We selected these models for their common use by the general public and quicker outputs.</p>
<p>Results</p>
<p>Our main results across the three tasks are given in Table 1, Table 2 and Table 3, and the main findings are as follows.</p>
<p>LLMs perform acceptable few-shot identification of directions As seen in Table 1, ChatGPT-3.5 and 4 succeed in achieving at least 50% classification rates, with better performance (Err.# &lt;25) on shorter trajectories (len&gt;5) and a neutral effect from the integer vs. floating point.We also see that parameter size and extensive training data likely play a huge role, with ChatGPT-4 hitting perfect classification for short trajectories and impressive performance (60%) for long trajectories (len&gt;35).</p>
<p>The models struggle with Shape Labeling however, unsurprisingly from the lack of data in zero-shot evaluation.</p>
<p>LLMs demonstrate poorer capabilities on more complex 3D trajectories We find that, as seen in Table 2, LLMs achieve subpar performance when compared with the 2D scenario, especially on the raw data from the CALVIN benchmark, with the highest F1-score capped at 63%.In their current form, it is improbable that such LLMs can be used for robotic trajectory classification.A possible cause for the disparity between the CALVIN and CALVIN-Cleaned datasets could be the higher degree of irregularity in the CALVIN dataset, since as demonstrated in [15], such models excel in mimicking more repetitive patterns (e.g.sinusoidal graphs).Another factor could be that LLMs connect spatial patterns to pre-trained semantic concepts in the CALVIN-Cleaned datasetfor example, the cleaned "lifting" trajectory illustrates only a downward and upward motion in the z-dimension, matching a fundamental understanding perhaps baked in from pretraining, whereas the extraneous datapoints might muddle such comprehension.</p>
<p>CoT reveals a reduction in spatial reasoning performance Table 2 and Fig. 3 conveys the volatility in the performance of CoT, revealing either losses or marginal performance gains (mostly bounded at 11%) compared to In-context Learning (ICL), and even the gains are much lower than other tasks [21].A potential reason for the diminishing returns in this application is that the CoT reasoning steps are fairly dependent on the examples chosen.We have qualitatively seen examples in which the model understands a single example in the context of its action (e.g.since an object is performing the action "lift", its z-coordinate decreases), but then witnesses a slight decrease in  the z-coordinate of a "slide" trajectory due to noisiness and concludes that it belongs to the "lift" category.</p>
<p>LLMs seem to enable knowledge transfer from simple to more complex tasks From Tables 2  and 3, we observe that Spatial Prefix-Prompting (SPP) often surpasses CoT and ICL, particularly on the CALVIN-Cleaned dataset and the "Find Relationship" (FR) and "Choose Object" (CO) questions in the SpartQA dataset [16].This outcome hints that SPP might perhaps be better suited to scenarios in which the labels themselves hold morphological meaning, permitting the model to expand upon its pretrained knowledgebase (e.g. in the FR and CO questions, the labels refer to directional relationships like "above" or qualitative adjectives "medium black square").Furthermore, it has previously been corroborated that, taking a Bayesian lens, ICL operates by helping the model to locate latent concepts that it learned during pretraining [22,14,18], i.e. if terms in a particular instance are exposed many times in the pretraining data, the model is likely to know better about the distribution of the inputs.It can be that SPP operates similarly, with a simple spatial question (e.g.direction identification) prodding the model to draw upon a more fundamental mechanism that it has been trained on (e.g.calculating numerical differences between coordinates to designate directions), in order to solve more complex questions that may use an analogous thought-process.</p>
<p>Conclusion</p>
<p>We examined the performance of LLMs including ChatGPT 3.5, 4 and Llama 2 7B on a variety of spatial tasks, namely 2D direction and path labeling, 3D trajectory labeling and abstract relationship identification.We show that the selected models exhibit acceptable performance on 2D direction labeling but flounder to a greater deal on 3D trajectory labeling.We speculate on possible causes, settling on the likelihood that the irregularity of the trajectories makes classification more onerous.We also hypothesize that the brittleness of Chain-of-Thought prompting's reliance on specific examples influences its diminished yield in noisy scenarios.Finally, we propose a technique called Spatial Prefix-Prompting that first inquires a simple, related question in order to better answer more complex spatial queries.Our work could have implications in a multitude of other domains than just higherdimensional numerical data, such as multi-variable financial trend forecasting or aggregate health data analysis.Future work includes evaluation on a larger robotic dataset, extension to other spatial tasks (e.g.segmenting trajectories), and assessment of other LLMs like PaLM 4. Overall, we establish that the domain of spatial reasoning, especially with regards to numerical data, is an underexplored realm ripe for more research.</p>
<p>Figure 2 :
2
Figure 2: Different Types of Prompting Mechanisms -Zero-shot, In-context Learning, Chain-of-Thought and Spatial Prefix-Prompting.In Spatial Pre-Prompt, a tangential question is first asked, to which the model provides a response, following which the primary query is inquired.</p>
<p>Figure 3 :
3
Figure 3: Accuracy Improvements (%) for In-context Learning, Chain-of-Thought and Spatial Prefix-Prompting on both the CALVIN and CALVIN-Cleaned datasets, for ChatGPT-3.5 and ChatGPT-4.As we can see, overall the accuracy gains for ChatGPT-4 are higher.</p>
<p>Table 1 :
1
2D Direction and Shape Labeling performance on short, long and floating-point sequences
Direction LabelingShape LabelingInteger (short)Float (short)Integer (long)IntegerFloatLLMAcc. (↑) Err. # (↓) Acc. (↑) Err. # (↓) Acc. (↑) Err. # (↓) Acc. (↑) Acc. (↑)ChatGPT-3.5 0.500.150.500.250.000.710.310.23ChatGPT-41.000.001.000.000.600.130.460.46Table 2: 3D Trajectory Labeling performance for ChatGPT-3.5 &amp; 4 on CALVIN &amp; CALVIN-CleanedChatGPT-3.5ChatGPT-4DatasetMethodF1 (↑) Acc. (↑) F1 (↑) Acc. (↑)Zero-shot 0.190.260.190.27CALVINIn-context 0.17 CoT 0.280.33 0.360.63 0.330.63 0.37SPP0.320.430.550.60Zero-shot 0.240.300.420.47CALVIN-CleanedIn-context 0.16 CoT 0.140.34 0.260.62 0.730.67 0.73SPP0.380.430.800.80</p>
<p>Table 3 :
3
Llama 2 7B performance on the SpartQA Test Dataset, split by subtypes FR, FB, CO, YN
FRFBCOYNOverallLLM Acc. Llama 2 7B Method Zero-shot 0.14 CoT 0.210.40 0.470.24 0.160.39 0.480.32 0.36SPP0.420.440.420.400.41
(↑) Acc.(↑) Acc.(↑) Acc.(↑) Acc.(↑)</p>
<p>. M Ahn, A Brohan, N Brown, Y Chebotar, O Cortes, B David, C Finn, C Fu, K Gopalakrishnan, K Hausman, A Herzog, D Ho, J Hsu, J Ibarz, B Ichter, A Irpan, E Jang, R J Ruano, K Jeffrey, S Jesmonth, N J Joshi, R Julian, D Kalashnikov, Y Kuang, K.-H Lee, S Levine, Y Lu, L Luu, C Parada, P Pastor, J Quiambao, K Rao, J Rettinghouse, D Reyes, P Sermanet, N Sievers, C Tan, A Toshev, V Vanhoucke, F Xia, T Xiao, P Xu, S Xu, M Yan, A Zeng, 2022Do as i can, not as i say: Grounding language in robotic affordances</p>
<p>A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. Y Bang, S Cahyawijaya, N Lee, W Dai, D Su, B Wilie, H Lovenia, Z Ji, T Yu, W Chung, Q V Do, Y Xu, P Fung, 2023</p>
<p>Language models are few-shot learners. T B Brown, B Mann, N Ryder, M Subbiah, J Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, S Agarwal, A Herbert-Voss, G Krueger, T Henighan, R Child, A Ramesh, D M Ziegler, J Wu, C Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess, J Clark, C Berner, S Mccandlish, A Radford, I Sutskever, D Amodei, 2020</p>
<p>Palm: Scaling language modeling with pathways. A Chowdhery, S Narang, J Devlin, M Bosma, G Mishra, A Roberts, P Barham, H W Chung, C Sutton, S Gehrmann, P Schuh, K Shi, S Tsvyashchenko, J Maynez, A Rao, P Barnes, Y Tay, N Shazeer, V Prabhakaran, E Reif, N Du, B Hutchinson, R Pope, J Bradbury, J Austin, M Isard, G Gur-Ari, P Yin, T Duke, A Levskaya, S Ghemawat, S Dev, H Michalewski, X Garcia, V Misra, K Robinson, L Fedus, D Zhou, D Ippolito, D Luan, H Lim, B Zoph, A Spiridonov, R Sepassi, D Dohan, S Agrawal, M Omernick, ; R Child, O Polozov, K Lee, Z Zhou, X Wang, B Saeta, M Diaz, O Firat, M Catasta, J Wei, K Meier-Hellstern, D Eck, J Dean, S Petrov, N Fiedel, M. Dai, T. S. Pillai, M. Pellat, A. Lewkowycz, E. Moreira,2022</p>
<p>Dialectical language model evaluation: An initial appraisal of the commonsense spatial reasoning abilities of llms. A G Cohn, J Hernandez-Orallo, 2023</p>
<p>Annollm: Making large language models to be better crowdsourced annotators. X He, Z Lin, Y Gong, A.-L Jin, H Zhang, C Lin, J Jiao, S M Yiu, N Duan, W Chen, 2023</p>
<p>Y Hong, H Zhen, P Chen, S Zheng, Y Du, Z Chen, C Gan, 3d-llm: Injecting the 3d world into large language models. 2023</p>
<p>Language instructed reinforcement learning for human-ai coordination. H Hu, D Sadigh, 2023</p>
<p>Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. W Huang, P Abbeel, D Pathak, I Mordatch, 2022</p>
<p>Large language models are few-shot health learners. M Kwon, S M Xie, K Bullard, D Sadigh, ; X Liu, D Mcduff, G Kovacs, I Galatzer-Levy, J Sunshine, J Zhan, M.-Z Poh, S Liao, P D Achille, S Patel, 2023. 2023Reward design with language models</p>
<p>Text and patterns: For effective chain of thought, it takes two to tango. A Madaan, A Yazdanbakhsh, 2022</p>
<p>Calvin: A benchmark for languageconditioned policy learning for long-horizon robot manipulation tasks. O Mees, L Hermann, E Rosete-Beas, W Burgard, 2022</p>
<p>Rethinking the role of demonstrations: What makes in-context learning work?. S Min, X Lyu, A Holtzman, M Artetxe, M Lewis, H Hajishirzi, L Zettlemoyer, 2022</p>
<p>Large language models as general pattern machines. S Mirchandani, F Xia, P Florence, B Ichter, D Driess, M G Arenas, K Rao, D Sadigh, A Zeng, 2023</p>
<p>SPARTQA: A textual question answering benchmark for spatial reasoning. R Mirzaee, H Faghihi, Q Ning, P Kordjamshidi, 10.18653/v1/2021.naacl-main.364Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesAssociation for Computational LinguisticsJune 2021</p>
<p>. OpenAI. Gpt-4 technical report. 2023</p>
<p>Impact of pretraining term frequencies on fewshot numerical reasoning. Y Razeghi, R L Logan, I V , M Gardner, S Singh, 10.18653/v1/2022.findings-emnlp.59Findings of the Association for Computational Linguistics: EMNLP 2022. Abu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDec. 2022</p>
<p>A Takmaz, E Fedele, R W Sumner, M Pollefeys, F Tombari, F Engelmann, Openmask3d: Open-vocabulary 3d instance segmentation. 2023</p>
<p>. H Touvron, L Martin, K Stone, P Albert, A Almahairi, Y Babaei, N Bashlykov, S Batra, P Bhargava, S Bhosale, D Bikel, L Blecher, C C Ferrer, M Chen, G Cucurull, D Esiobu, J Fernandes, J Fu, W Fu, B Fuller, C Gao, V Goswami, N Goyal, A Hartshorn, S Hosseini, R Hou, H Inan, M Kardas, V Kerkez, M Khabsa, I Kloumann, A Korenev, P S Koura, M.-A Lachaux, T Lavril, J Lee, D Liskovich, Y Lu, Y Mao, X Martinet, T Mihaylov, P Mishra, I Molybog, Y Nie, A Poulton, J Reizenstein, R Rungta, K Saladi, A Schelten, R Silva, E M Smith, R Subramanian, X E Tan, B Tang, R Taylor, A Williams, J X Kuan, P Xu, Z Yan, I Zarov, Y Zhang, A Fan, M Kambadur, S Narang, A Rodriguez, R Stojnic, S Edunov, T Scialom, 2023Llama 2: Open foundation and fine-tuned chat models</p>
<p>Chain-ofthought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, B Ichter, F Xia, E Chi, Q Le, D Zhou, 2023</p>
<p>An explanation of in-context learning as implicit bayesian inference. S M Xie, A Raghunathan, P Liang, T Ma, 2022</p>
<p>Y Xie, C Yu, T Zhu, J Bai, Z Gong, H Soh, Translating natural language to planning goals with large-language models. 2023</p>
<p>Pointllm: Empowering large language models to understand point clouds. R Xu, X Wang, T Wang, Y Chen, J Pang, D Lin1, 2023</p>
<p>Promptcast: A new prompt-based learning paradigm for time series forecasting. H Xue, F D Salim, 2023</p>            </div>
        </div>

    </div>
</body>
</html>