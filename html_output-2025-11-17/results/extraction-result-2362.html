<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2362 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2362</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2362</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-fd831cce62827a0abea5e4eb6507b501eac1cb44</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/fd831cce62827a0abea5e4eb6507b501eac1cb44" target="_blank">Meta-QSAR: a large-scale application of meta-learning to drug design and discovery</a></p>
                <p><strong>Paper Venue:</strong> Machine-mediated learning</p>
                <p><strong>Paper TL;DR:</strong> It is concluded that meta-learning outperforms base-learning methods for QSAR learning, and as this investigation is one of the most extensive ever comparisons of base and meta- learning methods ever made, it provides evidence for the general effectiveness of meta- Learning over base- learning.</p>
                <p><strong>Paper Abstract:</strong> We investigate the learning of quantitative structure activity relationships (QSARs) as a case-study of meta-learning. This application area is of the highest societal importance, as it is a key step in the development of new medicines. The standard QSAR learning problem is: given a target (usually a protein) and a set of chemical compounds (small molecules) with associated bioactivities (e.g. inhibition of the target), learn a predictive mapping from molecular representation to activity. Although almost every type of machine learning method has been applied to QSAR learning there is no agreed single best way of learning QSARs, and therefore the problem area is well-suited to meta-learning. We first carried out the most comprehensive ever comparison of machine learning methods for QSAR learning: 18 regression methods, 3 molecular representations, applied to more than 2700 QSAR problems. (These results have been made publicly available on OpenML and represent a valuable resource for testing novel meta-learning methods.) We then investigated the utility of algorithm selection for QSAR problems. We found that this meta-learning approach outperformed the best individual QSAR learning method (random forests using a molecular fingerprint representation) by up to 13%, on average. We conclude that meta-learning outperforms base-learning methods for QSAR learning, and as this investigation is one of the most extensive ever comparisons of base and meta-learning methods ever made, it provides evidence for the general effectiveness of meta-learning over base-learning.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2362.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2362.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Meta-learning (Algorithm selection)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Meta-learning via algorithm selection (Rice's framework)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A meta-learning approach that learns mappings from dataset- and target-level meta-features to the empirical performance of candidate QSAR learning workflows, used to select or rank the best algorithm+representation for a new QSAR dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Drug discovery / QSAR learning</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Given many QSAR datasets (one per protein target) described by dataset meta-features and target (protein) properties, predict which learning workflow (molecular representation + regression algorithm) will yield the best predictive performance (lowest RMSE) on a new dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Abundant in aggregate: authors used ChEMBL to extract 2,764 QSAR targets and generated 8,292 dataset-representations (3 representations per target); however, per-target datasets vary widely in size (10 to ~6,000 compounds), so some targets have limited labeled data. Data are labeled (bioactivity values) and publicly accessible (ChEMBL/OpenML), with quality curated but per-target sparsity a limitation.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular data: molecular descriptors (continuous, up to 1,447 dims), fingerprint bit vectors (1024 binary features), plus per-dataset aggregated statistics and protein-sequence-derived descriptors (hundreds of features). High-dimensional and mixed-type (continuous and binary), with some missing values in molecular descriptors.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High heterogeneity and nonlinearity: per-target sample sizes vary widely, feature dimensionality can be large (up to 1447 descriptors), biochemical mechanisms vary across targets creating varied signal-to-noise; search space includes 52 candidate workflows (3 representations × 17/18 algorithms) and many hyperparameter choices (not exhaustively tuned).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature application domain: QSAR and chemoinformatics are long-established with many prior methods; however there is no single agreed best predictor for all targets, and large public datasets (ChEMBL) enable large-scale meta-analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — the study focuses on predictive performance (ranking/selecting algorithms) rather than extracting mechanistic causal models; interpretability is useful but not emphasized as a primary requirement.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Meta-learning (classification and ranking)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Two meta-learning formulations: (1) classification to predict the single best workflow (algorithm+representation) for a target using a Random Forest meta-learner (500 trees) trained on meta-features; (2) ranking prediction implemented via k-NN (various k values) over past datasets and via multi-target (multivariate) Random Forest regression (500 trees) to predict RMSEs for each candidate workflow and derive a ranking. Meta-features include dataset statistics (simple, information-theoretic), landmarkers, aggregated fingerprint summaries, and >450 protein target descriptors.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised meta-learning (algorithm selection) / learning-to-rank</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate and directly applicable: meta-features and prior empirical evaluations across thousands of targets enable supervised learning to predict algorithm suitability; constrained by per-target sample-size variability and class imbalance in classification of best workflows; requires a repository of prior algorithm evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Aggregate baseline results: random forest was the single best base learner in 1,162 of 2,764 targets; FCFP4 fingerprint representations produced best models in 1,535 of 2,764 targets; the combined strategy rforest.fpFCFP4 was best for 675 targets and rforest.allmolprop.miss for 396 targets. Statistical test (Friedman) gave p-value << 0.05 indicating significant differences among strategies. The paper reports that meta-learning 'significantly outperformed' the best individual QSAR method but does not provide a single numerical improvement (e.g., delta RMSE) in the provided text.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Meta-learning improved selection over any single baseline: classification and ranking meta-learners were able to predict promising algorithms and thus improve expected QSAR performance; multi-target Random Forest and 50-NN produced the best ranking predictions. Information-theoretic dataset meta-features and protein descriptors were particularly informative for meta-prediction. Exact magnitude of improvement over the best baseline is stated qualitatively only ('significantly outperformed').</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High practical impact: better algorithm selection can yield systematically improved QSAR models across many targets, accelerating virtual screening and reducing experimental cost/time in drug discovery; generalizable to other domains with many similarly-structured datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Directly compared meta-selection approaches (classification via RF, k-NN ranking, multivariate RF ranking) and against base learners: meta-learning outperformed individual base algorithms (best baseline: random forest on FCFP4). Also compared meta-feature groups showing information-theoretic features were most influential. No numeric head-to-head improvement (e.g., average RMSE decrease) is provided in the text.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large-scale, standardized dataset collection (ChEMBL), uniform evaluation across many targets, diverse representations (fingerprints and molecular descriptors), rich meta-features including protein properties, and use of ensemble/meta-learners (Random Forest) that handle heterogeneous feature types and class imbalance.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>When many related datasets of the same problem class (QSAR across protein targets) are available, supervised meta-learning using dataset and target meta-features can reliably predict which algorithm+representation will perform best and thus outperform any single baseline method.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-QSAR: a large-scale application of meta-learning to drug design and discovery', 'publication_date_yy_mm': '2017-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2362.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2362.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Random Forest (rforest)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Random Forest (ensemble of decision trees)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ensemble tree-based regression method used both as a base-level QSAR predictor and as a meta-level learner for algorithm selection and multi-target regression, configured with 500 trees in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Drug discovery / QSAR learning</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict compound bioactivity from molecular representations; additionally used to predict RMSEs of candidate QSAR workflows (meta-level).</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>As above: many datasets from ChEMBL; per-target size varies (10–~6,000 compounds).</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular (continuous descriptors) and binary fingerprint vectors (sparse dense depending on fingerprint).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Handles high-dimensional mixed data and nonlinearity via tree ensembles; computational cost scales with number of trees and feature dimensionality.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Random Forests are an established, commonly used baseline in QSAR and machine learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium: RFs provide variable importance measures but are largely used as predictive black-box models in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Random Forest regression</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Used with n_trees=500, min_split=20, min_bucket=7 for base-level QSAR; also used as multi-target (multivariate) Random Forest with 500 trees to predict performances (RMSEs) of multiple candidate QSAR workflows simultaneously for ranking.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning — ensemble tree methods</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable: performed best among individual methods in the baseline experiments and was used as the meta-learner; robust to mixed feature types and missing-value imputation.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Random forest was the best performer (lowest RMSE) on 1,162 of 2,764 targets; the top strategy rforest.fpFCFP4 was best in 675 targets; rforest.allmolprop.miss best in 396 targets.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Very effective across many targets and representations; consistently top-performing among single algorithms and a strong choice for warm-starting meta-learning; its multivariate variant also produced good ranking predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High: as a reliable baseline algorithm for QSAR, RF can reduce model selection uncertainty and be used within automated pipelines for drug discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared against 17 other regressors (SVMs, GLM-NET, neural nets, ridge, PLSR, etc.); RF dominated frequency-wise across the large target set. Statistical tests reject equivalence among strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Ensemble averaging reduces variance across heterogeneous datasets; robustness to mixed data types and missing-value imputation; effective on binary fingerprint representations.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Random Forests are a consistently strong baseline for QSAR across many targets and representations, but meta-learning that leverages prior performance can still improve selection beyond always choosing RF.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-QSAR: a large-scale application of meta-learning to drug design and discovery', 'publication_date_yy_mm': '2017-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2362.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2362.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Support Vector Machines (SVM)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Support Vector Machines with RBF and Tanimoto kernels (ksvm, ksvmfp)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Kernel-based regression implemented with RBF kernel for continuous descriptors and a Tanimoto kernel variant for fingerprint similarity; used as baseline regression methods for QSAR.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Drug discovery / QSAR learning</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Regression to predict compound bioactivity from molecular features; different kernel choices to match feature types (RBF for continuous, Tanimoto for fingerprints).</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>As above (ChEMBL-derived datasets).</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Continuous molecular descriptors and binary fingerprint vectors; Tanimoto kernel used to handle fingerprint binary similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>SVMs can model nonlinear relationships via kernels but require kernel/hyperparameter choices and can be sensitive to large numbers of features and sample sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Well-established in QSAR literature; kernel choice tailored to chemical fingerprints is common practice.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium: SVMs are black-box regressors; kernel choice provides an implicit similarity measure but limited interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Support Vector Regression (KSVM) with RBF and Tanimoto kernels</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Two SVM variants: ksvm with RBF kernel (nu=0.2, epsilon=0.1) applied to continuous descriptor sets; ksvmfp using a Tanimoto kernel on fpFCFP4 fingerprint representations to capture substructure similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning — kernel methods</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate: RBF-SVM performed well on many targets and Tanimoto-kernel SVM was particularly successful with fingerprint inputs; requires careful kernel selection and hyperparameter setting; scaling to very large datasets may be costly.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>SVM (ksvm) was the second most frequent best performer with 298 targets; ksvmfp.fpFCFP4 strategy was best in 141 targets; ksvm.fpFCFP4 was best in 126 targets (counts from baseline experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Strong performer for many targets, particularly when kernel matches data representation (Tanimoto kernel for fingerprints). Not as dominant as Random Forest overall but competitive.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Moderate to high: appropriate kernelization for molecular fingerprints can yield strong QSAR predictors, especially when data dimensions and sizes are appropriate.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared across 18 regressors; SVM variants were among top-performing methods but behind RF in frequency of best performance.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Using a Tanimoto kernel for fingerprint inputs aligns model similarity measure with chemical substructure similarity; properly configured RBF settings for continuous descriptors.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Kernel choice strongly affects SVM effectiveness in QSAR: Tanimoto kernels work well for fingerprint inputs while RBF kernels are suitable for continuous descriptors, making SVMs competitive but not universally dominant.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-QSAR: a large-scale application of meta-learning to drug design and discovery', 'publication_date_yy_mm': '2017-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2362.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2362.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neural Networks (nnet, nneth2o)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Feedforward Neural Networks (two implementations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Shallow neural network regressors used as baseline QSAR methods: an MLR-based small network (size=3) and an H2O library implementation with two layers sized relative to input dimensionality.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Drug discovery / QSAR learning</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict continuous bioactivity values from molecular descriptors and fingerprint representations.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Same ChEMBL datasets; per-target sample sizes vary.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>High-dimensional continuous descriptors and binary fingerprints; may require preprocessing and imputation.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Neural nets can model nonlinear relationships but shallow architectures used here are limited in representational capacity; larger architectures may require more data and tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Neural networks are well-established; deep models have grown in use but in this study only small networks were used as baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low — treated as predictive models without explicit mechanistic interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Shallow feedforward neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Two NN variants: 'nnet' (size=3 hidden units) and 'nneth2o' using H2O with two hidden layers sized as fractions of the input dimensionality (layer1 = 0.333 * n_inputs, layer2 = 0.667 * n_inputs). No per-dataset hyperparameter optimization was performed (default/sensible settings used).</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning — neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable but limited by shallow architectures and lack of dataset-specific tuning; may underperform on very high-dimensional or small-sample datasets without careful regularization.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Not among the top-most frequent winners in baseline counts reported; exact win counts for NN variants not provided in the main figures in the provided text.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Worked as standard baselines but were outperformed often by Random Forest and SVM variants in frequency-of-best analyses; likely sensitive to hyperparameter tuning which was not exhaustively performed.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Moderate: with more extensive tuning and deeper architectures, neural networks could be more competitive, but in this large-scale baseline they were not top performers.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared with 17 other regression methods; NNs did not dominate the ranking statistics presented.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Model capacity and hyperparameter choice relative to per-target sample sizes; shallow architectures limit representational power but reduce overfitting on small datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Shallow neural networks with default/sensible settings are viable baselines but generally underperform ensemble tree methods and kernel methods on heterogeneous QSAR datasets without per-dataset tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-QSAR: a large-scale application of meta-learning to drug design and discovery', 'publication_date_yy_mm': '2017-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2362.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2362.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>k-NN ranking</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>k-Nearest Neighbours (for ranking algorithms)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A similarity-based approach that ranks candidate QSAR workflows for a new dataset by averaging ranks or performances over the k most similar prior datasets in meta-feature space.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Drug discovery / meta-learning for QSAR algorithm selection</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Given meta-features for a new QSAR dataset, find the k most similar historical datasets and predict the ranking (expected performance) of candidate algorithms based on their historical performance on those neighbors.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Requires a repository of prior meta-feature vectors and recorded algorithm performances (available from the baseline experiments: 2,764 targets × 52 workflows).</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular meta-features (dozens to hundreds of features) representing dataset statistics and protein descriptors.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Similarity computation in high-dimensional meta-feature space; choice of k affects bias/variance tradeoff; class imbalance and heterogeneous datasets can complicate neighbor selection.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>k-NN based ranking is an established method in meta-learning literature for algorithm recommendation.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low — method is exemplar-based and interpretable in terms of nearest historical datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>k-Nearest Neighbours (ranking via neighbor averaging)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Implemented with multiple k values (1, 5, 10, 50, 100, 500, all neighbors) to predict rankings of candidate workflows by aggregating historical RMSEs among nearest meta-feature neighbors; assessed via Spearman rank correlation with actual rankings.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised instance-based learning / learning-to-rank</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and simple to implement; performance depends on meaningful meta-feature distances and sufficient prior examples; found to be competitive for ranking (50-NN among top performers).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>50-NN and multivariate Random Forest produced the best ranking predictions as measured by Spearman rank correlation (exact correlation values not provided in text).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Effective when a sufficient number of similar prior datasets exist; simpler and less computationally intensive than model-based optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Practical for systems that can store historical algorithm evaluations; scales with number of prior examples.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared versus multivariate Random Forest ranking; 50-NN and multivariate RF were top performers with 50-NN being competitive.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Quality and discriminative power of meta-features, sufficient coverage of prior datasets in meta-feature space, and appropriate choice of k.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Instance-based ranking using k-NN over rich dataset and target meta-features provides a simple yet effective method to predict the relative performance of QSAR workflows when many prior datasets are available.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-QSAR: a large-scale application of meta-learning to drug design and discovery', 'publication_date_yy_mm': '2017-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2362.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2362.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Multivariate Random Forest (mRF)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multivariate Random Forest regression (multi-target RF)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multivariate extension of Random Forest used to predict the RMSEs of many candidate QSAR workflows simultaneously, enabling direct ranking of workflows for new datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Drug discovery / meta-learning for QSAR algorithm selection</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict vector-valued outputs (performances/RMSEs for multiple candidate workflows) from meta-features of a dataset so candidate QSAR workflows can be ranked for that dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Uses the baseline dataset of prior workflows' RMSEs across 2,764 targets (sufficient corpus for supervised multi-target learning).</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Tabular meta-features (dataset statistics, protein descriptors) to predict a vector of RMSEs (one per workflow).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Multi-output regression; covariance among outputs exploited by multivariate RF; 52 outputs (workflows) produce a high-dimensional output space.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Multivariate RF is an established method for multi-target prediction; its multi-output capacity is well-suited to algorithm performance prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low — used to predict performance metrics, not to explain mechanistic origins of activity.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Multivariate Random Forest (multi-target regression)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Implemented with 500 trees (Segal & Xiao, 2011 style) to predict RMSEs for all candidate QSAR workflows simultaneously; predictions used to rank workflows; performance assessed with Spearman rank correlation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning — multi-output ensemble methods</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable given many prior algorithm evaluations; computationally efficient relative to exhaustive testing; handles correlated outputs (workflows) naturally.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Multivariate RF and 50-NN had superior Spearman rank correlations vs alternatives (exact values not provided in text).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Produced the best overall ranking predictions in the experiments reported; effective at modeling relative performances across many workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for automated algorithm recommendation systems (warm-starting AutoML) in domains with many prior runs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to k-NN ranking and single-label classification; multivariate RF outperformed most k-NN variants overall in ranking quality.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Ability to model multiple correlated outputs (performances) and robustness of Random Forests to mixed meta-features and limited per-target samples.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Modeling algorithm performances jointly via multivariate Random Forest yields reliable predicted rankings of candidate workflows and outperforms many simpler neighbor-based ranking strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-QSAR: a large-scale application of meta-learning to drug design and discovery', 'publication_date_yy_mm': '2017-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2362.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2362.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Meta-features (dataset + protein descriptors)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dataset and drug-target (protein) meta-features for algorithm selection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A rich set of meta-features including simple, statistical, information-theoretic dataset descriptors and >450 protein target descriptors (hydrophobicity, sequence features, dipeptide composition) used as inputs to meta-learning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Drug discovery / QSAR meta-learning</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Describe each QSAR dataset (instances of molecules + activities) using measures that are predictive of algorithm performance, enabling supervised learning to select or rank algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Meta-features computed from the primary datasets and from protein sequences available in ChEMBL; full meta-dataset had 2,394 meta-features by 2,764 targets.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular meta-features: simple counts, entropy/skewness/kurtosis, aggregated fingerprint counts (1024 aggregated features), and numerous protein-sequence-derived features (aliphatic index, Boman index, net charge, DC groups etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High-dimensional meta-feature space; some redundancy and correlation among features; required feature selection/importance estimation (mean decrease accuracy used) to understand contributions.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Meta-feature engineering is an established area in meta-learning, but QSAR-specific meta-features (protein descriptors) are a novel and valuable extension.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — meta-features include physically meaningful protein descriptors enabling some interpretability into why certain algorithms may work better for related targets.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Meta-feature engineering (information-theoretic, statistical, target descriptors)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Constructed meta-features including dataset-level statistics (n instances, entropy, mutual information, total correlation), aggregated fingerprint summaries (sum of set bits normalized by instances), and drug-target properties (>450 features such as hydrophobicity variants, isoelectric point, dipeptide composition). These features feed into meta-learners (RF, k-NN, mRF).</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Feature engineering for supervised meta-learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Crucial and highly applicable: meta-features enabled discriminative meta-learners; information-theoretic features were found most informative.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Full meta-dataset comprised 2,394 meta-features × 2,764 targets; feature-group importance analysis showed information-theory group contributed most to meta-classification (exact importance scores not provided).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Meta-features including protein descriptors improved the ability to predict which base learner will perform well, enabling meta-learning to outperform best individual methods.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High: demonstrates that domain-specific meta-features (protein descriptors) can substantially improve algorithm selection in chemoinformatics and similar domains.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared meta-feature groups' importance (information-theory, dataset statistics, aggregated fingerprints, target descriptors); information-theoretic features were most relevant.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large variety and domain-specificity of meta-features, especially inclusion of protein properties and information-theoretic measures; availability of many prior datasets to learn from.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Incorporating richly descriptive dataset and target meta-features, particularly information-theoretic and protein descriptors, is essential for effective meta-learning in QSAR algorithm selection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-QSAR: a large-scale application of meta-learning to drug design and discovery', 'publication_date_yy_mm': '2017-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2362.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2362.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Multi-task learning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-task learning across related protein targets</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach mentioned for exploiting evolutionary relatedness of targets (sharing information across tasks) to improve QSAR prediction, with an extension to incorporate evolutionary distance as input.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Drug discovery / QSAR</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Leverage shared information across related protein targets (multi-task framework) to improve predictive performance when individual target datasets are small or related by evolutionary similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Many related targets exist in ChEMBL and authors note the presence of target groupings (preferred name, hierarchical classes), enabling multi-task approaches; exact multi-task experimental results are not detailed in the provided text.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Multiple related supervised regression tasks (one per target) with tabular molecular descriptors and fingerprints per task.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Multi-task introduces modeling of inter-task relationships (evolutionary distance), increasing model complexity but can improve sample efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Multi-task learning is an established concept in machine learning and has prior use in QSAR contexts; here it is proposed/applied as an extension but not detailed in results shown.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — joint models can aid interpretability of cross-target relationships but main aim is predictive improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Multi-task learning (multi-target / transfer across related tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Authors indicate application of multi-task learning to test exploitation of evolutionary related targets and to test whether incorporating evolutionary distance improves multi-task performance; exact model formulations and results are not provided in the supplied text.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised multi-task / transfer learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable in principle due to many related targets and target groupings in ChEMBL; requires modeling choices to exploit inter-target similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Mentioned as a promising extension but no detailed quantitative results are provided in the text excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Potentially significant for low-data targets by borrowing strength from related tasks; could reduce need for per-target data.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>No direct comparison results shown in the provided text.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of target groupings and evolutionary relationships, and sufficient cross-task coverage in the dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Exploiting evolutionary relatedness via multi-task learning can potentially improve QSAR predictions for related protein targets, especially when individual target datasets are small.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-QSAR: a large-scale application of meta-learning to drug design and discovery', 'publication_date_yy_mm': '2017-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2362.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2362.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Model-based optimization / AutoML (mentioned)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Model-based optimization (Bayesian optimization) and AutoML systems (Auto-WEKA, Auto-sklearn)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Related work: sequential model-based optimization using surrogate models (e.g., Gaussian Processes, Random Forests) and acquisition functions to select algorithms and hyperparameters; Auto-WEKA and Auto-sklearn are example AutoML systems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Automated algorithm/hyperparameter selection for machine learning (relevant to QSAR AutoML)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Search the joint space of algorithms and hyperparameters to find configurations that perform well on a dataset, typically expensively evaluated and accelerated via surrogate modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Requires prior evaluations for warm-starting or can operate from scratch; paper discusses combining meta-learning with model-based optimization to warm-start AutoML.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Algorithm-configuration performance history (tabular); surrogate models map configurations to predicted performance.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High-dimensional configuration search; expensive evaluations motivate surrogate models and acquisition functions.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Well-developed field with established tools (Auto-WEKA, Auto-sklearn) and methods (Bayesian optimization).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low — focus on finding high-performing configurations rather than mechanistic explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Model-based optimization / Bayesian optimization (AutoML frameworks)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Described in related work: build a surrogate model (Gaussian Processes or Random Forests) predicting performance and uncertainty, use acquisition function to tradeoff exploration/exploitation; meta-learning can warm-start by suggesting initial promising configurations based on dataset meta-features.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Automated ML / Bayesian optimization</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Mentioned as computationally expensive but effective; combining meta-learning for warm-starting improves speed and results.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Discussed as state-of-the-art for algorithm+hyperparameter search but computationally expensive; meta-learning can provide beneficial initialization.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for automating model selection and hyperparameter tuning in domains like QSAR; computational cost is a limiting factor.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Described in contrast to simpler algorithm-selection approaches; AutoML benefits from warm-starting via meta-learning according to cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Use of surrogate models for sample-efficient search; effective acquisition functions and warm-start suggestions from meta-learning.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Model-based optimization is powerful for full algorithm+hyperparameter search but is computationally costly; meta-learning can provide warm starts to accelerate convergence.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-QSAR: a large-scale application of meta-learning to drug design and discovery', 'publication_date_yy_mm': '2017-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2362.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2362.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Landmarking & collaborative approaches (mentioned)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Landmarking and collaborative filtering methods for meta-learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Meta-learning techniques from literature: landmarkers use fast/simple algorithms' performance as meta-features; collaborative filtering treats past algorithm evaluations as ratings to recommend algorithms for new datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Meta-learning / algorithm recommendation</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Create meta-features or recommendation signals from quick probes (landmarkers) or from matrix factorization of algorithm-dataset performance histories to suggest promising algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Requires some prior algorithm evaluations across datasets (available in their large baseline), but landmarking can be performed with small sample runs.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Landmarking: small-sample performance vectors; collaborative filtering: matrix of algorithm performances across datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Relatively low computational cost for landmarking; collaborative filtering involves matrix factorization complexity but scales with number of datasets and algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established in the meta-learning literature and referenced as prior art.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low — methods aim for useful recommendations rather than mechanistic insights.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Landmarking; collaborative filtering for algorithm recommendation</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Landmarking: run simple/fast algorithms (landmarkers) on dataset or subsamples and use their performance as discriminative meta-features; collaborative filtering: use past algorithm-dataset performances as a rating matrix and apply matrix factorization or CF models to predict algorithm ratings for new datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Meta-learning / instance-based and collaborative methods</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Mentioned as effective prior techniques; landmarkers are useful as cheap meta-features and collaborative filtering can exploit large performance matrices.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Recognized in literature as helpful; not central to experiments in this paper though landmarking is discussed as a type of meta-feature.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Useful components for building robust meta-learning systems, especially when many prior evaluations exist.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Discussed in related work as alternatives to classification/ranking meta-learners; hybrid approaches (landmarkers + decision trees) have been effective historically.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Speed of landmarkers, coverage and density of historical performance data for collaborative filtering.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Simple, fast probes of dataset behaviour (landmarkers) and collaborative filtering over historical runs are valuable complementary techniques in algorithm selection meta-learning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-QSAR: a large-scale application of meta-learning to drug design and discovery', 'publication_date_yy_mm': '2017-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Auto-WEKA <em>(Rating: 2)</em></li>
                <li>Auto-sklearn <em>(Rating: 2)</em></li>
                <li>Model-based optimization (Hutter et al., 2011) <em>(Rating: 1)</em></li>
                <li>Bayesian Optimization (Brochu et al., 2010) <em>(Rating: 1)</em></li>
                <li>Active testing (Leite et al., 2012) <em>(Rating: 1)</em></li>
                <li>Meta-learning by landmarking (Pfahringer et al., 2000) <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2362",
    "paper_id": "paper-fd831cce62827a0abea5e4eb6507b501eac1cb44",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "Meta-learning (Algorithm selection)",
            "name_full": "Meta-learning via algorithm selection (Rice's framework)",
            "brief_description": "A meta-learning approach that learns mappings from dataset- and target-level meta-features to the empirical performance of candidate QSAR learning workflows, used to select or rank the best algorithm+representation for a new QSAR dataset.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "Drug discovery / QSAR learning",
            "problem_description": "Given many QSAR datasets (one per protein target) described by dataset meta-features and target (protein) properties, predict which learning workflow (molecular representation + regression algorithm) will yield the best predictive performance (lowest RMSE) on a new dataset.",
            "data_availability": "Abundant in aggregate: authors used ChEMBL to extract 2,764 QSAR targets and generated 8,292 dataset-representations (3 representations per target); however, per-target datasets vary widely in size (10 to ~6,000 compounds), so some targets have limited labeled data. Data are labeled (bioactivity values) and publicly accessible (ChEMBL/OpenML), with quality curated but per-target sparsity a limitation.",
            "data_structure": "Structured tabular data: molecular descriptors (continuous, up to 1,447 dims), fingerprint bit vectors (1024 binary features), plus per-dataset aggregated statistics and protein-sequence-derived descriptors (hundreds of features). High-dimensional and mixed-type (continuous and binary), with some missing values in molecular descriptors.",
            "problem_complexity": "High heterogeneity and nonlinearity: per-target sample sizes vary widely, feature dimensionality can be large (up to 1447 descriptors), biochemical mechanisms vary across targets creating varied signal-to-noise; search space includes 52 candidate workflows (3 representations × 17/18 algorithms) and many hyperparameter choices (not exhaustively tuned).",
            "domain_maturity": "Mature application domain: QSAR and chemoinformatics are long-established with many prior methods; however there is no single agreed best predictor for all targets, and large public datasets (ChEMBL) enable large-scale meta-analysis.",
            "mechanistic_understanding_requirements": "Medium — the study focuses on predictive performance (ranking/selecting algorithms) rather than extracting mechanistic causal models; interpretability is useful but not emphasized as a primary requirement.",
            "ai_methodology_name": "Meta-learning (classification and ranking)",
            "ai_methodology_description": "Two meta-learning formulations: (1) classification to predict the single best workflow (algorithm+representation) for a target using a Random Forest meta-learner (500 trees) trained on meta-features; (2) ranking prediction implemented via k-NN (various k values) over past datasets and via multi-target (multivariate) Random Forest regression (500 trees) to predict RMSEs for each candidate workflow and derive a ranking. Meta-features include dataset statistics (simple, information-theoretic), landmarkers, aggregated fingerprint summaries, and &gt;450 protein target descriptors.",
            "ai_methodology_category": "Supervised meta-learning (algorithm selection) / learning-to-rank",
            "applicability": "Appropriate and directly applicable: meta-features and prior empirical evaluations across thousands of targets enable supervised learning to predict algorithm suitability; constrained by per-target sample-size variability and class imbalance in classification of best workflows; requires a repository of prior algorithm evaluations.",
            "effectiveness_quantitative": "Aggregate baseline results: random forest was the single best base learner in 1,162 of 2,764 targets; FCFP4 fingerprint representations produced best models in 1,535 of 2,764 targets; the combined strategy rforest.fpFCFP4 was best for 675 targets and rforest.allmolprop.miss for 396 targets. Statistical test (Friedman) gave p-value &lt;&lt; 0.05 indicating significant differences among strategies. The paper reports that meta-learning 'significantly outperformed' the best individual QSAR method but does not provide a single numerical improvement (e.g., delta RMSE) in the provided text.",
            "effectiveness_qualitative": "Meta-learning improved selection over any single baseline: classification and ranking meta-learners were able to predict promising algorithms and thus improve expected QSAR performance; multi-target Random Forest and 50-NN produced the best ranking predictions. Information-theoretic dataset meta-features and protein descriptors were particularly informative for meta-prediction. Exact magnitude of improvement over the best baseline is stated qualitatively only ('significantly outperformed').",
            "impact_potential": "High practical impact: better algorithm selection can yield systematically improved QSAR models across many targets, accelerating virtual screening and reducing experimental cost/time in drug discovery; generalizable to other domains with many similarly-structured datasets.",
            "comparison_to_alternatives": "Directly compared meta-selection approaches (classification via RF, k-NN ranking, multivariate RF ranking) and against base learners: meta-learning outperformed individual base algorithms (best baseline: random forest on FCFP4). Also compared meta-feature groups showing information-theoretic features were most influential. No numeric head-to-head improvement (e.g., average RMSE decrease) is provided in the text.",
            "success_factors": "Large-scale, standardized dataset collection (ChEMBL), uniform evaluation across many targets, diverse representations (fingerprints and molecular descriptors), rich meta-features including protein properties, and use of ensemble/meta-learners (Random Forest) that handle heterogeneous feature types and class imbalance.",
            "key_insight": "When many related datasets of the same problem class (QSAR across protein targets) are available, supervised meta-learning using dataset and target meta-features can reliably predict which algorithm+representation will perform best and thus outperform any single baseline method.",
            "uuid": "e2362.0",
            "source_info": {
                "paper_title": "Meta-QSAR: a large-scale application of meta-learning to drug design and discovery",
                "publication_date_yy_mm": "2017-09"
            }
        },
        {
            "name_short": "Random Forest (rforest)",
            "name_full": "Random Forest (ensemble of decision trees)",
            "brief_description": "An ensemble tree-based regression method used both as a base-level QSAR predictor and as a meta-level learner for algorithm selection and multi-target regression, configured with 500 trees in experiments.",
            "citation_title": "",
            "mention_or_use": "use",
            "scientific_problem_domain": "Drug discovery / QSAR learning",
            "problem_description": "Predict compound bioactivity from molecular representations; additionally used to predict RMSEs of candidate QSAR workflows (meta-level).",
            "data_availability": "As above: many datasets from ChEMBL; per-target size varies (10–~6,000 compounds).",
            "data_structure": "Structured tabular (continuous descriptors) and binary fingerprint vectors (sparse dense depending on fingerprint).",
            "problem_complexity": "Handles high-dimensional mixed data and nonlinearity via tree ensembles; computational cost scales with number of trees and feature dimensionality.",
            "domain_maturity": "Random Forests are an established, commonly used baseline in QSAR and machine learning.",
            "mechanistic_understanding_requirements": "Low-to-medium: RFs provide variable importance measures but are largely used as predictive black-box models in this study.",
            "ai_methodology_name": "Random Forest regression",
            "ai_methodology_description": "Used with n_trees=500, min_split=20, min_bucket=7 for base-level QSAR; also used as multi-target (multivariate) Random Forest with 500 trees to predict performances (RMSEs) of multiple candidate QSAR workflows simultaneously for ranking.",
            "ai_methodology_category": "Supervised learning — ensemble tree methods",
            "applicability": "Highly applicable: performed best among individual methods in the baseline experiments and was used as the meta-learner; robust to mixed feature types and missing-value imputation.",
            "effectiveness_quantitative": "Random forest was the best performer (lowest RMSE) on 1,162 of 2,764 targets; the top strategy rforest.fpFCFP4 was best in 675 targets; rforest.allmolprop.miss best in 396 targets.",
            "effectiveness_qualitative": "Very effective across many targets and representations; consistently top-performing among single algorithms and a strong choice for warm-starting meta-learning; its multivariate variant also produced good ranking predictions.",
            "impact_potential": "High: as a reliable baseline algorithm for QSAR, RF can reduce model selection uncertainty and be used within automated pipelines for drug discovery.",
            "comparison_to_alternatives": "Compared against 17 other regressors (SVMs, GLM-NET, neural nets, ridge, PLSR, etc.); RF dominated frequency-wise across the large target set. Statistical tests reject equivalence among strategies.",
            "success_factors": "Ensemble averaging reduces variance across heterogeneous datasets; robustness to mixed data types and missing-value imputation; effective on binary fingerprint representations.",
            "key_insight": "Random Forests are a consistently strong baseline for QSAR across many targets and representations, but meta-learning that leverages prior performance can still improve selection beyond always choosing RF.",
            "uuid": "e2362.1",
            "source_info": {
                "paper_title": "Meta-QSAR: a large-scale application of meta-learning to drug design and discovery",
                "publication_date_yy_mm": "2017-09"
            }
        },
        {
            "name_short": "Support Vector Machines (SVM)",
            "name_full": "Support Vector Machines with RBF and Tanimoto kernels (ksvm, ksvmfp)",
            "brief_description": "Kernel-based regression implemented with RBF kernel for continuous descriptors and a Tanimoto kernel variant for fingerprint similarity; used as baseline regression methods for QSAR.",
            "citation_title": "",
            "mention_or_use": "use",
            "scientific_problem_domain": "Drug discovery / QSAR learning",
            "problem_description": "Regression to predict compound bioactivity from molecular features; different kernel choices to match feature types (RBF for continuous, Tanimoto for fingerprints).",
            "data_availability": "As above (ChEMBL-derived datasets).",
            "data_structure": "Continuous molecular descriptors and binary fingerprint vectors; Tanimoto kernel used to handle fingerprint binary similarity.",
            "problem_complexity": "SVMs can model nonlinear relationships via kernels but require kernel/hyperparameter choices and can be sensitive to large numbers of features and sample sizes.",
            "domain_maturity": "Well-established in QSAR literature; kernel choice tailored to chemical fingerprints is common practice.",
            "mechanistic_understanding_requirements": "Low-to-medium: SVMs are black-box regressors; kernel choice provides an implicit similarity measure but limited interpretability.",
            "ai_methodology_name": "Support Vector Regression (KSVM) with RBF and Tanimoto kernels",
            "ai_methodology_description": "Two SVM variants: ksvm with RBF kernel (nu=0.2, epsilon=0.1) applied to continuous descriptor sets; ksvmfp using a Tanimoto kernel on fpFCFP4 fingerprint representations to capture substructure similarity.",
            "ai_methodology_category": "Supervised learning — kernel methods",
            "applicability": "Appropriate: RBF-SVM performed well on many targets and Tanimoto-kernel SVM was particularly successful with fingerprint inputs; requires careful kernel selection and hyperparameter setting; scaling to very large datasets may be costly.",
            "effectiveness_quantitative": "SVM (ksvm) was the second most frequent best performer with 298 targets; ksvmfp.fpFCFP4 strategy was best in 141 targets; ksvm.fpFCFP4 was best in 126 targets (counts from baseline experiments).",
            "effectiveness_qualitative": "Strong performer for many targets, particularly when kernel matches data representation (Tanimoto kernel for fingerprints). Not as dominant as Random Forest overall but competitive.",
            "impact_potential": "Moderate to high: appropriate kernelization for molecular fingerprints can yield strong QSAR predictors, especially when data dimensions and sizes are appropriate.",
            "comparison_to_alternatives": "Compared across 18 regressors; SVM variants were among top-performing methods but behind RF in frequency of best performance.",
            "success_factors": "Using a Tanimoto kernel for fingerprint inputs aligns model similarity measure with chemical substructure similarity; properly configured RBF settings for continuous descriptors.",
            "key_insight": "Kernel choice strongly affects SVM effectiveness in QSAR: Tanimoto kernels work well for fingerprint inputs while RBF kernels are suitable for continuous descriptors, making SVMs competitive but not universally dominant.",
            "uuid": "e2362.2",
            "source_info": {
                "paper_title": "Meta-QSAR: a large-scale application of meta-learning to drug design and discovery",
                "publication_date_yy_mm": "2017-09"
            }
        },
        {
            "name_short": "Neural Networks (nnet, nneth2o)",
            "name_full": "Feedforward Neural Networks (two implementations)",
            "brief_description": "Shallow neural network regressors used as baseline QSAR methods: an MLR-based small network (size=3) and an H2O library implementation with two layers sized relative to input dimensionality.",
            "citation_title": "",
            "mention_or_use": "use",
            "scientific_problem_domain": "Drug discovery / QSAR learning",
            "problem_description": "Predict continuous bioactivity values from molecular descriptors and fingerprint representations.",
            "data_availability": "Same ChEMBL datasets; per-target sample sizes vary.",
            "data_structure": "High-dimensional continuous descriptors and binary fingerprints; may require preprocessing and imputation.",
            "problem_complexity": "Neural nets can model nonlinear relationships but shallow architectures used here are limited in representational capacity; larger architectures may require more data and tuning.",
            "domain_maturity": "Neural networks are well-established; deep models have grown in use but in this study only small networks were used as baselines.",
            "mechanistic_understanding_requirements": "Low — treated as predictive models without explicit mechanistic interpretation.",
            "ai_methodology_name": "Shallow feedforward neural networks",
            "ai_methodology_description": "Two NN variants: 'nnet' (size=3 hidden units) and 'nneth2o' using H2O with two hidden layers sized as fractions of the input dimensionality (layer1 = 0.333 * n_inputs, layer2 = 0.667 * n_inputs). No per-dataset hyperparameter optimization was performed (default/sensible settings used).",
            "ai_methodology_category": "Supervised learning — neural networks",
            "applicability": "Applicable but limited by shallow architectures and lack of dataset-specific tuning; may underperform on very high-dimensional or small-sample datasets without careful regularization.",
            "effectiveness_quantitative": "Not among the top-most frequent winners in baseline counts reported; exact win counts for NN variants not provided in the main figures in the provided text.",
            "effectiveness_qualitative": "Worked as standard baselines but were outperformed often by Random Forest and SVM variants in frequency-of-best analyses; likely sensitive to hyperparameter tuning which was not exhaustively performed.",
            "impact_potential": "Moderate: with more extensive tuning and deeper architectures, neural networks could be more competitive, but in this large-scale baseline they were not top performers.",
            "comparison_to_alternatives": "Compared with 17 other regression methods; NNs did not dominate the ranking statistics presented.",
            "success_factors": "Model capacity and hyperparameter choice relative to per-target sample sizes; shallow architectures limit representational power but reduce overfitting on small datasets.",
            "key_insight": "Shallow neural networks with default/sensible settings are viable baselines but generally underperform ensemble tree methods and kernel methods on heterogeneous QSAR datasets without per-dataset tuning.",
            "uuid": "e2362.3",
            "source_info": {
                "paper_title": "Meta-QSAR: a large-scale application of meta-learning to drug design and discovery",
                "publication_date_yy_mm": "2017-09"
            }
        },
        {
            "name_short": "k-NN ranking",
            "name_full": "k-Nearest Neighbours (for ranking algorithms)",
            "brief_description": "A similarity-based approach that ranks candidate QSAR workflows for a new dataset by averaging ranks or performances over the k most similar prior datasets in meta-feature space.",
            "citation_title": "",
            "mention_or_use": "use",
            "scientific_problem_domain": "Drug discovery / meta-learning for QSAR algorithm selection",
            "problem_description": "Given meta-features for a new QSAR dataset, find the k most similar historical datasets and predict the ranking (expected performance) of candidate algorithms based on their historical performance on those neighbors.",
            "data_availability": "Requires a repository of prior meta-feature vectors and recorded algorithm performances (available from the baseline experiments: 2,764 targets × 52 workflows).",
            "data_structure": "Structured tabular meta-features (dozens to hundreds of features) representing dataset statistics and protein descriptors.",
            "problem_complexity": "Similarity computation in high-dimensional meta-feature space; choice of k affects bias/variance tradeoff; class imbalance and heterogeneous datasets can complicate neighbor selection.",
            "domain_maturity": "k-NN based ranking is an established method in meta-learning literature for algorithm recommendation.",
            "mechanistic_understanding_requirements": "Low — method is exemplar-based and interpretable in terms of nearest historical datasets.",
            "ai_methodology_name": "k-Nearest Neighbours (ranking via neighbor averaging)",
            "ai_methodology_description": "Implemented with multiple k values (1, 5, 10, 50, 100, 500, all neighbors) to predict rankings of candidate workflows by aggregating historical RMSEs among nearest meta-feature neighbors; assessed via Spearman rank correlation with actual rankings.",
            "ai_methodology_category": "Supervised instance-based learning / learning-to-rank",
            "applicability": "Applicable and simple to implement; performance depends on meaningful meta-feature distances and sufficient prior examples; found to be competitive for ranking (50-NN among top performers).",
            "effectiveness_quantitative": "50-NN and multivariate Random Forest produced the best ranking predictions as measured by Spearman rank correlation (exact correlation values not provided in text).",
            "effectiveness_qualitative": "Effective when a sufficient number of similar prior datasets exist; simpler and less computationally intensive than model-based optimization.",
            "impact_potential": "Practical for systems that can store historical algorithm evaluations; scales with number of prior examples.",
            "comparison_to_alternatives": "Compared versus multivariate Random Forest ranking; 50-NN and multivariate RF were top performers with 50-NN being competitive.",
            "success_factors": "Quality and discriminative power of meta-features, sufficient coverage of prior datasets in meta-feature space, and appropriate choice of k.",
            "key_insight": "Instance-based ranking using k-NN over rich dataset and target meta-features provides a simple yet effective method to predict the relative performance of QSAR workflows when many prior datasets are available.",
            "uuid": "e2362.4",
            "source_info": {
                "paper_title": "Meta-QSAR: a large-scale application of meta-learning to drug design and discovery",
                "publication_date_yy_mm": "2017-09"
            }
        },
        {
            "name_short": "Multivariate Random Forest (mRF)",
            "name_full": "Multivariate Random Forest regression (multi-target RF)",
            "brief_description": "A multivariate extension of Random Forest used to predict the RMSEs of many candidate QSAR workflows simultaneously, enabling direct ranking of workflows for new datasets.",
            "citation_title": "",
            "mention_or_use": "use",
            "scientific_problem_domain": "Drug discovery / meta-learning for QSAR algorithm selection",
            "problem_description": "Predict vector-valued outputs (performances/RMSEs for multiple candidate workflows) from meta-features of a dataset so candidate QSAR workflows can be ranked for that dataset.",
            "data_availability": "Uses the baseline dataset of prior workflows' RMSEs across 2,764 targets (sufficient corpus for supervised multi-target learning).",
            "data_structure": "Tabular meta-features (dataset statistics, protein descriptors) to predict a vector of RMSEs (one per workflow).",
            "problem_complexity": "Multi-output regression; covariance among outputs exploited by multivariate RF; 52 outputs (workflows) produce a high-dimensional output space.",
            "domain_maturity": "Multivariate RF is an established method for multi-target prediction; its multi-output capacity is well-suited to algorithm performance prediction.",
            "mechanistic_understanding_requirements": "Low — used to predict performance metrics, not to explain mechanistic origins of activity.",
            "ai_methodology_name": "Multivariate Random Forest (multi-target regression)",
            "ai_methodology_description": "Implemented with 500 trees (Segal & Xiao, 2011 style) to predict RMSEs for all candidate QSAR workflows simultaneously; predictions used to rank workflows; performance assessed with Spearman rank correlation.",
            "ai_methodology_category": "Supervised learning — multi-output ensemble methods",
            "applicability": "Highly applicable given many prior algorithm evaluations; computationally efficient relative to exhaustive testing; handles correlated outputs (workflows) naturally.",
            "effectiveness_quantitative": "Multivariate RF and 50-NN had superior Spearman rank correlations vs alternatives (exact values not provided in text).",
            "effectiveness_qualitative": "Produced the best overall ranking predictions in the experiments reported; effective at modeling relative performances across many workflows.",
            "impact_potential": "High for automated algorithm recommendation systems (warm-starting AutoML) in domains with many prior runs.",
            "comparison_to_alternatives": "Compared to k-NN ranking and single-label classification; multivariate RF outperformed most k-NN variants overall in ranking quality.",
            "success_factors": "Ability to model multiple correlated outputs (performances) and robustness of Random Forests to mixed meta-features and limited per-target samples.",
            "key_insight": "Modeling algorithm performances jointly via multivariate Random Forest yields reliable predicted rankings of candidate workflows and outperforms many simpler neighbor-based ranking strategies.",
            "uuid": "e2362.5",
            "source_info": {
                "paper_title": "Meta-QSAR: a large-scale application of meta-learning to drug design and discovery",
                "publication_date_yy_mm": "2017-09"
            }
        },
        {
            "name_short": "Meta-features (dataset + protein descriptors)",
            "name_full": "Dataset and drug-target (protein) meta-features for algorithm selection",
            "brief_description": "A rich set of meta-features including simple, statistical, information-theoretic dataset descriptors and &gt;450 protein target descriptors (hydrophobicity, sequence features, dipeptide composition) used as inputs to meta-learning.",
            "citation_title": "",
            "mention_or_use": "use",
            "scientific_problem_domain": "Drug discovery / QSAR meta-learning",
            "problem_description": "Describe each QSAR dataset (instances of molecules + activities) using measures that are predictive of algorithm performance, enabling supervised learning to select or rank algorithms.",
            "data_availability": "Meta-features computed from the primary datasets and from protein sequences available in ChEMBL; full meta-dataset had 2,394 meta-features by 2,764 targets.",
            "data_structure": "Structured tabular meta-features: simple counts, entropy/skewness/kurtosis, aggregated fingerprint counts (1024 aggregated features), and numerous protein-sequence-derived features (aliphatic index, Boman index, net charge, DC groups etc.).",
            "problem_complexity": "High-dimensional meta-feature space; some redundancy and correlation among features; required feature selection/importance estimation (mean decrease accuracy used) to understand contributions.",
            "domain_maturity": "Meta-feature engineering is an established area in meta-learning, but QSAR-specific meta-features (protein descriptors) are a novel and valuable extension.",
            "mechanistic_understanding_requirements": "Medium — meta-features include physically meaningful protein descriptors enabling some interpretability into why certain algorithms may work better for related targets.",
            "ai_methodology_name": "Meta-feature engineering (information-theoretic, statistical, target descriptors)",
            "ai_methodology_description": "Constructed meta-features including dataset-level statistics (n instances, entropy, mutual information, total correlation), aggregated fingerprint summaries (sum of set bits normalized by instances), and drug-target properties (&gt;450 features such as hydrophobicity variants, isoelectric point, dipeptide composition). These features feed into meta-learners (RF, k-NN, mRF).",
            "ai_methodology_category": "Feature engineering for supervised meta-learning",
            "applicability": "Crucial and highly applicable: meta-features enabled discriminative meta-learners; information-theoretic features were found most informative.",
            "effectiveness_quantitative": "Full meta-dataset comprised 2,394 meta-features × 2,764 targets; feature-group importance analysis showed information-theory group contributed most to meta-classification (exact importance scores not provided).",
            "effectiveness_qualitative": "Meta-features including protein descriptors improved the ability to predict which base learner will perform well, enabling meta-learning to outperform best individual methods.",
            "impact_potential": "High: demonstrates that domain-specific meta-features (protein descriptors) can substantially improve algorithm selection in chemoinformatics and similar domains.",
            "comparison_to_alternatives": "Compared meta-feature groups' importance (information-theory, dataset statistics, aggregated fingerprints, target descriptors); information-theoretic features were most relevant.",
            "success_factors": "Large variety and domain-specificity of meta-features, especially inclusion of protein properties and information-theoretic measures; availability of many prior datasets to learn from.",
            "key_insight": "Incorporating richly descriptive dataset and target meta-features, particularly information-theoretic and protein descriptors, is essential for effective meta-learning in QSAR algorithm selection.",
            "uuid": "e2362.6",
            "source_info": {
                "paper_title": "Meta-QSAR: a large-scale application of meta-learning to drug design and discovery",
                "publication_date_yy_mm": "2017-09"
            }
        },
        {
            "name_short": "Multi-task learning",
            "name_full": "Multi-task learning across related protein targets",
            "brief_description": "An approach mentioned for exploiting evolutionary relatedness of targets (sharing information across tasks) to improve QSAR prediction, with an extension to incorporate evolutionary distance as input.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Drug discovery / QSAR",
            "problem_description": "Leverage shared information across related protein targets (multi-task framework) to improve predictive performance when individual target datasets are small or related by evolutionary similarity.",
            "data_availability": "Many related targets exist in ChEMBL and authors note the presence of target groupings (preferred name, hierarchical classes), enabling multi-task approaches; exact multi-task experimental results are not detailed in the provided text.",
            "data_structure": "Multiple related supervised regression tasks (one per target) with tabular molecular descriptors and fingerprints per task.",
            "problem_complexity": "Multi-task introduces modeling of inter-task relationships (evolutionary distance), increasing model complexity but can improve sample efficiency.",
            "domain_maturity": "Multi-task learning is an established concept in machine learning and has prior use in QSAR contexts; here it is proposed/applied as an extension but not detailed in results shown.",
            "mechanistic_understanding_requirements": "Medium — joint models can aid interpretability of cross-target relationships but main aim is predictive improvement.",
            "ai_methodology_name": "Multi-task learning (multi-target / transfer across related tasks)",
            "ai_methodology_description": "Authors indicate application of multi-task learning to test exploitation of evolutionary related targets and to test whether incorporating evolutionary distance improves multi-task performance; exact model formulations and results are not provided in the supplied text.",
            "ai_methodology_category": "Supervised multi-task / transfer learning",
            "applicability": "Highly applicable in principle due to many related targets and target groupings in ChEMBL; requires modeling choices to exploit inter-target similarity.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Mentioned as a promising extension but no detailed quantitative results are provided in the text excerpt.",
            "impact_potential": "Potentially significant for low-data targets by borrowing strength from related tasks; could reduce need for per-target data.",
            "comparison_to_alternatives": "No direct comparison results shown in the provided text.",
            "success_factors": "Availability of target groupings and evolutionary relationships, and sufficient cross-task coverage in the dataset.",
            "key_insight": "Exploiting evolutionary relatedness via multi-task learning can potentially improve QSAR predictions for related protein targets, especially when individual target datasets are small.",
            "uuid": "e2362.7",
            "source_info": {
                "paper_title": "Meta-QSAR: a large-scale application of meta-learning to drug design and discovery",
                "publication_date_yy_mm": "2017-09"
            }
        },
        {
            "name_short": "Model-based optimization / AutoML (mentioned)",
            "name_full": "Model-based optimization (Bayesian optimization) and AutoML systems (Auto-WEKA, Auto-sklearn)",
            "brief_description": "Related work: sequential model-based optimization using surrogate models (e.g., Gaussian Processes, Random Forests) and acquisition functions to select algorithms and hyperparameters; Auto-WEKA and Auto-sklearn are example AutoML systems.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Automated algorithm/hyperparameter selection for machine learning (relevant to QSAR AutoML)",
            "problem_description": "Search the joint space of algorithms and hyperparameters to find configurations that perform well on a dataset, typically expensively evaluated and accelerated via surrogate modeling.",
            "data_availability": "Requires prior evaluations for warm-starting or can operate from scratch; paper discusses combining meta-learning with model-based optimization to warm-start AutoML.",
            "data_structure": "Algorithm-configuration performance history (tabular); surrogate models map configurations to predicted performance.",
            "problem_complexity": "High-dimensional configuration search; expensive evaluations motivate surrogate models and acquisition functions.",
            "domain_maturity": "Well-developed field with established tools (Auto-WEKA, Auto-sklearn) and methods (Bayesian optimization).",
            "mechanistic_understanding_requirements": "Low — focus on finding high-performing configurations rather than mechanistic explanations.",
            "ai_methodology_name": "Model-based optimization / Bayesian optimization (AutoML frameworks)",
            "ai_methodology_description": "Described in related work: build a surrogate model (Gaussian Processes or Random Forests) predicting performance and uncertainty, use acquisition function to tradeoff exploration/exploitation; meta-learning can warm-start by suggesting initial promising configurations based on dataset meta-features.",
            "ai_methodology_category": "Automated ML / Bayesian optimization",
            "applicability": "Mentioned as computationally expensive but effective; combining meta-learning for warm-starting improves speed and results.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Discussed as state-of-the-art for algorithm+hyperparameter search but computationally expensive; meta-learning can provide beneficial initialization.",
            "impact_potential": "High for automating model selection and hyperparameter tuning in domains like QSAR; computational cost is a limiting factor.",
            "comparison_to_alternatives": "Described in contrast to simpler algorithm-selection approaches; AutoML benefits from warm-starting via meta-learning according to cited work.",
            "success_factors": "Use of surrogate models for sample-efficient search; effective acquisition functions and warm-start suggestions from meta-learning.",
            "key_insight": "Model-based optimization is powerful for full algorithm+hyperparameter search but is computationally costly; meta-learning can provide warm starts to accelerate convergence.",
            "uuid": "e2362.8",
            "source_info": {
                "paper_title": "Meta-QSAR: a large-scale application of meta-learning to drug design and discovery",
                "publication_date_yy_mm": "2017-09"
            }
        },
        {
            "name_short": "Landmarking & collaborative approaches (mentioned)",
            "name_full": "Landmarking and collaborative filtering methods for meta-learning",
            "brief_description": "Meta-learning techniques from literature: landmarkers use fast/simple algorithms' performance as meta-features; collaborative filtering treats past algorithm evaluations as ratings to recommend algorithms for new datasets.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Meta-learning / algorithm recommendation",
            "problem_description": "Create meta-features or recommendation signals from quick probes (landmarkers) or from matrix factorization of algorithm-dataset performance histories to suggest promising algorithms.",
            "data_availability": "Requires some prior algorithm evaluations across datasets (available in their large baseline), but landmarking can be performed with small sample runs.",
            "data_structure": "Landmarking: small-sample performance vectors; collaborative filtering: matrix of algorithm performances across datasets.",
            "problem_complexity": "Relatively low computational cost for landmarking; collaborative filtering involves matrix factorization complexity but scales with number of datasets and algorithms.",
            "domain_maturity": "Established in the meta-learning literature and referenced as prior art.",
            "mechanistic_understanding_requirements": "Low — methods aim for useful recommendations rather than mechanistic insights.",
            "ai_methodology_name": "Landmarking; collaborative filtering for algorithm recommendation",
            "ai_methodology_description": "Landmarking: run simple/fast algorithms (landmarkers) on dataset or subsamples and use their performance as discriminative meta-features; collaborative filtering: use past algorithm-dataset performances as a rating matrix and apply matrix factorization or CF models to predict algorithm ratings for new datasets.",
            "ai_methodology_category": "Meta-learning / instance-based and collaborative methods",
            "applicability": "Mentioned as effective prior techniques; landmarkers are useful as cheap meta-features and collaborative filtering can exploit large performance matrices.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Recognized in literature as helpful; not central to experiments in this paper though landmarking is discussed as a type of meta-feature.",
            "impact_potential": "Useful components for building robust meta-learning systems, especially when many prior evaluations exist.",
            "comparison_to_alternatives": "Discussed in related work as alternatives to classification/ranking meta-learners; hybrid approaches (landmarkers + decision trees) have been effective historically.",
            "success_factors": "Speed of landmarkers, coverage and density of historical performance data for collaborative filtering.",
            "key_insight": "Simple, fast probes of dataset behaviour (landmarkers) and collaborative filtering over historical runs are valuable complementary techniques in algorithm selection meta-learning.",
            "uuid": "e2362.9",
            "source_info": {
                "paper_title": "Meta-QSAR: a large-scale application of meta-learning to drug design and discovery",
                "publication_date_yy_mm": "2017-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Auto-WEKA",
            "rating": 2
        },
        {
            "paper_title": "Auto-sklearn",
            "rating": 2
        },
        {
            "paper_title": "Model-based optimization (Hutter et al., 2011)",
            "rating": 1
        },
        {
            "paper_title": "Bayesian Optimization (Brochu et al., 2010)",
            "rating": 1
        },
        {
            "paper_title": "Active testing (Leite et al., 2012)",
            "rating": 1
        },
        {
            "paper_title": "Meta-learning by landmarking (Pfahringer et al., 2000)",
            "rating": 1
        }
    ],
    "cost": 0.02132425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Meta-QSAR: a large-scale application of meta-learning to drug design and discovery</h1>
<p>Ivan Olier $\cdot$ Noureddin Sadawi $\cdot$<br>G. Richard Bickerton $\cdot$ Joaquin<br>Vanschoren $\cdot$ Crina Grosan $\cdot$ Larisa<br>Soldatova $\cdot$ Ross D. King</p>
<p>Received: date / Accepted: date</p>
<h4>Abstract</h4>
<p>We investigate the learning of quantitative structure activity relationships (QSARs) as a case-study of meta-learning. This application area is of the highest societal importance, as it is a key step in the development of new medicines. The standard QSAR learning problem is: given a target (usually a protein) and a set of chemical compounds (small molecules) with associated bioactivities (e.g. inhibition of the target), learn a predictive mapping from molecular representation to activity. Although almost every type of machine learning method has been applied to QSAR learning there is no agreed single best way of learning QSARs, and therefore the problem area is well-suited to meta-learning.</p>
<p>We first carried out the most comprehensive ever comparison of machine learning methods for QSAR learning: 18 regression methods, 6 molecular representations, applied to more than 2,700 QSAR problems. (These results have been made publicly available on OpenML and represent a valuable</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>resource for testing novel meta-learning methods.) We then investigated the utility of algorithm selection for QSAR problems. We found that this meta-learning approach significantly outperformed the best individual QSAR learning method (random forests using a molecular fingerprint representation). We conclude that meta-learning outperforms base-learning methods for QSAR learning, and as this investigation is one of the most extensive ever comparisons of base and meta-learning methods ever made, it provides evidence for the general effectiveness of meta-learning over base-learning.</p>
<p>Keywords Meta-learning $\cdot$ Algorithm selection $\cdot$ Drug Discovery $\cdot$ QSAR</p>
<h1>1 Introduction</h1>
<p>The standard approach to predicting how active a chemical compound will be against a given target (usually a protein that needs to be inhibited) in the development of new medicines is to use machine learning models. Currently, there is no agreed single best learning algorithm to do this. In this paper we investigate the utility of meta-learning to address this problem. We aim to discover and exploit relationships between machine learning algorithms, measurable properties of the input data, and the empirical performance of learning algorithms, to infer the best models to predict the activity of chemical compounds on a given target.</p>
<h3>1.1 Quantitative Structure Activity Relationship (QSAR) Learning</h3>
<p>Drug development is one of the most important applications of science, as it is an essential step in the treatment of almost all diseases. Developing a new drug is however slow and expensive. The average cost to bring a new drug to market is $&gt;2.5$ billion US dollars (Tufts, 2014), which means that tropical diseases such as malaria, schistosomiasis, Chagas' disease, etc., which kill millions of people and infect hundreds of millions of others are 'neglected' (Ioset \&amp; Chang, 2011; Leslie, 2011) and that 'orphan' diseases (i.e. those with few sufferers) remain untreatable (Braun et al, 2010). More generally, the pharmaceutical industry is struggling to cope with spiralling drug discovery and development costs (Pammolli et al, 2011). Drug development is also slow, generally taking more than 10 years. This means that there is strong pressure to speed up development, both to save lives and reduce costs. A successful drug can earn billions of dollars a year, and as patent protection is time-limited, even one extra week of patent protection can be of great financial significance.</p>
<p>A key step in drug development is learning Quantitative Structure Activity Relationships (QSARs) (Martin, 2010),(Cherkasov et al., 2014; Cumming et al., 2013). These are functions that predict a compound's bioactivity from its structure. The standard QSAR learning problem is: given a target (usually a protein) and a set of chemical compounds (small</p>
<p>molecules) with associated bioactivities (e.g. inhibiting the target), learn a predictive mapping from molecular representation to activity.</p>
<p>Although almost every form of statistical and machine learning method has been applied to learning QSARs, there is no agreed single best way of learning QSARs. Therefore an important motivation for this work is to better understand the performance characteristics of the main (baseline) machine learning methods currently used in QSAR learning. This knowledge will feed into a better understanding of the performance characteristics of these algorithms, and will enable QSAR practitioners to improve there predictions.</p>
<p>The central motivation for this work is to better understand meta-learning through a case-study in the very important real-world application area of QSAR learning. This application area is an excellent test-bed for the development of meta-learning methodologies. The importance of the subject area means that there are now thousands of publicly available QSAR datasets, all with the same basic structure. Few machine learning application areas have so many datasets - enabling statistical confidence in meta-learning results. In investigating meta-learning we have focused on algorithm selection as this is the simplest form of meta-learning, and its use fits in with our desire to better understand the baseline-learning methods.</p>
<p>A final motivation for the work is to improve the predictive performance of QSAR learning through use of meta-learning. Our hope is that improved predictive performance will feed into faster and cheaper drug development.</p>
<p>To enable others to build on our base-learning and meta-learning work we have placed all our results in OpenML.</p>
<h1>1.2 Meta-Learning: Algorithm Selection</h1>
<p>Meta-learning has been used extensively to select the most appropriate learning algorithm on a given dataset. In this section, we first sketch a general framework for algorithm selection, and then provide an overview of prior approaches and the state-of-the-art in selecting algorithms using meta-learning.</p>
<h3>1.2.1 Algorithm Selection Framework</h3>
<p>The algorithm selection framework contains four main components: First, we construct the problem space $P$, in our case the space of all QSAR datasets. Each dataset expresses the properties and activity of a limited set of molecular compounds (drugs) on a specific target protein. In this paper, we consider 2,764 QSAR datasets, described in more detail in Section 2.2. Second, we describe each QSAR dataset in $P$ with a set of measurable characteristics (meta-features), yielding the feature space $F$. In this paper we include two types of meta-features: those that describe the QSAR data itself (e.g. the</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1: Rice's framework for algorithm selection. Adapted from (Rice, 1976; Smith-Miles, 2008).</p>
<p>number of data points), and those that describe properties of the target protein (e.g. hydrophobicity). We expect that these properties will affect the interplay of different QSAR features, and hence the choice of learning algorithm. The full set of meta-features used in this paper is described in Section 3.</p>
<p><em>Third</em>, the algorithm space <em>A</em> is created by the set of all candidate base-level learning algorithms, in our case a set of 18 regression algorithms combined with several preprocessing steps. These are described in Section 2.1.</p>
<p><em>Finally</em>, the performance space <em>Y</em> represents the empirically measured performance, e.g. root mean squared error (RMSE) (Witten and Frank, 2005) of each algorithm <em>A</em> on each of the QSAR datasets in <em>P</em>.</p>
<p>In the current state-of-the-art, there exists a wide variety of algorithm selection algorithms. If only a single algorithm should be run, we can train a classification model that makes exactly that prediction (Pfahringer et al., 2000; Guerri and Milano, 2012). We can also use a regression algorithm to predict the performance of each algorithm (Xu et al., 2008), build a ranking of promising algorithms (Leite et al., 2012), or use cost-sensitive techniques which allow us to optimize the loss we really care about in the end (Bischl et al., 2012; Xu et al., 2012).</p>
<p>Our task is: for any given QSAR problem <em>x</em> ∈ <em>P</em>, select the best combination of QSAR and molecular representation <em>a</em> ∈ <em>A</em> that maximizes a predefined performance measure <em>y</em> ∈ <em>Y</em>. In this paper, we investigate two meta-learning approaches: 1) classification problem: the aim is to learn a model that captures the relationship between the properties of the QSAR datasets, or meta-data, and the performance of the regression algorithms. This model can then be used to predict the most suitable algorithm for a new dataset. 2) ranking problem: the aim is to fit a model that ranks the QSAR combinations by their predicted performances.</p>
<h3>1.2.2 Previous Work on Algorithm Selection using Meta-Learning</h3>
<p><em>Meta-features</em>. In the meta-learning literature much effort has been devoted to the development of meta-features that effectively describe the</p>
<p>characteristics of the data. These should have discriminative power, meaning that they should be able to distinguish between base-learners in terms of their performance, and have a low computational complexity - preferably lower than $O(n \log n)$ (Pfahringer et al., 2000). Meta-features are typically categorised as one of the following: simple (e.g. number of data points, number of features), statistical (e.g. mean standard deviation of attributes, mean kurtosis of attributes, mean skewness of attributes), or information theoretic (e.g. mean entropy of the features, noise-signal ratio). See (Bickel et al., 2008; Kalousis, 2002; Vanschoren, 2010) for an extensive description of meta-features. A subset of these may be used for regression, and some measures are specifically defined for regression targets (Soares et al., 2004). Other meta-features can be trivially adapted to the regression data. First, landmarking (Pfahringer et al., 2000) works by training and evaluating sets of simple, fast algorithms on the datasets (e.g. a decision stump instead of a full decision tree), and using their performance (e.g. RMSE) as meta-features for the dataset. An analysis of landmarkers for regression problems can be found in Ler et al. (2005).</p>
<p>Another approach is to use model-based characteristics (Peng et al., 2002), obtained by building fast, interpretable models, e.g. decision trees, and then extracting properties of those models, such as the width, the depth and the number of leaves in the tree, and statistical properties (min, max, mean, stdev) of the distribution of nodes in each level of the tree, branch lengths, or occurrences of features in the splitting tests in the nodes. Recent research on finding interesting ways to measure data characteristics includes instance-level complexity (Smith et al., 2014a), measures for unsupervised learning (Lee and Giraud-Carrier, 2011), and discretized meta-features (Lee and Giraud-Carrier, 2008).</p>
<p>Meta-learning has also been successfully applied in stream mining (van Rijn et al., 2015b, 2014) and time series analysis (Prudêncio and Ludermir, 2004), each time requiring novel sets of meta-features.</p>
<p>Selecting algorithms. In meta-learning, algorithm selection is traditionally seen as a learning problem: train a meta-learner that predicts the best algorithm(s) given a set of meta-features describing the data. In the setting of selecting a best single algorithm, experiments on artificial datasets showed that there is no single best meta-learner, but that decision tree-like algorithms (e.g. C5.0boost) seem to have an edge, especially when used in combination with landmarkers (Bensusan and Giraud-Carrier, 2000; Pfahringer et al., 2000). Further experiments performed on real-world data corroborated these results, although they also show that most meta-learners are very sensitive to the exact combination of meta-features used (Köpf et al., 2000).</p>
<p>In the setting of recommending a subset of algorithms it was shown that, when using statistical and information-theoretical meta-features, boosted decision trees obtained best results (Kalousis, 2002; Kalousis and Hilario, 2001). Relational case-based reasoning has also been successfully applied</p>
<p>(Lindner and Studer, 1999; Hilario and Kalousis, 2001), which allows to include algorithm properties independent of the dataset and histogram representations of dataset attribute properties.</p>
<p>Most relevant for this paper is the work by Amasyali and Ersoy (Amasyali and Ersoy, 2009), which uses around 200 meta-features to select the best regression algorithm for a range of artificial, benchmarking, and drug discovery datasets. The reported correlations between meta-features and algorithm performances were typically above 0.9 on artificial and benchmarking datasets, but much worse (below 0.8) on the drug discovery datasets. Feature selection was found to be important to improve meta-learning performance.</p>
<p>Ranking algorithms Another approach is to build a ranking of algorithms, listing which algorithms to try first. Several techniques use k-nearest neighbors (Brazdil et al., 2003; dos Santos et al., 2004), and compute the average rank (or success rate ratio's or significant wins) over all similar prior datasets (Soares and Brazdil, 2000; Brazdil and Soares, 2000). Other approaches directly estimate the performances of all algorithms (Bensusan and Kalousis, 2001), or use predictive clustering trees (Todorovski et al., 2002).</p>
<p>Better results where obtained by subsampling landmarkers, i.e. running all candidate algorithms on several small samples of the new data (Fürnkranz and Petrak, 2001). Meta-learning on data samples (MDS) (Leite and Brazdil, 2005, 2007) builds on this idea by first determining the complete learning curves of a number of learning algorithms on several different datasets. Then, for a new dataset, progressive subsampling is done up to a certain point, creating a partial learning curve, which is then matched to the nearest complete learning curve for each algorithm in order to predict their final performances on the entire new dataset.</p>
<p>Another approach is to sequentially evaluate a few algorithms on the (complete) new dataset and learn from these results. Active testing (Leite et al., 2012) proceeds in a tournament-style fashion: in each round it selects and tests the algorithm that is most likely to outperform the current best algorithm, based on a history of prior duels between both algorithms on similar datasets. Each new test will contribute information to a better estimate of dataset similarity, and thus help to better predict which algorithms are most promising on the new dataset. Large-scale experiments show that active testing outperforms previous approaches, and yields an algorithm whose performance is very close to the optimum, after relatively few tests. More recent work aims to speed up active testing by combining it with learning curves (van Rijn et al., 2015a), so that candidates algorithms only need to be trained on a smaller sample of the data. It also uses a multi-objective criterion called AR3 (Abdulrahman and Brazdil, 2014) that trades off runtime and accuracy so that fast but reasonably accurate candidates are evaluated first. Experimental results show that this method converges extremely fast to an acceptable solution.</p>
<p>Finally, algorithms can also be ranked using collaborative filtering (Bardenet et al., 2013; Misir and Sebag, 2013; Smith et al., 2014b). In this approach, previous algorithm evaluations are used as 'ratings' for a given dataset. For a new dataset, algorithms which would likely perform well (give a high rating) are selected based on collaborative filtering models (e.g. using matrix decompositions).</p>
<p>Model-based optimization Model-based optimization (Hutter et al., 2011) aims to select the best algorithm and/or best hyperparameter settings for a given dataset by sequentially evaluating them on the full dataset. It learns from prior experiments by building a surrogate model that predicts which algorithms and parameters are likely to perform well. An approach that has proven to work well in practice is Bayesian Optimization (Brochu et al., 2010), which builds a surrogate model (e.g. using Gaussian Processes or Random Forests) to predict the expected performance of all candidate configurations, as well as the uncertainty of that prediction. In order to select the next candidate to evaluate, an acquisition function is used that trades off exploitation (choosing candidates in regions known to perform well) versus exploration (trying candidates in a relatively unexplored regions). Bayesian Optimization is used in Auto-WEKA (Thornton et al., 2013) and Auto-sklearn (Feurer et al., 2015), which search for the optimal algorithms and hyperparameters across the WEKA (Hall et al., 2009) and scikit-learn (Pedregosa et al., 2011) environments, respectively. Given that this technique is computationally very expensive, recent research has tried to include meta-learning to find a good solution faster. One approach is to find a good set of initial candidate configurations by using meta-learning (Feurer et al., 2015): based on meta-features, one can find the most similar datasets and use the optimal algorithms and parameter settings for these datasets as the initial candidates to evaluate. In effect, this provides a 'warm start' which yields better results faster.</p>
<h1>1.3 Meta-QSAR Learning</h1>
<p>Almost every form of statistical and machine learning method has been applied to learning QSARs: linear regression, decision trees, neural networks, nearestneighbour methods, support vector machines, Bayesian networks, relational learning, etc. These methods differ mainly in their a priori assumptions they make about the learning task. We focus on regression algorithms as this is how QSAR problems are normally cast.</p>
<p>For Meta-QSAR learning the input data are datasets of compound activity (one for each target protein), different representations of the structures of the compounds, and we aim to learn to predict how well different learning algorithms perform, and to exploit these predictions to improve QSAR predictions. We expect meta-learning to be successful for QSAR because although all the datasets have the same overall structure,</p>
<p>they differ in the numbers of data points (tested chemical compounds), in the range and occurrence of features (compound descriptors), and in the type of chemical/biochemical mechanism that causes the bioactivity. These differences indicate that different machine learning methods are to be used for different kinds of QSAR data.</p>
<p>We first applied meta-learning to predict the machine learning algorithm that is expected to perform best on a given QSAR dataset. This is known as the algorithm selection problem, and can be expressed formally using Rice's framework for algorithm selection (Rice, 1976) as illustrated in Figure 1. We then applied multi-task learning to first test whether it can improve on standard QSAR learning through the exploitation of evolutionary related targets, and whether multi-task learning can further be improved by incorporating the evolutionary distance of targets.</p>
<h1>1.4 Paper Outline</h1>
<p>The remainder of this paper is organized as follows. In Section 2, we report our baseline experiments investigating the effectiveness of a large number of regression algorithms on thousands of QSAR datasets, using different data representations. In Section 3 we describe a novel set of QSAR-specific metafeatures to inform our meta-learning approach. In Section 4 we investigate the utility of meta-learning for selecting the best algorithm for learning QSARs. Finally, Section 5 presents a discussion of our results and future work.</p>
<h2>2 Baseline QSAR Learning</h2>
<p>We first performed experiments with a set of baseline regression algorithms to investigate their effectiveness on QSAR problems. Learning a QSAR model consists of fitting a regression model to a dataset which has as instances the chemical compounds, as input variables the chemical compound descriptors, and as numeric response variable (output) the associated bioactivities.</p>
<h3>2.1 Baseline QSAR Learning Algorithms</h3>
<p>For our baseline QSAR methods we selected 18 regression algorithms, including linear regression, support vector machines, artificial neural networks, regression trees, and random forests. Table 1 lists all the algorithms used and their respective parameter settings. Within the scope of this study, we do not optimize the parameter settings on every dataset, but instead chose values that are likely to perform well on most QSAR datasets. This list includes the most commonly used QSAR methods in the literature.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Short name</th>
<th style="text-align: left;">Name</th>
<th style="text-align: left;">Parameter settings</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">ctree</td>
<td style="text-align: left;">Conditional trees</td>
<td style="text-align: left;">min_split=20, min_bucket=7</td>
</tr>
<tr>
<td style="text-align: left;">rtree</td>
<td style="text-align: left;">Regression trees</td>
<td style="text-align: left;">min_split=20, min_bucket=7</td>
</tr>
<tr>
<td style="text-align: left;">cforest</td>
<td style="text-align: left;">Random forest (with conditional <br> trees)</td>
<td style="text-align: left;">n_trees=500, min_split=20, <br> min_bucket=7</td>
</tr>
<tr>
<td style="text-align: left;">rforest</td>
<td style="text-align: left;">Random forest</td>
<td style="text-align: left;">n_trees=500, min_split=20, <br> min_bucket=7</td>
</tr>
<tr>
<td style="text-align: left;">gbm</td>
<td style="text-align: left;">Generalized boosted regression</td>
<td style="text-align: left;">n_trees=100, depth=1, CV=no, <br> min_obs_node=10</td>
</tr>
<tr>
<td style="text-align: left;">fnn</td>
<td style="text-align: left;">k-Nearest neighbor</td>
<td style="text-align: left;">k=1</td>
</tr>
<tr>
<td style="text-align: left;">earth</td>
<td style="text-align: left;">Adaptive regression splines <br> (earth)</td>
<td style="text-align: left;">(as default)</td>
</tr>
<tr>
<td style="text-align: left;">glmnet</td>
<td style="text-align: left;">Regularized GLM</td>
<td style="text-align: left;">(as default)</td>
</tr>
<tr>
<td style="text-align: left;">ridge</td>
<td style="text-align: left;">Penalized ridge regression</td>
<td style="text-align: left;">(as default)</td>
</tr>
<tr>
<td style="text-align: left;">lm</td>
<td style="text-align: left;">Multiple linear regression</td>
<td style="text-align: left;">(as default)</td>
</tr>
<tr>
<td style="text-align: left;">pcr</td>
<td style="text-align: left;">Principal component regression</td>
<td style="text-align: left;">(as default)</td>
</tr>
<tr>
<td style="text-align: left;">plsr</td>
<td style="text-align: left;">Partial least squares</td>
<td style="text-align: left;">(as default)</td>
</tr>
<tr>
<td style="text-align: left;">rsm</td>
<td style="text-align: left;">Response surface regression</td>
<td style="text-align: left;">(as default)</td>
</tr>
<tr>
<td style="text-align: left;">rvm</td>
<td style="text-align: left;">Relevance vector machine</td>
<td style="text-align: left;">Kernel=RBF, nu=0.2, <br> epsilon=0.1</td>
</tr>
<tr>
<td style="text-align: left;">ksvm</td>
<td style="text-align: left;">Support vector machines</td>
<td style="text-align: left;">Kernel=RBF, nu=0.2, <br> epsilon=0.1</td>
</tr>
<tr>
<td style="text-align: left;">ksvmfp</td>
<td style="text-align: left;">Support vector machines with <br> Tanimoto kernel</td>
<td style="text-align: left;">Kernel=Tanimoto</td>
</tr>
<tr>
<td style="text-align: left;">nnet</td>
<td style="text-align: left;">Neural networks</td>
<td style="text-align: left;">size=3</td>
</tr>
<tr>
<td style="text-align: left;">nneth2o</td>
<td style="text-align: left;">Neural networks using H2O <br> library</td>
<td style="text-align: left;">layers=2, size layer 1 = 0.333<em> <br> n_inputs, layer 2 = <br> 0.667</em>n_inputs</td>
</tr>
</tbody>
</table>
<p>Table 1: List of baseline QSAR algorithms. Abbreviations: n_trees: number of trees; min_split: minimum node size allowed for splitting; min_bucket: minimum size of the bucket. k: number of neighbours; depth: search depth; CV: cross-validation; min_obs_node: minimum number of observations per node; RBF: radial basis function with nu (spread) and epsilon (scale) parameters; size: number of neurons in the hidden layer; n_inputs: length of the input vector.</p>
<p>With the exception of one of the neural networks implementations, for which we used the H2O R package ${ }^{1}$, all of the algorithms were implemented using the MLR R package for machine learning ${ }^{2}$.</p>
<h1>2.2 Baseline QSAR Datasets</h1>
<p>For many years, QSAR research was held back by a lack of openly available datasets. This situation has been transformed by a number of developments. The most important of these is the open availability of the ChEMBL</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>database ${ }^{3}$, a medicinal chemistry database managed by the European Bioinformatics Institute (EBI). It is abstracted and curated from the scientific literature, and covers a significant fraction of the medicinal chemistry corpus. The data consist of information on the drug targets (mainly proteins from a broad set of target families, e.g. kinases), the structures of the tested compounds (from which different chemoinformatic representations may be calculated), and the bioactivities of the compounds on their targets, such as binding constants, pharmacology, and toxicity. The key advantages of using ChEMBL for Meta-QSAR are: (a) it covers a very large number of targets, (b) the diversity of the chemical space investigated, and (c) the high quality of the interaction data. Its main weakness is that for any single target, interaction data on only a relatively small number of compounds are given.</p>
<p>We extracted 2,764 targets from ChEMBL with a diverse number of chemical compounds, ranging from 10 to about 6,000 , each target resulting in a dataset with as many examples as compounds. The target (output) variable contains the associated bioactivities. Bioactivity data were selected on the basis that the target type is a protein, thereby excluding other potential targets such as cell-based and in vivo assays, and the activity type is from a defined list of potency/affinity endpoints (IC50, EC50, Ki, Kd and their equivalents). In the small proportion of cases where multiple activities have been reported for a particular compound-target pair, a consensus value was selected as the median of those activities falling in the modal log unit. The simplified molecular-input line-entry system (SMILES) representation of the molecules was used to calculate molecular properties such as molecular weight (MW), logarithm of the partition coefficient (LogP), topological polar surface area (TPSA), etc. For this we used Dragon version 6 (Mauri et al., 2006), which is a commercially available software library that can potentially calculate up to 4,885 molecular descriptors, depending on the availability of 3D structural information of the molecules. A full list is available on Dragon's website ${ }^{4}$.</p>
<p>As ChEMBL records 2D molecular structures only, we were restricted to estimating a maximum of 1,447 molecular descriptors. We decided to generate datasets using all permitted molecular descriptors as features, and then to extract a subset of 43, which Dragon identifies as basic or constitutional descriptors. We call these representations 'allmolprop' and 'basicmolprop', respectively. For some of the molecules, Dragon failed to compute some of the descriptors, possibly because of bad or malformed structures, and these were treated as missing values. To avoid favouring QSAR algorithms able to deal with missing values, we decided to impute them, as a preprocessing step, using the median value of the corresponding feature.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">Basic set of <br> descriptors (43)</th>
<th style="text-align: left;">All descriptors <br> (1447)</th>
<th style="text-align: left;">FCFP4 fingerprint <br> (1024)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Original dataset</td>
<td style="text-align: left;">basicmolprop (not <br> used)</td>
<td style="text-align: left;">allmolprop (not <br> used)</td>
<td style="text-align: left;">fpFCFP4</td>
</tr>
<tr>
<td style="text-align: left;">Missing value <br> imputation</td>
<td style="text-align: left;">basicmolprop.miss</td>
<td style="text-align: left;">allmolprop.miss</td>
<td style="text-align: left;">(no missing values)</td>
</tr>
</tbody>
</table>
<p>Table 2: Names of the generated dataset representations.</p>
<p>In addition, we calculated the FCFP4 fingerprint representation using the Pipeline Pilot software from BIOVIA (Rogers and Hahn, 2010). The fingerprint representation is the most commonly used in QSAR learning, whereby the presence or absence of a particular molecular substructure in a molecule (e.g. methyl group, benzine ring) is indicated by a Boolean variable. The FCFP4 fingerprint implementation generates 1024 such Boolean variables. We call this dataset representation 'fpFCFP4'. All of the fpFCFP4 datasets were complete, so a missing value imputation step is not necessary.</p>
<p>In summary, we use 3 types of feature representations and 1 level of preprocessing, thus generating 3 different dataset representations for each of the QSAR problems (targets), see Table 2. This produced in total 8,292 datasets from the 2,764 targets.</p>
<h1>2.3 Baseline QSAR Experiments</h1>
<p>The predictive performance of all the QSAR learning methods on the datasets (base QSAR experiments) was assessed by taking the average root mean squared error (RMSE) with 10 -fold cross-validation.</p>
<p>We used the parameter settings mentioned in Table 1 for all experiments. Figure 2 summarizes the overall relative performance (in frequencies) of the QSAR methods for all dataset representations previously mentioned in Table 2. Results showed that random forest ('rforest') was the best performer in 1,162 targets out of 2,764, followed by SVM ('ksvm'), 298 targets, and GLM-NET ('glmnet'), 258 targets. In these results, the best performer is the algorithm with the lowest RMSE, even if it wins by a small margin. In terms of dataset representation, it turned out that datasets formed using FCFP4 fingerprints yielded consistently better models than the rest of the datasets (in 1,535 out of 2,764 situations). Results are displayed in Figure 3.</p>
<p>Figure 4 summarizes the results obtained using various strategies (combinations of QSAR algorithm and dataset representation). As the figure shows, the bar plot is highly skewed towards the top ranked QSAR strategies with a long tail representing QSAR problems in which other algorithms perform better.</p>
<p>Applying random forest to datasets formed using either FCFP4 fingerprints or all molecular properties were the most successful QSAR</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2: Graphical representation of the number of times (target counts) a particular QSAR learning method obtains the best performance (minimum RMSE)</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3: Graphical representation of the number of times (target counts) a dataset representation was fitted with the best performer QSAR method (minimum RMSE)</p>
<p>strategies (in the figure, rforest.fpFCFP4 for 675 and rforest.allmolprop.miss for 396 out of 2,764 targets, respectively). Other strategies, such as regression with ridge penalisation (ridge.fpFCFP4), SVM with Tanimoto kernel (ksvmfp.fpFCFP4), and SVM with RBF kernel (ksvm.fpFCFP4) were particularly successful when using the FCFP4 fingerprint dataset representation (for 154, 141, and 126 targets, respectively). The full list of</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4: Graphical representation of the number of times (target counts) a combination of dataset representation and QSAR method obtained the best performance (minimum RMSE)
strategies ranked by frequency of success is shown in the figure. Combinations that never produced best performances are not shown.</p>
<p>Combinations of QSARs and representations were also ranked by their average performances. For this, we estimated an average RMSE ratio score (aRMSEr) which is adapted from (Brazdil et al., 2003), originally introduced for classification tasks. Our score was formulated as follows:</p>
<p>$$
a R M S E r_{p}=\frac{\sum_{q} \sqrt[i]{\prod_{i} R M S E r_{p, q}^{i}}}{m}
$$</p>
<p>where $R M S E r_{p, q}^{i}=R M S E_{q}^{i} / R M S E_{p}^{i}$ is the (inverse) RMSE ratio between algorithms $p$ and $q$ for the dataset $i$. In the same equation, $m$</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 5: Average ranking of dataset representation and QSAR combination as estimated using the RMSE ratio.</p>
<p>represents the number of algorithms, whilst <em>n</em>, the number of targets. Notice that, an <em>RMSEr</em><sup><em>p</em></sup><sub><em>p,q</em></sub> &gt; 1 indicates that algorithm <em>p</em> outperformed algorithm <em>q</em>. Ranking results using aRMSEr are presented in Figure 5.</p>
<p>We ran a Friedman test with a corresponding pairwise post-hoc test (Demsar, 2006), which is a non-parametric equivalent of ANOVA in order to verify whether the performances of baseline QSAR strategies were statistically different. The Friedman test ranks the strategies used per dataset according to their performance and tests them against the null hypothesis that they are equivalent. A post-hoc test was carried out if the null hypothesis is rejected. For this we used the Nemenyi test, also suggested by Demsar (2006). The resulting p-value (10E − 06) from the test indicates the null hypothesis was invalid (p-value &lt;&lt; 0.05), which suggests that algorithm selection should significantly impact the overall performance.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 6: Box plot displays the post-hoc test results over the top 6 ranked best performer QSAR strategies: 1 - rforest.fpFCFP4, 2 - ksvm.fpFCFP4, 3 - ksvmfp.fpFCFP4, 4 - rforest.allmolprop.miss, 5 - glmnet.fpFCFP4, and 6 - rforest.basicmolprop.miss.fs. Statistically significant comparisons (p-value $&lt;0.05$ ) represented with green boxes.</p>
<p>We ran the aforementioned post-hoc test for the top 6 QSAR strategies ${ }^{5}$ presented in Figure 5. Results are shown in Figure 6. It shows that performance differences between the QSAR strategies were statistically significant with the exception of rforest.allmolprop.miss vs ksvmfp.fpFCFP4.</p>
<h1>3 Meta-features for meta-QSAR learning</h1>
<h3>3.1 Meta-QSAR ontology</h3>
<p>Meta-learning analysis requires a set of meta-features. In our meta-qsar study we used measurable characteristics of the considered in the base study datasets and drug target properties as meta-features. We utilised a similar approach employed by BODO (the Blue Obelisk Descriptor Ontology) (Floris et al., 2011) and the Chemical Information Ontology (Hastings et al., 2011) for the formal definitions of molecular descriptors used in QSAR studies, and developed a meta-qsar ontology ${ }^{6}$.</p>
<p>The meta-qsar ontology provides formal definitions for the meta-features used in the reported meta-qsar study (see Figure 7). The meta-features are defined at the conceptual level, meaning that the ontology does not contain</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Fig. 7: The key branches of the meta-qsar ontology (a fragment).
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Fig. 8: The representation of the meta-features and their values.
instance-level values of meta-features for each of 16,584 considered dataset. For example, the meta-feature 'multiple information' is defined as the meta-feature of a dataset (multiple information (also called total correlation) among the random variables in the dataset), but the meta-qsar ontology does not contain values of this meta-feature for each dataset. Instead, it contains links to the code to calculate values of the relevant features. For example, we used the R Package Peptides ${ }^{7}$ to calculate values of the meta-feature 'hydrophobicity'. Figure 8 shows how this information is captured in the meta-qsar ontology. The description of the selected meta-features and instructions on the calculation of their values are available online ${ }^{8}$.</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">multiinfo</td>
<td style="text-align: left;">Multiple information (also called total correlation) <br> among the random variables in the dataset.</td>
</tr>
<tr>
<td style="text-align: left;">mutualinfo</td>
<td style="text-align: left;">Mutual information between nominal attributes X and <br> Y. Describes the reduction in uncertainty of Y due to <br> the knowledge of X, and leans on the conditional <br> entropy $H(Y \mid X)$.</td>
</tr>
<tr>
<td style="text-align: left;">nentropyfeat</td>
<td style="text-align: left;">Normalised entropy of the features which is the class <br> entropy divided by log(n) where n is the number of the <br> features.</td>
</tr>
<tr>
<td style="text-align: left;">mmeanfeat</td>
<td style="text-align: left;">Average mean of the features.</td>
</tr>
<tr>
<td style="text-align: left;">msdfeat</td>
<td style="text-align: left;">Average standard deviation of the features.</td>
</tr>
<tr>
<td style="text-align: left;">kurtresp</td>
<td style="text-align: left;">Kurtosis of the response variable.</td>
</tr>
<tr>
<td style="text-align: left;">meanresp</td>
<td style="text-align: left;">Mean of the response variable.</td>
</tr>
<tr>
<td style="text-align: left;">skewresp</td>
<td style="text-align: left;">Skewness of the response variable.</td>
</tr>
<tr>
<td style="text-align: left;">nentropyresp</td>
<td style="text-align: left;">Normalised entropy of the response variable.</td>
</tr>
<tr>
<td style="text-align: left;">sdresp</td>
<td style="text-align: left;">Standard deviation of the response.</td>
</tr>
<tr>
<td style="text-align: left;">aggFCFP4fp (1024 features)</td>
<td style="text-align: left;">Aggregated fingerprints and normalized over the <br> number of instances in the dataset.</td>
</tr>
</tbody>
</table>
<p>Table 3: Dataset meta-features (Examples).</p>
<h1>3.2 Dataset meta-features</h1>
<p>The considered 16,584 datasets have a range of different properties, e.g. 'number of compounds' (instances) in the dataset, 'entropy' and 'skewness' of the features and 'target meta-feature', 'mutual information' and 'total correlation' between the input and output features (see Table 3 for more detail). The dataset properties have a significant effect on the performance of the explored algorithms and were used for the meta-qsar learning. Figure 12 shows the level of influence of different categories of meta-features. For example information-theoretical meta-features make a considerable contribution to meta-learning.</p>
<p>Some descriptors of the dataset properties, e.g. 'number of instances', have been imported from the Data Mining Optimization (DMOP) Ontology 9 (Keeta et al., 2015). We also added qsar-specific dataset descriptors 'aggregated fingerprint'. These were calculated by summing 1 s (set bits) in each of the 1024 columns and normalised by the number of the compounds in each dataset.</p>
<h3>3.3 Drug target meta-features</h3>
<h3>3.3.1 Drug target properties</h3>
<p>The QSAR datasets are additionally characterized by measurable properties of the drug target (a protein) they represent, such as 'aliphatic index', 'sequence length', 'isoelectric point' (see Table 4 for more details). These differ from</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>the molecular properties we used to describe the chemical compounds in the QSAR dataset instances, e.g. 'molecular weight' (MW), 'LogP'.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Feature</th>
<th style="text-align: center;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Aliphatic index</td>
<td style="text-align: center;">The Aliphatic index (Atsushi, 1980) is defined as the relative volume occupied by aliphatic side chains (Alanine, Valine, Isoleucine, and Leucine). It may be regarded as a positive factor for the increase of thermo stability of globular proteins.</td>
</tr>
<tr>
<td style="text-align: center;">Hydrophobicity</td>
<td style="text-align: center;">Hydrophobicity is the association of non-polar groups or molecules in an aqueous environment which arises from the tendency of water to exclude non-polar molecules (Mcnaught and Wilkinson, 1997).</td>
</tr>
<tr>
<td style="text-align: center;">Boman index</td>
<td style="text-align: center;">This the potential protein interaction index proposed by Boman (Boman, 2003). It is calculated as the sum of the solubility values for all residues in a sequence (D. Osorio and Torres, 2014).</td>
</tr>
<tr>
<td style="text-align: center;">Hydrophobicity (38 features)</td>
<td style="text-align: center;">Hydrophobicity is the association of non-polar groups or molecules in an aqueous environment which arises from the tendency of water to exclude non-polar molecules (Mcnaught and Wilkinson, 1997). We estimated 38 variants of hydrophobicity.</td>
</tr>
<tr>
<td style="text-align: center;">Net charge</td>
<td style="text-align: center;">The theoretical net charge of a protein sequence as described by Moore (Moore, 1985).</td>
</tr>
<tr>
<td style="text-align: center;">Molecular weight</td>
<td style="text-align: center;">Ratio of the mass of a molecule to the unified atomic mass unit. Sometimes called the molecular weight or relative molar mass (Mcnaught and Wilkinson, 1997).</td>
</tr>
<tr>
<td style="text-align: center;">Isoelectric point</td>
<td style="text-align: center;">The pH value at which the net electric charge of an elementary entity is zero. ( pI is a commonly used symbol for this kind-of-quantity, however more accurate symbol is $\mathrm{pH}(\mathrm{I})$ ) (Mcnaught and Wilkinson, 1997).</td>
</tr>
<tr>
<td style="text-align: center;">Sequence length</td>
<td style="text-align: center;">A number of amino acids in a protein sequence.</td>
</tr>
<tr>
<td style="text-align: center;">Instability index</td>
<td style="text-align: center;">The instability index was proposed by (Guruprasad, 1990). A protein whose instability index is smaller than 40 is predicted as stable, a value above 40 predicts that the protein may be unstable.</td>
</tr>
<tr>
<td style="text-align: center;">DC groups (400 features)</td>
<td style="text-align: center;">The Dipeptide Composition descriptor (Xiao et al., 2015; Bhasin and Raghava, 2004) captures information about the fraction and local order of amino acids.</td>
</tr>
</tbody>
</table>
<p>Table 4: Drug targets meta-features (Examples).</p>
<h1>3.3.2 Drug target groupings</h1>
<p>We also used drug target groupings (Imming et al., 2006), such as 'drug target classes', and 'the preferred name groupings', as meta-features. These enable meta-learning to exploit known biological/chemical relationships between the targets (proteins). Indeed, if the target proteins are similar, this may make the resulting datasets more similar too.
Drug target classes: The ChEMBL database curators have classified the</p>
<p>protein targets in a manually curated family hierarchy. The version of the hierarchy that we have used (taken from ChEMBL20) comprises 6 levels, with Level 1 (L1) being the broadest class, and Level 6 (L6) the most specific. For example, the protein target 'Tyrosine-protein kinase Srms' is classified as follows: Enzyme (L1), Kinase (L2), Protein Kinase (L3), TK protein kinase group (L4), Tyrosine protein kinase Src family (L5), Tyrosine protein kinase Srm (L6). Different classes in Level 1 are not evolutionarily related to one another, whereas members of classes in L3 and below generally share common evolutionary origins. The picture is mixed for L2. The hierarchy is not fully populated, with the greatest emphasis being placed on the target families of highest pharmaceutical interest, and the different levels of the hierarchy are not defined by rigorous criteria. However, the hierarchical classification provides a useful means of grouping related targets at different levels of granularity.
The preferred name drug targets grouping: The ChEMBL curators have also assigned each protein target a preferred name - in a robust and consistent manner, independent of the various adopted names and synonyms used elsewhere. This preferred name is based on the practice that individual proteins can be described by a range of different identifiers and textual descriptions across the various data resources. The detailed manual annotation of canonical target names means that, for the most part, orthologous proteins (evolutionarily related proteins with the same function) from related species are described consistently, allowing the most related proteins to be grouped together. In the preferred name groupings, we obtained 468 drug target groups, each with two or more drug targets. The largest drug target group is that of Dihydrofolate Reductase with 21 drug targets.</p>
<h1>4 Meta-Learning: QSAR Algorithm Selection</h1>
<p>We cast the meta-QSAR problem as two different problems: 1) the classification task to predict which QSAR method should be used for a particular QSAR problem; and 2) ranking prediction task to rank QSAR methods by their performances. This entails a number of extensions to Rice's framework in Figure 1, as we are now dealing with multiple dataset representations per QSAR problem, and learning algorithm. The resulting setup is shown in Figure 9. Each original QSAR problem is first represented in 3 different ways resulting in 3 datasets for each QSAR target, from which we extract 11 dataset-based meta-features each (see Section 3.2) ${ }^{10}$, as well as over 450 meta-features based on the target (protein) that the dataset represents (see Section 3.3). The space of algorithms consists of workflows that generate the base-level features, and run one of the the 18 regression algorithms (see Section 2.1), resulting in 52 workflows which are evaluated,</p>
<p><sup id="fnref7:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Fig. 9: Meta-learning setup to select QSAR combinations (workflows) for a given QSAR dataset. The 52 QSAR combinations are generated by combining 3 types of representation/preprocessing with 17 regression algorithms, plus the Tanimoto KSVM which was only run on the fingerprint representation.</p>
<p>Based on their RMSE, on the corresponding datasets (those with the same representation).</p>
<h3>4.1 Meta-QSAR dataset</h3>
<p>A training meta-dataset was formed using the meta-features extracted from the baseline QSAR datasets as the inputs. For the classification tasks we used the best QSAR strategy (combination of QSAR method and dataset representation) per target as the output labels, whilst for the ranking tasks, the QSAR performances (RMSEs) were used. Figure 10 shows a schematic representation of the meta-dataset used in the meta-learning experiments. As this figure shows, we used meta-features derived from dataset and drug target properties. The size of the final meta-dataset was 2,394 meta-features by 2,764 targets.</p>
<h3>4.2 Meta-QSAR learning algorithms</h3>
<p>A meta-learning classification problem using all possible combinations of QSAR methods and dataset representations was implemented using a random forest with 500 trees. Given the large number of classes (52 combinations)</p>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Fig. 10: Schematic representation of the meta-dataset used for meta-QSAR.
and the highly imbalanced classification problem (as shown in Figure 4, additional random forest implementations using the top 2, 3, 6, 11 and 16 combinations (Figure 5) were also investigated. For the ranking problem, we used two approaches: K-nearest neighbour approach ( k -NN), as suggested in (Brazdil et al., 2003), and a multi-target regression approach. Experiments with k-NN were carried out using $1,5,10,50,100,500$, and all neighbours. The multi-target regression was implemented using a multivariate random forest regression (Segal and Xiao, 2011) with 500 trees to predict QSAR performances and with them, to rank QSAR combinations. All implementations were assessed using 10 -fold cross-validation.</p>
<h1>4.3 Results</h1>
<p>Algorithm selection experiments were applied to the 6 classification problems defined above. Results of the classification performances are presented in Figure 11 in the form of classification accuracies. As can be observed in the figure, performances improve as the number of base-learners decreases.</p>
<p>We also use the all-classes random forest implementation to estimate the importance of each meta-feature in the classification task, as estimated using the mean decrease accuracy. Summary results considered by meta-feature groups are presented in Figure 12. It is seen that the meta-features belonging to the information theory group (all dataset meta-features but the aggregated fingerprints, Table 3) were the most relevant, although we found all groups contributed to the task.</p>
<p>As mentioned before, k-NN and multivariate random forest were used to implement ranking models. We used the Spearman's rank correlation coefficient to compare the predicted with the actual rankings (average of the actual rankings were shown in Figure 5). Results of these comparisons are shown in Figure 13. It is observed from the figure that the multivariate random forest and 50-nearest neighbours implementations (mRF and 50-NN in the figure) predicted better rankings, overall. For illustrative purpose, the average of the predicted rankings by multivariate random forest is displayed in Figure 14.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>10 The actual number (21) is slightly smaller because some meta-features, such as the number of instances, is identical for each dataset.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref7:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>